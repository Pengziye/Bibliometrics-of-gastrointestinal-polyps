FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Majid, A
   Khan, MA
   Yasmin, M
   Rehman, A
   Yousafzai, A
   Tariq, U
AF Majid, Abdul
   Khan, Muhammad Attique
   Yasmin, Mussarat
   Rehman, Amjad
   Yousafzai, Abdullah
   Tariq, Usman
TI Classification of stomach infections: A paradigm of convolutional neural
   network along with classical features fusion and selection
SO MICROSCOPY RESEARCH AND TECHNIQUE
LA English
DT Article
DE CNN features; database preparation; features selection; gastric
   infections; handcrafted features
ID HYBRID FEATURE-SELECTION; GENETIC ALGORITHM; SEGMENTATION; IMAGES;
   ENDOSCOPY; RECOGNITION; DIAGNOSIS; STRATEGY; DISEASES; SYSTEM
AB Automated detection and classification of gastric infections (i.e., ulcer, polyp, esophagitis, and bleeding) through wireless capsule endoscopy (WCE) is still a key challenge. Doctors can identify these endoscopic diseases by using the computer-aided diagnostic (CAD) systems. In this article, a new fully automated system is proposed for the recognition of gastric infections through multi-type features extraction, fusion, and robust features selection. Five key steps are performed-database creation, handcrafted and convolutional neural network (CNN) deep features extraction, a fusion of extracted features, selection of best features using a genetic algorithm (GA), and recognition. In the features extraction step, discrete cosine transform, discrete wavelet transform strong color feature, and VGG16-based CNN features are extracted. Later, these features are fused by simple array concatenation and GA is performed through which best features are selected based on K-Nearest Neighbor fitness function. In the last, best selected features are provided to Ensemble classifier for recognition of gastric diseases. A database is prepared using four datasets-Kvasir, CVC-ClinicDB, Private, and ETIS-LaribPolypDB with four types of gastric infections such as ulcer, polyp, esophagitis, and bleeding. Using this database, proposed technique performs better as compared to existing methods and achieves an accuracy of 96.5%.
C1 [Majid, Abdul; Yasmin, Mussarat] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
   [Khan, Muhammad Attique; Yousafzai, Abdullah] HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Rawalpindi, Pakistan.
   [Rehman, Amjad] Prince Sultan Univ Riyadh, AIDA Lab CCIS, Riyadh, Saudi Arabia.
   [Tariq, Usman] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci, Al Kharj, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); NITEC University; Prince Sultan
   University; Prince Sattam Bin Abdulaziz University
RP Khan, MA (通讯作者)，HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Rawalpindi, Pakistan.
EM attique@ciitwah.edu.pk
RI Tariq, Usman/AAE-8037-2022; khan, sajid/HGE-2406-2022; Khan, Dr.
   Muhammad Attique/AAX-2644-2021; Yasmin, Mussarat/HPC-9476-2023; Tariq,
   Usman/AAF-8954-2020; Rehman, Amjad/GXV-0915-2022
OI Tariq, Usman/0000-0001-7672-1187; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Rehman, Amjad/0000-0002-3817-2655; Attique
   Khan, Muhammad/0000-0001-7058-0715
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Akram T., 2018, J AMBIENT INTELL HUM, P1, DOI DOI 10.1007/S12652-018-1051-5
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Billah M., 2017, INT J BIOMED IMAGING, V2017, P1, DOI DOI 10.1155/2017/9545920
   BLEDSOE WW, 1961, OPER RES, V9, pB145
   cancer.net, 2019, STOM CANC STAT
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Chen Yingju, 2012, Diagn Ther Endosc, V2012, P418037, DOI 10.1155/2012/418037
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P2355, DOI 10.1109/LGRS.2017.2764915
   Cogan T, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103351
   Das AK, 2018, APPL SOFT COMPUT, V65, P400, DOI 10.1016/j.asoc.2018.01.040
   De Souza L. A., 2017, 2017 30 SIBGRAPI C G
   Deeba F, 2018, BIOMED SIGNAL PROCES, V40, P415, DOI 10.1016/j.bspc.2017.10.011
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ghareb AS, 2016, EXPERT SYST APPL, V49, P31, DOI 10.1016/j.eswa.2015.12.004
   Ghatwary N, 2019, IEEE ACCESS, V7, P84374, DOI 10.1109/ACCESS.2019.2925585
   Gunal S, 2012, TURK J ELECTR ENG CO, V20, P1296, DOI 10.3906/elk-1101-1064
   Holland J. H., 1992, ADAPTATION NATURAL A, DOI [10.7551/mitpress/1090.001.0001 10.7551/mitpress/1090.001.0001, DOI 10.7551/MITPRESS/1090.001.0001]
   Hosseini S., 2018, ARXIV180107848, P8
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Khan MA, 2020, 2019 INT C COMP INF
   Khan MA, 2020, MED TEACH, V42, P476, DOI 10.1080/0142159X.2019.1626979
   Khan MA, 2021, NAT PROD RES, V35, P984, DOI 10.1080/14786419.2019.1608546
   Khan MA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12497
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Kishore M., 2015, INT J COMPUTER SCI I, V7, P2074
   Kwolek B, 2005, LECT NOTES COMPUT SC, V3696, P551, DOI 10.1007/11550822_86
   Lee JK, 2020, STRESS, V23, P153, DOI 10.1080/10253890.2019.1660871
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Munzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Nayak RS, 2019, PATTERN RECOGNIT LET
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pontabry J, 2017, MED IMAGE ANAL, V35, P313, DOI 10.1016/j.media.2016.07.005
   Rajaei A., 2011, INT J ENG SCI, V4, P131
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro MG, 2019, EXPERT SYST APPL, V120, P262, DOI 10.1016/j.eswa.2018.11.034
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Sharma M, 2019, J NEUROSURG-SPINE, V30, P623, DOI 10.3171/2018.10.SPINE18952
   Sharma M, 2019, J NEUROSURG, V131, P489, DOI [10.3171/2018.4.JNS172909, 10.1007/s40032-017-0423-5]
   Shi QQ, 2018, IEEE ACCESS, V6, P38656, DOI 10.1109/ACCESS.2018.2853620
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI 10.3322/caac.21395
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Swain P, 2003, GUT, V52, P48
   Uguz H, 2011, KNOWL-BASED SYST, V24, P1024, DOI 10.1016/j.knosys.2011.04.014
   Uysal AK, 2014, EXPERT SYST APPL, V41, P5938, DOI 10.1016/j.eswa.2014.03.041
   Vasilakakis M, 2019, EXPERT REV GASTROENT, V13, P129, DOI 10.1080/17474124.2019.1553616
   Yao H., 2016, 2016 3 INT C INF SCI
   Yi JR, 2017, IEEE COMPUT SOC CONF, P860, DOI 10.1109/CVPRW.2017.119
NR 64
TC 82
Z9 82
U1 7
U2 52
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1059-910X
EI 1097-0029
J9 MICROSC RES TECHNIQ
JI Microsc. Res. Tech.
PD MAY
PY 2020
VL 83
IS 5
BP 562
EP 576
DI 10.1002/jemt.23447
EA JAN 2020
PG 15
WC Anatomy & Morphology; Biology; Microscopy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Anatomy & Morphology; Life Sciences & Biomedicine - Other Topics;
   Microscopy
GA LG2KJ
UT WOS:000509376700001
PM 31984630
DA 2023-04-20
ER

PT J
AU Tokai, Y
   Yoshio, T
   Aoyama, K
   Horie, Y
   Yoshimizu, S
   Horiuchi, Y
   Ishiyama, A
   Tsuchida, T
   Hirasawa, T
   Sakakibara, Y
   Yamada, T
   Yamaguchi, S
   Fujisaki, J
   Tada, T
AF Tokai, Yoshitaka
   Yoshio, Toshiyuki
   Aoyama, Kazuharu
   Horie, Yoshimasa
   Yoshimizu, Shoichi
   Horiuchi, Yusuke
   Ishiyama, Akiyoshi
   Tsuchida, Tomohiro
   Hirasawa, Toshiaki
   Sakakibara, Yuko
   Yamada, Takuya
   Yamaguchi, Shinjiro
   Fujisaki, Junko
   Tada, Tomohiro
TI Application of artificial intelligence using convolutional neural
   networks in determining the invasion depth of esophageal squamous cell
   carcinoma
SO ESOPHAGUS
LA English
DT Article
DE Esophageal cancer; Artificial intelligence; Squamous cell carcinoma
ID CANCER; MUCOSAL
AB Objectives In Japan, endoscopic resection (ER) is often used to treat esophageal squamous cell carcinoma (ESCC) when invasion depths are diagnosed as EP-SM1, whereas ESCC cases deeper than SM2 are treated by surgical operation or chemoradiotherapy. Therefore, it is crucial to determine the invasion depth of ESCC via preoperative endoscopic examination. Recently, rapid progress in the utilization of artificial intelligence (AI) with deep learning in medical fields has been achieved. In this study, we demonstrate the diagnostic ability of AI to measure ESCC invasion depth. Methods We retrospectively collected 1751 training images of ESCC at the Cancer Institute Hospital, Japan. We developed an AI-diagnostic system of convolutional neural networks using deep learning techniques with these images. Subsequently, 291 test images were prepared and reviewed by the AI-diagnostic system and 13 board-certified endoscopists to evaluate the diagnostic accuracy. Results The AI-diagnostic system detected 95.5% (279/291) of the ESCC in test images in 10 s, analyzed the 279 images and correctly estimated the invasion depth of ESCC with a sensitivity of 84.1% and accuracy of 80.9% in 6 s. The accuracy score of this system exceeded those of 12 out of 13 board-certified endoscopists, and its area under the curve (AUC) was greater than the AUCs of all endoscopists. Conclusions The AI-diagnostic system demonstrated a higher diagnostic accuracy for ESCC invasion depth than those of endoscopists and, therefore, can be potentially used in ESCC diagnostics.
C1 [Tokai, Yoshitaka; Yoshio, Toshiyuki; Horie, Yoshimasa; Yoshimizu, Shoichi; Horiuchi, Yusuke; Ishiyama, Akiyoshi; Tsuchida, Tomohiro; Hirasawa, Toshiaki; Fujisaki, Junko] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Gastroenterol, Koto Ku, 3-8-31 Ariake, Tokyo 1358550, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] AI Med Serv Inc, Toshima Ku, Tokyo, Japan.
   [Horie, Yoshimasa] Toho Univ, Ohashi Med Ctr, Dept Internal Med, Div Gastroenterol & Hepatol,Meguro Ku, Tokyo, Japan.
   [Sakakibara, Yuko] Osaka Natl Hosp, Dept Gastroenterol, Osaka, Japan.
   [Yamada, Takuya] Osaka Rosai Hosp, Dept Gastroenterol, Sakai, Osaka, Japan.
   [Yamaguchi, Shinjiro] Kansai Rosai Hosp, Dept Gastroenterol, Amagasaki, Hyogo, Japan.
   [Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
C3 Japanese Foundation for Cancer Research; Toho University; Osaka National
   Hospital; Osaka Rosai Hospital; Kansai Rosai Hospital
RP Yoshio, T (通讯作者)，Japanese Fdn Canc Res, Canc Inst Hosp, Dept Gastroenterol, Koto Ku, 3-8-31 Ariake, Tokyo 1358550, Japan.
EM toshiyuki.yoshio@jfcr.or.jp
RI Yoshio, Toshiyuki/ABC-4723-2021; Horiuchi, Yusuke/V-3881-2019
OI Yoshio, Toshiyuki/0000-0002-6546-0329; Horiuchi,
   Yusuke/0000-0001-8116-8152; Hirasawa, Toshiaki/0000-0002-6450-1934
FU Uehara Memorial Foundation
FX This study was funded by the Uehara Memorial Foundation.
CR Bollschweiler E, 2006, ENDOSCOPY, V38, P149, DOI 10.1055/s-2006-924993
   Chino O., 2015, GASTROENTEROL ENDOSC, V57, P1243
   Ebi M, 2015, GASTROINTEST ENDOSC, V81, P1355, DOI 10.1016/j.gie.2014.11.015
   Higuchi Katsuhiko, 2009, Gastrointest Cancer Res, V3, P153
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Kamangar F, 2006, J CLIN ONCOL, V24, P2137, DOI 10.1200/JCO.2005.05.2308
   Kanda Y, 2013, BONE MARROW TRANSPL, V48, P452, DOI 10.1038/bmt.2012.244
   Kuwano H, 2015, ESOPHAGUS-TOKYO, V12, P1, DOI 10.1007/s10388-014-0465-1
   Makuuchi H, 1997, DIGEST ENDOSC, V9, P110, DOI DOI 10.1111/j.1443-1661.1997.tb00469.x
   NAKAGAWA K, 2019, GASTROINTEST ENDOSC
   Natsugoe S, 1998, ONCOLOGY-BASEL, V55, P235, DOI 10.1159/000011857
   Saeki H, 2015, J GASTROENTEROL, V50, P406, DOI 10.1007/s00535-014-0983-6
   Shimizu Y, 2004, GASTROINTEST ENDOSC, V59, P199, DOI 10.1016/S0016-5107(03)02688-9
   Tajima Y, 2000, CANCER, V89, P248, DOI 10.1002/1097-0142(20000715)89:2<248::AID-CNCR7>3.0.CO;2-Q
   Thosani N, 2012, GASTROINTEST ENDOSC, V75, P242, DOI 10.1016/j.gie.2011.09.016
   Wei WQ, 2015, J CLIN ONCOL, V33, P1951, DOI 10.1200/JCO.2014.58.0423
NR 16
TC 53
Z9 56
U1 3
U2 19
PU SPRINGER JAPAN KK
PI TOKYO
PA SHIROYAMA TRUST TOWER 5F, 4-3-1 TORANOMON, MINATO-KU, TOKYO, 105-6005,
   JAPAN
SN 1612-9059
EI 1612-9067
J9 ESOPHAGUS-TOKYO
JI Esophagus
PD JUL
PY 2020
VL 17
IS 3
BP 250
EP 256
DI 10.1007/s10388-020-00716-x
EA JAN 2020
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA MC1SG
UT WOS:000509133500001
PM 31980977
DA 2023-04-20
ER

PT J
AU Axon, ATR
AF Axon, Anthony Thomas Roger
TI Fifty years of digestive endoscopy: Successes, setbacks, solutions and
   the future
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE disinfection; flexible digestive endoscopy; history; setbacks; successes
ID GASTROINTESTINAL ENDOSCOPY; INFECTION; SPHINCTEROTOMY; TRANSMISSION;
   STOMACH; PAPILLA; SEPSIS; VATER; ERCP
AB Flexible endoscopes became generally available 50 years ago and created a revolution in the practice of gastroenterology. They improved diagnosis enormously, enabled quicker, less invasive, and more cost-effective surgical treatment, while endoscopic screening has prevented many cancer deaths. The new technology stimulated research leading to a better understanding of gastrointestinal pathology, identifying new diseases and clarifying the etiology of others. Better-controlled clinical trials accelerated the use of newer and more effective drugs. National and international endoscopy societies supported nursing input, encouraged research, stimulated specialist journals, and devised guidelines that encouraged audit and quality assurance. Advances in instrument design and the manufacture of new accessories enhanced endoscopic technique, diagnostic ability, patient comfort, and safety. The risk of cross-infection inherent in the use of complex labile equipment that cannot be autoclaved remains a challenge. Endoscopy societies working closely with industry have established rigid protocols for high-level disinfection that minimize the risks, but strict adherence to guidelines and continued vigilance is essential, especially with the increasing prevalence of antibiotic-resistant commensals that can give rise to opportunistic infection. Government health departments have a responsibility to encourage and support research in this area by endoscopists, instrument manufacturers, and the pharmaceutical industry. Current trends suggest that in the future, artificial intelligence will greatly improve endoscopic diagnosis, and that therapeutic endoscopy will expand, encouraging endoscopists to subspecialize.
C1 [Axon, Anthony Thomas Roger] Leeds Teaching Hosp NHS Trust, Dept Gastroenterol, Leeds, W Yorkshire, England.
   [Axon, Anthony Thomas Roger] Univ Leeds, Leeds, W Yorkshire, England.
C3 University of Leeds; University of Leeds
RP Axon, ATR (通讯作者)，Nidd Pk House, Nidd HG3 3BN, N Yorkshire, England.
EM axon@btinternet.com
CR Anderson, 2012, GASTROINTEST ENDOSC, V75, P467, DOI [DOI 10.1016/J.GIE.2011.07.010, 10.1016/j.gie.2011.07.010]
   [Anonymous], 2018, NAT BIOTECHNOL, V36, P555, DOI 10.1038/nbt.4193
   AXON ATR, 1983, GUT, V24, P1064, DOI 10.1136/gut.24.11.1064
   AXON ATR, 1981, LANCET, V1, P1093
   Axon ATR, 2001, ENDOSCOPY, V33, P1070, DOI 10.1055/s-2001-18937
   AXON ATR, 1974, LANCET, V1, P656
   BEECHAM HJ, 1979, JAMA-J AM MED ASSOC, V241, P1013, DOI 10.1001/jama.241.10.1013
   Beilenhoff U, 2018, ENDOSCOPY, V50, P1205, DOI 10.1055/a-0759-1629
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   CHMEL H, 1976, AM J MED, V60, P203, DOI 10.1016/0002-9343(76)90429-0
   CLASSEN M, 1974, DEUT MED WOCHENSCHR, V99, P496, DOI 10.1055/s-0028-1107790
   COTTON PB, 1973, BMJ-BRIT MED J, V2, P505, DOI 10.1136/bmj.2.5865.505
   COTTON PB, 1973, BRIT J SURG, V60, P629, DOI 10.1002/bjs.1800600813
   COTTON PB, 1972, GUT, V13, P1014, DOI 10.1136/gut.13.12.1014
   Cotton PB, 2009, GASTROINTEST ENDOSC, V70, P80, DOI 10.1016/j.gie.2008.10.039
   DEYHLE P, 1972, ENDOSCOPY, V4, P102, DOI 10.1055/s-0028-1098169
   DIMAGNO EP, 1980, LANCET, V1, P629
   ELSON CO, 1975, GASTROENTEROLOGY, V69, P507
   GREENE WH, 1974, GASTROENTEROLOGY, V67, P912
   HIRSCHOWITZ B, 1961, LANCET, V1, P1074
   HIRSCHOWITZ BI, 1958, GASTROENTEROLOGY, V35, P50
   HOPKINS HH, 1954, NATURE, V173, P39, DOI 10.1038/173039b0
   Inoue H, 2010, ENDOSCOPY, V42, P265, DOI 10.1055/s-0029-1244080
   KASUGAI T, 1972, GASTROENTEROLOGY, V63, P227
   KAWAI K, 1970, Gastroenterologia Japonica, V5, P215
   KAWAI K, 1974, GASTROINTEST ENDOSC, V20, P148, DOI 10.1016/S0016-5107(74)73914-1
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kovaleva J, 2013, CLIN MICROBIOL REV, V26, P231, DOI 10.1128/CMR.00085-12
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Magill SS, 2018, NEW ENGL J MED, V379, P1732, DOI 10.1056/NEJMoa1801550
   Murdani A, 2017, DIGEST ENDOSC, V29, P3, DOI 10.1111/den.12745
   NOY N, 1977, GUT, V18, pA90
   OCONNOR HJ, 1983, GUT, V24, P1067, DOI 10.1136/gut.24.11.1067
   OHTA H, 1987, CANCER, V60, P1099, DOI 10.1002/1097-0142(19870901)60:5<1099::AID-CNCR2820600530>3.0.CO;2-F
   OI I, 1970, ENDOSCOPY, V2, P103
   Oyama Tsuneo, 2005, Clin Gastroenterol Hepatol, V3, pS67, DOI 10.1016/S1542-3565(05)00291-0
   Petersen BT, 2017, GASTROINTEST ENDOSC, V85, P282, DOI 10.1016/j.gie.2016.10.002
   Petersen BT, 2016, GASTROENTEROLOGY, V151, P46, DOI 10.1053/j.gastro.2016.05.040
   RAINES DR, 1975, GASTROINTEST ENDOSC, V22, P86, DOI 10.1016/S0016-5107(75)73708-2
   Rauwers AW, 2018, GUT, V67, P1637, DOI 10.1136/gutjnl-2017-315082
   Rizk MK, 2015, GASTROINTEST ENDOSC, V81, P3, DOI 10.1016/j.gie.2014.07.055
   *ROYAL COLL PHYS J, STAND
   SCHILLER KFR, 1976, MODERN TOPICS GASTRO
   SOEHENDRA N, 1976, ENDOSCOPY, V8, P85, DOI 10.1055/s-0028-1098382
   TSENG A, 1977, ENDOSCOPY, V9, P250, DOI 10.1055/s-0028-1098529
   TUFFNELL PG, 1976, CAN J PUBLIC HEALTH, V67, P141
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Valori R, 2018, ENDOSCOPY, V50, P1186, DOI 10.1055/a-0755-7515
   Wendorf KA, 2015, INFECT CONT HOSP EP, V36, P634, DOI 10.1017/ice.2015.66
   *WORLD EC FOR, 2018, ANT RES TACKL GAP R
NR 50
TC 6
Z9 6
U1 1
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD MAR
PY 2020
VL 32
IS 3
BP 290
EP 297
DI 10.1111/den.13593
EA JAN 2020
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA KS3SS
UT WOS:000507482800001
PM 31794063
DA 2023-04-20
ER

PT J
AU Biniaz, A
   Abdolali, F
   Zoroofi, RA
AF Biniaz, Abbas
   Abdolali, Fatemeh
   Zoroofi, Reza Aghaeizadeh
TI Integrated system for automatic detection of representative video frames
   in wireless capsule endoscopy using adaptive sliding window singular
   value decomposition
SO IET IMAGE PROCESSING
LA English
DT Article
DE biomedical optical imaging; endoscopes; image segmentation;
   bioacoustics; singular value decomposition; medical image processing;
   patient diagnosis; video signal processing; feature extraction;
   integrated system; automatic detection; representative video frames;
   wireless capsule endoscopy; window singular value decomposition;
   noninvasive diagnosis method; capsule travels; gastrointestinal tract;
   practical drawback; long clinical video; review process; automated
   summarisation methods; evaluation time; adaptive contrast diffusion; WCE
   frames; novel knowledge-based method; segment video frames; GI tract;
   review time
ID EXTRACTION; REDUCTION; SPACE
AB Wireless capsule endoscopy (WCE) is a non-invasive diagnosis method that allows recording a video as the capsule travels through the gastrointestinal (GI) tract. The practical drawback is producing a long clinical video in which the review process by an experienced specialist is tedious. Automated summarisation methods can reduce the evaluation time by experts as well as errors in manual interpretation. The proposed approach consists of three main steps as follows: First, an adaptive sliding window singular value decomposition is employed to extract representative video frames. Then, adaptive contrast diffusion is utilised to increase the visibility of WCE frames. At the end stage, a novel knowledge-based method is developed to segment video frames into four topographic zones of GI tract, which are oesophagus, stomach, small intestine and large intestine. The authors have evaluated the proposed framework in the presence of 30 local datasets as well as publicly available KID database. The average recall and precision were estimated by 0.86 and 0.83, and by 0.82 and 0.83 for KID database, respectively. Their results reveal that significant reduction in the review time is feasible using the proposed technique. Quantitative results of summarisation show that the proposed method is more effective than three methods in the literature.
C1 [Biniaz, Abbas; Abdolali, Fatemeh; Zoroofi, Reza Aghaeizadeh] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
   [Abdolali, Fatemeh] Univ Alberta, Dept Radiol & Diagnost Imaging, Edmonton, AB, Canada.
C3 University of Tehran; University of Alberta
RP Abdolali, F (通讯作者)，Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.; Abdolali, F (通讯作者)，Univ Alberta, Dept Radiol & Diagnost Imaging, Edmonton, AB, Canada.
EM f.abdolali@ut.ac.ir
CR Al-shebani Q, 2019, ARTIF INTELL MED, V94, P18, DOI 10.1016/j.artmed.2018.12.008
   [Anonymous], 2012, MATRIX COMPUTATIONS
   Badeau R, 2004, IEEE T SIGNAL PROCES, V52, P1, DOI 10.1109/TSP.2003.820069
   Chen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P735, DOI 10.1109/ICDSP.2015.7251973
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Fireman Z, 2007, J GASTROEN HEPATOL, V22, P1174, DOI 10.1111/j.1440-1746.2007.04993.x
   Gopi Varun P., 2013, International Journal of Imaging & Robotics, V9, P48
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Koulaouzidis A., 2015, UNITED EUR GASTROENT
   Lee HG, 2013, COMPUT BIOL MED, V43, P670, DOI 10.1016/j.compbiomed.2013.02.009
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Lillesand T., 2014, REMOTE SENSING IMAGE
   Loukas C, 2018, COMPUT METH PROG BIO, V165, P13, DOI 10.1016/j.cmpb.2018.07.004
   Mc Caffrey C, 2008, IEEE PERVAS COMPUT, V7, P23, DOI 10.1109/MPRV.2008.17
   Mehmood I, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0109-y
   Mohammed A, 2017, COMP MED SY, P728, DOI 10.1109/CBMS.2017.13
   Muhammad K, 2017, BIOMED SIGNAL PROCES, V33, P161, DOI 10.1016/j.bspc.2016.11.011
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ramaraj M., 2013, 2013 IEEE INT C COMP, P1
   Smith AR., 1978, ACM SIG GRAPH COMPUT, P12
   Toennies JL, 2010, P I MECH ENG C-J MEC, V224, P1397, DOI 10.1243/09544062JMES1879
   Tsevas S, 2008, IEEE INT C BIOINF BI, P921
   Vadivel A, 2005, PROC SPIE, P598, DOI 10.1117/12.586823
   Wang S, 2016, ARTIF INTELL MED, V66, P1, DOI 10.1016/j.artmed.2015.08.006
   Wyllie R., 2021, PEDIAT GASTROINTESTI, V6th ed.
   Zhao Q, 2015, COMPUT MED IMAG GRAP, V41, P108, DOI 10.1016/j.compmedimag.2014.05.011
NR 29
TC 4
Z9 4
U1 0
U2 8
PU INST ENGINEERING TECHNOLOGY-IET
PI HERTFORD
PA MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND
SN 1751-9659
EI 1751-9667
J9 IET IMAGE PROCESS
JI IET Image Process.
PD JAN 10
PY 2020
VL 14
IS 1
BP 147
EP 153
DI 10.1049/iet-ipr.2019.0251
PG 7
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA KC0GX
UT WOS:000506866400016
OA Bronze
DA 2023-04-20
ER

PT J
AU Mikada, T
   Kanno, T
   Kawase, T
   Miyazaki, T
   Kawashima, K
AF Mikada, Takuto
   Kanno, Takahiro
   Kawase, Toshihiro
   Miyazaki, Tetsuro
   Kawashima, Kenji
TI Three-dimensional posture estimation of robot forceps using endoscope
   with convolutional neural network
SO INTERNATIONAL JOURNAL OF MEDICAL ROBOTICS AND COMPUTER ASSISTED SURGERY
LA English
DT Article
DE machine learning; posture estimation; surgical robot
ID INSTRUMENTS
AB Background In recent years, there has been significant developments in surgical robots. Image-based sensing of surgical instruments, without the use of electric sensors, are preferred for easily washable robots. Methods We propose a method to estimate the three-dimensional posture of the tip of the forceps tip by using an endoscopic image. A convolutional neural network (CNN) receives the image of the tracked markers attached to the forceps as an input and outputs the posture of the forceps. Results The posture estimation results showed that the posture estimated from the image followed the electrical sensor. The estimated results of the external force calculated based on the posture also followed the measured values. Conclusion The method which estimates the forceps posture from the image using CNN is effective. The mean absolute error of the estimated external force is smaller than the human detection limit.
C1 [Mikada, Takuto; Kanno, Takahiro; Kawase, Toshihiro; Miyazaki, Tetsuro; Kawashima, Kenji] Tokyo Med & Dent Univ, Inst Biomat & Bioengn, Dept Biomech, Tokyo, Japan.
   [Kawase, Toshihiro] Tokyo Inst Technol, Inst Innovat Res, Yokohama, Kanagawa, Japan.
C3 Tokyo Medical & Dental University (TMDU); Tokyo Institute of Technology
RP Mikada, T (通讯作者)，Tokyo Med & Dent Univ, Inst Biomat & Bioengn, Dept Biomech, Chiyoda Ku, Surugadai 2-3-10, Tokyo 1010062, Japan.
EM ma180079@tmd.ac.jp
OI Mikada, Takuto/0000-0002-4111-8297; Kawase,
   Toshihiro/0000-0001-9766-1726; Miyazaki, Tetsuro/0000-0003-3677-2371;
   Kawashima, Kenji/0000-0002-0161-8270
FU Tokyo Medical and Dental University
FX Tokyo Medical and Dental University
CR Alemzadeh H, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151470
   Allan M, 2013, IEEE T BIO-MED ENG, V60, P1050, DOI 10.1109/TBME.2012.2229278
   Du XF, 2018, IEEE T MED IMAGING, V37, P1276, DOI 10.1109/TMI.2017.2787672
   Garcia-Peraza-Herrera LC, 2017, IEEE INT C INT ROBOT, P5717
   Guthart G. S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P618, DOI 10.1109/ROBOT.2000.844121
   Haraguchi D, 2015, IEEE-ASME T MECH, V20, P2950, DOI 10.1109/TMECH.2015.2415838
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hubens G, 2004, ACTA CHIR BELG, V104, P609, DOI 10.1080/00015458.2004.11679629
   Karponis D, 2019, J ROBOT SURG, V13, P413, DOI 10.1007/s11701-018-0878-2
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Milletari F, 2018, INT C MED IM COMP CO
   Rajnoha M, 2018, INT C ULTRA MOD TELE
   Tadano K, 2010, J ROBOT MECHATRON, V22, P179, DOI 10.20965/jrm.2010.p0179
   Tanaka S, 2014, IEEE INT C INT ROBOT, P3529, DOI 10.1109/IROS.2014.6943055
   Tonet O, 2007, COMPUT AIDED SURG, V12, P35, DOI 10.1080/10929080701210782
   Wei GQ, 1997, IEEE ENG MED BIOL, V16, P40, DOI 10.1109/51.566151
   Yamakawa S, 2005, IEEE T SYST MAN CY A, V35, P275, DOI 10.1109/TSMCA.2004.832832
NR 18
TC 0
Z9 0
U1 3
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1478-5951
EI 1478-596X
J9 INT J MED ROBOT COMP
JI Int. J. Med. Robot. Comput. Assist. Surg.
PD APR
PY 2020
VL 16
IS 2
DI 10.1002/rcs.2062
EA JAN 2020
PG 9
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA KY2UD
UT WOS:000506089500001
PM 31913577
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Song, EM
   Park, B
   Ha, CA
   Hwang, SW
   Park, SH
   Yang, DH
   Ye, BD
   Myung, SJ
   Yang, SK
   Kim, N
   Byeon, JS
AF Song, Eun Mi
   Park, Beomhee
   Ha, Chun-Ae
   Hwang, Sung Wook
   Park, Sang Hyoung
   Yang, Dong-Hoon
   Ye, Byong Duk
   Myung, Seung-Jae
   Yang, Suk-Kyun
   Kim, Namkug
   Byeon, Jeong-Sik
TI Endoscopic diagnosis and treatment planning for colorectal polyps using
   a deep-learning model
SO SCIENTIFIC REPORTS
LA English
DT Article
ID CLASSIFICATION; LESIONS; SYSTEM; CARCINOMA; HISTOLOGY; VALIDATION;
   MANAGEMENT; RESECTION; TUMORS
AB We aimed to develop a computer-aided diagnostic system (CAD) for predicting colorectal polyp histology using deep-learning technology and to validate its performance. Near-focus narrow-band imaging (NBI) pictures of colorectal polyps were retrieved from the database of our institution. Of these, 12480 image patches of 624 polyps were used as a training set to develop the CAD. The CAD performance was validated with two test datasets of 545 polyps. Polyps were classified into three histological groups: serrated polyp (SP), benign adenoma (BA)/mucosal or superficial submucosal cancer (MSMC), and deep submucosal cancer (DSMC). The overall kappa value measuring the agreement between the true polyp histology and the expected histology by the CAD was 0.614-0.642, which was higher than that of trainees (n=6, endoscopists with experience of 100 NBI colonoscopies in <6 months; 0.368-0.401) and almost comparable with that of the experts (n=3, endoscopists with experience of 2,500 NBI colonoscopies in >= 5 years) (0.649-0.735). The areas under the receiver operating curves for CAD were 0.93-0.95, 0.86-0.89, and 0.89-0.91 for SP, BA/MSMC, and DSMC, respectively. The overall diagnostic accuracy of the CAD was 81.3-82.4%, which was significantly higher than that of the trainees (63.8-71.8%, P<0.01) and comparable with that of experts (82.4-87.3%). The kappa value and diagnostic accuracies of the trainees improved with CAD assistance: that is, the kappa value increased from 0.368 to 0.655, and the overall diagnostic accuracy increased from 63.8-71.8% to 82.7-84.2%. CAD using a deep-learning model can accurately assess polyp histology and may facilitate the diagnosis of colorectal polyps by endoscopists.
C1 [Song, Eun Mi; Ha, Chun-Ae; Hwang, Sung Wook; Park, Sang Hyoung; Yang, Dong-Hoon; Ye, Byong Duk; Myung, Seung-Jae; Yang, Suk-Kyun; Byeon, Jeong-Sik] Univ Ulsan, Dept Gastroenterol, Asan Med Ctr, Coll Med, Seoul, South Korea.
   [Park, Beomhee] Univ Ulsan, Asan Med Inst Convergence Sci & Technol, Dept Convergence Med, Asan Med Ctr,Coll Med, Seoul, South Korea.
   [Kim, Namkug] Univ Ulsan, Res Inst Radiol, Dept Convergence Med & Radiol, Asan Med Ctr,Coll Med, Seoul, South Korea.
   [Kim, Namkug] Univ Ulsan, Inst Biomed Engn, Coll Med, Asan Med Ctr, Seoul, South Korea.
C3 University of Ulsan; Asan Medical Center; University of Ulsan; Asan
   Medical Center; University of Ulsan; Asan Medical Center; University of
   Ulsan
RP Byeon, JS (通讯作者)，Univ Ulsan, Dept Gastroenterol, Asan Med Ctr, Coll Med, Seoul, South Korea.; Kim, N (通讯作者)，Univ Ulsan, Res Inst Radiol, Dept Convergence Med & Radiol, Asan Med Ctr,Coll Med, Seoul, South Korea.; Kim, N (通讯作者)，Univ Ulsan, Inst Biomed Engn, Coll Med, Asan Med Ctr, Seoul, South Korea.
EM namkugkim@gmail.com; jsbyeon@amc.seoul.kr
RI Ye, Byong Duk/AAF-4955-2020; Yang, Dong-Hoon/B-3437-2015; Park, Sang
   Hyoung/CAH-4735-2022
OI Ye, Byong Duk/0000-0001-6647-6325; Yang, Dong-Hoon/0000-0001-7756-2704;
   Kim, Namkug/0000-0002-3438-2217
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [NRF-2017R1A2B4005846]; Korea Health Technology R&D Project grant
   through the Korea Health Industry Development Institute (KHIDI) -
   Ministry of Health & Welfare, Republic of Korea [HI18C2383]; Korea
   Health Promotion Institute [HR18C0016020020] Funding Source: Korea
   Institute of Science & Technology Information (KISTI), National Science
   & Technology Information Service (NTIS)
FX This work was supported by a National Research Foundation of Korea (NRF)
   grant funded by the Korean government (MSIT) (grant number:
   NRF-2017R1A2B4005846); and the Korea Health Technology R&D Project grant
   through the Korea Health Industry Development Institute (KHIDI), funded
   by the Ministry of Health & Welfare, Republic of Korea (grant number:
   HI18C2383).
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Bartel MJ, 2016, DIGEST ENDOSC, V28, P330, DOI 10.1111/den.12598
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dai J, 2013, DIGEST ENDOSC, V25, P180, DOI 10.1111/j.1443-1661.2012.01367.x
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   East JE, 2015, GUT, V64, P991, DOI 10.1136/gutjnl-2014-309041
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Guo CG, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126237
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   He K., 2016, P IEEE C COMP VIS PA, P770
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Huang G., P IEEE C COMP VIS PA, P3
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Khalid O, 2009, WORLD J GASTROENTERO, V15, P3767, DOI 10.3748/wjg.15.3767
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nakadoi K, 2012, J GASTROEN HEPATOL, V27, P1057, DOI 10.1111/j.1440-1746.2011.07041.x
   Pohl J, 2008, AM J GASTROENTEROL, V103, P562, DOI 10.1111/j.1572-0241.2007.01670.x
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Watanabe T, 2012, INT J CLIN ONCOL, V17, P1, DOI 10.1007/s10147-011-0315-2
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhou B., P IEEE C COMP VIS PA, P2921
NR 28
TC 42
Z9 42
U1 0
U2 2
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JAN 8
PY 2020
VL 10
IS 1
AR 30
DI 10.1038/s41598-019-56697-0
PG 10
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA KI5WJ
UT WOS:000511420200012
PM 31913337
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Ashour, AS
   Dey, N
   Mohamed, WS
   Tromp, JG
   Sherratt, RS
   Shi, FQ
   Moraru, L
AF Ashour, Amira S.
   Dey, Nilanjan
   Mohamed, Waleed S.
   Tromp, Jolanda G.
   Sherratt, R. Simon
   Shi, Fuqian
   Moraru, Luminita
TI Colored Video Analysis in Wireless Capsule Endoscopy: A Survey of
   State-of-the-Art
SO CURRENT MEDICAL IMAGING
LA English
DT Review
DE Endoscopy capsule; video analysis; bleeding detection; reviewing time
   reduction; wireless video gastrointestinal (GI) endoscopy capsule;
   computer- aided diagnosis
ID INVARIANT TEXTURE CLASSIFICATION; HYBRID NEURAL-NETWORK; PUSH
   ENTEROSCOPY; TRANSIT-TIME; SMALL-BOWEL; GRAY-SCALE; SYSTEM; IMAGES;
   OPTIMIZATION; ALGORITHM
AB Wireless Capsule Endoscopy (WCE) is a highly promising technology for gastrointestinal (GI) tract abnormality diagnosis. However, low image resolution and low frame rates are challenging issues in WCE. In addition, the relevant frames containing the features of interest for accurate diagnosis only constitute 1% of the complete video information. For these reasons, analyzing the WCE videos is still a time consuming and laborious examination for the gastroenterologists, which reduces WCE system usability. This leads to the emergent need to speed-up and automates the WCE video process for GI tract examinations. Consequently, the present work introduced the concept of WCE technology, including the structure of WCE systems, with a focus on the medical endoscopy video capturing process using image sensors. It discussed also the significant characteristics of the different GI tract for effective feature extraction. Furthermore, video approaches for bleeding and lesion detection in the WCE video were reported with computer-aided diagnosis systems in different applications to support the gastroenterologist in the WCE video analysis. In image enhancement, WCE video review time reduction is also discussed, while reporting the challenges and future perspectives, including the new trend to employ the deep learning models for feature Learning, polyp recognition, and classification, as a new opportunity for researchers to develop future WCE video analysis techniques.
C1 [Ashour, Amira S.] Tanta Univ, Fac Engn, Dept Elect & Elect Commun Engn, Tanta 31527, Egypt.
   [Dey, Nilanjan] Techno India Coll Technol, Dept Informat Technol, Kolkata 740000, W Bengal, India.
   [Mohamed, Waleed S.] Tanta Univ, Fac Med, Dept Internal Med, Tanta 31527, Egypt.
   [Tromp, Jolanda G.] Duy Tan Univ, Ctr Visualizat & Simulat, Comp Sci Dept, Da Nang, Vietnam.
   [Sherratt, R. Simon] Univ Reading, Dept Biomed Engn, Reading, Berks, England.
   [Shi, Fuqian] Rutgers State Univ, Rutgers Canc Inst New Jersey, New Brunswick, NJ 08903 USA.
   [Moraru, Luminita] Dunarea de Jos Univ Galati, Fac Sci & Environm, Galati, Romania.
C3 Egyptian Knowledge Bank (EKB); Tanta University; Egyptian Knowledge Bank
   (EKB); Tanta University; Duy Tan University; University of Reading;
   Rutgers State University New Brunswick; Rutgers State University Medical
   Center; Rutgers Cancer Institute of New Jersey; Dunarea De Jos
   University Galati
RP Ashour, AS (通讯作者)，Tanta Univ, Fac Engn, Dept Elect & Elect Commun Engn, Tanta 31527, Egypt.
EM amira.salah@f-eng.tanta.edu.eg
RI Ashour, Amira S./T-5454-2019; Moraru, Luminita/A-8532-2012
OI Ashour, Amira S./0000-0003-3217-6185; Moraru,
   Luminita/0000-0002-9121-5714
CR Ahmed SS, 2017, MED BIOL ENG COMPUTI
   AlShahrani A.M., 2018, COMPUTER VISION CONC, P1208
   Appleyard M, 2000, GASTROENTEROLOGY, V119, P1431, DOI 10.1053/gast.2000.20844
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Berens J, 2000, IEE P-VIS IMAGE SIGN, V147, P349, DOI 10.1049/ip-vis:20000630
   Boulougoura M, 2004, 2 INT C BIOM ENG
   Bourbakis N, 2005, NEURAL NETWORK BASED, DOI [10.1109/BIBE.2005.6, DOI 10.1109/BIBE.2005.6]
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   Chu X, 2010, EPITOMIZED SUMMARIZA, DOI [10.1007/978-3-642-15745-5_64, DOI 10.1007/978-3-642-15745-5_64]
   Ciuti G, 2016, J MICRO-BIO ROBOT, V11, P1, DOI 10.1007/s12213-016-0087-x
   Connah D., 2006, P EUR C COL GRAPH IM, V3, P60
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Dalai N., 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Dey N., 2016, CLASSIFICATION CLUST
   Dey N, 2019, OPTIK, V183, P483, DOI 10.1016/j.ijleo.2019.02.118
   Dey Nilanjan, 2017, IEEE Rev Biomed Eng, V10, P2, DOI 10.1109/RBME.2017.2697950
   Drozdzal M, 2013, COMPUT MED IMAG GRAP, V37, P72, DOI 10.1016/j.compmedimag.2012.09.002
   Eliakim R, 2003, EUR J GASTROEN HEPAT, V15, P363, DOI 10.1097/00042737-200304000-00005
   Figueiredo IN, 2010, AUTOMATIC DETECTION, P10
   Fisher L, 2010, GASTROINTEST ENDOSC, V72, P471, DOI 10.1016/j.gie.2010.04.032
   Gong YH, 1996, MULTIMED TOOLS APPL, V2, P133, DOI 10.1023/A:1018095010693
   Gopi Varun P., 2013, International Journal of Imaging & Robotics, V9, P48
   Hafner M, 2013, COMP MED SY, P185, DOI 10.1109/CBMS.2013.6627786
   Hai V, 2006, INT C PATT RECOG, P980
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2016, DEEP CONVOLUTIONAL N, DOI [10.1109/EMBC.2016.7590783, DOI 10.1109/EMBC.2016.7590783]
   Jung YS, ACTIVE BLOOD DETECTI
   Karargyris A, 2010, ELASTIC VIDEO INTERP
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Koulaouzidis A, 2013, ANN GASTROENTEROL, V26, P365
   Kriti, 2016, INTEL SYST REF LIBR, V96, P159, DOI 10.1007/978-3-319-21212-8_7
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Kwack WG, 2016, CLIN ENDOSC, V49, P8, DOI 10.5946/ce.2016.49.1.8
   Lee J, 2007, AUTOMATIC CLASSIFICA, DOI [10.1145/1244002.1244230, DOI 10.1145/1244002.1244230]
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Li B, 2009, 2009 IEEE RSJ INT C
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Malagelada C, 2008, GASTROENTEROLOGY, V135, P1155, DOI 10.1053/j.gastro.2008.06.084
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mirjalili S, 2012, APPL MATH COMPUT, V218, P11125, DOI 10.1016/j.amc.2012.04.069
   Moglia Andrea, 2008, Recent Patents on Biomedical Engineering, V1, P24, DOI 10.2174/1874764710801010024
   Mylonaki M, 2003, GUT, V52, P1122, DOI 10.1136/gut.52.8.1122
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Okuhata H, 2013, APPL REAL TIME RETIN
   Ramaraj M, 2013, HOMOMORPHIC FILTERIN
   Razmjooy N, 2018, OPEN MED-WARSAW, V13, P9, DOI 10.1515/med-2018-0002
   Razmjooy N, 2013, MATH COMPUT MODEL, V57, P848, DOI 10.1016/j.mcm.2012.09.013
   Saba L, 2016, COMPUT METH PROG BIO, V130, P118, DOI 10.1016/j.cmpb.2016.03.016
   Santi S., 2016, IB C PATT REC SPRING, V10125, P326
   Sekuboyina AK, 2017, CONVOLUTIONAL NEURAL
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Szczypinski PM, 2009, MED IMAGE ANAL, V13, P312, DOI 10.1016/j.media.2008.12.002
   Szczypinski PM, 2004, 12 UN EUR GASTR WEEK, V36, pA76
   Szeliski R., 2022, COMPUTER VISION ALGO, V1478, P68007, DOI 10.1007/978-3-030-34372-9
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Toth E, 2017, ANN TRANSL MED, V5, DOI 10.21037/atm.2017.03.79
   Triester SL, 2005, AM J GASTROENTEROL, V100, P2407, DOI 10.1111/j.1572-0241.2005.00274.x
   Vilarino F, 2006, INT C PATT RECOG, P719
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P178
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Vu H, 2009, COMPUT BIOL MED, V39, P16, DOI 10.1016/j.compbiomed.2008.10.005
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wang CL, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293303
   Wang P, 2001, CLASSIFICATION ENDOS, DOI [10.1109/IEMBS.2001.1019637, DOI 10.1109/IEMBS.2001.1019637]
   Xin WH, 2010, INT J MED ROBOT COMP, V6, P113, DOI 10.1002/rcs.298
   Yagi Y., 2007, Inflammopharmacology, V15, P78, DOI 10.1007/s10787-006-0010-5
   Yu LC, 2012, INT C PATT RECOG, P45
   Yuan Y, 2013, HIERARCHICAL KEY FRA
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhao Q, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P948, DOI 10.1109/WCICA.2011.5970656
   ZHOU Meng-jia, 2015, THESIS
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 79
TC 3
Z9 3
U1 3
U2 15
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1573-4056
EI 1875-6603
J9 CURR MED IMAGING
JI Curr. Med. Imaging
PY 2020
VL 16
IS 9
BP 1074
EP 1084
DI 10.2174/1573405616666200124140915
PG 11
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA PG6IR
UT WOS:000599837400002
PM 32107996
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Chen, H
   Zhou, XY
   Tang, XY
   Li, S
   Zhang, GX
AF Chen, Han
   Zhou, Xiaoying
   Tang, Xinyu
   Li, Shuo
   Zhang, Guoxin
TI Prediction of Lymph Node Metastasis in Superficial Esophageal Cancer
   Using a Pattern Recognition Neural Network
SO CANCER MANAGEMENT AND RESEARCH
LA English
DT Article
DE superficial esophageal squamous cell carcinoma; lymph node metastasis;
   neural network; machine learning
ID ENDOSCOPIC SUBMUCOSAL DISSECTION; SQUAMOUS-CELL CARCINOMA;
   ALCOHOL-CONSUMPTION; CLINICAL-OUTCOMES; MODELS; DISCRIMINATION;
   SURVIVAL; MARKER; AREA
AB Background or Purpose: It is important to predict nodal metastases in patients with early esophageal cancer to stratify patients for endoscopic resection or esophagectomy. This study was to establish a novel artificial neural network (ANN) and assess its ability by comparing it with a traditional logistic regression (LR) model for predicting lymph node (LN) metastasis in patients with superficial esophageal squamous cell carcinoma (SESCC).
   Methods: A primary cohort was established, composed of 733 patients who underwent esophagectomy for SESCC from December 2012 to December 2019. The following steps were applied: (i) predictor selection; (ii) development of an ANN and a LR model, respectively; (iii) cross-validation; and (iv) evaluation of performance between the two models. The diagnostic assessment was performed with sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), accuracy, C-index, net reclassification improvement (NRI), and integrated discrimination improvement (IDI).
   Results: The established ANN model had 6 significant predictors: a past habit of alcohol taking, tumor size, submucosal invasion, histologic grade, lymph-vessel invasion, and pre-operative CT result. The ANN model performed better than the LR model in specificity (91.20% vs 72.59%, p=0.006), PPV (56.49% vs 39.78%, p=0.020), accuracy (90.72% vs 74.49%, p<0.0001), C-index (91.5% vs 86.8%, p<0.001), and IDI (improved by 23.3%, p<0.001). There were no differences between these two models in sensitivity (87.06% vs 83.21%, p=0.764), NPV (98.17% vs 95.21%, p=0.627), and NRI (improved by -1.1%, p=0.824).
   Conclusion: This ANN model is superior to the LR model and may become a valuable tool for the prediction of LN metastasis in patients with SESCC.
C1 [Chen, Han; Zhou, Xiaoying; Li, Shuo; Zhang, Guoxin] Nanjing Med Univ, Affiliated Hosp 1, Dept Gastroenterol, 300 Guangzhou Rd, Nanjing 210029, Peoples R China.
   [Chen, Han; Zhou, Xiaoying; Tang, Xinyu; Li, Shuo; Zhang, Guoxin] Nanjing Med Univ, Clin Med Coll 1, Nanjing, Peoples R China.
   [Tang, Xinyu] Nanjing Med Univ, Affiliated Hosp 1, Dept Radiat Oncol, Nanjing, Peoples R China.
C3 Nanjing Medical University; Nanjing Medical University; Nanjing Medical
   University
RP Zhang, GX (通讯作者)，Nanjing Med Univ, Affiliated Hosp 1, Dept Gastroenterol, 300 Guangzhou Rd, Nanjing 210029, Peoples R China.
EM guoxinz@njmu.edu.cn
RI Li, Shuo/GXV-6545-2022; Li, Shuo/HLV-7870-2023
CR Alba AC, 2017, JAMA-J AM MED ASSOC, V318, P1377, DOI 10.1001/jama.2017.12126
   Ancona E, 2008, ANN SURG ONCOL, V15, P3278, DOI 10.1245/s10434-008-0065-1
   Berger A, 2019, ENDOSCOPY, V51, P298, DOI 10.1055/a-0732-5317
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Choi J, 2010, SURG ENDOSC, V24, P1380, DOI 10.1007/s00464-009-0783-x
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Duda R. O., 2001, PATTERN CLASSIFICATI, V2nd
   Eslamizadeh G, 2017, ARTIF INTELL MED, V78, P23, DOI 10.1016/j.artmed.2017.05.005
   Evans JA, 2013, GASTROINTEST ENDOSC, V77, P328, DOI 10.1016/j.gie.2012.10.001
   Fei Y, 2019, HPB, V21, P891, DOI 10.1016/j.hpb.2018.11.009
   Hassanipour S, 2019, INJURY, V50, P244, DOI 10.1016/j.injury.2019.01.007
   Huang QY, 2014, CANCER SCI, V105, P1638, DOI 10.1111/cas.12552
   Jacobs M, 2014, QUAL LIFE RES, V23, P1097, DOI 10.1007/s11136-013-0545-z
   Kerr KF, 2011, AM J EPIDEMIOL, V174, P364, DOI 10.1093/aje/kwr086
   Lagergren J, 2017, LANCET, V390, P2383, DOI 10.1016/S0140-6736(17)31462-9
   Lagergren J, 2013, CA-CANCER J CLIN, V63, P232, DOI 10.3322/caac.21185
   Lind Penelope A., 2008, Human Genomics, V3, P24
   Ma DW, 2019, J THORAC CARDIOV SUR, V157, P397, DOI 10.1016/j.jtcvs.2018.07.034
   Min BH, 2019, J GASTROENTEROL HEPA, V31
   Park JS, 2016, CLIN ENDOSC, V49, P168, DOI 10.5946/ce.2015.080
   Pencina MJ, 2008, STAT MED, V27, P157, DOI 10.1002/sim.2929
   Qi ZP, 2018, ENDOSCOPY, V50, P839, DOI 10.1055/a-0577-2560
   Rice TW, 2017, ANN CARDIOTHORAC SUR, V6, P119, DOI 10.21037/acs.2017.03.14
   Schwarzinger M, 2018, LANCET PUBLIC HEALTH, V3, pE124, DOI 10.1016/S2468-2667(18)30022-7
   Steyerberg EW, 2010, EPIDEMIOLOGY, V21, P128, DOI 10.1097/EDE.0b013e3181c30fb2
   Suzuki G, 2018, RADIAT ONCOL, V13, DOI 10.1186/s13014-018-1195-7
   Takeuchi M, 2018, GASTROINTEST ENDOSC, V88, P456, DOI 10.1016/j.gie.2018.04.2361
   Tramontano AC, 2018, DIGEST DIS SCI, V63, P2880, DOI 10.1007/s10620-018-5238-6
   Tsujii Y, 2015, ENDOSCOPY, V47, P775, DOI 10.1055/s-0034-1391844
   van Vliet EPM, 2008, BRIT J CANCER, V98, P547, DOI 10.1038/sj.bjc.6604200
   Vastrad M, 2013, INT J INFORM SCI TEC, V3, P1, DOI DOI 10.5121/ijist.2013.3601
   Wang Y, 2012, DIS ESOPHAGUS, V25, P560, DOI 10.1111/j.1442-2050.2011.01279.x
   Wei WQ, 2015, J CLIN ONCOL, V33, P1951, DOI 10.1200/JCO.2014.58.0423
   Xue LY, 2015, MODERN PATHOL, V28, P161, DOI 10.1038/modpathol.2014.133
   Yamada T, 2014, GASTRIC CANCER, V17, P692, DOI 10.1007/s10120-013-0323-1
   Yu T, 2018, BIOMED RES INT, V20, P8591387
   Zheng H, 2018, BRIT J SURG, V105, P1464, DOI 10.1002/bjs.10882
   Zhou Y, 2019, INT J SURG, V66, P53, DOI 10.1016/j.ijsu.2019.04.014
   2017, ESOPHAGUS-TOKYO, V14, P37, DOI DOI 10.1007/S10388-016-0556-2
NR 39
TC 8
Z9 8
U1 0
U2 8
PU DOVE MEDICAL PRESS LTD
PI ALBANY
PA PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND
SN 1179-1322
J9 CANCER MANAG RES
JI Cancer Manag. Res.
PY 2020
VL 12
BP 12249
EP 12258
DI 10.2147/CMAR.S270316
PG 10
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA PA1XI
UT WOS:000595425800005
PM 33273861
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Chou, CL
   Chen, TJ
   Lin, CY
   Lee, SW
   Wang, SC
   Chu, SS
   Yang, CC
AF Chou, Chia-Lin
   Chen, Tzu-Ju
   Lin, Cheng-Yi
   Lee, Sung-Wei
   Wang, Shih-Chang
   Chu, Shou-Sheng
   Yang, Ching-Chieh
TI PCSK1 Overexpression in Rectal Cancer Correlates with Poor Response to
   Preoperative Chemoradiotherapy and Prognosis
SO ONCOTARGETS AND THERAPY
LA English
DT Article
DE PCSK1; rectal cancer; chemoradiotherapy; response; survival
ID PEPTIDE PROCESSING ENZYMES; BODY-MASS INDEX; PROPROTEIN-CONVERTASES;
   TUMOR PROGRESSION; COMMON VARIANTS; PC2; EXPRESSION; OBESITY;
   ASSOCIATION; OUTCOMES
AB Background: In a data mining search for potential therapeutic targets to improve the outcome of rectal cancer, we identified PCSK1 as the cell-cell signaling gene most significantly associated with poor response to concurrent chemoradiotherapy (CCRT). This study aims to investigate the prognostic value of PCSK1 expression in rectal cancer patients who underwent neoadjuvant CCRT.
   Methods: Endoscopic biopsy specimens from 172 rectal cancer patients receiving neoadjuvant CCRT followed by curative surgery were assessed immunohistochemically for PCSK1 expression, and H-scores were determined. Expression levels of PCSK1 were further analyzed for correlations with clinicopathologic features, tumor regression grade, metastasis-free survival, disease-specific survival, and recurrence-free survival.
   Results: PCKS1 overexpression was significantly associated with pretreatment tumor status (T3-4; p = 0.009), pretreatment nodal status (N1-2; p < 0.001), posttreatment tumor status (T3-4; p < 0.001), posttreatment nodal status (N1-2; p < 0.001), vascular invasion (p = 0.003), and perineurial invasion (p = 0.023). PCKS1 overexpression was also found to be significantly associated with a lower degree of tumor regression (p < 0.001). In the univariate analysis, PCSK1 overexpression was significantly associated with lower disease-specific survival, metastasis-free survival, and recurrence-free survival (p < 0.005). PCSK1 overexpression remained an independent prognostic factor of lower disease-specific survival (p = 0.003; hazard ratio, 5.478) in the multivariate analysis.
   Conclusion: Determination of PCSK1 overexpression may be useful for identifying rectal cancer patients at risk for a poor response and worse survival after CCRT.
C1 [Chou, Chia-Lin] Chi Mei Med Ctr, Dept Surg, Div Colon & Rectal Surg, Tainan, Taiwan.
   [Chou, Chia-Lin; Chen, Tzu-Ju] Natl Sun Yat Sen Univ, Inst Biomed Sci, Kaohsiung, Taiwan.
   [Chen, Tzu-Ju] Chi Mei Med Ctr, Dept Pathol, Tainan, Taiwan.
   [Chen, Tzu-Ju] Chung Hwa Univ Med Technol, Dept Optometry, Tainan, Taiwan.
   [Chen, Tzu-Ju; Lin, Cheng-Yi] Chi Mei Med Ctr, Dept Internal Med, Div Gastroenterol & Hepatol, Tainan, Taiwan.
   [Lee, Sung-Wei; Wang, Shih-Chang; Chu, Shou-Sheng; Yang, Ching-Chieh] Chi Mei Med Ctr, Dept Radiat Oncol, 901 Zhonghua Rd, Tainan 701, Taiwan.
   [Yang, Ching-Chieh] Chia Nan Univ Pharm & Sci, Dept Pharm, Tainan, Taiwan.
C3 Chi Mei Hospital; National Sun Yat Sen University; Chi Mei Hospital;
   Chung Hua University; Chi Mei Hospital; Chi Mei Hospital; Chia Nan
   University of Pharmacy & Science
RP Yang, CC (通讯作者)，Chi Mei Med Ctr, Dept Radiat Oncol, 901 Zhonghua Rd, Tainan 701, Taiwan.
EM cleanclear0905@gmail.com
RI Wang, Shih-Chang/X-4827-2018
OI Wang, Shih-Chang/0000-0003-4031-2132
FU WanFang Hospital, Chi Mei Medical Center [MOHW109-TDU-B-212-134020]; Chi
   Mei Medical center [CMFHR10828, CMFHR108105]
FX We acknowledge the support from the following grants: (1) Health and
   Welfare surcharge on tobacco products (MOHW109-TDU-B-212-134020, WanFang
   Hospital, Chi Mei Medical Center, and Hualien Tzu-Chi Hospital Joing
   Cancer Center Grant-Focus on Colon Cancer Research); (2) CMFHR10828 and
   CMFHR108105 from the Chi Mei Medical center; (3) BioBank of Chi Mei
   Medical Center for providing the tumor samples and to the translational
   research laboratory of human cancers at Chi Mei Medical Center (leaded
   by Prof. Chien-Feng Li) for their invaluable support.
CR Basak A, 2011, METHODS MOL BIOL, V768, P127, DOI 10.1007/978-1-61779-204-5_6
   Bassi DE, 2005, MOL CARCINOGEN, V44, P151, DOI 10.1002/mc.20134
   Cheng M, 1997, INT J CANCER, V71, P966, DOI 10.1002/(SICI)1097-0215(19970611)71:6<966::AID-IJC10>3.0.CO;2-4
   Choquet H, 2011, METHODS MOL BIOL, V768, P247, DOI 10.1007/978-1-61779-204-5_13
   Chretien M, 2008, EXPERT OPIN THER TAR, V12, P1289, DOI 10.1517/14728222.12.10.1289 
   Chretien M, 2016, J MOL ENDOCRINOL, V56, pT49, DOI 10.1530/JME-15-0261
   Du JL, 2001, CANCER LETT, V165, P211, DOI 10.1016/S0304-3835(01)00409-8
   Gu Q, 2015, J HUM HYPERTENS, V29, P82, DOI 10.1038/jhh.2014.59
   Ho V, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4776-9
   Horsch D, 1997, PEPTIDES, V18, P755, DOI 10.1016/S0196-9781(96)00029-0
   Huang Y, 2017, J BUON, V22, P686
   Incio J, 2016, CLIN CANCER RES, V22, P2993, DOI 10.1158/1078-0432.CCR-15-1839
   Itoh Y, 1996, PATHOL INT, V46, P726, DOI 10.1111/j.1440-1827.1996.tb03541.x
   Kajiwara Hiroshi, 1999, Tokai Journal of Experimental and Clinical Medicine, V24, P13
   Khatib AM, 2002, AM J PATHOL, V160, P1921, DOI 10.1016/S0002-9440(10)61140-6
   Lee SY, 2019, ANN SURG TREAT RES, V96, P116, DOI 10.4174/astr.2019.96.3.116
   Lee YC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078709
   Li CF, 2014, J CLIN PATHOL, V67, P1056, DOI 10.1136/jclinpath-2014-202551
   Li XM, 2012, HYPERTENS RES, V35, P994, DOI 10.1038/hr.2012.79
   Longuespee R, 2014, TRANSL ONCOL, V7, P410, DOI 10.1016/j.tranon.2014.04.008
   Maruoka D, 2015, SCAND J GASTROENTERO, V50, P333, DOI 10.3109/00365521.2014.1003399
   Mbikay M, 1997, BRIT J CANCER, V75, P1509, DOI 10.1038/bjc.1997.258
   Meyerhardt JA, 2004, J CLIN ONCOL, V22, P648, DOI 10.1200/JCO.2004.07.121
   Pinto AT, 2016, SCI REP-UK, V6, DOI 10.1038/srep18765
   Ramos-Molina B, 2016, PROG MOL BIOL TRANSL, V140, P47, DOI 10.1016/bs.pmbts.2015.12.001
   Rezaeian AH, 2017, NAT CELL BIOL, V19, P38, DOI 10.1038/ncb3445
   Rodel C, 2005, J CLIN ONCOL, V23, P8688, DOI 10.1200/JCO.2005.02.1329
   Sauer R, 2004, NEW ENGL J MED, V351, P1731, DOI 10.1056/NEJMoa040694
   Sheu MJ, 2014, TUMOR BIOL, V35, P7755, DOI 10.1007/s13277-014-2032-8
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Stijnen P, 2014, AM J EPIDEMIOL, V180, P1051, DOI 10.1093/aje/kwu237
   Tzimas GN, 2005, BMC CANCER, V5, DOI 10.1186/1471-2407-5-149
   van den Brink M, 2004, J CLIN ONCOL, V22, P3958, DOI 10.1200/jco.2004.01.023
   Vares G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106277
   Wynn TA, 2012, NAT MED, V18, P1028, DOI 10.1038/nm.2807
   Yoon JY, 1997, J BIOL CHEM, V272, P9450
   You JF, 2009, ANN SURG, V249, P783, DOI 10.1097/SLA.0b013e3181a3e52b
   Zhang YF, 2018, CANCER LETT, V431, P190, DOI 10.1016/j.canlet.2018.05.027
NR 38
TC 5
Z9 5
U1 0
U2 1
PU DOVE MEDICAL PRESS LTD
PI ALBANY
PA PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND
SN 1178-6930
J9 ONCOTARGETS THER
JI OncoTargets Ther.
PY 2020
VL 13
BP 3141
EP 3150
DI 10.2147/OTT.S243750
PG 10
WC Biotechnology & Applied Microbiology; Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Oncology
GA LC6OJ
UT WOS:000525453000001
PM 32346297
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Deeba, F
   Bui, FM
   Wahid, KA
AF Deeba, Farah
   Bui, Francis M.
   Wahid, Khan A.
TI Computer-aided polyp detection based on image enhancement and
   saliency-based selection
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Histogram of gradients; Polyp detection; Capsule endoscopy
ID CAPSULE ENDOSCOPY; PREVENTION; DIAGNOSIS; FEATURES
AB This paper presents a computer-aided polyp detection algorithm applicable to both colonoscopy and wireless capsule endoscopy (WCE). The proposed system has three integral parts: image enhancement, saliency map formation and Histogram of gradients (HOG) feature extraction for final classification. We propose a novel and efficient image enhancement algorithm, which enhances the saliency of clinically important features in endoscopic images. A saliency detection method is applied to the enhanced images to highlight the initial polyp candidates. In the classification stage, polyp candidates are selected after performing an image enhancement step and a saliency detection step. Exhaustive experiments have been performed on three publicly available databases: CVC ColonDB, CVC ClinicDB, and ETIS Larib to evaluate the performance of the proposed polyp detection algorithm. Comparison with the state-of-the-art methods shows that the proposed method outperforms the existing ones in terms of recall (=86.33%) and F2 score (=75.51%) for CVC ColonDB and in terms of recall (=74.04%) for the ETIS Larib dataset. With a significantly reduced number of search windows resulting from the saliency-based selection, the proposed scheme ensures a cost-effective and efficient polyp detection algorithm. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Deeba, Farah; Bui, Francis M.; Wahid, Khan A.] Univ Saskatchewan, Elect & Comp Engn, Saskatoon, SK, Canada.
C3 University of Saskatchewan
RP Deeba, F (通讯作者)，Univ Saskatchewan, Elect & Comp Engn, Saskatoon, SK, Canada.
EM farah.deeba@usask.ca
RI Deeba, Farah/AAJ-1923-2020
OI Bui, Francis/0000-0002-8799-5965
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX This work was supported by the Natural Sciences and Engineering Research
   Council of Canada (NSERC).
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Altobelli E, 2014, PREV MED, V62, P132, DOI 10.1016/j.ypmed.2014.02.010
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   [Anonymous], ISSCS 2013 INT S SIG
   Aranda-Hernandez J, 2016, WORLD J GASTROENTERO, V22, P1767, DOI 10.3748/wjg.v22.i5.1767
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   BOND JH, 1993, ANN INTERN MED, V119, P836, DOI 10.7326/0003-4819-119-8-199310150-00010
   Braun GJ, 1999, J ELECTRON IMAGING, V8, P380, DOI 10.1117/1.482706
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deeba F, 2016, IEEE ENG MED BIO, P3871, DOI 10.1109/EMBC.2016.7591573
   Forsyth D, 2014, COMPUTER, V47, P6, DOI 10.1109/MC.2014.42
   Gado A, 2013, ALEX J MED, V49, P25, DOI 10.1016/j.ajme.2012.08.005
   Hwang S., 2011, LECT NOTES COMPUT SC, V6939, P320
   HWANG S, 2007, P IEEE INT C IM PROC, V0002, P00465
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Imperiale TF, 2009, GASTROINTEST ENDOSC, V69, P1288, DOI 10.1016/j.gie.2007.11.043
   Iwahori Y., 2013, INT C MACH VIS APPL, P21
   Jang JY, 2012, CLIN ENDOSC, V45, P379, DOI 10.5946/ce.2012.45.4.379
   Karargyris A, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P143, DOI 10.1109/LISSA.2009.4906730
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Koulaouzidis A, 2013, WORLD J GASTROENTERO, V19, P3726, DOI 10.3748/wjg.v19.i24.3726
   Li BP, 2012, J MED SYST, V36, P2463, DOI 10.1007/s10916-011-9713-2
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li DL, 2009, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON RISK MANAGEMENT & GLOBAL E-BUSINESS, VOLS I AND II, P1022
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Park DY, 2008, ARCH PATHOL LAB MED, V132, P633, DOI 10.1043/1543-2165(2008)132[633:GPCAM]2.0.CO;2
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Rahtu Esa, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1137, DOI 10.1109/ICCVW.2009.5457577
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Shussman N, 2014, GASTROENTEROL REP, V2, P1, DOI 10.1093/gastro/got041
   Sieg A, 2009, AM J GASTROENTEROL, V104, P848, DOI 10.1038/ajg.2008.163
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2014, I S BIOMED IMAGING, P97, DOI 10.1109/ISBI.2014.6867818
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Wallace JL, 2016, DIGEST DIS SCI, V61, P1, DOI 10.1007/s10620-015-3963-7
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Zhao Q, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P948, DOI 10.1109/WCICA.2011.5970656
NR 47
TC 31
Z9 32
U1 2
U2 16
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD JAN
PY 2020
VL 55
AR 101530
DI 10.1016/j.bspc.2019.04.007
PG 8
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA JW2NA
UT WOS:000502893200013
DA 2023-04-20
ER

PT J
AU Dohi, O
   Majima, A
   Naito, Y
   Yoshida, T
   Ishida, T
   Azuma, Y
   Kitae, H
   Matsumura, S
   Mizuno, N
   Yoshida, N
   Kamada, K
   Itoh, Y
AF Dohi, Osamu
   Majima, Atsushi
   Naito, Yuji
   Yoshida, Takuma
   Ishida, Tsugitaka
   Azuma, Yuka
   Kitae, Hiroaki
   Matsumura, Shinya
   Mizuno, Naoki
   Yoshida, Naohisa
   Kamada, Kazuhiro
   Itoh, Yoshito
TI Can image-enhanced endoscopy improve the diagnosis of Kyoto
   classification of gastritis in the clinical setting?
SO DIGESTIVE ENDOSCOPY
LA English
DT Review
DE chronic gastritis; computer-aided diagnosis; Helicobacter pylori;
   image-enhanced endoscopy; Kyoto classification
ID HELICOBACTER-PYLORI INFECTION; NODULAR GASTRITIS; INTESTINAL METAPLASIA;
   ARTIFICIAL-INTELLIGENCE; HIGH-RISK; CANCER; FEATURES; MUCOSA;
   ERADICATION; STOMACH
AB Endoscopic diagnosis of Helicobacter pylori (H. pylori) infection, the most common cause of gastric cancer, is very important to clarify high-risk patients of gastric cancer for reducing morbidity and mortality of gastric cancer. Recently, the Kyoto classification of gastritis was developed based on the endoscopic characteristics of H. pylori infection-associated gastritis for clarifying H. pylori infection status and evaluating risk factors of gastric cancer. Recently, magnifying endoscopy with narrow-band imaging (NBI) has reported benefits of the accuracy and reproducibility of endoscopic diagnosis for H. pylori-related premalignant lesions. In addition to NBI, various types of image-enhanced endoscopies (IEEs) are available including autofluorescence imaging, blue laser imaging, and linked color imaging. This review focuses on understanding the clinical applications and the corresponding evidences shown to improve the diagnosis of gastritis based on Kyoto classification using currently available advanced technologies of IEEs.
C1 [Dohi, Osamu; Majima, Atsushi; Naito, Yuji; Yoshida, Takuma; Ishida, Tsugitaka; Azuma, Yuka; Kitae, Hiroaki; Matsumura, Shinya; Mizuno, Naoki; Yoshida, Naohisa; Kamada, Kazuhiro; Itoh, Yoshito] Kyoto Prefectural Univ Med, Grad Sch Med Sci, Dept Mol Gastroenterol & Hepatol, Kyoto, Japan.
   [Majima, Atsushi] Omihachiman Community Med Ctr, Dept Gastroenterol & Hepatol, Omihachiman, Shiga, Japan.
C3 Kyoto Prefectural University of Medicine
RP Dohi, O (通讯作者)，Kyoto Prefectural Univ Med, Dept Mol Gastroenterol & Hepatol, Grad Sch Med Sci, Kamigyo Ku, 465 Kawaramachi Hirokoji, Kyoto 6028566, Japan.
EM osamu-d@koto.kpu-m.ac.jp
OI Yoshida, Naohisa/0000-0001-6167-9705
CR Alaboudy AA, 2011, DIGEST DIS SCI, V56, P1127, DOI 10.1007/s10620-010-1414-z
   BAH A, 1995, ENDOSCOPY, V27, P593, DOI 10.1055/s-2007-1005764
   Chen TH, 2018, J CHIN MED ASSOC, V81, P1033, DOI 10.1016/j.jcma.2018.03.006
   Dinis-Ribeiro M, 2012, ENDOSCOPY, V44, P74, DOI 10.1055/s-0031-1291491
   Dohi O, 2017, GASTRIC CANCER, V20, P297, DOI 10.1007/s10120-016-0620-6
   Dohi O, 2016, ENDOSC INT OPEN, V4, pE800, DOI 10.1055/s-0042-109049
   Fukase K, 2008, LANCET, V372, P392, DOI 10.1016/S0140-6736(08)61159-9
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Graham DY, 1997, GASTROENTEROLOGY, V113, P1983, DOI 10.1016/S0016-5085(97)70019-2
   Gulati S, 2020, DIGEST ENDOSC, V32, P512, DOI 10.1111/den.13481
   Haruma K, 2014, KYOTO CLASSIFICATION
   HATTORI T, 1974, CELL TISSUE RES, V148, P213
   Hayashi S, 2015, DIGEST ENDOSC, V27, P53, DOI 10.1111/den.12335
   Inoue T, 2010, J GASTROENTEROL, V45, P45, DOI 10.1007/s00535-009-0150-7
   Ishioka M, 2019, DIGEST ENDOSC, V31, pe34, DOI 10.1111/den.13306
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Kamad T, 2007, DIGEST ENDOSC, V19, P180, DOI 10.1111/j.1443-1661.2007.00750.x
   Kamada Tomoari, 2005, Nihon Rinsho, V63 Suppl 11, P557
   Kaminishi M., 2002, DIGEST ENDOSC, V14, P138, DOI DOI 10.1046/J.1443-1661.2002.00199.X
   Kanemitsu T, 2017, ENDOSCOPY, V49, P529, DOI 10.1055/s-0043-103409
   Kanzaki H, 2012, HELICOBACTER, V17, P224, DOI 10.1111/j.1523-5378.2012.00938.x
   Kato T, 2013, DIGEST ENDOSC, V25, P508, DOI 10.1111/den.12031
   Kimura K, 1969, ENDOSCOPY, V1, P87, DOI [10.1055/s-0028-1098086, DOI 10.1055/S-0028-1098086]
   LAINE L, 1995, GASTROINTEST ENDOSC, V42, P420, DOI 10.1016/S0016-5107(95)70043-9
   Majima A, 2019, GASTROINTEST ENDOSC
   Miyamoto M, 2003, DIGEST DIS SCI, V48, P968, DOI 10.1023/A:1023016000096
   Miyamoto M, 2002, DIGEST LIVER DIS, V34, P819, DOI 10.1016/S1590-8658(02)80078-0
   Mizukami K, 2017, GASTROENT RES PRACT, V2017, DOI 10.1155/2017/5054237
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Moribata K, 2016, DIGEST ENDOSC, V28, P434, DOI 10.1111/den.12581
   Murayama Y, 2006, DIGEST ENDOSC, V18, P98
   Nagata N, 2011, GASTROENTEROL RES, V4, P203, DOI 10.4021/gr357w
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Nakayama Y, 2004, HELICOBACTER, V9, P95, DOI 10.1111/j.1083-4389.2004.00204.x
   Neumann H, 2019, DIGEST ENDOSC, V31, P389, DOI 10.1111/den.13391
   Nishibayashi H, 2003, J GASTROEN HEPATOL, V18, P1384, DOI 10.1046/j.1440-1746.2003.03192.x
   Nishikawa Y, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193197
   Nomura S, 2013, DIGEST ENDOSC, V25, P136, DOI 10.1111/j.1443-1661.2012.01357.x
   Ono S, 2020, DIGESTION, V101, P624, DOI 10.1159/000501634
   Ono S, 2018, DIGESTION, V98, P222, DOI 10.1159/000489454
   Pimentel-Nunes P, 2016, ENDOSCOPY, V48, P723, DOI 10.1055/s-0042-108435
   Redeen S, 2003, ENDOSCOPY, V35, P946, DOI 10.1055/s-2003-43479
   Saka A, 2015, DIGEST ENDOSC, V27, P734, DOI 10.1111/den.12483
   Shibukawa N, 2017, WORLD J GASTRO ONCOL, V9, P327, DOI 10.4251/wjgo.v9.i8.327
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shichijo S, 2017, J GASTROEN HEPATOL, V32, P1581, DOI 10.1111/jgh.13764
   Shiotani A, 2007, J GASTROENTEROL, V42, P610, DOI 10.1007/s00535-007-2073-5
   Sugimoto M, 2017, INTERNAL MED, V56, P579, DOI 10.2169/internalmedicine.56.7775
   Takao T, 2011, GASTROENT RES PRACT, V2011, DOI 10.1155/2011/631461
   Take S, 2005, AM J GASTROENTEROL, V100, P1037, DOI 10.1111/j.1572-0241.2005.41384.x
   Takeda T, 2020, DIGESTION, V101, P598, DOI 10.1159/000501534
   Terao S, 2020, DIGEST ENDOSC, V32, P364, DOI 10.1111/den.13500
   Tongtawee T, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/808505
   Uedo N, 2006, ENDOSCOPY, V38, P819, DOI 10.1055/s-2006-944632
   Uedo N, 2005, GASTROINTEST ENDOSC, V62, P521, DOI 10.1016/j.gie.2005.06.031
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   Venerito M, 2018, HELICOBACTER, V23, DOI 10.1111/hel.12518
   Watanabe K, 2013, WORLD J GASTROENTERO, V19, P4374, DOI 10.3748/wjg.v19.i27.4374
   Wong BCY, 2004, JAMA-J AM MED ASSOC, V291, P187, DOI 10.1001/jama.291.2.187
   Yagi K, 2002, J GASTROEN HEPATOL, V17, P39, DOI 10.1046/j.1440-1746.2002.02665.x
   Yamasaki Y, 2017, ANN GASTROENTEROL, V30, P302, DOI 10.20524/aog.2017.0134
   Yasuda T, 2020, DIGEST ENDOSC, V32, P373, DOI 10.1111/den.13509
   YASUNAGA Y, 1994, GUT, V35, P1571, DOI 10.1136/gut.35.11.1571
   Yoshida N, 2019, GUT LIVER, V13, P140, DOI 10.5009/gnl18276
   Yoshii S, 2020, DIGEST ENDOSC, V32, P74, DOI 10.1111/den.13486
NR 65
TC 21
Z9 23
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JAN
PY 2020
VL 32
IS 2
SI SI
BP 191
EP 203
DI 10.1111/den.13540
PG 13
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA KC7UM
UT WOS:000507378200003
PM 31550395
OA Bronze
DA 2023-04-20
ER

PT J
AU Furnari, M
   Telese, A
   Hann, A
   Lisotti, A
   Boskoski, I
   Eusebi, LH
AF Furnari, Manuele
   Telese, Andrea
   Hann, Alexander
   Lisotti, Andrea
   Boskoski, Ivo
   Eusebi, Leonardo Henry
TI New Devices for Endoscopic Treatments in Gastroenterology: A Narrative
   Review
SO CURRENT DRUG METABOLISM
LA English
DT Review
DE Artificial intelligence; enteroscopy; bariatric endoscopy;
   radiofrequency ablation; cholangioscopy; luminal opposing metal stents
ID DOUBLE-BALLOON ENTEROSCOPY; SMALL-BOWEL DISORDERS; UPPER
   GASTROINTESTINAL ENDOSCOPY; SINGLE-OPERATOR CHOLANGIOSCOPY; MALIGNANT
   BILIARY OBSTRUCTION; LOW-GRADE DYSPLASIA; BILE-DUCT STONES; SPIRAL
   ENTEROSCOPY; RADIOFREQUENCY ABLATION; EUROPEAN-SOCIETY
AB Endoscopy is in a period of continuous innovations in terms of image quality, endoscopes, post-processing software and lastly, application of Artificial Intelligence. Therapeutic boundaries have expanded, widening the grey zone between endoscopy and surgery, and increasing endoscopic approaches in clinical scenarios where, until a few years ago, surgery was the only option.
   New scopes and accessories have made it easier to access critical areas such as the biliary tree and the small bowel intestine. In the field of hepato-pancreato-biliary endoscopy (HPB), it is now possible to directly access the biliary ducts or cystic lesions though dedicated stents and scopes, rather than having to rely only on fluoroscopy and ultrasound, increasing the diagnostic and therapeutic options by applying a three-dimensional approach. This narrative review will give an overview of some of the most relevant emerging fields in luminal and HPB endoscopy, highlighting advantages and main limitations of the techniques, and providing considerations for future development.
C1 [Furnari, Manuele] Univ Genoa, Dept Internal Med, Gastroenterol Unit, Policlin IRCCS San Martino, Genoa, Italy.
   [Telese, Andrea] Univ Coll Hosp NHS Fdn Trust, Dept Gastroenterol, London, England.
   [Hann, Alexander] Univ Hosp Wuerzburg, Internal Med 2, Intervent & Expt Endoscopy InExEn, Wurzburg, Germany.
   [Lisotti, Andrea] Univ Bologna, Hosp Imola, Gastroenterol Unit, Bologna, Italy.
   [Boskoski, Ivo] Fdn Policlin Univ Agostino Gemelli IRCSS, Digest Endoscopy Unit, Rome, Italy.
   [Eusebi, Leonardo Henry] Univ Bologna, Dept Med & Surg Sci, Bologna, Italy.
C3 University of Genoa; University of London; University College London;
   University of Wurzburg; Azienda USL di Imola; University of Bologna;
   Catholic University of the Sacred Heart; IRCCS Policlinico Gemelli;
   University of Bologna
RP Eusebi, LH (通讯作者)，Univ Bologna, Dept Med & Surg Sci, Gastroenterol Unit, St Orsola Univ Hosp, Via Massarenti 9, I-40138 Bologna, Italy.
EM leonardo.eusebi@unibo.it
RI Boskoski, Ivo/A-9629-2014; Lisotti, Andrea/L-6762-2019; Eusebi, Leonardo
   Henry/E-6687-2017; Furnari, Manuele/N-5545-2015
OI Boskoski, Ivo/0000-0001-8194-2670; Lisotti, Andrea/0000-0002-7724-7402;
   Eusebi, Leonardo Henry/0000-0003-3323-7744; Furnari,
   Manuele/0000-0001-6424-079X
CR Abu Dayyeh BK, 2017, CLIN GASTROENTEROL H, V15, P37, DOI 10.1016/j.cgh.2015.12.030
   Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V82, P425, DOI 10.1016/j.gie.2015.03.1964
   Acosta A, 2017, CLIN GASTROENTEROL H, V15, P631, DOI 10.1016/j.cgh.2016.10.023
   Akerman PA, 2008, ENDOSCOPY, V40, P974, DOI 10.1055/s-0028-1103402
   Akerman PA, 2009, GASTROINTEST ENDOSC, V69, P327, DOI 10.1016/j.gie.2008.07.042
   Almadi MA, 2020, ENDOSCOPY, V52, P574, DOI 10.1055/a-1135-8980
   Alqahtani A, 2019, GASTROINTEST ENDOSC, V89, P1132, DOI 10.1016/j.gie.2018.12.012
   Anderloni A, 2019, GASTROINTEST ENDOSC, V89, P69, DOI 10.1016/j.gie.2018.08.047
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Badshah MB, 2019, EUR J GASTROEN HEPAT, V31, P935, DOI 10.1097/MEG.0000000000001402
   Bang J.Y., 2020, CLIN GASTROENTEROL H, V20
   Bang JY, 2018, GASTROINTEST ENDOSC, V87, P1432, DOI 10.1016/j.gie.2017.11.036
   Bang JY, 2016, ENDOSCOPY, V48, P339, DOI 10.1055/s-0034-1393354
   Baniya R, 2017, GASTROINTEST ENDOSC, V86, P997, DOI 10.1016/j.gie.2017.06.015
   Beyna T., 2020, GUT, P1053
   Beyna T, 2018, ENDOSCOPY, V50, P518, DOI 10.1055/s-0043-123577
   Bisschops R, 2016, ENDOSCOPY, V48, P843, DOI 10.1055/s-0042-113128
   Boskoski I., 2020, THERAP ADV GASTROENT, DOI [10.1590/0102-6720201700010006, DOI 10.1590/0102-6720201700010006]
   Boskoski I, 2020, EXPERT REV GASTROENT, V14, P375, DOI 10.1080/17474124.2020.1757429
   Buchwald H, 2007, SURGERY, V142, P621, DOI 10.1016/j.surg.2007.07.018
   Buscaglia JM, 2009, ENDOSCOPY, V41, P194, DOI 10.1055/s-0028-1119602
   Buxbaum J, 2018, GASTROINTEST ENDOSC, V87, P1050, DOI 10.1016/j.gie.2017.08.021
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Camus M, 2018, GASTROINTEST ENDOSC, V88, P511, DOI 10.1016/j.gie.2018.04.2332
   Confer BD, 2019, GASTROINTEST ENDOSC, V90, P321, DOI 10.1016/j.gie.2019.04.207
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   Deprez PH, 2018, ENDOSCOPY, V50, P109, DOI 10.1055/s-0043-121268
   Desai M, 2017, GASTROINTEST ENDOSC, V85, P482, DOI 10.1016/j.gie.2016.09.022
   Despott EJ, 2015, DIGEST LIVER DIS, V47, P395, DOI 10.1016/j.dld.2015.02.003
   Dumonceau JM, 2017, ENDOSCOPY, V49, P695, DOI 10.1055/s-0043-109021
   Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   El Chafic AH, 2017, GASTROINTEST ENDOSC, V86, P510, DOI 10.1016/j.gie.2017.01.010
   Eusebi LH, 2019, ENDOSC INT OPEN, V7, pE1393, DOI 10.1055/a-0967-4684
   Fabbri C, 2014, WORLD J GASTROENTERO, V20, P8424, DOI 10.3748/wjg.v20.i26.8424
   Facciorusso A, 2020, GASTROINTEST ENDOSC, V92, P1, DOI 10.1016/j.gie.2020.01.038
   Facciorusso A, 2020, GASTROINTEST ENDOSC, V91, P14, DOI 10.1016/j.gie.2019.07.018
   Fayad L, 2019, GASTROINTEST ENDOSC, V89, P782, DOI 10.1016/j.gie.2018.08.030
   Fogel EL, 2006, GASTROINTEST ENDOSC, V63, P71, DOI 10.1016/j.gie.2005.08.039
   Fugazza A, 2020, GASTROINTEST ENDOSC, V91, P574, DOI 10.1016/j.gie.2019.11.021
   Fujii Larissa L, 2014, Gastrointest Endosc Clin N Am, V24, P125, DOI 10.1016/j.giec.2013.08.003
   Fusaroli P, 2016, GASTROINTEST ENDOSC, V84, P587, DOI 10.1016/j.gie.2016.06.006
   Fusaroli P, 2016, PANCREAS, V45, P265, DOI 10.1097/MPA.0000000000000441
   Gerges C, 2019, ENDOSC INT OPEN, V7, pE99, DOI 10.1055/a-0808-4499
   Giovannini M, 2019, ENDOSC ULTRASOUND, V8, pS35, DOI 10.4103/eus.eus_47_19
   GRIMM H, 1992, GASTROINTEST ENDOSC, V38, P170, DOI 10.1016/S0016-5107(92)70384-8
   Gutierrez OIB, 2018, CLIN GASTROENTEROL H, V16, P918, DOI 10.1016/j.cgh.2017.10.017
   Hajifathalian K, 2019, GASTROINTEST ENDOSC, V89, pAB58, DOI 10.1016/j.gie.2019.04.019
   Hartmann D, 2007, ENDOSCOPY, V39, pE276, DOI 10.1055/s-2007-966616
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Hedjoudje A, 2020, CLIN GASTROENTEROL H, V18, P1043, DOI 10.1016/j.cgh.2019.08.022
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   de Moura DTH, 2020, CLIN ENDOSC, V53, P600, DOI 10.5946/ce.2019.170
   Huang JY, 2017, GASTROINTEST ENDOSC, V85, P996, DOI 10.1016/j.gie.2016.09.026
   Huberty V, 2018, ENDOSCOPY, V50, P1156, DOI 10.1055/a-0630-1224
   Huberty V, 2017, GASTROINTEST ENDOSC, V85, P833, DOI 10.1016/j.gie.2016.08.007
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jacques J., 2020, GASTROINTEST ENDOSC
   Jenssen C, 2016, ULTRASCHALL MED, V37, pE33, DOI 10.1055/s-0035-1553785
   Jin Z, 2019, DIGEST ENDOSC, V31, P256, DOI 10.1111/den.13307
   Kadayifci A, 2016, ENDOSCOPY, V48, P1096, DOI 10.1055/s-0042-115938
   Kamata K, 2016, ENDOSCOPY, V48, P35, DOI 10.1055/s-0034-1393564
   Komanduri S, 2016, GASTROINTEST ENDOSC, V84, P209, DOI 10.1016/j.gie.2016.03.013
   Krishna SG, 2020, GASTROINTEST ENDOSC, V91, P551, DOI 10.1016/j.gie.2019.09.014
   Krishna SG, 2020, CLIN GASTROENTEROL H, V18, P432, DOI 10.1016/j.cgh.2019.06.010
   Krishna SG, 2017, GASTROINTEST ENDOSC, V86, P644, DOI 10.1016/j.gie.2017.03.002
   Kuwahara T, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000045
   Larghi A, 2019, DIGEST ENDOSC, V31, P245, DOI 10.1111/den.13298
   Lenze F, 2018, UNITED EUR GASTROENT, V6, P902, DOI 10.1177/2050640618764943
   Li CF, 2018, CANCER COMMUN, V38, DOI 10.1186/s40880-018-0325-9
   Li H, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000010207
   Lipka S, 2015, J CLIN GASTROENTEROL, V49, P177, DOI 10.1097/MCG.0000000000000274
   Lisotti A, 2020, GASTROINTEST ENDOSC, V91, P1234, DOI 10.1016/j.gie.2020.01.034
   Lisotti A, 2019, ENDOSC INT OPEN, V7, pE504, DOI 10.1055/a-0854-3785
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Lopez-Nava G, 2017, OBES SURG, V27, P2649, DOI 10.1007/s11695-017-2693-7
   Lopez-Nava G, 2017, ABCD-ARQ BRAS CIR DI, V30, P18, DOI 10.1590/0102-6720201700010006
   Luigiano C, 2016, GASTROENT RES PRACT, V2016, DOI 10.1155/2016/4249510
   Luna LEM, 2006, GASTROENTEROLOGY, V131, P1064, DOI 10.1053/j.gastro.2006.08.021
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Manes G, 2019, ENDOSCOPY, V51, P472, DOI 10.1055/a-0862-0346
   Mans L, 2018, DIGEST DIS, V36, P325, DOI 10.1159/000488479
   May A, 2011, ENDOSCOPY, V43, P477, DOI 10.1055/s-0030-1256340
   Maydeo AP, 2019, ENDOSCOPY, V51, P922, DOI 10.1055/a-0942-9336
   McCarty Thomas R, 2019, Endosc Int Open, V7, pE1474, DOI 10.1055/a-0996-8178
   Messer I, 2013, GASTROINTEST ENDOSC, V77, P241, DOI 10.1016/j.gie.2012.08.020
   Moschler O, 2011, ENDOSCOPY, V43, P484, DOI 10.1055/s-0030-1256249
   Mohan BP, 2020, ENDOSCOPY, V52, P96, DOI 10.1055/a-1020-3932
   Mohan BP, 2019, ENDOSC ULTRASOUND, V8, P382, DOI 10.4103/eus.eus_27_19
   Mohan BP, 2019, ENDOSC ULTRASOUND, V8, P241, DOI 10.4103/eus.eus_63_18
   Mohan BP, 2019, GASTROINTEST ENDOSC, V89, P238, DOI [10.1016/j.gie.2018.10.018, 10.1016/j.gie.2018.10.036]
   Monkemuller KE, 1998, GASTROINTEST ENDOSC, V48, P195, DOI 10.1016/S0016-5107(98)70164-6
   Mori Y, 2018, J HEPATO-BIL-PAN SCI, V25, P87, DOI 10.1002/jhbp.504
   Napoleon B, 2016, SURG ENDOSC, V30, P2603, DOI 10.1007/s00464-015-4510-5
   Nayar MK, 2018, ENDOSC INT OPEN, V6, pE513, DOI 10.1055/s-0044-102097
   Neuhaus Horst, 2016, VideoGIE, V1, P32, DOI 10.1016/j.vgie.2016.08.005
   Njei B, 2016, ALIMENT PHARM THER, V44, P1139, DOI 10.1111/apt.13817
   Njei B, 2017, GASTROINTEST ENDOSC, V85, P773, DOI 10.1016/j.gie.2016.08.020
   Oh HC, 2016, KOREAN J INTERN MED, V31, P1073, DOI 10.3904/kjim.2016.066
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Palazzo M, 2020, SURG ENDOSC, V34, P2532, DOI 10.1007/s00464-019-07062-9
   Pecere S, 2018, TRANSL GASTROENT HEP, V3, DOI 10.21037/tgh.2018.10.01
   Phoa KN, 2014, JAMA-J AM MED ASSOC, V311, P1209, DOI 10.1001/jama.2014.2511
   Polkowski M, 2017, ENDOSCOPY, V49, P989, DOI 10.1055/s-0043-119219
   Pu LZ, 2015, WORLD J GASTROENTERO, V21, P13374, DOI 10.3748/wjg.v21.i47.13374
   Qumseya BJ, 2016, CLIN GASTROENTEROL H, V14, P1086, DOI 10.1016/j.cgh.2016.04.001
   Rajagopalan H, 2016, DIABETES CARE, V39, P2254, DOI 10.2337/dc16-0383
   Ramchandani M, 2015, WORLD J GASTROENTERO, V21, P4722, DOI 10.3748/wjg.v21.i15.4722
   Ramchandani M, 2011, GASTROINTEST ENDOSC, V74, P511, DOI 10.1016/j.gie.2011.04.034
   Rondonotti E, 2018, ENDOSCOPY, V50, P423, DOI 10.1055/a-0576-0566
   Rosenthal RJ, 2006, OBES SURG, V16, P119, DOI 10.1381/096089206775565230
   Sandler BJ, 2011, SURG ENDOSC, V25, P3028, DOI 10.1007/s00464-011-1665-6
   Sartoretto A, 2018, OBES SURG, V28, P1812, DOI 10.1007/s11695-018-3135-x
   Schembre DB, 2011, GASTROINTEST ENDOSC, V73, P515, DOI 10.1016/j.gie.2010.11.047
   Schmitz R, 2019, Z GASTROENTEROL, V57, P767, DOI 10.1055/a-0891-4032
   Schneider M, 2019, WORLD J GASTROENTERO, V25, P3538, DOI 10.3748/wjg.v25.i27.3538
   Sethi A, 2011, GASTROINTEST ENDOSC, V73, P251, DOI 10.1016/j.gie.2010.08.058
   Shah RJ, 2017, ENDOSCOPY, V49, P651, DOI 10.1055/s-0043-106295
   Shaheen NJ, 2011, GASTROENTEROLOGY, V141, P460, DOI 10.1053/j.gastro.2011.04.061
   Shaheen NJ, 2009, NEW ENGL J MED, V360, P2277, DOI 10.1056/NEJMoa0808145
   Sharaiha RZ, 2017, CLIN GASTROENTEROL H, V15, P504, DOI 10.1016/j.cgh.2016.12.012
   Sharma P, 2020, GASTROENTEROLOGY, V158, P760, DOI 10.1053/j.gastro.2019.09.051
   Singh S, 2014, GASTROINTEST ENDOSC, V79, P897, DOI 10.1016/j.gie.2014.01.009
   Singh T, 2019, CLEV CLIN J MED, V86, P724, DOI 10.3949/ccjm.86a.18106
   Sjostrom L, 2007, NEW ENGL J MED, V357, P741, DOI 10.1056/NEJMoa066254
   Sofi AA, 2018, GASTROINTEST ENDOSC, V87, P944, DOI 10.1016/j.gie.2017.10.029
   Spada C, 2019, UNITED EUR GASTROENT, V7, P614, DOI 10.1177/2050640619850365
   Steel AW, 2011, GASTROINTEST ENDOSC, V73, P149, DOI 10.1016/j.gie.2010.09.031
   Storm AC, 2019, GASTROINTEST ENDOSC, V89, P1139, DOI 10.1016/j.gie.2019.02.025
   Sullivan Shelby, 2017, Gastrointest Endosc Clin N Am, V27, P277, DOI 10.1016/j.giec.2016.12.001
   Sullivan S, 2017, OBESITY, V25, P294, DOI 10.1002/oby.21702
   Takano N, 2011, GASTROINTEST ENDOSC, V73, P734, DOI 10.1016/j.gie.2010.10.047
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Tang RSY, 2020, ENDOSCOPY, V52, pE251, DOI 10.1055/a-1089-7506
   Tate CM, 2017, ADV THER, V34, P1859, DOI 10.1007/s12325-017-0562-3
   Tringali A, 2015, ENDOSCOPY, V47, P739, DOI 10.1055/s-0034-1392584
   Tsujikawa T, 2008, ENDOSCOPY, V40, P11, DOI 10.1055/s-2007-966976
   Turowski F, 2018, SURG ENDOSC, V32, P3981, DOI 10.1007/s00464-018-6141-0
   VILMANN P, 1992, GASTROINTEST ENDOSC, V38, P172, DOI 10.1016/S0016-5107(92)70385-X
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Xin L, 2011, GASTROINTEST ENDOSC, V74, P563, DOI 10.1016/j.gie.2011.03.1239
   Yamamoto H, 2001, GASTROINTEST ENDOSC, V53, P216, DOI 10.1067/mge.2001.112181
   Yamamoto H, 2015, DIGEST ENDOSC, V27, P331, DOI 10.1111/den.12378
   Yang JF, 2018, ENDOSCOPY, V50, P751, DOI 10.1055/s-0043-124870
   Zheng WF, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000109
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 148
TC 0
Z9 0
U1 0
U2 2
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1389-2002
EI 1875-5453
J9 CURR DRUG METAB
JI Curr. Drug Metab.
PY 2020
VL 21
IS 11
BP 850
EP 865
DI 10.2174/1389200221666200722145727
PG 16
WC Biochemistry & Molecular Biology; Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Pharmacology & Pharmacy
GA PN3YW
UT WOS:000604419000004
PM 32703127
DA 2023-04-20
ER

PT J
AU Gao, Y
   Lu, WN
   Si, XB
   Lan, Y
AF Gao, Yan
   Lu, Weining
   Si, Xiaobei
   Lan, Yu
TI Deep Model-Based Semi-Supervised Learning Way for Outlier Detection in
   Wireless Capsule Endoscopy Images
SO IEEE ACCESS
LA English
DT Article
DE Convolutional neural network; long short term memory network; outlier
   detection; semi-supervised; wireless capsule endoscopy
ID FAULT-DETECTION
AB Wireless capsule endoscopy (WCE) has become an irreplaceable tool for diagnosing small intestinal diseases, and detecting the outliers in WCE images automatically remains as a hot research topic. Considering the difficulties in obtaining sufficient labeled WCE data, it is necessary to develop the diagnosis model which works well with only little labeled or even unlabeled training samples. In this paper, a novel semi-supervised deep-structured framework is introduced to solve the problem of outlier detection in WCE images. The key idea of our model is to mine the anomalous graphical patterns existed in the image by analyzing the spatial-scale trends of sequential image regions. Three main contributions are concluded: 1) we integrate a convolutional neural network into long short term memory network, so that the intrinsic differences between outliers and normal instances could be captured. Besides, 2) a assessment model is built by using various signs of anomaly occurrence and fake outliers knowledge learned during the training stage, which enhances the outlier alarm accuracy significantly. Furthermore, 3) a nest-structured training method is proposed, which helps our model achieving efficient training process. Experimental results on the real WCE images demonstrate the effectiveness of our model.
C1 [Gao, Yan; Si, Xiaobei; Lan, Yu] Beijing Jishuitan Hosp, Dept Gastroenterol, Beijing 100035, Peoples R China.
   [Lu, Weining] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Lan, Y (通讯作者)，Beijing Jishuitan Hosp, Dept Gastroenterol, Beijing 100035, Peoples R China.
EM lany_2020@163.com
OI Si, Xiaobei/0000-0002-3134-2295
FU Beijing JST Research Funding by Beijing Jishuitan (JST) Hospital, China
   [YGQ-201911]
FX This work was supported by the Beijing JST Research Funding under Grant
   YGQ-201911, which is provided by Beijing Jishuitan (JST) Hospital,
   China.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   [Anonymous], 2014, INT C INFORMATICS EL
   [Anonymous], 2007, INT J INF TECHNOL
   Bakator Mihalj, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030047
   Bchir O., 2018, P COMP SCI INF TECHN, P402
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fernandez-Francos D, 2013, COMPUT IND ENG, V64, P357, DOI 10.1016/j.cie.2012.10.013
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   He K., 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46493-0_38
   Huang J, 2016, J PROCESS CONTR, V39, P88, DOI 10.1016/j.jprocont.2016.01.001
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Lipton Z. C., 2015, ARXIV150600019
   Liu X., 2018, P SOC PHOTO-OPT INS
   Lu WN, 2018, IEEE T INSTRUM MEAS, V67, P1679, DOI 10.1109/TIM.2018.2800978
   Lu WN, 2017, IEEE T IMAGE PROCESS, V26, P4321, DOI 10.1109/TIP.2017.2713048
   Ma HH, 2013, IND ENG CHEM RES, V52, P2389, DOI 10.1021/ie302042c
   Mathew M, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1730, DOI 10.1109/ECS.2015.7124882
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yale Song, 2013, P 23 INT JOINT C ART, P1685
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhai SF, 2016, PR MACH LEARN RES, V48
   Zhao B, 2017, INT J AUTOM COMPUT, V14, P119, DOI 10.1007/s11633-017-1053-3
   Zhao ZT, 2019, 2018 7TH INTERNATIONAL CONFERENCE ON ADVANCED MATERIALS AND COMPUTER SCIENCE (ICAMCS 2018), P1, DOI [10.23977/icamcs.2018.001, 10.1109/TNNLS.2018.2876865]
NR 34
TC 6
Z9 6
U1 3
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 81621
EP 81632
DI 10.1109/ACCESS.2020.2991115
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA ML5CH
UT WOS:000549483200009
OA gold
DA 2023-04-20
ER

PT J
AU Goncalves, WGE
   dos Santos, MHD
   Lobato, FMF
   Ribeiro-dos-Santos, A
   de Araujo, GS
AF Goncalves e Goncalves, Wanderson
   de Paula dos Santos, Marcelo Henrique
   Franca Lobato, Fabio Manoel
   Ribeiro-dos-Santos, Andrea
   de Araujo, Gilderlanio Santana
TI Deep learning in gastric tissue diseases: a systematic review
SO BMJ OPEN GASTROENTEROLOGY
LA English
DT Review
ID HELICOBACTER-PYLORI INFECTION; NEURAL-NETWORKS; CANCER
AB Background In recent years, deep learning has gained remarkable attention in medical image analysis due to its capacity to provide results comparable to specialists and, in some cases, surpass them. Despite the emergence of deep learning research on gastric tissues diseases, few intensive reviews are addressing this topic.
   YMethod We performed a systematic review related to applications of deep learning in gastric tissue disease analysis by digital histology, endoscopy and radiology images.
   lusions This review highlighted the high potential and shortcomings in deep learning research studies applied to gastric cancer, ulcer, gastritis and non-malignant diseases. Our results demonstrate the effectiveness of gastric tissue analysis by deep learning applications. Moreover, we also identified gaps of evaluation metrics, and image collection availability, therefore, impacting experimental reproducibility.
C1 [Goncalves e Goncalves, Wanderson; Ribeiro-dos-Santos, Andrea; de Araujo, Gilderlanio Santana] Univ Fed Para, Inst Ciencias Biol, Lab Genet Humana & Med, Belem, Para, Brazil.
   [Goncalves e Goncalves, Wanderson; Ribeiro-dos-Santos, Andrea] Univ Fed Para, Nucleo Pesquisas Oncol, Belem, Para, Brazil.
   [de Paula dos Santos, Marcelo Henrique] Univ Fed Para, Engn Computacao, Belem, Para, Brazil.
   [Franca Lobato, Fabio Manoel] Univ Fed Oeste Para, Inst Engn & Geociencias, Santarem, Para, Brazil.
C3 Universidade Federal do Para; Universidade Federal do Para; Universidade
   Federal do Para; Universidade Federal do Oeste do Para
RP de Araujo, GS (通讯作者)，Univ Fed Para, Inst Ciencias Biol, Lab Genet Humana & Med, Belem, Para, Brazil.
EM gilderlanio@gmail.com
RI Araújo, Gilderlanio Santana de/K-4842-2019; Gonçalves e Gonçalves,
   Wanderson/ABF-5140-2020; Ribeiro dos Santos, Ândrea Kely
   Campos/W-6339-2019
OI Araújo, Gilderlanio Santana de/0000-0001-9199-9419; Gonçalves e
   Gonçalves, Wanderson/0000-0003-0918-1728; Ribeiro dos Santos, Ândrea
   Kely Campos/0000-0001-7001-1483
FU Fundacao Amazonia Paraense de Amparo a Pesquisa -FAPESPA [008/2017];
   PROPESP/UFPA
FX Fundacao Amazonia Paraense de Amparo a Pesquisa -FAPESPA (No. 008/2017)
   and PROPESP/UFPA for the financial support and scholarships.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agrusa AS, 2019, IEEE T BIOMEDICAL EN
   Alam M., 2016, P 9 EAI INT C BIOINS, P21
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x
   Bahrampour S, 2016, COMP STUDY CAFFE NEO
   Bergstra J, 2010, P PYTH SCI COMP C SC, V4, P3, DOI DOI 10.25080/MAJORA-92BF1922-003
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Buck S, 2015, SCIENCE, V348, P1403, DOI 10.1126/science.aac8041
   Bui M. M., 2019, J PATHOL INFORM, V10, P10
   Chen YF, 2016, BIOINFORMATICS, V32, P1832, DOI 10.1093/bioinformatics/btw074
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   Chollet F., 2015, TECH REP
   de Lange T, 2018, WORLD J GASTROENTERO, V24, P5057, DOI 10.3748/wjg.v24.i45.5057
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI DOI 10.1561/2000000039
   Fang M, 2019, INT SOC OPTICS PHOTO
   FDA US, 2019, PROP REG FRAM MOD AR
   Garcia E, 2017, COMP MED SY, P200, DOI 10.1109/CBMS.2017.94
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Grapov D, 2018, OMICS, V22, P630, DOI 10.1089/omi.2018.0097
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Guimaraes P, 2020, GUT, V69, P4, DOI 10.1136/gutjnl-2019-319347
   Haenssle H A, 2019, Ann Oncol, V30, p130e, DOI 10.1093/annonc/mdy520
   He YX, 2023, TRANSPORTMETRICA A, V19, DOI [10.1109/CVPR.2016.90, 10.1080/23249935.2022.2033348]
   Heaton JB, 2017, APPL STOCH MODEL BUS, V33, P3, DOI 10.1002/asmb.2209
   Hecht-Nielsen R, 1992, NEURAL NETWORKS PERC, P65, DOI [DOI 10.1016/0893-6080(88)90469-8, DOI 10.1016/B978-0-12-741252-8.50010-8]
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Ivakhnenko A. G., 1965, 1 WORKING DEEP LEARN
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Jia Q, 2018, J HEALTHC ENG, V2018, P1, DOI 10.1155/2018/9235023
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kanai M, 2019, IEEE IMAGE PROC, P1371, DOI 10.1109/ICIP.2019.8803705
   Kather JN, 2019, NAT MED, V25, P1054, DOI 10.1038/s41591-019-0462-y
   Khryashchev VV, 2019, ICGSP '19 - PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON GRAPHICS AND SIGNAL PROCESSING, P90, DOI 10.1145/3338472.3338492
   Lee JH, 2019, SURG ENDOSC, V33, P3790, DOI 10.1007/s00464-019-06677-2
   Lee J, 2018, JCO CLIN CANCER INFO, V2, DOI 10.1200/CCI.17.00065
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Leon F, 2019, 2019 22 S IM SIGN PR, V2019, P1, DOI DOI 10.1109/STSIVA.2019.8730284
   Li YX, 2018, PROC INT C TOOLS ART, P20, DOI 10.1109/ICTAI.2018.00014
   Li YX, 2018, I S BIOMED IMAGING, P182
   Li Z, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300917
   Liang QK, 2019, IEEE J BIOMED HEALTH, V23, P1205, DOI 10.1109/JBHI.2018.2850040
   Liu B, 2018, P INT COMP SOFTW APP, P408, DOI 10.1109/COMPSAC.2018.10267
   Liu B, 2018, CHIN CONTR CONF, P7187
   Liu XQ, 2018, IEEE IMAGE PROC, P1388, DOI 10.1109/ICIP.2018.8451067
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Malon C., 2008, Proceedings of the 5th International Conference on Soft Computing as Transdisciplinary Science and Technology 2008. In Memory of Professor Yasuhiko Dote, P450, DOI 10.1145/1456223.1456316
   Martin DR, 2020, ARCH PATHOL LAB MED, V144, P370, DOI 10.5858/arpa.2019-0004-OA
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mori H, 2019, PATHOL INT, V69, P437, DOI 10.1111/pin.12828
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Nezhad MZ, 2016, IEEE INT C BIOINFORM, P501, DOI 10.1109/BIBM.2016.7822569
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Radi K, 2016, P 5 INT C NETW COMM, P73
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Ratner M, 2018, NAT BIOTECHNOL, V36, P673, DOI 10.1038/nbt0818-673a
   Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Robertson S, 2018, TRANSL RES, V194, P19, DOI 10.1016/j.trsl.2017.10.010
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharma H, 2017, COMPUT MED IMAG GRAP, V61, P2, DOI 10.1016/j.compmedimag.2017.06.001
   Simonyan K, 2015, Arxiv
   Sun JY, 2018, COMP MED SY, P351, DOI 10.1109/CBMS.2018.00068
   Sun M, 2015, IEEE ACCESS
   Takahashi Tsunehiro, 2013, Cancers (Basel), V5, P48, DOI 10.3390/cancers5010048
   Togo R, 2019, IEEE ACCESS, V7, P87448, DOI 10.1109/ACCESS.2019.2925863
   Togo R, 2018, IEEE IMAGE PROC, P2082, DOI 10.1109/ICIP.2018.8451019
   Togo R, 2019, J GASTROENTEROL, V54, P321, DOI 10.1007/s00535-018-1514-7
   Torre LA, 2016, CANCER EPIDEM BIOMAR, V25, P16, DOI 10.1158/1055-9965.EPI-15-0578
   Van Cutsem E, 2016, LANCET, V388, P2654, DOI 10.1016/S0140-6736(16)30354-3
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang JJ, 2018, J MANUF SYST, V48, P144, DOI 10.1016/j.jmsy.2018.01.003
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Yada T., 2013, DIAGN THER ENDOSC, V2013, DOI DOI 10.1155/2013/241320
NR 79
TC 19
Z9 21
U1 3
U2 21
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 2054-4774
J9 BMJ OPEN GASTROENTER
JI BMJ Open Gastroenterol.
PY 2020
VL 7
IS 1
AR e000371
DI 10.1136/bmjgast-2019-000371
PG 11
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA LF9TY
UT WOS:000527756600016
PM 32337060
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Gong, HF
   Chen, LM
   Li, CH
   Zeng, J
   Tao, XC
   Wang, Y
AF Gong, Haifan
   Chen, Limin
   Li, Changhao
   Zeng, Jun
   Tao, Xichen
   Wang, Yue
TI Online Tracking and Relocation Based on a New Rotation-Invariant
   Haar-Like Statistical Descriptor in Endoscopic Examination
SO IEEE ACCESS
LA English
DT Article
DE Gastrointestinal tract; Target tracking; Biopsy; Feature extraction;
   Robustness; Cancer; Relocation; online tracking; Haar-like feature;
   random forest; Siamese network
AB In the gastrointestinal biopsy, online tracking and relocation of the region-of-interest are essential to early diagnosis and surgical intervention of colorectal cancer. However, it is challenging for the examiner to track and retarget the optical biopsy site due to interfering factors, e.g. violent rotation of the lens, illumination variation, shape deformation, and target long-time-lost. Previous works may not effectively handle the mentioned challenges due to the complexity of gastrointestinal environment and the limitation of data. In this work, we construct an online tracking and relocation framework based on the concept of detection and tracking, which is dramatically adapted to the inherent characteristics of the gastrointestinal biopsy image. To effectively distinguish the target area from the gastrointestinal biopsy, we designed a new rotated invariant Haar-like statistical descriptor which is robust for rotating and illumination changes. The descriptor is based on the sector-ring difference under the circular sampling area. A simplified statistical random forest discriminator based on confidence statistics is proposed to complete the preliminary screening of the potential tracking target. In order to further estimate the location of the target, a supervised support vector machine is introduced to rank the candidate target regions. Based on proposals of Siamese network and the random forest, a location refinement fusion has been proposed to determine the location and the confidence of the tracking area. Extensive experiments on various gastrointestinal videos, which consists of open source and self-collected data, demonstrate that the proposed framework is superior to the mainstreams methods in accuracy and robustness.
C1 [Gong, Haifan; Chen, Limin; Li, Changhao; Tao, Xichen] Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Zeng, Jun] Jiangxi Prov Peoples Hosp, Nanchang 330031, Jiangxi, Peoples R China.
   [Wang, Yue] Nanchang Univ, Clin Med Coll 2, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang University
RP Chen, LM (通讯作者)，Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM Chenlimin@ncu.edu.cn
RI Chen, Limin/HLW-1539-2023
OI Chen, Limin/0000-0001-8022-5565; Gong, Haifan/0000-0002-2749-6830
FU National Natural Science Foundation of China [61773051, 6171101044];
   National Innovation and Entrepreneurship Program for College Students
   [201910403076]; Jiangxi Provincial Department of Science and Technology
   [20171ACB20007, 20151BBE50046, 20142BBE50035, 20151BAB207052]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61773051 and Grant 6171101044, in part
   by the National Innovation and Entrepreneurship Program for College
   Students under Grant 201910403076, and in part by the Jiangxi Provincial
   Department of Science and Technology under Grant 20171ACB20007, Grant
   20151BBE50046, Grant 20142BBE50035, and Grant 20151BAB207052.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alzarouni K, 2016, IEEE INT CONF INNOV, P72
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Barczak A., 2007, P 6 WORLD AVOCADO C, P1
   Barczak A. L., 2005, IVCNZ05, P31
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Ben XY, 2019, IEEE T IMAGE PROCESS, V28, P3142, DOI 10.1109/TIP.2019.2894362
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Danelljan M., 2014, P BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Du SY, 2006, LECT NOTES COMPUT SC, V4270, P128
   Grasa Oscar G., 2011, IEEE International Conference on Robotics and Automation, P4816
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kanemitsu T, 2017, ENDOSCOPY, V49, P529, DOI 10.1055/s-0043-103409
   Kousera CA, 2014, IEEE T BIO-MED ENG, V61, P1902, DOI 10.1109/TBME.2014.2310954
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   LaScala BF, 1996, IEEE T SIGNAL PROCES, V44, P739, DOI 10.1109/78.489052
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Lin BX, 2013, LECT NOTES COMPUT SC, V8090, P35, DOI 10.1007/978-3-642-40843-4_5
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Menglong Ye, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P448, DOI 10.1007/978-3-319-46720-7_52
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Oualla M, 2016, COLLOQ INF SCI TECH, P471
   Oualla M, 2014, COLLOQ INF SCI TECH, P351, DOI 10.1109/CIST.2014.7016645
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Seibert, 2015, P 2 WORKSH LLVM COMP, P1, DOI [10.1145/2833157.2833162, DOI 10.1145/2833157.2833162]
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang Jianren, 2019, ARXIV190403280
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N., 2013, P ADV NEUR INF PROC, P809, DOI DOI 10.5555/2999611.2999702
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Ye ML, 2017, INT J COMPUT ASS RAD, V12, P1281, DOI 10.1007/s11548-017-1620-7
   Ye ML, 2016, MED IMAGE ANAL, V30, P144, DOI 10.1016/j.media.2015.10.003
   Zhang HM, 2006, IMAGE VISION COMPUT, V24, P327, DOI 10.1016/j.imavis.2005.11.010
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 43
TC 4
Z9 4
U1 3
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 101867
EP 101883
DI 10.1109/ACCESS.2020.2994440
PG 17
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MH0HC
UT WOS:000546410800002
OA gold
DA 2023-04-20
ER

PT J
AU Guo, LJ
   Xiao, X
   Wu, CC
   Zeng, XH
   Zhang, YH
   Du, J
   Bai, S
   Xie, J
   Zhang, ZW
   Li, YH
   Wang, XD
   Cheung, OP
   Sharma, M
   Liu, JJ
   Hu, B
AF Guo, LinJie
   Xiao, Xiao
   Wu, ChunCheng
   Zeng, Xianhui
   Zhang, Yuhang
   Du, Jiang
   Bai, Shuai
   Xie, Jia
   Zhang, Zhiwei
   Li, Yuhong
   Wang, Xuedan
   Cheung, Onpan
   Sharma, Malay
   Liu, Jingjia
   Hu, Bing
TI Real-time automated diagnosis of precancerous lesions and early
   esophageal squamous cell carcinoma using a deep learning model (with
   videos)
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID GASTRIC-CANCER
AB Background and Aims: We developed a system for computer-assisted diagnosis (CAD) for real-time automated diagnosis of precancerous lesions and early esophageal squamous cell carcinomas (ESCCs) to assist the diagnosis of esophageal cancer.
   Methods: A total of 6473 narrow-band imaging (NBI) images, including precancerous lesions, early ESCCs, and noncancerous lesions, were used to train the CAD system. We validated the CAD system using both endoscopic images and video datasets. The receiver operating characteristic curve of the CAD system was generated based on image datasets. An artificial intelligence probability heat map was generated for each input of endoscopic images. The yellow color indicated high possibility of cancerous lesion, and the blue color indicated noncancerous lesions on the probability heat map. When the CAD system detected any precancerous lesion or early ESCCs, the lesion of interest was masked with color.
   Results: The image datasets contained 1480 malignant NBI images from 59 consecutive cancerous cases (sensitivity, 98.04%) and 5191 noncancerous NBI images from 2004 cases (specificity, 95.03%). The area under curve was 0.989. The video datasets of precancerous lesions or early ESCCs included 27 nonmagnifying videos (perframe sensitivity 60.8%, per-lesion sensitivity, 100%) and 20 magnifying videos (per-frame sensitivity 96.1%, per-lesion sensitivity, 100%). Unaltered full-range normal esophagus videos included 33 videos (per-frame specificity 99.9%, per-case specificity, 90.9%).
   Conclusions: A deep learning model demonstrated high sensitivity and specificity for both endoscopic images and video datasets. The real-time CAD system has a promising potential in the near future to assist endoscopists in diagnosing precancerous lesions and ESCCs.
C1 [Guo, LinJie; Wu, ChunCheng; Zeng, Xianhui; Zhang, Yuhang; Du, Jiang; Bai, Shuai; Xie, Jia; Hu, Bing] Sichuan Univ, West China Hosp, Dept Gastroenterol, Chengdu, Sichuan, Peoples R China.
   [Xiao, Xiao; Zhang, Zhiwei; Li, Yuhong; Wang, Xuedan; Liu, Jingjia] Shanghai Wision AI Co Ltd, Shanghai, Peoples R China.
   [Cheung, Onpan] San Bernardino Gastroenterol Associates Inc, Rialto, CA USA.
   [Cheung, Onpan] Ace Endoscopy & Surg Ctr, Rialto, CA USA.
   [Sharma, Malay] Jaswant Rai Special Hosp, Meerut, Uttar Pradesh, India.
C3 Sichuan University
RP Hu, B (通讯作者)，37 Guoxue Rd, Chengdu, Sichuan, Peoples R China.
OI Du, Jiang/0000-0002-6558-7047
FU Sichuan Science and Technology Department Key RD projects [2019YFS0257];
   Chengdu Technological Innovation RD Projects [2018-YFYF-00033-GX]
FX This research was funded by Sichuan Science and Technology Department
   Key R&D projects (grant no. 2019YFS0257) and by Chengdu Technological
   Innovation R&D Projects (grant no. 2018-YFYF-00033-GX).
CR Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen XX, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-00650-0
   Codipilly DC, 2018, GASTROINTEST ENDOSC, V88, P413, DOI 10.1016/j.gie.2018.04.2352
   Cotton Peter B, 2011, J Interv Gastroenterol, V1, P83
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Ishihara R, 2010, DIS ESOPHAGUS, V23, P480, DOI 10.1111/j.1442-2050.2009.01039.x
   Menghi MS, 2019, PROPOS REPRESENT, V7, P189, DOI 10.20511/pyr2019.v7n3.338
   Minami H, 2014, DIGESTION, V89, P6, DOI 10.1159/000356200
   Nagami Y, 2014, AM J GASTROENTEROL, V109, P845, DOI 10.1038/ajg.2014.94
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Rustgi AK, 2014, NEW ENGL J MED, V371, P2499, DOI 10.1056/NEJMra1314530
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yamada S, 2014, GASTROINTEST ENDOSC, V79, P55, DOI 10.1016/j.gie.2013.07.008
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
NR 17
TC 96
Z9 104
U1 10
U2 55
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JAN
PY 2020
VL 91
IS 1
BP 41
EP 51
DI 10.1016/j.gie.2019.08.018
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA JX0DA
UT WOS:000503413400008
PM 31445040
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Jia, X
   Xing, XH
   Yuan, YX
   Xing, L
   Meng, MQH
AF Jia, Xiao
   Xing, Xiaohan
   Yuan, Yixuan
   Xing, Lei
   Meng, Max Q. -H.
TI Wireless Capsule Endoscopy: A New Tool for Cancer Screening in the Colon
   With Deep-Learning-Based Polyp Recognition
SO PROCEEDINGS OF THE IEEE
LA English
DT Article
DE Cancer screening; deep learning; polyp recognition; wireless capsule
   endoscopy (WCE)
ID GENERATIVE ADVERSARIAL NETWORKS; CONVOLUTIONAL NEURAL-NETWORK; CT IMAGE;
   CLASSIFICATION; SEGMENTATION; AUTOENCODERS; COLONOSCOPY; VALIDATION;
   DIAGNOSIS; PATHOLOGY
AB Accurate recognition of polyps is crucial for early colorectal cancer diagnosis and treatment. Wireless capsule endoscopy (WCE) is a noninvasive, wireless imaging tool that allows direct visualization of the entire colon without discomfort to patients and has the potential to revolutionize the screening workup for colorectal diseases. However, current manual review is laborious and time consuming, requiring the undivided concentration of the gastroenterologist. Computational methods that can assist automated polyp recognition will enhance the outcome both in terms of diagnostic accuracy and efficiency of WCE. This review introduces the computer-assisted algorithms as applied to colorectal polyp screening, focusing on the successes of deep-learning-based strategies in the WCE sequences. We survey key applications of WCE polyp recognition, covering deep-learning-based image-level classification, lesion region detection, and pixel-accurate segmentation. We conclude by discussing emerging research challenges, possible trends, and future directions.
C1 [Jia, Xiao; Xing, Xiaohan; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Yuan, Yixuan] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Xing, Lei] Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94305 USA.
   [Meng, Max Q. -H.] Chinese Univ Hong Kong, Shenzhen Res Inst, Shenzhen 518172, Guangdong, Peoples R China.
C3 Chinese University of Hong Kong; City University of Hong Kong; Stanford
   University; Chinese University of Hong Kong, Shenzhen
RP Meng, MQH (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM xjia@ee.cuhk.edu.hk; xhxing@ee.cuhk.edu.hk; yxyuan.ee@cityu.edu.hk;
   lei@stanford.edu; max.meng@ieee.org
RI meng, meng/GWZ-7461-2022
OI Meng, Max Q.-H./0000-0002-5255-5898; Yuan, Yixuan/0000-0002-0853-6948;
   Xing, Lei/0000-0003-2536-5359; Xing, Xiaohan/0000-0002-9992-3387
FU Hong Kong Research Grants Council (RGC) Collaborative Research Fund
   (CRF) Project [C4063-18GF]; Shenzhen Science and Technology Innovation
   Project [JCYJ20170413161503220]
FX The work of M. Q.-H. Meng was supported in part by the Hong Kong
   Research Grants Council (RGC) Collaborative Research Fund (CRF) Project
   under Grant C4063-18GF and in part by the Shenzhen Science and
   Technology Innovation Project under Grant JCYJ20170413161503220. (Xiao
   Jia, Xiaohan Xing, and Yixuan Yuan contributed equally to this work.)
CR American Cancer Society, 2017, CANC FACTS FIG 2017
   [Anonymous], 2007, P ICML
   [Anonymous], P SPIE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2018, EVOL SYST
   [Anonymous], P SPIE
   [Anonymous], 2017, COL CANC FACTS FIG 2
   [Anonymous], P C ESP INF
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baehrens D, 2010, J MACH LEARN RES, V11, P1803
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Blanz W. E., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P272, DOI 10.1109/ICPR.1990.119369
   Brandao P., 2018, J MED ROBOT RES, V3, P1840002, DOI DOI 10.1142/S2424905X18400020
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen Hao, 2018, Neuroimage, V170, P446, DOI 10.1016/j.neuroimage.2017.04.041
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Constantinescu AF, 2016, ROM J MORPHOL EMBRYO, V57, P979
   David E., 2013, INTERNALIZED OPPRESS, P1
   Diamantis DE, 2019, BIOMED SIGNAL PROCES, V49, P192, DOI 10.1016/j.bspc.2018.12.005
   Diamantis D, 2018, IEEE IMAGE PROC, P3124, DOI 10.1109/ICIP.2018.8451673
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Eliakim R, 2006, ENDOSCOPY, V38, P963, DOI 10.1055/s-2006-944832
   Fisher M., 2013, COLOR MED IMAGE ANAL, P129
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Frid-Adar M, 2018, I S BIOMED IMAGING, P289
   Georgakopoulos SV, 2016, IEEE CONF IMAGING SY, P510, DOI 10.1109/IST.2016.7738279
   Gibson E, 2018, IEEE T MED IMAGING, V37, P1822, DOI 10.1109/TMI.2018.2806309
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gorzalczany MB, 2017, EXPERT SYST APPL, V71, P26, DOI 10.1016/j.eswa.2016.11.017
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He K., 2017, IEEE I CONF COMP VIS, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong SN, 2018, CLIN ENDOSC, V51, P334, DOI 10.5946/ce.2018.121
   Huang C, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1423, DOI 10.1145/3269206.3271793
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Janowczyk A, 2017, COMPUT MED IMAG GRAP, V57, P50, DOI 10.1016/j.compmedimag.2016.05.003
   Jeatrakul P, 2010, LECT NOTES COMPUT SC, V6444, P152, DOI 10.1007/978-3-642-17534-3_19
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Jin YM, 2018, IEEE T MED IMAGING, V37, P1114, DOI 10.1109/TMI.2017.2787657
   Johnson JW., 2018, P 2019 COMP VIS C
   Kallenberg M, 2016, IEEE T MED IMAGING, V35, P1322, DOI 10.1109/TMI.2016.2532122
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044
   Kooi T, 2017, MED PHYS, V44, P1017, DOI 10.1002/mp.12110
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lan LB, 2019, IEEE ACCESS, V7, P30017, DOI 10.1109/ACCESS.2019.2901568
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee HG, 2013, COMPUT BIOL MED, V43, P670, DOI 10.1016/j.compbiomed.2013.02.009
   Lei HJ, 2018, PATTERN RECOGN, V79, P290, DOI 10.1016/j.patcog.2018.02.006
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Li Katherine M, 2018, ARXIV180708332
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu HY, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P102, DOI 10.1109/PACRIM.2011.6032875
   Liu JM, 2017, MED PHYS, V44, P4630, DOI 10.1002/mp.12399
   Long MZ, 2018, IEEE T BIOMED CIRC S, V12, P993, DOI 10.1109/TBCAS.2018.2869530
   Maghsoudi O. H., 2016, P IEEE SIGN PROC MED, P1
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Min SB, 2019, AAAI CONF ARTIF INTE, P4578, DOI 10.1609/aaai.v33i01.33014578
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Nie Dong, 2017, Med Image Comput Comput Assist Interv, V10435, P417, DOI 10.1007/978-3-319-66179-7_48
   Nie D, 2016, LECT NOTES COMPUT SC, V10008, P170, DOI 10.1007/978-3-319-46976-8_18
   Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P112, DOI 10.1145/3083187.3083189
   Radford A., 2015, COMPUTER SCI
   Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Redmon J, 2018, Arxiv
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romain O., 2013, IEEE 13 INT C BIOINF, P1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sa R, 2017, IEEE ENG MED BIO, P564, DOI 10.1109/EMBC.2017.8036887
   Sae Hwang, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P320, DOI 10.1007/978-3-642-24031-7_32
   Sarikaya D, 2017, IEEE T MED IMAGING, V36, P1542, DOI 10.1109/TMI.2017.2665671
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277
   Silva J, 2013, IEEE ENG MED BIO, P5711, DOI 10.1109/EMBC.2013.6610847
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv
   Singeap AM, 2016, WORLD J GASTROENTERO, V22, P369, DOI 10.3748/wjg.v22.i1.369
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tao GH, 2018, ADV NEUR IN, V31
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Van Gossum A, 2009, NEW ENGL J MED, V361, P264, DOI 10.1056/NEJMoa0806347
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang Jiangcong, 2018, WEAKLY SUPERVISED AD
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang YR, 2016, IEEE IMAGE PROC, P111, DOI 10.1109/ICIP.2016.7532329
   Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Xing Xiaohan, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P1, DOI 10.1109/EMBC.2018.8513012
   Yan Xu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P496, DOI 10.1007/978-3-319-46723-8_57
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   Yim S, 2014, IEEE T BIO-MED ENG, V61, P513, DOI 10.1109/TBME.2013.2283369
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
   Yuan L, 2014, RSC ADV, V4, P30259, DOI 10.1039/c4ra05012f
   Yuan YX, 2019, MED PHYS, V46, P756, DOI 10.1002/mp.13367
   Yuan YX, 2018, LECT NOTES COMPUT SC, V11071, P620, DOI 10.1007/978-3-030-00934-2_69
   Yuan YX, 2018, IEEE T CYBERNETICS, V48, P2074, DOI 10.1109/TCYB.2017.2726818
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Yuan YX, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P225, DOI 10.1109/ICMA.2013.6617922
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JK, 2016, INT SYM COMPUT INTEL, P363, DOI [10.1109/ISCID.2016.89, 10.1109/ISCID.2016.1090]
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang ZZ, 2018, PROC CVPR IEEE, P9242, DOI 10.1109/CVPR.2018.00963
   Zhang ZZ, 2017, PROC CVPR IEEE, P3549, DOI 10.1109/CVPR.2017.378
   Zhao Q, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P948, DOI 10.1109/WCICA.2011.5970656
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
NR 147
TC 27
Z9 27
U1 9
U2 51
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9219
EI 1558-2256
J9 P IEEE
JI Proc. IEEE
PD JAN
PY 2020
VL 108
IS 1
BP 178
EP 197
DI 10.1109/JPROC.2019.2950506
PG 20
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA KA4TS
UT WOS:000505790500010
DA 2023-04-20
ER

PT J
AU Khan, MA
   Kadry, S
   Alhaisoni, M
   Nam, Y
   Zhang, YD
   Rajinikanth, V
   Sarfraz, MS
AF Khan, Muhammad Attique
   Kadry, Seifedine
   Alhaisoni, Majed
   Nam, Yunyoung
   Zhang, Yudong
   Rajinikanth, Venkatesan
   Sarfraz, Muhammad Shahzad
TI Computer-Aided Gastrointestinal Diseases Analysis From Wireless Capsule
   Endoscopy: A Framework of Best Features Selection
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Stomach; Cancer; Image color analysis; Hemorrhaging;
   Support vector machines; Gastrointestinal tract; Stomach diseases; WCE;
   saliency estimation; deep learning; features selection; features
   classification
ID NEURAL-NETWORK; CLASSIFICATION; RECOGNITION; FUSION; IMAGES;
   SEGMENTATION; ALGORITHM
AB The continuous improvements in the area of medical imaging, makes the patient monitoring a crucial concern. The internet of things (IoT) embedded in a medical technologies to collect data from human body through sensors, wireless connectivity etc. The junction of medicine and IT like medical informatics will transform healthcare, curbing cost, make more efficient, and saving lives. Various computerized techniques are implemented in the area of Artificial Intelligence (AI) for the application of medical imaging to diagnose the infected regions in the images and videos such as WCE and pathology. The famous stomach infections are ulcer, polyp, and bleeding. Stomach cancer is the most common infection and a leading cause of human deaths worldwide. In the USA, since 2019, a total of 27,510 new cases are reported including 17,230 men and 10,230 women. While the number of deaths is 11,140 consists of 6,800 men and 4,340 women. The manual diagnosis of these stomach infections is a difficult and agitated process therefore it is required to design a fully automated system using AI. In this article, we presented a fully automated system for stomach infection recognition based on deep learning features fusion and selection. In this design, ulcer images are assigned manually and support to a saliency-based method for ulcer detection. Later, pre-trained deep learning model named VGG16 is employing and re-trained using transfer learning. Features of re-trained model are extracted from two consecutive fully connected layers and fused by array-based approach. Besides, the best individuals are selected through the metaheuristic approach name PSO along mean value-based fitness function. The selected individuals are finally recognized through Cubic SVM. The experiments are conducted on Private collected dataset and achieved an accuracy of 98.4%, which is best as compared to existing state-of-the-art techniques.
C1 [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.
   [Kadry, Seifedine] Beirut Arab Univ, Fac Sci, Dept Math & Comp Sci, Beirut 11072809, Lebanon.
   [Alhaisoni, Majed] Univ Hail, Coll Comp Sci & Engn, Hail 55476, Saudi Arabia.
   [Nam, Yunyoung] Soonchunhyang Univ, Dept Comp Sci & Engn, Asan 31538, South Korea.
   [Zhang, Yudong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
   [Rajinikanth, Venkatesan] St Josephs Coll Engn, Dept Elect & Instrumentat Engn, Chennai 600119, Tamil Nadu, India.
   [Sarfraz, Muhammad Shahzad] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Chiniot Faisalabad Campus, Islamabad 44000, Pakistan.
C3 NITEC University; Beirut Arab University; University Ha'il;
   Soonchunhyang University; University of Leicester; St. Joseph's College
   of Engineering, Chennai
RP Khan, MA (通讯作者)，HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.; Nam, Y (通讯作者)，Soonchunhyang Univ, Dept Comp Sci & Engn, Asan 31538, South Korea.
EM attique@ciitwah.edu.pk; ynam@sch.ac.kr
RI Kadry, Seifedine/C-7437-2011; Rajinikanth, V/X-9395-2018; VENKATESAN,
   RAJINIKANTH/F-6734-2011; khan, sajid/HGE-2406-2022; ALHAISONI,
   MAJED/ABF-7642-2021; Zhang, Yudong/I-7633-2013; Khan, Dr. Muhammad
   Attique/AAX-2644-2021
OI Kadry, Seifedine/0000-0002-1939-4842; Rajinikanth,
   V/0000-0003-3897-4460; VENKATESAN, RAJINIKANTH/0000-0003-3897-4460;
   Zhang, Yudong/0000-0002-4870-1493; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Nam, Yunyoung/0000-0002-3318-9394; Attique
   Khan, Muhammad/0000-0001-7058-0715
FU Korea Institute for Advancement of Technology (KIAT) - Korea Government
   (MOTIE) [P0012724]; Soonchunhyang University Research Fund
FX This research was supported by Korea Institute for Advancement of
   Technology (KIAT) grant funded by the Korea Government (MOTIE)
   (P0012724, The Competency Development Program for Industry Specialist)
   and the Soonchunhyang University Research Fund.
CR Agrawal T., 2017, P MEDIAEVAL 2017 MUL
   Anwar MZ, 2019, IEEE T VEH TECHNOL, V68, P2526, DOI 10.1109/TVT.2019.2893615
   Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Athi, 2019, TEXT FEAT EXTR GLDM
   Barbosa DJC, 2009, IEEE ENG MED BIO, P6683, DOI 10.1109/IEMBS.2009.5334013
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Charfi S, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P134
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P2355, DOI 10.1109/LGRS.2017.2764915
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Deeba F, 2018, BIOMED SIGNAL PROCES, V40, P415, DOI 10.1016/j.bspc.2017.10.011
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Ghatwary N, 2019, IEEE ACCESS, V7, P84374, DOI 10.1109/ACCESS.2019.2925585
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu Y, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P386, DOI 10.1109/ICISCE.2016.91
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MA, 2020, NEURAL COMPUT APPL, V32, P15929, DOI 10.1007/s00521-019-04514-0
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P909, DOI 10.1002/jemt.23238
   Khan MA, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105986
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, MULTIMED TOOLS APPL, V78, P27743, DOI 10.1007/s11042-019-07875-9
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Khan SA, 2019, MICROSC RES TECHNIQ, V82, P1256, DOI 10.1002/jemt.23275
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kundu AK, 2017, TENCON IEEE REGION, P1300
   Kwolek B, 2005, LECT NOTES COMPUT SC, V3696, P551, DOI 10.1007/11550822_86
   Lee JH, 2019, SURG ENDOSC, V33, P3790, DOI 10.1007/s00464-019-06677-2
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Mergener Klaus, 2008, Gastroenterol Hepatol (N Y), V4, P107
   Munzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Najarian, 2018, ARXIV PREPRINT ARXIV
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sharif M, 2021, J EXP THEOR ARTIF IN, V33, P577, DOI 10.1080/0952813X.2019.1572657
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Shi QQ, 2018, IEEE ACCESS, V6, P38656, DOI 10.1109/ACCESS.2018.2853620
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI 10.3322/caac.21395
   Simonyan K, 2015, Arxiv
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Xu GP, 2019, SWARM EVOL COMPUT, V45, P33, DOI 10.1016/j.swevo.2018.12.009
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
NR 55
TC 68
Z9 68
U1 4
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 132850
EP 132859
DI 10.1109/ACCESS.2020.3010448
PG 10
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MS6FU
UT WOS:000554370100001
OA gold
DA 2023-04-20
ER

PT J
AU Khan, MA
   Sarfraz, MS
   Alhaisoni, M
   Albesher, AA
   Wang, SH
   Ashraf, I
AF Khan, Muhammad Attique
   Sarfraz, Muhammad Shahzad
   Alhaisoni, Majed
   Albesher, Abdulaziz A.
   Wang, Shuihua
   Ashraf, Imran
TI StomachNet: Optimal Deep Learning Features Fusion for Stomach
   Abnormalities Classification
SO IEEE ACCESS
LA English
DT Article
DE Licenses; Stomach infections; contrast stretching; deep learning;
   optimization; fusion
ID WIRELESS CAPSULE ENDOSCOPY; GASTROINTESTINAL-DISEASES; ENHANCEMENT;
   CHALLENGES; IMAGES
AB A fully automated design is proposed in this work employing optimal deep learning features for classifying gastrointestinal infections. Here, three prominent infections- ulcer, bleeding, polyp and a healthy class are considered as class labels. In the initial stage, the contrast is improved by fusing bi-directional histogram equalization with top-hat filtering output. The resultant fusion images are then passed to ResNet101 pre-trained model and trained once again using deep transfer learning. However, there are challenges involved in extracting deep learning features including impertinent information and redundancy. To mitigate this problem, we took advantage of two metaheuristic algorithms- Enhanced Crow Search and Differential Evolution. These algorithms are implemented in parallel to obtain optimal feature vectors. Following this, a maximum correlation-based fusion approach is applied to fuse optimal vectors from the previous step to obtain an enhanced vector. This final vector is given as input to Extreme Learning Machine (ELM) classifier for final classification. The proposed method is evaluated on a combined database. It accomplished an accuracy of 99.46%, which shows significant improvement over preceding techniques and other neural network architectures.
C1 [Khan, Muhammad Attique; Ashraf, Imran] HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.
   [Sarfraz, Muhammad Shahzad] Natl Univ Comp & Emerging Sci Chiniot Faisalabad, Dept Comp Sci, Chiniot 35400, Pakistan.
   [Alhaisoni, Majed] Univ Hail, Coll Comp Sci & Engn, Hail 50141, Saudi Arabia.
   [Albesher, Abdulaziz A.] Saudi Elect Univ, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
   [Wang, Shuihua] Univ Leicester, Dept Math, Leicester LE1 7RH, Leics, England.
C3 NITEC University; University Ha'il; Saudi Electronic University;
   University of Leicester
RP Ashraf, I (通讯作者)，HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.; Albesher, AA (通讯作者)，Saudi Elect Univ, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
EM a.albesher@seu.edu.sa; imran.ashraf@hitecuni.edu.pk
RI ashraf, imran/HJA-5212-2022; ALHAISONI, MAJED/ABF-7642-2021; khan,
   sajid/HGE-2406-2022; Khan, Dr. Muhammad Attique/AAX-2644-2021; Wang,
   Shuihua/G-7326-2016
OI ashraf, imran/0000-0003-4480-2489; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Wang, Shuihua/0000-0003-4713-2791;
   albesher, abdulaziz/0000-0002-4879-9128; Attique Khan,
   Muhammad/0000-0001-7058-0715
CR Akram T., 2018, J AMB INTEL HUM COMP, P1, DOI [10.1007/s12652-018-1051-5, DOI 10.1007/S12652-018-1051-5]
   Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen F, 2020, PATTERN RECOGN LETT, V136, P309, DOI 10.1016/j.patrec.2020.04.033
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fireman Z, 2003, GUT, V52, P390, DOI 10.1136/gut.52.3.390
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Iandola FN, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1602.07360
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Khan M, 2021, MAG CONCRETE RES, V73, P487, DOI [10.1680/jmacr.19.00226, 10.1007/s11042-020-08806-9]
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2021, MICROSC RES TECHNIQ, V84, P202, DOI 10.1002/jemt.23578
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, MULTIMED TOOLS APPL, V78, P27743, DOI 10.1007/s11042-019-07875-9
   Khan SA, 2020, J MED IMAG HEALTH IN, V10, P2523, DOI 10.1166/jmihi.2020.3222
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kundu AK, 2020, IEEE ACCESS, V8, P58509, DOI 10.1109/ACCESS.2020.2982870
   Kuo CFJ, 2019, INT J IMAG SYST TECH, V29, P132, DOI 10.1002/ima.22307
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Little S. G., 2006, TECH REP
   Lu XX, 2020, NEW ENGL J MED, V382, P1663, DOI 10.1056/NEJMc2005073
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Mehmood I, 2019, MULTIMED TOOLS APPL, V78, P12723, DOI 10.1007/s11042-018-6027-0
   Muhammad K, 2020, FUTURE GENER COMP SY, V113, P266, DOI 10.1016/j.future.2020.06.048
   Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800
   Naheed N, 2020, CMES-COMP MODEL ENG, V125, P1, DOI 10.32604/cmes.2020.011380
   Ouadfel S, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113572
   Price K, 2006, DIFFERENTIAL EVOLUTI
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rehman A., MICROSC RES TECHNIQ
   Sharif M, 2021, J EXP THEOR ARTIF IN, V33, P577, DOI 10.1080/0952813X.2019.1572657
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI DOI 10.3322/caac.21387
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Torrey L, 2010, HDB RES MACHINE LEAR, P242, DOI 10.4018/978-1-60566-766-9.ch011
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
NR 43
TC 59
Z9 59
U1 3
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 197969
EP 197981
DI 10.1109/ACCESS.2020.3034217
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA OS7GJ
UT WOS:000590327700001
OA gold
DA 2023-04-20
ER

PT J
AU Le Berre, C
   Sandborn, WJ
   Aridhi, S
   Devignes, MD
   Fournier, L
   Smail-Tabbone, M
   Danese, S
   Peyrin-Biroulet, L
AF Le Berre, Catherine
   Sandborn, William J.
   Aridhi, Sabeur
   Devignes, Marie-Dominique
   Fournier, Laure
   Smail-Tabbone, Malika
   Danese, Silvio
   Peyrin-Biroulet, Laurent
TI Application of Artificial Intelligence to Gastroenterology and
   Hepatology
SO GASTROENTEROLOGY
LA English
DT Review
DE Deep Learning; Machine Learning; Neural Network; Digestive System
ID COMPUTER-AIDED DIAGNOSIS; HELICOBACTER-PYLORI INFECTION; CONVOLUTIONAL
   NEURAL-NETWORK; CAPSULE ENDOSCOPY IMAGES; COLORECTAL POLYPS; TEXTURE
   DESCRIPTORS; LEARNING ALGORITHM; PANCREATIC-CANCER; LESION DETECTION;
   CELIAC-DISEASE
AB Since 2010, substantial progress has been made in artificial intelligence (AI) and its application to medicine. AI is explored in gastroenterology for endoscopic analysis of lesions, in detection of cancer, and to facilitate the analysis of inflammatory lesions or gastrointestinal bleeding during wireless capsule endoscopy. AI is also tested to assess liver fibrosis and to differentiate patients with pancreatic cancer from those with pancreatitis. AI might also be used to establish prognoses of patients or predict their response to treatments, based on multiple factors. We review the ways in which AI may help physicians make a diagnosis or establish a prognosis and discuss its limitations, knowing that further randomized controlled studies will be required before the approval of AI techniques by the health authorities.
C1 [Le Berre, Catherine] Nantes Univ Hosp, Inst Malad Appareil Digestif, Nantes, France.
   [Le Berre, Catherine; Peyrin-Biroulet, Laurent] Univ Lorraine, INSERM, U954, Nancy Univ Hosp, Nancy, France.
   [Le Berre, Catherine; Peyrin-Biroulet, Laurent] Univ Lorraine, Nancy Univ Hosp, Dept Gastroenterol, 1 Allee Morvan, F-54511 Vandoeuvre Les Nancy, France.
   [Sandborn, William J.] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Aridhi, Sabeur; Devignes, Marie-Dominique; Smail-Tabbone, Malika] Univ Lorraine, CNRS, INRIA, Lab Lorrain Rech Informat & Ses Applicat, Nancy, France.
   [Fournier, Laure] Univ Paris 05, INSERM, Unite Mixte Rech S970, AP HP, Paris, France.
   [Danese, Silvio] Humanitas Univ, Humanitas Clin & Res Ctr, Inflammatory Bowel Dis Ctr, Milan, Italy.
   [Danese, Silvio] Humanitas Univ, Humanitas Clin & Res Ctr, Dept Biomed Sci, Milan, Italy.
C3 Nantes Universite; CHU de Nantes; CHU de Nancy; Institut National de la
   Sante et de la Recherche Medicale (Inserm); Universite de Lorraine; CHU
   de Nancy; Universite de Lorraine; University of California System;
   University of California San Diego; Centre National de la Recherche
   Scientifique (CNRS); Inria; Universite de Lorraine; Assistance Publique
   Hopitaux Paris (APHP); Institut National de la Sante et de la Recherche
   Medicale (Inserm); UDICE-French Research Universities; Universite Paris
   Cite; Humanitas University; Humanitas University
RP Peyrin-Biroulet, L (通讯作者)，Univ Lorraine, Nancy Univ Hosp, Dept Gastroenterol, 1 Allee Morvan, F-54511 Vandoeuvre Les Nancy, France.; Peyrin-Biroulet, L (通讯作者)，Univ Lorraine, INSERM, U1256, NGERE, 1 Allee Morvan, F-54511 Vandoeuvre Les Nancy, France.
EM peyrinbiroulet@gmail.com
RI Danese, Silvio/ABH-9571-2020; Devignes, Marie-Dominique/AAI-4554-2020;
   Fournier, Laure/HJI-9361-2023; Sandborn, William/ABE-8342-2020
OI Danese, Silvio/0000-0001-7341-1351; Devignes,
   Marie-Dominique/0000-0002-0399-8713; Fournier,
   Laure/0000-0002-1878-0290; peyrin-biroulet, laurent/0000-0003-2536-6618;
   Le Berre, Catherine/0000-0002-1124-2019
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Ai LY, 2017, ONCOTARGET, V8, P9546, DOI 10.18632/oncotarget.14488
   Ali H, 2018, COMPUT METH PROG BIO, V157, P39, DOI 10.1016/j.cmpb.2018.01.013
   Ananthakrishnan AN, 2017, CELL HOST MICROBE, V21, P603, DOI 10.1016/j.chom.2017.04.010
   Ayaru L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132485
   Banerjee R, 2003, J GASTROEN HEPATOL, V18, P1054, DOI 10.1046/j.1440-1746.2003.03123.x
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bibault JE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30657-6
   Biglarian A, 2012, ASIAN PAC J CANCER P, V13, P927, DOI 10.7314/APJCP.2012.13.3.927
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Briceno J, 2014, J HEPATOL, V61, P1020, DOI 10.1016/j.jhep.2014.05.039
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Charisis VS, 2016, WORLD J GASTROENTERO, V22, P8641, DOI 10.3748/wjg.v22.i39.8641
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chen Y, 2012, P 20 ACM INT C MULT, P1181, DOI DOI 10.1145/2393347.2396413
   Chen Y, 2017, COMPUT BIOL MED, V89, P18, DOI 10.1016/j.compbiomed.2017.07.012
   Ciaccio EJ, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-44
   Colom Roberto, 2010, Dialogues Clin Neurosci, V12, P489
   Constantinescu AF, 2016, ROM J MORPHOL EMBRYO, V57, P979
   Cui L, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P3088, DOI 10.1109/WCICA.2010.5554005
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036
   Das A, 2008, GASTROENTEROLOGY, V134, P65, DOI 10.1053/j.gastro.2007.10.037
   David E., 2013, INTERNALIZED OPPRESS, P1
   Dinevari VF, 2016, APPL BIONICS BIOMECH, V2016, DOI 10.1155/2016/3678913
   Dong TS, 2019, CLIN GASTROENTEROL H, V17, P1894, DOI 10.1016/j.cgh.2019.01.025
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Fialoke Suruchi, 2018, AMIA Annu Symp Proc, V2018, P430
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Gadermayr M, 2016, WORLD J GASTROENTERO, V22, P7124, DOI 10.3748/wjg.v22.i31.7124
   Gatos I, 2017, ULTRASOUND MED BIOL, V43, P1797, DOI 10.1016/j.ultrasmedbio.2017.05.002
   Ghosh T, 2014, IEEE ENG MED BIO, P4683, DOI 10.1109/EMBC.2014.6944669
   Girgis HZ, 2010, I S BIOMED IMAGING, P1373, DOI 10.1109/ISBI.2010.5490253
   Gohari MR, 2011, ASIAN PAC J CANCER P, V12, P1469
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hafner M, 2010, IEEE T INF TECHNOL B, V14, P958, DOI 10.1109/TITB.2010.2044184
   Hashem S, 2018, IEEE ACM T COMPUT BI, V15, P861, DOI 10.1109/TCBB.2017.2690848
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Heida A, 2017, CLIN GASTROENTEROL H, V15, P1742, DOI 10.1016/j.cgh.2017.06.007
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hong WD, 2013, CLINICS, V68, P27, DOI 10.6061/clinics/2013(01)RC01
   Hong WD, 2011, HEPAT MON, V11, P544
   Hoogendoorn M, 2016, ARTIF INTELL MED, V69, P53, DOI 10.1016/j.artmed.2016.03.003
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Hujoel IA, 2018, CLIN GASTROENTEROL H, V16, P1354, DOI 10.1016/j.cgh.2017.12.022
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Japkowicz N., 2011, EVALUATING LEARNING, DOI [DOI 10.1017/CBO9780511921803, 10.1017/CBO9780511921803]
   Jebarani WSL, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P303, DOI 10.1109/ICSIPR.2013.6497945
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Jovanovic P, 2014, GASTROINTEST ENDOSC, V80, P260, DOI 10.1016/j.gie.2014.01.023
   Jung YS, 2009, P SOC PHOTO-OPT INS
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Karargyris A, 2009, I S BIOMED IMAGING, P554, DOI 10.1109/ISBI.2009.5193107
   Khosravi B, 2015, HEPAT MON, V15, DOI 10.5812/hepatmon.25164
   Kinar Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171759
   Klein A, 2017, UNITED EUR GASTROENT, V5, P694, DOI 10.1177/2050640616676435
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Konerman MA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187344
   Konerman MA, 2015, HEPATOLOGY, V61, P1832, DOI 10.1002/hep.27750
   Kop R, 2016, COMPUT BIOL MED, V76, P30, DOI 10.1016/j.compbiomed.2016.06.019
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Lee JY, 2018, J ADV NURS, V74, P2094, DOI 10.1111/jan.13711
   Lee JH, 2019, SURG ENDOSC, V33, P3790, DOI 10.1007/s00464-019-06677-2
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li BP, 2009, IEEE ENG MED BIO, P3731, DOI 10.1109/IEMBS.2009.5334875
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   Lv GL, 2011, IEEE ENG MED BIO, P6643, DOI 10.1109/IEMBS.2011.6091638
   Ma H, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/4304376
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mossotto E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02606-2
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Nilsaz-Dezfouli H, 2017, CANCER INFORM, V16, DOI 10.1177/1176935116686062
   Ogawa R, 2019, J GASTROINTEST CANC, V50, P386, DOI 10.1007/s12029-018-0083-6
   Ozkan M, 2016, ENDOSC ULTRASOUND, V5, P101, DOI 10.4103/2303-9027.180473
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Pearce CB, 2006, PANCREATOLOGY, V6, P123, DOI 10.1159/000090032
   Peng JH, 2016, ONCOTARGET, V7, P22939, DOI 10.18632/oncotarget.8217
   Peng JC, 2015, INT J COLORECTAL DIS, V30, P1267, DOI 10.1007/s00384-015-2250-6
   Piscaglia F, 2006, EUR J GASTROEN HEPAT, V18, P1255, DOI 10.1097/01.meg.0000243885.55562.7e
   Raoufy MR, 2011, J MED SYST, V35, P121, DOI 10.1007/s10916-009-9348-8
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Riaz F, 2013, IEEE ENG MED BIO, P3714, DOI 10.1109/EMBC.2013.6610350
   Riaz F, 2012, IEEE T BIO-MED ENG, V59, P2893, DOI 10.1109/TBME.2012.2212440
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Romain O., 2013, IEEE 13 INT C BIOINF, P1
   Ruffle JK, 2019, AM J GASTROENTEROL, V114, P422, DOI 10.1038/s41395-018-0268-4
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russell Stuart, 2002, ARTIF INTELL
   Saftoiu A, 2015, GASTROINTEST ENDOSC, V82, P59, DOI 10.1016/j.gie.2014.11.040
   Saftoiu A, 2012, CLIN GASTROENTEROL H, V10, P84, DOI 10.1016/j.cgh.2011.09.014
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sakai Y, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P4138, DOI 10.1109/EMBC.2018.8513274
   Sengupta N, 2017, AM J MED, V130, DOI 10.1016/j.amjmed.2016.12.009
   Shalev-Shwartz S, 2014, UNDERSTANDING MACHIN, DOI 10.1017/CBO9781107298019
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Sowa JP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101444
   Sowa JP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062439
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Takayama T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0131197
   Takayama T, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027223
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Tenorio JM, 2011, INT J MED INFORM, V80, P793, DOI 10.1016/j.ijmedinf.2011.08.001
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Usman MA, 2016, COMPUT MED IMAG GRAP, V54, P16, DOI 10.1016/j.compmedimag.2016.09.005
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Waljee AK, 2018, ALIMENT PHARM THER, V47, P763, DOI 10.1111/apt.14510
   Waljee AK, 2018, INFLAMM BOWEL DIS, V24, P45, DOI 10.1093/ibd/izx007
   Waljee AK, 2017, J CROHNS COLITIS, V11, P801, DOI 10.1093/ecco-jcc/jjx014
   Waljee AK, 2010, CLIN GASTROENTEROL H, V8, P143, DOI 10.1016/j.cgh.2009.09.031
   Wang DN, 2010, BMC INFECT DIS, V10, DOI 10.1186/1471-2334-10-251
   Wang K, 2019, GUT, V68, P729, DOI 10.1136/gutjnl-2018-316204
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wei RM, 2018, EBIOMEDICINE, V35, P124, DOI 10.1016/j.ebiom.2018.07.041
   Wei Z, 2013, AM J HUM GENET, V92, P1008, DOI 10.1016/j.ajhg.2013.05.002
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Wu CC, 2019, COMPUT METH PROG BIO, V170, P23, DOI 10.1016/j.cmpb.2018.12.032
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Yang YC, 2014, CHINESE MED J-PEKING, V127, P1891, DOI 10.3760/cma.j.issn.0366-6999.20133101
   Yip TCF, 2017, ALIMENT PHARM THER, V46, P447, DOI 10.1111/apt.14172
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang B., 2016, GENET MOL RES, V15, P01, DOI DOI 10.4238/GMR.15028643
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu ML, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063820
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 149
TC 189
Z9 190
U1 50
U2 190
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD JAN
PY 2020
VL 158
IS 1
BP 76
EP +
DI 10.1053/j.gastro.2019.08.058
PG 21
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA JV7NZ
UT WOS:000502549500029
PM 31593701
OA Green Published, Bronze
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Lee, C
   Shin, D
   Min, J
   Cha, J
   Lee, S
AF Lee, Changhoo
   Shin, Dongwook
   Min, Junki
   Cha, Jaemyung
   Lee, Seungkyu
TI Decision Boundary Re-Sampling in Imbalanced Learning for Ulcer Detection
SO IEEE ACCESS
LA English
DT Article
DE Distributed Bragg reflectors; Training; Lesions; Machine learning;
   Endoscopes; Training data; Convolutional neural networks; Decision
   boundary re-sampling; convolutional neural network; ulcer classification
ID POLYP DETECTION; SMOTE
AB Data imbalance problem between normal and lesion endoscopy images makes it difficult to employ deep learning approaches in automatic Ulcer detection and classification. Due to the large variety of normal images in their appearance, characterizing ulcer with limited training samples is not a trivial task. In this work, we propose decision boundary re-sampling (DBR) in imbalanced learning that extrapolates ulcer samples in a latent space of deep convolutional neural network. Proposed method shows improved ulcer classification performance on wireless endoscopy images compared to state-of-the-art methods.
C1 [Lee, Changhoo; Shin, Dongwook; Lee, Seungkyu] Kyung Hee Univ, Dept Comp Sci & Engn, Yongin, South Korea.
   [Min, Junki; Cha, Jaemyung] Kyung Hee Univ, Dept Internal Med, Seoul 17104, South Korea.
C3 Kyung Hee University; Kyung Hee University
RP Lee, S (通讯作者)，Kyung Hee Univ, Dept Comp Sci & Engn, Yongin, South Korea.
EM seungkyu@khu.ac.kr
FU Kyung Hee University [KHU-20181044]
FX This work was supported by Kyung Hee University, in 2018, under Grant
   KHU-20181044.
CR Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   Hovde O, 2018, P BRIT MACH VIS C 20
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Kumar R, 2009, I S BIOMED IMAGING, P1314, DOI 10.1109/ISBI.2009.5193306
   Lee C, 2019, I S BIOMED IMAGING, P100, DOI 10.1109/ISBI.2019.8759101
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Qu HN, 2010, PATTERN RECOGN, V43, P3448, DOI 10.1016/j.patcog.2010.05.002
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
NR 17
TC 0
Z9 0
U1 2
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 186274
EP 186278
DI 10.1109/ACCESS.2020.3029259
PG 5
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA OI9DM
UT WOS:000583569900001
OA gold
DA 2023-04-20
ER

PT J
AU Li, L
   Chen, YS
   Shen, Z
   Zhang, XQ
   Sang, JZ
   Ding, Y
   Yang, XY
   Li, J
   Chen, M
   Jin, CH
   Chen, CL
   Yu, CH
AF Li, Lan
   Chen, Yishu
   Shen, Zhe
   Zhang, Xuequn
   Sang, Jianzhong
   Ding, Yong
   Yang, Xiaoyun
   Li, Jun
   Chen, Ming
   Jin, Chaohui
   Chen, Chunlei
   Yu, Chaohui
TI Convolutional neural network for the diagnosis of early gastric cancer
   based on magnifying narrow band imaging
SO GASTRIC CANCER
LA English
DT Article
DE Magnifying endoscopy; Narrow band imaging; Convolutional neural network;
   Early gastric cancer
ID ARTIFICIAL-INTELLIGENCE; ENDOSCOPY
AB Background Magnifying endoscopy with narrow band imaging (M-NBI) has been applied to examine early gastric cancer by observing microvascular architecture and microsurface structure of gastric mucosal lesions. However, the diagnostic efficacy of non-experts in differentiating early gastric cancer from non-cancerous lesions by M-NBI remained far from satisfactory. In this study, we developed a new system based on convolutional neural network (CNN) to analyze gastric mucosal lesions observed by M-NBI. Methods A total of 386 images of non-cancerous lesions and 1702 images of early gastric cancer were collected to train and establish a CNN model (Inception-v3). Then a total of 341 endoscopic images (171 non-cancerous lesions and 170 early gastric cancer) were selected to evaluate the diagnostic capabilities of CNN and endoscopists. Primary outcome measures included diagnostic accuracy, sensitivity, specificity, positive predictive value, and negative predictive value. Results The sensitivity, specificity, and accuracy of CNN system in the diagnosis of early gastric cancer were 91.18%, 90.64%, and 90.91%, respectively. No significant difference was spotted in the specificity and accuracy of diagnosis between CNN and experts. However, the diagnostic sensitivity of CNN was significantly higher than that of the experts. Furthermore, the diagnostic sensitivity, specificity and accuracy of CNN were significantly higher than those of the non-experts. Conclusions Our CNN system showed high accuracy, sensitivity and specificity in the diagnosis of early gastric cancer. It is anticipated that more progress will be made in optimization of the CNN diagnostic system and further development of artificial intelligence in the medical field.
C1 [Li, Lan; Chen, Yishu; Shen, Zhe; Zhang, Xuequn; Yu, Chaohui] Zhejiang Univ, Coll Med, Affiliated Hosp 1, Dept Gastroenterol, 79 Qingchun Rd, Hangzhou 310003, Zhejiang, Peoples R China.
   [Sang, Jianzhong] Yuyao Peoples Hosp, Dept Gastroenterol, Yuyao, Peoples R China.
   [Ding, Yong] Ningbo Univ, Sch Med, Affiliated Hosp, Dept Gastroenterol, Ningbo, Peoples R China.
   [Yang, Xiaoyun] Zhejiang Univ, Jinhua Hosp, Sch Med, Dept Gastroenterol, Jinhua, Zhejiang, Peoples R China.
   [Li, Jun] Zhejiang Univ, Coll Med, Dept Pathol, Affiliated Hosp 1, Hangzhou, Peoples R China.
   [Chen, Ming; Jin, Chaohui] Hithink RoyalFlush Informat Network Co Ltd, Hangzhou, Peoples R China.
   [Chen, Chunlei] Zhejiang Univ, State Key Lab Diag & Treatment Infect Dis, Collaborat Innovat Ctr Diag & Treatment Infect Di, Affiliated Hosp 1,Coll Med, Hangzhou, Peoples R China.
C3 Zhejiang University; Ningbo University; Zhejiang University; Zhejiang
   University; Collaborative Innovation Center for Diagnosis & Treatment of
   Infectious Diseases; Zhejiang University
RP Yu, CH (通讯作者)，Zhejiang Univ, Coll Med, Affiliated Hosp 1, Dept Gastroenterol, 79 Qingchun Rd, Hangzhou 310003, Zhejiang, Peoples R China.
EM zyyyych@zju.edu.cn
CR Abdelhafiz D, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2823-4
   Brinker TJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0218713
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Das N, 2018, CURR OPIN PULM MED, V24, P117, DOI 10.1097/MCP.0000000000000459
   Dixon MF, 2002, GUT, V51, P130, DOI 10.1136/gut.51.1.130
   Ezoe Y, 2011, GASTROENTEROLOGY, V141, P2017, DOI 10.1053/j.gastro.2011.08.007
   Fitkov-Norris E, 2013, COMM COM INF SC, V383, P213
   Fujishiro M, 2017, GASTRIC CANCER, V20, pS39, DOI 10.1007/s10120-016-0647-8
   Hu YY, 2015, WORLD J GASTROENTERO, V21, P7884, DOI 10.3748/wjg.v21.i25.7884
   Huang YC, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00509
   Japanese Gastric Canc Assoc, 2011, GASTRIC CANCER, V14, P101, DOI 10.1007/s10120-011-0041-5
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Kadowaki S, 2009, J GASTROEN HEPATOL, V24, P1625, DOI 10.1111/j.1440-1746.2009.05918.x
   Kaise M, 2009, ENDOSCOPY, V41, P310, DOI 10.1055/s-0028-1119639
   Kao YC, 2019, GASTRIC CANCER, V22, P255, DOI 10.1007/s10120-018-0860-8
   Kato M, 2010, GASTROINTEST ENDOSC, V72, P523, DOI 10.1016/j.gie.2010.04.041
   Li B, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1346-x
   Li HY, 2012, GASTROINTEST ENDOSC, V76, P1124, DOI 10.1016/j.gie.2012.08.015
   Lv XH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123832
   Maki S, 2013, GASTRIC CANCER, V16, P140, DOI 10.1007/s10120-012-0160-7
   Muto M, 2016, DIGEST ENDOSC, V28, P379, DOI 10.1111/den.12638
   Pimentel-Nunes P, 2012, ENDOSCOPY, V44, P236, DOI 10.1055/s-0031-1291537
   Pimentel-Nunes P, 2016, ENDOSCOPY, V48, P723, DOI 10.1055/s-0042-108435
   Shibagaki K, 2016, ENDOSCOPY, V48, P16, DOI 10.1055/s-0034-1392542
   Shichijo S, 2016, GASTROINTEST ENDOSC, V84, P618, DOI 10.1016/j.gie.2016.03.791
   Spence AD, 2017, BMC GASTROENTEROL, V17, DOI 10.1186/s12876-017-0708-4
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   Verlato G, 2015, WORLD J GASTROENTERO, V21, P6434, DOI 10.3748/wjg.v21.i21.6434
   White JR, 2018, SCAND J GASTROENTERO, V53, P1611, DOI 10.1080/00365521.2018.1542455
   Yamada S, 2014, GASTROINTEST ENDOSC, V79, P55, DOI 10.1016/j.gie.2013.07.008
   Yao K, 2009, ENDOSCOPY, V41, P462, DOI 10.1055/s-0029-1214594
   Yao K, 2015, CLIN ENDOSC, V48, P481, DOI 10.5946/ce.2015.48.6.481
   Zhang Q, 2016, GASTRIC CANCER, V19, P543, DOI 10.1007/s10120-015-0500-5
NR 34
TC 96
Z9 106
U1 7
U2 44
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1436-3291
EI 1436-3305
J9 GASTRIC CANCER
JI Gastric Cancer
PD JAN
PY 2020
VL 23
IS 1
BP 126
EP 132
DI 10.1007/s10120-019-00992-2
PG 7
WC Oncology; Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology; Gastroenterology & Hepatology
GA KJ0QV
UT WOS:000511763600015
PM 31332619
OA hybrid, Green Published
DA 2023-04-20
ER

PT J
AU Liaqat, A
   Khan, MA
   Sharif, M
   Mittal, M
   Saba, T
   Manic, KS
   Al Attar, FNH
AF Liaqat, Amna
   Khan, Muhammad Attique
   Sharif, Muhammad
   Mittal, Mamta
   Saba, Tanzila
   Manic, K. Suresh
   Al Attar, Feras Nadhim Hasoon
TI Gastric Tract Infections Detection and Classification from Wireless
   Capsule Endoscopy using Computer Vision Techniques: A Review
SO CURRENT MEDICAL IMAGING
LA English
DT Review
DE Wireless capsule endoscopy; preprocessing techniques; feature-based
   techniques; segmentation techniques; classification; future trends
ID BLEEDING DETECTION; IMAGE SEGMENTATION; FEATURES SELECTION; POLYP
   DETECTION; RECOGNITION; ENTROPY; TEXTURE; SYSTEM; DISEASES; FUSION
AB Recent facts and figures published in various studies in the US show that approximately 27,510 new cases of gastric infections are diagnosed. Furthermore, it has also been reported that the mortality rate is quite high in diagnosed cases. The early detection of these infections can save precious human lives. As the manual process of these infections is time-consuming and expensive, therefore automated Computer-Aided Diagnosis (CAD) systems are required which helps the endoscopy specialists in their clinics. Generally, an automated method of gastric infection detections using Wireless Capsule Endoscopy (WCE) is comprised of the following steps such as contrast pre-processing, feature extraction, segmentation of infected regions, and classification into their relevant categories. These steps consist of various challenges that reduce the detection and recognition accuracy as well as increase the computation time. In this review, authors have focused on the importance of WCE in medical imaging, the role of endoscopy for bleeding-related infections, and the scope of endoscopy. Further, the general steps and highlighting the importance of each step have been presented. A detailed discussion and future directions have been provided at the end.
C1 [Liaqat, Amna; Sharif, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Wah Cantt, Pakistan.
   [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci, Taxila, Pakistan.
   [Mittal, Mamta] GB Pant Govt Engn Coll, Dept Comp Sci & Engn, New Delhi, India.
   [Saba, Tanzila] Prince Sultan Univ, Dept Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Manic, K. Suresh; Al Attar, Feras Nadhim Hasoon] Natl Univ Sci & Technol, Dept Elect & Comp Engn, Muscat, Oman.
C3 COMSATS University Islamabad (CUI); NITEC University; Prince Sultan
   University; National University of Science & Technology, Oman
RP Manic, KS (通讯作者)，Natl Univ Sci & Technol, Dept Elect & Comp Engn, Muscat, Oman.
EM sureshmanic@nu.edu.om
RI Mittal, Mamta/AAC-2229-2020; khan, sajid/HGE-2406-2022; kesavan, suresh
   manic/AAT-6437-2020; Saba, Tanzila/D-4593-2018; Sharif,
   Muhammad/ACD-2598-2022; Khan, Dr. Muhammad Attique/AAX-2644-2021; Manic,
   K./AAX-5786-2021; Sharif, Muhammad/AAB-8376-2022
OI Mittal, Mamta/0000-0003-0490-4413; kesavan, suresh
   manic/0000-0002-7184-6084; Saba, Tanzila/0000-0003-3138-3801; Sharif,
   Muhammad/0000-0002-7258-8400; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Sharif, Muhammad/0000-0002-1355-2168
CR Abouelenien M., 2013, AM J SCI ENG, V2, P24
   Abuzneid AA., 2010, ARXIV10055439
   ACHANTA R, INT C COMP VIS SYST, P66, DOI DOI 10.1007/978-3-540-79547-6_7
   Acharya UR, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1428-9
   Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Afza F, 2019, MICROSC RES TECHNIQ, V82, P1471, DOI 10.1002/jemt.23301
   Akram T., 2018, J AMBIENT INTELL HUM, P1, DOI DOI 10.1007/S12652-018-1051-5
   Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Ali H, 2017, COMPUT BIOL MED, V88, P84, DOI 10.1016/j.compbiomed.2017.07.002
   Allied, 2019, TECHN TRENDS DRIV CA
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Aurangzeb K, 2019, J MED IMAG HEALTH IN, V9, P662, DOI 10.1166/jmihi.2019.2611
   Balasubramanian K, 2018, J MED IMAG HEALTH IN, V8, P1598, DOI 10.1166/jmihi.2018.2504
   Barbosa DJC, 2009, IEEE ENG MED BIO, P6683, DOI 10.1109/IEMBS.2009.5334013
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Bhavani R. R., 2018, International Journal of Computers and Applications, V40, P88, DOI 10.1080/1206212X.2017.1395108
   Bourbakis N, 2005, BIBE 2005: 5th IEEE Symposium on Bioinformatics and Bioengineering, P324
   Buscaglia JM, 2008, CLIN GASTROENTEROL H, V6, P298, DOI 10.1016/j.cgh.2007.12.029
   Charfi S, 2019, IET IMAGE PROCESS, V13, P1023, DOI 10.1049/iet-ipr.2018.6232
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Chee Khun Poh, 2010, 2010 IEEE Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM 2010), P76, DOI 10.1109/ICCIS.2010.5518576
   Chen Y, 2012, P 20 ACM INT C MULT, P1181, DOI DOI 10.1145/2393347.2396413
   Cheng DC, 2008, LECT NOTES ARTIF INT, V5108, P62, DOI 10.1007/978-3-540-70715-8_6
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Hwang CL, 2006, IEEE SYS MAN CYBERN, P2006, DOI 10.1109/ICSMC.2006.385025
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Dassopoulos T, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P117, DOI 10.1109/BHI.2017.7897219
   Dey, 2018, P 2 INT C SCI 2018, V2, P23, DOI [10.1007/978-981-13-1927-3_3, DOI 10.1007/978-981-13-1927-3_3]
   Dey N, 2019, BIOCYBERN BIOMED ENG, V39, P843, DOI 10.1016/j.bbe.2019.07.005
   Dey N, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020051
   Dilna C, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING AND NETWORK COMMUNICATIONS (COCONET), P854, DOI 10.1109/CoCoNet.2015.7411289
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Ell C, 2002, ENDOSCOPY, V34, P685, DOI 10.1055/s-2002-33446
   Eskandari H., 2012, 2012 19th Iranian Conference of Biomedical Engineering (ICBME 2012). Proceedings, P305, DOI 10.1109/ICBME.2012.6519699
   Estrela V. V., 2018, MED TECHNOL J, V2, P262
   Estrela V. V., 2019, MED TECHNOL J, V3, P421, DOI [10.26415/2572-004X-vol3iss3p421-429, DOI 10.26415/2572-004X-VOL3ISS3P421-429]
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fernandes SL, 2020, NEURAL COMPUT APPL, V32, P15897, DOI 10.1007/s00521-019-04369-5
   Fernandes SL, 2019, IEEE CONSUM ELECTR M, V8, P31, DOI 10.1109/MCE.2019.2923926
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Guo G, 2011, 2011 IEEE 54 INT MID, P1, DOI [10.1109/MWSCAS.2011.6026527, DOI 10.1109/MWSCAS.2011.6026527]
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Hemmat Esfe M, 2015, INT COMMUN HEAT MASS, V68, P50, DOI 10.1016/j.icheatmasstransfer.2015.06.013
   Hussain H, 2000, GASTROENTEROL CLIN N, V29, P445, DOI 10.1016/S0889-8553(05)70122-9
   Hwang S, 2007, PROC SPIE, V6514, DOI 10.1117/12.709835
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Jadhav ST, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P264, DOI 10.1109/ECS.2015.7124905
   Jalil UMA, 2012, INT C STAT SCI BUS E, P1, DOI [10.1109/ICSSBE.2012.6396580, DOI 10.1109/ICSSBE.2012.6396580]
   Kalpathy-Cramer J, 2009, CLASSIFICATION RETRI
   Karargyris A, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P143, DOI 10.1109/LISSA.2009.4906730
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karargyris A, 2009, I S BIOMED IMAGING, P554, DOI 10.1109/ISBI.2009.5193107
   Katz L B, 1999, Semin Gastrointest Dis, V10, P78
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MA, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4465-8
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P909, DOI 10.1002/jemt.23238
   Khan MA, 2020, EMERG MARK FINANC TR, V56, P3829, DOI 10.1080/1540496X.2019.1588725
   Khan MA, 2020, IET IMAGE PROCESS, V14, P818, DOI 10.1049/iet-ipr.2018.5769
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P741, DOI 10.1002/jemt.23220
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Khan MA, 2018, IET IMAGE PROCESS, V12, P200, DOI 10.1049/iet-ipr.2017.0368
   Khan SA, 2019, MICROSC RES TECHNIQ, V82, P1256, DOI 10.1002/jemt.23275
   Khun PC, 2009, 2009 INTERNATIONAL CONFERENCE ON BIOMEDICAL AND PHARMACEUTICAL ENGINEERING, P39
   Kundu AK, 2015, 2015 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (WIECON-ECE), P455, DOI 10.1109/WIECON-ECE.2015.7443966
   Lee YG., 2011, WORLD ACAD SCI ENG T, V59, P2526
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P498, DOI 10.1109/IROS.2009.5354726
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Lin H, 2020, FIREFLY ALGORITHM BA, P221, DOI [10.1007/978-981-15-0306-1_10, DOI 10.1007/978-981-15-0306-1_10]
   Liu DD, 2012, IEEE ENG MED BIO, P73, DOI 10.1109/EMBC.2012.6345874
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   Loschi HJ, 2018, P 4 BRAZ TECHN S, P633, DOI [10.1007/978-3-030-16053-1_62, DOI 10.1007/978-3-030-16053-1_62]
   Lv GL, 2011, IEEE ENG MED BIO, P6643, DOI 10.1109/IEMBS.2011.6091638
   Ma, 2015 IEEE WORKSH SIG, P1, DOI [10.1109/SiPS.2015.7345001, DOI 10.1109/SIPS.2015.7345001]
   Ma JW, 2013, INT SYM MED INFORM, P56, DOI 10.1109/ISMICT.2013.6521699
   Ma L, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000014158
   Mackiewicz, 2011, CAPSULE ENDOSCOPYSTA, P978
   Mackiewicz, 2011, CAPSULE ENDOSCOPY ST, DOI [10.5772/23145, DOI 10.5772/23145]
   Mackiewicz M, 2008, PROC SPIE, V6914, DOI 10.1117/12.770510
   Maghsoudi O. H., 2016, PROC IEEE SIGNAL PRO, P1
   Mathew M, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1730, DOI 10.1109/ECS.2015.7124882
   Mughal B, 2017, EUR PHYS J PLUS, V132, DOI 10.1140/epjp/i2017-11523-8
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Nazar U, 2020, CURR MED IMAGING, V16, P823, DOI 10.2174/1573405615666191120110855
   Nazir M, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P434
   Niu YZ, 2018, IEEE ACCESS, V6, P56170, DOI 10.1109/ACCESS.2018.2873022
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Penna B, 2009 17 EUR SIGN PRO, P1864
   Qureshi WA, 2004, NAT REV DRUG DISCOV, V3, P447, DOI 10.1038/nrd1385
   Raja, 2020, EXAMINATION RETINAL, P177
   Raja N. S. M., 2018, J AMB INTEL HUM COMP, V1, P1, DOI [10.1007/s12652-018-0854-8, DOI 10.1007/S12652-018-0854-8]
   Raja NSM, 2017, J MED IMAG HEALTH IN, V7, P1825, DOI 10.1166/jmihi.2017.2267
   Raja NSM, 2014, MOD SIMUL ENG, V2014, DOI 10.1155/2014/794574
   Rajinikanth V, 2018, ARAB J SCI ENG, V43, P4365, DOI 10.1007/s13369-017-3053-6
   Rajinikanth V, 2018, FUTURE GENER COMP SY, V85, P160, DOI 10.1016/j.future.2018.03.025
   Rajinikanth V, 2017, J MED IMAG HEALTH IN, V7, P1837, DOI 10.1166/jmihi.2017.2265
   Rajinikanth V., 2018, 2nd International Conference on Micro-Electronics, Electromagnetics and Telecommunications, ICMEET 2016. Proceedings: LNEE 434, P313, DOI 10.1007/978-981-10-4280-5_33
   Rajinikanth V, 2017, PATTERN RECOGN LETT, V94, P87, DOI 10.1016/j.patrec.2017.05.028
   Rajinikanth V, 2015, PROCEDIA COMPUT SCI, V46, P1449, DOI 10.1016/j.procs.2015.02.064
   Rajivegandhi C, 2015, 2015 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Rashid M., 2018, MULTIMEDIA TOOLS APP, P1
   Raza M, 2018, FUTURE GENER COMP SY, V88, P28, DOI 10.1016/j.future.2018.05.002
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Sae Hwang, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P320, DOI 10.1007/978-3-642-24031-7_32
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sainju S, 2013, CAN CON EL COMP EN, P539
   Salehpour P, 2016, BIOMED ENG-APP BAS C, V28, DOI 10.4015/S1016237216500290
   Satapathy SC, 2018, J OPTIM, V2018, DOI 10.1155/2018/3738049
   Shakeel PM, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0054-0
   Sharif M, 2020, J ORGAN END USER COM, V32, P67, DOI 10.4018/JOEUC.2020040104
   Sharif M, 2021, J EXP THEOR ARTIF IN, V33, P577, DOI 10.1080/0952813X.2019.1572657
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Sharif N, 2018, J OCUL PHARMACOL TH, V34, P1, DOI 10.1089/jop.2017.29037.int
   Siddiqui S, 2018, INT J APPL PATTERN R, V5, P206, DOI 10.1504/IJAPR.2018.094815
   Signorelli C, 2005, ENDOSCOPY, V37, P1170, DOI 10.1055/s-2005-870410
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Thivya Roopini I., 2018, Computational Signal Processing and Analysis. Select Proceedings of ICNETS2: LNEE 490, P297, DOI 10.1007/978-981-10-8354-9_27
   Triester SL, 2005, AM J GASTROENTEROL, V100, P2407, DOI 10.1111/j.1572-0241.2005.00274.x
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Valdastri P, 2012, ANNU REV BIOMED ENG, V14, P397, DOI 10.1146/annurev-bioeng-071811-150006
   Vieira PM, 2015, IEEE ENG MED BIO, P3025, DOI 10.1109/EMBC.2015.7319029
   Wang Y, 2019, APPL SOFT COMPUT, V74, P40, DOI 10.1016/j.asoc.2018.10.006
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   YAMADA A, 2001, MPEG 7 VISUAL PART E
   Yoon, 2011, WORLD ACAD SCI ENG T, V57
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE INT CONF ROBOT, P1310, DOI 10.1109/ICRA.2015.7139360
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang MX, 2019, SOFT COMPUT, V23, P2033, DOI 10.1007/s00500-017-2916-9
   Zhang S, 2011, INT C INT SCI INT DA, V72022011, P167, DOI [10.1007/978-3-642-31919-8_22, DOI 10.1007/978-3-642-31919-8_22]
   Zhang S, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P2374, DOI 10.1109/ICMLC.2009.5212217
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 158
TC 9
Z9 9
U1 1
U2 8
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1573-4056
EI 1875-6603
J9 CURR MED IMAGING
JI Curr. Med. Imaging
PY 2020
VL 16
IS 10
BP 1229
EP 1242
DI 10.2174/1573405616666200425220513
PG 14
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA PS3YO
UT WOS:000607861200005
PM 32334504
DA 2023-04-20
ER

PT J
AU Liu, DY
   Jiang, HX
   Rao, NN
   Du, WJ
   Luo, CS
   Li, ZW
   Zhu, LL
   Gan, T
AF Liu, Dingyun
   Jiang, Hongxiu
   Rao, Nini
   Du, Wenju
   Luo, Chengsi
   Li, Zhengwen
   Zhu, Linlin
   Gan, Tao
TI Depth Information-Based Automatic Annotation of Early Esophageal Cancers
   in Gastroscopic Images Using Deep Learning Techniques
SO IEEE ACCESS
LA English
DT Article
DE Lesions; Training; Cancer; Machine learning; Image segmentation; Feature
   extraction; Licenses; Gastroscopic image; early esophageal cancer;
   lesion annotation; deep learning; depth map
ID CONVOLUTIONAL NEURAL-NETWORK; ARTIFICIAL-INTELLIGENCE; CLASSIFICATION;
   LESIONS
AB The early diagnoses of esophageal cancer are of great significance in the clinic because they are critical for reducing mortality. At present, the diagnoses are mainly performed by artificial detection and annotations based on gastroscopic images. However, these procedures are very challenging to clinicians due to the large variability in the appearance of early cancer lesions. To reduce the subjectivity and fatigue in manual annotations and to improve the efficiency of diagnoses, computer-aided annotation methods are highly required. In this work, we proposed a novel method that utilized deep learning (DL) techniques to realize the automatic annotation of early esophageal cancer (EEC) lesions in gastroscopic images. The depth map of gastroscopic images was initially extracted by a DL network. Then, this additional depth information was fused with the original RGB gastroscopic images, which were then sent to another DL network to obtain precise annotations of EEC regions. In total, 4231 gastroscopic images of 732 patients were used to build and validate the proposed method. A total of 3190 of those images were EEC images, and the remaining 1041 were non-EEC images. The experimental results show that the combination of depth information and RGB information improved the annotation performance. The final EEC detection rate and mean Dice Similarity Coefficient (DSC) of our method were 97.54% and 74.43%, respectively. Compared with other state-of-the-art DL-based methods, the proposed method showed better annotation performances and fewer false positive outputs. Therefore, our method offers a good prospect in aiding the clinical diagnoses of EEC.
C1 [Liu, Dingyun; Jiang, Hongxiu; Rao, Nini; Du, Wenju; Luo, Chengsi; Li, Zhengwen] Univ Elect Sci & Technol China, Ctr Informat Biol, Chengdu 610054, Peoples R China.
   [Liu, Dingyun; Jiang, Hongxiu; Rao, Nini; Du, Wenju; Luo, Chengsi; Li, Zhengwen] Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu 610054, Peoples R China.
   [Zhu, Linlin; Gan, Tao] Sichuan Univ, Digest Endoscop Ctr, West China Hosp, Chengdu 610017, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; Sichuan University
RP Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Ctr Informat Biol, Chengdu 610054, Peoples R China.; Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu 610054, Peoples R China.
EM raonn@uestc.edu.cn
OI Rao, Nini/0000-0001-7979-2917
FU National Natural Science Foundation of China [61872405, 61720106004];
   Key Project of Natural Science Foundation of Guangdong province
   [2016A030311040]; Scientific Platform Improvement Project of UESTC
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61872405 and Grant 61720106004, in part
   by the Key Project of Natural Science Foundation of Guangdong province
   under Grant 2016A030311040, and in part by the Scientific Platform
   Improvement Project of UESTC.
CR [Anonymous], [No title captured]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Calkins H, 2017, J ARRYTHM, V33, P369, DOI 10.1016/j.joa.2017.08.001
   Chen CI, 2010, PROC SPIE, V7625, DOI 10.1117/12.839027
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Chmelik J, 2018, MED IMAGE ANAL, V49, P76, DOI 10.1016/j.media.2018.07.008
   Choudhury A, 2018, I CONF VLSI DESIGN, P115, DOI 10.1109/VLSID.2018.47
   de Groof J, 2019, UNITED EUR GASTROENT, V7, P538, DOI 10.1177/2050640619837443
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Du XX, 2018, PROCEEDINGS OF 2018 THE 2ND INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2018), P17, DOI 10.1145/3301506.3301540
   Ell C, 2007, GASTROINTEST ENDOSC, V65, P3, DOI 10.1016/j.gie.2006.04.033
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Globocan, 2019, EST CANC INC MORT PR
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Hu JJ, 2019, IEEE WINT CONF APPL, P1043, DOI 10.1109/WACV.2019.00116
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Liu DY, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1063-x
   Liu LX, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-9
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Ronneberger O., 2016, MICCAI, P234
   Roy R, 2019, PATTERN RECOGN LETT, V123, P31, DOI 10.1016/j.patrec.2019.03.004
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   van der Sommen F, 2018, COMPUT MED IMAG GRAP, V67, P9, DOI 10.1016/j.compmedimag.2018.02.007
   van Riel S, 2018, IEEE IMAGE PROC, P1383, DOI 10.1109/ICIP.2018.8451771
   Vasilakakis M, 2019, EXPERT REV GASTROENT, V13, P129, DOI 10.1080/17474124.2019.1553616
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Zhang J, 2019, IEEE T MED IMAGING, V38, P435, DOI 10.1109/TMI.2018.2865671
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 34
TC 3
Z9 3
U1 1
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 97907
EP 97919
DI 10.1109/ACCESS.2020.2996631
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LZ3QG
UT WOS:000541142600013
OA gold
DA 2023-04-20
ER

PT J
AU Liu, WN
   Zhang, YY
   Bian, XQ
   Wang, LJ
   Yang, Q
   Zhang, XD
   Huang, J
AF Liu, Wen-Na
   Zhang, Yang-Yang
   Bian, Xu-Qiang
   Wang, Li-Juan
   Yang, Qiang
   Zhang, Xi-Dou
   Huang, Jin
TI Study on detection rate of polyps and adenomas in
   artificial-intelligence-aided colonoscopy
SO SAUDI JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Adenoma; artificial intelligence; colonoscopy; detection rate; polyp
ID COLORECTAL-CANCER; CLASSIFICATION; PREVENTION; DIAGNOSIS; LESIONS; RISK
AB Background/Aim: To study the impact of computer-aided detection (CADe) system on the detection rate of polyps and adenomas in colonoscopy.
   Materials and Methods: A total of 1026 patients were prospectively randomly scheduled for colonoscopy with (the CADe group, CADe) or without (the control group, CON) the aid of the CADe system, together with visual notification and voice alarm, so as to compare the detection rate of polyp.
   Results: Compared with group CON, the detection rate of adenomas increased in group CADe, the average number of adenomas increased, the number of small adenomas increased, the number of proliferative polyps increased, and the differences were statistically significant (P < 0.001), but the comparison for the number of larger adenomas showed no significant difference between the groups (P > 0.05).
   Conclusions: The CADe system is feasible for increasing the detection of polyps and adenomas in colonoscopy.
C1 [Liu, Wen-Na; Zhang, Yang-Yang; Bian, Xu-Qiang; Wang, Li-Juan; Yang, Qiang; Zhang, Xi-Dou; Huang, Jin] 988 Hosp Joint Logist Support Force PLA, Dept Digest Endoscopy, Zhengzhou 450000, Peoples R China.
RP Huang, J (通讯作者)，988 Hosp Joint Logist Support Force PLA, Dept Digest Endoscopy, Zhengzhou 450000, Peoples R China.
EM jinhuangdoc@126.com
RI zhang, yangyang/GZG-7467-2022
CR Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chen SC, 2007, AM J GASTROENTEROL, V102, P856, DOI 10.1111/j.1572-0241.2006.01054.x
   Chin M, 2016, WORLD J GASTROENTERO, V22, P9642, DOI 10.3748/wjg.v22.i43.9642
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Halpern Z, 2015, ENDOSCOPY, V47, P238, DOI 10.1055/s-0034-1391437
   Horton N, 2016, AM J GASTROENTEROL, V111, P1330, DOI 10.1038/ajg.2016.273
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Marcondes FO, 2018, DIGEST DIS SCI, V63, P856, DOI 10.1007/s10620-018-4947-1
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 24
TC 77
Z9 78
U1 1
U2 9
PU WOLTERS KLUWER MEDKNOW PUBLICATIONS
PI MUMBAI
PA WOLTERS KLUWER INDIA PVT LTD , A-202, 2ND FLR, QUBE, C T S  NO 1498A-2
   VILLAGE MAROL, ANDHERI EAST, MUMBAI, Maharashtra, INDIA
SN 1319-3767
EI 1998-4049
J9 SAUDI J GASTROENTERO
JI Saudi J. Gastroenterol.
PD JAN-FEB
PY 2020
VL 26
IS 1
BP 13
EP 19
AR PMID 31898644
DI 10.4103/sjg.SJG_377_19
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA LC9NG
UT WOS:000525660100003
PM 31898644
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Meng, J
   Xue, LY
   Chang, Y
   Zhang, JG
   Chang, SL
   Liu, K
   Liu, S
   Wang, BM
   Yang, K
AF Meng, Jie
   Xue, Linyan
   Chang, Ying
   Zhang, Jianguang
   Chang, Shilong
   Liu, Kun
   Liu, Shuang
   Wang, Bangmao
   Yang, Kun
TI Automatic detection and segmentation of adenomatous colorectal polyps
   during colonoscopy using Mask R-CNN
SO OPEN LIFE SCIENCES
LA English
DT Article
DE CRC; adenomatous polyps; CAD; CNN; colonoscopy
ID REAL-TIME; CANCER; POLYPECTOMY; PREVENTION; GUIDELINES
AB Colorectal cancer (CRC) is one of the main alimentary tract system malignancies affecting people worldwide. Adenomatous polyps are precursors of CRC, and therefore, preventing the development of these lesions may also prevent subsequent malignancy. However, the adenoma detection rate (ADR), a measure of the ability of a colonoscopist to identify and remove precancerous colorectal polyps, varies significantly among endoscopists. Here, we attempt to use a convolutional neural network (CNN) to generate a unique computer-aided diagnosis (CAD) system by exploring in detail the multiple-scale performance of deep neural networks. We applied this system to 3,375 hand-labeled images from the screening colonoscopies of 1,197 patients; of whom, 3,045 were assigned to the training dataset and 330 to the testing dataset. The images were diagnosed simply as either an adenomatous or non-adenomatous polyp. When applied to the testing dataset, our CNN-CAD system achieved a mean average precision of 89.5%. We conclude that the proposed framework could increase the ADR and decrease the incidence of interval CRCs, although further validation through large multicenter trials is required.
C1 [Meng, Jie; Wang, Bangmao] Tianjin Med Univ, Dept Gastroenterol & Hepatol, Gen Hosp, Tianjin 300052, Peoples R China.
   [Xue, Linyan; Chang, Shilong; Liu, Kun; Liu, Shuang; Yang, Kun] Hebei Univ, Coll Qual & Tech Supervis, Baoding 071002, Peoples R China.
   [Meng, Jie; Chang, Ying; Zhang, Jianguang] Hebei Univ, Affiliated Hosp, Dept Gastroenterol, Baoding 071000, Peoples R China.
C3 Tianjin Medical University; Hebei University; Hebei University
RP Wang, BM (通讯作者)，Tianjin Med Univ, Dept Gastroenterol & Hepatol, Gen Hosp, Tianjin 300052, Peoples R China.; Yang, K (通讯作者)，Hebei Univ, Coll Qual & Tech Supervis, Baoding 071002, Peoples R China.
EM mwang02@tmu.edu.cn; hbuyangkun@163.com
FU Foundation of Hebei University [DXK201914]; Natural Science Foundation
   of Hebei Province [H2019201378]; President fund of Hebei University
   [XZJJ201914]
FX This work was funded by the Foundation of Hebei University (DXK201914),
   the Natural Science Foundation of Hebei Province (H2019201378) and the
   President fund of Hebei University (XZJJ201914).
CR Anderson JC, 2015, CLIN TRANSL GASTROEN, V6, DOI 10.1038/ctg.2015.5
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P., 2018, J MED ROBOT RES, V3, P1840002, DOI DOI 10.1142/S2424905X18400020
   Brenner H, 2011, ANN INTERN MED, V154, P22, DOI 10.7326/0003-4819-154-1-201101040-00004
   Byrne MF, 2017, GASTROINTEST ENDOSC, V85, pAB364, DOI 10.1016/j.gie.2017.03.843
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He YX, 2023, TRANSPORTMETRICA A, V19, DOI [10.1109/CVPR.2016.90, 10.1080/23249935.2022.2033348]
   Huang X, 2019, COMPUT MED IMAG GRAP, V74, P25, DOI 10.1016/j.compmedimag.2019.02.003
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Kaiming He, 2020, IEEE Transactions on Pattern Analysis and Machine Intelligence, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Le Cun YL, 1997, ADV NEURAL INFORM PR, V2, P396
   Levine JS, 2006, NEW ENGL J MED, V355, P2551, DOI 10.1056/NEJMcp063038
   Li TB, 2016, GASTROINTEST ENDOSC, V83, pAB482, DOI 10.1016/j.gie.2016.03.671
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Pignone M, 2002, ANN INTERN MED, V137, P96, DOI 10.7326/0003-4819-137-2-200207160-00007
   Potter JD, 1999, JNCI-J NATL CANCER I, V91, P916, DOI 10.1093/jnci/91.11.916
   Rex DK, 2009, AM J GASTROENTEROL, V104, P739, DOI 10.1038/ajg.2009.104
   Simonyan Karen, 2013, ARXIV PREPRINT ARXIV
   Sun WQ, 2017, COMPUT MED IMAG GRAP, V57, P4, DOI 10.1016/j.compmedimag.2016.07.004
   Szegedy, 2013, ARXIV13126199, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 34
TC 6
Z9 6
U1 0
U2 6
PU DE GRUYTER POLAND SP Z O O
PI WARSAW
PA BOGUMILA ZUGA 32A STR, 01-811 WARSAW, MAZOVIA, POLAND
SN 2391-5412
J9 OPEN LIFE SCI
JI Open Life Sci.
PY 2020
VL 15
IS 1
BP 588
EP 596
DI 10.1515/biol-2020-0055
PG 9
WC Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics
GA NH4XQ
UT WOS:000564675100001
PM 33817247
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Meroni, G
   Pace, F
   Grossi, E
   Casini, V
   Drago, L
AF Meroni, Gabriele
   Pace, Fabio
   Grossi, Enzo
   Casini, Valentina
   Drago, Lorenzo
TI Bacterial network community in fecal and endoluminal Microbiota after
   colonoscopy
SO NEW MICROBIOLOGICA
LA English
DT Article
DE Gut microbiota; Bacterial network; Auto contractive map; Colonoscopy
ID INTESTINAL MICROBIOTA; GUT MICROBIOTA; OXALOBACTER-FORMIGENES; OBESITY;
   HEALTH; ANGIOGENESIS
AB The gut microbiota is a complex and dynamic ecosystem with a strong influence on the host's health. Several factors can modify the gut's bacterial composition, often leading to the onset of intestinal dysbiosis. Therefore, it is essential not only to evaluate the quantitative bacterial changes occurring in the human microbiota but also to characterize relationships existing among all the microorganisms. This study aimed to evaluate the impact of bowel cleansing on the fecal microbiota network by highlighting differences between fecal microflora before and after colonoscopy, and luminal samples during colonoscopy. Fecal and luminal samples, previously analyzed by mean of Next-Generation Sequencing (NGS) for their bacterial abundance, were further processed by a method based on Artificial Neural Network (ANN) architecture. The bowel lavage had a strong effect on the intestinal microbiota network, leading to significant changes in the distribution of different bacterial hubs potentially involved in the microbiota homeostasis. Furthermore, the fecal and luminal microbiota showed a different bacterial network, characterized by distinct microbial hubs. In particular, the latter seemed to be rich in potentially pathogenic bacteria which, in physiological conditions, are counteracted by fecal microorganisms.
C1 [Meroni, Gabriele; Drago, Lorenzo] Univ Milan, Dept Biomed Sci Hlth, Lab Clin Microbiol, Milan, Italy.
   [Pace, Fabio; Casini, Valentina] Bolognini Hosp, UOC Gastroenterol & Digest Endoscopy, Seriate, Italy.
   [Grossi, Enzo] Villa Santa Maria Inst, Wa 4 Novembre Tavernerio, Como, Italy.
   [Drago, Lorenzo] Univ Milan, Ctr Ric Pediat Romeo & Enrica Invernizzi, Milan, Italy.
C3 University of Milan; University of Milan
RP Drago, L (通讯作者)，Univ Milan, Dept Biomed Sci Hlth, Lab Clin Microbiol, Milan, Italy.; Drago, L (通讯作者)，Univ Milan, Ctr Ric Pediat Romeo & Enrica Invernizzi, Milan, Italy.
EM lorenzo.drago@unimi.it
RI Meroni, Gabriele/AAV-4571-2020
OI Meroni, Gabriele/0000-0003-2772-6410; GROSSI, ENZO/0000-0003-0346-2684
CR Andriessen EMMA, 2016, EMBO MOL MED, V8, P1366, DOI 10.15252/emmm.201606531
   Backhed F, 2004, P NATL ACAD SCI USA, V101, P15718, DOI 10.1073/pnas.0407076101
   Baldassano S.N., 2016, SCI REPORTS, V6, P1
   Biedermann L, 2015, EUR J PEDIATR, V174, P151, DOI 10.1007/s00431-014-2476-2
   Braga M.N.P., 2019, BRAZ J DEV, V12, P32316
   Buscema M, 2008, CURR ALZHEIMER RES, V5, P481, DOI 10.2174/156720508785908928
   Buscema M, 2008, INT J DATA MIN BIOIN, V2, P362, DOI 10.1504/IJDMB.2008.022159
   Chen LP, 2014, MEDICINE, V93, DOI 10.1097/MD.0000000000000051
   Cheng VCC, 2015, EUR J CLIN MICROBIOL, V34, P2359, DOI 10.1007/s10096-015-2489-4
   Dicksved J, 2014, MBIO, V5, DOI 10.1128/mBio.01212-14
   Donaldson GP, 2016, NAT REV MICROBIOL, V14, P20, DOI 10.1038/nrmicro3552
   Drago L, 2017, ISME J, V11, P875, DOI 10.1038/ismej.2016.183
   Drago L, 2016, EUR J GASTROEN HEPAT, V28, P532, DOI 10.1097/MEG.0000000000000581
   Drago L, 2012, J CLIN GASTROENTEROL, V46, pS56, DOI 10.1097/MCG.0b013e318265ef38
   Faust K, 2012, NAT REV MICROBIOL, V10, P538, DOI 10.1038/nrmicro2832
   Harley ITW, 2012, MOL METAB, V1, P21, DOI 10.1016/j.molmet.2012.07.002
   Hullar MAJ, 2015, CANCER EPIDEM BIOMAR, V24, P546, DOI 10.1158/1055-9965.EPI-14-0262
   Jalanka J, 2015, GUT, V64, P1562, DOI 10.1136/gutjnl-2014-307240
   Jiang HY, 2015, BRAIN BEHAV IMMUN, V48, P186, DOI 10.1016/j.bbi.2015.03.016
   Jiang WW, 2015, SCI REP-UK, V5, DOI 10.1038/srep08096
   Kruskal JB., 1956, P AM MATH SOC, V7, P48, DOI 10.2307/2033241
   Lu K, 2015, ILAR J, V56, P218, DOI 10.1093/ilar/ilv018
   Rodriguez JM, 2015, MICROB ECOL HEALTH D, V26, DOI 10.3402/mehd.v26.26050
   Milani C., 2016, SCI REPORTS, V6, P1
   Mittal RD, 2004, J ENDOUROL, V18, P418, DOI 10.1089/0892779041271706
   Moschen AR, 2016, CELL HOST MICROBE, V19, P455, DOI 10.1016/j.chom.2016.03.007
   Nakano V., 2006, MICROBIOLOGY, V1, P61
   Ohkawara S, 2005, J NUTR, V135, P2878, DOI 10.1093/jn/135.12.2878
   Sajib S, 2018, ANGIOGENESIS, V21, P1, DOI 10.1007/s10456-017-9583-4
   Saulnier DM, 2011, GASTROENTEROLOGY, V141, P1782, DOI 10.1053/j.gastro.2011.06.072
   Sommer F, 2017, NAT REV MICROBIOL, V15, P630, DOI 10.1038/nrmicro.2017.58
   Stewart CS, 2004, FEMS MICROBIOL LETT, V230, P1, DOI 10.1016/S0378-1097(03)00864-4
   Tilg H, 2018, CANCER CELL, V33, P954, DOI 10.1016/j.ccell.2018.03.004
   Vandeputte D, 2016, GUT, V65, P57, DOI 10.1136/gutjnl-2015-309618
   von Martels JZH, 2017, ANAEROBE, V44, P3, DOI 10.1016/j.anaerobe.2017.01.001
   Walters WA, 2014, FEBS LETT, V588, P4223, DOI 10.1016/j.febslet.2014.09.039
NR 36
TC 1
Z9 2
U1 2
U2 5
PU EDIZIONI INT SRL
PI MILANO
PA VIA SPADOLINI 7, MILANO, 20141, ITALY
SN 1121-7138
J9 NEW MICROBIOL
JI New Microbiol.
PD JAN
PY 2020
VL 43
IS 1
BP 22
EP 27
PG 6
WC Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Microbiology
GA LC5DI
UT WOS:000525344800005
PM 32118281
DA 2023-04-20
ER

PT J
AU Nadimi, ES
   Buijs, MM
   Herp, J
   Kroijer, R
   Kobaek-Larsen, M
   Nielsen, E
   Pedersen, CD
   Blanes-Vidal, V
   Baatrup, G
AF Nadimi, Esmaeil S.
   Buijs, Maria M.
   Herp, Jurgen
   Kroijer, Rasmus
   Kobaek-Larsen, Morten
   Nielsen, Emilie
   Pedersen, Claus D.
   Blanes-Vidal, Victoria
   Baatrup, Gunnar
TI Application of deep learning for autonomous detection and localization
   of colorectal polyps in wireless colon capsule endoscopy
SO COMPUTERS & ELECTRICAL ENGINEERING
LA English
DT Article
DE Colorectal polyps; Colon capsule endoscopy (CCE); Deep learning; Machine
   learning; Convolutional neural networks
AB Recent advances in deep learning have prompted a surge of interest in analysis of medical images. In this study, we developed a convolutional neural network (CNN) for autonomous detection of colorectal polyps, in images captured during wireless colon capsule endoscopy, with risk of malignant evolution to colorectal cancer. Our CNN is an improved version of ZF-Net which uses a combination of transfer learning, pre-processing and data augmentation. We further deployed our CNN as the basis for a Faster R-CNN to localize regions of images containing colorectal polyps. We created an image database of 11,300 capsule endoscopy images from a screening population, including colorectal polyps (any size or morphology, N=4800) and normal mucosa (N=6500). Our CNN scored an accuracy of 98.0%, a sensitivity of 98.1% and a specificity of 96.3%. Our network outperforms all state-of-the-art results in autonomous detection of colorectal polyps and shows high interpretability in terms of sensitive regions. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Nadimi, Esmaeil S.; Herp, Jurgen; Blanes-Vidal, Victoria] Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Grp Appl AI & Data Sci, Odense, Denmark.
   [Buijs, Maria M.; Kroijer, Rasmus; Kobaek-Larsen, Morten; Baatrup, Gunnar] Odense Univ Hosp, Dept Surg, Odense, Denmark.
   [Buijs, Maria M.; Kroijer, Rasmus; Kobaek-Larsen, Morten; Baatrup, Gunnar] Univ Southern Denmark, Dept Clin Res, Odense, Denmark.
   [Nielsen, Emilie; Pedersen, Claus D.] Odense Univ Hosp, Ctr Innovat Med Technol, Odense, Denmark.
C3 University of Southern Denmark; University of Southern Denmark; Odense
   University Hospital; University of Southern Denmark; University of
   Southern Denmark; Odense University Hospital
RP Nadimi, ES (通讯作者)，Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Grp Appl AI & Data Sci, Odense, Denmark.
EM esi@mmmi.sdu.dk
RI ; Blanes-Vidal, Victoria/B-5196-2019; Nadimi, Esmaeil/B-5289-2019
OI Kroijer, Rasmus/0000-0003-4358-7916; Kobaek-Larsen,
   Morten/0000-0002-5097-9283; Blanes-Vidal, Victoria/0000-0002-9269-4526;
   baatrup, gunnar/0000-0003-0300-5766; Nadimi, Esmaeil/0000-0003-2613-2696
FU University of Southern Denmark; Odense University Hospital; Danish
   Cancer Society; Region of Southern Denmark, through the Project EFFICACY
FX This research was financially supported in part by a research grant from
   the University of Southern Denmark, Odense University Hospital, Danish
   Cancer Society and Region of Southern Denmark, through the Project
   EFFICACY. The Quadro P6000 GPU card used for this research was
   generously donated by NVIDIA Corporation.
CR [Anonymous], 2007, INT J INF TECHNOL
   Blanes-Vidal V, 2018, INT J COLORECTAL DIS
   Bujanda L, 2010, WORLD J GASTROENTERO, V16, P3103, DOI 10.3748/wjg.v16.i25.3103
   He K, 2018, ARXIV151203385V1
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Hovde O, 2018, P BRIT MACH VIS C 20
   Jia J, 2014, US Patent, Patent No. [14/471:143, 201414471143]
   Kobaek-Larsen M, 2018, COLORECTAL DIS, V20, P479, DOI 10.1111/codi.13965
   Krizhevsky A., NIPS 2012
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Murino A, 2016, CURR OPIN GASTROEN, V32, P38, DOI 10.1097/MOG.0000000000000230
   Nadimi ES, 2017, 27 IEEE INT WORKSH M, DOI [10.1109/MLSP.2017.8168115, DOI 10.1109/MLSP.2017.8168115]
   Pogorelov Konstantin, 2018, 2018 IEEE 31 INT S C
   Puig I, 2018, GUT LIVER, V12, P385, DOI 10.5009/gnl17137
   Shaoqing R, 2015, ADV NEURAL INF PROCE, V28
   Simonyan K, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34553-x
   Surya-Prasath V.B, 2018, ARXIV160901915
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Urban G, 2018, GASTROENTEROLOGY
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zeiler M, ICCV 2012
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 25
TC 25
Z9 25
U1 3
U2 17
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0045-7906
EI 1879-0755
J9 COMPUT ELECTR ENG
JI Comput. Electr. Eng.
PD JAN
PY 2020
VL 81
AR 106531
DI 10.1016/j.compeleceng.2019.106531
PG 9
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KT0BH
UT WOS:000518675000030
DA 2023-04-20
ER

PT J
AU Nguyen, NQ
   Vo, DM
   Lee, SW
AF Ngoc-Quang Nguyen
   Duc My Vo
   Lee, Sang-Woong
TI Contour-Aware Polyp Segmentation in Colonoscopy Images Using Detailed
   Upsamling Encoder-Decoder Networks
SO IEEE ACCESS
LA English
DT Article
DE Cancer; Image segmentation; Colonoscopy; Feature extraction; Training;
   Decoding; Colon; Polyp segmentation; hierarchical collaborative
   representation-based classification; local ternary patterns; deep
   convolutional neural network; colorectal segmentation
AB Colorectal cancer has become one of the most common cause of cancer mortality worldwide, with a five-year survival rate of over 50%. Additionally, the potential of some common polyp types to progress to colorectal cancer is considered high. Colonoscopy is the most common method for finding and removing polyps. However, during colonoscopy, a significant number of polyps is missed as a result of human error mistakes. Thus, this study was primarily motivated by the need to obtain an early and accurate diagnosis of polyps detected in colonoscopy images. In this paper, we propose a new polyp segmentation method based on an architecture of multi-model deep encoder-decoder networks called MED-Net. Not only does this architecture obtain multi-level contextual information by extracting discriminative features at different effective fields-of-view and multiple image scales, it also can substantially do upsample more correctly to produce better prediction. It is also able to capture more accurate polyp boundaries by using multi-scale effective decoders. Moreover, we also present a complementary strategy for improving the method's segmentation performance based on a combination of a boundary-aware data augmentation method and an effective weighted loss function. The purpose of this strategy is to allow our deep learning network to sequentially focus on poorly defined polyp boundaries, which are caused by the non-specular transition zone between the polyp and non-polyp regions. To provide a general view of the proposed method, our network was trained and evaluated on four well-known dataset CVC-ColonDB, CVC-ClinicDB, ASU-Mayo Clinic Colonoscopy Video Database, and ETIS-LaribPolypDB. Our results show that our MED-Net significantly outperforms state-of-the-art methods.
C1 [Ngoc-Quang Nguyen; Duc My Vo; Lee, Sang-Woong] Gachon Univ, Pattern Recognit & Machine Learning Lab, Seongnam 13120, South Korea.
C3 Gachon University
RP Lee, SW (通讯作者)，Gachon Univ, Pattern Recognit & Machine Learning Lab, Seongnam 13120, South Korea.
EM slee@gachon.ac.kr
RI Lee, Sang-Woong/ABF-6191-2020
OI Lee, Sang-Woong/0000-0001-8117-6566; Nguyen, Quang/0000-0002-7448-535X
FU Gyeonggi-do Regional Research Center (GRRC) Program of Gyeonggi Province
   through the Analysis of Behavior Based on Senior Life Log
   [GRRC-2017-B01]
FX This work was supported by the Gyeonggi-do Regional Research Center
   (GRRC) Program of Gyeonggi Province through the Analysis of Behavior
   Based on Senior Life Log under Grant GRRC-2017-B01.
CR Abadi, 2015, TENSORFLOW LARGE SCA
   Akbari M., 2018, ARXIV180200368
   American Cancer Society, 2011, COL CANC FACTS FIG 2
   Arshad M, 2020, BRAZ J PROBAB STAT, V34, P167, DOI 10.1214/18-BJPS407
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bengio Y., 2016, ADAPTIVE COMPUTATION
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bradski G., 2008, LEARNING OPENCV COMP
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Breier M, 2011, PROC SPIE, V7963, DOI 10.1117/12.877986
   Bui T.D., 2017, ARXIV PREPRINT ARXIV
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen L.C., 2018, LECT NOTES COMPUT SC, P801, DOI DOI 10.1007/978-3-030-01234-2_49
   Chen YT, 2019, NEURAL NETWORKS, V110, P170, DOI 10.1016/j.neunet.2018.11.009
   Cho K., 2014, 2014 C EMPIRICAL MET, V2014, P1724, DOI [10.3115/v1/d14-1179, 10.3115/v1/ d14-1179, DOI 10.3115/V1/D14-1179]
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Vo DM, 2019, INFORM SCIENCES, V482, P123, DOI 10.1016/j.ins.2018.12.089
   Vo DM, 2018, MULTIMED TOOLS APPL, V77, P18689, DOI 10.1007/s11042-018-5653-x
   Vo DM, 2018, INFORM SCIENCES, V432, P332, DOI 10.1016/j.ins.2017.12.014
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Han C, 2020, SMART INNOV SYST TEC, V151, P291, DOI 10.1007/978-981-13-8950-4_27
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Holland O, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500442
   Holschneider M., 1990, WAVELETS TIME FREQUE, P286, DOI DOI 10.1007/978-3-642-75988-8_28
   Huang FM, 2020, LANDSLIDES, V17, P217, DOI 10.1007/s10346-019-01274-9
   Izmailov P, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P876
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Jia YQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1631, DOI 10.1109/ROBIO.2015.7419005
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kucharski D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061546
   Lee K, 2020, J COMPUT PHYS, V404, DOI 10.1016/j.jcp.2019.108973
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Liu P, 2020, IEEE ACCESS, V8, P34029, DOI 10.1109/ACCESS.2020.2973707
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmood F, 2019, PROC SPIE, V10950, DOI 10.1117/12.2513117
   Nguyen NQ, 2019, IEEE ACCESS, V7, P33795, DOI 10.1109/ACCESS.2019.2904094
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Ouali Y., 2020, ARXIV200309005
   Papandreou G, 2015, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2015.7298636
   Park HC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051650
   Perl Y. S., 2020, DATA AUGMENTATION BA
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI 10.3322/caac.21395
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tao Y, 2017, CHIN CONTR CONF, P4288, DOI 10.23919/ChiCC.2017.8028032
   Tian Z., 2019, ARXIV190302120
   Varkarakis V, 2020, NEURAL NETWORKS, V121, P101, DOI 10.1016/j.neunet.2019.07.020
   Wang LS, 2018, GUT, V67, pA84, DOI 10.1136/gutjnl-2018-IDDFabstracts.181
   Wojna Z, 2019, INT J COMPUT VISION, V127, P1694, DOI 10.1007/s11263-019-01170-8
   Wu Z, 2005, INT J PROD RES, V43, P3027, DOI 10.1080/00207540500057639
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang Y, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101664
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou Q, 2019, WORLD WIDE WEB, V22, P555, DOI 10.1007/s11280-018-0556-3
NR 67
TC 15
Z9 15
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 99495
EP 99508
DI 10.1109/ACCESS.2020.2995630
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LZ3KT
UT WOS:000541127800047
OA gold
DA 2023-04-20
ER

PT J
AU Patel, V
   Khan, MN
   Shrivastava, A
   Sadiq, K
   Ali, SA
   Moore, SR
   Brown, DE
   Syed, S
AF Patel, Vatsal
   Khan, Marium N.
   Shrivastava, Aman
   Sadiq, Kamran
   Ali, S. Asad
   Moore, Sean R.
   Brown, Donald E.
   Syed, Sana
TI Artificial Intelligence Applied to Gastrointestinal Diagnostics: A
   Review
SO JOURNAL OF PEDIATRIC GASTROENTEROLOGY AND NUTRITION
LA English
DT Review
DE artificial intelligence; diagnostic efficiency; gastrointestinal
   diagnostics; machine learning
ID HIGH-RESOLUTION MANOMETRY; CAPSULE ENDOSCOPY; CELIAC-DISEASE; LESION
   DETECTION; CROHNS-DISEASE; MEAN SHIFT; MISS RATE; CLASSIFICATION;
   FUTURE; RISK
AB Artificial intelligence (AI), a discipline encompassed by data science, has seen recent rapid growth in its application to healthcare and beyond, and is now an integral part of daily life. Uses of AI in gastroenterology include the automated detection of disease and differentiation of pathology subtypes and disease severity. Although a majority of AI research in gastroenterology focuses on adult applications, there are a number of pediatric pathologies that could benefit from more research. As new and improved diagnostic tools become available and more information is retrieved from them, AI could provide physicians a method to distill enormous amounts of data into enhanced decision-making and cost saving for children with digestive disorders. This review provides a broad overview of AI and examples of its possible applications in pediatric gastroenterology.
C1 [Patel, Vatsal] Univ Virginia, Sch Med, Charlottesville, VA 22908 USA.
   [Khan, Marium N.; Moore, Sean R.; Syed, Sana] Univ Virginia, Dept Pediat, Div Gastroenterol, Charlottesville, VA 22908 USA.
   [Shrivastava, Aman; Brown, Donald E.] Univ Virginia, Data Sci Inst, Charlottesville, VA USA.
   [Sadiq, Kamran; Ali, S. Asad; Syed, Sana] Aga Khan Univ, Dept Pediat & Child Hlth, Karachi, Pakistan.
   [Brown, Donald E.] Univ Virginia, Dept Syst & Informat Engn, Charlottesville, VA USA.
C3 University of Virginia; University of Virginia; University of Virginia;
   Aga Khan University; University of Virginia
RP Syed, S (通讯作者)，Univ Virginia, POB 801349, Charlottesville, VA 22908 USA.
EM sana.syed@virginia.edu
RI Shrivastava, Aman/AAF-6144-2021
OI Brown, Donald/0000-0002-9140-2632; Ali, Syed Asad/0000-0001-5274-7665
FU University of Virginia Translational Health Research Institute of
   Virginia (THRIV), Mentored Career Development Award; National Institute
   of Diabetes and Digestive and Kidney Diseases of the National Institutes
   of Health K23 Mentored Patient-Oriented Research Career Development
   Award [K23 DK117061-01A1]; University of Virginia Engineering in
   Medicine SEED Grant
FX The study was supported by University of Virginia Translational Health
   Research Institute of Virginia (THRIV), Mentored Career Development
   Award (S.S.), the National Institute of Diabetes and Digestive and
   Kidney Diseases of the National Institutes of Health K23 Mentored
   Patient-Oriented Research Career Development Award [K23 DK117061-01A1]
   (S.S.), and the University of Virginia Engineering in Medicine SEED
   Grant (S.S. and D.E.B.).
CR Administration F-USFD, FDA PERM MARK ART IN
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Asadi H, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088225
   Beam AL, 2018, JAMA-J AM MED ASSOC, V319, P1317, DOI 10.1001/jama.2017.18391
   Bejakovic S, 2009, ICRA 09 P 2009 IEEE
   Biswas M, 2018, COMPUT METH PROG BIO, V155, P165, DOI 10.1016/j.cmpb.2017.12.016
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Charisis VS, 2016, HEALTHC TECHNOL LETT, V3, P27, DOI 10.1049/htl.2015.0055
   Chauhan SS, 2014, GASTROINTEST ENDOSC, V80, P928, DOI 10.1016/j.gie.2014.06.021
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Chollet F, 2016, DEEP LEARNING R KERA
   Ciaccio EJ, 2017, WORLD J GASTRO ENDOS, V9, P310, DOI 10.4253/wjge.v9.i7.310
   Ciaccio EJ, 2013, WORLD J GASTRO ENDOS, V5, P313, DOI 10.4253/wjge.v5.i7.313
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deo RC, 2015, CIRCULATION, V132, P1920, DOI 10.1161/CIRCULATIONAHA.115.001593
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Farmer M, 2000, AM J GASTROENTEROL, V95, P3184
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gadermayr M, 2016, IRBM, V37, P31, DOI 10.1016/j.irbm.2015.09.009
   Gatos I, 2017, ULTRASOUND MED BIOL, V43, P1797, DOI 10.1016/j.ultrasmedbio.2017.05.002
   Girgis HZ, 2010, I S BIOMED IMAGING, P1373, DOI 10.1109/ISBI.2010.5490253
   Golden JA, 2017, JAMA-J AM MED ASSOC, V318, P2184, DOI 10.1001/jama.2017.14580
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Green PHR, 2007, NEW ENGL J MED, V357, P1731, DOI 10.1056/NEJMra071600
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hoffman MR, 2013, LARYNGOSCOPE, V123, P713, DOI 10.1002/lary.23655
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1
   Jang JY, 2015, CLIN ENDOSC, V48, P466, DOI 10.5946/ce.2015.48.6.466
   Jones CA, 2018, NEUROGASTROENT MOTIL, V30, DOI 10.1111/nmo.13236
   Jungheim M, 2016, PHYSIOL BEHAV, V165, P413, DOI 10.1016/j.physbeh.2016.08.005
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Krittanawong C, 2018, EUR J INTERN MED, V48, pE13, DOI 10.1016/j.ejim.2017.06.017
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Kwon RS, 2009, GASTROINTEST ENDOSC, V70, P610, DOI 10.1016/j.gie.2009.06.030
   Lamash Y, 2019, J MAGN RESON IMAGING, V49, P1565, DOI 10.1002/jmri.26330
   Larghi A, 2008, GUT, V57, P976, DOI 10.1136/gut.2007.127845
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu JM, 2017, MED PHYS, V44, P4630, DOI 10.1002/mp.12399
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   McCulloch TM, 2010, ANN OTO RHINOL LARYN, V119, P369, DOI 10.1177/000348941011900602
   Mielens JD, 2012, J SPEECH LANG HEAR R, V55, P892, DOI 10.1044/1092-4388(2011/11-0088)
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mossotto E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02606-2
   Muller B., 1990, NEURAL NETWORKS
   Neill DB, 2013, IEEE INTELL SYST, V28, P92, DOI 10.1109/MIS.2013.51
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Plevy S, 2013, INFLAMM BOWEL DIS, V19, P1139, DOI 10.1097/MIB.0b013e318280b19e
   Russell Stuart, 2002, ARTIF INTELL
   Sasaki Y., 2003, DIGEST ENDOSC, V15, P206, DOI [10.1046/j.1443-1661.2003.00246.x, DOI 10.1046/J.1443-1661.2003.00246.X]
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Seshamani S, 2010, LECT NOTES COMPUT SC, V6362, P454
   Subramanian V, 2014, CLIN GASTROENTEROL H, V12, P368, DOI 10.1016/j.cgh.2013.06.015
   Syed S, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.5822
   Syed S, 2016, J PEDIATR GASTR NUTR, V63, P6, DOI 10.1097/MPG.0000000000001147
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tabatabaei N, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20668-8
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vecsei A, 2011, COMPUT BIOL MED, V41, P313, DOI 10.1016/j.compbiomed.2011.03.009
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wimmer G, 2016, INT CONF IMAG PROC
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zeevi D, 2015, CELL, V163, P1079, DOI 10.1016/j.cell.2015.11.001
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 74
TC 12
Z9 12
U1 7
U2 21
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0277-2116
EI 1536-4801
J9 J PEDIATR GASTR NUTR
JI J. Pediatr. Gastroenterol. Nutr.
PD JAN
PY 2020
VL 70
IS 1
BP 4
EP 11
DI 10.1097/MPG.0000000000002507
PG 8
WC Gastroenterology & Hepatology; Nutrition & Dietetics; Pediatrics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Nutrition & Dietetics; Pediatrics
GA NC7BE
UT WOS:000561369900004
PM 31567886
OA Green Accepted, Bronze
DA 2023-04-20
ER

PT J
AU Patino-Barrientos, S
   Sierra-Sosa, D
   Garcia-Zapirain, B
   Castillo-Olea, C
   Elmaghraby, A
AF Patino-Barrientos, Sebastian
   Sierra-Sosa, Daniel
   Garcia-Zapirain, Begonya
   Castillo-Olea, Cristian
   Elmaghraby, Adel
TI Kudo's Classification for Colon Polyps Assessment Using a Deep Learning
   Approach
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE colon cancer; deep learning; image processing; medical dataset; VGG
ID COLONOSCOPY; DIAGNOSIS
AB Colorectal cancer (CRC) is the second leading cause of cancer death in the world. This disease could begin as a non-cancerous polyp in the colon, when not treated in a timely manner, these polyps could induce cancer, and in turn, death. We propose a deep learning model for classifying colon polyps based on the Kudo's classification schema, using basic colonoscopy equipment. We train a deep convolutional model with a private dataset from the University of Deusto with and without using a VGG model as a feature extractor, and compared the results. We obtained 83% of accuracy and 83% of F1-score after fine tuning our model with the VGG filter. These results show that deep learning algorithms are useful to develop computer-aided tools for early CRC detection, and suggest combining it with a polyp segmentation model for its use by specialists.
C1 [Patino-Barrientos, Sebastian] Univ EAFIT, Apolo Sci Comp Ctr, Medellin 50035, Colombia.
   [Sierra-Sosa, Daniel; Elmaghraby, Adel] Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA.
   [Garcia-Zapirain, Begonya; Castillo-Olea, Cristian] Univ Deusto, eVida Res Grp, Bilbao, Spain.
C3 Universidad EAFIT; University of Louisville; University of Deusto
RP Sierra-Sosa, D (通讯作者)，Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA.
EM spatino6@eafit.edu.co; desier01@louisville.edu; mbgarciazapi@deusto.es;
   cristian.castillo@deusto.es; adel@louisville.edu
RI Elmaghraby, Adel S/B-3353-2014; Sierra-Sosa, Daniel/AAP-4604-2020;
   Sierra-Sosa, Daniel/AAP-4610-2020; /L-5619-2014
OI Elmaghraby, Adel S/0000-0001-5274-8596; Sierra-Sosa,
   Daniel/0000-0003-1326-0867; Sierra-Sosa, Daniel/0000-0003-1326-0867;
   /0000-0002-9356-1186; Castillo olea, Cristian/0000-0002-8717-7524
FU Basque Government "Aids for health research projects"; Basque Government
   Department of Education (eVIDA Certified Group) [IT905-16]
FX This research was supported by the Basque Government "Aids for health
   research projects" and the publication fees supported by the Basque
   Government Department of Education (eVIDA Certified Group IT905-16).
CR Antipov G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1263, DOI 10.1145/2733373.2806332
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Dalai N., 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Holzinger A, 2018, LECT NOTES COMPUT SC, V11015, P1, DOI 10.1007/978-3-319-99740-7_1
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Li TB, 2016, GASTROINTEST ENDOSC, V83, pAB482, DOI 10.1016/j.gie.2016.03.671
   Lieberman DA, 2000, NEW ENGL J MED, V343, P162, DOI 10.1056/NEJM200007203430301
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Navarro M, 2017, WORLD J GASTROENTERO, V23, P3632, DOI 10.3748/wjg.v23.i20.3632
   Neilson LJ, 2015, FRONTLINE GASTROENTE, V6, P117, DOI 10.1136/flgastro-2015-100565
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Simonyan K, 2015, Arxiv
   Tanaka S, 2006, GASTROINTEST ENDOSC, V64, P604, DOI 10.1016/j.gie.2006.06.007
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 19
TC 17
Z9 17
U1 0
U2 9
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD JAN
PY 2020
VL 10
IS 2
AR 501
DI 10.3390/app10020501
PG 7
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA KY4LI
UT WOS:000522540400077
OA gold
DA 2023-04-20
ER

PT J
AU Poudel, S
   Kim, YJ
   Vo, DM
   Lee, SW
AF Poudel, Sahadev
   Kim, Yoon Jae
   Vo, Duc My
   Lee, Sang-Woong
TI Colorectal Disease Classification Using Efficiently Scaled Dilation in
   Convolutional Neural Network
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Biomedical imaging; Cancer; Colonic polyps; Support
   vector machines; Image color analysis; Colorectal image classification;
   colon disease classification; colon disease classification with CNN
ID CAPSULE ENDOSCOPY IMAGES; TUMOR RECOGNITION; FEATURES; CANCER
AB Computer-aided diagnosis systems developed by computer vision researchers have helped doctors to recognize several endoscopic colorectal diseases more rapidly, which allows appropriate treatment and increases the patient's survival ratio. Herein, we present a robust architecture for endoscopic image classification using an efficient dilation in Convolutional Neural Network (CNNs). It has a high receptive field of view at the deep layers in increasing and decreasing dilation factor to preserve spatial details. We argue that dimensionality reduction in CNN can cause the loss of spatial information, resulting in miss of polyps and confusion in similar-looking images. Additionally, we use a regularization technique called DropBlock to reduce overfitting and deal with noise and artifacts. We compare and evaluate our method using various metrics: accuracy, recall, precision, and F1-score. Our experiments demonstrate that the proposed method provides the F1-score of 0.93 for Colorectal dataset and F1-score of 0.88 for KVASIR dataset. Experiments show higher accuracy of the proposed method over traditional methods when classifying endoscopic colon diseases.
C1 [Poudel, Sahadev; Vo, Duc My; Lee, Sang-Woong] Gachon Univ, Dept Software, Seongnam 13557, South Korea.
   [Kim, Yoon Jae] Gachon Univ, Gil Med Ctr, Dept Internal Med, Incheon 21565, South Korea.
C3 Gachon University; Gachon University
RP Lee, SW (通讯作者)，Gachon Univ, Dept Software, Seongnam 13557, South Korea.
EM slee@gachon.ac.kr
RI Lee, Sang-Woong/ABF-6191-2020
OI Lee, Sang-Woong/0000-0001-8117-6566
FU Gyeonggi-do Regional Research Center (GRRC) program of Gyeonggi
   province; National Research Foundation of Korea (NRF) - Korea government
   (MSIT) [2020R1A2C1011708]
FX This work was supported by the Gyeonggi-do Regional Research Center
   (GRRC) program of Gyeonggi province [GRRC-Gachon2017(B01), Analysis of
   behavior based on senior life log] and the National Research Foundation
   of Korea (NRF) grant funded by the Korea government (MSIT)
   (2020R1A2C1011708).
CR Ahmed SS, 2017, MED BIOL ENG COMPUT, V55, P101, DOI 10.1007/s11517-016-1508-7
   Alammari Ali, 2017, P 9 INT C INFORM MAN, P139, DOI [10.1145/3149572.3149613, DOI 10.1145/3149572.3149613]
   Amato F, 2013, J APPL BIOMED, V11, P47, DOI 10.2478/v10136-012-0031-x
   Braithwaite D, 2016, AM CANC SOC CANC FAC
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Vo DM, 2019, INFORM SCIENCES, V482, P123, DOI 10.1016/j.ins.2018.12.089
   Ghiasi G, 2018, ADV NEUR IN, V31
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Han L, 2018, BIOINFORMATICS, V34, P985, DOI 10.1093/bioinformatics/btx651
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He YX, 2023, TRANSPORTMETRICA A, V19, DOI [10.1109/CVPR.2016.90, 10.1080/23249935.2022.2033348]
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Huang G., 2017, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2017.243, 10.1109/CVPR.2017.243]
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Mahapatra Dwarikanath, 2012, Abdominal Imaging. Computational and Clinical Applications. Proceedings of the 4th International Workshop. Held in Conjunction with MICCAI 2012, P97, DOI 10.1007/978-3-642-33612-6_11
   Mahapatra D, 2013, J DIGIT IMAGING, V26, P920, DOI 10.1007/s10278-013-9576-9
   Mossotto E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02606-2
   Nadeem S, 2018, LECT NOTES ARTIF INT, V11056, P469, DOI 10.1007/978-3-319-98446-9_44
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8040462
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sawant S, 2015, INT J COMPUT SCI NET, V15, P85
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Simonyan K, 2015, Arxiv
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stehle T, 2009, PROC SPIE, V7260, DOI 10.1117/12.808103
   Stidham RW, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3963
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wei ZS, 2013, I S BIOMED IMAGING, P141, DOI 10.1109/ICCCAS.2013.6765204
   Wimmer G, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.034504
   Wimmer G, 2016, INT C PATT RECOG, P2150, DOI 10.1109/ICPR.2016.7899954
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yu F., 2017, IEEE C COMPUTER VISI, P472, DOI DOI 10.1109/CVPR.2017.75
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Yun K, 2020, IEEE ACCESS, V8, P32502, DOI 10.1109/ACCESS.2020.2973390
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhou B., 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 49
TC 19
Z9 19
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 99227
EP 99238
DI 10.1109/ACCESS.2020.2996770
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LZ3KT
UT WOS:000541127800025
OA gold
DA 2023-04-20
ER

PT J
AU Qadir, HA
   Balasingham, I
   Solhusvik, J
   Bergsland, J
   Aabakken, L
   Shin, Y
AF Qadir, Hemin Ali
   Balasingham, Ilangko
   Solhusvik, Johannes
   Bergsland, Jacob
   Aabakken, Lars
   Shin, Younghak
TI Improving Automatic Polyp Detection Using CNN by Exploiting Temporal
   Dependency in Colonoscopy Video
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Detectors; Feature extraction; Sensitivity; Proposals; Colonoscopy;
   Convolutional neural networks; Cancer; Colonoscopy; polyp detection;
   computer aided diagnosis; convolutional neural networks; false positive
   learning; transfer learning; temporal information
ID VALIDATION
AB Automatic polyp detection has been shown to be difficult due to various polyp-like structures in the colon and high interclass variations in polyp size, color, shape, and texture. An efficient method should not only have a high correct detection rate (high sensitivity) but also a low false detection rate (high precision and specificity). The state-of-the-art detection methods include convolutional neural networks (CNN). However, CNNs have shown to be vulnerable to small perturbations and noise; they sometimes miss the same polyp appearing in neighboring frames and produce a high number of false positives. We aim to tackle this problem and improve the overall performance of the CNN-based object detectors for polyp detection in colonoscopy videos. Our method consists of two stages: a region of interest (RoI) proposal by CNN-based object detector networks and a false positive (FP) reduction unit. The FP reduction unit exploits the temporal dependencies among image frames in video by integrating the bidirectional temporal information obtained by RoIs in a set of consecutive frames. This information is used to make the final decision. The experimental results show that the bidirectional temporal information has been helpful in estimating polyp positions and accurately predict the FPs. This provides an overall performance improvement in terms of sensitivity, precision, and specificity compared to conventional false positive learning method, and thus achieves the state-of-the-art results on the CVC-ClinicVideoDB video data set.
C1 [Qadir, Hemin Ali] Oslo Univ Hosp, OmniVis Technol, Intervent Ctr, N-0337 Oslo, Norway.
   [Qadir, Hemin Ali; Solhusvik, Johannes] Univ Oslo, Dept Informat, N-0315 Oslo, Norway.
   [Balasingham, Ilangko; Bergsland, Jacob] Oslo Univ Hosp, Intervent Ctr, N-0337 Oslo, Norway.
   [Balasingham, Ilangko; Shin, Younghak] Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.
   [Solhusvik, Johannes] OmniVis Technol, N-0337 Oslo, Norway.
   [Aabakken, Lars] Univ Oslo, Fac Med, Dept Transplantat, N-0315 Oslo, Norway.
   [Aabakken, Lars] Oslo Univ Hosp, N-0337 Oslo, Norway.
C3 University of Oslo; University of Oslo; University of Oslo; Norwegian
   University of Science & Technology (NTNU); University of Oslo;
   University of Oslo
RP Shin, Y (通讯作者)，Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.
EM hemina.qadir@gmail.com; ilangko.balasingham@medisin.uio.no;
   johannes.solhusvik@ovt.com; jacobbergsland622@gmail.com;
   larsaa@medisin.uio.no; shinyh0919@gmail.com
RI Balasingham, Ilangko/AGU-7268-2022; Bergsland, Jacob/H-3966-2016
OI Bergsland, Jacob/0000-0002-3101-4064
FU Research Council of Norway through the industrial Ph.D. project
   [271542/O30]; Research Council of Norway through MELODY project
   [225885/O70]
FX This work was supported by Research Council of Norway through the
   industrial Ph.D. project under the contract number 271542/O30 and
   through the MELODY project under the contract number 225885/O70.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Angermann Q, 2016, PROCEDIA COMPUT SCI, V90, P182, DOI 10.1016/j.procs.2016.07.017
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P., 2018, J MED ROBOT RES, V3, P1840002, DOI DOI 10.1142/S2424905X18400020
   Davis P. J., 1975, INTERPOLATION APPROX
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Howard A. G., 2017, ARXIV170404861
   Huang J, 2017, IEEE INT C INT ROBOT, P3296
   Jurman G., 2009, P ADV RANKING NIPS 0, P22
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Narodytska N, 2017, IEEE COMPUT SOC CONF, P1310, DOI 10.1109/CVPRW.2017.172
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P1186, DOI 10.1016/S0002-9270(03)00183-7
   Redmon J, 2015, PROC CVPR IEEE, P779, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tajbakhsh N., 2018, US Patent App, Patent No. [15/562 088, 15562088]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 43
TC 39
Z9 40
U1 1
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD JAN
PY 2020
VL 24
IS 1
BP 180
EP 193
DI 10.1109/JBHI.2019.2907434
PG 14
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA KB6ZZ
UT WOS:000506642000019
PM 30946683
DA 2023-04-20
ER

PT J
AU Raju, BR
   Swamy, GN
   Raju, KP
AF Raju, B. Ratna
   Swamy, G. N.
   Raju, K. Padma
TI Diagnosis of colorectal cancer based on imperialist competitive
   algorithm
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Colorectal cancer (CRC); Colonoscopy; feature selection; imperialist
   competitive algorithm (ICA); k-Nearest Neighbor (k-NN) classifier
ID INFLAMMATORY-BOWEL-DISEASE; COLON-CANCER; MORTALITY
AB The Colorectal cancer leads to more number of death in recent years. The diagnosis of Colorectal cancer as early is safe to treat the patient. To identify and treat this type of cancer, Colonoscopy is applied commonly. The feature selection based methods are proposed which helps to choose the subset variables and to attain better prediction. An Imperialist Competitive Algorithm (ICA) is proposed which helps to select features in identification of colon cancer and its treatment. Also K-Nearest Neighbor (KNN) classifier is used to retain a minimal Euclidean distance between the feature of query vector and all the data in the nature of prototype training. Experimental results have proved that the proposed method is superior when compared to other methods in its metrics of performance. Better accuracy is achieved by the proposed method.
C1 [Raju, B. Ratna] Miracle Educ Soc Grp Inst, ECE, Bhogapuram, AP, India.
   [Swamy, G. N.] VR Siddhartha Engn Coll, Vijayawada, AP, India.
   [Raju, K. Padma] JNTUK, Univ Coll Engn, Kakinada, India.
   [Raju, K. Padma] APPSC, Itanagar, Arunachal Prade, India.
C3 Miracle Educational Society Group Of Institutions; Velagapudi
   Ramakrishna Siddhartha Engineering College; Jawaharlal Nehru
   Technological University - Kakinada
RP Raju, BR (通讯作者)，Miracle Educ Soc Grp Inst, ECE, Bhogapuram, AP, India.
EM ratnarajumes@gmail.com
RI Koppireddi, Padmaraju/AAO-2175-2021
OI Koppireddi, Padmaraju/0000-0001-7493-965X; BONASU, RATNA
   RAJU/0000-0002-5622-5773
CR Aleardi M., 2018, 37 CONV GRUPP NAZ GE, P172
   Ananthakrishnan AN, 2015, CLIN GASTROENTEROL H, V13, P322, DOI 10.1016/j.cgh.2014.07.018
   Andersen V, 2012, WORLD J GASTROENTERO, V18, P4091, DOI 10.3748/wjg.v18.i31.4091
   Archetti F, 2010, ARTIFICIAL LIFE AND EVOLUTIONARY COMPUTATION, P49, DOI 10.1142/9789814287456_0004
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Dehal AN, 2012, J CLIN ONCOL, V30, P53, DOI 10.1200/JCO.2011.38.0303
   Dienstmann R, 2015, J CLIN ONCOL, V33, P1787, DOI 10.1200/JCO.2014.60.0213
   Ebrahimi E, 2014, MEASUREMENT, V55, P196, DOI 10.1016/j.measurement.2014.05.003
   Elfouly F.H., 2014, INT J COMPUTING, V6, P23
   Halder S., 2013, THESIS
   Jess T, 2012, GASTROENTEROLOGY, V143, P375, DOI 10.1053/j.gastro.2012.04.016
   Keerthika G., 2015, J NETWORK COMMUNICAT, V1, P22
   Moraru L, 2011, AIP CONF PROC, V1387, DOI 10.1063/1.3647090
   Ogata-Kawata H, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092921
   Rad SM., 2012, INT J COMPUT APPL, V40, P41
   Rahmadwati, 2011, 2011 IEEE International Conference on Healthcare Informatics, Imaging and Systems Biology, P48, DOI 10.1109/HISB.2011.15
   Ratnaraju B., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI DOI 10.17485/ijst/2016/v9iS1/107929
   Sears CL, 2014, CELL HOST MICROBE, V15, P317, DOI 10.1016/j.chom.2014.02.007
   Sebastian S, 2014, J CROHNS COLITIS, V8, P5, DOI 10.1016/j.crohns.2013.04.008
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI 10.3322/caac.21220
   Tsai M.J., COLORECTAL CANC TISS
   Vieira SM, 2013, APPL SOFT COMPUT, V13, P3494, DOI 10.1016/j.asoc.2013.03.021
   Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457
   Xu JC, 2014, BIO-MED MATER ENG, V24, P1001, DOI 10.3233/BME-130897
   Zhao DD, 2019, J BIOMED INFORM, V92, DOI 10.1016/j.jbi.2019.103124
NR 25
TC 0
Z9 0
U1 1
U2 4
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2020
VL 39
IS 4
BP 5359
EP 5368
DI 10.3233/JIFS-189021
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OH1HF
UT WOS:000582322000054
DA 2023-04-20
ER

PT J
AU Rosenfeld, A
   Graham, DG
   Jevons, S
   Ariza, J
   Hagan, D
   Wilson, A
   Lovat, SJ
   Sami, SS
   Ahmad, OF
   Novelli, M
   Justo, MR
   Winstanley, A
   Heifetz, EM
   Ben-Zecharia, M
   Noiman, U
   Fitzgerald, RC
   Sasieni, P
   Lovat, LB
AF Rosenfeld, Avi
   Graham, David G.
   Jevons, Sarah
   Ariza, Jose
   Hagan, Daryl
   Wilson, Ash
   Lovat, Samuel J.
   Sami, Sarmed S.
   Ahmad, Omer F.
   Novelli, Marco
   Justo, Manuel Rodriguez
   Winstanley, Alison
   Heifetz, Eliyahu M.
   Ben-Zecharia, Mordehy
   Noiman, Uria
   Fitzgerald, Rebecca C.
   Sasieni, Peter
   Lovat, Laurence B.
CA BEST2 Study Grp
TI Development and validation of a risk prediction model to diagnose
   Barrett's oesophagus (MARK-BE): a case-control machine learning approach
SO LANCET DIGITAL HEALTH
LA English
DT Article
ID GASTROESOPHAGEAL-REFLUX DISEASE; ADENOCARCINOMA; DYSPLASIA; SYMPTOMS;
   COHORT
AB Background Screening for Barrett's oesophagus relies on endoscopy, which is invasive and few who undergo the procedure are found to have the condition. We aimed to use machine learning techniques to develop and externally validate a simple risk prediction panel to screen individuals for Barrett's oesophagus.
   Methods In this prospective study, machine learning risk prediction in Barrett's oesophagus (MARK-BE), we used data from two case-control studies, BEST2 and BOOST, to compile training and validation datasets. From the BEST2 study, we analysed questionnaires from 1299 patients, of whom 880 (67.7%) had Barrett's oesophagus, including 40 with invasive oesophageal adenocarcinoma, and 419 (32.3%) were controls. We randomly split (6:4) the cohort using a computer algorithm into a training dataset of 776 patients and a testing dataset of 523 patients. We compiled an external validation cohort from the BOOST study, which included 398 patients, comprising 198 patients with Barrett's oesophagus (23 with oesophageal adenocarcinoma) and 200 controls. We identified independently important diagnostic features of Barrett's oesophagus using the machine learning techniques information gain and correlation-based feature selection. We assessed multiple classification tools to create a multivariable risk prediction model. Internal validation of the model using the BEST2 testing dataset was followed by external validation using the BOOST external validation dataset. From these data we created a prediction panel to identify at-risk individuals.
   Findings The BEST2 study included 40 diagnostic features. Of these, 19 added information gain but after correlation-based feature selection only eight showed independent diagnostic value including age, sex, cigarette smoking, waist circumference, frequency of stomach pain, duration of heartburn and acidic taste, and taking antireflux medication, of which all were associated with increased risk of Barrett's oesophagus, except frequency of stomach pain, with was inversely associated in a case-control population. Logistic regression offered the highest prediction quality with an area under the receiver-operator curve (AUC) of 0.87 (95% CI 0.84-0.90; sensitivity set at 90%; specificity of 68%). In the testing dataset, AUC was 0.86 (0.83-0.89; sensitivity set at 90%; specificity of 65%). In the external validation dataset, the AUC was 0.81 (0.74-0.84; sensitivity set at 90%; specificity of 58%).
   Interpretation Our diagnostic model offers valid predictions of diagnosis of Barrett's oesophagus in patients with symptomatic gastro-oesophageal reflux disease, assisting in identifying who should go forward to invasive confirmatory testing. Our predictive panel suggests that overweight men who have been taking antireflux medication for a long time might merit particular consideration for further testing. Our risk prediction panel is quick and simple to administer but will need further calibration and validation in a prospective study in primary care. Copyright (C) 2019 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY 4.0 license.
C1 [Rosenfeld, Avi] Jerusalem Coll Technol, Dept Ind Engn, Jerusalem, Israel.
   [Heifetz, Eliyahu M.; Ben-Zecharia, Mordehy; Noiman, Uria] Jerusalem Coll Technol, Dept Hlth Informat, Jerusalem, Israel.
   [Rosenfeld, Avi; Graham, David G.; Jevons, Sarah; Ariza, Jose; Hagan, Daryl; Wilson, Ash; Lovat, Samuel J.; Sami, Sarmed S.; Ahmad, Omer F.; Lovat, Laurence B.] UCL, GENIE GastroENterol IntervEnt Grp, Dept Targeted Intervent, London, England.
   [Graham, David G.; Ariza, Jose; Sami, Sarmed S.; Ahmad, Omer F.; Lovat, Laurence B.] Univ Coll London Hosp, Gastrointestinal Serv, London, England.
   [Novelli, Marco; Justo, Manuel Rodriguez; Winstanley, Alison] Univ Coll London Hosp, Dept Pathol, London, England.
   [Fitzgerald, Rebecca C.] Univ Cambridge, Canc Unit, Cambridge, England.
   [Sasieni, Peter] Queen Mary Univ London, Canc Prevent Trials Unit, London, England.
   [Sasieni, Peter] Kings Coll London, Sch Canc & Pharmaceut Sci, London, England.
C3 University of London; University College London; University College
   London Hospitals NHS Foundation Trust; University College London
   Hospitals NHS Foundation Trust; University of London; University College
   London; University of Cambridge; University of London; Queen Mary
   University London; University of London; King's College London
RP Lovat, LB (通讯作者)，UCL, Div Surg & Intervent Sci, London W1W 7TS, England.
EM l.lovat@ucl.ac.uk
RI Heifetz, Eliyahu Meir/HLH-6027-2023; Lovat, Laurence/C-1986-2009
OI Heifetz, Eliyahu Meir/0000-0002-0396-0950; Hagan,
   Daryl/0000-0002-3549-2258; Fitzgerald, Rebecca/0000-0002-3434-3568;
   Lovat, Laurence/0000-0003-4542-3915; Sasieni, Peter/0000-0003-1509-8744;
   Bown, Stephen/0000-0002-5538-9303
FU Charles Wolfson Charitable Trust; Guts UK
FX Charles Wolfson Charitable Trust and Guts UK.
CR Alexandre L, 2012, DIS ESOPHAGUS, V25, P535, DOI 10.1111/j.1442-2050.2011.01285.x
   Anderson LA, 2007, WORLD J GASTROENTERO, V13, P1585, DOI 10.3748/wjg.v13.i10.1585
   Brown KF, 2018, BRIT J CANCER, V118, P1130, DOI 10.1038/s41416-018-0029-6
   Collins GS, 2015, EUR UROL, V67, P1142, DOI 10.1016/j.eururo.2014.11.025
   Deo RC, 2015, CIRCULATION, V132, P1920, DOI 10.1161/CIRCULATIONAHA.115.001593
   Di Caro S, 2016, EUR J GASTROEN HEPAT, V28, P251, DOI 10.1097/MEG.0000000000000536
   Eftekhar Behzad, 2005, BMC Med Inform Decis Mak, V5, P3
   Eloubeidi MA, 2001, J CLIN GASTROENTEROL, V33, P306, DOI 10.1097/00004836-200110000-00010
   Fitzgerald RC, 2014, GUT, V63, P7, DOI 10.1136/gutjnl-2013-305372
   Ford AC, 2005, AM J EPIDEMIOL, V162, P454, DOI 10.1093/aje/kwi218
   Gerson LB, 2001, AM J GASTROENTEROL, V96, P2005, DOI 10.1016/S0002-9270(01)02496-0
   Haidry RJ, 2015, ENDOSCOPY, V47, P980, DOI 10.1055/s-0034-1392414
   Elizondo JLH, 2017, REV GASTROENTEROL ME, V82, P296, DOI 10.1016/j.rgmx.2017.01.006
   Hippisley-Cox J, 2015, BMJ OPEN, V5, DOI 10.1136/bmjopen-2015-007825
   Hippisley-Cox J, 2013, BRIT J GEN PRACT, V63, DOI 10.3399/bjgp13X660724
   Hvid-Jensen F, 2011, NEW ENGL J MED, V365, P1375, DOI 10.1056/NEJMoa1103042
   Ireland CJ, 2017, DIS ESOPHAGUS, V30, DOI 10.1093/dote/dox033
   Ireland CJ, 2018, CLIN EXP GASTROENTER, V11, P135, DOI 10.2147/CEG.S158627
   Jiang X, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0143247
   Johansson J, 2007, SCAND J GASTROENTERO, V42, P148, DOI 10.1080/00365520600881037
   Kalousis A, 2007, KNOWL INF SYST, V12, P95, DOI 10.1007/s10115-006-0040-8
   Khalilia M, 2011, BMC MED INFORM DECIS, V11, DOI 10.1186/1472-6947-11-51
   Krittanawong C, 2017, J AM COLL CARDIOL, V69, P2657, DOI 10.1016/j.jacc.2017.03.571
   Kubo A, 2013, GUT, V62, P1684, DOI 10.1136/gutjnl-2012-303753
   Kunzmann AT, 2018, CLIN GASTROENTEROL H, V16, P1229, DOI 10.1016/j.cgh.2018.03.014
   Lagergren J, 2005, GUT, V54, pI1, DOI 10.1136/gut.2004.041517
   Lagergren J, 1999, NEW ENGL J MED, V340, P825, DOI 10.1056/NEJM199903183401101
   Langley NR, 2018, J FORENSIC SCI, V63, P31, DOI 10.1111/1556-4029.13534
   Lemaitre G, 2017, J MACH LEARN RES, V18
   Lipman G, 2017, ENDOSCOPY, V49, P1219, DOI 10.1055/s-0043-113441
   Liu XX, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094163
   Locke GR, 2003, GASTROINTEST ENDOSC, V58, P661, DOI 10.1016/S0016-5107(03)02011-X
   Maroco Joao, 2011, BMC Res Notes, V4, P299, DOI 10.1186/1756-0500-4-299
   Moturu ST, 2007, IEEE INT C BIOINFORM, P202, DOI 10.1109/BIBM.2007.54
   Nason KS, 2011, ARCH SURG-CHICAGO, V146, P851, DOI 10.1001/archsurg.2011.174
   Nie F., 2008, P 23 NAT C ART INT, P671
   Offman J, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-4664-3
   Offman Judith, 2017, Gastrointest Endosc Clin N Am, V27, P379, DOI 10.1016/j.giec.2017.02.002
   Park J, 2018, CLIN ENDOSC, V51, P317, DOI 10.5946/ce.2018.101
   Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337
   Rosenfeld A, 2019, AUTON AGENT MULTI-AG, V33, P673, DOI 10.1007/s10458-019-09408-y
   Ross-Innes CS, 2017, LANCET GASTROENTEROL, V2, P23, DOI 10.1016/S2468-1253(16)30118-2
   Ross-Innes CS, 2015, PLOS MED, V12, DOI 10.1371/journal.pmed.1001780
   Rubenstein JH, 2013, AM J GASTROENTEROL, V108, P353, DOI 10.1038/ajg.2012.446
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Shahid N, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212356
   Steevens J, 2011, CANCER EPIDEM BIOMAR, V20, P345, DOI 10.1158/1055-9965.EPI-10-0636
   Sun XQ, 2016, CANCER EPIDEM BIOMAR, V25, P727, DOI 10.1158/1055-9965.EPI-15-0832
   Thrift AP, 2014, CLIN GASTROENTEROL H, V12, P1267, DOI 10.1016/j.cgh.2013.12.014
   Thrift AP, 2012, CANCER PREV RES, V5, P1115, DOI 10.1158/1940-6207.CAPR-12-0010
   Thukkani N, 2010, ALIMENT PHARM THER, V31, P852, DOI 10.1111/j.1365-2036.2010.04245.x
   Wang P, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3214306
   Ward EM, 2006, AM J GASTROENTEROL, V101, P12, DOI 10.1111/j.1572-0241.2006.00379.x
   Xie SH, 2018, AM J GASTROENTEROL, V113, P829, DOI 10.1038/s41395-018-0069-9
   Zhang WS, 2009, 2009 INTERNATIONAL JOINT CONFERENCE ON BIOINFORMATICS, SYSTEMS BIOLOGY AND INTELLIGENT COMPUTING, PROCEEDINGS, P242, DOI 10.1109/IJCBS.2009.23
   Zhang XG, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-197
NR 56
TC 7
Z9 7
U1 3
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
EI 2589-7500
J9 LANCET DIGIT HEALTH
JI Lancet Digit. Health
PD JAN
PY 2020
VL 2
IS 1
BP E37
EP E48
DI 10.1016/S2589-7500(19)30216-X
PG 12
WC Medical Informatics; Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Medical Informatics; General & Internal Medicine
GA LD2PM
UT WOS:000525876500011
PM 32133440
OA gold, Green Published, Green Accepted
DA 2023-04-20
ER

PT J
AU Shahril, R
   Saito, A
   Shimizu, A
   Baharun, S
AF Shahril, Rosdiana
   Saito, Atsushi
   Shimizu, Akinobu
   Baharun, Sabariah
TI Bleeding Classification of Enhanced Wireless Capsule Endoscopy Images
   using Deep Convolutional Neural Network
SO JOURNAL OF INFORMATION SCIENCE AND ENGINEERING
LA English
DT Article
DE convolutional neural network; wireless capsule endoscopy; deep learning;
   classification; detection
AB This paper investigates the performance of a Deep Convolutional Neural Network (DCNN) algorithm to identify bleeding areas of wireless capsule endoscopy (WCE) images without known prior knowledge of bleeding and normal features of the images. In this study, a pre-processing technique has been proposed to improve the classification accuracy of WCE images into bleeding areas and normal areas by enhancing the WCE images. The proposed technique is applied to WCE images from six cases and divided into one training case and five test cases. To evaluate the effectiveness of the processes, the results were then compared between DCNN, SVM and Fuzzy, and also between DCNN with completely enhanced images and DCNN with normalized images. DCNN has shown to give a better result compared to SVM and Fuzzy logic; and the latter experiment has shown that the WCE images that have undergone the proposed enhancement technique gives better classification result compared to those images that did not go through the technique. The specificity, sensitivity and average are 0.8703, 0.8271 and 0.8907 respectively. In conclusion, DCNN has been proven to be able to successfully detecting bleeding areas from images without having any specific knowledge on imaging diagnosis or pathology.
C1 [Shahril, Rosdiana] Univ Malaysia Pahang, Fac Comp Syst & Software Engn, Pahang, Malaysia.
   [Saito, Atsushi; Shimizu, Akinobu] Tokyo Univ Agr & Technol, Tokyo, Japan.
   [Baharun, Sabariah] Univ Teknol Malaysia, Malaysia Japan Int Inst Technol, Kuala Lumpur, Malaysia.
C3 Universiti Malaysia Pahang; Tokyo University of Agriculture &
   Technology; Universiti Teknologi Malaysia
RP Shahril, R (通讯作者)，Univ Malaysia Pahang, Fac Comp Syst & Software Engn, Pahang, Malaysia.
EM rosdiana@ump.edu.my; a-saito@go.tuat.ac.jp; simiz@cc.tuat.ac.jp;
   sabariahb@utm.my
RI shahril, rosdiana/AAV-4457-2020; SHIMIZU, Akinobu/G-1085-2013
OI shahril, rosdiana/0000-0003-1114-087X
FU Universiti Malaysia Pahang (UMP) Research Grant Scheme (RDU) [1803147];
   Tokyo University of Agriculture and Technology (TUAT); Japan Student
   Services Organization (JASSO)
FX This work is supported by Universiti Malaysia Pahang (UMP) Research
   Grant Scheme (RDU No. 1803147), Tokyo University of Agriculture and
   Technology (TUAT) and Japan Student Services Organization (JASSO).
CR [Anonymous], 2014, INT C INFORMATICS EL
   Charfi S., 2018, IEEE T LEARN TECHNOL, P1, DOI DOI 10.1109/TLT.2017.2720670
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ghosh T, 2014, IEEE ENG MED BIO, P4683, DOI 10.1109/EMBC.2014.6944669
   Ghosh T, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2017.2756034
   Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Iakovidis D, 2014, GLOB J GASTROENTEROL, V2, P11, DOI DOI 10.12970/2308-6483.2014.02.01.3
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Khachane M. Y., 2014, IJCA P NAT C REC ADV, P28
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Li XL, 2017, IEEE ENG MED BIO, P1994, DOI 10.1109/EMBC.2017.8037242
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Pannu HS, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P1054, DOI 10.1109/ICCMC.2017.8282632
   Paulus D, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P161, DOI 10.1109/ICIP.1998.723449
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Shahril R., 2015, INT J COMPUTER ASSIS, V10, pS292
   Shahril R., 2016, INT J ELECT COMPUT E, V6, ppp1617, DOI [10.11591/ijece.v6i4, DOI 10.11591/IJECE.V6I4]
   Shahril R, 2014, 2014 IEEE CONFERENCE ON BIOMEDICAL ENGINEERING AND SCIENCES (IECBES), P922, DOI 10.1109/IECBES.2014.7047646
   SHAHROKHI-SHAHRAKI R, 2014, P IEEE PES GEN M, P1
   Sindhu C.P, 2017, ICIIECS, P1, DOI [10.1109/iciiecs.2017.8276073, DOI 10.1109/ICIIECS.2017.8276073]
   Suman S., 2016, INT C SIGN INF PROC, P1
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Wimmer G, 2016, INT CONF IMAG PROC
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 30
TC 5
Z9 5
U1 3
U2 9
PU INST INFORMATION SCIENCE
PI TAIPEI
PA ACADEMIA SINICA, TAIPEI 115, TAIWAN
SN 1016-2364
J9 J INF SCI ENG
JI J. Inf. Sci. Eng.
PD JAN
PY 2020
VL 36
IS 1
BP 91
EP 108
DI 10.6688/JISE.202001_36(1).0006
PG 18
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU5TA
UT WOS:000519773900006
DA 2023-04-20
ER

PT J
AU Sharma, P
   Bora, K
   Kasugai, K
   Balabantaray, BK
AF Sharma, Pallabi
   Bora, Kangkana
   Kasugai, Kunio
   Balabantaray, Bunil Kumar
TI Two Stage Classification with CNN for Colorectal Cancer Detection
SO ONCOLOGIE
LA English
DT Article
DE Colon cancer; deep learning; polyps detection; CNN; colonoscopy
ID HIGHLIGHT REMOVAL; ARCHITECTURES
AB In this paper, we address a current problem in medical image processing, the detection of colorectal cancer from colonoscopy videos. According to worldwide cancer statistics, colorectal cancer is one of the most common cancers. The process of screening and the removal of pre-cancerous cells from the large intestine is a crucial task to date. The traditional manual process is dependent on the expertise of the medical practitioner. In this paper, a two-stage classification is proposed to detect colorectal cancer. In the first stage, frames of colonoscopy video are extracted and are rated as significant if it contains a polyp, and these results are then aggregated in a second stage to come to an overall decision concerning the final classification of that frame to be neoplastic and non-neoplastic. In doing so, a comparative study is being made by considering the applicability of deep learning to perform this two-stage classification. The CNN models namely VGG16, VGG19, Inception V3, Xception, GoogLeNet, ResNet50, ResNet100, DenseNet, NASNetMobile, MobilenetV2, InceptionResNetV2 and fine-tuned version of each model is evaluated. It is observed that the VGG19 model is the best deep learning method for colonoscopy image diagnosis.
C1 [Sharma, Pallabi; Balabantaray, Bunil Kumar] Natl Inst Technol Meghalaya, Dept Comp Sci & Engn, Shillong 793003, Meghalaya, India.
   [Bora, Kangkana] Cotton Univ, Comp Sci & Informat Technol, Gauhati 781001, India.
   [Kasugai, Kunio] Aichi Med Univ, Dept Gastroenterol, Nagakute, Aichi 4801195, Japan.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Meghalaya; Aichi Medical University
RP Sharma, P (通讯作者)，Natl Inst Technol Meghalaya, Dept Comp Sci & Engn, Shillong 793003, Meghalaya, India.
EM pallabishrma@nitm.ac.in
RI Balabantaray, Bunil Kumar/M-9711-2013
OI Balabantaray, Bunil Kumar/0000-0002-2769-7122; SHARMA,
   PALLABI/0000-0003-3447-9251
CR Akbari M, 2018, IEEE ENG MED BIO, P65, DOI 10.1109/EMBC.2018.8512226
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eaden JA, 2000, GASTROINTEST ENDOSC, V51, P123, DOI 10.1016/S0016-5107(00)70405-6
   Gao YF, 2017, PROCEDIA COMPUT SCI, V107, P762, DOI 10.1016/j.procs.2017.03.161
   Geng DQ, 2019, IEEE ACCESS, V7, P44574, DOI 10.1109/ACCESS.2019.2909060
   Ghesu FC, 2019, IEEE T PATTERN ANAL, V41, P176, DOI 10.1109/TPAMI.2017.2782687
   Graham S, 2019, MED IMAGE ANAL, V52, P199, DOI 10.1016/j.media.2018.12.001
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   He K., 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46493-0_38
   He TC, 2019, JCO CLIN CANCER INFO, V3, P1, DOI 10.1200/CCI.18.00121
   Howard A. G., 2017, ARXIV170404861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang J, 2019, IEEE T MED IMAGING, V38, P134, DOI 10.1109/TMI.2018.2857800
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Ksiazek W, 2019, COGN SYST RES, V54, P116, DOI 10.1016/j.cogsys.2018.12.001
   Li C, 2019, MED IMAGE ANAL, V53, P165, DOI 10.1016/j.media.2019.01.013
   Morgand A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P274
   Nasr-Esfahani E, 2019, COMPUT MED IMAG GRAP, V78, DOI 10.1016/j.compmedimag.2019.101658
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Qi XF, 2019, MED IMAGE ANAL, V52, P185, DOI 10.1016/j.media.2018.12.006
   Queiroz F, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P282, DOI 10.1109/SIBGRAPI.2014.18
   Saikia AR, 2019, TISSUE CELL, V57, P8, DOI 10.1016/j.tice.2019.02.001
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Simonyan K, 2015, Arxiv
   Sonnenberg A, 2000, ANN INTERN MED, V133, P573, DOI 10.7326/0003-4819-133-8-200010170-00007
   Sun WQ, 2017, COMPUT MED IMAG GRAP, V57, P4, DOI 10.1016/j.compmedimag.2016.07.004
   Sundaram PS, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1153-9
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tan K, 2017, PROC SPIE, V10420, DOI 10.1117/12.2285403
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P1304, DOI 10.1109/TPAMI.2014.2360402
   Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7
   Yu DH, 2014, SIGNAL PROCESS, V103, P367, DOI 10.1016/j.sigpro.2013.11.021
   Zhang S, 2019, COMPUT MED IMAG GRAP, V77, DOI 10.1016/j.compmedimag.2019.101645
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 43
TC 4
Z9 5
U1 1
U2 11
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1292-3818
EI 1765-2839
J9 ONCOLOGIE
JI Oncologie
PY 2020
VL 22
IS 3
BP 129
EP 145
DI 10.32604/oncologie.2020.013870
PG 17
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA PI7AR
UT WOS:000601239800002
OA hybrid
DA 2023-04-20
ER

PT J
AU Shung, DL
   Au, B
   Taylor, RA
   Tay, JK
   Laursen, SB
   Stanley, AJ
   Dalton, HR
   Ngu, J
   Schultz, M
   Laine, L
AF Shung, Dennis L.
   Au, Benjamin
   Taylor, Richard Andrew
   Tay, J. Kenneth
   Laursen, Stig B.
   Stanley, Adrian J.
   Dalton, Harry R.
   Ngu, Jeffrey
   Schultz, Michael
   Laine, Loren
TI Validation of a Machine Learning Model That Outperforms Clinical Risk
   Scoring Systems for Upper Gastrointestinal Bleeding
SO GASTROENTEROLOGY
LA English
DT Article
DE Artificial Intelligence; Prognostic Factor; Mortality; Prediction
ID IN-HOSPITAL MORTALITY; PREDICT MORTALITY; HEMORRHAGE; MANAGEMENT;
   EPIDEMIOLOGY; REGRESSION; REGULARIZATION; DIAGNOSIS; CONSENSUS;
   SELECTION
AB BACKGROUND & AIMS: Scoring systems are suboptimal for determining risk in patients with upper gastrointestinal bleeding (UGIB); these might be improved by a machine learning model. Weused machine learning to develop amodel to calculate the risk of hospital-based intervention or death in patients with UGIB and compared its performance with other scoring systems. METHODS: We analyzed data collected from consecutive unselected patients with UGIB from medical centers in 4 countries (the United States, Scotland, England, and Denmark; n = 1958) from March 2014 through March 2015. We used the data to derive and internally validate a gradient-boosting machine learning model to identify patients who met a composite endpoint of hospital-based intervention (transfusion or hemostatic intervention) or death within 30 days. We compared the performance of the machine learning prediction model with validated pre-endoscopic clinical risk scoring systems (the Glasgow-Blatchford score [GBS], admission Rockall score, and AIMS65). We externally validated the machine learningmodel using data from 2 Asia-Pacific sites (Singapore and New Zealand; n = 399). Performance was measured by area under receiver operating characteristic curve (AUC) analysis. RESULTS: The machine learning model identified patients who met the composite endpoint with an AUC of 0.91 in the internal validation set; the clinical scoring systems identified patients who met the composite endpoint with AUC values of 0.88 for the GBS (P =.001), 0.73 for Rockall score (P <.001), and 0.78 for AIMS65 score (P <.001). In the external validation cohort, the machine learning model identified patients who met the composite endpoint with an AUC of 0.90, the GBS with an AUC of 0.87 (P =.004), the Rockall score with an AUC of 0.66 (P <.001), and the AIMS65 with an AUC of 0.64 (P <.001). At cutoff scores at which the machine learning model and GBS identified patients who met the composite endpoint with 100% sensitivity, the specificity values were 26% with the machine learning model versus 12% with GBS (P <.001). CONCLUSIONS: We developed a machine learning model that identifies patients with UGIB who met a composite endpoint of hospital-based intervention or death within 30 days with a greater AUC and higher levels of specificity, at 100% sensitivity, than validated clinical risk scoring systems. This model could increase identification of low-risk patients who can be safely discharged from the emergency department for outpatient management.
C1 [Shung, Dennis L.; Au, Benjamin; Taylor, Richard Andrew; Laine, Loren] Yale Sch Med, New Haven, CT USA.
   [Tay, J. Kenneth] Stanford Univ, Palo Alto, CA 94304 USA.
   [Laursen, Stig B.] Odense Univ Hosp, Odense, Denmark.
   [Stanley, Adrian J.] Glasgow Royal Infirm, Glasgow, Lanark, Scotland.
   [Dalton, Harry R.] Royal Cornwall Hosp, Truro, Cornwall, England.
   [Ngu, Jeffrey] Christchurch Hosp, Christchurch, New Zealand.
   [Schultz, Michael] Dunedin Publ Hosp, Dunedin, New Zealand.
   [Laine, Loren] Vet Affairs Connecticut Healthcare Syst, West Haven, CT USA.
C3 Yale University; Stanford University; University of Southern Denmark;
   Odense University Hospital; University of Glasgow; Royal Cornwall
   Hospital; Christchurch Hospital New Zealand; Dunedin Public Hospital; US
   Department of Veterans Affairs; Veterans Health Administration (VHA); VA
   Connecticut Healthcare System
RP Shung, DL; Laine, L (通讯作者)，Yale Sch Med, Sect Digest Dis, POB 208019, New Haven, CT 06520 USA.
EM dennis.shung@yale.edu; loren.laine@yale.edu
RI Laursen, Stig Borbjerg/ABG-6317-2021
OI Schultz, Michael/0000-0003-3116-0747; Laursen, Stig/0000-0002-5268-6599;
   Tay, Jingyi/0000-0003-3046-1820
FU National Institutes of Health [T32 DK007017]
FX This work was supported by the National Institutes of Health (T32
   DK007017 to Dennis Shung).
CR Abougergi MS, 2015, GASTROINTEST ENDOSC, V81, P882, DOI 10.1016/j.gie.2014.09.027
   Barkun AN, 2010, ANN INTERN MED, V152, P101, DOI 10.7326/0003-4819-152-2-201001190-00009
   Blatchford O, 1997, BMJ-BRIT MED J, V315, P510, DOI 10.1136/bmj.315.7107.510
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen Tianqi, XGBOOST SCALABLE TRE
   Czernichow P, 2000, EUR J GASTROEN HEPAT, V12, P175, DOI 10.1097/00042737-200012020-00007
   D'Amico G, 2003, HEPATOLOGY, V38, P599, DOI 10.1053/jhep.2003.50385
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   GRALNEK IM, 2015, ENDOSCOPY, V47, pA1, DOI [DOI 10.1055/S-0034-1393172, 10.1055/s-0034-1393172]
   Hearnshaw SA, 2011, GUT, V60, P1327, DOI 10.1136/gut.2010.228437
   Hecht-Nielsen R, 1992, NEURAL NETWORKS PERC, P65, DOI [DOI 10.1016/0893-6080(88)90469-8, DOI 10.1016/B978-0-12-741252-8.50010-8]
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Kennedy EH, 2013, MED CARE, V51, P251, DOI 10.1097/MLR.0b013e31827da594
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Laine L, 2012, AM J GASTROENTEROL, V107, P345, DOI 10.1038/ajg.2011.480
   Lanas A, 2009, AM J GASTROENTEROL, V104, P1633, DOI 10.1038/ajg.2009.164
   Lee HH, 2018, DIGEST LIVER DIS, V50, P247, DOI 10.1016/j.dld.2017.11.006
   LONGSTRETH GF, 1995, AM J GASTROENTEROL, V90, P206
   Lyles T, 2014, J CLIN GASTROENTEROL, V48, P712, DOI 10.1097/MCG.0000000000000014
   Motwani M, 2017, EUR HEART J, V38, P500, DOI 10.1093/eurheartj/ehw188
   Nahon S, 2012, ENDOSCOPY, V44, P998, DOI 10.1055/s-0032-1310006
   Paspatis GA, 2000, EUR J GASTROEN HEPAT, V12, P1215, DOI 10.1097/00042737-200012110-00008
   Peery AF, 2019, GASTROENTEROLOGY, V156, P254, DOI [10.1053/j.gastro.2015.08.045, 10.1053/j.gastro.2018.08.063]
   Ramaekers R, 2016, ACAD EMERG MED, V23, P1218, DOI 10.1111/acem.13101
   ROCKALL TA, 1995, BRIT MED J, V311, P222, DOI 10.1136/bmj.311.6999.222
   Rotondano G, 2011, GASTROINTEST ENDOSC, V73, P218, DOI 10.1016/j.gie.2010.10.006
   Saltzman JR, 2011, GASTROINTEST ENDOSC, V74, P1215, DOI 10.1016/j.gie.2011.06.024
   Samad MD, 2019, JACC-CARDIOVASC IMAG, V12, P681, DOI 10.1016/j.jcmg.2018.04.026
   Shimabukuro DW, 2017, BMJ OPEN RESPIR RES, V4, DOI 10.1136/bmjresp-2017-000234
   Shung D, 2019, DIGEST DIS SCI, V64, P2078, DOI 10.1007/s10620-019-05645-z
   Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623
   Stanley AJ, 2009, LANCET, V373, P42, DOI 10.1016/S0140-6736(08)61769-9
   Stanley Adrian J, 2017, BMJ, V356, pi6432, DOI 10.1136/bmj.i6432
   Steyerberg EW, 2018, J CLIN EPIDEMIOL, V103, P131, DOI 10.1016/j.jclinepi.2018.07.010
   Sung JJY, 2018, GUT, V67, P1757, DOI 10.1136/gutjnl-2018-316276
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   van Leerdam ME, 2008, BEST PRACT RES CL GA, V22, P209, DOI 10.1016/j.bpg.2007.10.011
   Vreeburg EM, 1997, AM J GASTROENTEROL, V92, P236
   Wickham H, 2016, GGPLOT2 ELEGANT GRAP
   Wilson FP, 2015, LANCET, V385, P1966, DOI 10.1016/S0140-6736(15)60266-5
   Wong A, 2018, JAMA NETW OPEN, V1, DOI 10.1001/jamanetworkopen.2018.1018
   Wuerth BA, 2018, DIGEST DIS SCI, V63, P1286, DOI 10.1007/s10620-017-4882-6
   YAVORSKI RT, 1995, AM J GASTROENTEROL, V90, P568
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 47
TC 78
Z9 79
U1 2
U2 27
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD JAN
PY 2020
VL 158
IS 1
BP 160
EP 167
DI 10.1053/j.gastro.2019.09.009
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA JV7NZ
UT WOS:000502549500035
PM 31562847
OA Green Published, Green Accepted
DA 2023-04-20
ER

PT J
AU Sun, MY
   Liang, KY
   Zhang, WB
   Chang, Q
   Zhou, XG
AF Sun, Muyi
   Liang, Kaiyi
   Zhang, Wenbao
   Chang, Qing
   Zhou, Xiaoguang
TI Non-Local Attention and Densely-Connected Convolutional Neural Networks
   for Malignancy Suspiciousness Classification of Gastric Ulcer
SO IEEE ACCESS
LA English
DT Article
DE Gastric ulcer; attention mechanism; malignancy suspiciousness
   classification; densely-connected neural network; medical image analysis
ID SYSTEM; TUMOR
AB Gastric ulcer is one of the most common types of stomach disease. Malignancy suspiciousness classification of gastric ulcer is a crucial indicator for early cancer detection and prognosis. Technically, this problem suffers from the complexity and variability of endoscopic pathological images. For addressing these challenges, we propose a deep learning based classification neural network which combines the densely-connected architecture and non-local attention mechanism. Structurally, we add the attention block into the cascaded dense blocks for catching more contextual information and enhancing the correlation between pixels and regions. Experimentally, we implement sufficient experiments on our own gastroscopic image dataset, which is delicately annotated twice per image by medical specialists. Quantitative comparisons against several prior state-of-the-art methods demonstrate the superiority of our approach. As a result, we achieve an overall diagnostic accuracy of 96.79 %, a recall of 94.92% and an F1-score of 94.70 %, close to the diagnostic level of a gastroenterologist. The area under the receiver operating characteristic (ROC) curves of the deep learning model achieve an average of 0.93.
C1 [Sun, Muyi; Zhang, Wenbao] Beijing Univ Posts & Telecommun, Sch Automat, Beijing 100876, Peoples R China.
   [Sun, Muyi; Zhang, Wenbao] Beijing Univ Posts & Telecommun, Engn Res Ctr Informat Network, Minist Educ, Beijing 100876, Peoples R China.
   [Chang, Qing] Shanghai Univ Med & Hlth Sci, Jiading Dist Cent Hosp Affiliated, Dept Radiol, Shanghai Gen Practice Med Educ & Res Ctr, Shanghai 201800, Peoples R China.
   [Liang, Kaiyi; Chang, Qing] Shanghai Univ Med & Hlth Sci, Jiading Dist Cent Hosp Affiliated, Shanghai 201800, Peoples R China.
   [Zhou, Xiaoguang] Minjiang Univ, Fuzhou 350108, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications; Shanghai University of Medicine & Health
   Sciences; Shanghai University of Medicine & Health Sciences; Minjiang
   University
RP Chang, Q (通讯作者)，Shanghai Univ Med & Hlth Sci, Jiading Dist Cent Hosp Affiliated, Dept Radiol, Shanghai Gen Practice Med Educ & Res Ctr, Shanghai 201800, Peoples R China.; Liang, KY; Chang, Q (通讯作者)，Shanghai Univ Med & Hlth Sci, Jiading Dist Cent Hosp Affiliated, Shanghai 201800, Peoples R China.; Zhou, XG (通讯作者)，Minjiang Univ, Fuzhou 350108, Peoples R China.
EM lkyieee@126.com; robie0510@hotmail.com; zxg@bupt.edu.cn
RI Sun, Muyi/ABA-4342-2021
FU Open Foundation of State key Laboratory of Networking and Switching
   Technology, Beijing University of Posts and Telecommunications
   [SKLNST-2018-1-18]
FX This work was supported in part by the Open Foundation of State key
   Laboratory of Networking and Switching Technology, Beijing University of
   Posts and Telecommunications, under Grant SKLNST-2018-1-18.
CR Aggarwal N, 2006, IEEE T IMAGE PROCESS, V15, P582, DOI 10.1109/TIP.2005.863021
   Alvarenga AV, 2007, MED PHYS, V34, P379, DOI 10.1118/1.2401039
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Bashar MK, 2008, LECT NOTES COMPUT SC, V5242, P603, DOI 10.1007/978-3-540-85990-1_72
   Bi C., 2000, CHIN J GASTROENTEROL, V5, P240, DOI [10.3969/j.issn.1008-7125.2000.04.014, DOI 10.3969/J.ISSN.1008-7125.2000.04.014]
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Fu Y., 2011, ADV MATER RES-SWITZ, P1
   Gao WS, 2010, INT CONF COMP SCI, P67, DOI 10.1109/ICCSIT.2010.5563693
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GL, 2017, IEEE ICC
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iandola FN, 2016, SQUEEZENET ALEXNET L
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Lin X, 2019, IEEE T IND INFORM, V15, P6367, DOI 10.1109/TII.2019.2917307
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853
   Morgagni P., 2012, SURG MULTIMODAL MANA, P81
   Nawarathna RD, 2010, LECT NOTES COMPUT SC, V6165, P153, DOI 10.1007/978-3-642-13923-9_16
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Ping Tian D., 2013, INT J MULTIMED UBIQU, V8, P385
   Qin YX, 2020, IEEE T IND INFORM, V16, P6324, DOI 10.1109/TII.2019.2963434
   Shen W, 2017, PATTERN RECOGN, V61, P663, DOI 10.1016/j.patcog.2016.05.029
   Simonyan K, 2015, Arxiv
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu J, 2019, IEEE COMMUN MAG, V57, P48, DOI 10.1109/MCOM.2019.1800778
   [吴英 Wu Ying], 2019, [中国医学影像技术, Chinese Journal of Medical Imaging Technology], V35, P357
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
   Zhang S, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P2374, DOI 10.1109/ICMLC.2009.5212217
NR 50
TC 10
Z9 10
U1 2
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 15812
EP 15822
DI 10.1109/ACCESS.2020.2967350
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LB6LA
UT WOS:000524744100001
OA gold
DA 2023-04-20
ER

PT J
AU Sun, Z
   Yan, XY
AF Sun Zheng
   Yan Xiangyang
TI Image reconstruction based on compressed sensing for sparse-data
   endoscopic photoacoustic tomography
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Endoscopic photoacoustic tomography (EPAT); Image reconstruction; Sparse
   measurement; Compressed sensing (CS); Time reversal (TR)
ID NEURAL-NETWORK; IN-VIVO
AB Endoscopic photoacoustic tomography (EPAT) is an interventional application of photoacoustic tomography (PAT) to visualize anatomical features and functional components of biological cavity structures such as nasal cavity, digestive tract or coronary arterial vessels. One of the main challenges in clinical applicability of EPAT is the incomplete acoustic measurements due to the limited detectors or the limited-view acoustic detection enclosed in the cavity. In this case, conventional image reconstruction methodologies suffer from significantly degraded image quality. This work introduces a compressed-sensing (CS)-based method to reconstruct a high-quality image that represents the initial pressure distribution on a luminal cross-section from incomplete discrete acoustic measurements. The method constructs and trains a complete dictionary for the sparse representation of the photoacoustically-induced acoustic measurements. The sparse representation of the complete acoustic signals is then optimally obtained based on the sparse measurements and a sensing matrix. The complete acoustic signals are recovered from the sparse representation by inverse sparse transformation. The image of the initial pressure distribution is finally reconstructed from the recovered complete signals by using the time reversal (TR) algorithm. It was shown with numerical experiments that high-quality images with reduced under-sampling artifacts can be reconstructed from sparse measurements. The comparison results suggest that the proposed method outperforms the standard TR reconstruction by 40% in terms of the structural similarity of the reconstructed images.
C1 [Sun Zheng; Yan Xiangyang] North China Elect Power Univ, Dept Elect & Commun Engn, Baoding 071003, Peoples R China.
C3 North China Electric Power University
RP Yan, XY (通讯作者)，North China Elect Power Univ, POB 21, Baoding 071003, Peoples R China.
EM sunzheng_tju@163.com
CR Antholzer S., 2019, NETT REGULARIZATION
   Antholzer S, 2019, INVERSE PROBL SCI EN, V27, P987, DOI 10.1080/17415977.2018.1518444
   Arridge S, 2016, PHYS MED BIOL, V61, P8908, DOI 10.1088/1361-6560/61/24/8908
   Bu S, 2010, P 3 BIOM ENG INT C, P129
   Cai CJ, 2018, OPT LETT, V43, P2752, DOI 10.1364/OL.43.002752
   Cai N, 2018, SIGNAL IMAGE VIDEO P, V12, P133, DOI 10.1007/s11760-017-1139-y
   Cao YC, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20881-5
   Chaudhary G, 2010, PROC SPIE, V7564, DOI 10.1117/12.842607
   Foucart S., 2013, MATH INTRO COMPRESSI, P133
   Guo ZJ, 2010, J BIOMED OPT, V15, DOI 10.1117/1.3381187
   Haltmeier M., 2017, NEW SPARSIFICATION R
   Haltmeier M, 2018, J ACOUST SOC AM, V143, P3838, DOI 10.1121/1.5042230
   Haltmeier M, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/11/114004
   Hauptmann A, 2018, IEEE T MED IMAGING, V37, P1382, DOI 10.1109/TMI.2018.2820382
   Hoelen CGA, 2000, APPL OPTICS, V39, P5872, DOI 10.1364/AO.39.005872
   Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099
   Jing Meng, 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P717, DOI 10.1109/BHI.2012.6211683
   Kostli KP, 2003, APPL OPTICS, V42, P1899, DOI 10.1364/AO.42.001899
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu FY, 2019, BIOMED OPT EXPRESS, V10, P1660, DOI 10.1364/BOE.10.001660
   Liu XY, 2016, CHIN CONTR CONF, P2201, DOI 10.1109/ChiCC.2016.7553694
   Liu XY, 2012, INT J BIOMED IMAGING, V2012, DOI 10.1155/2012/206214
   Liu XY, 2013, APPL OPTICS, V52, P3477, DOI 10.1364/AO.52.003477
   Liu XY, 2012, PROC SPIE, V8313, DOI 10.1117/12.911152
   Ma SB, 2009, J APPL PHYS, V106, DOI 10.1063/1.3273322
   Meng J, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.7.076007
   Meng J, 2012, OPT EXPRESS, V20, P16510, DOI 10.1364/OE.20.016510
   Poudel J, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab2017
   Prakash J, 2019, IEEE T MED IMAGING, V38, P1935, DOI 10.1109/TMI.2018.2889314
   Provost J, 2009, IEEE T MED IMAGING, V28, P585, DOI 10.1109/TMI.2008.2007825
   Schwab J., 2019, DEEP LEARNING TRUNCA
   Sreedevi G., 2019, IEEE J SEL TOP QUANT, V25
   Sun Z, 2016, COMPUT BIOL MED, V76, P60, DOI 10.1016/j.compbiomed.2016.06.028
   Syed TA, 2016, IEEE T COMPUT IMAG, V2, P540, DOI 10.1109/TCI.2016.2615806
   Wang J, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7050505
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang LZ, 2007, ACTA PHYS SIN-CH ED, V56, P3911, DOI 10.7498/aps.56.3911
   Xu MH, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.016706
   Xu Y, 2004, PHYS REV LETT, V92, DOI 10.1103/PhysRevLett.92.033902
   Yang D.W., 2005, ACTA OPT SINICA, V6047
   Yang DW, 2010, CHINESE PHYS LETT, V27, DOI 10.1088/0256-307X/27/5/054301
   Yao JJ, 2018, CURR OPIN CHEM BIOL, V45, P104, DOI 10.1016/j.cbpa.2018.03.016
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
NR 43
TC 7
Z9 9
U1 0
U2 17
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD JAN
PY 2020
VL 116
AR 103587
DI 10.1016/j.compbiomed.2019.103587
PG 13
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA KM2TU
UT WOS:000513976500038
PM 32001014
DA 2023-04-20
ER

PT J
AU Wang, SQ
   Wang, SD
   Zhang, S
   Fan, FF
   He, GW
AF Wang, Shaoqiang
   Wang, Shudong
   Zhang, Song
   Fan, Fangfang
   He, Gewen
TI Research on Recognition of Medical Image Detection Based on Neural
   Network
SO IEEE ACCESS
LA English
DT Article
DE Cancer; Tumors; Magnetic resonance imaging; Pancreas; Medical diagnostic
   imaging; Neural networks; Neural network; fecal occult blood detection;
   error back propagation neural network; medical image
ID RESECTION MARGIN; CT-COLONOGRAPHY; RECTAL-CANCER; COLONOSCOPY;
   METAANALYSIS; POPULATION; PREDICTION; EMPHASIS
AB Bowel cancer, which is easily affected by diet and drugs, has some restrictive factors such as the fecal occult blood test (FOBT) in the routine detection and the high cost and inconvenience of microscopy. In order to break through these restrictive factors, a possible alternative method of FOBT is sought. In this paper, error back propagation neural network (BPNN) algorithm is used, and expression spectrum is used as an auxiliary method to detect medical images, and a colorectal cancer (CRC) diagnosis model based on neural network is constructed. The results show that the accuracy of the model on the training set and the test set are 0.943 and 0.935, respectively, the AUC reaches more than 0.95. Therefore, the CRC diagnosis model based on neural network provides a possible alternative method of FOBT. Experimental results show that the proposed algorithm have high robustness and accuracy, which meets the current clinical needs.
C1 [Wang, Shaoqiang; Wang, Shudong] China Univ Petr East China, Sch Comp & Commun Engn, Qingdao 266000, Peoples R China.
   [Zhang, Song] Qingdao Univ, Affiliated Hosp, Qingdao 266000, Peoples R China.
   [Fan, Fangfang] Harvard Univ, Harvard Med Sch, Cambridge, MA 02215 USA.
   [He, Gewen] Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA.
C3 China University of Petroleum; Qingdao University; Harvard University;
   State University System of Florida; Florida State University
RP Fan, FF (通讯作者)，Harvard Univ, Harvard Med Sch, Cambridge, MA 02215 USA.
EM 1505376552@qq.com
RI Fan, Fang/GRO-2696-2022; fan, fang/GQY-9173-2022
OI Fan, Fangfang/0000-0001-7658-7221
FU National Natural Science Foundation of China [61873281, 61572522,
   61502535, 61972416, 61672248]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61873281, Grant 61572522, Grant 61502535, Grant
   61972416, and Grant 61672248.
CR Anderson JC, 2001, GASTROINTEST ENDOSC, V54, P558, DOI 10.1067/mge.2001.118950
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Beets-Tan RGH, 2004, RADIOLOGY, V232, P335, DOI 10.1148/radiol.2322021326
   Beets-Tan RGH, 2001, LANCET, V357, P497, DOI 10.1016/S0140-6736(00)04040-X
   Blomqvist L, 2000, EUR RADIOL, V10, P653, DOI 10.1007/s003300050979
   Chen ZJ, 2019, IEEE INTEL TRANSP SY, V11, P41, DOI 10.1109/MITS.2019.2903525
   de Haan MC, 2011, EUR RADIOL, V21, P1747, DOI 10.1007/s00330-011-2104-8
   Dong LB, 2019, J COMB OPTIM, V37, P1237, DOI 10.1007/s10878-018-0350-2
   Dorudi S, 1998, BRIT J SURG, V85, P98
   Glimelius B, 2011, J CLIN ONCOL, V29, P2142, DOI 10.1200/JCO.2010.34.4473
   Guan Yan, 2012, Zhong Xi Yi Jie He Xue Bao, V10, P751
   Halligan S, 2005, RADIOLOGY, V237, P893, DOI 10.1148/radiol.2373050176
   HAYASHI N, 1995, LANCET, V345, P1257, DOI 10.1016/S0140-6736(95)90922-2
   Hewitson P, 2007, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001216.pub2
   Hewitson P, 2008, AM J GASTROENTEROL, V103, P1541, DOI 10.1111/j.1572-0241.2008.01875.x
   Hu JB, 2019, MEASUREMENT, V141, P227, DOI 10.1016/j.measurement.2019.03.010
   Huang ZH, 2020, IEEE T NEUR NET LEAR, V31, P4461, DOI 10.1109/TNNLS.2019.2955567
   Huang ZH, 2019, IEEE INTERNET THINGS, V6, P7713, DOI 10.1109/JIOT.2019.2901759
   Hundt S, 2009, ANN INTERN MED, V150, P162, DOI 10.7326/0003-4819-150-3-200902030-00005
   Ma RY, 2020, ALEX ENG J, V59, P1135, DOI 10.1016/j.aej.2020.01.007
   Maldjian C, 2000, ABDOM IMAGING, V25, P75, DOI 10.1007/s002619910015
   Niekel MC, 2010, RADIOLOGY, V257, P674, DOI 10.1148/radiol.10100729
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Qian Kai, 2015, Acta Entomologica Sinica, V58, P496
   Schmoll HJ, 2012, ANN ONCOL, V23, P2479, DOI 10.1093/annonc/mds236
   Shah HA, 2007, GASTROENTEROLOGY, V132, P2297, DOI 10.1053/j.gastro.2007.03.032
   Sun Y, 2020, ALEX ENG J, V59, P1149, DOI 10.1016/j.aej.2020.01.015
   Torigan DA, 2007, CA-CANCER J CLIN, V57, P206, DOI 10.3322/canjclin.57.4.206
   Wang Y, 2019, INT J DISAST RISK RE, V33, P343, DOI 10.1016/j.ijdrr.2018.10.019
   Warren JD, 2011, BMC MED, V9, DOI 10.1186/1741-7015-9-133
   Wei W, 2019, COMPUT NETW, V161, P210, DOI 10.1016/j.comnet.2019.04.017
   Wei W, 2018, IEEE T SERV COMPUT, V11, P78, DOI 10.1109/TSC.2016.2528246
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   [张颖超 Zhang Yingchao], 2017, [电力系统保护与控制, Power System Protection and Control], V45, P58
NR 40
TC 3
Z9 3
U1 0
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 94947
EP 94955
DI 10.1109/ACCESS.2020.2995466
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LZ3KK
UT WOS:000541126800016
OA gold
DA 2023-04-20
ER

PT J
AU Wang, YT
   He, XY
   Nie, H
   Zhou, JH
   Cao, PF
   Ou, CL
AF Wang, Yutong
   He, Xiaoyun
   Nie, Hui
   Zhou, Jianhua
   Cao, Pengfei
   Ou, Chunlin
TI Application of artificial intelligence to the diagnosis and therapy of
   colorectal cancer
SO AMERICAN JOURNAL OF CANCER RESEARCH
LA English
DT Review
DE Artificial intelligence; colorectal cancer; colonoscopy; pathological
   biopsy; diagnosis; therapy
ID COMPUTER-AIDED DIAGNOSIS; HUMAN BLOOD-PLASMA; NEURAL-NETWORK;
   UNITED-STATES; STAGE-II; PREDICTION; SURGERY; CLASSIFICATION;
   METASTASIS; TUMORS
AB Artificial intelligence (AI) is a relatively new branch of computer science involving many disciplines and technologies, including robotics, speech recognition, natural language and image recognition or processing, and machine learning. Recently, AI has been widely applied in the medical field. The effective combination of AI and big data can provide convenient and efficient medical services for patients. Colorectal cancer (CRC) is a common type of gastrointestinal cancer. The early diagnosis and treatment of CRC are key factors affecting its prognosis. This review summarizes the research progress and clinical application value of AI in the investigation, early diagnosis, treatment, and prognosis of CRC, to provide a comprehensive theoretical basis for AI as a promising diagnostic and treatment tool for CRC.
C1 [Wang, Yutong; He, Xiaoyun; Nie, Hui; Zhou, Jianhua; Ou, Chunlin] Cent South Univ, Xiangya Hosp, Dept Pathol, Changsha 410008, Hunan, Peoples R China.
   [He, Xiaoyun] Cent South Univ, Xiangya Hosp, Dept Endocrinol, Changsha 410008, Hunan, Peoples R China.
   [Cao, Pengfei] Cent South Univ, Xiangya Hosp, Dept Hematol, Changsha 410008, Hunan, Peoples R China.
C3 Central South University; Central South University; Central South
   University
RP Ou, CL (通讯作者)，Cent South Univ, Xiangya Hosp, Dept Pathol, Changsha 410008, Hunan, Peoples R China.; Cao, PF (通讯作者)，Cent South Univ, Xiangya Hosp, Dept Hematol, Changsha 410008, Hunan, Peoples R China.
EM caopengfei66@163.com; ouchunlin@csu.edu.cn
FU Natural Science Foundation of Hunan Province of China [2019JJ40487];
   National Natural Science Foundation of China [81903032, 2019JJ40497];
   China Postdoctoral Science Foundation [2020M672520]; student innovation
   project of Central south university [1053320191093]; Youth Fund of
   Xiangya Hospital [2018Q011]; Open Sharing Fund for the Large-scale
   Instruments and Equipments of Central South University
FX the Natural Science Foundation of Hunan Province of China (2019JJ40487
   This study was supported by the National Natural Science Foundation of
   China (81903032), and 2019JJ40497), The China Postdoctoral Science
   Foundation (2020M672520), the student innovation project of Central
   south university (1053320191093), the Youth Fund of Xiangya Hospital
   (2018Q011), and the Open Sharing Fund for the Large-scale Instruments
   and Equipments of Central South University.
CR Abdelsamea MM, 2019, HISTOPATHOLOGY, V74, P1045, DOI 10.1111/his.13838
   Acs B, 2020, J INTERN MED, V288, P62, DOI 10.1111/joim.13030
   Adamson AS, 2019, NEW ENGL J MED, V381, P2285, DOI 10.1056/NEJMp1907407
   Afshar Saeid, 2019, Iranian Biomedical Journal, V23, P175, DOI 10.29252/.23.3.175
   Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Akturk U, 2018, RES THEOR NURS PRACT, V32, P255, DOI 10.1891/1541-6577.32.3.255
   Akutekwe A, 2015, IET SYST BIOL, V9, P294, DOI 10.1049/iet-syb.2015.0031
   Amirkhah R, 2015, MOL BIOSYST, V11, P2126, DOI 10.1039/c5mb00245a
   Berishvili VP, 2018, MOL INFORM, V37, DOI 10.1002/minf.201800030
   Betge J, 2012, CANCER-AM CANCER SOC, V118, P628, DOI 10.1002/cncr.26310
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Boselli C, 2017, AGING CLIN EXP RES, V29, pS65, DOI 10.1007/s40520-016-0642-2
   Brenner H, 2014, LANCET, V383, P1490, DOI 10.1016/S0140-6736(13)61649-9
   Caobelli F, 2020, EUR J RADIOL, V126, DOI 10.1016/j.ejrad.2020.108940
   Cavalera F, 2018, JOVE-J VIS EXP, DOI 10.3791/56668
   Chadebecq F, 2015, MED IMAGE ANAL, V19, P58, DOI 10.1016/j.media.2014.09.002
   Chang KH, 2011, INT J COLORECTAL DIS, V26, P1415, DOI 10.1007/s00384-011-1279-4
   Coppede F, 2015, EPIGENOMICS-UK, V7, P175, DOI [10.2217/EPI.14.77, 10.2217/epi.14.77]
   Cruz S, 2018, BIOMOLECULES, V8, DOI 10.3390/biom8030056
   Ding D, 2019, COMPUT BIOL CHEM, V83, DOI 10.1016/j.compbiolchem.2019.107106
   Ding L, 2019, CHINESE MED J-PEKING, V132, P379, DOI 10.1097/CM9.0000000000000095
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Doubeni CA, 2010, ANN FAM MED, V8, P299, DOI 10.1370/afm.1112
   Eu EW, 2018, ANZ J SURG, V88, P1076, DOI 10.1111/ans.14550
   Eyraud D, 2018, PATHOLOGY, V50, P607, DOI 10.1016/j.pathol.2018.04.006
   Felfoul O, 2016, NAT NANOTECHNOL, V11, P941, DOI [10.1038/nnano.2016.137, 10.1038/NNANO.2016.137]
   Ferlay J, 2010, INT J CANCER, V127, P2893, DOI 10.1002/ijc.25516
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Ferrari R, 2019, EUR J RADIOL, V118, P1, DOI 10.1016/j.ejrad.2019.06.013
   Francolini G, 2020, MED ONCOL, V37, DOI 10.1007/s12032-020-01374-w
   Gallardo-Gomez M, 2018, CLIN EPIGENETICS, V10, DOI 10.1186/s13148-018-0487-y
   Ge PL, 2019, BIOMED PHARMACOTHER, V118, DOI 10.1016/j.biopha.2019.109228
   Geessink OGF, 2019, CELL ONCOL, V42, P331, DOI 10.1007/s13402-019-00429-z
   Graham S, 2019, MED IMAGE ANAL, V52, P199, DOI 10.1016/j.media.2018.12.001
   Grundner J, 2018, STUD HEALTH TECHNOL, V247, P101, DOI 10.3233/978-1-61499-852-5-101
   Gruson D, 2019, CLIN BIOCHEM, V69, P1, DOI 10.1016/j.clinbiochem.2019.04.013
   Gupta N, 2019, JAMA-J AM MED ASSOC, V321, P2022, DOI 10.1001/jama.2019.4842
   Gupta Pratyush, 2019, J Circ Biomark, V8, p1849454419899214, DOI 10.1177/1849454419899214
   Gupta P, 2019, CANCERS, V11, DOI 10.3390/cancers11122007
   Haj-Hassan Hawraa, 2017, J Pathol Inform, V8, P1, DOI 10.4103/jpi.jpi_47_16
   Halligan S, 2005, RADIOLOGY, V237, P893, DOI 10.1148/radiol.2373050176
   Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011
   He XY, 2019, J CANCER, V10, P6405, DOI 10.7150/jca.32216
   Herreros-Villanueva M, 2019, CLIN TRANSL GASTROEN, V10
   Hilsden RJ, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207848
   Hornbrook MC, 2017, DIGEST DIS SCI, V62, P2719, DOI 10.1007/s10620-017-4722-8
   Horta AB, 2018, INT J MED INFORM, V113, P56, DOI 10.1016/j.ijmedinf.2018.02.014
   Hu HP, 2015, GENET MOL RES, V14, P17605, DOI 10.4238/2015.December.21.33
   Huang HY, 2017, CHIN J CANCER, V36, DOI 10.1186/s40880-017-0209-4
   Ichimasa K, 2018, ENDOSCOPY, V50, P230, DOI 10.1055/s-0043-122385
   Imler TD, 2015, AM J GASTROENTEROL, V110, P543, DOI 10.1038/ajg.2015.51
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Ivancic MM, 2020, J SURG RES, V246, P160, DOI 10.1016/j.jss.2019.08.004
   Jackson-Thompson J, 2006, CANCER, V107, P1103, DOI 10.1002/cncr.22007
   Jimenez-Rodriguez RM, 2016, INT J COLORECTAL DIS, V31, P1807, DOI 10.1007/s00384-016-2660-0
   Kainz P, 2017, PEERJ, V5, DOI 10.7717/peerj.3874
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Kel A, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2687-7
   Keshava N, 2019, NPJ SYST BIOL APPL, V5, DOI 10.1038/s41540-019-0113-4
   Kim EJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213640
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kuo RJ, 2015, ARTIF INTELL MED, V63, P119, DOI 10.1016/j.artmed.2014.12.008
   Lee J, 2019, FRONT CHEM, V7, DOI 10.3389/fchem.2019.00779
   Lefere P, 2006, ONKOLOGIE, V29, P281, DOI 10.1159/000093125
   Liao CW, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209698
   Lin YC, 2019, COMPLEMENT THER MED, V42, P279, DOI 10.1016/j.ctim.2018.12.001
   Ling BS, 2009, ARCH INTERN MED, V169, P47, DOI 10.1001/archinternmed.2008.519
   Lovis C, 2019, J MED INTERNET RES, V21, DOI 10.2196/16607
   Lu Y, 2018, CANCER RES, V78, P5135, DOI 10.1158/0008-5472.CAN-18-0494
   Marmol I, 2017, INT J MOL SCI, V18, DOI 10.3390/ijms18010197
   Martel S, 2016, MICROMACHINES-BASEL, V7, DOI 10.3390/mi7060097
   Mezheyeuski A, 2016, SCI REP-UK, V6, DOI 10.1038/srep36149
   Milewski R, 2017, ADV MED SCI-POLAND, V62, P202, DOI 10.1016/j.advms.2017.02.001
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   Mirroshandel SA, 2016, COMPUT METH PROG BIO, V137, P215, DOI 10.1016/j.cmpb.2016.09.013
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Miyano Satoru, 2019, Brain Nerve, V71, P25, DOI 10.11477/mf.1416201213
   Mohamad Marzuki MF, 2019, JMIR HUM FACTORS, V6
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Naugler C, 2019, CRIT REV CL LAB SCI, V56, P98, DOI 10.1080/10408363.2018.1561640
   Nie H, 2020, CELL PROLIFERAT, V53, DOI 10.1111/cpr.12815
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Nowak-Sliwinska P, 2019, BBA-REV CANCER, V1871, P434, DOI 10.1016/j.bbcan.2019.04.005
   Odle T, 2020, RADIOL TECHNOL, V91, P391
   Orringer DA, 2017, NAT BIOMED ENG, V1, DOI 10.1038/s41551-016-0027
   Ou CL, 2020, ADV SCI, V7, DOI 10.1002/advs.201901380
   Ou CL, 2017, ONCOTARGET, V8, P75727, DOI 10.18632/oncotarget.20155
   Ou CL, 2017, CANCER LETT, V399, P53, DOI 10.1016/j.canlet.2017.04.011
   Oyaga-Iriarte E, 2019, J PHARMACOL SCI, V140, P20, DOI 10.1016/j.jphs.2019.03.004
   Pacheco MP, 2019, EBIOMEDICINE, V43, P98, DOI 10.1016/j.ebiom.2019.04.046
   Patriarca S, 2017, EPIDEMIOL PREV, V41, P140, DOI 10.19191/EP17.2.P140.034
   Peng JH, 2016, ONCOTARGET, V7, P22939, DOI 10.18632/oncotarget.8217
   Peters U, 2015, GUT, V64, P1623, DOI 10.1136/gutjnl-2013-306705
   Rathore S, 2015, COMPUT BIOL MED, V65, P279, DOI 10.1016/j.compbiomed.2015.03.004
   Rathore S, 2015, COMPUT METH PROG BIO, V121, P92, DOI 10.1016/j.cmpb.2015.05.008
   Reichling C, 2020, GUT, V69, P681, DOI 10.1136/gutjnl-2019-319292
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Rocha JC, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.192
   Saeedi P, 2017, IEEE T BIO-MED ENG, V64, P2968, DOI 10.1109/TBME.2017.2759665
   Saghapour E, 2017, J THEOR BIOL, V429, P116, DOI 10.1016/j.jtbi.2017.06.024
   Schmidt C., 2017, J NATL CANC I, V109
   Shahbazy M, 2016, MOL BIOSYST, V12, P1963, DOI 10.1039/c6mb00162a
   Shi LM, 2019, MAGN RESON IMAGING, V61, P33, DOI 10.1016/j.mri.2019.05.003
   Shiraishi T, 2020, VIRCHOWS ARCH, V477, P409, DOI 10.1007/s00428-020-02775-y
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI 10.3322/caac.21395
   Simon K, 2016, CLIN INTERV AGING, V11, DOI 10.2147/CIA.S109285
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Skrede OJ, 2020, LANCET, V395, P350, DOI 10.1016/S0140-6736(19)32998-8
   Smith RA, 2012, CA-CANCER J CLIN, V62, P129, DOI 10.3322/caac.20143
   Soares F, 2017, ARTIF INTELL MED, V82, P1, DOI 10.1016/j.artmed.2017.09.004
   Song CL, 2019, ANAL BIOANAL CHEM, V411, P6969, DOI 10.1007/s00216-019-02069-6
   Spanheimer PM, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1841
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Sun Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/7361042
   Sun ZQ, 2019, ONCOGENE, V38, P2627, DOI 10.1038/s41388-018-0628-y
   Takamatsu M, 2019, COMPUT METH PROG BIO, V178, P155, DOI 10.1016/j.cmpb.2019.06.022
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Timp S, 2010, IEEE T INF TECHNOL B, V14, P803, DOI 10.1109/TITB.2010.2043296
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Tutar Y, 2014, CURR PHARM BIOTECHNO, V15, P429, DOI 10.2174/138920101505140828161335
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van de Wiel MA, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-116
   Van den Eynde M, 2018, CANCER CELL, V34, P1012, DOI 10.1016/j.ccell.2018.11.003
   Van Eycke YR, 2018, MED IMAGE ANAL, V49, P35, DOI 10.1016/j.media.2018.07.004
   VerMilyea M, 2020, HUM REPROD, V35, P770, DOI 10.1093/humrep/deaa013
   Wan N, 2019, BMC CANCER, V19, DOI 10.1186/s12885-019-6003-8
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang Q, 2019, ONCOL LETT, V17, P3314, DOI 10.3892/ol.2019.10010
   Wang YT, 2020, THERANOSTICS, V10, P11049, DOI 10.7150/thno.49168
   Weis CA, 2018, DIAGN PATHOL, V13, DOI 10.1186/s13000-018-0739-3
   Win AK, 2012, CANCER EPIDEM BIOMAR, V21, P398, DOI 10.1158/1055-9965.EPI-11-0771
   Winkler-Schwartz A, 2019, J SURG EDUC, V76, P1681, DOI 10.1016/j.jsurg.2019.05.015
   Xu GR, 2017, GENE, V604, P33, DOI 10.1016/j.gene.2016.12.016
   Xu JF, 2018, CELL PHYSIOL BIOCHEM, V45, P1444, DOI 10.1159/000487571
   Xuan P, 2018, INT J MOL SCI, V19, DOI 10.3390/ijms19123732
   Yanez LZ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms10809
   Yang K, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1429-8
   Yang SX, 2018, TECHNOL CANCER RES T, V17, DOI 10.1177/1533033818794160
   Yoon SN, 2015, HEPATO-GASTROENTEROL, V62, P34, DOI 10.5754/hge14806
   Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z
   Zawadzki M, 2017, INT J COLORECTAL DIS, V32, P399, DOI 10.1007/s00384-016-2697-0
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2019, MOLECULES, V24, DOI 10.3390/molecules24122238
   Zhi JJ, 2018, INT J MOL MED, V41, P1419, DOI 10.3892/ijmm.2018.3359
   Zhou Y P, 2019, Zhonghua Wai Ke Za Zhi, V57, P108, DOI 10.3760/cma.j.issn.0529-5815.2019.02.007
NR 148
TC 25
Z9 25
U1 4
U2 30
PU E-CENTURY PUBLISHING CORP
PI MADISON
PA 40 WHITE OAKS LN, MADISON, WI 53711 USA
SN 2156-6976
J9 AM J CANCER RES
JI Am. J. Cancer Res.
PY 2020
VL 10
IS 11
BP 3575
EP 3598
PG 24
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA OZ9VY
UT WOS:000595267700005
PM 33294256
DA 2023-04-20
ER

PT J
AU Xiao, ZG
   Feng, LN
AF Xiao, Zhiguo
   Feng, Li Nian
TI A Study on Wireless Capsule Endoscopy for Small Intestinal Lesions
   Detection Based on Deep Learning Target Detection
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Lesions; Object detection; Intestines; Machine
   learning; Endoscopes; Detection network; wireless capsule endoscope;
   small intestine lesions; YOLOv3
ID TEXTURE
AB Wireless capsule endoscope (WCE) has been verified in clinical medicine for many years. However, the detection process needs experienced doctors to read the film manually for a long time. In addition, the cost of the endoscope itself leads to a high cost of WCE detection and overall cycle is long. New research method based on deep learning technology with robustness and high accuracy can reduce the detection cost and benefit the public. According to the characteristics of small intestine lesion, a method focuses on labeling and feature detection which can optimize the process by analyzing small intestine WCE image and experimental comparison. Based on the YOLOv3 detection network, retaining the original basic feature of detection network, an improved one is further optimized and effectively verified. Finally, the redundant images are filtered out by comparing the Hash value of images, presenting the final concise detection results for doctors. Starting from image labeling, the design of deep learning network structure for the image of small intestine digestive tract endoscope is studied, which can effectively improve intelligent detection computer-aided clinical application of WCE, with higher accuracy and lower missing detection rate than manual detection.
C1 [Xiao, Zhiguo; Feng, Li Nian] Changchun Univ, Coll Comp Sci & Technol, Changchun 130022, Peoples R China.
C3 Changchun University
RP Feng, LN (通讯作者)，Changchun Univ, Coll Comp Sci & Technol, Changchun 130022, Peoples R China.
EM cculinianfeng@126.com
RI Xiao, Zhiguo/GQQ-5152-2022
OI Xiao, Zhiguo/0000-0001-6719-0652
FU Project of the Education Department of Jilin Province [2019LY505L28];
   Jilin Science and Technology Development Plan Project [20200404221YY];
   School Level Training Program [2018JBC05L11]
FX This work was supported in part by the Project of the Education
   Department of Jilin Province under Grant 2019LY505L28, in part by the
   Jilin Science and Technology Development Plan Project under Grant
   20200404221YY, and in part by the School Level Training Program under
   Project 2018JBC05L11.
CR Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Alizadeh M, 2017, J BIOMED RES, V31, P419, DOI 10.7555/JBR.31.20160008
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Charfi S, 2019, IET IMAGE PROCESS, V13, P1023, DOI 10.1049/iet-ipr.2018.6232
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Erfani SM, 2016, PATTERN RECOGN, V58, P121, DOI 10.1016/j.patcog.2016.03.028
   Fu C.Y., 2017, ARXIV17010665
   Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   He Yihui, 2018, ARXIV180908545
   Hurtik P., 2020, ARXIV200513243
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Li S., PROGR LASER OPTOELEC
   Liu KE, 2012, INT J ROBUST NONLIN, V22, P1881, DOI 10.1002/rnc.1792
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297
   Redmon J, 2018, Arxiv
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren Mengye, 2018, INT C LEARN REPR
   Shuo L., J CHONGQING U TECHNO
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI DOI 10.3322/caac.21387
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Wang C, 2011, INT J INNOV COMPUT I, V7, P4237
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Wyner AJ, 2017, J MACH LEARN RES, V18, P1
   Xie GM, 2009, AUTOMATICA, V45, P2141, DOI 10.1016/j.automatica.2009.05.016
   Yu J., 2011, T I MEAS CONTROL, V32, P607
   Yu L, 2012, IEEE INT CONF NANO, P21, DOI 10.1109/NANOMED.2012.6509137
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 40
TC 3
Z9 3
U1 9
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 159017
EP 159026
DI 10.1109/ACCESS.2020.3019888
PG 10
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA NN4RR
UT WOS:000568777800001
OA gold
DA 2023-04-20
ER

PT J
AU Xue, Y
   Li, N
   Wei, XJ
   Wan, RA
   Wang, CY
AF Xue, Yuan
   Li, Na
   Wei, Xiaojie
   Wan, Ren'An
   Wang, Chunyan
TI Deep Learning-Based Earlier Detection of Esophageal Cancer Using
   Improved Empirical Wavelet Transform From Endoscopic Image
SO IEEE ACCESS
LA English
DT Article
DE Esophageal cancer; empirical wavelet transformation; binary images;
   endoscopic image; detection and nursing
AB In the current scenario, the research perspective on esophageal cancer becomes severe, high-prognosis malignancy; poor prognosis is primarily attributed to the fact that most tumors remain asymptomatic and unrelated before it grows through the esophagus. Significant decreases in mortality from esophageal cancer may require effective approaches to detect and nurse more patients at early, curable stages. A new Improved Empirical Wavelet Transform (IEWT) dependent on feature extraction approach and a consistent homology for the diagnosis of early esophageal endoscopic cancer have been proposed in this article. The approach is to convert an input endoscope image into CIE colored spaces L * x * y, and the x* and y* components to create a fusion image for analysis. Further, the two kinds of wavelets are obtained by adding the two forms to the fusion signal. Another is the lower-frequency component provided by the improved empirical wavelet transformation of the wave, and the other is the high- components generated from the Deep Learning-based Complex Empirical Wavelet Transformation (DL-CEWT). The fractal sizes are determined using the box interpolation method for each small block, and the abnormal regions are defined for the basis of their fractal sizes. Binary pictures are obtained by the complex threshold in each frequency variable and then divided into small blocks in every binary image. Using the homology of every block to obtain the new features in the entry image. The extraction strategies for this application are comprehensive and preliminary findings indicate that the method is effective for the early detection of esophageal cancer in an image.
C1 [Xue, Yuan; Li, Na; Wei, Xiaojie; Wan, Ren'An; Wang, Chunyan] Rizhao Peoples Hosp, Rizhao 276800, Peoples R China.
RP Wang, CY (通讯作者)，Rizhao Peoples Hosp, Rizhao 276800, Peoples R China.
EM a15863341981@163.com
CR Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Ali H, 2020, ARTIF INTELL REV, V53, P2635, DOI 10.1007/s10462-019-09743-2
   Ardabili S, 2020, LECT NOTE NETW SYST, V101, P215, DOI 10.1007/978-3-030-36841-8_21
   Charisis V., 2012, NEW ADV BASIC CLIN G, P185
   Chatterjee S, 2020, INTEL SYST REF LIBR, V172, P427, DOI 10.1007/978-3-030-32644-9_33
   Chen HH, 2017, NEUROCOMPUTING, V229, P77, DOI 10.1016/j.neucom.2016.06.077
   de Souza LA, 2018, SIBGRAPI, P166, DOI 10.1109/SIBGRAPI.2018.00028
   Diamantis DE, 2019, BIOMED SIGNAL PROCES, V49, P192, DOI 10.1016/j.bspc.2018.12.005
   Feng SY, 2013, APPL PHYS LETT, V102, DOI 10.1063/1.4789996
   Ghatwary N, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014502
   Gomathi P, 2019, J MED IMAG HEALTH IN, V9, P482, DOI 10.1166/jmihi.2019.2587
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Janse MHA, 2015, PROC SPIE, V9785, DOI 10.1117/12.2208583
   Klomp S., 2017, P SOC PHOTO-OPT INS, V10134
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Setio A. A., 2013, PROC VISAPP, V1, P238
   Shakeel PM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1045-z
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van Riel S, 2018, IEEE IMAGE PROC, P1383, DOI 10.1109/ICIP.2018.8451771
   Vasilakakis MD, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/2026962
   Vemuri A.S., 2019, ARXIV190413307
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Yang F, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4620732
   Yusantay P., 2018, PROC 11 INT C IMAGE, P1
NR 26
TC 4
Z9 4
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 123765
EP 123772
DI 10.1109/ACCESS.2020.3006106
PG 8
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MS8NR
UT WOS:000554530900001
OA gold
DA 2023-04-20
ER

PT J
AU Yang, YJ
AF Yang, Young Joo
TI The Future of Capsule Endoscopy: The Role of Artificial Intelligence and
   Other Technical Advancements
SO CLINICAL ENDOSCOPY
LA English
DT Review
DE Artificial intelligence; Capsule endoscopy; Convolutional neural
   network; Locomotion
ID WIRELESS CAPSULE; GASTROINTESTINAL HEMORRHAGE; IMAGES; ACCURACY; SYSTEM;
   DEVICE; ULCER; 1ST
AB Capsule endoscopy has revolutionized the management of small-bowel diseases owing to its convenience and noninvasiveness. Capsule endoscopy is a common method for the evaluation of obscure gastrointestinal bleeding, Crohn's disease, small-bowel tumors, and polyposis syndrome. However, the laborious reading process, oversight of small-bowel lesions, and lack of locomotion are major obstacles to expanding its application. Along with recent advances in artificial intelligence, several studies have reported the promising performance of convolutional neural network systems for the diagnosis of various small-bowel lesions including erosion/ulcers, angioectasias, polyps, and bleeding lesions, which have reduced the time needed for capsule endoscopy interpretation. Furthermore, colon capsule endoscopy and capsule endoscopy locomotion driven by magnetic force have been investigated for clinical application, and various capsule endoscopy prototypes for active locomotion, biopsy, or therapeutic approaches have been introduced. In this review, we will discuss the recent advancements in artificial intelligence in the field of capsule endoscopy, as well as studies on other technological improvements in capsule endoscopy.
C1 [Yang, Young Joo] Hallym Univ, Dept Internal Med, Coll Med, 77 Sakju Ro, Chunchon 24253, South Korea.
   [Yang, Young Joo] Hallym Univ, Inst Liver & Digest Dis, Chunchon, South Korea.
C3 Hallym University; Hallym University
RP Yang, YJ (通讯作者)，Hallym Univ, Dept Internal Med, Coll Med, 77 Sakju Ro, Chunchon 24253, South Korea.
EM yjyang@hallym.ac.kr
CR Aoki T, 2020, DIGEST ENDOSC, V32, P585, DOI 10.1111/den.13517
   Aoki T, 2020, J GASTROEN HEPATOL, V35, P1196, DOI 10.1111/jgh.14941
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Beg S, 2020, GASTROINTEST ENDOSC, V91, P773, DOI 10.1016/j.gie.2019.10.031
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Chen WW, 2014, INT J PRECIS ENG MAN, V15, P2317, DOI 10.1007/s12541-014-0596-2
   Ching HL, 2019, ENDOSCOPY, V51, P409, DOI 10.1055/a-0750-5682
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   Demosthenous P, 2016, IEEE T BIOMED CIRC S, V10, P467, DOI 10.1109/TBCAS.2015.2449277
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Donghoon Son, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1132, DOI 10.1109/ICRA.2017.7989135
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Eliakim R, 2013, CURR OPIN GASTROEN, V29, P133, DOI 10.1097/MOG.0b013e32835bdc03
   Fontana R, 2017, IEEE T BIOMED CIRC S, V11, P143, DOI 10.1109/TBCAS.2016.2560800
   Fu Q, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1001, DOI 10.1109/ICMA.2017.8015953
   Guo J, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P439, DOI 10.1109/ICMA.2017.8015857
   Hall B, 2015, WORLD J GASTRO ENDOS, V7, P1230, DOI 10.4253/wjge.v7.i16.1230
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jang J, 2018, ISSCC DIG TECH PAP I, P282
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Kopylov U, 2015, CURR OPIN GASTROEN, V31, P111, DOI 10.1097/MOG.0000000000000159
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Leung BHK, 2017, IEEE T BIO-MED ENG, V64, P1106, DOI 10.1109/TBME.2016.2591060
   Li BP, 2009, IEEE ENG MED BIO, P3731, DOI 10.1109/IEMBS.2009.5334875
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Li Z, 2018, VISC MED, V34, P45, DOI 10.1159/000486121
   Liao ZA, 2016, CLIN GASTROENTEROL H, V14, P1266, DOI 10.1016/j.cgh.2016.05.013
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Noya F, 2017, IEEE ENG MED BIO, P3158, DOI 10.1109/EMBC.2017.8037527
   Pennazio M, 2015, ENDOSCOPY, V47, P352, DOI 10.1055/s-0034-1391855
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Shamsudhin N, 2017, MED PHYS, V44, pE91, DOI [10.1002/mp.12299, 10.1002/mp.12446]
   Soffer S, 2020, GASTROINTEST ENDOSC, V92, P831, DOI 10.1016/j.gie.2020.04.039
   Spada C, 2016, CLIN GASTROENTEROL H, V14, P1533, DOI 10.1016/j.cgh.2016.04.038
   Stewart Fraser, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8092467
   Tenorio JM, 2011, INT J MED INFORM, V80, P793, DOI 10.1016/j.ijmedinf.2011.08.001
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Ye CA, 2013, J DIGEST DIS, V14, P117, DOI 10.1111/1751-2980.12005
   Yim S, 2014, IEEE T BIO-MED ENG, V61, P513, DOI 10.1109/TBME.2013.2283369
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhao AJ, 2018, GASTROINTEST ENDOSC, V88, P466, DOI 10.1016/j.gie.2018.05.003
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 53
TC 21
Z9 21
U1 2
U2 18
PU KOREAN SOC GASTROINTESTINAL ENDOSCOPY
PI SEOUL
PA 2003 LG PALACE, 165-8 DONGGYO-DONG, MAPO-GU, SEOUL, 121-754, SOUTH KOREA
SN 2234-2400
EI 2234-2443
J9 CLIN ENDOSC
JI Clin. Endosc.
PY 2020
VL 53
IS 4
BP 387
EP 394
DI 10.5946/ce.2020.133
PG 8
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA MV9WT
UT WOS:000556699600005
PM 32668529
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Yoshii, S
   Mabe, K
   Watano, K
   Ohno, M
   Matsumoto, M
   Ono, S
   Kudo, T
   Nojima, M
   Kato, M
   Sakamoto, N
AF Yoshii, Shinji
   Mabe, Katsuhiro
   Watano, Keiko
   Ohno, Masayoshi
   Matsumoto, Mio
   Ono, Shoko
   Kudo, Takahiko
   Nojima, Masanori
   Kato, Mototsugu
   Sakamoto, Naoya
TI Validity of endoscopic features for the diagnosis of Helicobacter pylori
   infection status based on the Kyoto classification of gastritis
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE classification; endoscopy; gastritis; Helicobacter pylori; infection
ID CANCER; ERADICATION; PREVALENCE; MUCOSA
AB Objectives Evaluation of Helicobacter pylori infection status (non-infection, past infection, current infection) has become important. This study aimed to determine the usefulness of the Kyoto classification of gastritis for diagnosing H. pylori infection status by endoscopy. Methods In this prospective study, 498 subjects were recruited. Seven well-experienced endoscopists blinded to the history of eradication therapy performed the examinations. Endoscopic findings were assessed according to the Kyoto classification of gastritis: diffuse redness, regular arrangement of collecting venules (RAC), fundic gland polyp (FGP), atrophy, xanthoma, hyperplastic polyp, map-like redness, intestinal metaplasia, nodularity, mucosal swelling, white and flat elevated lesion, sticky mucus, depressive erosion, raised erosion, red streak, and enlarged folds. We established prediction models according to a machine learning procedure and compared them with general assessment by endoscopists using the Kyoto classification of gastritis. Results Significantly higher diagnostic odds were obtained for RAC (32.2), FGP (7.7), and red streak (4.7) in subjects with non-infection, map-like redness (12.9) in subjects with past infection, and diffuse redness (26.8), mucosal swelling (13.3), sticky mucus (10.2) and enlarged fold (8.6) in subjects with current infection. The overall diagnostic accuracy rate was 82.9% with the Kyoto classification of gastritis. The diagnostic accuracy of the prediction model was 88.6% for the model without H. pylori eradication history and 93.4% for the model with eradication history. Conclusions The Kyoto classification of gastritis is useful for diagnosing H. pylori infection status based on endoscopic findings. Our prediction model is helpful for novice endoscopists. (UMIN000016674).
C1 [Yoshii, Shinji] Sapporo Med Ctr NTT EC, Dept Gastroenterol, Sapporo, Hokkaido, Japan.
   [Watano, Keiko] Sapporo Med Ctr NTT EC, Med Check Up Ctr, Sapporo, Hokkaido, Japan.
   [Mabe, Katsuhiro; Kato, Mototsugu] Hakodate Natl Hosp, Dept Gastroenterol, Sapporo, Hokkaido, Japan.
   [Ohno, Masayoshi; Ono, Shoko] Hokkaido Univ Hosp, Div Endoscopy, Sapporo, Hokkaido, Japan.
   [Matsumoto, Mio] Hokkaido Med Ctr, Dept Gastroenterol, Sapporo, Hokkaido, Japan.
   [Kudo, Takahiko] Hlth Sci Univ, Dept Gastroenterol, Hokkaido Hosp, Sapporo, Hokkaido, Japan.
   [Sakamoto, Naoya] Hokkaido Univ, Dept Gastroenterol, Grad Sch Med, Sapporo, Hokkaido, Japan.
   [Nojima, Masanori] Univ Tokyo, Inst Med Sci Hosp, Ctr Translat Res, Tokyo, Japan.
C3 Hokkaido University; Hokkaido University; University of Tokyo
RP Yoshii, S (通讯作者)，NTT EC, Sapporo Med Ctr, Dept Gastroenterol, Chuo Ku, S1 W15, Sapporo, Hokkaido 0600061, Japan.
EM shinji-yoshii@umin.ac.jp
RI Sakamoto, Naoya/G-2734-2012
OI Sakamoto, Naoya/0000-0003-0061-059X; Ono, Shoko/0000-0002-4485-6367
CR Fukase K, 2008, LANCET, V372, P392, DOI 10.1016/S0140-6736(08)61159-9
   Glas AS, 2003, J CLIN EPIDEMIOL, V56, P1129, DOI 10.1016/S0895-4356(03)00177-X
   Haruma K., 2017, KYOTO CLASSIFICATION
   Kamada T, 2005, ALIMENT PHARM THER, V21, P1121, DOI 10.1111/j.1365-2036.2005.02459.x
   Kanda Y, 2013, BONE MARROW TRANSPL, V48, P452, DOI 10.1038/bmt.2012.244
   Kato M, 2013, DIGEST ENDOSC, V25, P264, DOI 10.1111/j.1443-1661.2012.01385.x
   Kato T, 2013, DIGEST ENDOSC, V25, P508, DOI 10.1111/den.12031
   Kikuchi S, 2000, JPN J MED PHARM SCI, V43, P581
   Kitamura Y, 2015, J GASTROEN HEPATOL, V30, P1473, DOI 10.1111/jgh.12987
   Mabe K, 2009, WORLD J GASTROENTERO, V15, P4290, DOI 10.3748/wjg.15.4290
   Matsuo T, 2011, HELICOBACTER, V16, P415, DOI 10.1111/j.1523-5378.2011.00889.x
   Miyamoto M, 2003, DIGEST DIS SCI, V48, P968, DOI 10.1023/A:1023016000096
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Nagata N, 2011, GASTROENTEROL RES, V4, P203, DOI 10.4021/gr357w
   Neumann H, 2019, DIGEST ENDOSC, V31, P389, DOI 10.1111/den.13391
   Nishibayashi H, 2003, J GASTROEN HEPATOL, V18, P1384, DOI 10.1046/j.1440-1746.2003.03192.x
   Nomura S, 2013, DIGEST ENDOSC, V25, P136, DOI 10.1111/j.1443-1661.2012.01357.x
   Ono S, 2012, DIGESTION, V86, P59, DOI 10.1159/000339176
   Research Center for Cancer Prevention and Screening, 2014, NAT CANC CTR JAP GUI
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Ueda J, 2014, HELICOBACTER, V19, P105, DOI 10.1111/hel.12110
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
   Watanabe K, 2013, WORLD J GASTROENTERO, V19, P4374, DOI 10.3748/wjg.v19.i27.4374
   Yagi K, 2002, J GASTROEN HEPATOL, V17, P39, DOI 10.1046/j.1440-1746.2002.02665.x
NR 26
TC 44
Z9 48
U1 1
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JAN
PY 2020
VL 32
IS 1
BP 74
EP 83
DI 10.1111/den.13486
PG 10
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA KA4LY
UT WOS:000505769500024
PM 31309632
DA 2023-04-20
ER

PT J
AU Zachariah, R
   Samarasena, J
   Luba, D
   Duh, E
   Dao, T
   Requa, J
   Ninh, A
   Karnes, W
AF Zachariah, Robin
   Samarasena, Jason
   Luba, Daniel
   Duh, Erica
   Dao, Tyler
   Requa, James
   Ninh, Andrew
   Karnes, William
TI Prediction of Polyp Pathology Using Convolutional Neural Networks
   Achieves "Resect and Discard" Thresholds
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
ID SMALL COLORECTAL POLYPS; OPTICAL BIOPSY; DIAGNOSIS; ENDOSCOPY; CANCER;
   SYSTEM; PREVENTION; HISTOLOGY; ACCURACY; SOCIETY
AB OBJECTIVES: Reliable in situ diagnosis of diminutive (<= 5 mm) colorectal polyps could allow for "resect and discard" and "diagnose and leave" strategies, resulting in $1 billion cost savings per year in the United States alone. Current methodologies have failed to consistently meet the Preservation and Incorporation of Valuable endoscopic Innovations (PIVIs) initiative thresholds. Convolutional neural networks (CNNs) have the potential to predict polyp pathology and achieve PIVI thresholds in real time. METHODS: We developed a CNN-based optical pathology (OP) model using Tensorflow and pretrained on ImageNet, capable of operating at 77 frames per second. A total of 6,223 images of unique colorectal polyps of known pathology, location, size, and light source (white light or narrow band imaging [NBI]) underwent 5-fold cross-training (80%) and validation (20%). Separate fresh validation was performed on 634 polyp images. Surveillance intervals were calculated, comparing OP with true pathology. RESULTS: In the original validation set, the negative predictive value for adenomas was 97% among diminutive rectum/rectosigmoid polyps. Results were independent of use of NBI or white light. Surveillance interval concordance comparing OP and true pathology was 93%. In the fresh validation set, the negative predictive value was 97% among diminutive polyps in the rectum and rectosigmoid and surveillance concordance was 94%. DISCUSSION: This study demonstrates the feasibility of in situ diagnosis of colorectal polyps using CNN. Our model exceeds PIVI thresholds for both "resect and discard" and "diagnose and leave" strategies independent of NBI use. Point-of-care adenoma detection rate and surveillance recommendations are potential added benefits.
C1 [Zachariah, Robin; Samarasena, Jason; Duh, Erica; Karnes, William] Univ Calif Irvine, Med Ctr, Dept Gastroenterol, Orange, CA 92668 USA.
   [Zachariah, Robin; Samarasena, Jason; Duh, Erica; Karnes, William] Univ Calif Irvine, Med Ctr, Dept Internal Med, Orange, CA 92668 USA.
   [Samarasena, Jason; Dao, Tyler; Requa, James; Karnes, William] Docbot, Irvine, CA USA.
   [Luba, Daniel; Ninh, Andrew] Monterey Bay GI Consultants Med Grp, Monterey, CA USA.
C3 University of California System; University of California Irvine;
   University of California System; University of California Irvine
RP Zachariah, R (通讯作者)，Univ Calif Irvine, Med Ctr, Dept Gastroenterol, Orange, CA 92668 USA.; Zachariah, R (通讯作者)，Univ Calif Irvine, Med Ctr, Dept Internal Med, Orange, CA 92668 USA.
EM rzachar1@uci.edu
OI Karnes, William/0000-0002-6225-9080
FU National Center for Research Resources; National Center for Advancing
   Translational Sciences, National Institutes of Health [UL1 TR001414]
FX The project described was supported by the National Center for Research
   Resources and the National Center for Advancing Translational Sciences,
   National Institutes of Health, through Grant UL1 TR001414. The content
   is solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institutes of Health.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Flores SL, 2014, GASTROINTEST ENDOSC, V79, pAB170
   Hamoudah T, 2018, GASTROINTEST ENDOSC, V87, P1518, DOI 10.1016/j.gie.2017.12.028
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Iwatate Mineo, 2012, Diagn Ther Endosc, V2012, P173269, DOI 10.1155/2012/173269
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Kumar S, 2013, GASTROINTEST ENDOSC, V78, P902, DOI 10.1016/j.gie.2013.06.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lee J, 2016, CLIN ENDOSC, V49, P355, DOI 10.5946/ce.2016.063
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Ponugoti P, 2019, ENDOSCOPY, V51, P221, DOI 10.1055/a-0831-2348
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rex DK, 1999, GASTROINTEST ENDOSC, V50, P468, DOI 10.1016/S0016-5107(99)70067-2
   Rex DK, 2018, NEJM J WATCH
   Rex Douglas K, 2014, Gastroenterol Hepatol (N Y), V10, P671
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Surveillance Epidemiology and End Results (SEER) Program, 2016, SEER STAT DAT MORT A
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P22, DOI 10.1055/s-0029-1215268
   Turkiewicz J, 2018, GASTROINTEST ENDOSC, V87, pAB465
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wong NACS, 2009, HISTOPATHOLOGY, V55, P63, DOI 10.1111/j.1365-2559.2009.03329.x
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 29
TC 53
Z9 54
U1 1
U2 12
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0002-9270
EI 1572-0241
J9 AM J GASTROENTEROL
JI Am. J. Gastroenterol.
PD JAN
PY 2020
VL 115
IS 1
BP 138
EP 144
DI 10.14309/ajg.0000000000000429
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA LP3TS
UT WOS:000534242100019
PM 31651444
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Zeng, YF
   Xu, SQ
   Chapman, WC
   Li, SY
   Alipour, Z
   Abdelal, H
   Chatterjee, D
   Mutch, M
   Zhu, Q
AF Zeng, Yifeng
   Xu, Shiqi
   Chapman, William C., Jr.
   Li, Shuying
   Alipour, Zahra
   Abdelal, Heba
   Chatterjee, Deyali
   Mutch, Matthew
   Zhu, Quing
TI Real-time colorectal cancer diagnosis using PR-OCT with deep learning
SO THERANOSTICS
LA English
DT Article
DE colorectal cancer; optical coherence tomography (OCT); deep learning;
   optical biopsy
ID OPTICAL COHERENCE TOMOGRAPHY; RECTAL-CANCER; RADIOFREQUENCY ABLATION;
   ULTRAHIGH-RESOLUTION; ENDOSCOPIC OCT; CLASSIFICATION; IDENTIFICATION;
   SURGERY; TUMORS; WATCH
AB Prior reports have shown optical coherence tomography (OCT) can differentiate normal colonic mucosa from neoplasia, potentially offering an alternative technique to endoscopic biopsy - the current gold-standard colorectal cancer screening and surveillance modality. To help clinical translation limited by processing the large volume of generated data, we designed a deep learning-based pattern recognition (PR) OCT system that automates image processing and provides accurate diagnosis potentially in real-time.
   Method: OCT is an emerging imaging technique to obtain 3-dimensional (3D) "optical biopsies" of biological samples with high resolution. We designed a convolutional neural network to capture the structure patterns in human colon OCT images. The network is trained and tested using around 26,000 OCT images acquired from 20 tumor areas, 16 benign areas, and 6 other abnormal areas.
   Results: The trained network successfully detected patterns that identify normal and neoplastic colorectal tissue. Experimental diagnoses predicted by the PR-OCT system were compared to the known histologic findings and quantitatively evaluated. A sensitivity of 100% and specificity of 99.7% can be reached. Further, the area under the receiver operating characteristic (ROC) curves (AUC) of 0.998 is achieved.
   Conclusions: Our results demonstrate that PR-OCT can be used to give an accurate real-time computer-aided diagnosis of colonic neoplastic mucosa. Future development of this system as an "optical biopsy" tool to assist doctors in real-time for early mucosal neoplasms screening and treatment evaluation following initial oncologic therapy is planned.
C1 [Zeng, Yifeng; Li, Shuying; Zhu, Quing] Washington Univ, Dept Biomed Engn, St Louis, MO 14263 USA.
   [Xu, Shiqi] Washington Univ, Dept Elect & Syst Engn, St Louis, MO 14263 USA.
   [Chapman, William C., Jr.; Mutch, Matthew] Washington Univ, Sch Med, Dept Surg, Sect Colon & Rectal Surg, St Louis, MO 14263 USA.
   [Alipour, Zahra; Abdelal, Heba; Chatterjee, Deyali] Washington Univ, Sch Med, Dept Pathol & Immunol, St Louis, MO 14263 USA.
   [Zhu, Quing] Washington Univ, Sch Med, Dept Radiol, St Louis, MO 14263 USA.
C3 Washington University (WUSTL); Washington University (WUSTL); Washington
   University (WUSTL); Washington University (WUSTL); Washington University
   (WUSTL)
RP Zhu, Q (通讯作者)，Washington Univ, Dept Biomed Engn, St Louis, MO 14263 USA.; Zhu, Q (通讯作者)，Washington Univ, Sch Med, Dept Radiol, St Louis, MO 14263 USA.
EM zhu.q@wustl.edu
RI Zeng, Yifeng/Z-3331-2019; Li, Shuying/AAA-5696-2021
OI Zeng, Yifeng/0000-0003-2676-8088; Li, Shuying/0000-0003-3253-6304
FU NIH [R01CA151570, R01EB 002136, R01 CA228047]; Washington University
   School of Medicine Surgical Oncology Basic Science and Translational
   Research Training Program grant (NCI) [T32CA009621]
FX Research reported in this publication was partially supported by the NIH
   (R01CA151570, R01EB 002136, and R01 CA228047), and by the Washington
   University School of Medicine Surgical Oncology Basic Science and
   Translational Research Training Program grant T32CA009621 from NCI). We
   thank Michelle Sperry, study coordinator, for consenting patients to the
   study.
CR Abdolmanafi A, 2017, BIOMED OPT EXPRESS, V8, P1203, DOI 10.1364/BOE.8.001203
   Adler DC, 2009, OPT EXPRESS, V17, P784, DOI 10.1364/OE.17.000784
   Ahsen OO, 2017, THER ADV GASTROENTER, V10, P931, DOI 10.1177/1756283X17739503
   Chen CL, 2017, BIOMED OPT EXPRESS, V8, P1056, DOI 10.1364/BOE.8.001056
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dossa F, 2017, LANCET GASTROENTEROL, V2, P501, DOI 10.1016/S2468-1253(17)30074-2
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fleischer DE, 2010, ENDOSCOPY, V42, P781, DOI 10.1055/s-0030-1255779
   Freund JE, 2019, LASER SURG MED, V51, P399, DOI 10.1002/lsm.23079
   Glorot Y. Bengio, 2010, P 13 INT C ARTIFICIA, P249, DOI DOI 10.1177/1753193409103364.
   Gora MJ, 2018, GASTROINTEST ENDOSC, V88, P830, DOI 10.1016/j.gie.2018.07.009
   Gora MJ, 2017, BIOMED OPT EXPRESS, V8, P2405, DOI 10.1364/BOE.8.002405
   Hariri LP, 2015, ANN AM THORAC SOC, V12, P193, DOI 10.1513/AnnalsATS.201408-370OC
   He YX, 2023, TRANSPORTMETRICA A, V19, DOI [10.1109/CVPR.2016.90, 10.1080/23249935.2022.2033348]
   Hsiung PL, 2005, GASTROINTEST ENDOSC, V62, P561, DOI 10.1016/j.gie.2005.05.006
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Huang J., 2017, CVPR
   Hwang DK, 2019, THERANOSTICS, V9, P232, DOI 10.7150/thno.28447
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Katta N, 2019, THERANOSTICS, V9, P3555, DOI 10.7150/thno.31811
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Kirtane TS, 2014, GASTROENT RES PRACT, V2014, DOI 10.1155/2014/376367
   Kong JC, 2017, DIS COLON RECTUM, V60, P335, DOI 10.1097/DCR.0000000000000754
   Lee CS, 2017, OPHTHALMOL RETINA, V1, P322, DOI 10.1016/j.oret.2016.12.009
   Li DW, 2019, BIOMED OPT EXPRESS, V10, P1126, DOI 10.1364/BOE.10.001126
   Li Y, 2019, BIOMED OPT EXPRESS, V10, P2419, DOI 10.1364/BOE.10.002419
   Lin T.Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lu Y, 2018, CANCER RES, V78, P5135, DOI 10.1158/0008-5472.CAN-18-0494
   Mavadia-Shukla J, 2018, BIOMED OPT EXPRESS, V9, DOI 10.1364/BOE.9.003731
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Pahlevaninezhad H, 2018, NAT PHOTONICS, V12, P540, DOI 10.1038/s41566-018-0224-2
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panta P., 2019, ORAL CANC DETECTION, P217
   Redmon J, 2018, Arxiv
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Shen B, 2004, CLIN GASTROENTEROL H, V2, P1080, DOI 10.1016/S1542-3565(04)00621-4
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Sivak MV, 2000, GASTROINTEST ENDOSC, V51, P474, DOI 10.1016/S0016-5107(00)70450-0
   SPACHOS P, 2017, I S WORLD WIREL MOBI
   Tanaka Takuji, 2009, J Carcinog, V8, P5
   Than M, 2015, ANN GASTROENTEROL, V28, P94
   Tran T, 2015, J CANCER, V6, P759, DOI 10.7150/jca.12094
   Tontini GE, 2015, WORLD J GASTROENTERO, V21, P21, DOI 10.3748/wjg.v21.i1.21
   Tsai TH, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.12.121716
   Tsai TH, 2012, GASTROINTEST ENDOSC, V76, P1104, DOI 10.1016/j.gie.2012.05.024
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2018, GASTROENTEROLOGY, V154, P1876, DOI 10.1053/j.gastro.2018.01.070
   Welge WA, 2017, LASER SURG MED, V49, P249, DOI 10.1002/lsm.22578
   Winkler AM, 2010, J BIOMED OPT, V15, DOI 10.1117/1.3446674
   Xiao L, 2016, SCI REP-UK, V6, DOI 10.1038/srep34923
   Zagaynova E, 2008, J BIOPHOTONICS, V1, P114, DOI 10.1002/jbio.200710017
   Zeng XX, 2018, THERANOSTICS, V8, P3099, DOI 10.7150/thno.24599
   Zeng YF, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39146-w
   Zhu MY, 2019, THERANOSTICS, V9, P2827, DOI 10.7150/thno.33823
NR 56
TC 24
Z9 24
U1 4
U2 34
PU IVYSPRING INT PUBL
PI LAKE HAVEN
PA PO BOX 4546, LAKE HAVEN, NSW 2263, AUSTRALIA
SN 1838-7640
J9 THERANOSTICS
JI Theranostics
PY 2020
VL 10
IS 6
BP 2587
EP 2596
DI 10.7150/thno.40099
PG 10
WC Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine
GA KM9GZ
UT WOS:000514450900010
PM 32194821
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Rasti, P
   Wolf, C
   Dorez, H
   Sablong, R
   Moussata, D
   Samiei, S
   Rousseau, D
AF Rasti, Pejman
   Wolf, Christian
   Dorez, Hugo
   Sablong, Raphael
   Moussata, Driffa
   Samiei, Salma
   Rousseau, David
TI Machine Learning-Based Classification of the Health State of Mice Colon
   in Cancer Study from Confocal Laser Endomicroscopy
SO SCIENTIFIC REPORTS
LA English
DT Article
ID ENDOSCOPY; IMAGES; MUCOSA; MODEL
AB In this article, we address the problem of the classification of the health state of the colon's wall of mice, possibly injured by cancer with machine learning approaches. This problem is essential for translational research on cancer and is a priori challenging since the amount of data is usually limited in all preclinical studies for practical and ethical reasons. Three states considered including cancer, health, and inflammatory on tissues. Fully automated machine learning-based methods are proposed, including deep learning, transfer learning, and shallow learning with SVM. These methods addressed different training strategies corresponding to clinical questions such as the automatic clinical state prediction on unseen data using a pre-trained model, or in an alternative setting, real-time estimation of the clinical state of individual tissue samples during the examination. Experimental results show the best performance of 99.93% correct recognition rate obtained for the second strategy as well as the performance of 98.49% which were achieved for the more difficult first case.
C1 [Rasti, Pejman; Samiei, Salma; Rousseau, David] Univ Angers, INRA, UMR IRHS, LARIS, F-49000 Angers, France.
   [Wolf, Christian] CNRS, INSA Lyon, INRIA, LIRIS,CITI, Villeurbanne, France.
   [Dorez, Hugo; Sablong, Raphael; Moussata, Driffa] Univ Claude Bernard Lyon 1, Univ Lyon, INSA Lyon, CNRS,UMR 5220,INSERM,U1206,CREATIS,UJM St Etienne, F-69621 Lyon, France.
C3 INRAE; Universite d'Angers; Centre National de la Recherche Scientifique
   (CNRS); Inria; Institut National des Sciences Appliquees de Lyon - INSA
   Lyon; Centre National de la Recherche Scientifique (CNRS); Institut
   National de la Sante et de la Recherche Medicale (Inserm); Institut
   National des Sciences Appliquees de Lyon - INSA Lyon; UDICE-French
   Research Universities; Universite Claude Bernard Lyon 1
RP Rousseau, D (通讯作者)，Univ Angers, INRA, UMR IRHS, LARIS, F-49000 Angers, France.
EM david.rousseau@univ-angers.fr
FU LABEX PRIMES of Universite de Lyon within the program Investissements
   d'Avenir [ANR-11-LABX-0063, ANR-11-IDEX-0007]; DORA plus (Estonian
   government programme)
FX This work was supported by the LABEX PRIMES (ANR-11-LABX-0063) of
   Universite de Lyon, within the program Investissements d'Avenir
   (ANR-11-IDEX-0007) operated by the French National Research Agency (ANR)
   as well as DORA plus (Estonian government programme).
CR Akram SU, 2016, LECT NOTES COMPUT SC, V10008, P21, DOI 10.1007/978-3-319-46976-8_3
   Akselrod-Ballin A, 2016, LECT NOTES COMPUT SC, V10008, P197, DOI 10.1007/978-3-319-46976-8_21
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Becker C, 2006, NAT PROTOC, V1, P2900, DOI 10.1038/nprot.2006.446
   Benou A, 2016, LECT NOTES COMPUT SC, V10008, P95, DOI 10.1007/978-3-319-46976-8_11
   Brady SM, 2016, MED IMAGE ANAL, V33, P7, DOI 10.1016/j.media.2016.06.012
   Bujoreanu D, 2017, PATTERN RECOGN LETT, V87, P29, DOI 10.1016/j.patrec.2016.07.022
   Cicchi R, 2013, BIOMED OPT EXPRESS, V4, P1204, DOI 10.1364/BOE.4.001204
   Dorez H, 2016, MAGN RESON MATER PHY, V29, P657, DOI 10.1007/s10334-016-0539-2
   Douarre C, 2018, J IMAGING, V4, DOI 10.3390/jimaging4050065
   Evans JP, 2016, CRIT REV ONCOL HEMAT, V98, P94, DOI 10.1016/j.critrevonc.2015.10.009
   Foersch S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041760
   Ganin Y., 2015, INT C MACH LEARN, P1180
   He K., 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Konda JA, 2013, CURR ANGIOGENESIS, V2, P67
   Latt WT, 2011, IEEE T BIO-MED ENG, V58, P2694, DOI 10.1109/TBME.2011.2162064
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu J, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0099756, 10.1371/journal.pone.0093183]
   Mielke L, 2015, J IMMUNOL METHODS, V421, P81, DOI 10.1016/j.jim.2015.04.012
   Min X, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39071-y
   Murthy VN, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254333
   Na KS, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39478-7
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Neumann H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058753
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Simonyan K, 2015, Arxiv
   Singh SP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-35218-5
   Sirinukunwattana K, 2017, MED IMAGE ANAL, V35, P489, DOI 10.1016/j.media.2016.08.008
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Waldner MJ, 2011, NAT PROTOC, V6, P1471, DOI 10.1038/nprot.2011.377
   Wang HW, 1999, IEEE T BIO-MED ENG, V46, P1246, DOI 10.1109/10.790502
   Yosinski J., 2014, NIPS
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 40
TC 4
Z9 4
U1 1
U2 4
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD DEC 27
PY 2019
VL 9
AR 20010
DI 10.1038/s41598-019-56583-9
PG 11
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA KF5XV
UT WOS:000509315700013
PM 31882817
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Nakahira, H
   Ishihara, R
   Aoyama, K
   Kono, M
   Fukuda, H
   Shimamoto, Y
   Nakagawa, K
   Ohmori, M
   Iwatsubo, T
   Iwagami, H
   Matsuno, K
   Inoue, S
   Matsuura, N
   Shichijo, S
   Maekawa, A
   Kanesaka, T
   Yamamoto, S
   Takeuchi, Y
   Higashino, K
   Uedo, N
   Matsunagat, T
   Tada, T
AF Nakahira, Hiroko
   Ishihara, Ryu
   Aoyama, Kazuharu
   Kono, Mitsuhiro
   Fukuda, Hiromu
   Shimamoto, Yusaku
   Nakagawa, Kentaro
   Ohmori, Masayasu
   Iwatsubo, Taro
   Iwagami, Hiroyoshi
   Matsuno, Kenshi
   Inoue, Shuntaro
   Matsuura, Noriko
   Shichijo, Satoki
   Maekawa, Akira
   Kanesaka, Takashi
   Yamamoto, Sachiko
   Takeuchi, Yoji
   Higashino, Koji
   Uedo, Noriya
   Matsunagat, Takashi
   Tada, Tomohiro
TI Stratification of gastric cancer risk using a deep neural network
SO JGH OPEN
LA English
DT Article
DE artificial intelligence; convolutional neural network; endoscopy;
   gastric cancer
ID HELICOBACTER-PYLORI INFECTION; ATROPHIC GASTRITIS; CLASSIFICATION;
   DIAGNOSIS; MANAGEMENT; STOMACH; SOCIETY; LESIONS
AB Background and Aim Stratifying gastric cancer (GC) risk and endoscopy findings in high-risk individuals may provide effective surveillance for GC. We developed a computerized image- analysis system for endoscopic images to stratify the risk of GC. Methods The system was trained using images taken during endoscopic examinations with non-magnified white-light imaging. Patients were classified as high-risk (patients with GC), moderate-risk (patients with current or past Helicobacter pylori infection or gastric atrophy), or low-risk (patients with no history of H. pylori infection or gastric atrophy). After selection, 20,960, 17,404, and 68,920 images were collected as training images for the high-, moderate-, and low-risk groups, respectively. Results Performance of the artificial intelligence (AI) system was evaluated by the prevalence of GC in each group using an independent validation dataset of patients who underwent endoscopic examination and H. pylori serum antibody testing. In total, 12,824 images from 454 patients were included in the analysis. The time required for diagnosing all the images was 345 seconds. The AI system diagnosed 46, 250, and 158 patients as low-, moderate-, and high risk, respectively. The prevalence of GC in the low-, moderate-, and high-risk groups was 2.2, 8.8, and 16.4%, respectively (P = 0.0017). Three experienced endoscopists also successfully stratified the risk; however, interobserver agreement was not satisfactory (kappa value of 0.27, indicating fair agreement). Conclusion The current AI system detected significant differences in the prevalence of GC among the low-, moderate-, and high-risk groups, suggesting its potential for stratifying GC risk.
C1 [Nakahira, Hiroko; Ishihara, Ryu; Kono, Mitsuhiro; Fukuda, Hiromu; Shimamoto, Yusaku; Nakagawa, Kentaro; Ohmori, Masayasu; Iwatsubo, Taro; Iwagami, Hiroyoshi; Matsuno, Kenshi; Inoue, Shuntaro; Matsuura, Noriko; Shichijo, Satoki; Maekawa, Akira; Kanesaka, Takashi; Yamamoto, Sachiko; Takeuchi, Yoji; Higashino, Koji; Uedo, Noriya] Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Osaka, Japan.
   [Matsunagat, Takashi] Osaka Int Canc Inst, Dept Med Informat, Osaka, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Al Med Serv Inc, Tokyo, Japan.
   [Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
C3 University of Tokyo; University of Tokyo
RP Ishihara, R (通讯作者)，Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Chuo Ku, 3-1-69 Otemae, Osaka 5418567, Japan.
EM ryu1486@gmail.com
RI Takeuchi, Yoji/H-3395-2019; Uedo, Noriya/H-8047-2018
OI Takeuchi, Yoji/0000-0003-3814-298X; Uedo, Noriya/0000-0002-3029-9272;
   Fukuda, Hiromu/0000-0002-1630-6288
CR Capelle LG, 2010, GASTROINTEST ENDOSC, V71, P1150, DOI 10.1016/j.gie.2009.12.029
   Chinese Society of Gastroenterology, 2017, CHIN J GASTROENTEROL, V22, P670
   Correa P, 2012, J DIGEST DIS, V13, P2, DOI 10.1111/j.1751-2980.2011.00550.x
   Dias-Silva D, 2014, GASTROINTEST ENDOSC, V79, P910, DOI 10.1016/j.gie.2013.10.020
   Dinis-Ribeiro M, 2012, ENDOSCOPY, V44, P74, DOI 10.1055/s-0031-1291491
   Dixon MF, 1996, AM J SURG PATHOL, V20, P1161, DOI 10.1097/00000478-199610000-00001
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Inui M, 2020, DIGESTION, V101, P298, DOI 10.1159/000498966
   Iwatsuka K, 2014, GASTRIC CANCER, V17, P680, DOI 10.1007/s10120-013-0333-z
   Kamad T, 2007, DIGEST ENDOSC, V19, P180, DOI 10.1111/j.1443-1661.2007.00750.x
   Kanda Y, 2013, BONE MARROW TRANSPL, V48, P452, DOI 10.1038/bmt.2012.244
   Karim-Kos HE, 2008, EUR J CANCER, V44, P1345, DOI 10.1016/j.ejca.2007.12.015
   Kikuste I, 2013, SCAND J GASTROENTERO, V48, P1108, DOI 10.3109/00365521.2013.825315
   Kimura K, 1969, ENDOSCOPY, V1, P87, DOI [10.1055/s-0028-1098086, DOI 10.1055/S-0028-1098086]
   Lee KJ, 2006, INT J CANCER, V118, P2315, DOI 10.1002/ijc.21664
   Masuyama H, 2015, DIGESTION, V91, P30, DOI 10.1159/000368807
   Miehlke S, 1998, BRIT J CANCER, V78, P263, DOI 10.1038/bjc.1998.475
   Miftahussurur M, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/4819423
   Miki K, 2011, P JPN ACAD B-PHYS, V87, P405, DOI 10.2183/pjab.87.405
   Naghavi M, 2015, LANCET, V385, P117, DOI 10.1016/S0140-6736(14)61682-2
   Nishibayashi H, 2003, J GASTROEN HEPATOL, V18, P1384, DOI 10.1046/j.1440-1746.2003.03192.x
   Rugge M, 2008, DIGEST LIVER DIS, V40, P650, DOI 10.1016/j.dld.2008.02.030
   Rugge M, 2005, HUM PATHOL, V36, P228, DOI 10.1016/j.humpath.2004.12.008
   Rugge M, 2007, GUT, V56, P631, DOI 10.1136/gut.2006.106666
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Satoh K, 2008, HELICOBACTER, V13, P225, DOI 10.1111/j.1523-5378.2008.00599.x
   Sekikawa A, 2016, J GASTROENTEROL, V51, P35, DOI 10.1007/s00535-015-1081-0
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin WG, 2012, DIGEST DIS SCI, V57, P746, DOI 10.1007/s10620-011-1919-0
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sugimoto M, 2017, INTERNAL MED, V56, P579, DOI 10.2169/internalmedicine.56.7775
   Tsai YC, 2013, ALIMENT PHARM THER, V37, P969, DOI 10.1111/apt.12291
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   Yagi K, 2005, J GASTROENTEROL, V40, P443, DOI 10.1007/s00535-005-1605-0
NR 38
TC 12
Z9 13
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2397-9070
J9 JGH OPEN
JI JGH Open
PD JUN
PY 2020
VL 4
IS 3
BP 466
EP 471
DI 10.1002/jgh3.12281
EA DEC 2019
PG 6
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA LY5RW
UT WOS:000504676000001
PM 32514455
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Ding, S
   Hu, SK
   Pan, JX
   Li, XJ
   Li, G
   Liu, X
AF Ding, Shuai
   Hu, Shikang
   Pan, Jinxin
   Li, Xiaojian
   Li, Gang
   Liu, Xiao
TI A homogeneous ensemble method for predicting gastric cancer based on
   gastroscopy reports
SO EXPERT SYSTEMS
LA English
DT Article
DE clinical decision support; gastric cancer inference; homogeneous
   ensemble; natural language processing
ID DIAGNOSIS; CLASSIFICATION
AB Gastroscopy is important for finding suspicious stomach lesions, screening for gastric cancer, and providing early diagnoses. Due to the differences in the levels of diagnosis and treatment among gastroscope doctors, clinical diagnosis based on gastroscopy is limited by low diagnostic sensitivity and specificity to gastric cancer. An assistive system for gastroscopy report analysis can be helpful to improve the success rate of gastric cancer detection. In this study, a homogeneous ensemble decision support system for gastric cancer screening (Endo-GCS) that performs word segmentation, feature extraction, and gastric cancer screening on text-based gastroscopy reports is proposed. The proposed Endo-GCS method establishes a progressive local weighting algorithm that improves the overall prediction performance of the homogeneous ensemble model in gastric cancer screening. An optimal threshold estimation algorithm is developed to minimize the negative impact of misdiagnosis and missed diagnoses. Through a comparative experimental study using real gastroscopy report data, the pathological examination conclusion is the gold standard. The sensitivity of the proposed Endo-GCS method is 88.27%, the specificity is 77.84%, and the accuracy is 82.11%, which significantly improved the sensitivity 65.49% and the accuracy 80.5% of the gastroscopic diagnosis results, respectively.
C1 [Ding, Shuai; Hu, Shikang; Pan, Jinxin; Li, Xiaojian] Hefei Univ Technol, Key Lab Proc Optimizat & Intelligent Decis Making, 193 Tun Xi Rd, Hefei 23009, Anhui, Peoples R China.
   [Li, Gang; Liu, Xiao] Deakin Univ, Sch Informat Technol, Burwood, Vic, Australia.
C3 Hefei University of Technology; Deakin University
RP Ding, S (通讯作者)，Hefei Univ Technol, Key Lab Proc Optimizat & Intelligent Decis Making, 193 Tun Xi Rd, Hefei 23009, Anhui, Peoples R China.
EM dingshuai@hfut.edu.cn
RI Li, Gang/C-4925-2009; Liu, Xiao/AAG-1593-2020
OI Li, Gang/0000-0003-1583-641X; Liu, Xiao/0000-0001-8400-5754
FU Anhui Provincial Science and Technology Major Project [17030801001,
   18030801137]; Fundamental Research Funds for the Central Universities
   [PA2019GDQT0021]; National Natural Science Foundation of China
   [91846107, 71571058, 71771077, 61903115]
FX Anhui Provincial Science and Technology Major Project, Grant/Award
   Numbers: 17030801001, 18030801137; Fundamental Research Funds for the
   Central Universities, Grant/Award Numbers: PA2019GDQT0021,
   PA2019GDQT0021; National Natural Science Foundation of China,
   Grant/Award Numbers: 91846107, 71571058, 71771077, 61903115
CR Adil U., IEEE J BIOMEDICAL HL, P1
   Adlassnig KP, 2001, ARTIF INTELL MED, V21, P139, DOI 10.1016/S0933-3657(00)00078-6
   Aguaron J., ANN OPERATIONS RES, V245, P245
   Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Atasoy H., 2015, SOC SCI ELECT PUBL, V108, P1772, DOI [10.2139/ssrn.2419690, DOI 10.2139/SSRN.2419690]
   Barata C, 2019, IEEE J BIOMED HEALTH, V23, P1096, DOI 10.1109/JBHI.2018.2845939
   Boj SF, 2015, CELL, V160, P324, DOI 10.1016/j.cell.2014.12.021
   Ciabattoni A, 2009, STUD HEALTH TECHNOL, V150, P648, DOI 10.3233/978-1-60750-044-5-648
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dag A., DECISION SUPPORT SYS
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gupta N., EXPERT SYSTEMS
   Hamashima C., CANC SCI, V108, P101
   Hassan MM, 2018, INFORM FUSION, V41, P105, DOI 10.1016/j.inffus.2017.08.004
   Huang M., IEEE J BIOMEDICAL HL, P1
   Huang Z., IEEE T BIOMEDICAL EN, P1
   Ishihara K., 2017, 2017 IEEE INT C IM P
   Jha SK, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12343
   Jiao ZC, 2018, PATTERN RECOGN, V75, P292, DOI 10.1016/j.patcog.2017.07.008
   Kanesaka T., GASTROINTESTINAL END
   Kim G. H., GASTROINTESTINAL END
   Ledley, JAMA, V196, P933
   LEDLEY RS, 1959, SCIENCE, V130, P9, DOI 10.1126/science.130.3366.9
   Leja M, 2014, BEST PRACT RES CL GA, V28, P1093, DOI 10.1016/j.bpg.2014.09.005
   Li C, 2015, J BIOMED INFORM, V57, P358, DOI 10.1016/j.jbi.2015.08.017
   Li Q, 2016, IEEE T IMAGE PROCESS, V25, P3801, DOI 10.1109/TIP.2016.2577382
   Lin Y. - K., 2017, MIS Q, V41
   Misiunas N, 2016, OMEGA-INT J MANAGE S, V58, P46, DOI 10.1016/j.omega.2015.03.010
   Neofytou MS, 2015, IEEE J BIOMED HEALTH, V19, P1129, DOI 10.1109/JBHI.2014.2332760
   Pal D., KNOWLEDGE BASED SYST, V36, P162
   Pellise M., 2016, GUT, V66
   Picado-Muino D., 2011, CADIAG 2, V15, P2013
   Piri S., DECISION SUPPORT SYS
   Salim A., 2016, AS C INT INF DAT SYS
   Santosh KC, 2018, IEEE T MED IMAGING, V37, P1168, DOI 10.1109/TMI.2017.2775636
   Swager A., GASTROINTESTINAL END
   Topuz K, 2018, DECIS SUPPORT SYST, V106, P97, DOI 10.1016/j.dss.2017.12.004
   Tourassi A. G. D., 2007, CROSS DIGITIZER ROBU
   Vallejo M, 2018, EXPERT SYST, V35, DOI 10.1111/exsy.12274
   Walczak S., DECISION SUPPORT SYS
   Wang H., INT J PRODUCTION RES, P1
   Wang S, 2017, MED IMAGE ANAL, V40, P172, DOI 10.1016/j.media.2017.06.014
   Wang Z., IEEE T MED IMAGING, P1
   Xu H., IEEE T KNOWLEDGE DAT, P1
   Zhou Z. G., KNOWLEDGE BASED SYST, V85, P62
   Zhou Z. G., KNOWLEDGE BASED SYST, V54, P128
NR 47
TC 3
Z9 3
U1 2
U2 19
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD JUN
PY 2020
VL 37
IS 3
SI SI
AR e12499
DI 10.1111/exsy.12499
EA DEC 2019
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MC0CM
UT WOS:000502942000001
DA 2023-04-20
ER

PT J
AU Pan, JX
   Ding, S
   Yang, SL
   Li, G
   Liu, X
AF Pan, Jinxin
   Ding, Shuai
   Yang, Shanlin
   Li, Gang
   Liu, Xiao
TI Endoscopy report mining for intelligent gastric cancer screening
SO EXPERT SYSTEMS
LA English
DT Article
DE gastric cancer screening; hyperparameters; multiobjective optimization;
   neural networks; NSGA-II
ID GENETIC ALGORITHM APPROACH; DECISION-SUPPORT-SYSTEM; NEURAL-NETWORK;
   OPTIMIZATION; DIAGNOSIS
AB Endoscopy is an important tool for gastric cancer screening. Due to the lack of effective decision support system for endoscopy, the detection of gastric cancer in the clinic is usually with low sensitivity. In this paper, we propose a Genetic Algorithm optimized Neural Network (GAoNN) approach for gastric cancer detection based on endoscopy reports mining. Considering the fact that gastric cancer sensitivity can significantly improve the 5-year survival rate of patients, both the prediction accuracy and the sensitivity are employed to construct a multiobjective optimization model for enhancing the classification performance of GAoNN. In particular, we extended an effective genetic algorithm Nondominated Sorting Genetic Algorithm II (NSGA-II) to train a neural network and reduced the complexity in training hyperparameters and improved the efficiency by substituting the computationally intensive stochastic gradient descent (SGD) algorithm in a neural network. Specifically, we designed the novel crossover and mutation operators and modified the nondominated ranking and crowding distance sorting procedures in NSGA-II for GAoNN. Through testing on 8,546 real-world endoscopy reports, we show that GAoNN achieves a prediction accuracy up to 83.74%, which is better than several competitors by significantly increasing sensitivity to 83.14%. GAoNN also reduces the training time by 30.94% when compared with conventional SGD-based training, which indicates the feasibility of GAoNN in clinical practice.
C1 [Pan, Jinxin; Ding, Shuai; Yang, Shanlin] Hefei Univ Technol, Sch Management, 193 Tunxi Rd, Hefei 230009, Anhui, Peoples R China.
   [Pan, Jinxin; Ding, Shuai; Yang, Shanlin] Hefei Univ Technol, Minist Educ, Key Lab Proc Optimizat & Intelligent Decis Making, Hefei, Anhui, Peoples R China.
   [Li, Gang] Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia.
   [Liu, Xiao] Deakin Univ, Sch Informat Technol, Melbourne, Vic, Australia.
C3 Hefei University of Technology; Hefei University of Technology; Deakin
   University; Deakin University
RP Ding, S; Yang, SL (通讯作者)，Hefei Univ Technol, Sch Management, 193 Tunxi Rd, Hefei 230009, Anhui, Peoples R China.
EM dingshuai@hfut.edu.cn; yangsl@hfut.edu.cn
RI Alidadi, Mehdi/HJZ-0235-2023; Liu, Xiao/AAG-1593-2020
OI Alidadi, Mehdi/0000-0001-5183-7829; Liu, Xiao/0000-0001-8400-5754; Li,
   Gang/0000-0003-1583-641X
FU Anhui Provincial Science and Technology Major Project [18030801137,
   17030801001]; Fundamental Research Funds for the Central Universities
   [PA2019GDQT0021, PA2019GDZC0100]; National Natural Science Foundation of
   China [91846107, 71571058, 71771077, 61903115]
FX Anhui Provincial Science and Technology Major Project, Grant/Award
   Numbers: 18030801137, 17030801001; Fundamental Research Funds for the
   Central Universities, Grant/Award Numbers: PA2019GDQT0021,
   PA2019GDZC0100; National Natural Science Foundation of China,
   Grant/Award Numbers: 91846107, 71571058, 71771077, 61903115
CR Abidi S, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0841-1
   Arabasadi Z, 2017, COMPUT METH PROG BIO, V141, P19, DOI 10.1016/j.cmpb.2017.01.004
   Ardestani MM, 2014, EXPERT SYST APPL, V41, P7466, DOI 10.1016/j.eswa.2014.06.034
   Bhardwaj A, 2015, EXPERT SYST APPL, V42, P4611, DOI 10.1016/j.eswa.2015.01.065
   Bourouis A, 2014, DECIS SUPPORT SYST, V59, P341, DOI 10.1016/j.dss.2014.01.005
   Bukharov OE, 2015, EXPERT SYST APPL, V42, P6177, DOI 10.1016/j.eswa.2015.03.018
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Dag A, 2017, DECIS SUPPORT SYST, V94, P42, DOI 10.1016/j.dss.2016.10.005
   Dalakleidi K, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12214
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Duran-Rosal AM, 2018, APPL SOFT COMPUT, V70, P347, DOI 10.1016/j.asoc.2018.05.035
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fatima I, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12409
   Frutos M, 2010, ANN OPER RES, V181, P745, DOI 10.1007/s10479-010-0751-9
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hamashima C, 2017, CANCER SCI, V108, P101, DOI 10.1111/cas.13100
   Helm JE, 2015, OPER RES, V63, P979, DOI 10.1287/opre.2015.1405
   Huang HX, 2015, EXPERT SYST APPL, V42, P146, DOI 10.1016/j.eswa.2014.07.039
   Ishihara K, 2017, IEEE IMAGE PROC, P2055
   Jiao ZC, 2018, PATTERN RECOGN, V75, P292, DOI 10.1016/j.patcog.2017.07.008
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   KEEN T, 2017, SURGERY OXFORD, V35, P210
   Kraus M, 2017, DECIS SUPPORT SYST, V104, P38, DOI 10.1016/j.dss.2017.10.001
   Liu JM, 2017, BIOL OPEN, V6, P29, DOI 10.1242/bio.019828
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Newgard CD, 2018, PREHOSP EMERG CARE, V22, P539, DOI 10.1080/10903127.2018.1430875
   Oztekin A, 2018, EUR J OPER RES, V266, P639, DOI 10.1016/j.ejor.2017.09.034
   Pellise M, 2017, GUT, V66, P644, DOI 10.1136/gutjnl-2015-310249
   Pinto BQ, 2018, EUR J OPER RES, V271, P849, DOI 10.1016/j.ejor.2018.05.071
   Quellec G, 2016, IEEE T MED IMAGING, V35, P1604, DOI 10.1109/TMI.2016.2521442
   Raza SA, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12413
   Sabra S, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12388
   Sahoo A, 2017, IEEE T NEUR NET LEAR, V28, P639, DOI 10.1109/TNNLS.2016.2539366
   Sakurai K, 2019, J GERIATR ONCOL, V10, P604, DOI 10.1016/j.jgo.2019.01.003
   Salgueiro R, 2017, EUR J OPER RES, V258, P877, DOI 10.1016/j.ejor.2016.11.007
   Sun YX, 2018, IEEE ACCESS, V6, P56977, DOI 10.1109/ACCESS.2018.2873019
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Tang Y, 2016, IEEE ACM T COMPUT BI, V13, P778, DOI 10.1109/TCBB.2015.2485226
   Vallejo M, 2018, EXPERT SYST, V35, DOI 10.1111/exsy.12274
   Walczak S, 2018, DECIS SUPPORT SYST, V106, P110, DOI 10.1016/j.dss.2017.12.007
   Wang ZS, 2019, APPL MATH COMPUT, V349, P134, DOI 10.1016/j.amc.2018.12.045
   Wang ZW, 2018, IEEE T MED IMAGING, V37, P1127, DOI 10.1109/TMI.2017.2789181
   WU T, 2017, OPERATIONS RES REVOL, P152
   Xia CY, 2019, INFORM SCIENCES, V471, P185, DOI 10.1016/j.ins.2018.08.050
   ZHANG L, 2019, J MED SYST, V43
   Zhang X, 2018, GASTROENTEROLOGY, V155, P347, DOI 10.1053/j.gastro.2018.04.026
   Zhu MH, 2018, IEEE T VLSI SYST, V26, P831, DOI 10.1109/TVLSI.2018.2791442
NR 48
TC 0
Z9 0
U1 2
U2 20
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD JUN
PY 2020
VL 37
IS 3
SI SI
DI 10.1111/exsy.12504
EA DEC 2019
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MC0CM
UT WOS:000501710600001
DA 2023-04-20
ER

PT J
AU Gao, Y
   Zhang, ZD
   Li, S
   Guo, YT
   Wu, QY
   Liu, SH
   Yang, SJ
   Ding, L
   Zhao, BC
   Li, S
   Lu, Y
AF Gao, Yuan
   Zhang, Zheng-Dong
   Li, Shuo
   Guo, Yu-Ting
   Wu, Qing-Yao
   Liu, Shu-Hao
   Yang, Shu-Jian
   Ding, Lei
   Zhao, Bao-Chun
   Li, Shuai
   Lu, Yun
TI Deep neural network-assisted computed tomography diagnosis of metastatic
   lymph nodes from gastric cancer
SO CHINESE MEDICAL JOURNAL
LA English
DT Article
DE Faster region-based convolutional neural networks; Perigastric
   metastatic lymph nodes; Deep learning; Gastric cancer
ID ENDOSCOPIC RESECTION; CLASSIFICATION; CHEMOTHERAPY; SURVIVAL; LOCATION;
   NUMBER
AB Background:Artificial intelligence-assisted image recognition technology is currently able to detect the target area of an image and fetch information to make classifications according to target features. This study aimed to use deep neural networks for computed tomography (CT) diagnosis of perigastric metastatic lymph nodes (PGMLNs) to simulate the recognition of lymph nodes by radiologists, and to acquire more accurate identification results.Methods:A total of 1371 images of suspected lymph node metastasis from enhanced abdominal CT scans were identified and labeled by radiologists and were used with 18,780 original images for faster region-based convolutional neural networks (FR-CNN) deep learning. The identification results of 6000 random CT images from 100 gastric cancer patients by the FR-CNN were compared with results obtained from radiologists in terms of their identification accuracy. Similarly, 1004 CT images with metastatic lymph nodes that had been post-operatively confirmed by pathological examination and 11,340 original images were used in the identification and learning processes described above. The same 6000 gastric cancer CT images were used for the verification, according to which the diagnosis results were analyzed.Results:In the initial group, precision-recall curves were generated based on the precision rates, the recall rates of nodule classes of the training set and the validation set; the mean average precision (mAP) value was 0.5019. To verify the results of the initial learning group, the receiver operating characteristic curves was generated, and the corresponding area under the curve (AUC) value was calculated as 0.8995. After the second phase of precise learning, all the indicators were improved, and the mAP and AUC values were 0.7801 and 0.9541, respectively.Conclusion:Through deep learning, FR-CNN achieved high judgment effectiveness and recognition accuracy for CT diagnosis of PGMLNs.Trial Registration:Chinese Clinical Trial Registry, No. ChiCTR1800016787; https://hfbicd694639c1db04224h995u9bvnqn966605fiac.eds.tju.edu.cn/showproj.aspx?proj=28515.
C1 [Gao, Yuan; Li, Shuo; Wu, Qing-Yao; Liu, Shu-Hao; Yang, Shu-Jian; Lu, Yun] Qingdao Univ, Dept Gen Surg, Affiliated Hosp, Shandong 266555, Peoples R China.
   [Zhang, Zheng-Dong; Guo, Yu-Ting; Li, Shuai] Beihang Univ, Qingdao Res Inst, Shandong 266100, Peoples R China.
   [Ding, Lei] Qingdao Univ, Dept Med Adm, Affiliated Hosp, Shandong 266555, Peoples R China.
   [Zhao, Bao-Chun] Qingdao Univ, Dept Follow Up Ctr, Affiliated Hosp, Shandong 266555, Peoples R China.
   [Lu, Yun] Shandong Key Lab Digital Med & Comp Assisted Surg, Qingdao 266555, Shandong, Peoples R China.
C3 Qingdao University; Beihang University; Qingdao University; Qingdao
   University
RP Lu, Y (通讯作者)，Qingdao Univ, Dept Gen Surg, Affiliated Hosp, Shandong 266555, Peoples R China.
EM luyun@qdyy.cn
RI zhang, ZY/HJH-6535-2023; zhang, zheng/HCH-9684-2022
CR Ajani JA, 2016, J NATL COMPR CANC NE, V14, P1286, DOI 10.6004/jnccn.2016.0137
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Choi JI, 2014, WORLD J GASTROENTERO, V20, P4546, DOI 10.3748/wjg.v20.i16.4546
   Eom BW, 2018, J GASTRIC CANCER, V18, P69
   Gholami S, 2015, J AM COLL SURGEONS, V221, P291, DOI 10.1016/j.jamcollsurg.2015.04.024
   Han TS, 2011, ANN SURG ONCOL, V18, P2818, DOI 10.1245/s10434-011-1620-8
   Hartgrink HH, 2009, LANCET, V374, P477, DOI 10.1016/S0140-6736(09)60617-6
   Ichimasa K, 2018, ENDOSCOPY, V50, P230, DOI 10.1055/s-0043-122385
   Japanese Gastr Canc Assoc, 2021, GASTRIC CANCER, V24, P1, DOI [10.1007/s10120-016-0622-4, 10.1007/s10120-020-01042-y]
   Jung DH, 2017, ANN SURG ONCOL, V24, P1643, DOI 10.1245/s10434-017-5791-9
   Karpeh MS, 2000, ANN SURG, V232, P362, DOI 10.1097/00000658-200009000-00008
   Kubota K, 2017, GASTROINTEST TUMORS, V3, P163, DOI 10.1159/000454923
   Kwee RM, 2009, GASTRIC CANCER, V12, P6, DOI 10.1007/s10120-008-0492-5
   Li J, 2018, EUR RADIOL, V28, P5241, DOI 10.1007/s00330-018-5483-2
   Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286
   Nishio M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200721
   Park JW, 2017, SURG ENDOSC, V31, P4419, DOI 10.1007/s00464-017-5490-4
   Sakuramoto S, 2007, NEW ENGL J MED, V357, P1810, DOI 10.1056/NEJMoa072252
   Seevaratnam R, 2012, GASTRIC CANCER, V15, pS70, DOI 10.1007/s10120-012-0169-y
   Shang-Guan XC, 2018, SURG ONCOL, V27, P54, DOI 10.1016/j.suronc.2017.11.009
   Sitarz R, 2018, CANCER MANAG RES, V10, P239, DOI 10.2147/CMAR.S149619
   Song Y, 2018, J MAGN RESON IMAGING, V48, P1570, DOI 10.1002/jmri.26047
   Tanizawa Y, 2010, GASTRIC CANCER, V13, P137, DOI 10.1007/s10120-010-0560-5
   Torre LA, 2015, CA-CANCER J CLIN, V65, P87, DOI 10.3322/caac.21262
   Woo YH, 2017, J AM COLL SURGEONS, V224, P546, DOI 10.1016/j.jamcollsurg.2016.12.015
   Yoshikawa T, 2014, ANN SURG ONCOL, V21, P385, DOI 10.1245/s10434-014-3615-8
   Zhao BC, 2018, SCAND J GASTROENTERO, V53, P185, DOI 10.1080/00365521.2017.1415371
   Zhao ST, 2016, CANCER MED-US, V5, P837, DOI 10.1002/cam4.650
   Zhou YX, 2018, J CANCER, V9, P660, DOI 10.7150/jca.22016
NR 29
TC 25
Z9 27
U1 1
U2 17
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0366-6999
EI 2542-5641
J9 CHINESE MED J-PEKING
JI Chin. Med. J.
PD DEC 5
PY 2019
VL 132
IS 23
BP 2804
EP 2811
DI 10.1097/CM9.0000000000000532
PG 8
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA JY9QU
UT WOS:000504741400006
PM 31856051
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Tham, J
   Stanley, A
AF Tham, Jennifer
   Stanley, Adrian
TI Clinical utility of pre-endoscopy risk scores in upper gastrointestinal
   bleeding
SO EXPERT REVIEW OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Review
DE Acute upper gastrointestinal bleeding; acute upper gastrointestinal
   hemorrhage; risk assessment; Glasgow Blatchford score; AIMS65;
   pre-endoscopic Rockall score
ID GLASGOW-BLATCHFORD SCORE; IN-HOSPITAL MORTALITY; AIMS65 SCORE; SYSTEMS;
   NONVARICEAL; MULTICENTER; HEMORRHAGE; STRATIFICATION; PERFORMANCE;
   OUTCOMES
AB Introduction: Acute upper-gastrointestinal bleeding (AUGIB) is a common medical emergency, with an incidence of 103-172 per 100,000 in the United Kingdom (UK) and mortality of 2% to 10%. Early and accurate prediction of the severity of an AUGIB episode may help guide management, including in or outpatient management, level of care required, and timing of endoscopy. This article aims to address the clinical utility of the various pre-endoscopic risk assessment tools used in AUGIB. Areas covered: The authors undertook a literature review of the current evidence on the pre-endoscopic risk assessment scores. Additional the authors discuss the recently published novel risk assessment scores. Expert opinion: The evidence shows that GBS is the most clinically useful risk assessment score in correctly identifying very low-risk patients suitable for outpatient management. At present, research is ongoing to assess machine learning in the assessment of patients presenting with AUGIB. More research is needed but it shows promise for the future.
C1 [Tham, Jennifer; Stanley, Adrian] Glasgow Royal Infirm, Dept Gastroenterol, 84 Castle St, Glasgow G4 0SF, Lanark, Scotland.
C3 University of Glasgow
RP Tham, J (通讯作者)，Glasgow Royal Infirm, Dept Gastroenterol, 84 Castle St, Glasgow G4 0SF, Lanark, Scotland.
EM j.tham1@nhs.net
CR Abougergi MS, 2016, J CLIN GASTROENTEROL, V50, P464, DOI 10.1097/MCG.0000000000000395
   Abougergi MS, 2015, GASTROINTEST ENDOSC, V81, P882, DOI 10.1016/j.gie.2014.09.027
   Blatchford O, 2000, LANCET, V356, P1318, DOI 10.1016/S0140-6736(00)02816-6
   Bryant RV, 2013, GASTROINTEST ENDOSC, V78, P576, DOI 10.1016/j.gie.2013.05.003
   Button LA, 2011, ALIMENT PHARM THER, V33, P64, DOI 10.1111/j.1365-2036.2010.04495.x
   Cameron EA, 2002, EUR J GASTROEN HEPAT, V14, P497, DOI 10.1097/00042737-200205000-00006
   Dicu D, 2013, AM J EMERG MED, V31, P94, DOI 10.1016/j.ajem.2012.06.009
   GRALNEK IM, 2015, ENDOSCOPY, V47, pA1, DOI [DOI 10.1055/S-0034-1393172, 10.1055/s-0034-1393172]
   Hearnshaw SA, 2011, GUT, V60, P1327, DOI 10.1136/gut.2010.228437
   Hyett BH, 2013, GASTROINTEST ENDOSC, V77, P551, DOI 10.1016/j.gie.2012.11.022
   Laine L, 2012, AM J GASTROENTEROL, V107, P345, DOI 10.1038/ajg.2011.480
   Lanas A, 2009, AM J GASTROENTEROL, V104, P1633, DOI 10.1038/ajg.2009.164
   Laursen SB, 2018, UNIT EURO GASTRO J, V6, P126
   Laursen SB, 2015, CLIN GASTROENTEROL H, V13, P115, DOI 10.1016/j.cgh.2014.07.023
   Laursen SB, 2012, CLIN GASTROENTEROL H, V10, P1130, DOI 10.1016/j.cgh.2012.06.022
   Lim LG, 2011, ENDOSCOPY, V43, P300, DOI 10.1055/s-0030-1256110
   Martinez-Cara JG, 2016, UNITED EUR GASTROENT, V4, P371, DOI 10.1177/2050640615604779
   Nahon S, 2012, ENDOSCOPY, V44, P998, DOI 10.1055/s-0032-1310006
   National Institute for Health and Care Excellence, 2012, AC UPP GASTR BLEED O
   Oakland K, 2019, CLIN GASTROENTEROL H, V17, P1121, DOI 10.1016/j.cgh.2018.09.039
   Pang SH, 2010, GASTROINTEST ENDOSC, V71, P1134, DOI 10.1016/j.gie.2010.01.028
   Park SM, 2016, GUT LIVER, V10, P526, DOI 10.5009/gnl15153
   Ramaekers R, 2016, ACAD EMERG MED, V23, P1218, DOI 10.1111/acem.13101
   Redondo-Cerezo E, 2020, J GASTROEN HEPATOL, V35, P82, DOI 10.1111/jgh.14811
   Robertson M, 2016, GASTROINTEST ENDOSC, V83, P1151, DOI 10.1016/j.gie.2015.10.021
   Rockall TA, 1996, GUT, V38, P316, DOI 10.1136/gut.38.3.316
   Rotondano G, 2011, GASTROINTEST ENDOSC, V73, P218, DOI 10.1016/j.gie.2010.10.006
   Safari S, 2016, EMERGENCY, V4, P111
   Saltzman JR, 2011, GASTROINTEST ENDOSC, V74, P1215, DOI 10.1016/j.gie.2011.06.024
   Shung D, 2019, DIGEST DIS SCI, V64, P2078, DOI 10.1007/s10620-019-05645-z
   Shung DL, 2019, GASTROENTEROLOGY, P25
   Stanley AJ, 2011, ALIMENT PHARM THER, V34, P470, DOI 10.1111/j.1365-2036.2011.04747.x
   Stanley AJ, 2009, LANCET, V373, P42, DOI 10.1016/S0140-6736(08)61769-9
   Stanley AJ, 2017, BMJ-BRIT MED J, V356, pi6432, DOI DOI 10.1136/BMJ.I6432
   Sung JJY, 2018, GUT, V67, P1757, DOI 10.1136/gutjnl-2018-316276
   Thanapirom K, 2016, J GASTROEN HEPATOL, V31, P761, DOI 10.1111/jgh.13222
   Wong JC, 2015, GASTROENTEROLOGY, V148, pS154
   Wuerth BA, 2018, DIGEST DIS SCI, V63, P1286, DOI 10.1007/s10620-017-4882-6
   Yaka E, 2015, ACAD EMERG MED, V22, P22, DOI 10.1111/acem.12554
   Yang HM, 2016, J GASTROEN HEPATOL, V31, P119, DOI 10.1111/jgh.13057
NR 40
TC 12
Z9 13
U1 2
U2 9
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1747-4124
EI 1747-4132
J9 EXPERT REV GASTROENT
JI Expert Rev. Gastroenterol. Hepatol.
PD DEC 2
PY 2019
VL 13
IS 12
BP 1161
EP 1167
DI 10.1080/17474124.2019.1698292
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA JS0JE
UT WOS:000499999600004
PM 31791160
DA 2023-04-20
ER

PT J
AU Armin, MA
   Barnes, N
   Grimpen, F
   Salvado, O
AF Armin, Mohammad Ali
   Barnes, Nick
   Grimpen, Florian
   Salvado, Olivier
TI Learning colon centreline from optical colonoscopy, a new way to
   generate a map of the internal colon surface
SO HEALTHCARE TECHNOLOGY LETTERS
LA English
DT Article
DE medical image processing; image segmentation; cancer; biomedical optical
   imaging; endoscopes; cameras; biological organs; convolutional neural
   nets; optical colonoscopy; internal colon surface; cancerous polyps;
   ConvNet algorithm; colonoscopy simulator; colonoscopy video frames; 3D
   centreline points; simulated colonoscopy frames; real colonoscopy
   frames; consecutive simulated frames; colon centreline; convolutional
   neural network algorithm
AB Optical colonoscopy is known as a gold standard screening method in detecting and removing cancerous polyps. During this procedure, some polyps may be undetected due to their positions, not being covered by the camera or missed by the surgeon. In this Letter, the authors introduce a novel convolutional neural network (ConvNet) algorithm to map the internal colon surface to a 2D map (visibility map), which can be used to increase the awareness of clinicians about areas they might miss. This was achieved by leveraging a colonoscopy simulator to generate a dataset consisting of colonoscopy video frames and their corresponding colon centreline (CCL) points in 3D camera coordinates. A pair of video frames were used as input to a ConvNet, whereas the output was a point on the CCL and its direction vector. By knowing CCL for each frame and roughly modelling the colon as a cylinder, frames could be unrolled to build a visibility map. They validated their results using both simulated and real colonoscopy frames. Their results showed that using consecutive simulated frames to learn the CCL can be generalised to real colonoscopy video frames to generate a visibility map.
C1 [Armin, Mohammad Ali; Barnes, Nick; Salvado, Olivier] CSIRO Data61 3D Comp Vis, Canberra, ACT, Australia.
   [Barnes, Nick] Coll Engn & Comp Sci ANU, Canberra, ACT, Australia.
   [Grimpen, Florian] Royal Brisbane & Womens Hosp, Dept Gastroenterol & Hepatol, Brisbane, Qld, Australia.
C3 Commonwealth Scientific & Industrial Research Organisation (CSIRO);
   Royal Brisbane & Women's Hospital
RP Armin, MA (通讯作者)，CSIRO Data61 3D Comp Vis, Canberra, ACT, Australia.
EM m.a.armin@gmail.com
RI Armin, mohammad Ali/AAV-4848-2021; Barnes, Nick/Y-2744-2018
OI Armin, mohammad Ali/0000-0003-4884-1557; Barnes,
   Nick/0000-0002-9343-9535
CR Abadi Martin, 2016, arXiv
   Armin MA, 2018, LECT NOTES COMPUT SC, V11041, P108, DOI 10.1007/978-3-030-01201-4_13
   Armin MA, 2016, INT J COMPUT ASS RAD, V11, P1599, DOI 10.1007/s11548-016-1462-8
   Armin MA, 2015, LECT NOTES COMPUT SC, V9349, P396, DOI 10.1007/978-3-319-24553-9_49
   Haker S, 2000, IEEE T MED IMAGING, V19, P665, DOI 10.1109/42.875181
   Hong DH, 2014, COMPUT MED IMAG GRAP, V38, P22, DOI 10.1016/j.compmedimag.2013.10.005
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Imperiale TF, 2009, GASTROINTEST ENDOSC, V69, P1288, DOI 10.1016/j.gie.2007.11.043
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Prema T., COLORECTAL CANC AUST
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Sudarsky S, 2008, LECT NOTES COMPUT SC, V5242, P205, DOI 10.1007/978-3-540-85990-1_25
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Varayil JE, 2011, GASTROENTEROLOGY, V140, pS718
   Yin Z., 2018, 2018 IEEE CVF C COMP
NR 15
TC 3
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2053-3713
J9 HEALTHC TECHNOL LETT
JI Healthc. Technol. Lett.
PD DEC
PY 2019
VL 6
IS 6
SI SI
BP 187
EP 190
DI 10.1049/htl.2019.0073
PG 4
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA KA3ZS
UT WOS:000505737400008
PM 32038855
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Bisschops, R
   East, JE
   Hassan, C
   Hazewinkel, Y
   Kaminski, MF
   Neumann, H
   Pellise, M
   Antonelli, G
   Balen, MB
   Coron, E
   Cortas, G
   Iacucci, M
   Yuichi, M
   Longcroft-Wheaton, G
   Pilonis, N
   Puig, I
   van Hooft, JE
   Dekker, E
AF Bisschops, Raf
   East, James E.
   Hassan, Cesare
   Hazewinkel, Yark
   Kaminski, Michal F.
   Neumann, Helmut
   Pellise, Maria
   Antonelli, Giulio
   Bustamante Balen, Marco
   Coron, Emmanuel
   Cortas, Georges
   Iacucci, Marietta
   Yuichi, Mori
   Longcroft-Wheaton, Gaius
   Pilonis, Nastazja
   Puig, Ignasi
   van Hooft, Jeanin E.
   Dekker, Evelien
TI Advanced imaging for detection and differentiation of colorectal
   neoplasia: European Society of Gastrointestinal Endoscopy (ESGE)
   Guideline - Update 2019
SO ENDOSCOPY
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; WHITE-LIGHT ENDOSCOPY;
   INFLAMMATORY-BOWEL-DISEASE; SERRATED POLYPOSIS SYNDROME; HIGH-DEFINITION
   COLONOSCOPY; DIMINUTIVE COLONIC POLYPS; HIGH-RESOLUTION ENDOSCOPY; TIME
   OPTICAL DIAGNOSIS; HIGH-GRADE DYSPLASIA; OCCULT BLOOD-TEST
AB Main Recommendations 1 ESGE suggests that high definition endoscopy, and dye or virtual chromoendoscopy, as well as add-on devices, can be used in average risk patients to increase the endoscopist's adenoma detection rate. However, their routine use must be balanced against costs and practical considerations. Weak recommendation, high quality evidence. 2 ESGE recommends the routine use of high definition systems in individuals with Lynch syndrome. Strong recommendation, high quality evidence. 3 ESGE recommends the routine use, with targeted biopsies, of dye-based pancolonic chromoendoscopy or virtual chromoendoscopy for neoplasia surveillance in patients with long-standing colitis. Strong recommendation, moderate quality evidence. 4 ESGE suggests that virtual chromoendoscopy and dye-based chromoendoscopy can be used, under strictly controlled conditions, for real-time optical diagnosis of diminutive (<= 5 mm) colorectal polyps and can replace histopathological diagnosis. The optical diagnosis has to be reported using validated scales, must be adequately photodocumented, and can be performed only by experienced endoscopists who are adequately trained, as defined in the ESGE curriculum, and audited. Weak recommendation, high quality evidence. 5 ESGE recommends the use of high definition white-light endoscopy in combination with (virtual) chromoendoscopy to predict the presence and depth of any submucosal invasion in nonpedunculated colorectal polyps prior to any treatment. Strong recommendation, moderate quality evidence. 6 ESGE recommends the use of virtual or dye-based chromoendoscopy in addition to white-light endoscopy for the detection of residual neoplasia at a piecemeal polypectomy scar site. Strong recommendation, moderate quality evidence. 7 ESGE suggests the possible incorporation of computer-aided diagnosis (detection and characterization of lesions) to colonoscopy, if acceptable and reproducible accuracy for colorectal neoplasia is demonstrated in high quality multicenter in vivo clinical studies. Possible significant risks with implementation, specifically endoscopist deskilling and over-reliance on artificial intelligence, unrepresentative training datasets, and hacking, need to be considered. Weak recommendation, low quality evidence.
C1 [Bisschops, Raf] Katholieke Univ Leuven, Dept Gastroenterol & Hepatol, Univ Hosp Leuven, TARGID, Leuven, Belgium.
   [East, James E.] Univ Oxford, John Radcliffe Hosp, Nuffield Dept Med, Expt Med Div,Translat Gastroenterol Unit, Oxford, England.
   [East, James E.] Oxford Natl Inst Hlth Res, Biomed Res Ctr, Oxford, England.
   [Hassan, Cesare] Nuovo Regina Margherita Hosp, Digest Endoscopy Unit, Rome, Italy.
   [Hazewinkel, Yark; van Hooft, Jeanin E.; Dekker, Evelien] Univ Amsterdam, Acad Med Ctr, Dept Gastroenterol & Hepatol, Amsterdam, Netherlands.
   [Kaminski, Michal F.; Pilonis, Nastazja] Maria Sklodowska Curie Mem Canc Ctr, Dept Gastroenterol Oncol, Warsaw, Poland.
   [Kaminski, Michal F.; Pilonis, Nastazja] Inst Oncol, Warsaw, Poland.
   [Kaminski, Michal F.; Pilonis, Nastazja] Med Ctr Postgrad Educ, Dept Gastroenterol Hepatol & Oncol, Warsaw, Poland.
   [Kaminski, Michal F.] Univ Oslo, Inst Hlth & Soc, Oslo, Norway.
   [Neumann, Helmut] Univ Med Ctr Mainz, Dept Med 1, Mainz, Germany.
   [Pellise, Maria] Hosp Clin Barcelona, Dept Gastroenterol, Inst Clin Malalties Digest Metab 1, Barcelona, Spain.
   [Pellise, Maria] Univ Barcelona, CIBERehd, IDIBAPS, Barcelona, Spain.
   [Antonelli, Giulio] Sapienza Univ Rome, St Andrea Univ Hosp, Endoscopy Unit, Rome, Italy.
   [Bustamante Balen, Marco] La Fe Polytech Univ Hosp, Digest Dis Dept, Gastrointestinal Endoscopy Unit, Valencia, Spain.
   [Bustamante Balen, Marco] La Fe Hlth Res Inst, Gastrointestinal Endoscopy Res Grp, Valencia, Spain.
   [Coron, Emmanuel] Univ Nantes, CHU Nantes, IMAD, Nantes, France.
   [Cortas, Georges] Univ Balamand, St George Hosp Univ Med Ctr, Div Gastroenterol, Fac Med, Beirut, Lebanon.
   [Iacucci, Marietta] Univ Birmingham, Inst Immunol & Immunotherapy, Inst Translat Med, Birmingham, W Midlands, England.
   [Iacucci, Marietta] Univ Hosp Birmingham NHS Fdn Trust, Birmingham, W Midlands, England.
   [Yuichi, Mori] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Longcroft-Wheaton, Gaius] Portsmouth Hosp NHS Trust, Portsmouth, Hants, England.
   [Puig, Ignasi] Althaia Xarxa Assistencial Univ Manresa, Digest Dis Dept, Manresa, Spain.
   [Puig, Ignasi] Univ Vic, Univ Cent Catalunya, UVic UCC, Fac Ciencies Salut,Dept Med, Manresa, Spain.
C3 KU Leuven; University Hospital Leuven; University of Oxford; University
   of Oxford; Poliambulatorio Nuovo Regina Margherita; University of
   Amsterdam; Academic Medical Center Amsterdam; Maria Sklodowska-Curie
   National Research Institute of Oncology; Maria Sklodowska-Curie National
   Research Institute of Oncology; Centre of Postgraduate Medical Education
   - Poland; University of Oslo; Johannes Gutenberg University of Mainz;
   University of Barcelona; Hospital Clinic de Barcelona; CIBER - Centro de
   Investigacion Biomedica en Red; CIBEREHD; University of Barcelona;
   Hospital Clinic de Barcelona; IDIBAPS; Sapienza University Rome; Azienda
   Ospedaliera Sant'Andrea; Nantes Universite; CHU de Nantes; University
   Balamand; University of Birmingham; University of Birmingham; Showa
   University; Portsmouth Hospitals NHS Trust; Universitat de Vic -
   Universitat Central de Catalunya (UVic-UCC)
RP Bisschops, R (通讯作者)，Univ Hosp Leuven, Targid, Gastroenterol & Hepatol, 49 Herestr, B-3000 Leuven, Belgium.
EM raf.bisschops@uzleuven.be
RI hassan, cesare/H-2844-2012; van hooft, Jeanin/AAT-3600-2020; Kaminski,
   Michal F./AFN-3411-2022; Mori, Yuichi/AAU-5406-2020; Puig,
   Ignasi/N-1208-2014; Pellise, Maria/ABC-3246-2021; Dekker,
   Evelien/HOH-9015-2023; Bustamante-Balen, Marco/E-2123-2013
OI hassan, cesare/0000-0001-7167-1459; van hooft,
   Jeanin/0000-0002-4424-0079; Puig, Ignasi/0000-0002-9059-8602; Kaminski,
   Michal/0000-0002-9714-6457; Dekker, Evelien/0000-0002-4363-0745;
   Bisschops, Raf/0000-0002-9994-8226; Pilonis, Nastazja
   Dagny/0000-0003-3806-8679; Antonelli, Giulio/0000-0003-1797-3864;
   IACUCCI, MARIETTA/0000-0002-3142-9550; Bustamante-Balen,
   Marco/0000-0003-2019-0158
FU National Institute for Health Research (NIHR) Oxford Biomedical Research
   Centre; National Institute for Health Research (NIHR) Birmingham
   Biomedical Research Centre - Research Foundation Flanders (FWO); Japan
   Society for the Promotion of Science
FX J.E. East was funded by the National Institute for Health Research
   (NIHR) Oxford Biomedical Research Centre, and M. Iacucci receives
   funding support from the National Institute for Health Research (NIHR)
   Birmingham Biomedical Research Centre. R. Bisschops was funded by a
   grant of the Research Foundation Flanders (FWO). Y. Mori was funded by
   the Japan Society for the Promotion of Science. E. Coron, H. Neumann,
   and Y. Hazewinkel received no funding.
CR Abdeljawad K, 2015, GASTROINTEST ENDOSC, V81, P517, DOI 10.1016/j.gie.2014.04.064
   Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Aldridge AJ, 2001, EUR J SURG, V167, P777
   [Anonymous], 2018, UNITED EUR GASTROENT, V6, pA195
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Atkin WS, 2012, ENDOSCOPY, V44, pSE151, DOI 10.1055/s-0032-1309821
   Atkinson NSS, 2019, GASTROENTEROLOGY, V157, P462, DOI 10.1053/j.gastro.2019.04.014
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Backes Y, 2017, AM J GASTROENTEROL, V112, P54, DOI 10.1038/ajg.2016.403
   Backes Y, 2019, GUT, V68, P271, DOI 10.1136/gutjnl-2017-314723
   Bae JH, 2019, CLIN GASTROENTEROL H, V17, P2479, DOI 10.1016/j.cgh.2019.02.019
   Belderbos TDG, 2014, ENDOSCOPY, V46, P388, DOI 10.1055/s-0034-1364970
   Bessissow T, 2018, INFLAMM BOWEL DIS, V24, P2518, DOI 10.1093/ibd/izy188
   Bisschops R, 2018, GUT, V67, P1087, DOI 10.1136/gutjnl-2016-313213
   Bisschops R, 2018, ENDOSCOPY, V50, P211, DOI 10.1055/s-0043-121570
   Bisschops R, 2017, GASTROINTEST ENDOSC, V86, P1100, DOI 10.1016/j.gie.2017.09.024
   Bisschops R, 2017, ENDOSCOPY, V49, P342, DOI 10.1055/s-0042-121005
   Biswas S, 2013, GUT, V62, P475, DOI 10.1136/gutjnl-2012-303233
   Bogie RMM, 2018, ENDOSCOPY, V50, P263, DOI 10.1055/s-0043-121144
   Boparai KS, 2011, ENDOSCOPY, V43, P676, DOI 10.1055/s-0030-1256447
   Bretagne JF, 2010, DIS COLON RECTUM, V53, P339, DOI 10.1007/DCR.0b013e3181c37f9c
   Brown SR, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006439.pub4
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Buchner AM, 2010, GASTROENTEROLOGY, V138, P834, DOI 10.1053/j.gastro.2009.10.053
   Bugajski M, 2015, SCAND J GASTROENTERO, V50, P1261, DOI 10.3109/00365521.2015.1024280
   Burgess NG, 2017, GASTROENTEROLOGY, V153, P732, DOI 10.1053/j.gastro.2017.05.047
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cabitza F, 2017, JAMA-J AM MED ASSOC, V318, P517, DOI 10.1001/jama.2017.7797
   Cairns SR, 2010, GUT, V59, P666, DOI 10.1136/gut.2009.179804
   Carballal S, 2018, GUT, V67, P70, DOI 10.1136/gutjnl-2016-312332
   Cassinotti A, 2019, J CLIN GASTROENTEROL, V53, P269, DOI 10.1097/MCG.0000000000000974
   Cellier C, 2019, AM J GASTROENTEROL, V114, P1665, DOI 10.14309/ajg.0000000000000386
   Chan JL, 2012, WORLD J GASTROENTERO, V18, P5905, DOI 10.3748/wjg.v18.i41.5905
   Chandran S, 2015, INTERN MED J, V45, P1293, DOI 10.1111/imj.12917
   Chaput U, 2011, DIGEST LIVER DIS, V43, P609, DOI 10.1016/j.dld.2011.02.002
   Chen C, 2019, PREV MED, V123, P333, DOI 10.1016/j.ypmed.2019.03.048
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chiu HM, 2014, DIGEST ENDOSC, V26, P64, DOI 10.1111/den.12260
   Church JM, 2004, DIS COLON RECTUM, V47, P481, DOI 10.1007/s10350-003-0078-6
   Clark BT, 2014, AM J GASTROENTEROL, V109, P1714, DOI 10.1038/ajg.2014.232
   Coe SG, 2012, GASTROINTEST ENDOSC, V76, P118, DOI 10.1016/j.gie.2012.03.007
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deenadayalu VP, 2004, AM J GASTROENTEROL, V99, P2138, DOI 10.1111/j.1572-0241.2004.40430.x
   Deepak P, 2016, GASTROINTEST ENDOSC, V83, P1005, DOI 10.1016/j.gie.2015.09.021
   Dekker E, 2007, ENDOSCOPY, V39, P216, DOI 10.1055/s-2007-966214
   Delamothe T, 2004, BMJ-BRIT MED J, V328, P1, DOI 10.1136/bmj.328.7430.1
   Denis B, 2011, ENDOSCOPY, V43, P81, DOI 10.1055/s-0030-1255952
   Desomer L, 2017, GASTROINTEST ENDOSC, V85, P518, DOI 10.1016/j.gie.2016.06.031
   Dinesen L, 2012, GASTROINTEST ENDOSC, V75, P604, DOI 10.1016/j.gie.2011.10.017
   dos Santos CEO, 2018, EUR J GASTROEN HEPAT, V30, P1514, DOI 10.1097/MEG.0000000000001278
   Dos Santos Carlos Eduardo Oliveira, 2012, Diagn Ther Endosc, V2012, P279521, DOI 10.1155/2012/279521
   Dumonceau JM, 2012, ENDOSCOPY, V44, P626, DOI 10.1055/s-0031-1291747
   East JE, 2008, ENDOSCOPY, V40, P811, DOI 10.1055/s-2008-1077586
   East JE, 2008, GUT, V57, P65, DOI 10.1136/gut.2007.128926
   East JE, 2006, GUT, V55, P1432, DOI 10.1136/gut.2005.087171
   East JE, 2018, LANCET GASTROENTEROL, V3, P10, DOI 10.1016/S2468-1253(17)30366-7
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Elsadani NN, 2011, GUT, V60, P282, DOI 10.1136/gut.2010.225466
   Facciorusso A, 2018, CLIN GASTROENTEROL H, V16, P1209, DOI 10.1016/j.cgh.2017.11.007
   Fatima H, 2008, CLIN GASTROENTEROL H, V6, P109, DOI 10.1016/j.cgh.2007.10.009
   Feuerstein JD, 2019, GASTROINTEST ENDOSC, V90, P186, DOI 10.1016/j.gie.2019.04.219
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Gasia MF, 2016, CLIN GASTROENTEROL H, V14, P704, DOI 10.1016/j.cgh.2015.12.047
   Graser A, 2009, GUT, V58, P241, DOI 10.1136/gut.2008.156448
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Gunther U, 2011, INT J COLORECTAL DIS, V26, P667, DOI 10.1007/s00384-011-1130-y
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P494, DOI 10.1016/j.gie.2011.08.002
   Haanstra JF, 2019, GASTROINTEST ENDOSC, V90, P624, DOI 10.1016/j.gie.2019.04.227
   Har-Noy O, 2017, DIGEST DIS SCI, V62, P2982, DOI 10.1007/s10620-017-4772-y
   Hassan C, 2010, CLIN J GASTROENTEROL, V8, P865
   Hazewinkel Y, 2015, GASTROINTEST ENDOSC, V81, P531, DOI 10.1016/j.gie.2014.06.043
   Hazewinkel Y, 2013, GASTROINTEST ENDOSC, V77, P916, DOI 10.1016/j.gie.2012.12.018
   Henry ZH, 2010, GASTROINTEST ENDOSC, V72, P118, DOI 10.1016/j.gie.2010.01.048
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hewett DG, 2012, GASTROINTEST ENDOSC, V76, P374, DOI 10.1016/j.gie.2012.04.446
   High-Level Expert Group on Artificial Intelligence, ETH GUID TRUSTW AI
   Hlavaty T, 2011, EUR J GASTROEN HEPAT, V23, P680, DOI 10.1097/MEG.0b013e32834791b4
   Hoffman A, 2010, ENDOSCOPY, V42, P827, DOI 10.1055/s-0030-1255713
   Hoffman A, 2010, DIGEST LIVER DIS, V42, P45, DOI 10.1016/j.dld.2009.04.005
   Hong S N, 2012, GASTROINTEST ENDOSC, V75, P1011
   Huneburg R, 2009, ENDOSCOPY, V41, P316, DOI 10.1055/s-0028-1119628
   Hurlstone DP, 2005, AM J GASTROENTEROL, V100, P2167, DOI 10.1111/j.1572-0241.2005.41481.x
   Iacucci M, 2019, ENDOSCOPY, V51, P133, DOI 10.1055/a-0757-7759
   Iacucci M, 2018, ENDOSCOPY, V50, P779, DOI 10.1055/s-0044-100791
   Iacucci M, 2018, AM J GASTROENTEROL, V113, P225, DOI 10.1038/ajg.2017.417
   Iannone A, 2017, CLIN GASTROENTEROL H, V15, P1684, DOI 10.1016/j.cgh.2016.11.021
   Ichimasa K, 2018, ENDOSCOPY, V50, P230, DOI 10.1055/s-0043-122385
   Ignjatovic A, 2011, ENDOSCOPY, V43, P94, DOI 10.1055/s-0030-1256074
   Ignjatovic A, 2012, AM J GASTROENTEROL, V107, P885, DOI 10.1038/ajg.2012.67
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Ijspeert JE, 2015, GASTROINTEST ENDOSC, V81, pAB260, DOI 10.1016/j.gie.2015.03.1348
   Ikematsu H, 2017, GASTROINTEST ENDOSC, V86, P386, DOI 10.1016/j.gie.2017.01.017
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Iwai T, 2019, J GASTROEN HEPATOL, V34, P397, DOI 10.1111/jgh.14409
   Iwatate M, 2018, DIGEST ENDOSC, V30, P642, DOI 10.1111/den.13065
   Jeong YH, 2016, J KOREAN MED SCI, V31, P1426, DOI 10.3346/jkms.2016.31.9.1426
   Jin XF, 2012, J GASTROEN HEPATOL, V27, P882, DOI 10.1111/j.1440-1746.2011.06987.x
   Kahi CJ, 2012, GASTROINTEST ENDOSC, V75, P515, DOI 10.1016/j.gie.2011.08.021
   Kaltenbach T, 2015, GUT, V64, P1569, DOI 10.1136/gutjnl-2014-307742
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kandel P, 2019, GUT, V68, P1633, DOI 10.1136/gutjnl-2018-316574
   Kawaguti FS, 2019, DIS COLON RECTUM, V62, P422, DOI 10.1097/DCR.0000000000001343
   Kawasaki K, 2019, DIGEST ENDOSC, V31, P36, DOI 10.1111/den.13382
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Khashab M, 2009, GASTROINTEST ENDOSC, V70, P344, DOI 10.1016/j.gie.2008.10.037
   Kidambi TD, 2019, CLIN GASTROENTEROL H, V17, P701, DOI 10.1016/j.cgh.2018.06.024
   Kiesslich R, 2003, GASTROENTEROLOGY, V124, P880, DOI 10.1053/gast.2003.50146
   Kiesslich R, 2007, GASTROENTEROLOGY, V132, P874, DOI 10.1053/j.gastro.2007.01.048
   Kim YS, 2011, CLIN GASTROENTEROL H, V9, P744, DOI 10.1016/j.cgh.2011.05.021
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Klare P, 2016, ENDOSCOPY, V48, P909, DOI 10.1055/s-0042-110650
   Knabe M, 2014, AM J GASTROENTEROL, V109, P183, DOI 10.1038/ajg.2013.419
   Kobayashi S, 2019, UNITED EUR GASTROENT, V7, P914, DOI 10.1177/2050640619845987
   Kolligs FT, 2013, GUT, V62, P863, DOI 10.1136/gutjnl-2011-300111
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P49, DOI 10.1159/000481230
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Konijeti GG, 2014, GASTROINTEST ENDOSC, V79, P455, DOI 10.1016/j.gie.2013.10.026
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Kudo Shin-ei, 2008, Gastrointest Endosc Clin N Am, V18, P581, DOI 10.1016/j.giec.2008.05.013
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lecomte T, 2005, CLIN GASTROENTEROL H, V3, P897, DOI 10.1016/S1542-3565(05)00403-9
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P603, DOI 10.1016/j.gie.2011.04.049
   Lesne A, 2017, ENDOSCOPY, V49, P765, DOI 10.1055/s-0043-105073
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Longcroft-Wheaton G, 2012, ENDOSCOPY, V44, P905, DOI 10.1055/s-0032-1310004
   Longcroft-Wheaton GR, 2011, EUR J GASTROEN HEPAT, V23, P903, DOI 10.1097/MEG.0b013e328349e276
   Lopez-Vicente J, 2019, CLIN GASTROENTEROL H, V17, P2016, DOI 10.1016/j.cgh.2018.10.029
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Marion JF, 2008, AM J GASTROENTEROL, V103, P2342, DOI 10.1111/j.1572-0241.2008.01934.x
   Marion JF, 2016, CLIN GASTROENTEROL H, V14, P713, DOI 10.1016/j.cgh.2015.11.011
   Matsuda T, 2008, AM J GASTROENTEROL, V103, P2700, DOI 10.1111/j.1572-0241.2008.02190.x
   Matsumoto T, 2010, COLORECTAL DIS, V12, pE291, DOI 10.1111/j.1463-1318.2009.02181.x
   Matsumoto T, 2003, AM J GASTROENTEROL, V98, P1827, DOI 10.1016/S0002-9270(03)00429-5
   Matsumoto T, 2007, GASTROINTEST ENDOSC, V66, P957, DOI 10.1016/j.gie.2007.04.014
   Min M, 2017, GASTROINTEST ENDOSC, V86, P724, DOI 10.1016/j.gie.2017.02.035
   Minoda Y, 2019, DIGEST ENDOSC, V31, P544, DOI 10.1111/den.13393
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Mooiweer E, 2015, AM J GASTROENTEROL, V110, P1014, DOI 10.1038/ajg.2015.63
   Moreira L, 2013, GUT, V62, P476, DOI 10.1136/gutjnl-2012-303496
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Moss A, 2015, GUT, V64, P57, DOI 10.1136/gutjnl-2013-305516
   Moussata D, 2018, GUT, V67, P616, DOI 10.1136/gutjnl-2016-311892
   Nagorni A, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008361.pub2
   Nusko G, 1997, INT J COLORECTAL DIS, V12, P267, DOI 10.1007/s003840050103
   Oka S, 2014, DIGEST ENDOSC, V26, P78, DOI 10.1111/den.12275
   dos Santos CEO, 2015, ENDOSC INT OPEN, V3, pE240, DOI 10.1055/s-0034-1391667
   dos Santos CEO, 2010, EUR J GASTROEN HEPAT, V22, P1364, DOI 10.1097/MEG.0b013e32833a5d63
   Omata F, 2014, SCAND J GASTROENTERO, V49, P222, DOI 10.3109/00365521.2013.863964
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Paggi S, 2012, ENDOSCOPY, V44, P899, DOI 10.1055/s-0032-1309891
   Paggi S, 2018, ENDOSCOPY, V50, P396, DOI 10.1055/a-0580-7405
   Paggi S, 2015, ENDOSCOPY, V47, P808, DOI 10.1055/s-0034-1392042
   Pasha SF, 2012, AM J GASTROENTEROL, V107, P363, DOI 10.1038/ajg.2011.436
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Pellise M, 2011, GASTROINTEST ENDOSC, V74, P840, DOI 10.1016/j.gie.2011.05.013
   Pickhardt PJ, 2009, AM J ROENTGENOL, V193, P40, DOI 10.2214/AJR.08.1709
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Picot J, 2017, HEALTH TECHNOL ASSES, V21, P1, DOI 10.3310/hta21790
   Pigo F, 2013, INT J COLORECTAL DIS, V28, P399, DOI 10.1007/s00384-012-1583-7
   Pioche M, 2018, GASTROINTEST ENDOSC, V88, P107, DOI 10.1016/j.gie.2018.01.025
   Pohl J, 2009, GUT, V58, P73, DOI 10.1136/gut.2008.153601
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Povyakalo AA, 2013, MED DECIS MAKING, V33, P98, DOI 10.1177/0272989X12465490
   Puig I, 2019, CURR OPIN GASTROEN, V35, P432, DOI 10.1097/MOG.0000000000000570
   Puig I, 2019, GASTROENTEROLOGY, V156, P75, DOI 10.1053/j.gastro.2018.10.004
   Rahmi G, 2015, AM J GASTROENTEROL, V110, P288, DOI 10.1038/ajg.2014.423
   Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259
   Ramsoekh D, 2010, GUT, V59, P785, DOI 10.1136/gut.2008.151589
   Rastogi A, 2014, GASTROINTEST ENDOSC, V79, P390, DOI 10.1016/j.gie.2013.07.032
   Rastogi A, 2011, GASTROINTEST ENDOSC, V74, P593, DOI 10.1016/j.gie.2011.04.050
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Regula J, 2006, NEW ENGL J MED, V355, P1863, DOI 10.1056/NEJMoa054967
   Repici A, 2016, GASTROINTEST ENDOSC, V84, P479
   Repici A, 2019, GASTROENTEROLOGY, V156, P2198, DOI 10.1053/j.gastro.2019.02.001
   Repici A, 2013, GASTROINTEST ENDOSC, V78, P106, DOI 10.1016/j.gie.2013.01.035
   Rex DK, 2003, AM J GASTROENTEROL, V98, P2000, DOI 10.1016/S0002-9270(03)00625-7
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rex DK, 2009, AM J GASTROENTEROL, V104, P149, DOI 10.1038/ajg.2008.35
   Richardson WS, 1995, ACP J CLUB, V123, P12, DOI DOI 10.7326/ACPJC-1995-123-3-A12
   Pons FR, 2018, WORLD J GASTROENTERO, V24, P5179, DOI 10.3748/wjg.v24.i45.5179
   Rivero Sanchez L, 2018, UNITED EUR GASTROENT, V6, pA117
   Rivero-Sanchez L, 2019, ENDOSCOPY, V51, P637, DOI 10.1055/a-0925-4956
   Rivero-Sanchez L, 2017, ENDOSCOPY, V49, P44, DOI 10.1055/s-0042-115640
   Roelandt P, 2019, ENDOSCOPY, V51, P237, DOI 10.1055/a-0755-7471
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Ross C., 2018, IBMS WATSON SUPERCOM
   Rutter MD, 2004, GUT, V53, P256, DOI 10.1136/gut.2003.016386
   Sakamoto T, 2013, COLORECTAL DIS, V15, pE295, DOI 10.1111/codi.12210
   Sakamoto T, 2018, GASTROINTEST ENDOSC, V87, P1318, DOI 10.1016/j.gie.2017.12.021
   Sakamoto T, 2012, J GASTROEN HEPATOL, V27, P351, DOI 10.1111/j.1440-1746.2011.06854.x
   Sano Y, 2009, GASTROINTEST ENDOSC, V69, P278, DOI 10.1016/j.gie.2008.04.066
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Shahid MW, 2012, AM J GASTROENTEROL, V107, P231, DOI 10.1038/ajg.2011.376
   Shapiro R, 2012, INT J COLORECTAL DIS, V27, P1071, DOI 10.1007/s00384-012-1409-7
   Aladren BS, 2019, ENDOSC INT OPEN, V7, pE743, DOI 10.1055/a-0839-4514
   Singh R, 2013, DIGEST ENDOSC, V25, P16, DOI 10.1111/den.12075
   Sinh P, 2015, DIGEST ENDOSC, V27, P374, DOI 10.1111/den.12403
   Smith SCL, 2019, DIGEST ENDOSC, V31, P535, DOI 10.1111/den.13389
   Solon C, 2016, J MED ECON, V19, P1040, DOI 10.1080/13696998.2016.1192550
   Stock C, 2010, ENDOSCOPY, V42, P546, DOI 10.1055/s-0029-1244127
   Stoffel EM, 2008, CANCER PREV RES, V1, P470, DOI 10.1158/1940-6207.CAPR-08-0098
   Subramanian V, 2011, ENDOSCOPY, V43, P499, DOI 10.1055/s-0030-1256207
   Subramanian V, 2011, ALIMENT PHARM THER, V33, P304, DOI 10.1111/j.1365-2036.2010.04525.x
   Sugimoto S, 2017, GASTROINTEST ENDOSC, V85, P639, DOI 10.1016/j.gie.2016.11.013
   Sumimoto K, 2017, GASTROINTEST ENDOSC, V86, P700, DOI 10.1016/j.gie.2017.02.018
   Sumimoto K, 2017, GASTROINTEST ENDOSC, V85, P816, DOI 10.1016/j.gie.2016.07.035
   Suna N, 2015, ACTA GASTRO-ENT BELG, V78, P287
   Takeuchi Y, 2019, GASTROINTEST ENDOSC, V89, P460, DOI 10.1016/j.gie.2018.11.012
   Togashi K, 2009, GASTROINTEST ENDOSC, V69, P734, DOI 10.1016/j.gie.2008.10.063
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Tsai FC, 2011, DIGEST DIS SCI, V56, P2384, DOI 10.1007/s10620-011-1598-x
   Tsai TL, 2003, J AM MED INFORM ASSN, V10, P478, DOI 10.1197/jamia.M1279
   Turner KO, 2018, AM J GASTROENTEROL, V113, P303, DOI 10.1038/ajg.2017.439
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Van Assche G, 2013, J CROHNS COLITIS, V7, P1, DOI 10.1016/j.crohns.2012.09.005
   van den Broek FJC, 2008, GUT, V57, P1083, DOI 10.1136/gut.2007.144097
   van den Broek FJC, 2011, ENDOSCOPY, V43, P108, DOI 10.1055/s-0030-1255956
   van den Broek FJC, 2014, AM J GASTROENTEROL, V109, P715, DOI 10.1038/ajg.2011.93
   van den Broek FJC, 2009, CLIN GASTROENTEROL H, V7, P288, DOI 10.1016/j.cgh.2008.10.025
   van Leerdam ME, 2019, ENDOSCOPY, V51, P877, DOI 10.1055/a-0965-0605
   Vemulapalli KC, 2012, GASTROINTEST ENDOSC, V75, P1206, DOI 10.1016/j.gie.2012.01.033
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Vleugels JLA, 2019, GASTROENTEROLOGY, V156, P623, DOI 10.1053/j.gastro.2018.10.050
   Vleugels JLA, 2018, J CROHNS COLITIS, V12, P1438, DOI 10.1093/ecco-jcc/jjy129
   Vleugels JLA, 2018, GASTROENTEROLOGY, V154, P1682, DOI 10.1053/j.gastro.2018.01.063
   Vleugels JLA, 2018, LANCET GASTROENTEROL, V3, P305, DOI 10.1016/S2468-1253(18)30055-4
   Vleugels JLA, 2017, ENDOSC INT OPEN, V5, pE1197, DOI 10.1055/s-0043-113565
   von Renteln D, 2018, CLIN GASTROENTEROL H, V16, P706, DOI 10.1016/j.cgh.2017.11.036
   Vu HT, 2015, DIGEST DIS SCI, V60, P502, DOI 10.1007/s10620-014-3376-z
   Wallace MB, 2014, GASTROINTEST ENDOSC, V80, P1072, DOI 10.1016/j.gie.2014.05.305
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Watanabe T, 2016, GASTROENTEROLOGY, V151, P1122, DOI 10.1053/j.gastro.2016.08.002
   WESTON AP, 1995, AM J GASTROENTEROL, V90, P24
   Yoo TW, 2007, HEPATO-GASTROENTEROL, V54, P418
   Zhao ZY, 2015, ENDOSC INT OPEN, V3, pE226, DOI 10.1055/s-0034-1391708
   Zimmermann-Fraedrich K, 2018, ENDOSCOPY, V50, P878, DOI 10.1055/a-0607-2636
NR 252
TC 116
Z9 119
U1 0
U2 10
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD DEC
PY 2019
VL 51
IS 12
BP 1155
EP 1179
DI 10.1055/a-1031-7657
PG 25
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA JU6WR
UT WOS:000501815100042
PM 31711241
OA Green Accepted, Green Submitted, Bronze
DA 2023-04-20
ER

PT J
AU Cho, BJ
   Bang, CS
   Park, SW
   Yang, YJ
   Seo, SI
   Lim, H
   Shin, WG
   Hong, JT
   Yoo, YT
   Hong, SH
   Choi, JH
   Lee, JJ
   Baik, GH
AF Cho, Bum-Joo
   Bang, Chang Seok
   Park, Se Woo
   Yang, Young Joo
   Seo, Seung In
   Lim, Hyun
   Shin, Woon Geon
   Hong, Ji Taek
   Yoo, Yong Tak
   Hong, Seok Hwan
   Choi, Jae Ho
   Lee, Jae Jun
   Baik, Gwang Ho
TI Automated classification of gastric neoplasms in endoscopic images using
   a convolutional neural network
SO ENDOSCOPY
LA English
DT Article
ID CANCER
AB Background Visual inspection, lesion detection, and differentiation between malignant and benign features are key aspects of an endoscopist's role. The use of machine learning for the recognition and differentiation of images has been increasingly adopted in clinical practice. This study aimed to establish convolutional neural network (CNN) models to automatically classify gastric neoplasms based on endoscopic images. Methods Endoscopic white-light images of pathologically confirmed gastric lesions were collected and classified into five categories: advanced gastric cancer, early gastric cancer, high grade dysplasia, low grade dysplasia, and non-neoplasm. Three pretrained CNN models were fine-tuned using a training dataset. The classifying performance of the models was evaluated using a test dataset and a prospective validation dataset. Results A total of 5017 images were collected from 1269 patients, among which 812 images from 212 patients were used as the test dataset. An additional 200 images from 200 patients were collected and used for prospective validation. For the five-category classification, the weighted average accuracy of the Inception-Resnet-v2 model reached 84.6 %. The mean area under the curve (AUC) of the model for differentiating gastric cancer and neoplasm was 0.877 and 0.927, respectively. In prospective validation, the Inception-Resnet-v2 model showed lower performance compared with the endoscopist with the best performance (five-category accuracy 76.4 % vs. 87.6 %; cancer 76.0 % vs. 97.5 %; neoplasm 73.5 % vs. 96.5 %; P < 0.001). However, there was no statistical difference between the Inception-Resnet-v2 model and the endoscopist with the worst performance in the differentiation of gastric cancer (accuracy 76.0 % vs. 82.0 %) and neoplasm (AUC 0.776 vs. 0.865). Conclusion The evaluated deep-learning models have the potential for clinical application in classifying gastric cancer or neoplasm on endoscopic white-light images.
C1 [Cho, Bum-Joo] Hallym Univ, Dept Ophthalmol, Coll Med, Chunchon, South Korea.
   [Cho, Bum-Joo] Seoul Natl Univ, Coll Med, Interdisciplinary Program Med Informat, Seoul, South Korea.
   [Cho, Bum-Joo; Bang, Chang Seok; Yang, Young Joo; Choi, Jae Ho; Lee, Jae Jun] Hallym Univ, Coll Med, Inst New Frontier Res, Chunchon, South Korea.
   [Bang, Chang Seok; Park, Se Woo; Yang, Young Joo; Seo, Seung In; Lim, Hyun; Shin, Woon Geon; Hong, Ji Taek; Baik, Gwang Ho] Hallym Univ, Coll Med, Dept Internal Med, Sakju Ro 77, Chunchon 24253, Gangwon Do, South Korea.
   [Bang, Chang Seok; Park, Se Woo; Yang, Young Joo; Seo, Seung In; Lim, Hyun; Shin, Woon Geon; Hong, Ji Taek; Baik, Gwang Ho] Hallym Univ, Inst Liver & Digest Dis, Chunchon, South Korea.
   [Yoo, Yong Tak; Hong, Seok Hwan] Dudaji Inc, Seoul, South Korea.
   [Lee, Jae Jun] Hallym Univ, Coll Med, Dept Anesthesiol & Pain Med, Chunchon, South Korea.
C3 Hallym University; Seoul National University (SNU); Hallym University;
   Hallym University; Hallym University; Hallym University
RP Bang, CS (通讯作者)，Hallym Univ, Coll Med, Dept Internal Med, Sakju Ro 77, Chunchon 24253, Gangwon Do, South Korea.
EM csbang@hallym.ac.kr
RI Bang, Chang SEOK/I-9689-2019
OI Cho, Bum-Joo/0000-0002-0244-388X; Seo, Seung In/0000-0003-4417-0135;
   YANG, YOUNGJOO/0000-0001-6325-1104
FU Bio & Medical Technology Development Program of the National Research
   Foundation (NRF); Korean government, Ministry of Science and ICT (MSIT)
   [NRF2017M3A9E8033207]
FX This research was supported by the Bio & Medical Technology Development
   Program of the National Research Foundation (NRF) and funded by the
   Korean government, Ministry of Science and ICT (MSIT) (grant number
   NRF2017M3A9E8033207).
CR Anderson MA, 2009, GASTROINTEST ENDOSC, V70, P1060, DOI 10.1016/j.gie.2009.09.040
   Bang Chang Seok, 2015, Korean Journal of Helicobacter Upper Gastrointestinal Research, V15, P33, DOI 10.7704/kjhugr.2015.15.1.33
   Bang CS, 2015, WORLD J GASTROENTERO, V21, P6032, DOI 10.3748/wjg.v21.i19.6032
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cohen J, 2006, AM J GASTROENTEROL, V101, P886, DOI 10.1111/j.1572-0241.2006.00676.x
   Cotton PB, 2006, GASTROINTEST ENDOSC, V64, P395, DOI 10.1016/j.gie.2006.05.003
   de Vries AC, 2008, GASTROENTEROLOGY, V134, P945, DOI 10.1053/j.gastro.2008.01.071
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hong JS, 2017, IEEE ENG MED BIO, P2892, DOI 10.1109/EMBC.2017.8037461
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jun JK, 2017, GASTROENTEROLOGY, V152, P1319, DOI 10.1053/j.gastro.2017.01.029
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Muguruma N, 2013, CLIN ENDOSC, V46, P603, DOI 10.5946/ce.2013.46.6.603
   Park JM, 2017, GASTROENTEROLOGY, V153, P460, DOI 10.1053/j.gastro.2017.05.009
   Stolte M, 2003, VIRCHOWS ARCH, V442, P99, DOI 10.1007/s00428-002-0680-3
NR 16
TC 62
Z9 64
U1 3
U2 25
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD DEC
PY 2019
VL 51
IS 12
BP 1121
EP 1129
DI 10.1055/a-0981-6133
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA JU6WR
UT WOS:000501815100036
PM 31443108
DA 2023-04-20
ER

PT J
AU Ebigbo, A
   Palm, C
   Probst, A
   Mendel, R
   Manzeneder, J
   Prinz, F
   de Souza, LA
   Papa, JP
   Siersema, P
   Messmann, H
AF Ebigbo, Alanna
   Palm, Christoph
   Probst, Andreas
   Mendel, Robert
   Manzeneder, Johannes
   Prinz, Friederike
   de Souza, Luis A.
   Papa, Joao P.
   Siersema, Peter
   Messmann, Helmut
TI A technical review of artificial intelligence as applied to
   gastrointestinal endoscopy: clarifying the terminology
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Review
ID HELICOBACTER-PYLORI INFECTION; COMPUTER-AIDED DIAGNOSIS;
   BARRETTS-ESOPHAGUS; CLASSIFICATION; LESIONS; CANCER; SYSTEM
AB Background and aim The growing number of publications on the application of artificial intelligence (AI) in medicine underlines the enormous importance and potential of this emerging field of research. In gastrointestinal endoscopy, AI has been applied to all segments of the gastrointestinal tract most importantly in the detection and characterization of colorectal polyps. However, AI research has been published also in the stomach and esophagus for both neoplastic and non-neoplastic disorders. The various technical as well as medical aspects of AI, however, remain confusing especially for non-expert physicians. This physician-engineer co-authored review explains the basic technical aspects of AI and provides a comprehensive overview of recent publications on AI in gastrointestinal endoscopy. Finally, a basic insight is offered into understanding publications on AI in gastrointestinal endoscopy.
C1 [Ebigbo, Alanna; Probst, Andreas; Manzeneder, Johannes; Prinz, Friederike; Messmann, Helmut] Univ Klinikum Augsburg, Dept Gastroenterol, Augsburg, Germany.
   [Palm, Christoph; Mendel, Robert; de Souza, Luis A.] Ostbayer TH Regensburg OTH Regensburg, Regensburg Med Image Comp ReMIC, Regensburg, Germany.
   [Palm, Christoph; Mendel, Robert] OTH Regensburg, Regensburg Ctr Hlth Sci & Technol, Regensburg, Germany.
   [de Souza, Luis A.] Univ Fed Sao Carlos, Dept Comp, Sao Carlos, SP, Brazil.
   [Papa, Joao P.] Sao Paulo State Univ, Dept Comp, Sao Paulo, SP, Brazil.
   [Siersema, Peter] Radboud Univ Nijmegen, Dept Gastroenterol & Hepatol, Med Ctr, Nijmegen, Netherlands.
C3 Universidade Federal de Sao Carlos; Universidade Estadual Paulista;
   Radboud University Nijmegen
RP Ebigbo, A (通讯作者)，Univ Klinikum Augsburg, Stenglinstr 2, D-86156 Augsburg, Germany.
EM Alanna.ebigbo@gmx.de
RI Siersema, Peter/V-1636-2019; Ebigbo, Alanna/ACP-0443-2022; Papa, Joao
   Paulo/ABC-6283-2020; Messmann, Helmut/AAB-6758-2020; Messmann,
   Helmut/AAQ-3568-2021
OI Papa, Joao Paulo/0000-0002-6494-7514; Souza Jr., Luis
   Antonio/0000-0002-7060-6097
CR Baker JA, 2003, AM J ROENTGENOL, V181, P1083, DOI 10.2214/ajr.181.4.1811083
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   de Groof J, 2019, UNITED EUR GASTROENT, V7, P538, DOI 10.1177/2050640619837443
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ghatwary N, 2019, INT J COMPUT ASS RAD, V14, P611, DOI 10.1007/s11548-019-01914-4
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He K., 2016, P IEEE C COMP VIS PA
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Iizuka T, 2008, J GASTROEN HEPATOL, V23, P1358, DOI 10.1111/j.1440-1746.2008.05528.x
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Mendel R., 2017, BILDVERARBEITUNG MED, P80
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Scholvinck DW, 2017, ENDOSCOPY, V49, P113, DOI 10.1055/s-0042-118312
   Sharma P, 2016, GASTROENTEROLOGY, V150, P591, DOI 10.1053/j.gastro.2015.11.037
   Topol E. J., 2019, DEEP MED
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Wang P, 2019, GUT
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 29
TC 27
Z9 28
U1 2
U2 7
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD DEC
PY 2019
VL 7
IS 12
BP E1616
EP E1623
DI 10.1055/a-1010-5705
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA JU6TW
UT WOS:000501807800006
PM 31788542
OA gold, Green Submitted, Green Published
DA 2023-04-20
ER

PT J
AU Furukawa, R
   Nagamatsu, G
   Oka, S
   Kotachi, T
   Okamoto, Y
   Tanaka, S
   Kawasaki, H
AF Furukawa, Ryo
   Nagamatsu, Genki
   Oka, Shiro
   Kotachi, Takahiro
   Okamoto, Yuki
   Tanaka, Shinji
   Kawasaki, Hiroshi
TI Simultaneous shape and camera-projector parameter estimation for 3D
   endoscopic system using CNN-based grid-oneshot scan
SO HEALTHCARE TECHNOLOGY LETTERS
LA English
DT Article
DE image matching; medical image processing; cameras; endoscopes; computer
   vision; feature extraction; stereo image processing; neural nets; image
   reconstruction; learning (artificial intelligence); extended bundle
   adjustment technique; camera-projector parameter estimation; 3D
   endoscopic system; CNN-based grid-oneshot scan; situ endoscopic
   diagnosis; polyp sizes; active stereo technique; special pattern;
   feature extraction; endoscope camera; pattern projection area;
   learning-based technique
AB For effective in situ endoscopic diagnosis and treatment, measurement of polyp sizes is important. For this purpose, 3D endoscopic systems have been researched. Among such systems, an active stereo technique, which projects a special pattern wherein each feature is coded, is a promising approach because of simplicity and high precision. However, previous works of this approach have problems. First, the quality of 3D reconstruction depended on the stabilities of feature extraction from the images captured by the endoscope camera. Second, due to the limited pattern projection area, the reconstructed region was relatively small. In this Letter, the authors propose a learning-based technique using convolutional neural networks to solve the first problem and an extended bundle adjustment technique, which integrates multiple shapes into a consistent single shape, to address the second. The effectiveness of the proposed techniques compared to previous techniques was evaluated experimentally.
C1 [Furukawa, Ryo] Hiroshima City Univ, Grad Sch Informat Sci, Hiroshima, Japan.
   [Nagamatsu, Genki; Kawasaki, Hiroshi] Kyushu Univ, Grad Sch, Fukuoka, Fukuoka, Japan.
   [Nagamatsu, Genki; Kawasaki, Hiroshi] Kyushu Univ, Fac Informat Sci & Elect Engn, Fukuoka, Fukuoka, Japan.
   [Oka, Shiro] Hiroshima Univ Hosp, Dept Gastroenterol & Metab, Hiroshima, Japan.
   [Kotachi, Takahiro; Okamoto, Yuki; Tanaka, Shinji] Hiroshima Univ Hosp, Dept Endoscopy, Hiroshima, Japan.
C3 Kyushu University; Kyushu University; Hiroshima University; Hiroshima
   University
RP Furukawa, R (通讯作者)，Hiroshima City Univ, Grad Sch Informat Sci, Hiroshima, Japan.
EM ryo-f@hiroshima-cu.ac.jp
RI Furukawa, Ryo/GWZ-2117-2022; Oka, Shiro/AAZ-8368-2021
OI Furukawa, Ryo/0000-0002-2063-1008; 
FU JSPS/KAKENHI [16H02849, 16KK0151, 18H04119, 18K19824, MSRA CORE14];
   Grants-in-Aid for Scientific Research [16H02849] Funding Source: KAKEN
FX This work is supported by JSPS/KAKENHI 16H02849, 16KK0151, 18H04119,
   18K19824, and MSRA CORE14.
CR Carr JC, 1997, IEEE T MED IMAGING, V16, P96, DOI 10.1109/42.552059
   Furukawa R, 2016, IEEE ENG MED BIO, P2091, DOI 10.1109/EMBC.2016.7591140
   Furukawa R, 2016, LECT NOTES COMPUT SC, V9910, P399, DOI 10.1007/978-3-319-46466-4_24
   Geurten J, 2018, LECT NOTES COMPUT SC, V11073, P143, DOI 10.1007/978-3-030-00937-3_17
   Grasa OG, 2014, IEEE T MED IMAGING, V33, P135, DOI 10.1109/TMI.2013.2282997
   Inokuchi S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P806
   Lin JY, 2015, LECT NOTES COMPUT SC, V9349, P405, DOI 10.1007/978-3-319-24553-9_50
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Stoyanov D, 2010, LECT NOTES COMPUT SC, V6361, P275
   Visentini-Scarzanella M, 2012, IEEE IMAGE PROC, P25, DOI 10.1109/ICIP.2012.6466786
NR 11
TC 7
Z9 7
U1 0
U2 1
PU INST ENGINEERING TECHNOLOGY-IET
PI HERTFORD
PA MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND
EI 2053-3713
J9 HEALTHC TECHNOL LETT
JI Healthc. Technol. Lett.
PD DEC
PY 2019
VL 6
IS 6
SI SI
BP 249
EP 254
DI 10.1049/htl.2019.0070
PG 6
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA KA3ZS
UT WOS:000505737400019
PM 32038866
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Guo, XD
   Zhang, N
   Guo, JF
   Zhang, HH
   Hao, YG
   Hang, JQ
AF Guo, Xudong
   Zhang, Na
   Guo, Jiefang
   Zhang, Huihe
   Hao, Youguo
   Hang, Jingqing
TI Automated polyp segmentation for colonoscopy images: A method based on
   convolutional neural networks and ensemble learning
SO MEDICAL PHYSICS
LA English
DT Article
DE colonoscopy image; deep learning; ensemble learning; polyp segmentation;
   transfer learning
AB Purpose: To automatically and efficiently segment the lesion area of the colonoscopy polyp image, a polyp segmentation method has been presented.
   Methods: An ensemble model of pretrained convolutional neural networks was proposed, using Unet-VGG, SegNet-VGG, and PSPNet. Firstly, the Unet-VGG is obtained by the first 10 layers of VGG16 as the contraction path of the left half of the Unet. Then, the SegNet-VGG is acquired by fine-tuned transfer learning VGG16, using the first 13 layers of VGG16 as the encoder of the SegNet and combined the original decoder of the SegNet. By adjusting the input size of the Unet-VGG, SegNet-VGG, and PSPNet, the preprocessed data can be correctly fed to the three network models. The three models are used as the basic trainer to train and segment the datasets. Based on the ensemble learning algorithm, the weight voting method is used to ensemble the segmentation results corresponding to single basic trainer.
   Results: Both IoU and DICE similarity score were used to evaluate the segmentation quality for cvc300 with 300 images, CVC-ClinicDB with 612 images, and ETIS-LaribPolypDB with 196 images. From the experimental results, the IoU and DICE obtained by the proposed method for the cvc300 datasets can reach up to 96.16% and 98.04%, respectively, the IoU and DICE for the CVCC-linicDB datasets can reach up to 96.66% and 98.30%, respectively, whereas the IoU and DICE for the ETIS-LaribPolypDB datasets can reach up to 96.95% and 98.45%, respectively. Evaluation of the IoU and DICE in our methods shows higher accuracy than previous methods.
   Conclusions: The experimental results show that the proposed method improved correspondingly in IoU and DICE compared to a single basic trainer. The range of improvement is 1.98%-6.38%. The proposed ensemble learning succeeds in automatic polyp segmentation, which potentially helps to establish more polyp datasets. (C) 2019 American Association of Physicists in Medicine
C1 [Guo, Xudong; Zhang, Na; Zhang, Huihe] Univ Shanghai Sci & Technol, Sch Med Instrument & Food Engn, Shanghai 200093, Peoples R China.
   [Guo, Jiefang] Changhai Hosp, Dept Gastroenterol, Shanghai 200433, Peoples R China.
   [Hao, Youguo; Hang, Jingqing] Shanghai Putuo Peoples Hosp, Dept Rehabil, Shanghai 200060, Peoples R China.
C3 University of Shanghai for Science & Technology; Naval Medical
   University
RP Guo, JF (通讯作者)，Changhai Hosp, Dept Gastroenterol, Shanghai 200433, Peoples R China.
EM zn_0506@163.com
RI Guo, Jiefang/AAD-9042-2021
FU Research Project on Community Medicine and Health Management of Shanghai
   Society of Integrated Traditional Chinese and Western Medicine
   [SH201741]; Key Funding Projects for Independent Innovation of Health
   System Research in Putuo District, Shanghai [ptkwws201708]
FX This study was supported by the Research Project on Community Medicine
   and Health Management of Shanghai Society of Integrated Traditional
   Chinese and Western Medicine (no: SH201741) and The Key Funding Projects
   for Independent Innovation of Health System Research in Putuo District,
   Shanghai (no: ptkwws201708).
CR Akbari M, 2018, POLYP SEGMENTATION C, DOI [10.1109/EMBC.2018.8512197, DOI 10.1109/EMBC.2018.8512197]
   Al-Kafri AS, 2019, IEEE ACCESS, V7, P43487, DOI 10.1109/ACCESS.2019.2908002
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bardhi O, 2017, IEEE INT SYMP SIGNAL, P445
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, IEEE T MED IMAGING, V2017, P1
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dutta S, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Fehri H, 2019, IEEE T IMAGE PROCESS, V28, P3246, DOI 10.1109/TIP.2019.2895455
   Gao X, 2018, 2018 7TH INTERNATIONAL CONFERENCE ON SOCIAL SCIENCE, EDUCATION AND HUMANITIES RESEARCH (SSEHR 2018), P182, DOI 10.25236/ssehr.2018.036
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Jing Tang, 2018, 2018 33 YOUTH AC ANN, DOI [10.1109/YAC.2018.8406531, DOI 10.1109/YAC.2018.8406531]
   Kamal U, 2020, IEEE T INTELL TRANSP, V21, P1467, DOI 10.1109/TITS.2019.2911727
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Krishnan K, 2015, IEEE ENG MED BIO, P3093, DOI 10.1109/EMBC.2015.7319046
   Kumar N, 2017, IEEE T MED IMAGING, V36, P1550, DOI 10.1109/TMI.2017.2677499
   Kumar P, 2018, IEEE IMAGE PROC, P3503, DOI 10.1109/ICIP.2018.8451295
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Maghsoudi OH, 2017, CONF REC ASILOMAR C, P209, DOI 10.1109/ACSSC.2017.8335168
   Miyamoto R, 2019, IEEE INT SYMP CIRC S
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sasmal P, 2018, INT CONF CIRC SYST S, P201
   Shan YF, 2018, 2018 INTERNATIONAL CONFERENCE ON CONTROL, ARTIFICIAL INTELLIGENCE, ROBOTICS & OPTIMIZATION (ICCAIRO), P147, DOI 10.1109/ICCAIRO.2018.00032
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Valliappan CA, 2019, ICASSP 2019 2019 IEE, DOI [10.1109/ICASSP.2019.8683153, DOI 10.1109/ICASSP.2019.8683153]
   Vazquez D., 2017, J HEALTHCARE ENG, P1
   Wang W, 2018, 2018 CHIN AUT C CAC, DOI [10.1109/CAC.2018, DOI 10.1109/CAC.2018]
   Weng Y, 2019, IEEE ACCESS, V7, P44247, DOI 10.1109/ACCESS.2019.2908991
   Wickstrom K., 2018, IEEE INT WORKS MACH, P1, DOI DOI 10.1109/MLSP.2018.8516998
   Xiao WT, 2018, IEEE INT C ELECTR TA
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Zeng ZT, 2019, IEEE ACCESS, V7, P21420, DOI 10.1109/ACCESS.2019.2896920
   Zhao X, 2018, 2018 AS PAC SIGN INF, DOI [10.23919/APSIPA.2018.8659654, DOI 10.23919/APSIPA.2018.8659654]
   Zhao Y, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P1, DOI 10.1109/AICAS.2019.8771573
   Zhou Z, 2012, ENSEMBLE METHODS FDN, DOI [10.1109/MCI.2012.2228600, DOI 10.1109/MCI.2012.2228600]
   Zhu B, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P55
NR 48
TC 24
Z9 25
U1 3
U2 31
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD DEC
PY 2019
VL 46
IS 12
BP 5666
EP 5676
DI 10.1002/mp.13865
PG 11
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA KP9VQ
UT WOS:000516580200031
PM 31610020
DA 2023-04-20
ER

PT J
AU Hsieh, YH
   Leung, FW
AF Hsieh, Yu-Hsi
   Leung, Felix W.
TI An overview of deep learning algorithms and water exchange in
   colonoscopy in improving adenoma detection
SO EXPERT REVIEW OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Review
DE Adenoma detection rate; water exchange; artificial intelligence; machine
   learning
ID BOWEL PREPARATION QUALITY; COMPUTER-AIDED DIAGNOSIS; GASTROINTESTINAL
   ENDOSCOPY; POLYP DETECTION; ARTIFICIAL-INTELLIGENCE; TIME; MULTICENTER;
   PREVALENCE; VALIDATION; HISTOLOGY
AB Introduction: Among the Gastrointestinal (GI) Endoscopy Editorial Board top 10 topics in advances in endoscopy in 2018, water exchange colonoscopy and artificial intelligence were both considered important advances. Artificial intelligence holds the potential to increase and water exchange significantly increases adenoma detection. Areas covered: The authors searched MEDLINE (1998-2019) using the following medical subject terms: water-aided, water-assisted and water exchange colonoscopy, adenoma, artificial intelligence, deep learning, computer-assisted detection, and neural networks. Additional related studies were manually searched from the reference lists of publications. Only fully published journal articles in English were reviewed. The latest date of the search was Aug10, 2019. Artificial intelligence, machine learning, and deep learning contribute to the promise of real-time computer-aided detection diagnosis. By emphasizing near-complete suction of infused water during insertion, water exchange provides salvage cleaning and decreases cleaning-related multi-tasking distractions during withdrawal, increasing adenoma detection. The review will address how artificial intelligence and water exchange can complement each other in improving adenoma detection during colonoscopy. Expert opinion: In 5 years, research on artificial intelligence will likely achieve real-time application and evaluation of factors contributing to quality colonoscopy. Better understanding and more widespread use of water exchange will be possible.
C1 [Hsieh, Yu-Hsi] Dalin Tzu Chi Hosp, Buddhist Tzu Chi Med Fdn, Chiayi, Taiwan.
   [Hsieh, Yu-Hsi] Tzu Chi Univ, Sch Med, Hualien, Taiwan.
   [Leung, Felix W.] Vet Affairs Greater Los Angeles Healthcare Syst, Sepulveda Ambulatory Care Ctr, North Hills, CA USA.
   [Leung, Felix W.] Univ Calif Los Angeles, David Geffen Sch Med, Los Angeles, CA 90095 USA.
C3 Buddhist Tzu Chi General Hospital; Dalin Tzu Chi Hospital; Tzu Chi
   University; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); VA Greater Los Angeles Healthcare System;
   University of California System; University of California Los Angeles;
   University of California Los Angeles Medical Center; David Geffen School
   of Medicine at UCLA
RP Hsieh, YH (通讯作者)，Dalin Tzu Chi Hosp, Buddhist Tzu Chi Med Fdn, Dept Med, Div Gastroenterol, 2 Minsheng Rd, Chiayi 62247, Taiwan.
EM hsieh.yuhsi@msa.hinet.net
FU 2016 Endoscopic Research Award titled, "A prospective RCT to Show
   Water-Exchange Cap Assisted Colonoscopy Significantly Increases ADR
   Compared with Water Exchange." (ASGE Sponsored Award, UCLA) [20174037];
   Veterans Affairs Merit Review [5101CX001418-02]
FX This paper was funded by the 2016 Endoscopic Research Award titled, "A
   prospective RCT to Show Water-Exchange Cap Assisted Colonoscopy
   Significantly Increases ADR Compared with Water Exchange." (ASGE
   Sponsored Award, UCLA #20174037). and the Veterans Affairs Merit Review
   (5101CX001418-02).
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Anderson JC, 2014, GASTROINTEST ENDOSC, V80, P463, DOI 10.1016/j.gie.2014.03.021
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Cadoni S, 2017, ENDOSCOPY, V49, P456, DOI 10.1055/s-0043-101229
   Calderwood AH, 2015, GASTROINTEST ENDOSC, V81, P691, DOI 10.1016/j.gie.2014.10.032
   Chokshi RV, 2012, GASTROINTEST ENDOSC, V75, P1197, DOI 10.1016/j.gie.2012.01.005
   Cohen J, 2019, GASTROINTEST ENDOSC, V90, P35, DOI 10.1016/j.gie.2019.03.020
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Lange T, 2018, WORLD J GASTROENTERO, V24, P5057, DOI 10.3748/wjg.v24.i45.5057
   East JE, 2007, AM J GASTROENTEROL, V102, P2529, DOI 10.1111/j.1572-0241.2007.01429.x
   Facciorusso A, 2019, CLIN GASTROENTEROL H, V17, P2439, DOI 10.1016/j.cgh.2018.11.058
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Filip D, 2012, WORLD J GASTROENTERO, V18, P4270, DOI 10.3748/wjg.v18.i32.4270
   Fritz CDL, 2018, DIGEST DIS SCI, V63, P3120, DOI 10.1007/s10620-018-5100-x
   Fuccio L, 2018, GASTROINTEST ENDOSC, V88, P589, DOI 10.1016/j.gie.2018.06.028
   Hsieh YH, 2019, UNITED EUR GASTROENT, V7, P230, DOI 10.1177/2050640618817105
   Hsieh YH, 2017, GASTROINTEST ENDOSC, V86, P192, DOI 10.1016/j.gie.2016.12.005
   Hwang S, 2008, IEEE ENG MED BIO, P3004, DOI 10.1109/IEMBS.2008.4649835
   Jia H, 2019, J CLIN GASTROENTEROL, V53, P523, DOI 10.1097/MCG.0000000000001080
   Jia H, 2017, AM J GASTROENTEROL, V112, P568, DOI 10.1038/ajg.2016.501
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lebwohl B, 2011, GASTROINTEST ENDOSC, V73, P1207, DOI 10.1016/j.gie.2011.01.051
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000007468
   Lee RH, 2011, GASTROINTEST ENDOSC, V74, P128, DOI 10.1016/j.gie.2011.03.003
   Leung JW, 2019, UNITED EUR GASTROENT, V7, P477, DOI 10.1177/2050640619832196
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259
   Rembacken B, 2012, ENDOSCOPY, V44, P957, DOI 10.1055/s-0032-1325686
   Repici A, 2019, GASTROENTEROLOGY, V156, P2198, DOI 10.1053/j.gastro.2019.02.001
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Ruffle JK, 2019, AM J GASTROENTEROL, V114, P422, DOI 10.1038/s41395-018-0268-4
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sawhney MS, 2008, GASTROENTEROLOGY, V135, P1892, DOI 10.1053/j.gastro.2008.08.024
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Soetikno RM, 2008, JAMA-J AM MED ASSOC, V299, P1027, DOI 10.1001/jama.299.9.1027
   Stanek SR, 2013, COMPUT METH PROG BIO, V112, P407, DOI 10.1016/j.cmpb.2013.07.028
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   von Renteln D, 2017, GASTROINTEST ENDOSC, V85, P574, DOI 10.1016/j.gie.2016.08.021
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Yang MH, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-124
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 58
TC 9
Z9 9
U1 3
U2 14
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1747-4124
EI 1747-4132
J9 EXPERT REV GASTROENT
JI Expert Rev. Gastroenterol. Hepatol.
PD DEC 2
PY 2019
VL 13
IS 12
BP 1153
EP 1160
DI 10.1080/17474124.2019.1694903
EA DEC 2019
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA JS0JE
UT WOS:000499573900001
PM 31755802
DA 2023-04-20
ER

PT J
AU Itoh, H
   Roth, H
   Oda, M
   Misawa, M
   Mori, Y
   Kudo, SE
   Mori, K
AF Itoh, Hayato
   Roth, Holger
   Oda, Masahiro
   Misawa, Masashi
   Mori, Yuichi
   Kudo, Shin-Ei
   Mori, Kensaku
TI Stable polyp-scene classification via subsampling and residual learning
   from an imbalanced large dataset
SO HEALTHCARE TECHNOLOGY LETTERS
LA English
DT Article
DE feature extraction; image classification; learning (artificial
   intelligence); cancer; biological organs; computerised tomography;
   endoscopes; medical image processing; convolutional neural nets;
   polyp-detection dataset; stable polyp-scene classification method; false
   positive detection; high-performance CAD system; nonpolyp scenes;
   colonoscopic video dataset; unstable polyp detection; subsampling;
   residual learning; imbalanced large dataset; computer-assisted diagnosis
   system; three-dimensional convolutional neural network; 3D CNN
ID COLONOSCOPY
AB This Letter presents a stable polyp-scene classification method with low false positive (FP) detection. Precise automated polyp detection during colonoscopies is essential for preventing colon-cancer deaths. There is, therefore, a demand for a computer-assisted diagnosis (CAD) system for colonoscopies to assist colonoscopists. A high-performance CAD system with spatiotemporal feature extraction via a three-dimensional convolutional neural network (3D CNN) with a limited dataset achieved about 80% detection accuracy in actual colonoscopic videos. Consequently, further improvement of a 3D CNN with larger training data is feasible. However, the ratio between polyp and non-polyp scenes is quite imbalanced in a large colonoscopic video dataset. This imbalance leads to unstable polyp detection. To circumvent this, the authors propose an efficient and balanced learning technique for deep residual learning. The authors' method randomly selects a subset of non-polyp scenes whose number is the same number of still images of polyp scenes at the beginning of each epoch of learning. Furthermore, they introduce post-processing for stable polyp-scene classification. This post-processing reduces the FPs that occur in the practical application of polyp-scene classification. They evaluate several residual networks with a large polyp-detection dataset consisting of 1027 colonoscopic videos. In the scene-level evaluation, their proposed method achieves stable polyp-scene classification with 0.86 sensitivity and 0.97 specificity.
C1 [Itoh, Hayato; Roth, Holger; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Misawa, Masashi; Mori, Yuichi; Kudo, Shin-Ei] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Tsuzuki Ku, Yokohama, Kanagawa 2248503, Japan.
   [Mori, Kensaku] Nagoya Univ, Informat Technol Ctr, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Mori, Kensaku] Res Ctr Med Bigdata, Natl Inst Informat, Chiyoda Ku, Hitotsubashi 2-1-2, Tokyo 1018430, Japan.
C3 Nagoya University; Showa University; Nagoya University; Research
   Organization of Information & Systems (ROIS); National Institute of
   Informatics (NII) - Japan
RP Itoh, H (通讯作者)，Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM hitoh@mori.m.is.nagoya-u.ac.jp
RI Misawa, Masashi/H-9004-2019; Itoh, Hayato/AAM-4022-2021; Mori,
   Yuichi/AAU-5406-2020
OI Misawa, Masashi/0000-0002-8520-2036; Itoh, Hayato/0000-0002-1410-1078;
   Mori, Yuichi/0000-0003-2262-0334; Oda, Masahiro/0000-0001-7714-422X;
   Roth, Holger/0000-0002-3662-8743
FU AMED [19hs0110006h0003]; MEXT KAKENHI [26108006, 17H00867, 17K20099];
   JSPS Bilateral Joint Research Project
FX Parts of this research were supported by AMED (19hs0110006h0003), MEXT
   KAKENHI (26108006, 17H00867, 17K20099), and the JSPS Bilateral Joint
   Research Project. Conflict of interest: None declared.
CR [Anonymous], P INT WORKSH LEARN I
   [Anonymous], P INT C LEARN REPR I
   [Anonymous], P VISIGRAPP PRAG CZE
   [Anonymous], SUBCH END VIS CHALL
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brugman Hennie, 2006, P 5 INT C LANG RES E, V5, P1556
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   King Gary, 2001, POLIT ANAL, V9, P137, DOI DOI 10.1093/OXFORDJOURNALS.PAN.A004868
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Vo N, 2017, IEEE INT CONF BIG DA, P797
   Ratner AJ, 2017, ADV NEUR IN, V30
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Takeru M., 2018, ARXIV180205957, P1, DOI DOI 10.48550/ARXIV.1802.05957
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Zagoruyko S, 2016, BRIT MACHINE VISION
NR 28
TC 3
Z9 3
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2053-3713
J9 HEALTHC TECHNOL LETT
JI Healthc. Technol. Lett.
PD DEC
PY 2019
VL 6
IS 6
SI SI
BP 237
EP 242
DI 10.1049/htl.2019.0079
PG 6
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA KA3ZS
UT WOS:000505737400017
PM 32038864
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Khan, MA
   Sharif, M
   Akram, T
   Yasmin, M
   Nayak, RS
AF Khan, Muhammad Attique
   Sharif, Muhammad
   Akram, Tallha
   Yasmin, Mussarat
   Nayak, Ramesh Sunder
TI Stomach Deformities Recognition Using Rank-Based Deep Features Selection
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Colorectal cancer; WCE; Saliency estimation; Deep features selection;
   Features fusion
ID BRAIN-TUMOR DETECTION; CAPSULE ENDOSCOPY; LESION DETECTION;
   CLASSIFICATION; SEGMENTATION; FRAMEWORK; STRATEGY; ENTROPY
AB Doctor utilizes various kinds of clinical technologies like MRI, endoscopy, CT scan, etc., to identify patient's deformity during the review time. Among set of clinical technologies, wireless capsule endoscopy (WCE) is an advanced procedures used for digestive track malformation. During this complete process, more than 57,000 frames are captured and doctors need to examine a complete video frame by frame which is a tedious task even for an experienced gastrologist. In this article, a novel computerized automated method is proposed for the classification of abdominal infections of gastrointestinal track from WCE images. Three core steps of the suggested system belong to the category of segmentation, deep features extraction and fusion followed by robust features selection. The ulcer abnormalities from WCE videos are initially extracted through a proposed color features based low level and high-level saliency (CFbLHS) estimation method. Later, DenseNet CNN model is utilized and through transfer learning (TL) features are computed prior to feature optimization using Kapur's entropy. A parallel fusion methodology is opted for the selection of maximum feature value (PMFV). For feature selection, Tsallis entropy is calculated later sorted into descending order. Finally, top 50% high ranked features are selected for classification using multilayered feedforward neural network classifier for recognition. Simulation is performed on collected WCE dataset and achieved maximum accuracy of 99.5% in 21.15 s.
C1 [Khan, Muhammad Attique] HITEC Univ, Dept CS&E, Museum Rd, Taxila, Pakistan.
   [Nayak, Ramesh Sunder] COMSATS Univ Islamabad, Dept CS, Wah Campus, Islamabad, Pakistan.
   [Sharif, Muhammad; Yasmin, Mussarat] COMSATS Univ Islamabad, Dept E&CE, Wah Campus, Islamabad, Pakistan.
   [Akram, Tallha] Canara Engn Coll, Informat Sci, Mangaluru, Karnataka, India.
C3 NITEC University; COMSATS University Islamabad (CUI); COMSATS University
   Islamabad (CUI)
RP Sharif, M (通讯作者)，COMSATS Univ Islamabad, Dept E&CE, Wah Campus, Islamabad, Pakistan.
EM attique@ciitwah.edu.pk; muhammadsharifmalik@yahoo.com;
   tallha@ciitwah.edu.pk
RI Yasmin, Mussarat/HPC-9476-2023; Khan, Dr. Muhammad
   Attique/AAX-2644-2021; khan, sajid/HGE-2406-2022; Sharif,
   Muhammad/AAB-8376-2022; Sharif, Muhammad/ACD-2598-2022
OI Khan, Dr. Muhammad Attique/0000-0002-6347-4890; Sharif,
   Muhammad/0000-0002-7258-8400
CR Acharya UR, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1428-9
   Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Afza F, 2019, MICROSC RES TECHNIQ, V82, P1471, DOI 10.1002/jemt.23301
   Akram T., 2018, J AMBIENT INTELL HUM, P1, DOI DOI 10.1007/S12652-018-1051-5
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Bhowmick AK, 2017, IEEE INT CONF MOB DA, P11, DOI 10.1109/MDM.2017.13
   Charfi S, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P134
   Chatterjee S, 2018, BIOMED SIGNAL PROCES, V40, P252, DOI 10.1016/j.bspc.2017.09.028
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Faris H, 2018, NEURAL COMPUT APPL, V30, P2355, DOI 10.1007/s00521-016-2818-2
   Fernandes SL, 2020, NEURAL COMPUT APPL, V32, P15897, DOI 10.1007/s00521-019-04369-5
   Fernandes SL, 2019, IEEE CONSUM ELECTR M, V8, P31, DOI 10.1109/MCE.2019.2923926
   Fernandes SL, 2017, J MED IMAG HEALTH IN, V7, P1841, DOI 10.1166/jmihi.2017.2280
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Fulkerson B, 2009, IEEE I CONF COMP VIS, P670
   He YX, 2023, TRANSPORTMETRICA A, V19, DOI [10.1109/CVPR.2016.90, 10.1080/23249935.2022.2033348]
   Heidari AA, 2019, SOFT COMPUT, V23, P7941, DOI 10.1007/s00500-018-3424-2
   Huang G., 2017, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2017.243, 10.1109/CVPR.2017.243]
   Iandola FN, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1602.07360
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Kaur T, 2018, NEURAL COMPUT APPL, V29, P193, DOI 10.1007/s00521-017-2869-z
   Khan MA, 2019, ULTRAMICROSCOPY, V196, P1, DOI 10.1016/j.ultramic.2018.09.003
   Khan MF, 2018, BMC COMPLEM ALTERN M, V18, DOI 10.1186/s12906-018-2116-x
   Khan MA, 2020, MED TEACH, V42, P476, DOI 10.1080/0142159X.2019.1626979
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P909, DOI 10.1002/jemt.23238
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P741, DOI 10.1002/jemt.23220
   Khan MA, 2018, IET IMAGE PROCESS, V12, P200, DOI 10.1049/iet-ipr.2017.0368
   Khan SA, 2019, MICROSC RES TECHNIQ, V82, P1256, DOI 10.1002/jemt.23275
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Kundu AK, 2017, TENCON IEEE REGION, P1300
   Lavanya D., 2011, INT J COMPUTER APPL, V26, P1
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Maghsoudi O.H., 2018, ARXIV180202232
   Mergener Klaus, 2008, Gastroenterol Hepatol (N Y), V4, P107
   Najarian, 2018, ARXIV PREPRINT ARXIV
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Naz I, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419500556
   Nur N., 2018, Journal of Physics: Conference Series, V1108, DOI 10.1088/1742-6596/1108/1/012110
   Raja NSM, 2017, J MED IMAG HEALTH IN, V7, P1825, DOI 10.1166/jmihi.2017.2267
   Rajinikanth V., 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 105), P23, DOI 10.1007/978-981-13-1927-3_3
   Rajinikanth V, 2017, J MED IMAG HEALTH IN, V7, P1837, DOI 10.1166/jmihi.2017.2265
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Redmon J, 2015, PROC CVPR IEEE, P779, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sharif M, 2021, J EXP THEOR ARTIF IN, V33, P577, DOI 10.1080/0952813X.2019.1572657
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharma M, 2019, J NEUROSURG, V131, P489, DOI [10.3171/2018.4.JNS172909, 10.1007/s40032-017-0423-5]
   Sharmila R., 2019, WEIGHTED K NN BASED
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Simonyan K, 2015, Arxiv
   Sivakumar P, 2019, CONNECT TISSUE RES, V60, P62, DOI 10.1080/03008207.2018.1500557
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Szegedy, 2013, ARXIV13126199, DOI DOI 10.1109/CVPR.2015.7298594
   Xing Xiaohan, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P1, DOI 10.1109/EMBC.2018.8513012
   Yin Xi, 2018, ARXIV180309014
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang X., 2018, ARXIV180902371
NR 61
TC 41
Z9 41
U1 0
U2 17
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD DEC
PY 2019
VL 43
IS 12
AR 329
DI 10.1007/s10916-019-1466-3
PG 15
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA JI7OW
UT WOS:000493655300001
PM 31676931
DA 2023-04-20
ER

PT J
AU Kundu, AK
   Fattah, SA
AF Kundu, Amit Kumar
   Fattah, Shaikh Anowarul
TI Probability density function based modeling of spatial feature variation
   in capsule endoscopy data for automatic bleeding detection
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Bleeding detection; Bleeding zone localization; Pixels of interest;
   Rayleigh probability density function (PDF); Support vector machine;
   Wireless capsule endoscopy
ID SUSPECTED BLOOD INDICATOR; SENSITIVITY
AB Wireless capsule endoscopy (WCE) is a video technology to inspect abnormalities, like bleeding in the gastrointestinal tract. In order to avoid a complex and long duration manual review process, automatic bleeding detection schemes are developed that mainly utilize features extracted from WCE images. In feature-based bleeding detection schemes, either global features are used which produce averaged characteristics ignoring the effect of smaller bleeding regions or local features are utilized that cause large feature dimension. In this paper, pixels of interest (POI) in a given WCE image are determined using a linear separation scheme, local spatial features are then extracted from the POI and finally, a suitable characteristic probability density function (PDF) is fitted over the resulting feature space. The proposed PDF model fitting based approach not only reduces the computational complexity but also offers more consistent representation of a class. Details analysis are carried out to find the best suitable PDF and it is found that fitting of Rayleigh PDF model to the local spatial features is best suited for bleeding detection. For the purpose of classification, the fitted PDF parameters are used as features in the supervised support vector machine classifier. Pixels residing in the close vicinity of the POI are further classified with the help of an unsupervised clustering-based scheme to extract more precise bleeding regions. A large number of WCE images obtained from 30 publicly available WCE videos are used for performance evaluation of the proposed scheme and the effects on classification performance due to the changes in PDF models, block statistics, color spaces, and classifiers are experimentally analyzed. The proposed scheme shows satisfactory performance in terms of sensitivity (97.55%), specificity (96.59%) and accuracy (96.77%) and the results obtained by the proposed method outperforms the results reported for some state-of-the-art methods.
C1 [Kundu, Amit Kumar; Fattah, Shaikh Anowarul] Bangladesh Univ Engn & Technol, Dept Elect & Elect Engn, Dhaka, Bangladesh.
C3 Bangladesh University of Engineering & Technology (BUET)
RP Fattah, SA (通讯作者)，Bangladesh Univ Engn & Technol, Dept Elect & Elect Engn, Dhaka, Bangladesh.
EM amit31416@gmail.com; fattah@eee.buet.ac.bd
CR Adler DG., 2003, HOSP PHYS, V39, P14
   ALTMAN DG, 1994, BRIT MED J, V308, P1552, DOI 10.1136/bmj.308.6943.1552
   [Anonymous], 2001, PROBABILITY RANDOM V
   Bhat H. S., DERIVATION BAYESIAN
   Buscaglia JM, 2008, CLIN GASTROENTEROL H, V6, P298, DOI 10.1016/j.cgh.2007.12.029
   Chen Yingju, 2012, Diagn Ther Endosc, V2012, P418037, DOI 10.1155/2012/418037
   Coelho P, 2018, LECT NOTES COMPUT SC, V10882, P553, DOI 10.1007/978-3-319-93000-8_63
   Coimbra M., 2007, EURASIP NEWS LETT, V18, P1
   Conversano F, 2011, ACAD RADIOL, V18, P461, DOI 10.1016/j.acra.2010.11.015
   Deeba F., 2016, BLEEDING IMAGES CORR
   Deeba F, 2016, IEEE IJCNN, P4650, DOI 10.1109/IJCNN.2016.7727810
   Eliakim R, 2008, CURR OPIN GASTROEN, V24, P159, DOI 10.1097/MOG.0b013e3282f3d946
   Faigel D. O., 2008, CAPSULE ENDOSCOPY, P1
   FREEDMAN D, 1981, Z WAHRSCHEINLICHKEIT, V57, P453, DOI 10.1007/BF01025868
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ghosh T, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2017.2756034
   Ghosh T, 2018, COMPUT BIOL MED, V94, P41, DOI 10.1016/j.compbiomed.2017.12.014
   Gonzales R.C., 2008, DIGITAL IMAGE PROCES, V3rd
   Greene John, 2001, P PATT REC ASS S AFR
   Hu XY, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090730
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kundu AK, 2016, IEEE STUDENT TECHNOL, P245, DOI 10.1109/TechSym.2016.7872690
   Kundu AK, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/9423062
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Park SC, 2012, WORLD J GASTROENTERO, V18, P4169, DOI 10.3748/wjg.v18.i31.4169
   Ramaraj M, 2014, J MED IMAG HEALTH IN, V4, P500, DOI 10.1166/jmihi.2014.1297
   Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sainju S, 2013, CAN CON EL COMP EN, P539
   Signorelli C, 2005, ENDOSCOPY, V37, P1170, DOI 10.1055/s-2005-870410
   Sivakumar P, 2019, CONNECT TISSUE RES, V60, P62, DOI 10.1080/03008207.2018.1500557
   Thornton C, 1997, PERSP NEURAL COMP, P40
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Vapnik V, 1998, STAT LEARNING THEORY
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
NR 42
TC 7
Z9 7
U1 4
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD DEC
PY 2019
VL 115
AR 103478
DI 10.1016/j.compbiomed.2019.103478
PG 12
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA JW5IP
UT WOS:000503085900015
PM 31698239
DA 2023-04-20
ER

PT J
AU Luo, HY
   Xu, GL
   Li, CF
   He, LJ
   Luo, LN
   Wang, ZX
   Jing, BZ
   Deng, YS
   Jin, Y
   Li, Y
   Li, B
   Tan, WC
   He, CS
   Seeruttun, SR
   Wu, QB
   Huang, J
   Huang, DW
   Chen, B
   Lin, SB
   Chen, QM
   Yuan, CM
   Chen, HX
   Pu, HY
   Zhou, F
   He, Y
   Xu, RH
AF Luo, Huiyan
   Xu, Guoliang
   Li, Chaofeng
   He, Longjun
   Luo, Linna
   Wang, Zixian
   Jing, Bingzhong
   Deng, Yishu
   Jin, Ying
   Li, Yin
   Li, Bin
   Tan, Wencheng
   He, Caisheng
   Seeruttun, Sharvesh Raj
   Wu, Qiubao
   Huang, Jun
   Huang, De-wang
   Chen, Bin
   Lin, Shao-bin
   Chen, Qin-ming
   Yuan, Chu-ming
   Chen, Hai-xin
   Pu, Heng-ying
   Zhou, Feng
   He, Yun
   Xu, Rui-hua
TI Real-time artificial intelligence for detection of upper
   gastrointestinal cancer by endoscopy: a multicentre, case-control,
   diagnostic study
SO LANCET ONCOLOGY
LA English
DT Article
ID GASTRIC-CANCER; ESOPHAGUS
AB Background Upper gastrointestinal cancers (including oesophageal cancer and gastric cancer) are the most common cancers worldwide. Artificial intelligence platforms using deep learning algorithms have made remarkable progress in medical imaging but their application in upper gastrointestinal cancers has been limited. We aimed to develop and validate the Gastrointestinal Artificial Intelligence Diagnostic System (GRAIDS) for the diagnosis of upper gastrointestinal cancers through analysis of imaging data from clinical endoscopies.
   Methods This multicentre, case-control, diagnostic study was done in six hospitals of different tiers (ie, municipal, provincial, and national) in China. The images of consecutive participants, aged 18 years or older, who had not had a previous endoscopy were retrieved from all participating hospitals. All patients with upper gastrointestinal cancer lesions (including oesophageal cancer and gastric cancer) that were histologically proven malignancies were eligible for this study. Only images with standard white light were deemed eligible. The images from Sun Yat-sen University Cancer Center were randomly assigned (8:1:1) to the training and intrinsic verification datasets for developing GRAIDS, and the internal validation dataset for evaluating the performance of GRAIDS. Its diagnostic performance was evaluated using an internal and prospective validation set from Sun Yat-sen University Cancer Center (a national hospital) and additional external validation sets from five primary care hospitals. The performance of GRAIDS was also compared with endoscopists with three degrees of expertise: expert, competent, and trainee. The diagnostic accuracy, sensitivity, specificity, positive predictive value, and negative predictive value of GRAIDS and endoscopists for the identification of cancerous lesions were evaluated by calculating the 95% CIs using the Clopper-Pearson method.
   Findings 1 036 496 endoscopy images from 84 424 individuals were used to develop and test GRAIDS. The diagnostic accuracy in identifying upper gastrointestinal cancers was 0.955 (95% CI 0.952-0.957) in the internal validation set, 0.927 (0.925-0.929) in the prospective set, and ranged from 0.915 (0.913-0.917) to 0.977 (0.977-0.978) in the five external validation sets. GRAIDS achieved diagnostic sensitivity similar to that of the expert endoscopist (0.942 [95% CI 0.924-0.957] vs 0.945 [0.927-0.959]; p=0.692) and superior sensitivity compared with competent (0.858 [0.832-0.880], p<0.0001) and trainee (0.722 [0.691-0.752], p<0.0001) endoscopists. The positive predictive value was 0.814 (95% CI 0.788-0.838) for GRAIDS, 0.932 (0.913-0.948) for the expert endoscopist, 0.974 (0.960-0.984) for the competent endoscopist, and 0.824 (0.795-0.850) for the trainee endoscopist. The negative predictive value was 0.978 (95% CI 0.971-0.984) for GRAIDS, 0.980 (0.974-0.985) for the expert endoscopist, 0.951 (0.942-0.959) for the competent endoscopist, and 0.904 (0.893-0.916) for the trainee endoscopist.
   Interpretation GRAIDS achieved high diagnostic accuracy in detecting upper gastrointestinal cancers, with sensitivity similar to that of expert endoscopists and was superior to that of non-expert endoscopists. This system could assist community-based hospitals in improving their effectiveness in upper gastrointestinal cancer diagnoses. Copyright (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Luo, Huiyan; Luo, Linna; Wang, Zixian; Jin, Ying; Xu, Rui-hua] Sun Yat Sen Univ, Canc Ctr, Collaborat Innovat Ctr Canc Med, Dept Med Oncol,State Key Lab Oncol South China, Guangzhou 510060, Guangdong, Peoples R China.
   [Xu, Guoliang; He, Longjun; Li, Yin; Tan, Wencheng] Sun Yat Sen Univ, Canc Ctr, Collaborat Innovat Ctr Canc Med, Dept Endoscopy,State Key Lab Oncol South China, Guangzhou, Guangdong, Peoples R China.
   [Li, Chaofeng; Jing, Bingzhong; Deng, Yishu; Li, Bin; He, Caisheng] Sun Yat Sen Univ, Canc Ctr, Collaborat Innovat Ctr Canc Med, Artificial Intelligence Lab,State Key Lab Oncol S, Guangzhou, Guangdong, Peoples R China.
   [Seeruttun, Sharvesh Raj] Sun Yat Sen Univ, Canc Ctr, Collaborat Innovat Ctr Canc Med, Dept Gastr Surg,State Key Lab Oncol South China, Guangzhou, Guangdong, Peoples R China.
   [Pu, Heng-ying; Zhou, Feng; He, Yun] Sun Yat Sen Univ, Canc Ctr, Collaborat Innovat Ctr Canc Med, Med Adm Dept,State Key Lab Oncol South China, Guangzhou, Guangdong, Peoples R China.
   [Wu, Qiubao; Huang, Jun] Jiangxi Canc Hosp, Dept Endoscopy, Nanchang, Jiangxi, Peoples R China.
   [Huang, De-wang] Wuzhou Red Cross Hosp, Dept Digest Internal, Wuzhou, Peoples R China.
   [Chen, Bin] North Guangdong Peoples Hosp, Dept Digest Internal, Shaoguan, Peoples R China.
   [Lin, Shao-bin; Chen, Qin-ming] Puning Peoples Hosp, Dept Digest Internal, Puning, Peoples R China.
   [Yuan, Chu-ming; Chen, Hai-xin] Jieyang Peoples Hosp, Dept Digest Internal, Jieyang, Peoples R China.
C3 State Key Lab Oncology South China; Sun Yat Sen University; State Key
   Lab Oncology South China; Sun Yat Sen University; Sun Yat Sen
   University; State Key Lab Oncology South China; Sun Yat Sen University;
   State Key Lab Oncology South China; Sun Yat Sen University
RP Xu, RH (通讯作者)，Sun Yat Sen Univ, Canc Ctr, Collaborat Innovat Ctr Canc Med, Dept Med Oncol,State Key Lab Oncol South China, Guangzhou 510060, Guangdong, Peoples R China.
EM xurh@sysucc.org.cn
RI xu, rui/GRX-5734-2022; 骆, 卉妍/GWR-3383-2022; Xu, Rui-Hua/AAW-4766-2021
OI 骆, 卉妍/0000-0001-6312-9299; Xu, Rui-Hua/0000-0001-9771-8534; Wang,
   Zi-Xian/0000-0002-7950-787X
FU National Key R&D Program of China; Natural Science Foundation of
   Guangdong Province; Science and Technology Program of Guangdong; Science
   and Technology Program of Guangzhou; Fundamental Research Funds for the
   Central Universities
FX The National Key R&D Program of China, the Natural Science Foundation of
   Guangdong Province, the Science and Technology Program of Guangdong, the
   Science and Technology Program of Guangzhou, and the Fundamental
   Research Funds for the Central Universities.
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Amin MB, 2017, CA-CANCER J CLIN, V67, P93, DOI 10.3322/caac.21388
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chiu PWY, 2019, GUT, V68, P186, DOI 10.1136/gutjnl-2018-317111
   Dohi O, 2019, GASTROINTEST ENDOSC, V89, P47, DOI 10.1016/j.gie.2018.08.049
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Hamashima C, 2018, JPN J CLIN ONCOL, V48, P673, DOI 10.1093/jjco/hyy077
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Jun JK, 2017, GASTROENTEROLOGY, V152, P1319, DOI 10.1053/j.gastro.2017.01.029
   Li XC, 2019, LANCET ONCOL, V20, P193, DOI 10.1016/S1470-2045(18)30762-9
   Liang HY, 2019, NAT MED, V25, P433, DOI 10.1038/s41591-018-0335-9
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Muto M, 2010, J CLIN ONCOL, V28, P1566, DOI 10.1200/JCO.2009.25.4680
   Neumann H, 2010, GASTROENTEROLOGY, V139, P388, DOI 10.1053/j.gastro.2010.06.029
   Otutaha B, 2019, ANZ J SURG, V89, P20, DOI 10.1111/ans.14565
   Pohlen T, 2016, FULL RESOLUTION RESI
   Rice TW, 2016, DIS ESOPHAGUS, V29, P897, DOI 10.1111/dote.12533
   Sano T, 2017, GASTRIC CANCER, V20, P217, DOI 10.1007/s10120-016-0601-9
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Trister AD, 2017, JAMA ONCOL, V3, P1463, DOI 10.1001/jamaoncol.2017.0473
   Veitch AM, 2015, NAT REV GASTRO HEPAT, V12, P660, DOI 10.1038/nrgastro.2015.128
   Wong Kee Song Louis-Michel, 2005, Best Pract Res Clin Gastroenterol, V19, P833, DOI 10.1016/j.bpg.2005.04.006
   Yamazato T, 2012, INTERNAL MED, V51, P1461, DOI 10.2169/internalmedicine.51.7414
NR 25
TC 155
Z9 173
U1 10
U2 83
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1470-2045
EI 1474-5488
J9 LANCET ONCOL
JI Lancet Oncol.
PD DEC
PY 2019
VL 20
IS 12
BP 1645
EP 1654
DI 10.1016/S1470-2045(19)30637-0
PG 10
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA JT1HZ
UT WOS:000500750400045
PM 31591062
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Oda, M
   Tanaka, K
   Takabatake, H
   Mori, M
   Natori, H
   Mori, K
AF Oda, Masahiro
   Tanaka, Kiyohito
   Takabatake, Hirotsugu
   Mori, Masaki
   Natori, Hiroshi
   Mori, Kensaku
TI Realistic endoscopic image generation method using virtual-to-real
   image-domain translation
SO HEALTHCARE TECHNOLOGY LETTERS
LA English
DT Article
DE realistic images; data visualisation; rendering (computer graphics);
   computerised tomography; endoscopes; biological organs; image
   segmentation; medical image processing; virtual reality; high-quality
   image-domain translation results; image cleansing; image-domain
   translator; realistic endoscopic image generation method; realistic
   image generation method; endoscopic simulation systems; endoscope
   insertions; nonrealistic virtual endoscopic images; unpaired virtual
   images; real endoscopic images; shallow U-Net; deep U-Net; endoscopic
   treatment; endoscopic diagnosis
AB A realistic image generation method for visualisation in endoscopic simulation systems is proposed in this study. Endoscopic diagnosis and treatment are performed in many hospitals. To reduce complications related to endoscope insertions, endoscopic simulation systems are used for training or rehearsal of endoscope insertions. However, current simulation systems generate non-realistic virtual endoscopic images. To improve the value of the simulation systems, improvement of the reality of their generated images is necessary. The authors propose a realistic image generation method for endoscopic simulation systems. Virtual endoscopic images are generated by using a volume rendering method from a CT volume of a patient. They improve the reality of the virtual endoscopic images using a virtual-to-real image-domain translation technique. The image-domain translator is implemented as a fully convolutional network (FCN). They train the FCN by minimising a cycle consistency loss function. The FCN is trained using unpaired virtual and real endoscopic images. To obtain high-quality image-domain translation results, they perform an image cleansing to the real endoscopic image set. They tested to use the shallow U-Net, U-Net, deep U-Net, and U-Net having residual units as the image-domain translator. The deep U-Net and U-Net having residual units generated quite realistic images.
C1 [Oda, Masahiro] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Tanaka, Kiyohito] Kyoto Second Red Cross Hosp, Dept Gastroenterol, Kamigyo Ku, 355-5 Haruobi Cho, Kyoto, Kyoto 6028026, Japan.
   [Takabatake, Hirotsugu] Sapporo Minami Sanjo Hosp, Dept Resp Med, Chuo Ku, Nishi 6 Chome,Minami 3 Jo, Sapporo, Hokkaido 0600063, Japan.
   [Mori, Masaki] Sapporo Kosei Gen Hosp, Dept Resp Med, Chuo Ku, Higashi 8 Chome,Kita 3 Jo, Sapporo, Hokkaido 0600033, Japan.
   [Natori, Hiroshi] Keiwakai Nishioka Hosp, Dept Resp Med, Toyohira Ku, 1-52,4 Jo 4 Chome, Sapporo, Hokkaido 0620034, Japan.
   [Mori, Kensaku] Natl Inst Informat, Res Ctr Med Bigdata, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan.
C3 Nagoya University; Sapporo Kosei General Hospital; Research Organization
   of Information & Systems (ROIS); National Institute of Informatics (NII)
   - Japan
RP Oda, M (通讯作者)，Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM moda@mori.m.is.nagoya-u.ac.jp
OI Oda, Masahiro/0000-0001-7714-422X
FU AMED [18lk1010028s0401, 19lk1010036h0001, 19hs0110006h0003]; MEXT/JSPS
   KAKENHI [26108006, 17H00867, 17K20099]; JSPS Bilateral International
   Collaboration Grants
FX Parts of this research were supported by the AMED grant nos.
   18lk1010028s0401, 19lk1010036h0001, and 19hs0110006h0003, the MEXT/JSPS
   KAKENHI grant nos 26108006, 17H00867, and 17K20099, and the JSPS
   Bilateral International Collaboration Grants.
CR [Anonymous], 2017, ARXIV160708022
   [Anonymous], 2017, ICCV
   Engelhardt S, 2018, LECT NOTES COMPUT SC, V11070, P747, DOI 10.1007/978-3-030-00928-1_84
   Esteban-Lansaque A., 2019, 681825 BIORXIV
   Gil D, 2019, INT J COMPUT ASS RAD, V14, P63, DOI 10.1007/s11548-018-1849-9
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Harpham-Lockyer L, 2015, WORLD J GASTRO ENDOS, V7, P1287, DOI 10.4253/wjge.v7.i18.1287
   He K., 2016, IEEE C CVPR LAS VEG
   Hiasa Y, 2018, LECT NOTES COMPUT SC, V11037, P31, DOI 10.1007/978-3-030-00536-8_4
   Huo Y., 2018, IEEE 15 INT S ISBI W
   Khan R, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008237.pub3
   Miki T, 2016, J CRANIO MAXILL SURG, V44, P1800, DOI 10.1016/j.jcms.2016.08.018
   Mori K, 2003, PROC SPIE, V5031, P111, DOI 10.1117/12.480417
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Savenije M H F, 2017, LECT NOTES COMPUT, P14, DOI DOI 10.1007/978-3-319-68127-6_2.LNCS
   Shrivastava A., 2017, IEEE C CVPR HON US
   Triantafyllou K, 2014, WORLD J GASTRO ENDOS, V6, P6, DOI 10.4253/wjge.v6.i1.6
NR 17
TC 9
Z9 9
U1 0
U2 4
PU INST ENGINEERING TECHNOLOGY-IET
PI HERTFORD
PA MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND
EI 2053-3713
J9 HEALTHC TECHNOL LETT
JI Healthc. Technol. Lett.
PD DEC
PY 2019
VL 6
IS 6
SI SI
BP 214
EP 219
DI 10.1049/htl.2019.0071
PG 6
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA KA3ZS
UT WOS:000505737400013
PM 32038860
OA gold, Green Submitted, Green Published
DA 2023-04-20
ER

PT J
AU Wang, S
   Xing, YX
   Zhang, L
   Gao, HW
   Zhang, H
AF Wang, Sen
   Xing, Yuxiang
   Zhang, Li
   Gao, Hewei
   Zhang, Hao
TI A systematic evaluation and optimization of automatic detection of
   ulcers in wireless capsule endoscopy on a large dataset using deep
   convolutional neural networks
SO PHYSICS IN MEDICINE AND BIOLOGY
LA English
DT Article
DE wireless capsule endoscopy; computer-aided diagnosis; convolutional
   neural network; detection
AB Compared with conventional gastroscopy which is invasive and painful, wireless capsule endoscopy (WCE) can provide noninvasive examination of gastrointestinal (GI) tract. The WCE video can effectively support physicians to reach a diagnostic decision while a huge number of images need to be analyzed (more than 50 000 frames per patient). In this paper, we propose a computer-aided diagnosis method called second glance (secG) detection framework for automatic detection of ulcers based on deep convolutional neural networks that provides both classification confidence and bounding box of lesion area. We evaluated its performance on a large dataset that consists of 1504 patient cases (the largest WCE ulcer dataset to our best knowledge, 1076 cases with ulcers, 428 normal cases). We use 15 781 ulcer frames from 753 ulcer cases and 17 138 normal frames from 300 normal cases for training. Validation dataset consists of 2040 ulcer frames from 108 cases and 2319 frames from 43 normal cases. For test, we use 4917 ulcer frames from 215 ulcer cases and 5007 frames from 85 normal cases. Test results demonstrate the 0.9469 ROC-AUC of the proposed secG detection framework outperforms state-of-the-art detection frameworks including Faster-RCNN (0.9014) and SSD-300 (0.8355), which implies the effectiveness of our method. From the ulcer size analysis, we find the detection of ulcers is highly related to the size. For ulcers with size larger than 1% of the full image size, the sensitivity exceeds 92.00%. For ulcers that are smaller than 1% of the full image size, the sensitivity is around 85.00%. The overall sensitivity, specificity and accuracy are 89.71%, 90.48% and 90.10%, at a threshold value of 0.6706, which implies the potential of the proposed method to suppress oversights and to reduce the burden of physicians.
C1 [Wang, Sen; Xing, Yuxiang; Zhang, Li; Gao, Hewei] Tsinghua Univ, Minist Educ, Key Lab Particle & Radiat Imaging, Beijing, Peoples R China.
   [Wang, Sen; Xing, Yuxiang; Zhang, Li; Gao, Hewei] Tsinghua Univ, Dept Engn Phys, Beijing 100084, Peoples R China.
   [Zhang, Hao] Ankon Technol Co Ltd, Shanghai, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Zhang, L (通讯作者)，Tsinghua Univ, Minist Educ, Key Lab Particle & Radiat Imaging, Beijing, Peoples R China.; Zhang, L (通讯作者)，Tsinghua Univ, Dept Engn Phys, Beijing 100084, Peoples R China.
EM zli@mail.tsinghua.edu.cn
RI Xing, Yuxiang/H-4143-2012
OI Wang, Sen/0000-0001-6948-3264
FU Ankon Technologies Co Ltd (Wuhan, Shanghai, China); National Key
   Scientific Instrument and Equipment Development Project [2013YQ160439];
   Zhangjiang National Innovation Demonstration Zone Special Development
   Fund [ZJ2017-ZD-001]
FX The authors would like to thank Ankon Technologies Co, Ltd (Wuhan,
   Shanghai, China) for providing the WCE data (ankoninc.com.cn). They
   would also like to thank the participating engineers of Ankon
   Technologies Co, Ltd, for their thoughtful support and cooperation. This
   work was supported by a research project from Ankon Technologies Co Ltd
   (Wuhan, Shanghai, China), the National Key Scientific Instrument and
   Equipment Development Project under Grant No. 2013YQ160439 and the
   Zhangjiang National Innovation Demonstration Zone Special Development
   Fund under Grant No. ZJ2017-ZD-001.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Charisis V, 2012, NEW ADV BASIC CLIN G
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He K., 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46493-0_38
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Li B, 2008, C EL COMP ENG NIAG F, DOI [10.1109/CCECE.2008.4564887, DOI 10.1109/CCECE.2008.4564887]
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liao ZA, 2016, CLIN GASTROENTEROL H, V14, P1266, DOI 10.1016/j.cgh.2016.05.013
   Lin T.Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Redmon J., 2017, PROC CVPR IEEE, P7263, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]
   Redmon J, 2015, PROC CVPR IEEE, P779, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shamsudhin N, 2017, MED PHYS, V44, pE91, DOI [10.1002/mp.12299, 10.1002/mp.12446]
   Shen Lin, 2013, Lancet Oncol, V14, pe535, DOI 10.1016/S1470-2045(13)70436-4
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Wang S, 2019, MED PHYS, V46, pE462
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   YOUDEN WJ, 1950, BIOMETRICS, V6, P172, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3
   Yu L, 2012, P 21 INT C PATT REC
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
NR 31
TC 24
Z9 26
U1 5
U2 22
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0031-9155
EI 1361-6560
J9 PHYS MED BIOL
JI Phys. Med. Biol.
PD DEC
PY 2019
VL 64
IS 23
AR 235014
DI 10.1088/1361-6560/ab5086
PG 13
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA KT1IO
UT WOS:000518765200004
PM 31645019
DA 2023-04-20
ER

PT J
AU Wu, LL
   Zhang, J
   Zhou, W
   An, P
   Shen, L
   Liu, J
   Jiang, XD
   Huang, X
   Mu, GG
   Wan, XY
   Lv, XG
   Gao, J
   Cui, N
   Hu, S
   Chen, YY
   Hu, X
   Li, JJ
   Chen, D
   Gong, DX
   He, XQ
   Ding, QS
   Zhu, XY
   Li, SQ
   Wei, X
   Li, X
   Wang, XM
   Zhou, J
   Zhang, MJ
   Yu, HG
AF Wu, Lianlian
   Zhang, Jun
   Zhou, Wei
   An, Ping
   Shen, Lei
   Liu, Jun
   Jiang, Xiaoda
   Huang, Xu
   Mu, Ganggang
   Wan, Xinyue
   Lv, Xiaoguang
   Gao, Juan
   Cui, Ning
   Hu, Shan
   Chen, Yiyun
   Hu, Xiao
   Li, Jiangjie
   Chen, Di
   Gong, Dexin
   He, Xinqi
   Ding, Qianshan
   Zhu, Xiaoyun
   Li, Suqin
   Wei, Xiao
   Li, Xia
   Wang, Xuemei
   Zhou, Jie
   Zhang, Mengjiao
   Yu, Hong Gang
TI Randomised controlled trial of WISENSE, a real-time quality improving
   system for monitoring blind spots during esophagogastroduodenoscopy
SO GUT
LA English
DT Article
ID GASTROINTESTINAL ENDOSCOPY; GASTRIC-CANCER; EUROPEAN-SOCIETY;
   NEURAL-NETWORKS; IMPROVEMENT
AB Objective Esophagogastroduodenoscopy (EGD) is the pivotal procedure in the diagnosis of upper gastrointestinal lesions. However, there are significant variations in EGD performance among endoscopists, impairing the discovery rate of gastric cancers and precursor lesions. The aim of this study was to construct a real-time quality improving system, WISENSE, to monitor blind spots, time the procedure and automatically generate photodocumentation during EGD and thus raise the quality of everyday endoscopy.
   Design WISENSE system was developed using the methods of deep convolutional neural networks and deep reinforcement learning. Patients referred because of health examination, symptoms, surveillance were recruited from Renmin hospital of Wuhan University. Enrolled patients were randomly assigned to groups that underwent EGD with or without the assistance of WISENSE. The primary end point was to ascertain if there was a difference in the rate of blind spots between WISENSE-assisted group and the control group.
   Results WISENSE monitored blind spots with an accuracy of 90.40% in real EGD videos. A total of 324 patients were recruited and randomised. 153 and 150 patients were analysed in the WISENSE and control group, respectively. Blind spot rate was lower in WISENSE group compared with the control (5.86% vs 22.46%, p<0.001), and the mean difference was -15.39% (95% CI -19.23 to -11.54). There was no significant adverse event.
   Conclusions WISENSE significantly reduced blind spot rate of EGD procedure and could be used to improve the quality of everyday endoscopy.
C1 [Wu, Lianlian; Zhang, Jun; Zhou, Wei; An, Ping; Shen, Lei; Liu, Jun; Jiang, Xiaoda; Huang, Xu; Mu, Ganggang; Wan, Xinyue; Lv, Xiaoguang; Gao, Juan; Cui, Ning; Chen, Di; Gong, Dexin; He, Xinqi; Ding, Qianshan; Zhu, Xiaoyun; Li, Suqin; Wei, Xiao; Li, Xia; Wang, Xuemei; Zhou, Jie; Zhang, Mengjiao; Yu, Hong Gang] Wuhan Univ, Dept Gastroenterol, Renmin Hosp, Wuhan 430060, Hubei, Peoples R China.
   [Wu, Lianlian; Zhang, Jun; Zhou, Wei; An, Ping; Shen, Lei; Liu, Jun; Jiang, Xiaoda; Huang, Xu; Mu, Ganggang; Wan, Xinyue; Lv, Xiaoguang; Cui, Ning; Chen, Di; Gong, Dexin; He, Xinqi; Ding, Qianshan; Zhu, Xiaoyun; Li, Suqin; Wei, Xiao; Li, Xia; Wang, Xuemei; Zhou, Jie; Zhang, Mengjiao; Yu, Hong Gang] Wuhan Univ, Key Lab Hubei Prov Digest Syst Dis, Renmin Hosp, Wuhan 430060, Hubei, Peoples R China.
   [Wu, Lianlian; Zhang, Jun; Zhou, Wei; An, Ping; Shen, Lei; Liu, Jun; Jiang, Xiaoda; Huang, Xu; Mu, Ganggang; Wan, Xinyue; Lv, Xiaoguang; Gao, Juan; Cui, Ning; Chen, Di; Gong, Dexin; He, Xinqi; Ding, Qianshan; Zhu, Xiaoyun; Li, Suqin; Wei, Xiao; Li, Xia; Wang, Xuemei; Zhou, Jie; Zhang, Mengjiao; Yu, Hong Gang] Wuhan Univ, Hubei Prov Clin Res Ctr Digest Dis Minimally Inva, Renmin Hosp, Wuhan, Hubei, Peoples R China.
   [Hu, Shan; Chen, Yiyun; Hu, Xiao; Li, Jiangjie] Wuhan Univ, Sch Resources & Environm Sci, Wuhan, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University; Wuhan University; Wuhan University
RP Yu, HG (通讯作者)，Wuhan Univ, Dept Gastroenterol, Renmin Hosp, Wuhan 430060, Hubei, Peoples R China.
EM yuhonggang1968@163.com
RI Wang, Xuemei/GXF-3702-2022; CHEN, YIYUN/AAD-9501-2019
OI CHEN, YIYUN/0000-0002-7442-3239; wan, xinyue/0000-0002-4507-2011
FU Research Funds for Key Laboratory of Hubei Province [2016CFA066];
   National Natural Science Foundation of China [81672387]; China Youth
   Development Foundation [81703030]
FX This work was partly supported by the grant from the Research Funds for
   Key Laboratory of Hubei Province (No 2016CFA066), the National Natural
   Science Foundation of China (grant nos 81672387 [to HGY]) and the China
   Youth Development Foundation (grant no 81703030 [to QD]).
CR [Anonymous], 2018, THESIS LANZHOU U
   Bisschops R, 2016, ENDOSCOPY, V48, P843, DOI 10.1055/s-0042-113128
   Bretthauer M, 2016, ENDOSCOPY, V48, P291, DOI 10.1055/s-0042-100186
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chang P, 2018, AM J NEURORADIOL, V39, P1201, DOI 10.3174/ajnr.A5667
   Cohen J, 2006, GASTROINTEST ENDOSC, V63, pS10, DOI 10.1016/j.gie.2006.02.018
   Di LJ, 2017, BMC GASTROENTEROL, V17, DOI 10.1186/s12876-017-0711-9
   Faigel DO, 2006, ENDOSCOPY, V38, pS65, DOI 10.1055/s-2006-946657
   Faigel DO, 2006, GASTROINTEST ENDOSC, V63, pS3, DOI 10.1016/j.gie.2006.02.017
   Fang Meng, 2017, P C EMPIRICAL METHOD, P595, DOI DOI 10.18653/V1/D17-1063
   Fujifilm Holding Corporation, 2016, FUJ HOLD CORP ANN RE
   Gado AS, 2016, ARAB J GASTROENTEROL, V17, P153, DOI 10.1016/j.ajg.2016.11.002
   Glimcher PW, 2011, P NATL ACAD SCI USA, V108, P15647, DOI 10.1073/pnas.1014269108
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Huang Q, 2015, PATHOLOGY, V47, P526, DOI 10.1097/PAT.0000000000000276
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leung WK, 2008, LANCET ONCOL, V9, P279, DOI 10.1016/S1470-2045(08)70072-X
   Malheiro R, 2014, ENDOSCOPY, V46, P513, DOI 10.1055/s-0034-1365394
   Miot Hélio Amante, 2011, J. vasc. bras., V10, P275, DOI 10.1590/S1677-54492011000400001
   Mnih, 2013, P NIPS DEEP LEARN WO, DOI DOI 10.1038/NATURE14236
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Olympus Global, 2018, 3 OL GLOB
   Park WG, 2012, TECH GASTROINTEST EN, V14, P13, DOI 10.1016/j.tgie.2011.10.003
   Rutter MD, 2014, ENDOSCOPY, V46, P526, DOI 10.1055/s-0034-1365738
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv
   Teh JL, 2015, CLIN GASTROENTEROL H, V13, P480, DOI 10.1016/j.cgh.2014.07.059
   Tobin J, 2017, IEEE INT C INT ROBOT, P23
   Torkamani A, 2017, CELL, V170, P828, DOI 10.1016/j.cell.2017.08.007
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Van Cutsem E, 2016, LANCET, V388, P2654, DOI 10.1016/S0140-6736(16)30354-3
   Wen ZY, 2017, AAAI CONF ARTIF INTE, P2768
   Yao K, 2013, ANN GASTROENTEROL, V26, P11
   Zhang JG, 2011, WORLD J GASTROENTERO, V17, P4277, DOI 10.3748/wjg.v17.i38.4277
NR 34
TC 135
Z9 153
U1 7
U2 41
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0017-5749
EI 1468-3288
J9 GUT
JI Gut
PD DEC
PY 2019
VL 68
IS 12
BP 2161
EP 2169
DI 10.1136/gutjnl-2018-317366
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA JW7NJ
UT WOS:000503234500010
PM 30858305
OA Green Published, hybrid
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Zhang, X
   Yu, T
   Zheng, WF
   Lin, N
   Huang, ZX
   Liu, JQ
   Hu, WL
   Duan, HL
   Si, JM
AF Zhang Xu
   Yu Tao
   Zheng Wenfang
   Lin Ne
   Huang Zhengxing
   Liu Jiquan
   Hu Weiling
   Duan Huilong
   Si Jianmin
TI Upper gastrointestinal anatomy detection with multi-task convolutional
   neural networks
SO HEALTHCARE TECHNOLOGY LETTERS
LA English
DT Article
DE image classification; medical image processing; biomedical optical
   imaging; endoscopes; learning (artificial intelligence); patient
   diagnosis; neural nets; biological organs; inspection; diagnosis
   quality; classification task; gastroscopy examination process; upper
   gastrointestinal anatomy detection; multitask convolutional neural
   networks; gastrointestinal examinations; EGD inspection process; authors
   design; multitask anatomy detection convolutional neural network;
   MT-AD-CNN; EGD inspection quality; upper digestive tract; informative
   video frames; noninformative frames; gastroscopic videos; anatomies;
   detection network; noninformative images; detected box; informative
   frames
ID ARTIFICIAL-INTELLIGENCE; GASTRIC-CANCER
AB Esophagogastroduodenoscopy (EGD) has been widely applied for gastrointestinal (GI) examinations. However, there is a lack of mature technology to evaluate the quality of the EGD inspection process. In this Letter, the authors design a multi-task anatomy detection convolutional neural network (MT-AD-CNN) to evaluate the EGD inspection quality by combining the detection task of the upper digestive tract with ten anatomical structures and the classification task of informative video frames. The authors' model is able to eliminate non-informative frames of the gastroscopic videos and detect the anatomies in real time. Specifically, a sub-branch is added to the detection network to classify NBI images, informative and non-informative images. By doing so, the detected box will be only displayed on the informative frames, which can reduce the false-positive rate. They can determine the video frames on which each anatomical location is effectively examined, so that they can analyse the diagnosis quality. Their method reaches the performance of 93.74% mean average precision for the detection task and 98.77% accuracy for the classification task. Their model can reflect the detailed circumstance of the gastroscopy examination process, which shows application potential in improving the quality of examinations.
C1 [Zhang Xu; Yu Tao; Huang Zhengxing; Liu Jiquan; Duan Huilong] Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou 310027, Peoples R China.
   [Zheng Wenfang; Lin Ne; Hu Weiling; Si Jianmin] Zhejiang Univ, Sir Run Run Shaw Hosp, Med Sch, Dept Gastroenterol, Hangzhou 310016, Peoples R China.
   [Zheng Wenfang; Lin Ne; Hu Weiling; Si Jianmin] Zhejiang Univ, Inst Gastroenterol, Hangzhou 310029, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University
RP Liu, JQ (通讯作者)，Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou 310027, Peoples R China.
EM liujq@zju.edu.cn
OI Yu, Tao/0000-0001-9617-7465
FU National Key Research and Development Program of China [2017YFC0114106];
   National Natural Science Foundation of China [31771072, 81827804]
FX This work was supported by the National Key Research and Development
   Program of China (grant 2017YFC0114106), National Natural Science
   Foundation of China (grant nos. 31771072 and 81827804).
CR Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Fu C.Y., 2017, ARXIV170106659
   Girshick R., 2013, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Jeong J., 2017, BRIT MACH VIS C
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li HY, 2012, GASTROINTEST ENDOSC, V76, P1124, DOI 10.1016/j.gie.2012.08.015
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Redmon J, 2015, PROC CVPR IEEE, P779, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ruder S., 2017, ARXIV E PRINTS
   Sakai Y, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P4138, DOI 10.1109/EMBC.2018.8513274
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Vandenhende S., 2019, ARXIV E PRINTS
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yao K, 2013, ANN GASTROENTEROL, V26, P11
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
NR 24
TC 7
Z9 7
U1 2
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2053-3713
J9 HEALTHC TECHNOL LETT
JI Healthc. Technol. Lett.
PD DEC
PY 2019
VL 6
IS 6
SI SI
BP 176
EP 180
DI 10.1049/htl.2019.0066
PG 5
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA KA3ZS
UT WOS:000505737400006
PM 32038853
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Zheng, WF
   Zhang, X
   Kim, JJ
   Zhu, XJ
   Ye, GL
   Ye, B
   Wang, JP
   Luo, SL
   Li, JJ
   Yu, T
   Liu, JQ
   Hu, WL
   Si, JM
AF Zheng, Wenfang
   Zhang, Xu
   Kim, John J.
   Zhu, Xinjian
   Ye, Guoliang
   Ye, Bin
   Wang, Jianping
   Luo, Songlin
   Li, Jingjing
   Yu, Tao
   Liu, Jiquan
   Hu, Weiling
   Si, Jianmin
TI High Accuracy of Convolutional Neural Network for Evaluation of
   Helicobacter pylori Infection Based on Endoscopic Images: Preliminary
   Experience
SO CLINICAL AND TRANSLATIONAL GASTROENTEROLOGY
LA English
DT Article
ID CLINICAL-PRACTICE; DIAGNOSIS; GASTRITIS
AB OBJECTIVES: Application of artificial intelligence in gastrointestinal endoscopy is increasing. The aim of the study was to examine the accuracy of convolutional neural network (CNN) using endoscopic images for evaluating Helicobacter pylori (H. pylori) infection.
   METHODS: Patients who received upper endoscopy and gastric biopsies at Sir Run Run Shaw Hospital (January 2015-June 2015) were retrospectively searched. A novel Computer-Aided Decision Support System that incorporates CNN model (ResNet-50) based on endoscopic gastric images was developed to evaluate for H. pylori infection. Diagnostic accuracy was evaluated in an independent validation cohort. H. pylori infection was defined by the presence of H. pylori on immunohistochemistry testing on gastric biopsies and/or a positive 13C-urea breath test.
   RESULTS: Of 1,959 patients, 1,507 (77%) including 847 (56%) with H. pylori infection (11,729 gastric images) were assigned to the derivation cohort, and 452 (23%) including 310 (69%) with H. pylori infection (3,755 images) were assigned to the validation cohort. The area under the curve for a single gastric image was 0.93 (95% confidence interval [CI] 0.92-0.94) with sensitivity, specificity, and accuracy of 81.4% (95% CI 79.8%-82.9%), 90.1% (95% CI 88.4%-91.7%), and 84.5% (95% CI 83.3%-85.7%), respectively, using an optimal cutoff value of 0.3. Area under the curve for multiple gastric images (8.3 +/- 3.3) per patient was 0.97 (95% CI 0.96-0.99) with sensitivity, specificity, and accuracy of 91.6% (95% CI 88.0%-94.4%), 98.6% (95% CI 95.0%-99.8%), and 93.8% (95% CI 91.2%-95.8%), respectively, using an optimal cutoff value of 0.4.
   DISCUSSION: In this pilot study, CNN using multiple archived gastric images achieved high diagnostic accuracy for the evaluation of H. pylori infection.
C1 [Zheng, Wenfang; Kim, John J.; Hu, Weiling; Si, Jianmin] Zhejiang Univ, Sir Run Run Shaw Hosp, Med Sch, Dept Gastroenterol, Hangzhou, Peoples R China.
   [Zheng, Wenfang; Hu, Weiling; Si, Jianmin] Zhejiang Univ IGZJU, Inst Gastroenterol, Hangzhou, Peoples R China.
   [Zhang, Xu; Yu, Tao; Liu, Jiquan] Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou, Peoples R China.
   [Kim, John J.] Loma Linda Univ Hlth, Div Gastroenterol & Hepatol, Loma Linda, CA USA.
   [Zhu, Xinjian] Zhejiang Univ, Shaoxing Shangyu Peoples Hosp, Dept Gastroenterol, Shaoxing, Peoples R China.
   [Zhu, Xinjian] Zhejiang Univ, Shangyu Hosp, Affiliated Hosp 2, Med Sch, Shaoxing, Peoples R China.
   [Ye, Guoliang] Ningbo Univ, Affiliated Hosp, Med Sch, Dept Gastroenterol, Ningbo, Peoples R China.
   [Ye, Bin] Wenzhou Med Univ, Dept Gastroenterol, Affiliated Hosp 5, Lishui, Peoples R China.
   [Ye, Bin] Lishui Municipal Cent Hosp, Lishui, Peoples R China.
   [Wang, Jianping] Deqing Peoples Hosp, Dept Gastroenterol, Huzhou, Peoples R China.
   [Luo, Songlin] Shangyu Hosp Tradit Chinese Med, Dept Gastroenterol, Shaoxing, Peoples R China.
   [Li, Jingjing] First Peoples Hosp Huzhou, Dept Gastroenterol, Huzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Loma Linda University;
   Zhejiang University; Zhejiang University; Ningbo University; Wenzhou
   Medical University; Huzhou University
RP Hu, WL (通讯作者)，Zhejiang Univ, Sir Run Run Shaw Hosp, Med Sch, Dept Gastroenterol, Hangzhou, Peoples R China.; Hu, WL (通讯作者)，Zhejiang Univ IGZJU, Inst Gastroenterol, Hangzhou, Peoples R China.; Liu, JQ (通讯作者)，Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou, Peoples R China.
EM liujq@zju.edu.cn; huweiling@zju.edu.cn
RI Li, Jing/GYU-5036-2022; LI, Jing/HNB-5575-2023
FU Public Welfare Research Project of Zhejiang Province [LGF18H160012];
   Medical Health Project of Zhejiang Province [2020RC064]; National Key
   Research and Development Program of China [2017YFC0113505]
FX This work was supported by Public Welfare Research Project of Zhejiang
   Province (LGF18H160012), Medical Health Project of Zhejiang Province
   (2020RC064) and National Key Research and Development Program of China
   (2017YFC0113505).
CR Cho BJ, 2019, ENDOSCOPY
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Ferwana M, 2015, WORLD J GASTROENTERO, V21, P1305, DOI 10.3748/wjg.v21.i4.1305
   Gisbert JR, 2006, AM J GASTROENTEROL, V101, P1921, DOI 10.1111/j.1572-0241.2006.00668.x
   Gonen C, 2009, HELICOBACTER, V14, P12, DOI 10.1111/j.1523-5378.2009.00650.x
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kim I, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9020038
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LAINE L, 1995, GASTROINTEST ENDOSC, V42, P420, DOI 10.1016/S0016-5107(95)70043-9
   Laine L, 1997, GASTROINTEST ENDOSC, V45, P463, DOI 10.1016/S0016-5107(97)70174-3
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Malfertheiner P, 2017, GUT, V66, P6, DOI 10.1136/gutjnl-2016-312288
   Miwa H, 2015, J GASTROENTEROL, V50, P125, DOI 10.1007/s00535-014-1022-3
   Parkhi O M, 2015, PROC BRIT MACH VIS C, DOI DOI 10.5244/C.29.41
   PARSONNET J, 1991, NEW ENGL J MED, V325, P1127, DOI 10.1056/NEJM199110173251603
   Redeen S, 2003, ENDOSCOPY, V35, P946, DOI 10.1055/s-2003-43479
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Tahara T, 2009, GASTROINTEST ENDOSC, V70, P246, DOI 10.1016/j.gie.2008.11.046
   Togashi K, 2019, DIGEST ENDOSC, V31, P270, DOI 10.1111/den.13354
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 24
TC 38
Z9 39
U1 3
U2 12
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
EI 2155-384X
J9 CLIN TRANSL GASTROEN
JI Clin. Transl. Gastroenterol.
PD DEC
PY 2019
VL 10
AR e00109
DI 10.14309/ctg.0000000000000109
PG 6
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA KL8HM
UT WOS:000513658900001
PM 31833862
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Wan, JJ
   Chen, BL
   Kong, YX
   Ma, XG
   Yu, YT
AF Wan, Jing-Jing
   Chen, Bo-Lun
   Kong, Yi-Xiu
   Ma, Xing-Gang
   Yu, Yong-Tao
TI An Early Intestinal Cancer Prediction Algorithm Based on Deep Belief
   Network
SO SCIENTIFIC REPORTS
LA English
DT Article
ID FEATURE-SELECTION; CLASSIFICATION; SUPPORT
AB The incidence of colorectal cancer (colorectal cancer, CRC) in China has increased in recent years, and its mortality rate has become one of the highest among all cancers. CRC also increasingly affects people's health and quality of life, and the workloads of medical doctors have further increased due to the lack of sufficient medical resources in China. The goal of this study was to construct an automated expert system using a deep learning technique to predict the probability of early stage CRC based on the patient's case report and the patient's attributes. Compared with previous prediction methods, which are either based on sophisticated examinations or have high computational complexity, this method is shown to provide valuable information such as suggesting potentially important early signs to assist in early diagnosis, early treatment and prevention of CRC, hence helping medical doctors reduce the workloads of endoscopies and other treatments.
C1 [Wan, Jing-Jing; Ma, Xing-Gang] Xuzhou Med Univ, Affiliated Huaian Hosp, Dept Gastroenterol, Second Peoples Hosp Huaian, Huaian 223002, Peoples R China.
   [Chen, Bo-Lun; Kong, Yi-Xiu; Yu, Yong-Tao] Huaiyin Inst Technol, Coll Comp Engn, Huaian 223003, Peoples R China.
C3 Xuzhou Medical University; Huaiyin Institute of Technology
RP Chen, BL (通讯作者)，Huaiyin Inst Technol, Coll Comp Engn, Huaian 223003, Peoples R China.
EM chenbolun1986@163.com
RI Kong, Yixiu/HJB-4006-2022
FU Chinese National Natural Science Foundation [61602202]; Natural Science
   Foundation of Jiangsu Province [BK20160428]; Six Talent Peaks project in
   Jiangsu Province [XYDXX-034]; Natural Science Foundation of Huaian
   [HAB201934]
FX This research was supported in part by the Chinese National Natural
   Science Foundation under grant No. 61602202, the Natural Science
   Foundation of Jiangsu Province under contract BK20160428, the Six Talent
   Peaks project in Jiangsu Province under contract XYDXX-034 and the
   Natural Science Foundation of Huaian under contract HAB201934. The
   datasets were provided by the Jiangsu Provincial Hospital of Traditional
   Chinese Medicine.
CR Cruz-Roa AA, 2013, LECT NOTES COMPUT SC, V8150, P403, DOI 10.1007/978-3-642-40763-5_50
   An JG, 2013, LANCET, V382, P936, DOI 10.1016/S0140-6736(13)61928-5
   Bennasar M, 2015, EXPERT SYST APPL, V42, P8520, DOI 10.1016/j.eswa.2015.07.007
   Boareto M, 2015, IEEE ACM T COMPUT BI, V12, P705, DOI 10.1109/TCBB.2014.2377750
   Burke HB, 1997, CANCER, V79, P857, DOI 10.1002/(SICI)1097-0142(19970215)79:4<857::AID-CNCR24>3.0.CO;2-Y
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Camma C, 2000, JAMA-J AM MED ASSOC, V284, P1008, DOI 10.1001/jama.284.8.1008
   Carter JV, 2016, ANN SURG, V264, P575, DOI 10.1097/SLA.0000000000001873
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Chen XiaoJun, 2013, Chinese Medicine, V4, P1, DOI 10.4236/cm.2013.41001
   Cobos C, 2013, INFORM PROCESS MANAG, V49, P607, DOI 10.1016/j.ipm.2012.12.002
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Courtney RJ, 2013, BMC CANCER, V13, DOI 10.1186/1471-2407-13-13
   Danaee P, 2017, BIOCOMPUT-PAC SYM, P219, DOI 10.1142/9789813207813_0022
   Das L., 2017, P 2017 2 INT C MAN M, P1
   Duan KB, 2005, IEEE T NANOBIOSCI, V4, P228, DOI 10.1109/TNB.2005.853657
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fong S, 2014, IT PROF, V16, P24, DOI 10.1109/MITP.2014.50
   Funk S., 2006, NETFLIX UPDATE TRY T
   Guimera R, 2009, P NATL ACAD SCI USA, V106, P22073, DOI 10.1073/pnas.0908366106
   He AJ, 2016, HEALTH ECON POLICY L, V11, P359, DOI 10.1017/S1744133116000128
   Kleftogiannis D, 2015, IEEE ACM T COMPUT BI, V12, P1183, DOI 10.1109/TCBB.2014.2388227
   Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874
   Kourou K, 2015, COMPUT STRUCT BIOTEC, V13, P8, DOI 10.1016/j.csbj.2014.11.005
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Leng C. C., 2016, P 12 IEEE IMAG VID M, P1
   Li YF, 2013, SOURCE CODE BIOL MED, V8, DOI 10.1186/1751-0473-8-10
   Mamoshina P, 2016, MOL PHARMACEUT, V13, P1445, DOI 10.1021/acs.molpharmaceut.5b00982
   Metsis V, 2014, IEEE ACM T COMPUT BI, V11, P168, DOI 10.1109/TCBB.2013.141
   Mohapatra P, 2016, SWARM EVOL COMPUT, V28, P144, DOI 10.1016/j.swevo.2016.02.002
   Nikitidis S, 2012, PATTERN RECOGN, V45, P4080, DOI 10.1016/j.patcog.2012.04.030
   Oja E., 2004, INDEPENDENT COMPONEN, V46
   Qureshi N. A., 2017, INDIAN J SCI TECHNOL, V10, P1, DOI [10.17485/ijst/2017/v10i20/91294, DOI 10.17485/ijst/2017/v10i20/91294]
   Reda I, 2016, I S BIOMED IMAGING, P1237, DOI 10.1109/ISBI.2016.7493490
   Sandler R, 2011, IEEE T PATTERN ANAL, V33, P1590, DOI 10.1109/TPAMI.2011.18
   Society, 2017, CA CANC J CLIN
   Wang F., 2016, P 22 ACM SIGKDD INT, P2137
   Wang LP, 2016, METHODS, V111, P21, DOI 10.1016/j.ymeth.2016.08.014
   Wu D, 2014, BMJ OPEN, V4, DOI 10.1136/bmjopen-2014-006431
   Wu H, 2011, RES NURS HEALTH, V34, P401, DOI 10.1002/nur.20449
   Xiao YW, 2018, COMPUT METH PROG BIO, V153, P1, DOI 10.1016/j.cmpb.2017.09.005
   Xu XY, 2015, IET SYST BIOL, V9, P155, DOI 10.1049/iet-syb.2014.0051
   [袁平 Yuan Ping], 2017, [中国肿瘤, Bulletin of Chinese Cancer], V26, P241
   Zhong JC, 2015, TSINGHUA SCI TECHNOL, V20, P491, DOI 10.1109/TST.2015.7297748
NR 45
TC 12
Z9 12
U1 1
U2 10
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD NOV 22
PY 2019
VL 9
AR 17418
DI 10.1038/s41598-019-54031-2
PG 13
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA JP1UP
UT WOS:000498057400005
PM 31758076
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU He, YS
   Su, JR
   Li, Z
   Zuo, XL
   Li, YQ
AF He, Yi Shan
   Su, Jing Ran
   Li, Zhen
   Zuo, Xiu Li
   Li, Yan Qing
TI Application of artificial intelligence in gastrointestinal endoscopy
SO JOURNAL OF DIGESTIVE DISEASES
LA English
DT Article
DE artificial intelligence; gastrointestinal endoscopy
ID HELICOBACTER-PYLORI INFECTION; COMPUTER-AIDED DIAGNOSIS; CAPSULE
   ENDOSCOPY; PERFORMANCE; HISTOLOGY; POLYPS; CANCER
AB With recent significant improvements in artificial intelligence (AI), especially in the field of deep learning, an increasing number of studies have evaluated the use of AI in endoscopy to detect and diagnose gastrointestinal (GI) lesions. The present review summarizes current publications on the use of AI in GI endoscopy and focuses on the challenges and future of AI-aided systems. We expect AI to provide an effective and practical method for endoscopists in lesion detection and characterization as well as in quality control in endoscopy. However, so far, most studies have remained at the preclinical stage. More attention should be paid in the future to the use of AI in real-life clinical applications.
C1 [He, Yi Shan; Su, Jing Ran; Li, Zhen; Zuo, Xiu Li; Li, Yan Qing] Shandong Univ, Dept Gastroenterol, Qilu Hosp, 107 Wenhuaxi Rd, Jinan 250012, Shandong, Peoples R China.
   [He, Yi Shan; Su, Jing Ran; Li, Zhen; Zuo, Xiu Li; Li, Yan Qing] Shandong Univ, Lab Translat Gastroenterol, Qilu Hosp, Jinan, Shandong, Peoples R China.
   [He, Yi Shan; Su, Jing Ran; Li, Zhen; Zuo, Xiu Li; Li, Yan Qing] Shandong Univ, Robot Engn Lab Precise Diag & Therapy GI Tumor, Qilu Hosp, Jinan, Shandong, Peoples R China.
C3 Shandong University; Shandong University; Shandong University
RP Li, YQ (通讯作者)，Shandong Univ, Dept Gastroenterol, Qilu Hosp, 107 Wenhuaxi Rd, Jinan 250012, Shandong, Peoples R China.
EM liyanqing@sdu.edu.cn
RI Li, Zhen/HHM-3328-2022; Li, Zhen/AAH-2515-2022; Li, Zhen/AFK-5293-2022
OI Li, Zhen/0000-0002-9783-169X; Li, Yanqing/0000-0003-0575-0399
FU Key Research and Development Program of Shandong Province
   [2018CXGC1209]; National Key R&D Program of China [2018YFB1307700]
FX Key Research and Development Program of Shandong Province, Grant/Award
   Number: 2018CXGC1209; National Key R&D Program of China, Grant/Award
   Number: 2018YFB1307700
CR Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1373/clinchem.2015.246280, 10.1136/bmj.h5527, 10.1148/radiol.2015151516]
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   England JR, 2019, AM J ROENTGENOL, V212, P513, DOI 10.2214/AJR.18.20490
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   McCarthy J, 2006, AI MAG, V27, P12
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920
   Rees CJ, 2016, GUT, V65, P2045, DOI 10.1136/gutjnl-2016-312043
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yoon HJ, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091310
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 41
TC 17
Z9 20
U1 5
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-2972
EI 1751-2980
J9 J DIGEST DIS
JI J. Dig. Dis.
PD DEC
PY 2019
VL 20
IS 12
BP 623
EP 630
DI 10.1111/1751-2980.12827
EA NOV 2019
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA NE4IS
UT WOS:000497300000001
PM 31639272
DA 2023-04-20
ER

PT J
AU Kudo, SE
   Mori, Y
   Abdel-aal, UM
   Misawa, M
   Itoh, H
   Oda, M
   Mori, K
AF Kudo, Shin-Ei
   Mori, Yuichi
   Abdel-aal, Usama M.
   Misawa, Masashi
   Itoh, Hayato
   Oda, Masahiro
   Mori, Kensaku
TI Artificial intelligence and computer-aided diagnosis for colonoscopy:
   where do we stand now?
SO TRANSLATIONAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Review
DE Computer-aided diagnosis (CAD); colon cancer; polyp
ID COLORECTAL POLYP HISTOLOGY; LESIONS; SYSTEM; CLASSIFICATION; CANCER;
   ENDOCYTOSCOPY; ENDOSCOPY; PATTERNS
AB Computer-aided diagnosis (CAD) for colonoscopy with use of artificial intelligence (AI) is catching increased attention of endoscopists. CAD allows automated detection and pathological prediction, namely optical biopsy, of colorectal polyps during real-time endoscopy, which help endoscopists avoid missing and/or misdiagnosing colorectal lesions. With the increased number of publications in this field and emergence of the AI medical device that have already secured regulatory approval, CAD in colonoscopy is now being implemented into clinical practice. On the other side, drawbacks and weak points of CAD in colonoscopy have not been thoroughly discussed. In this review, we provide an overview of CAD for optical biopsy of colorectal lesions with a particular focus on its clinical applications and limitations.
C1 [Kudo, Shin-Ei; Mori, Yuichi; Abdel-aal, Usama M.; Misawa, Masashi] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Abdel-aal, Usama M.] Sohag Univ, Fac Med, Internal Med, Sohag, Egypt.
   [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
C3 Showa University; Egyptian Knowledge Bank (EKB); Sohag University;
   Nagoya University
RP Kudo, SE (通讯作者)，Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Tsuzuki Ku, 35-1 Chigasaki Tyuo, Yokohama, Kanagawa 2248503, Japan.
EM kudos@med.showa-u.ac.jp
RI Itoh, Hayato/AAM-4022-2021; Misawa, Masashi/H-9004-2019
OI Itoh, Hayato/0000-0002-1410-1078; Misawa, Masashi/0000-0002-8520-2036;
   Oda, Masahiro/0000-0001-7714-422X
CR Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Aihara H, 2009, GASTROINTEST ENDOSC, V69, P726, DOI 10.1016/j.gie.2008.10.044
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Ferlitsch M, 2017, ENDOSCOPY, V49, P270, DOI 10.1055/s-0043-102569
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hazewinkel Y, 2013, GASTROINTEST ENDOSC, V77, P916, DOI 10.1016/j.gie.2012.12.018
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   McCarthy J, 2006, AI MAG, V27, P12
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Morris EJA, 2015, GUT, V64, P1248, DOI 10.1136/gutjnl-2014-308362
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P27
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
NR 39
TC 2
Z9 2
U1 0
U2 0
PU AME PUBLISHING COMPANY
PI SHATIN
PA FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG
   00000, PEOPLES R CHINA
EI 2415-1289
J9 TRANSL GASTROENT HEP
JI Transl. Gastroenterol. Hepatol.
PD OCT
PY 2021
VL 6
AR 64
DI 10.21037/tgh.2019.12.14
EA NOV 2019
PG 7
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA WW9SU
UT WOS:000675480100001
PM 34805586
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Taunk, P
   Atkinson, CD
   Lichtenstein, D
   Rodriguez-Diaz, E
   Singh, SK
AF Taunk, Pushpak
   Atkinson, Christopher D.
   Lichtenstein, David
   Rodriguez-Diaz, Eladio
   Singh, Satish K.
TI Computer-assisted assessment of colonic polyp histopathology using
   probe-based confocal laser endomicroscopy
SO INTERNATIONAL JOURNAL OF COLORECTAL DISEASE
LA English
DT Article
DE Confocal laser endomicroscopy; Colorectal cancer; Polyp histology;
   Machine learning
ID SOCIETY-TASK-FORCE; COLORECTAL-CANCER; WHITE-LIGHT; COLONOSCOPY
   SURVEILLANCE; VIRTUAL CHROMOENDOSCOPY; BARRETTS-ESOPHAGUS; COMMUNITY
   PRACTICE; OPTICAL BIOPSY; HISTOLOGY; ACCURACY
AB Introduction Probe-based confocal laser endomicroscopy (pCLE) is a promising modality for classifying polyp histology in vivo, but decision making in real-time is hampered by high-magnification targeting and by the learning curve for image interpretation. The aim of this study is to test the feasibility of a system combining the use of a low-magnification, wider field-of-view pCLE probe and a computer-assisted diagnosis (CAD) algorithm that automatically classifies colonic polyps. Methods This feasibility study utilized images of polyps from 26 patients who underwent colonoscopy with pCLE. The pCLE images were reviewed offline by two expert and five junior endoscopists blinded to index histopathology. A subset of images was used to train classification software based on the consensus of two GI histopathologists. Images were processed to extract image features as inputs to a linear support vector machine classifier. We compared the CAD algorithm's prediction accuracy against the classification accuracy of the endoscopists. Results We utilized 96 neoplastic and 93 non-neoplastic confocal images from 27 neoplastic and 20 non-neoplastic polyps. The CAD algorithm had sensitivity of 95%, specificity of 94%, and accuracy of 94%. The expert endoscopists had sensitivities of 98% and 95%, specificities of 98% and 96%, and accuracies of 98% and 96%, while the junior endoscopists had, on average, a sensitivity of 60%, specificity of 85%, and accuracy of 73%. Conclusion The CAD algorithm showed comparable performance to offline review by expert endoscopists and improved performance when compared to junior endoscopists and may be useful for assisting clinical decision making in real time.
C1 [Taunk, Pushpak] Univ S Florida, Morsani Coll Med, Div Digest Dis & Nutr, Tampa, FL 33612 USA.
   [Atkinson, Christopher D.; Singh, Satish K.] VA Boston Healthcare Syst, Sect Gastroenterol, Dept Med, Boston, MA 02130 USA.
   [Lichtenstein, David] Boston Univ, Sch Med, Boston Med Ctr, Boston, MA 02118 USA.
   [Rodriguez-Diaz, Eladio] VA Boston Healthcare Syst, Res Serv, Boston, MA USA.
   [Singh, Satish K.] Boston Univ, Sch Med, Boston, MA 02118 USA.
   [Singh, Satish K.] Boston Univ, Coll Engn, Boston, MA 02215 USA.
C3 State University System of Florida; University of South Florida; US
   Department of Veterans Affairs; Veterans Health Administration (VHA);
   Harvard University; VA Boston Healthcare System; Boston Medical Center;
   Boston University; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); Harvard University; VA Boston Healthcare System;
   Boston University; Boston University
RP Singh, SK (通讯作者)，VA Boston Healthcare Syst, Sect Gastroenterol, Dept Med, Boston, MA 02130 USA.; Singh, SK (通讯作者)，Boston Univ, Sch Med, Boston, MA 02118 USA.; Singh, SK (通讯作者)，Boston Univ, Coll Engn, Boston, MA 02215 USA.
EM ptaunk@heahh.usf.edu; christopher.atkinson2@va.gov;
   David.Lichtenstein@bmc.org; Eladio.Rodriguez-Diaz@va.gov;
   Satish.Singh@va.gov
OI Singh, Satish/0000-0002-7664-3155
FU U.S. Department of Veterans Affairs [I01CX001146, I01BX004455] Funding
   Source: Medline; BLRD VA [I01 BX004455] Funding Source: Medline; CSRD VA
   [I01 CX001146] Funding Source: Medline
CR Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Andre B, 2011, MED IMAGE ANAL, V15, P460, DOI 10.1016/j.media.2011.02.003
   Buchner AM, 2010, GASTROENTEROLOGY, V138, P834, DOI 10.1053/j.gastro.2009.10.053
   Buda A, 2014, J CROHNS COLITIS, V8, P304, DOI 10.1016/j.crohns.2013.09.005
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Canto MI, 2014, GASTROINTEST ENDOSC, V79, P211, DOI 10.1016/j.gie.2013.09.020
   Dhar A, 2006, GASTROINTEST ENDOSC, V63, P257, DOI 10.1016/j.gie.2005.07.026
   Duda R. O., 2001, PATTERN CLASSIFICATI, V2nd
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P494, DOI 10.1016/j.gie.2011.08.002
   Huang CS, 2004, AM J GASTROENTEROL, V99, P2242, DOI 10.1111/j.1572-0241.2004.40131.x
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jain A, 1989, FUNDAMENTALS DIGITAL
   Kiesslich R, 2012, GUT, V61, P1146, DOI 10.1136/gutjnl-2011-300695
   Kim YS, 2011, CLIN GASTROENTEROL H, V9, P744, DOI 10.1016/j.cgh.2011.05.021
   Kuiper T, 2012, AM J GASTROENTEROL, V107, P543, DOI 10.1038/ajg.2012.14
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P603, DOI 10.1016/j.gie.2011.04.049
   Levin B, 2008, CA-CANCER J CLIN, V58, P130, DOI 10.3322/CA.2007.0018
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Liu JJ, 2011, J CLIN GASTROENTEROL, V45, P240, DOI 10.1097/MCG.0b013e3181fbdb8a
   Liu JJ, 2011, GASTROINTEST ENDOSC, V73, P1174, DOI 10.1016/j.gie.2011.01.018
   Meining A, 2011, GASTROINTEST ENDOSC, V74, P961, DOI 10.1016/j.gie.2011.05.009
   Moussata D, 2011, GUT, V60, P26, DOI 10.1136/gut.2010.213264
   Neumann H, 2012, INFLAMM BOWEL DIS, V18, P2261, DOI 10.1002/ibd.22907
   Parkin DM, 2001, EUR J CANCER, V37, pS4, DOI 10.1016/S0959-8049(01)00267-2
   Pohl J, 2008, AM J GASTROENTEROL, V103, P562, DOI 10.1111/j.1572-0241.2007.01670.x
   Rastogi A, 2014, GASTROINTEST ENDOSC, V79, P390, DOI 10.1016/j.gie.2013.07.032
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rodriguez-Diaz E, 2015, GASTROINTEST ENDOSC, V81, P539, DOI 10.1016/j.gie.2014.07.012
   Rodriguez-Diaz E, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3592488
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Shahid MW, 2012, ENDOSCOPY, V44, P343, DOI 10.1055/s-0031-1291589
   Shahid MW, 2012, AM J GASTROENTEROL, V107, P231, DOI 10.1038/ajg.2011.376
   Sharma P, 2011, GASTROINTEST ENDOSC, V74, P465, DOI 10.1016/j.gie.2011.04.004
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Singh R, 2013, J GASTROEN HEPATOL, V28, P472, DOI 10.1111/jgh.12098
   Ussui VM, 2012, GASTROENT RES PRACT, V2012, DOI 10.1155/2012/545679
   Vapnik V, 1998, STAT LEARNING THEORY
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Wallace M, 2011, ENDOSCOPY, V43, P882, DOI 10.1055/s-0030-1256632
   Winawer SJ, 2006, GASTROENTEROLOGY, V130, P1872, DOI 10.1053/j.gastro.2006.03.012
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
NR 45
TC 9
Z9 10
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0179-1958
EI 1432-1262
J9 INT J COLORECTAL DIS
JI Int. J. Colorectal Dis.
PD DEC
PY 2019
VL 34
IS 12
BP 2043
EP 2051
DI 10.1007/s00384-019-03406-y
EA NOV 2019
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA JT7OL
UT WOS:000494764900001
PM 31696259
DA 2023-04-20
ER

PT J
AU Wang, H
   Ding, S
   Wu, DS
   Zhang, YT
   Yang, SL
AF Wang, Hao
   Ding, Shuai
   Wu, Desheng
   Zhang, Youtao
   Yang, Shanlin
TI Smart connected electronic gastroscope system for gastric cancer
   screening using multi-column convolutional neural networks
SO INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH
LA English
DT Article
DE artificial intelligence; decision support systems; complex product;
   endoscopy system; gastric cancer screening; convolutional neural network
AB Gastroscopy is a widely adopted method for gastric cancer screening and early diagnosis. Clinical studies show that it can effectively prolong patient life and maximise therapeutic effect. However, it is difficult for doctors to identify and detect lesions in real time, which manifests as the major challenge in gastroscopy. In this paper, we propose SCEG, a smart connected electronic gastroscopy system that performs dynamic cancer screening in gastroscopy. By integrating electronic gastroscopy with cloud-based medical image analysis service, we develop an AdaBoost-based multi-column convolutional neural network (MCNN) for enhancing gastric cancer screening. Experimental results show that the proposed MCNN approach significantly outperforms other competing approaches.
C1 [Wang, Hao; Ding, Shuai; Yang, Shanlin] Hefei Univ Technol, Sch Management, Hefei, Anhui, Peoples R China.
   [Wang, Hao; Ding, Shuai; Yang, Shanlin] Hefei Univ Technol, Minist Educ, Key Lab Proc Optimizat & Intelligent Decis Making, Hefei, Anhui, Peoples R China.
   [Wu, Desheng] Univ Chinese Acad Sci, Econ & Management Sch, Beijing, Peoples R China.
   [Zhang, Youtao] Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA.
C3 Hefei University of Technology; Hefei University of Technology; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh
RP Ding, S; Yang, SL (通讯作者)，Hefei Univ Technol, Sch Management, Hefei, Anhui, Peoples R China.; Ding, S; Yang, SL (通讯作者)，Hefei Univ Technol, Minist Educ, Key Lab Proc Optimizat & Intelligent Decis Making, Hefei, Anhui, Peoples R China.
EM dingshui@hfut.edu.cn; yangsl@hfut.edu.cn
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Chon HK, 2017, SURG ENDOSC, V31, P2783, DOI 10.1007/s00464-016-5287-x
   Cuingnet R, 2011, MED IMAGE ANAL, V15, P729, DOI 10.1016/j.media.2011.05.007
   Demir E, 2015, INT J PROD RES, V53, P7238, DOI 10.1080/00207543.2015.1029647
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding JR, 2015, OPTIK, V126, P5188, DOI 10.1016/j.ijleo.2015.09.231
   Ding RK, 2017, INT J PROD RES, V55, P750, DOI 10.1080/00207543.2016.1208372
   Dong L, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P260
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kang LN, 2014, CANC CONTROL, V2014, P131, DOI DOI 10.1016/S0039-6109(15)00125-11
   Kannan SR, 2011, EXPERT SYST APPL, V38, P4382, DOI 10.1016/j.eswa.2010.09.107
   le Clercq CMC, 2015, GASTROINTEST ENDOSC, V82, P325, DOI 10.1016/j.gie.2014.12.052
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Nagar Anil Bernard, 2017, NOTES ENDOLUMINAL SU, P47, DOI [10.1007/978-3-319-50610-4_4, DOI 10.1007/978-3-319-50610-4_4]
   Oh JH, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P415, DOI 10.1145/3018661.3018737
   Pellise M, 2017, GUT, V66, P644, DOI 10.1136/gutjnl-2015-310249
   Priya M, 2015, INT J PROD RES, V53, P7517, DOI 10.1080/00207543.2015.1087655
   Pyo JH, 2016, AM J GASTROENTEROL, V111, P240, DOI 10.1038/ajg.2015.427
   Santosh KC, 2018, IEEE T MED IMAGING, V37, P1168, DOI 10.1109/TMI.2017.2775636
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Simonyan K, 2015, Arxiv
   Sugano K, 2015, BEST PRACT RES CL GA, V29, P895, DOI 10.1016/j.bpg.2015.09.013
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   van der Spoel S, 2017, INT J PROD RES, V55, P5062, DOI 10.1080/00207543.2015.1064183
   Ye XM, 2015, PROCEEDINGS OF THE 2015 7TH IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P234, DOI 10.1109/ICCIS.2015.7274579
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhu Z. Q., 2008, IEEE VEH POW PROP C, P1
NR 32
TC 20
Z9 23
U1 5
U2 31
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0020-7543
EI 1366-588X
J9 INT J PROD RES
JI Int. J. Prod. Res.
PD NOV 2
PY 2019
VL 57
IS 21
BP 6795
EP 6806
DI 10.1080/00207543.2018.1464232
PG 12
WC Engineering, Industrial; Engineering, Manufacturing; Operations Research
   & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Operations Research & Management Science
GA JE0VO
UT WOS:000490412500013
DA 2023-04-20
ER

PT J
AU Cai, SL
   Li, B
   Tan, WM
   Niu, XJ
   Yu, HH
   Yao, LQ
   Zhou, PH
   Yan, B
   Zhong, YS
AF Cai, Shi-Lun
   Li, Bing
   Tan, Wei-Min
   Niu, Xue-Jing
   Yu, Hon-Ho
   Yao, Li-Qing
   Zhou, Ping-Hong
   Yan, Bo
   Zhong, Yun-Shi
TI Using a deep learning system in endoscopy for screening of early
   esophageal squamous cell carcinoma (with video)
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID CANCER; HEAD
AB Background and Aims: Few artificial intelligence-based technologies have been developed to improve the efficiency of screening for esophageal squamous cell carcinoma (ESCC). Here, we developed and validated a novel system of computer-aided detection (CAD) using a deep neural network (DNN) to localize and identify early ESCC under conventional endoscopic white-light imaging.
   Methods: We collected 2428 (1332 abnormal, 1096 normal) esophagoscopic images from 746 patients to set up a novel DNN-CAD system in 2 centers and prepared a validation dataset containing 187 images from 52 patients. Sixteen endoscopists (senior, mid-level, and junior) were asked to review the images of the validation set. The diagnostic results, including accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV), were compared between the DNN-CAD system and endoscopists.
   Results: The receiver operating characteristic curve for DNN-CAD showed that the area under the curve was >96%. For the validation dataset, DNN-CAD had a sensitivity, specificity, accuracy, PPV, and NPV of 97.8%, 85.4%, 91.4%, 86.4%, and 97.6%, respectively. The senior group achieved an average diagnostic accuracy of 88.8%, whereas the junior group had a lower value of 77.2%. After referring to the results of DNN-CAD, the average diagnostic ability of the endoscopists improved, especially in terms of sensitivity (74.2% vs 89.2%), accuracy (81.7% vs 91.1%), and NPV (79.3% vs 90.4%).
   Conclusions: The novel DNN-CAD system used for screening of early ESCC has high accuracy and sensitivity, and can help endoscopists to detect lesions previously ignored under white-light imaging.
C1 [Cai, Shi-Lun; Li, Bing; Yao, Li-Qing; Zhou, Ping-Hong; Zhong, Yun-Shi] Fudan Univ, Zhongshan Hosp, Endoscopy Ctr, Shanghai, Peoples R China.
   [Cai, Shi-Lun; Li, Bing; Yao, Li-Qing; Zhou, Ping-Hong; Zhong, Yun-Shi] Fudan Univ, Endoscopy Res Inst, Shanghai, Peoples R China.
   [Tan, Wei-Min; Niu, Xue-Jing; Yan, Bo] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai, Peoples R China.
   [Yu, Hon-Ho] Kiang Wu Hosp, Taipa, Macau, Peoples R China.
C3 Fudan University; Fudan University; Fudan University
RP Zhong, YS (通讯作者)，Fudan Univ, Endoscopy Res Inst, Shanghai, Peoples R China.; Yan, B (通讯作者)，Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai, Peoples R China.
EM byan@fudan.edu.cn; zhongyunshi@yahoo.com
RI Zhong, Yun/HCH-6868-2022
FU National Natural Science Foundation of China [81861168036, 81702305];
   Shanghai Engineering and Research Center of Diagnostic and Therapeutic
   Endoscopy [19DZ2280100]; Shanghai Municipal Health System Outstanding
   Academic Leaders Foundation Program [2017BR010]; Dawn Program of
   Shanghai Education Commission [18SG08]
FX This project was supported by the National Natural Science Foundation of
   China (81861168036, 81702305), Shanghai Engineering and Research Center
   of Diagnostic and Therapeutic Endoscopy (19DZ2280100), Shanghai
   Municipal Health System Outstanding Academic Leaders Foundation Program
   (2017BR010), and Dawn Program of Shanghai Education Commission (18SG08).
   The funders had no role in the study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR Arnold M, 2015, GUT, V64, P381, DOI 10.1136/gutjnl-2014-308124
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Dawsey SM, 1998, CANCER-AM CANCER SOC, V83, P220
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   Enzinger PC, 2003, NEW ENGL J MED, V349, P2241, DOI 10.1056/NEJMra035010
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Ishihara R, 2010, DIS ESOPHAGUS, V23, P480, DOI 10.1111/j.1442-2050.2009.01039.x
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Li JJ, 2018, CLIN GASTROENTEROL H, V16, P1585, DOI 10.1016/j.cgh.2017.11.031
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Muto M, 2010, J CLIN ONCOL, V28, P1566, DOI 10.1200/JCO.2009.25.4680
   Nagami Y, 2014, AM J GASTROENTEROL, V109, P845, DOI 10.1038/ajg.2014.94
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Takenaka R, 2009, AM J GASTROENTEROL, V104, P2942, DOI 10.1038/ajg.2009.426
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang GQ, 2004, ANN THORAC SURG, V77, P1740, DOI 10.1016/j.athoracsur.2003.10.098
   Wei WQ, 2015, J CLIN ONCOL, V33, P1951, DOI 10.1200/JCO.2014.58.0423
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
NR 22
TC 71
Z9 76
U1 4
U2 20
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD NOV
PY 2019
VL 90
IS 5
BP 745
EP +
DI 10.1016/j.gie.2019.06.044
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA JE9BN
UT WOS:000490983600006
PM 31302091
DA 2023-04-20
ER

PT J
AU Cave, DR
   Hakimian, S
   Patel, K
AF Cave, David R.
   Hakimian, Shahrad
   Patel, Krunal
TI Current Controversies Concerning Capsule Endoscopy
SO DIGESTIVE DISEASES AND SCIENCES
LA English
DT Article
DE Video capsule endoscopy; Controversies; Indications; Small intestine
ID SMALL-BOWEL PREPARATION; VIDEO CAPSULE; DIAGNOSTIC YIELD; INTEROBSERVER
   AGREEMENT; CROHNS-DISEASE; SIMETHICONE; MULTICENTER; VISUALIZATION;
   LOCALIZATION; ENTEROGRAPHY
AB Video capsule endoscopy became a reality in 2001. This device enabled us to directly view the mucosa of the small intestine for the first time. The main indications for the video capsule remain the detection of small intestinal bleeding and iron deficiency anemia, diagnosis and management of Crohn's disease, and detection of tumors. The device is extraordinarily safe and can be used in the very young to the very old. However, there remain several areas of controversy and difficulty. These are covered in this article and include details of indications and contraindications, whether to prepare patients, whether or not to use simethicone and prokinetics. Detection of location of the capsule remains a major engineering challenge. Reading the videos reliably and quickly remains challenging. However, artificial intelligence and machine learning are already on the horizon to provide assistance. New uses for capsule endoscopy promise more accurate diagnosis and hence improved management of acute gastrointestinal bleeding. The colon capsule may eventually help those who refuse conventional colonoscopy, and robotically controlled capsules may be helpful in screening for serious disease in patients with upper abdominal complaints. The advent of the broadening use of video capsule endoscopy is, though it will be controversial, embraced by some and derided by others; such is the nature of technological development. In the long run, if the use of the video capsule, based on sound evidence-based studies, can be shown to improve the care of our patients and reduce the cost of health care, its use will continue to expand.
C1 [Cave, David R.; Hakimian, Shahrad; Patel, Krunal] Univ Massachusetts, Div Gastroenterol, Dept Med, 55 Lake Ave North, Worcester, MA 01655 USA.
C3 University of Massachusetts System; University of Massachusetts
   Worcester
RP Cave, DR (通讯作者)，Univ Massachusetts, Div Gastroenterol, Dept Med, 55 Lake Ave North, Worcester, MA 01655 USA.
EM David.cave@umassmemorial.org
RI Cave, David/HPG-1312-2023
CR Albert J, 2004, GASTROINTEST ENDOSC, V59, P487, DOI 10.1016/S0016-5107(04)00003-3
   Alexandrino G, 2019, CLIN ENDOSC, V52, P47, DOI 10.5946/ce.2018.093
   Bandorski D, 2014, ANN GASTROENTEROL, V27, P3
   Biagi F, 2006, CLIN GASTROENTEROL H, V4, P998, DOI 10.1016/j.cgh.2006.04.004
   Cauned-Alvarez A, 2006, P 5 INT C CAPS END
   Cave DR, 2008, GASTROINTEST ENDOSC, V68, P487, DOI 10.1016/j.gie.2007.12.037
   Chen HB, 2011, J CLIN GASTROENTEROL, V45, P337, DOI 10.1097/MCG.0b013e3181f0f3a3
   De Leusse A, 2005, ENDOSCOPY, V37, P617, DOI 10.1055/s-2005-861419
   Dionisio PM, 2010, AM J GASTROENTEROL, V105, P1240, DOI 10.1038/ajg.2009.713
   Enns RA, 2017, GASTROENTEROLOGY, V152, P497, DOI 10.1053/j.gastro.2016.12.032
   Esaki M, 2009, GASTROINTEST ENDOSC, V69, P94, DOI 10.1016/j.gie.2008.04.054
   Fang YH, 2009, J ZHEJIANG UNIV-SC B, V10, P46, DOI 10.1631/jzus.B0820148
   Fry LC, 2006, ENDOSCOPY, V38, P498, DOI 10.1055/s-2006-925340
   Gomes C, 2018, WORLD J GASTRO ENDOS, V10, P74, DOI 10.4253/wjge.v10.i4.74
   Hakimian S, 2018, ENDOSC INT OPEN, V6, pE989, DOI 10.1055/a-0590-3940
   Hartmann D, 2003, Z GASTROENTEROL, V41, P377
   Hookey L, 2017, GASTROINTEST ENDOSC, V85, P187, DOI 10.1016/j.gie.2016.07.028
   Jang BI, 2010, SCAND J GASTROENTERO, V45, P370, DOI 10.3109/00365520903521574
   Jensen MD, 2010, SCAND J GASTROENTERO, V45, P878, DOI 10.3109/00365521.2010.483014
   Karargyris A, 2013, WORLD J GASTROENTERO, V19, P5943, DOI 10.3748/wjg.v19.i35.5943
   Koulaouzidis A, 2018, ENDOSC INT OPEN, V6, pE205, DOI 10.1055/s-0043-121882
   Krijbolder MS, 2018, NETH J MED, V76, P27
   Lai LH, 2005, GASTROINTEST ENDOSC, V61, pAB173, DOI 10.1016/S0016-5107(05)00969-7
   Laursen SB, 2017, GASTROINTEST ENDOSC, V85, P936, DOI 10.1016/j.gie.2016.08.049
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Limsrivilai J, 2017, J CLIN GASTROENTEROL, V51, P611, DOI 10.1097/MCG.0000000000000639
   Lujan-Sanchis M, 2016, WORLD J GASTRO ENDOS, V8, P572, DOI 10.4253/wjge.v8.i17.572
   Marshall CA, 2017, GASTROINTEST ENDOSC, V85, P194, DOI 10.1016/j.gie.2016.08.037
   Marya N, 2014, GASTROINTEST ENDOSC, V79, P669, DOI 10.1016/j.gie.2013.11.022
   Marya NB, 2019, GASTROINTEST ENDOSC, V89, P33, DOI 10.1016/j.gie.2018.06.016
   Mustafa BF, 2013, EXPERT REV GASTROENT, V7, P323, DOI [10.1586/egh.13.20, 10.1586/EGH.13.20]
   Niv Y, 2008, WORLD J GASTROENTERO, V14, P1313, DOI 10.3748/wjg.14.1313
   Pasha SF, 2020, INFLAMM BOWEL DIS, V26, P33, DOI 10.1093/ibd/izz083
   Pioche M, 2011, GASTROINTEST ENDOSC, V73, P1181, DOI 10.1016/j.gie.2011.02.011
   Postgate AJ, 2009, ENDOSCOPY, V41, P1001, DOI 10.1055/s-0029-1215175
   Rokkas T, 2009, AM J GASTROENTEROL, V104, P219, DOI 10.1038/ajg.2008.63
   Rosa BJF, 2013, WORLD J GASTRO ENDOS, V5, P67, DOI 10.4253/wjge.v5.i2.67
   Schulmann K, 2005, AM J GASTROENTEROL, V100, P27, DOI 10.1111/j.1572-0241.2005.40102.x
   Shin JK, 2011, J GASTROEN HEPATOL, V26, P901, DOI 10.1111/j.1440-1746.2010.06577.x
   Singh A, 2013, GASTROINTEST ENDOSC, V77, P761, DOI 10.1016/j.gie.2012.11.041
   Song HJ, 2017, GUT LIVER, V11, P253, DOI 10.5009/gnl16231
   Spada C, 2008, WORLD J GASTROENTERO, V14, P4146, DOI 10.3748/wjg.14.4146
   Sung JJY, 2016, GASTROINTEST ENDOSC, V84, P907, DOI 10.1016/j.gie.2016.04.043
   Vlachogiannakos J, 2011, DIGEST DIS SCI, V56, P1763, DOI 10.1007/s10620-011-1592-3
   Xia Y, 2016, 2016 IEEE C EL FIELD
   Yamada A, 2012, HEPATO-GASTROENTEROL, V59, P676, DOI 10.5754/hge12180
   Zwinger LL, 2019, J CLIN GASTROENTEROL, V53, pE101, DOI 10.1097/MCG.0000000000000994
NR 47
TC 16
Z9 19
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0163-2116
EI 1573-2568
J9 DIGEST DIS SCI
JI Dig. Dis. Sci.
PD NOV
PY 2019
VL 64
IS 11
BP 3040
EP 3047
DI 10.1007/s10620-019-05791-4
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA JL4EL
UT WOS:000495483700006
PM 31468267
DA 2023-04-20
ER

PT J
AU Ding, S
   Li, L
   Li, ZM
   Wang, H
   Zhang, YC
AF Ding, Shuai
   Li, Ling
   Li, Zhenmin
   Wang, Hao
   Zhang, Yanchun
TI Smart electronic gastroscope system using a cloud-edge collaborative
   framework
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
LA English
DT Article
DE Electronic gastroscope system; Lesion detection; Edge computing;
   Cloud-edge framework; Deep learning
ID NEURAL-NETWORK; BIG DATA; CANCER; ENDOSCOPY; DIAGNOSIS; TRENDS;
   INTERNET; THINGS
AB Computer-aided gastroscopic image analysis is capable of reducing the work intensity of gastroscopists, and it is of great significance for improving the sensitivity and specificity of upper gastrointestinal disease screening. However, most computer-aided gastroscope systems provide intelligent image analysis services that rely on public cloud platforms and suffer from high communication and computing costs. Moreover, these systems are normally unavailable for offline clinical practice. In this study, we propose a smart electronic gastroscope system based on a cloud-edge collaborative framework. In this system, edge computing platforms and cloud platforms work collaboratively to achieve real-time lesion localization and fine-grained disease classification of gastroscopic videos. In addition, we propose a novel approach called cloud-edge collaborative dynamic lesion detection for upper gastrointestinal disease inference. First, to assist real-time lesion detection in the offline mode or discover a suspicious frame in the online mode, we develop a Tinier-YOLO algorithm based on the k-DSC module in edge computing platforms. Second, to further improve the modeling performance, we integrate lesion ROI segmentation strategy into the YOLOv3 algorithm in the cloud platform. By testing clinical data, we prove that our approach exhibits superior performance in mAP and IOU of lesion detection and response time of service. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Ding, Shuai; Li, Ling; Wang, Hao] Hefei Univ Technol, Sch Management, Hefei, Anhui, Peoples R China.
   [Ding, Shuai; Li, Ling; Wang, Hao] Hefei Univ Technol, Minist Educ, Key Lab Proc Optimizat & Intelligent Decis Making, Hefei, Anhui, Peoples R China.
   [Li, Zhenmin] Hefei Univ Technol, Sch Microelectron, Hefei, Anhui, Peoples R China.
   [Zhang, Yanchun] Victoria Univ, Ctr Appl Informat, Melbourne, Vic, Australia.
   [Zhang, Yanchun] Zhejiang Lab, Hangzhou, Zhejiang, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology; Hefei
   University of Technology; Victoria University; Zhejiang Laboratory
RP Ding, S (通讯作者)，Hefei Univ Technol, Sch Management, Hefei, Anhui, Peoples R China.
EM dingshuai@hfut.edu.cn; cynerelee@mail.hfut.edu.cn;
   zhenmin.li@hfut.edu.cn; waynehfut@mail.hfut.edu.cn;
   yunchun.zhang@vu.edu.au
FU National Natural Science Foundation of China [91846107, 71571058,
   71690235]; Anhui Provincial Science and Technology Major Project
   [17030801001, 18030801137]; Fundamental Research Funds for the Central
   Universities [PA2019GDQT0021]
FX This work is fully supported by the National Natural Science Foundation
   of China [Nos. 91846107, 71571058, and 71690235], Anhui Provincial
   Science and Technology Major Project [Nos. 17030801001, and
   18030801137], and the Fundamental Research Funds for the Central
   Universities [No. PA2019GDQT0021].
CR Abdulhay E, 2018, FUTURE GENER COMP SY, V83, P366, DOI 10.1016/j.future.2018.02.009
   Adame T, 2018, FUTURE GENER COMP SY, V78, P602, DOI 10.1016/j.future.2016.12.023
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Charisis VS, 2016, HEALTHC TECHNOL LETT, V3, P27, DOI 10.1049/htl.2015.0055
   Chen HH, 2017, NEUROCOMPUTING, V229, P77, DOI 10.1016/j.neucom.2016.06.077
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Din S, 2019, FUTURE GENER COMP SY, V91, P611, DOI 10.1016/j.future.2017.12.059
   Gu L, 2017, IEEE T EMERG TOP COM, V5, P108, DOI 10.1109/TETC.2015.2508382
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y., 2018, DIAGNOSTIC OUTCOMES, DOI [10.1016/J.GIE.2018.07.037, DOI 10.1016/J.GIE.2018.07.037]
   Howard A. G., 2017, ARXIV170404861
   Huang CR, 2016, IEEE T BIO-MED ENG, V63, P588, DOI 10.1109/TBME.2015.2466460
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Ishihara K, 2017, IEEE IMAGE PROC, P2055
   Jiang YM, 2017, JAMA SURG, V152, DOI 10.1001/jamasurg.2017.1087
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kang LN, 2014, CANC CONTROL, V2014, P131, DOI DOI 10.1016/S0039-6109(15)00125-11
   Kobusinska A, 2018, FUTURE GENER COMP SY, V87, P416, DOI 10.1016/j.future.2018.05.021
   Koh JEW, 2019, FUTURE GENER COMP SY, V90, P86, DOI 10.1016/j.future.2018.07.044
   Lagergren J, 2017, LANCET, V390, P2383, DOI 10.1016/S0140-6736(17)31462-9
   Li YX, 2018, I S BIOMED IMAGING, P182
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu C, 2018, IEEE T SERV COMPUT, V11, P249, DOI 10.1109/TSC.2017.2662008
   Liu JQ, 2015, IEEE T BIO-MED ENG, V62, P2296, DOI 10.1109/TBME.2015.2424438
   Liu Y, 2018, CANCER CELL, V33, P721, DOI 10.1016/j.ccell.2018.03.010
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Mohammed MA, 2018, FUTURE GENER COMP SY, V89, P539, DOI 10.1016/j.future.2018.07.022
   Ning ZY, 2019, IEEE J BIOMED HEALTH, V23, P1181, DOI 10.1109/JBHI.2018.2841992
   Olaniyan R, 2018, FUTURE GENER COMP SY, V89, P633, DOI 10.1016/j.future.2018.07.040
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014
   Redmon J, 2018, Arxiv
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Torre LA, 2016, CANCER EPIDEM BIOMAR, V25, P16, DOI 10.1158/1055-9965.EPI-15-0578
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Varghese B, 2018, FUTURE GENER COMP SY, V79, P849, DOI 10.1016/j.future.2017.09.020
   Veitch AM, 2015, NAT REV GASTRO HEPAT, V12, P660, DOI 10.1038/nrgastro.2015.128
   Wang H, 2019, INT J PROD RES, V57, P6795, DOI 10.1080/00207543.2018.1464232
   Wang YT, 2014, IEEE T IMAGE PROCESS, V23, P4838, DOI 10.1109/TIP.2014.2358880
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Xie LL, 2018, IEEE T INTELL TRANSP, V19, P507, DOI 10.1109/TITS.2017.2784093
   Xue QK, 2016, PROC IEEE MICR ELECT, P1, DOI 10.1109/MEMSYS.2016.7421541
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   Zahran EHM, 2016, APPL MATH MODEL, V40, P1769, DOI 10.1016/j.apm.2015.08.018
   Zhuang Y, 2014, INFORM SCIENCES, V263, P60, DOI 10.1016/j.ins.2013.10.013
NR 49
TC 19
Z9 21
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-739X
EI 1872-7115
J9 FUTURE GENER COMP SY
JI Futur. Gener. Comp. Syst.
PD NOV
PY 2019
VL 100
BP 395
EP 407
DI 10.1016/j.future.2019.04.031
PG 13
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JX6FD
UT WOS:000503827500030
DA 2023-04-20
ER

PT J
AU Iakovidis, DK
   Dimas, G
   Karargyris, A
   Bianchi, F
   Ciuti, G
   Koulaouzidis, A
AF Iakovidis, Dimitris K.
   Dimas, George
   Karargyris, Alexandros
   Bianchi, Federico
   Ciuti, Gastone
   Koulaouzidis, Anastasios
TI Deep Endoscopic Visual Measurements
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Biomedical measurement; Cameras; Endoscopes; Size measurement;
   Visualization; Lesions; Robots; Endoscopy; neural networks; deep
   learning; deep matching; measurements
ID WIRELESS CAPSULE ENDOSCOPE; TARGETED DRUG-DELIVERY; CALIBRATION; VISION;
   SIZE; LOCALIZATION; LOCOMOTION
AB Robotic endoscopic systems offer a minimally invasive approach to the examination of internal body structures, and their application is rapidly extending to cover the increasing needs for accurate therapeutic interventions. In this context, it is essential for such systems to be able to perform measurements, such as measuring the distance traveled by a wireless capsule endoscope, so as to determine the location of a lesion in the gastrointestinal tract, or to measure the size of lesions for diagnostic purposes. In this paper, we investigate the feasibility of performing contactless measurements using a computer vision approach based on neural networks. The proposed system integrates a deep convolutional image registration approach and a multilayer feed-forward neural network into a novel architecture. The main advantage of this system, with respect to the state-of-the-art ones, is that it is more generic in the sense that it is 1) unconstrained by specific models, 2) more robust to nonrigid deformations, and 3) adaptable to most of the endoscopic systems and environment, while enabling measurements of enhanced accuracy. The performance of this system is evaluated under ex vivo conditions using a phantom experimental model and a robotically assisted test bench. The results obtained promise a wider applicability and impact in endoscopy in the era of big data.
C1 [Iakovidis, Dimitris K.; Dimas, George] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia 35131, Greece.
   [Karargyris, Alexandros] IBM Res, San Jose, CA 95120 USA.
   [Bianchi, Federico; Ciuti, Gastone] Scuola Super Sant Anna, BioRobot Inst, I-56127 Pisa, Italy.
   [Koulaouzidis, Anastasios] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh EH16 4SA, Midlothian, Scotland.
C3 International Business Machines (IBM); Scuola Superiore Sant'Anna; Royal
   Infirmary of Edinburgh; University of Edinburgh
RP Iakovidis, DK (通讯作者)，Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia 35131, Greece.
EM diakovidis@uth.gr; gdimas@uth.gr; akarargyris@gmail.com;
   federico.bianchi@santannapisa.it; gastone.ciuti@santannapisa.it;
   akoulaouzidis@hotmail.com
RI Koulaouzidis, Anastasios/G-9060-2014; Ciuti, Gastone/T-6377-2018
OI Koulaouzidis, Anastasios/0000-0002-2248-489X; Ciuti,
   Gastone/0000-0002-0855-7976; Iakovidis, Dimitris/0000-0002-5027-5323;
   Karargyris, Alexandros/0000-0002-1930-3410
FU European Commission (EU) [688592, H2020-ICT-24-2015]
FX This work was partially supported by the European Commission within the
   framework of the "Endoscopic versatile robotic guidance, diagnosis and
   therapy of magnetic driven soft-tethered endoluminal robots" Project,
   H2020-ICT-24-2015 (EU Project-G.A. number: 688592).
CR Ahmed M. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P463, DOI 10.1109/ICCV.1999.791257
   Bao GQ, 2014, IEEE ENG MED BIO, P5615, DOI 10.1109/EMBC.2014.6944900
   Besdok E, 2009, SENSORS-BASEL, V9, P4572, DOI 10.3390/s90604572
   Bouguet J.-Y., CAMERA CALIBRATION T
   Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49
   Ciuti G, 2012, SENSOR ACTUAT A-PHYS, V186, P270, DOI 10.1016/j.sna.2011.12.024
   Ciuti G, 2016, J MICRO-BIO ROBOT, V11, P1, DOI 10.1007/s12213-016-0087-x
   Ciuti G, 2010, ROBOTICA, V28, P199, DOI 10.1017/S0263574709990361
   Craine BL, 1998, IEEE T MED IMAGING, V17, P1003, DOI 10.1109/42.746633
   Dimas G, 2017, COMP MED SY, P734, DOI 10.1109/CBMS.2017.67
   Dimas G, 2017, COMPUT BIOL MED, V89, P429, DOI 10.1016/j.compbiomed.2017.08.029
   Dimas G, 2017, MEAS SCI TECHNOL, V28, DOI 10.1088/1361-6501/aa7ebf
   Figueiredo IN, 2018, BIOMED SIGNAL PROCES, V39, P486, DOI 10.1016/j.bspc.2017.08.019
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Goldstein O, 2018, GUT, V67, P1755, DOI 10.1136/gutjnl-2017-314829
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   HORNIK K, 1990, NEURAL NETWORKS, V3, P551, DOI 10.1016/0893-6080(90)90005-6
   Hu C, 2004, IEEE INT CONF ROBOT, P4718
   Iakovidis D.K., 2013, P 13 IEEE INT C BIOI, P1
   Iakovidis D.K., 2014, IEEE INT C IM SYST T, P95
   Iakovidis DK, 2016, IEEE CONF IMAGING SY, P83, DOI 10.1109/IST.2016.7738202
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153
   Karargyris A, 2015, IEEE T BIO-MED ENG, V62, P352, DOI 10.1109/TBME.2014.2352493
   Koulaouzidis A, 2015, WORLD J GASTROENTERO, V21, P5119, DOI 10.3748/wjg.v21.i17.5119
   Mahmood F., 2018, P MED IM IM PROC, V10574
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   McKinlay R, 2004, SURG ENDOSC, V18, P709, DOI 10.1007/s00464-003-8818-1
   Memon Q, 2001, INT J SYST SCI, V32, P1155, DOI 10.1080/00207720010024276
   Mi L, 2014, PROC SPIE, V9036, DOI 10.1117/12.2043963
   Nadeem S., 2016, P SOC PHOTO-OPT INS, V9785
   Park H, 2017, SURG ENDOSC, V31, P4824, DOI 10.1007/s00464-017-5560-7
   Quirini M, 2008, GASTROINTEST ENDOSC, V67, P1153, DOI 10.1016/j.gie.2007.11.052
   Revaud J, 2016, INT J COMPUT VISION, V120, P300, DOI 10.1007/s11263-016-0908-3
   Schoen RE, 1997, GASTROINTEST ENDOSC, V46, P492, DOI 10.1016/S0016-5107(97)70002-6
   Simonovsky Martin, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9902, P10, DOI 10.1007/978-3-319-46726-9_2
   Singh AV, 2016, CURR PHARM DESIGN, V22, P1418, DOI 10.2174/1381612822666151210124326
   Sliker LJ, 2014, EXPERT REV MED DEVIC, V11, P649, DOI 10.1586/17434440.2014.941809
   Spyrou E, 2015, COMPUT BIOL MED, V65, P297, DOI 10.1016/j.compbiomed.2015.05.013
   Spyrou E, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/1/015002
   VAKIL N, 1994, GASTROINTEST ENDOSC, V40, P178, DOI 10.1016/S0016-5107(94)70163-6
   Visentini-Scarzanella M., 2015, P INT WORKSH COMP AS, P46
   Woods SP, 2013, IEEE T BIO-MED ENG, V60, P945, DOI 10.1109/TBME.2012.2228647
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
NR 47
TC 18
Z9 18
U1 1
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD NOV
PY 2019
VL 23
IS 6
BP 2211
EP 2219
DI 10.1109/JBHI.2018.2853987
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA JP9KQ
UT WOS:000498576400002
PM 29994623
DA 2023-04-20
ER

PT J
AU Kakkava, E
   Rahmani, B
   Borhani, N
   Tegin, U
   Loterie, D
   Konstantinou, G
   Moser, C
   Psaltis, D
AF Kakkava, Eirini
   Rahmani, Babak
   Borhani, Navid
   Tegin, Ugur
   Loterie, Damien
   Konstantinou, Georgia
   Moser, Christophe
   Psaltis, Demetri
TI Imaging through multimode fibers using deep learning: The effects of
   intensity versus holographic recording of the speckle pattern
SO OPTICAL FIBER TECHNOLOGY
LA English
DT Article
ID 3-DIMENSIONAL MICROFABRICATION; CONFOCAL MICROSCOPY; HIGH-RESOLUTION;
   TRANSMISSION; COMPENSATION; MATRIX; IMAGES; LIGHT; POWER
AB Information transmission through multimode fibers (MMFs) has been a topic of great interest for many years. Deep learning algorithms have been applied successfully to MMFs in particular to fiber endoscopy. In this work, we show how Deep Neural Networks (DNNs) can be a versatile technique for classification and recovery of input images that have been significantly distorted while propagating along the MMF forming a speckle pattern. A comparison between holographic and intensity-only recording of the speckle output, which is used as an input to the DNNs, shows that high performance can be achieved without having the full field information (amplitude and phase). Impressive reconstruction fidelity and classification accuracy of the fiber inputs from the intensity-only images of the speckle patterns is reported.
C1 [Kakkava, Eirini; Borhani, Navid; Tegin, Ugur; Psaltis, Demetri] Ecole Polytech Fed Lausanne, Opt Lab, CH-1015 Lausanne, Switzerland.
   [Rahmani, Babak; Tegin, Ugur; Loterie, Damien; Konstantinou, Georgia; Moser, Christophe] Ecole Polytech Fed Lausanne, Lab Appl Photon Devices, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Swiss Federal Institutes of Technology Domain;
   Ecole Polytechnique Federale de Lausanne
RP Kakkava, E (通讯作者)，Ecole Polytech Fed Lausanne, Opt Lab, CH-1015 Lausanne, Switzerland.
EM eirini.kakkava@epfl.ch
RI Moser, Christophe/ABF-3174-2020; Tegin, Ugur/AAQ-2543-2021; Borhani,
   Navid/A-7945-2015
OI Moser, Christophe/0000-0002-2078-0273; Tegin, Ugur/0000-0002-4690-588X;
   Rahmani, Babak/0000-0002-0856-9635; Borhani, Navid/0000-0002-0663-8625
CR Andresen ER, 2013, OPT EXPRESS, V21, P20713, DOI 10.1364/OE.21.020713
   Andresen ER, 2013, OPT LETT, V38, P609, DOI 10.1364/OL.38.000609
   Bianchi S, 2012, LAB CHIP, V12, P635, DOI 10.1039/c1lc20719a
   Borhani N, 2018, OPTICA, V5, P960, DOI 10.1364/OPTICA.5.000960
   Caravaca-Aguirre AM, 2013, OPT EXPRESS, V21, P12881, DOI 10.1364/OE.21.012881
   Carpenter J, 2014, OPT EXPRESS, V22, P96, DOI 10.1364/OE.22.000096
   Choi Y, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.203901
   Cizmar T, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms2024
   Conkey DB, 2017, OPT EXPRESS, V25, P11491, DOI 10.1364/OE.25.011491
   Conkey DB, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.4.045002
   Cuche E, 1999, OPT LETT, V24, P291, DOI 10.1364/OL.24.000291
   Defienne H, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1501054
   Delrot P, 2018, OPT EXPRESS, V26, P1766, DOI 10.1364/OE.26.001766
   Di Leonardo R, 2011, OPT EXPRESS, V19, P247, DOI 10.1364/OE.19.000247
   Dremeau A, 2015, OPT EXPRESS, V23, P11898, DOI 10.1364/OE.23.011898
   Fan P., 2018, ARXIV181202814PHYSIC
   Farahi S, 2013, OPT EXPRESS, V21, P22504, DOI 10.1364/OE.21.022504
   FRIESEM AA, 1983, P IEEE, V71, P208, DOI 10.1109/PROC.1983.12560
   GARIBYAN OV, 1981, OPT COMMUN, V38, P67, DOI 10.1016/0030-4018(81)90309-6
   Goodman J. W., 2005, ROBERTS CO PUBLISHER, V3
   GOVER A, 1976, J OPT SOC AM, V66, P306, DOI 10.1364/JOSA.66.000306
   Gu RY, 2015, OPT EXPRESS, V23, P26905, DOI 10.1364/OE.23.026905
   Kakkava E., 2019, HIGH SPEED BIOMEDICA, P46
   Kakkava E, 2019, BIOMED OPT EXPRESS, V10, P423, DOI 10.1364/BOE.10.000423
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Kuschmierz R, 2018, OPT LETT, V43, P2997, DOI 10.1364/OL.43.002997
   Lan MY, 2019, OPT EXPRESS, V27, P12957, DOI 10.1364/OE.27.012957
   Lin YC, 2011, APPL OPTICS, V50, pB25, DOI 10.1364/AO.50.000B25
   Loterie D, 2017, OPT EXPRESS, V25, P6263, DOI 10.1364/OE.25.006263
   Loterie D, 2015, OPT LETT, V40, P5754, DOI 10.1364/OL.40.005754
   Loterie D, 2015, OPT EXPRESS, V23, P23845, DOI 10.1364/OE.23.023845
   Mann CJ, 2005, OPT EXPRESS, V13, P8693, DOI 10.1364/OPEX.13.008693
   Morales-Delgado EE, 2017, OPT EXPRESS, V25, P7031, DOI 10.1364/OE.25.007031
   Morales-Delgado EE, 2015, OPT EXPRESS, V23, P9109, DOI 10.1364/OE.23.009109
   Ohayon S, 2018, BIOMED OPT EXPRESS, V9, P1492, DOI 10.1364/BOE.9.001492
   Papadopoulos IN, 2013, BIOMED OPT EXPRESS, V4, P260, DOI 10.1364/BOE.4.000260
   Papadopoulos IN, 2012, OPT EXPRESS, V20, P10583, DOI 10.1364/OE.20.010583
   Ploschner M, 2015, NAT PHOTONICS, V9, P529, DOI [10.1038/nphoton.2015.112, 10.1038/NPHOTON.2015.112]
   Popoff SM, 2011, NEW J PHYS, V13, DOI 10.1088/1367-2630/13/12/123021
   Rahmani B, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0074-1
   Shabairou N, 2018, OPT LETT, V43, P5603, DOI 10.1364/OL.43.005603
   Simonyan K., 2014, ARXIV PREPRINT ARXIV
   Sivankutty S, 2016, OPT EXPRESS, V24, P825, DOI 10.1364/OE.24.000825
   Son JY, 1996, APPL OPTICS, V35, P273, DOI 10.1364/AO.35.000273
   Turtaev S, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0094-x
   Wertz, 1967, CR HEBD ACAD SCI, V264, P1015
   Xiong W, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.053901
   Yamaguchi I, 1997, OPT LETT, V22, P1268, DOI 10.1364/OL.22.001268
   YARIV A, 1978, APPL PHYS LETT, V32, P635, DOI 10.1063/1.89876
   Zhao J, 2018, ACS PHOTONICS, V5, P3930, DOI 10.1021/acsphotonics.8b00832
NR 50
TC 32
Z9 33
U1 10
U2 55
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1068-5200
EI 1095-9912
J9 OPT FIBER TECHNOL
JI Opt. Fiber Technol.
PD NOV
PY 2019
VL 52
AR 101985
DI 10.1016/j.yofte.2019.101985
PG 7
WC Engineering, Electrical & Electronic; Optics; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Telecommunications
GA JF2SZ
UT WOS:000491237100027
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Kim, DH
   Cho, H
   Cho, HC
AF Kim, Dong-hyun
   Cho, HyunChin
   Cho, Hyun-chong
TI Gastric Lesion Classification Using Deep Learning Based on Fast and
   Robust Fuzzy C-Means and Simple Linear Iterative Clustering Superpixel
   Algorithms
SO JOURNAL OF ELECTRICAL ENGINEERING & TECHNOLOGY
LA English
DT Article
DE Gastric disease; Computer aided diagnosis; CADx; Endoscopy; Deep
   learning; Inception module
ID COMPUTER-AIDED DIAGNOSIS; ENDOSCOPY
AB Gastric diseases are a common medical issue; they can be detected using endoscopy equipment. Computer-aided diagnosis (CADx) systems can help internists identify gastric diseases more accurately. In this paper, we present a CADx system that can detect and classify gastric diseases such as gastric polyps, gastric ulcers, gastritis, and cancer. The system uses a deep learning model as a GoogLeNet based on an Inception module. The fast and robust fuzzy C-means (FRFCM) and simple linear iterative clustering (SLIC) superpixel algorithms are applied for image segmentation during preprocessing. The FRFCM algorithm, which is based on morphological reconstruction and membership filtering, is much faster and more robust than fuzzy C-means. In addition, the SLIC superpixel algorithm adapts the k-means clustering method to efficiently generate superpixels. These two approaches produce a feasible method of classifying normal and abnormal gastric lesions. The areas under the receiver operating characteristic curves were 0.85 and 0.87 for normal and abnormal lesions, respectively. The proposed CADx system also performs reliably.
C1 [Cho, Hyun-chong] Kangwon Natl Univ, Dept Elect Engn, Chuncheon Si, South Korea.
   [Kim, Dong-hyun; Cho, Hyun-chong] Kangwon Natl Univ, Interdisciplinary Grad Program BIT Med Convergenc, Chuncheon Si, South Korea.
   [Cho, HyunChin] Gyeongsang Natl Univ, Dept Internal Med, Sch Med, Jinju Si, South Korea.
   [Cho, HyunChin] Gyeongsang Natl Univ, Inst Hlth Sci, Sch Med, Jinju Si, South Korea.
   [Cho, HyunChin] Gyeongsang Natl Univ Hosp, Jinju Si, South Korea.
C3 Kangwon National University; Kangwon National University; Gyeongsang
   National University; Gyeongsang National University; Gyeongsang National
   University; Gyeongsang National University Hospital
RP Cho, HC (通讯作者)，Kangwon Natl Univ, Dept Elect Engn, Chuncheon Si, South Korea.; Cho, HC (通讯作者)，Kangwon Natl Univ, Interdisciplinary Grad Program BIT Med Convergenc, Chuncheon Si, South Korea.
EM wlflqna@gmail.com; hccholuck@gmail.com; hyuncho@kangwon.ac.kr
RI Kim, Dong-Hyun/AAH-3043-2020
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2017R1E1A1A03070297]; MSIT (Ministry of Science and ICT), Korea, under
   the ITRC (Information Technology Research Center) support program
   [IITP-2019-2018-0-01433]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2017R1E1A1A03070297). This research was supported by the MSIT (Ministry
   of Science and ICT), Korea, under the ITRC (Information Technology
   Research Center) support program (IITP-2019-2018-0-01433) supervised by
   the IITP (Institute for Information & communications Technology
   Promotion).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bray F, 2019, CA CANC J CLIN, V2018
   Choi Il Ju, 2018, Korean J Gastroenterol, V72, P245, DOI 10.4166/kjg.2018.72.5.245
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   DONGHYUN KIM, 2018, 전기학회논문지, V67, P928
   Kim YI., 1992, KOR J GASTROENTEROL, V24, P216
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Lee TC, 2013, IEEE ENG MED BIO, P4430, DOI 10.1109/EMBC.2013.6610529
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Ministry of Health and Welfare Korea National Cancer Center, 2019, NAT CANC REG STAT 20
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
NR 14
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER SINGAPORE PTE LTD
PI SINGAPORE
PA #04-01 CENCON I, 1 TANNERY RD, SINGAPORE 347719, SINGAPORE
SN 1975-0102
EI 2093-7423
J9 J ELECTR ENG TECHNOL
JI J. Electr. Eng. Technol.
PD NOV
PY 2019
VL 14
IS 6
BP 2549
EP 2556
DI 10.1007/s42835-019-00259-x
PG 8
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA JV1TL
UT WOS:000502151600032
DA 2023-04-20
ER

PT J
AU Lee, JH
   Kim, YJ
   Kim, YW
   Park, S
   Choi, YI
   Kim, YJ
   Park, DK
   Kim, KG
   Chung, JW
AF Lee, Jang Hyung
   Kim, Young Jae
   Kim, Yoon Woo
   Park, Sungjin
   Choi, Youn-i
   Kim, Yoon Jae
   Park, Dong Kyun
   Kim, Kwang Gi
   Chung, Jun-Won
TI Spotting malignancies from gastric endoscopic images using deep learning
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
LA English
DT Article
DE Gastrointestinal malignancy; Endoscopy; Ulcer; Cancer; Deep learning;
   Neural network; ResNet
ID DIAGNOSIS; CANCER
AB Background Gastric cancer is a common kind of malignancies, with yearly occurrences exceeding one million worldwide in 2017. Typically, ulcerous and cancerous tissues develop abnormal morphologies through courses of progression. Endoscopy is a routinely adopted means for examination of gastrointestinal tract for malignancy. Early and timely detection of malignancy closely correlate with good prognosis. Repeated presentation of similar frames from gastrointestinal tract endoscopy often weakens attention for practitioners to result in true patients missed out to incur higher medical cost and unnecessary morbidity. Highly needed is an automatic means for spotting visual abnormality and prompts for attention for medical staff for more thorough examination. Methods We conduct classification of benign ulcer and cancer for gastrointestinal endoscopic color images using deep neural network and transfer-learning approach. Using clinical data gathered from Gil Hospital, we built a dataset comprised of 200 normal, 367 cancer, and 220 ulcer cases, and applied the inception, ResNet, and VGGNet models pretrained on ImageNet. Three classes were defined-normal, benign ulcer, and cancer, and three separate binary classifiers were built-those for normal vs cancer, normal vs ulcer, and cancer vs ulcer for the corresponding classification tasks. For each task, considering inherent randomness entailed in the deep learning process, we performed data partitioning and model building experiments 100 times and averaged the performance values. Results Areas under curves of respective receiver operating characteristics were 0.95, 0.97, and 0.85 for the three classifiers. The ResNet showed the highest level of performance. The cases involving normal, i.e., normal vs ulcer and normal vs cancer resulted in accuracies above 90%. The case of ulcer vs cancer classification resulted in a lower accuracy of 77.1%, possibly due to smaller difference in appearance than those cases involving normal. Conclusions The overall level of performance of the proposed method was very promising to encourage applications in clinical environments. Automatic classification using deep learning technique as proposed can be used to complement manual inspection efforts for practitioners to minimize dangers of missed out positives resulting from repetitive sequence of endoscopic frames and weakening attentions.
C1 [Lee, Jang Hyung; Kim, Young Jae; Kim, Yoon Woo; Park, Sungjin; Kim, Kwang Gi] Gachon Univ, Coll Med, Dept Biomed Engn, 38 3 Dockjeomro, Incheon 21565, South Korea.
   [Choi, Youn-i; Kim, Yoon Jae; Park, Dong Kyun; Chung, Jun-Won] Gachon Univ, Gachon Gil Hosp, Coll Med, Dept Gastroenterol, Incheon, South Korea.
   [Chung, Jun-Won] Gachon Univ, Gil Med Ctr, Sch Med, Dept Gastroenterol, 38 3 Dockjeomro, Incheon 21565, South Korea.
C3 Gachon University; Gachon University; Gachon University
RP Kim, KG (通讯作者)，Gachon Univ, Coll Med, Dept Biomed Engn, 38 3 Dockjeomro, Incheon 21565, South Korea.; Chung, JW (通讯作者)，Gachon Univ, Gachon Gil Hosp, Coll Med, Dept Gastroenterol, Incheon, South Korea.; Chung, JW (通讯作者)，Gachon Univ, Gil Med Ctr, Sch Med, Dept Gastroenterol, 38 3 Dockjeomro, Incheon 21565, South Korea.
EM kimkg@gachon.ac.kr; junwonchung@hanmail.net
RI kim, kwanggi/D-6890-2012
OI kim, kwanggi/0000-0001-9714-6038; Choi, Youn I/0000-0001-6561-6752
FU Institute for Information & communications Technology Promotion (IITP) -
   Korea government (MSIT) [2018-2-00861]; Gachon University Gil Medical
   Center [2018-5283]
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIT)
   (2018-2-00861, Intelligent SW Technology Development for Medical Data
   Analysis) and the Gachon University Gil Medical Center (Grant No:
   2018-5283). Authors Kim KG and Chung JW equally contributed to this
   work.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Almadi MA, 2015, CAN J GASTROENTEROL, V29, P304, DOI 10.1155/2015/789038
   [Anonymous], 2014, WORLD CANC REPORT
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Clements LM, 2017, J TRANSP RES BOARD, V2606, P2606
   Dauphin Gregoire Mesnil Yann, 2012, JMLR P TRACK, P97
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gerhardus D, 2003, J HEALTHC MANAG, V48, P242, DOI 10.1097/00115514-200307000-00008
   He K., 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46493-0_38
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Maroulis DE, 2005, P 18 IEEE S COMP MED
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Paszke A., 2016, ANAL DEEP NEURAL NET, DOI DOI 10.1002/(SICI)1520-6416(199906)127:439::AID-EEJ53.0.CO;2-8
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2015, IEEE 12 INT S BIOM I
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zhu R, 2015, 2015 8 INT C IM SIGN
   Zuiderveld K., 1994, GRAPHICS GEMS
NR 27
TC 51
Z9 56
U1 4
U2 22
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0930-2794
EI 1432-2218
J9 SURG ENDOSC
JI Surg. Endosc.
PD NOV
PY 2019
VL 33
IS 11
BP 3790
EP 3797
DI 10.1007/s00464-019-06677-2
PG 8
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA JE3OQ
UT WOS:000490605100031
PM 30719560
DA 2023-04-20
ER

PT J
AU Li, XG
   Tiong, AMH
   Cao, L
   Lai, WJ
   Phan, PT
   Phee, SJ
AF Li, Xiaoguo
   Tiong, Anthony Meng Huat
   Cao, Lin
   Lai, Wenjie
   Phuoc Thien Phan
   Phee, Soo Jay
TI Deep learning for haptic feedback of flexible endoscopic robot without
   prior knowledge on sheath configuration
SO INTERNATIONAL JOURNAL OF MECHANICAL SCIENCES
LA English
DT Article
DE Flexible endoscopic surgical robots; Tendon-sheath mechanisms; Haptic
   Force Feedback; Force Hysteresis; Deep Learning
ID MINIMALLY INVASIVE SURGERY; NEURAL-NETWORK; DISTAL-END; FORCE; MODEL;
   PREDICTION; SYSTEM; EMG
AB Distal-end force information is usually missing in flexible endoscopic robots due to the difficulties of mounting miniature force sensors on their end-effectors. This hurdle creates big challenges in providing a sense of touch for the operating surgeons. Many existing studies have developed models to calculate the distal-end forces based on the measured proximal-end forces of Tendon-Sheath Mechanisms (TSMs), but these models assume known sheath bending configuration which is unknown during real-life surgeries. This paper presents a two-stage data-driven method that makes dynamic distal-end force prediction of a flexible endoscopic robot without this assumption. In stage one, a convolutional neural network is used to estimate the sheath cumulative bending angle based on the proximal-end force responses of the robot to a probing signal; in stage two, a combination of two long-short-term-memory models pre-trained for the bending angles nearest to the estimated angle (obtained in stage one) makes dynamic estimations of the distal-end force of the robot. The proposed approach overcomes the challenges due to unknown TSM configurations and can robustly identify the correct force hysteresis phases of TSMs. The force prediction is continuous, accurate, and has a mean RMSE of 0.1711 N. This method was validated on an actual flexible surgical robot. In addition, since the proposed approach provides an estimation of the current system cumulative bending angle, it can also be used:to facilitate the mathematical modeling methods which require information on the cumulative bending angle.
C1 [Li, Xiaoguo; Tiong, Anthony Meng Huat; Cao, Lin; Lai, Wenjie; Phuoc Thien Phan; Phee, Soo Jay] Nanyang Technol Univ, Robot Res Ctr, Sch Mech & Aerosp Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University
RP Cao, L (通讯作者)，Nanyang Technol Univ, Robot Res Ctr, Sch Mech & Aerosp Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM lin.cao@ntu.edu.sg
RI Lai, Wenjie/S-1460-2019
OI Lai, Wenjie/0000-0002-6020-107X; CAO, LIN/0000-0003-4769-775X
FU National Research Foundation (NRF) Singapore [NRFI2016-07]
FX This research is supported by the National Research Foundation (NRF)
   Singapore (NRFI2016-07).
CR Agrawal V, 2008, IEEE INT CONF ROBOT, P3407, DOI 10.1109/ROBOT.2008.4543731
   Bai FJ, 2013, IEEE ENG MED BIO, P4589, DOI 10.1109/EMBC.2013.6610569
   Cao L, 2019, IEEE INT CONF ROBOT, P1514, DOI 10.1109/ICRA.2019.8794247
   Do TN, 2015, MECH SYST SIGNAL PR, V60-61, P770, DOI 10.1016/j.ymssp.2015.01.001
   Do TN, 2015, MECH MACH THEORY, V85, P14, DOI 10.1016/j.mechmachtheory.2014.11.003
   Do TN, 2014, MECHATRONICS, V24, P12, DOI 10.1016/j.mechatronics.2013.11.003
   Do TN, 2014, MECH SYST SIGNAL PR, V42, P97, DOI 10.1016/j.ymssp.2013.08.014
   Do T.N., 2013, NONLINEAR MODELING P
   ECKMANN JP, 1987, EUROPHYS LETT, V4, P973, DOI 10.1209/0295-5075/4/9/004
   Ehrampoosh S, 2013, COMPUT AIDED SURG, V18, P129, DOI 10.3109/10929088.2013.839744
   Fabretti A, 2005, INT J MOD PHYS C, V16, P671, DOI 10.1142/S0129183105007492
   Faria FA, 2016, PATTERN RECOGN LETT, V83, P205, DOI 10.1016/j.patrec.2016.03.005
   He W, 2019, IEEE T CONTR SYST T, V27, P790, DOI 10.1109/TCST.2017.2780055
   He W, 2018, IEEE T NEUR NET LEAR, V29, P1174, DOI 10.1109/TNNLS.2017.2665581
   He W, 2018, IEEE T NEUR NET LEAR, V29, P1539, DOI 10.1109/TNNLS.2017.2673865
   Heess N., 2015, MEMORY BASED CONTROL
   HILL KO, 1993, APPL PHYS LETT, V62, P1035, DOI 10.1063/1.108786
   Hinz T, 2018, INT J COMPUT INTELL, V17, DOI 10.1142/S1469026818500086
   HOWE RD, 1995, IEEE ENG MED BIOL, V14, P318, DOI 10.1109/51.391770
   Hu XH, 2019, IEEE-ASME T MECH, V24, P1785, DOI 10.1109/TMECH.2019.2928786
   Huu Minh Le, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1766, DOI 10.1109/ICRA.2017.7989209
   In H, 2015, IEEE INT CONF ROBOT, P1229, DOI 10.1109/ICRA.2015.7139348
   Irgolic T, 2014, PROCEDIA ENGINEER, V69, P804, DOI 10.1016/j.proeng.2014.03.057
   KANEKO M, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1028, DOI 10.1109/ROBOT.1991.131727
   Kassahun Y, 2016, INT J COMPUT ASS RAD, V11, P553, DOI 10.1007/s11548-015-1305-z
   Koebbe M., 1994, USE RECURRENCE PLOTS
   Krakovska A., 2015, J COMPLEX SYST, V2015, DOI 10.1155/2015/932750
   Lai XL, 2018, INT CONF CLOUD COMPU, P1, DOI 10.1109/CCIS.2018.8691395
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li XG, 2019, MECH MACH THEORY, V134, P323, DOI 10.1016/j.mechmachtheory.2018.12.035
   Liu MM, 1999, J ELECTROMYOGR KINES, V9, P391, DOI 10.1016/S1050-6411(99)00014-0
   Miyasaka M, 2019, IEEE INT CONF ROBOT, P9828, DOI 10.1109/ICRA.2019.8793937
   Okamura AM, 2009, CURR OPIN UROL, V19, P102, DOI 10.1097/MOU.0b013e32831a478c
   Palli G, 2006, IEEE INT CONF ROBOT, P988, DOI 10.1109/ROBOT.2006.1641838
   Palli G., 2006, P IFAC S ROB CONTR, V39, P73
   Palli G, 2012, IEEE T ROBOT, V28, P277, DOI 10.1109/TRO.2011.2171610
   Phee SJ, 2010, ROBOTICA, V28, P1073, DOI 10.1017/S026357470999083X
   Phee SJ, 2009, IEEE ENG MED BIO, P1192, DOI 10.1109/IEMBS.2009.5333413
   Phee SJ, 2012, CLIN GASTROENTEROL H, V10, P1117, DOI 10.1016/j.cgh.2012.05.019
   Reiley CE, 2010, IEEE ENG MED BIO, P967, DOI 10.1109/IEMBS.2010.5627594
   Ren F, 2018, IEEE PHOTONICS J, V10, P1
   Rodriguez P, 2018, IMAGE VISION COMPUT, V75, P21, DOI 10.1016/j.imavis.2018.04.004
   Rosen J, 1999, IEEE T BIO-MED ENG, V46, P1212, DOI 10.1109/10.790498
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Socher R, 2013, P 2013 C EMPIRICAL M, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sun ZL, 2015, COMPUT METH PROG BIO, V119, P77, DOI 10.1016/j.cmpb.2015.03.001
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173
   Tadano K, 2010, ADV ROBOTICS, V24, P1763, DOI 10.1163/016918610X522559
   Tholey G, 2004, LECT NOTES COMPUT SC, V3078, P38
   Valdastri P, 2006, IEEE T BIO-MED ENG, V53, P2397, DOI 10.1109/TBME.2006.883618
   Wang L, 2002, IEEE T NEUR SYS REH, V10, P30, DOI 10.1109/TNSRE.2002.1021584
   Wang Z, 2013, COMPUT METH PROG BIO, V112, P260, DOI 10.1016/j.cmpb.2013.01.018
   Xu W., 2016, DATA DRIVEN METHODS
   Zhai XL, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00379
   Zhao R, 2019, MECH SYST SIGNAL PR, V115, P213, DOI 10.1016/j.ymssp.2018.05.050
NR 55
TC 22
Z9 22
U1 7
U2 37
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0020-7403
EI 1879-2162
J9 INT J MECH SCI
JI Int. J. Mech. Sci.
PD NOV
PY 2019
VL 163
AR 105129
DI 10.1016/j.ijmecsci.2019.105129
PG 13
WC Engineering, Mechanical; Mechanics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Mechanics
GA JN4JT
UT WOS:000496866200029
DA 2023-04-20
ER

PT J
AU Soh, YSA
   Lee, YY
   Gotoda, T
   Sharma, P
   Ho, KY
AF Soh, Yu Sen Alex
   Lee, Yeong Yeh
   Gotoda, Takuji
   Sharma, Prateek
   Ho, Khek-Yu
CA Asian Barrett's Consortium
TI Challenges to diagnostic standardization of Barrett's esophagus in Asia
SO DIGESTIVE ENDOSCOPY
LA English
DT Review
DE Asia; Barrett's esophagus; columnar-lined esophagus; gastroesophageal
   junction; intestinal metaplasia
ID SPECIALIZED INTESTINAL METAPLASIA; COLUMNAR-LINED ESOPHAGUS; RESOLUTION
   MAGNIFICATION ENDOSCOPY; GASTROESOPHAGEAL-REFLUX DISEASE; HIGH-GRADE
   DYSPLASIA; IN-VIVO DIAGNOSIS; ACETIC-ACID; ESOPHAGOGASTRIC JUNCTION;
   RAMAN-SPECTROSCOPY; PRAGUE C
AB Barrett's esophagus (BE), a premalignant condition of the lower esophagus, is increasingly prevalent in Asia. However, endoscopic and histopathological criteria vary widely between studies across Asia, making it challenging to assess comparability between geographical regions. Furthermore, guidelines from various societies worldwide provide differing viewpoints and definitions, leading to diagnostic challenges that affect prognostication of the condition. In this review, the authors discuss the controversies surrounding the diagnosis of BE, particularly in Asia. Differences between guidelines worldwide are summarized with further discussion regarding various classifications of BE used, different definitions of gastroesophageal junction used across geographical regions and the clinical implications of intestinal metaplasia in the setting of BE. Although many guidelines recommend the Seattle protocol as the preferred approach regarding dysplasia surveillance in BE, some limitations exist, leading to poor adherence. Newer technologies, such as acetic acid-enhanced magnification endoscopy, narrow band imaging, Raman spectroscopy, molecular approaches and the use of artificial intelligence appear promising in addressing these problems, but further studies are required before implementation into routine clinical practice. The Asian Barrett's Consortium also outlines its ongoing plans to tackle the challenge of standardizing the diagnosis of BE in Asia.
C1 [Soh, Yu Sen Alex; Ho, Khek-Yu] Natl Univ Singapore Hosp, Dept Gastroenterol & Hepatol, Singapore, Singapore.
   [Soh, Yu Sen Alex; Ho, Khek-Yu] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Med, Singapore, Singapore.
   [Lee, Yeong Yeh] Univ Sains Malaysia, Sch Med Sci, Kota Baharu, Kelantan, Malaysia.
   [Gotoda, Takuji] Nihon Univ, Sch Med, Dept Med, Div Gastroenterol & Hepatol, Tokyo, Japan.
   [Sharma, Prateek] Univ Kansas, Vet Affairs Med Ctr, Sch Med, Gastroenterol & Hepatol, Kansas City, KS USA.
   [Sharma, Prateek] Univ Kansas, Sch Med, Gastroenterol, Kansas City, KS USA.
C3 National University of Singapore; National University of Singapore;
   Universiti Sains Malaysia; Nihon University; University of Kansas;
   University of Kansas Medical Center; US Department of Veterans Affairs;
   Veterans Health Administration (VHA); University of Kansas; University
   of Kansas Medical Center
RP Ho, KY (通讯作者)，Natl Univ Hlth Syst, Dept Med, Level 10,NUNS Tower Block,1E Kent Ridge Rd, Singapore 119228, Singapore.
EM khek_yu_ho@nuhs.edu.sg
RI Lee, Yeong Yeh/H-2777-2019; Lee, Yeong Yeh/G-2470-2010
OI Lee, Yeong Yeh/0000-0002-6486-7717; Lee, Yeong Yeh/0000-0002-6486-7717
CR ALLISON PR, 1953, THORAX, V8, P87, DOI 10.1136/thx.8.2.87
   Almond LM, 2014, GASTROINTEST ENDOSC, V79, P37, DOI 10.1016/j.gie.2013.05.028
   Almond LM, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.8.081421
   Alvi MA, 2013, CLIN CANCER RES, V19, P878, DOI 10.1158/1078-0432.CCR-12-2880
   Anagnostopoulos GK, 2007, ALIMENT PHARM THER, V26, P501, DOI 10.1111/j.1365-2036.2007.03374.x
   Antony A, 2018, CLIN RES HEPATOL GAS, V42, P591, DOI 10.1016/j.clinre.2018.06.004
   Baldaque-Silva F, 2013, SCAND J GASTROENTERO, V48, P160, DOI 10.3109/00365521.2012.746392
   Bandla S, 2014, ANN SURG, V260, P72, DOI 10.1097/SLA.0000000000000424
   BARRETT NR, 1950, BRIT J SURG, V38, P175, DOI 10.1002/bjs.18003815005
   Bennett C, 2015, AM J GASTROENTEROL, V110, P662, DOI 10.1038/ajg.2015.55
   Bennett C, 2012, GASTROENTEROLOGY, V143, P336, DOI 10.1053/j.gastro.2012.04.032
   Bergholt MS, 2011, TECHNOL CANCER RES T, V10, P103, DOI 10.7785/tcrt.2012.500185
   Bergholt MS, 2014, GASTROENTEROLOGY, V146, P27, DOI 10.1053/j.gastro.2013.11.002
   Bhandari P, 2012, DIS ESOPHAGUS, V25, P386, DOI 10.1111/j.1442-2050.2011.01267.x
   Bhat S, 2011, J NATL CANCER I, V103, P1049, DOI 10.1093/jnci/djr203
   BOSHER LH, 1951, J THORAC SURG, V21, P306
   Boyce HW, 2000, GASTROINTEST ENDOSC, V51, P586, DOI 10.1016/S0016-5107(00)70295-1
   Chang CY, 2016, HEALTH QUAL LIFE OUT, V14, DOI 10.1186/s12955-016-0551-2
   Chang CY, 2011, J GASTROEN HEPATOL, V26, P240, DOI 10.1111/j.1440-1746.2010.06529.x
   Chang CY, 2009, AM J GASTROENTEROL, V104, P13, DOI 10.1038/ajg.2008.43
   Choe JW, 2016, WORLD J GASTRO ENDOS, V8, P357, DOI 10.4253/wjge.v8.i8.357
   Coletta M, 2016, GASTROINTEST ENDOSC, V83, P57, DOI 10.1016/j.gie.2015.07.023
   Critchley-Thorne RJ, 2016, CANCER EPIDEM BIOMAR, V25, P958, DOI 10.1158/1055-9965.EPI-15-1164
   Curvers W, 2008, GASTROENTEROLOGY, V134, P670, DOI 10.1053/j.gastro.2008.01.003
   Curvers WL, 2010, AM J GASTROENTEROL, V105, P1523, DOI 10.1038/ajg.2010.171
   Das D, 2008, AM J GASTROENTEROL, V103, P1079, DOI 10.1111/j.1572-0241.2008.01790.x
   Dekel R, 2003, AM J GASTROENTEROL, V98, P2612, DOI 10.1016/S0002-9270(03)00665-8
   Eluri S, 2015, AM J GASTROENTEROL, V110, P828, DOI 10.1038/ajg.2015.152
   Fitzgerald RC, 2001, DIGEST DIS SCI, V46, P1892, DOI 10.1023/A:1010678913481
   Fitzgerald RC, 2014, GUT, V63, P7, DOI 10.1136/gutjnl-2013-305372
   Fock KM, 2008, J GASTROEN HEPATOL, V23, P8, DOI 10.1111/j.1440-1746.2007.05249.x
   Fock KM, 2016, GUT, V65, P1402, DOI 10.1136/gutjnl-2016-311715
   Fortun PJ, 2006, ALIMENT PHARM THER, V23, P735, DOI 10.1111/j.1365-2036.2006.02823.x
   Gatenby PAC, 2008, SCAND J GASTROENTERO, V43, P524, DOI 10.1080/00365520701879831
   Goda K, 2007, GASTROINTEST ENDOSC, V65, P36, DOI 10.1016/j.gie.2006.03.938
   Guelrud M, 2001, GASTROINTEST ENDOSC, V53, P559, DOI 10.1067/mge.2001.114059
   HAGGITT RC, 1994, HUM PATHOL, V25, P982, DOI 10.1016/0046-8177(94)90057-4
   Hahn HP, 2009, AM J SURG PATHOL, V33, P1006, DOI 10.1097/PAS.0b013e31819f57e9
   Hamade N, 2019, CLIN GASTROENTEROL H, V17, P864, DOI 10.1016/j.cgh.2018.07.008
   Harrison R, 2007, AM J GASTROENTEROL, V102, P1154, DOI 10.1111/j.1572-0241.2007.01230.x
   Hayeck TJ, 2010, DIS ESOPHAGUS, V23, P451, DOI 10.1111/j.1442-2050.2010.01054.x
   HAYWARD JOHN, 1961, THORAX, V16, P36, DOI 10.1136/thx.16.1.36
   Ho KY, 2011, J GASTROEN HEPATOL, V26, P816, DOI 10.1111/j.1440-1746.2011.06669.x
   Hong JS, 2017, IEEE ENG MED BIO, P2892, DOI 10.1109/EMBC.2017.8037461
   Ichihara S, 2017, DIGEST ENDOSC, V29, P3, DOI 10.1111/den.12792
   Ishimura N, 2012, DIGESTION, V86, P136, DOI 10.1159/000339778
   Ishimura N, 2009, DIGEST ENDOSC, V21, P213, DOI 10.1111/j.1443-1661.2009.00895.x
   Kandiah K, 2018, GUT, V67, P2085, DOI 10.1136/gutjnl-2017-314512
   Kara MA, 2006, GASTROINTEST ENDOSC, V64, P155, DOI 10.1016/j.gie.2005.11.049
   Kariv R, 2009, CLIN GASTROENTEROL H, V7, P653, DOI 10.1016/j.cgh.2008.11.024
   Kaye PV, 2009, HISTOPATHOLOGY, V54, P699, DOI 10.1111/j.1365-2559.2009.03288.x
   Kelty CJ, 2007, SCAND J GASTROENTERO, V42, P1271, DOI 10.1080/00365520701420735
   KIM SL, 1994, GASTROENTEROLOGY, V107, P945, DOI 10.1016/0016-5085(94)90217-8
   Kinjo T, 2010, J GASTROENTEROL, V45, P1039, DOI 10.1007/s00535-010-0264-y
   Koh JC, 2016, J GASTROEN HEPATOL, V31, P1405, DOI 10.1111/jgh.13385
   Kusano C, 2008, J GASTROEN HEPATOL, V23, P1662, DOI 10.1111/j.1440-1746.2008.05572.x
   Kusano C, 2009, J GASTROENTEROL, V44, P842, DOI 10.1007/s00535-009-0083-1
   Lambert R, 2003, ENDOSCOPY, V35, P437, DOI 10.1055/s-2003-38766
   Lee HS, 2014, CLIN ENDOSC, V47, P15, DOI 10.5946/ce.2014.47.1.15
   Lee YC, 2010, ENDOSCOPY, V42, P699, DOI 10.1055/s-0030-1255629
   Liu W, 2009, AM J GASTROENTEROL, V104, P816, DOI 10.1038/ajg.2009.85
   Longcroft-Wheaton G, 2010, CLIN GASTROENTEROL H, V8, P843, DOI 10.1016/j.cgh.2010.06.016
   Mayinger B, 2006, SCAND J GASTROENTERO, V41, P349, DOI 10.1080/00365520510024016
   MORSON BC, 1952, BRIT J CANCER, V6, P127, DOI 10.1038/bjc.1952.14
   Nieto T, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-020427
   NODA T, 1984, VIRCHOWS ARCH A, V404, P381, DOI 10.1007/BF00695222
   Ogiya K, 2008, DIS ESOPHAGUS, V21, P645, DOI 10.1111/j.1442-2050.2008.00825.x
   Park WG, 2015, AM J GASTROENTEROL, V110, P60, DOI 10.1038/ajg.2014.384
   PAULL A, 1976, NEW ENGL J MED, V295, P476, DOI 10.1056/NEJM197608262950904
   PEDERSEN S A, 1972, Scandinavian Journal of Thoracic and Cardiovascular Surgery, V6, P191, DOI 10.3109/14017437209134800
   Pohl H, 2016, GUT, V65, P196, DOI 10.1136/gutjnl-2015-309220
   Qi X, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2337314
   Reaud S, 2006, GASTROEN CLIN BIOL, V30, P217, DOI 10.1016/S0399-8320(06)73156-6
   REID BJ, 1988, GASTROENTEROLOGY, V94, P81, DOI 10.1016/0016-5085(88)90613-0
   REID BJ, 1987, ANNU REV MED, V38, P477, DOI 10.1146/annurev.me.38.020187.002401
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Sharma N, 2017, DIS ESOPHAGUS, V30, DOI 10.1093/dote/dox026
   Sharma N, 2016, CLIN ENDOSC, V49, P404, DOI 10.5946/ce.2016.100
   Sharma P, 1998, AM J GASTROENTEROL, V93, P1033
   Sharma P, 2006, GASTROINTEST ENDOSC, V64, P167, DOI 10.1016/j.gie.2005.10.044
   Sharma P, 2006, GASTROENTEROLOGY, V131, P1392, DOI 10.1053/j.gastro.2006.08.032
   Sharma P, 2016, GASTROENTEROLOGY, V150, P591, DOI 10.1053/j.gastro.2015.11.037
   Sharma P, 2015, GASTROENTEROLOGY, V149, P1599, DOI 10.1053/j.gastro.2015.08.007
   Shiota S, 2015, CLIN GASTROENTEROL H, V13, P1907, DOI 10.1016/j.cgh.2015.07.050
   Singh M, 2011, ENDOSCOPY, V43, P745, DOI 10.1055/s-0030-1256631
   Singh R, 2008, ENDOSCOPY, V40, P457, DOI 10.1055/s-2007-995741
   SKINNER DB, 1983, ANN SURG, V198, P554, DOI 10.1097/00000658-198310000-00016
   Sonwalkar SA, 2010, HISTOPATHOLOGY, V56, P900, DOI 10.1111/j.1365-2559.2010.03571.x
   SPECHLER SJ, 1994, LANCET, V344, P1533, DOI 10.1016/S0140-6736(94)90349-2
   Spechler SJ, 2011, GASTROENTEROLOGY, V140, pE18, DOI 10.1053/j.gastro.2011.01.031
   Spechler SJ, 2010, GASTROENTEROLOGY, V138, P854, DOI 10.1053/j.gastro.2010.01.002
   Srivastava S, 2017, DIGEST LIVER DIS, V49, P1104, DOI 10.1016/j.dld.2017.06.014
   Sun YT, 2018, BMC GASTROENTEROL, V18, DOI 10.1186/s12876-018-0745-7
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Takubo K, 2009, HUM PATHOL, V40, P65, DOI 10.1016/j.humpath.2008.06.008
   Uedo N, 2017, DIGEST ENDOSC, V29, P26, DOI 10.1111/den.12849
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Vennalaganti PR, 2018, GASTROINTEST ENDOSC, V87, P348, DOI 10.1016/j.gie.2017.07.039
   VIANNA A, 1987, GASTROENTEROLOGY, V93, P876, DOI 10.1016/0016-5085(87)90453-7
   Weinstein WM, 1996, GASTROINTEST ENDOSC, V44, P91, DOI 10.1016/S0016-5107(96)70239-0
   Whiteman DC, 2015, J GASTROEN HEPATOL, V30, P804, DOI 10.1111/jgh.12913
   Yagi K., 2006, DIGEST ENDOSC, V18, pS21, DOI [DOI 10.1111/J.1443-1661.2006.00613.X, 10.1111/j.1443-1661.2006.00613.x]
   Yamamoto Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms10380
   Zhang ZH, 2016, MULTIMED TOOLS APPL, V75, P3993, DOI 10.1007/s11042-015-3108-1
   2017, ESOPHAGUS-TOKYO, V14, P1, DOI DOI 10.1007/S10388-016-0551-7
NR 105
TC 7
Z9 7
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD NOV
PY 2019
VL 31
IS 6
BP 609
EP 618
DI 10.1111:den,13402
PG 10
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA JK2XF
UT WOS:000494709200012
PM 30892742
DA 2023-04-20
ER

PT J
AU Tomita, N
   Abdollahi, B
   Wei, JS
   Ren, B
   Suriawinata, A
   Hassanpour, S
AF Tomita, Naofumi
   Abdollahi, Behnaz
   Wei, Jason
   Ren, Bing
   Suriawinata, Arief
   Hassanpour, Saeed
TI Attention-Based Deep Neural Networks for Detection of Cancerous and
   Precancerous Esophagus Tissue on Histopathological Slides
SO JAMA NETWORK OPEN
LA English
DT Article
ID BARRETTS-ESOPHAGUS; ADENOCARCINOMA; DYSPLASIA; TRENDS
AB IMPORTANCE Deep learning-based methods, such as the sliding window approach for cropped-image classification and heuristic aggregation for whole-slide inference, for analyzing histological patterns in high-resolution microscopy images have shown promising results. These approaches, however, require a laborious annotation process and are fragmented.
   OBJECTIVE To evaluate a novel deep learningmethod that uses tissue-level annotations for high-resolution histological image analysis for Barrett esophagus (BE) and esophageal adenocarcinoma detection.
   DESIGN, SETTING, AND PARTICIPANTS This diagnostic study collected deidentified high-resolution histological images (N = 379) for training a new model composed of a convolutional neural network and a grid-based attention network. Histological images of patients who underwent endoscopic esophagus and gastroesophageal junction mucosal biopsy between January 1, 2016, and December 31, 2018, at Dartmouth-Hitchcock Medical Center (Lebanon, New Hampshire) were collected.
   MAIN OUTCOMES AND MEASURES The model was evaluated on an independent testing set of 123 histological images with 4 classes: normal, BE-no-dysplasia, BE-with-dysplasia, and adenocarcinoma. Performance of this model was measured and compared with that of the current state-of-the-art sliding window approach using the following standard machine learningmetrics: accuracy, recall, precision, and F1 score.
   RESULTS Of the independent testing set of 123 histological images, 30 (24.4%) were in the BE-nodysplasia class, 14 (11.4%) in the BE-with-dysplasia class, 21 (17.1%) in the adenocarcinoma class, and 58 (47.2%) in the normal class. Classification accuracies of the proposed model were 0.85 (95% CI, 0.81-0.90) for the BE-no-dysplasia class, 0.89 (95% CI, 0.84-0.92) for the BE-with-dysplasia class, and 0.88 (95% CI, 0.84-0.92) for the adenocarcinoma class. The proposed model achieved a mean accuracy of 0.83 (95% CI, 0.80-0.86) and marginally outperformed the sliding window approach on the same testing set. The F1 scores of the attention-based model were at least 8% higher for each class compared with the sliding window approach: 0.68 (95% CI, 0.61-0.75) vs 0.61 (95% CI, 0.530.68) for the normal class, 0.72 (95% CI, 0.63-0.80) vs 0.58 (95% CI, 0.45-0.69) for the BE-nodysplasia class, 0.30 (95% CI, 0.11-0.48) vs 0.22 (95% CI, 0.11-0.33) for the BE-with-dysplasia class, and 0.67 (95% CI, 0.54-0.77) vs 0.58 (95% CI, 0.44-0.70) for the adenocarcinoma class. However, this outperformance was not statistically significant.
   CONCLUSIONS AND RELEVANCE Results of this study suggest that the proposed attention-based deep neural network framework for BE and esophageal adenocarcinoma detection is important because it is based solely on tissue-level annotations, unlike existingmethods that are based on regions of interest. This new model is expected to open avenues for applying deep learning to digital pathology.
C1 [Tomita, Naofumi; Abdollahi, Behnaz; Wei, Jason; Hassanpour, Saeed] Dartmouth Coll, Geisel Sch Med, Dept Biomed Data Sci, HB 7261, Hanover, NH 03755 USA.
   [Wei, Jason; Hassanpour, Saeed] Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.
   [Ren, Bing; Suriawinata, Arief] Dartmouth Hitchcock Med Ctr, Dept Pathol & Lab Med, Lebanon, NH USA.
   [Hassanpour, Saeed] Dartmouth Coll, Geisel Sch Med, Dept Epidemiol, Hanover, NH 03755 USA.
C3 Dartmouth College; Dartmouth College; Dartmouth College; Dartmouth
   College
RP Hassanpour, S (通讯作者)，Dartmouth Coll, Geisel Sch Med, Dept Biomed Data Sci, HB 7261, Hanover, NH 03755 USA.
EM saeed.hassanpour@dartmouth.edu
RI Suriawinata, Arief/ABA-7718-2020
FU National Institutes of Health [R01LM012837, P20GM104416]
FX This research was supported in part by grants R01LM012837 and
   P20GM104416 from the National Institutes of Health.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   [Anonymous], 2010, P 13 INT C ARTIFICIA
   BLOT WJ, 1994, SEMIN ONCOL, V21, P403
   Bollschweiler E, 2001, CANCER, V92, P549, DOI 10.1002/1097-0142(20010801)92:3<549::AID-CNCR1354>3.0.CO;2-L
   Bossuyt PM, 2015, RADIOLOGY, V277, P826, DOI 10.1148/radiol.2015151516
   Brown Linda Morris, 2002, Surg Oncol Clin N Am, V11, P235, DOI 10.1016/S1055-3207(02)00002-9
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Coco DP, 2011, AM J SURG PATHOL, V35, P45, DOI 10.1097/PAS.0b013e3181ffdd14
   Conio M, 2002, INT J CANCER, V97, P225, DOI 10.1002/ijc.1583
   Corredor G, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.2.021105
   Cosatto E., 2013, PROC SPIE, V8676
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Daly JM, 1996, CANCER, V78, P1820, DOI 10.1002/(SICI)1097-0142(19961015)78:8<1820::AID-CNCR25>3.0.CO;2-Z
   Edgren G, 2013, GUT, V62, P1406, DOI 10.1136/gutjnl-2012-302412
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Guan Q, DIAGNOSE RADIOLOGIST
   HAGGITT RC, 1994, HUM PATHOL, V25, P982, DOI 10.1016/0046-8177(94)90057-4
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266
   Ioffe S, BATCH NORMALIZATION
   Jaderberg M., 2015, INT C LEARN REPR ICL
   Komura D, 2018, COMPUT STRUCT BIOTEC, V16, P34, DOI 10.1016/j.csbj.2018.01.001
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Korbar B, 2017, IEEE COMPUT SOC CONF, P821, DOI 10.1109/CVPRW.2017.114
   Liu Y, DETECTING CANC METAS
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Loshchilov I, 2017, 2017 5 INT C LEARN R
   Odze RD., 2014, ODZE GOLDBLUM SURG P
   PAULL A, 1976, NEW ENGL J MED, V295, P476, DOI 10.1056/NEJM197608262950904
   Pesce E, LEARNING DETECT CHES
   Polednak AP, 2003, INT J CANCER, V105, P98, DOI 10.1002/ijc.11029
   Saha M, 2018, COMPUT MED IMAG GRAP, V64, P29, DOI 10.1016/j.compmedimag.2017.12.001
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stein Hubert J., 1993, Dysphagia, V8, P276, DOI 10.1007/BF01354551
   Wang F, RESIDUAL ATTENTION N
   Wei Jason W, 2019, J Pathol Inform, V10, P7, DOI 10.4103/jpi.jpi_87_18
   Wei JW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40041-7
   Wild CP, 2003, NAT REV CANCER, V3, P676, DOI 10.1038/nrc1166
   World Medical Association, 2013, JAMA-J AM MED ASSOC, V310, P2191, DOI [10.1001/jama.2013.281053, DOI 10.1001/JAMA.2013.281053]
   Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Ypsilantis P-P, ARXIV
NR 45
TC 67
Z9 68
U1 4
U2 18
PU AMER MEDICAL ASSOC
PI CHICAGO
PA 330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA
SN 2574-3805
J9 JAMA NETW OPEN
JI JAMA Netw. Open
PD NOV
PY 2019
VL 2
IS 11
AR e1914645
DI 10.1001/jamanetworkopen.2019.14645
PG 13
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA JZ6OX
UT WOS:000505224400022
PM 31693124
OA gold, Green Submitted, Green Accepted, Green Published
DA 2023-04-20
ER

PT J
AU Tong, L
   Wu, H
   Wang, MD
AF Tong, Li
   Wu, Hang
   Wang, May D.
TI CAESNet: Convolutional AutoEncoder based Semi-supervised Network for
   improving multiclass classification of endomicroscopic images
SO JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION
LA English
DT Article
DE endomicroscopy; Barrett's esophagus; semisupervised learning;
   convolutional autoencoders
ID CONFOCAL LASER ENDOMICROSCOPY; COMPUTER-AIDED DIAGNOSIS;
   BARRETTS-ESOPHAGUS; SURVEILLANCE; MULTICENTER; DISEASE
AB Objective: This article presents a novel method of semisupervised learning using convolutional autoencoders for optical endomicroscopic images. Optical endomicroscopy (OE) is a newly emerged biomedical imaging modality that can support real-time clinical decisions for the grade of dysplasia. To enable real-time decision making, computer-aided diagnosis (CAD) is essential for its high speed and objectivity. However, traditional supervised CAD requires a large amount of training data. Compared with the limited number of labeled images, we can collect a larger number of unlabeled images. To utilize these unlabeled images, we have developed a Convolutional AutoEncoder based Semi-supervised Network (CAESNet) for improving the classification performance.
   Materials and Methods: We applied our method to an OE dataset collected from patients undergoing endoscope-based confocal laser endomicroscopy procedures for Barrett's esophagus at Emory Hospital, which consists of 429 labeled images and 2826 unlabeled images. Our CAESNet consists of an encoder with 5 convolutional layers, a decoder with 5 transposed convolutional layers, and a classification network with 2 fully connected layers and a softmax layer. In the unsupervised stage, we first update the encoder and decoder with both labeled and unlabeled images to learn an efficient feature representation. In the supervised stage, we further update the encoder and the classification network with only labeled images for multiclass classification of the OE images.
   Results: Our proposed semisupervised method CAESNet achieves the best average performance for multiclass classification of OE images, which surpasses the performance of supervised methods including standard convolutional networks and convolutional autoencoder network.
   Conclusions: Our semisupervised CAESNet can efficiently utilize the unlabeled OE images, which improves the diagnosis and decision making for patients with Barrett's esophagus.
C1 [Tong, Li; Wang, May D.] Emory Univ, Georgia Inst Technol, Dept Biomed Engn, Atlanta, GA 30332 USA.
   [Wu, Hang] Georgia Inst Technol, Dept Biomed Engn, 313 Ferst Dr,Room 4106, Atlanta, GA 30332 USA.
   [Wang, May D.] Georgia Inst Technol, Inst People & Technol, Dept Elect & Comp Engn, Winship Canc Inst,Parker H Petit Inst Bioengn & B, 313 Ferst Dr,Room 4106, Atlanta, GA 30332 USA.
   [Wang, May D.] Georgia Inst Technol, Inst People & Technol, Dept Computat Sci & Engn, Winship Canc Inst,Parker H Petit Inst Bioengn & B, 313 Ferst Dr,Room 4106, Atlanta, GA 30332 USA.
   [Wang, May D.] Emory Univ, 313 Ferst Dr,Room 4106, Atlanta, GA 30332 USA.
C3 Emory University; University System of Georgia; Georgia Institute of
   Technology; University System of Georgia; Georgia Institute of
   Technology; University System of Georgia; Georgia Institute of
   Technology; University System of Georgia; Georgia Institute of
   Technology; Emory University
RP Wang, MD (通讯作者)，Georgia Inst Technol, Dept Biomed Engn, 313 Ferst Dr,Room 4106, Atlanta, GA 30332 USA.; Wang, MD (通讯作者)，Georgia Inst Technol, Inst People & Technol, Dept Elect & Comp Engn, Winship Canc Inst,Parker H Petit Inst Bioengn & B, 313 Ferst Dr,Room 4106, Atlanta, GA 30332 USA.; Wang, MD (通讯作者)，Georgia Inst Technol, Inst People & Technol, Dept Computat Sci & Engn, Winship Canc Inst,Parker H Petit Inst Bioengn & B, 313 Ferst Dr,Room 4106, Atlanta, GA 30332 USA.; Wang, MD (通讯作者)，Emory Univ, 313 Ferst Dr,Room 4106, Atlanta, GA 30332 USA.
EM maywang@bme.gatech.edu
RI Wang, May Dongmei/AAF-2065-2021
OI Wang, May Dongmei/0000-0003-3961-3608
FU National Institutes of Health (National Cancer Institute) [R01
   CA163256]; National Center for Advancing Translational Sciences
   [UL1TR000454]; Microsoft Research; Hewlett Packard; China Scholarship
   Council [CSC 201406010343]
FX This work was supported by the grants from the National Institutes of
   Health (National Cancer Institute Transformative R01 CA163256), the
   National Center for Advancing Translational Sciences (UL1TR000454),
   Microsoft Research, and Hewlett Packard for LT, HW, and MDW. This work
   was also supported in part by a scholarship from China Scholarship
   Council (CSC 201406010343) for LT. The content is solely the
   responsibility of the authors and does not necessarily represent the
   official views of the National Institutes of Health or China Scholarship
   Council.
CR Anaparthy R, 2014, NAT REV GASTRO HEPAT, V11, P525, DOI 10.1038/nrgastro.2014.69
   Bloice M. D., 2017, ARXIV E PRINTS
   Bron EE, 2015, NEUROIMAGE, V111, P562, DOI 10.1016/j.neuroimage.2015.01.048
   Canto MI, 2014, GASTROINTEST ENDOSC, V79, P211, DOI 10.1016/j.gie.2013.09.020
   Carignan CS, 2012, DIAGN PATHOL, V7, DOI 10.1186/1746-1596-7-98
   Chang JT, 2004, ARCH INTERN MED, V164, P1482, DOI 10.1001/archinte.164.14.1482
   Cheng JJ, 2016, SCI REP-UK, V6, DOI 10.1038/srep21808
   Cooper LAD, 2012, J AM MED INFORM ASSN, V19, P317, DOI 10.1136/amiajnl-2011-000700
   Devesa SS, 1998, CANCER, V83, P2049, DOI 10.1002/(SICI)1097-0142(19981115)83:10<2049::AID-CNCR1>3.0.CO;2-2
   Dunbar KB, 2009, GASTROINTEST ENDOSC, V70, P645, DOI 10.1016/j.gie.2009.02.009
   Ghatwary N., 2017, P SOC PHOTO-OPT INS, V10134
   Gill RS, 2012, ANN GASTROENTEROL, V25, P89
   Grisan E, 2012, GASTROINTEST ENDOSC, V75, P126
   Hong J, 2017, 2017 39 ANN INT C IE
   Jemal A, 2009, CA-CANCER J CLIN, V59, P225, DOI 10.3322/caac.20006
   Jia ZP, 2017, IEEE T MED IMAGING, V36, P2376, DOI 10.1109/TMI.2017.2724070
   Kang D, 2014, ENDOSC INT OPEN, V2, pE135, DOI 10.1055/s-0034-1377177
   Kothari S, 2013, J AM MED INFORM ASSN, V20, P1099, DOI 10.1136/amiajnl-2012-001540
   Leggett CL, 2016, GASTROINTEST ENDOSC, V83, P880, DOI 10.1016/j.gie.2015.08.050
   LI CQ, 2014, GASTROINTEST ENDOSC, V74
   Li JY, 2018, COMPUT MED IMAG GRAP, V69, P125, DOI 10.1016/j.compmedimag.2018.08.003
   Makhzani A, 2015, ADV NEUR IN, V28
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Mendel R., 2017, BILDVERARBEITUNG MED, P80
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Ratner AJ, 2017, ADV NEUR IN, V30
   Sharma P, 2004, GASTROENTEROLOGY, V127, P310, DOI 10.1053/j.gastro.2004.04.010
   Sharma P, 2011, GASTROINTEST ENDOSC, V74, P465, DOI 10.1016/j.gie.2011.04.004
   Sharma P, 2009, NEW ENGL J MED, V361, P2548, DOI 10.1056/NEJMcp0902173
   Spechler SJ, 2014, NEW ENGL J MED, V371, P836, DOI 10.1056/NEJMra1314704
   Sturm MB, 2015, GUT, V64, P1816, DOI 10.1136/gutjnl-2013-306706
   Veronese E, 2013, I S BIOMED IMAGING, P362
   Wang KK, 2008, AM J GASTROENTEROL, V103, P788, DOI 10.1111/j.1572-0241.2008.01835.x
   Wu H, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P5, DOI 10.1109/BHI.2017.7897191
NR 35
TC 5
Z9 5
U1 1
U2 13
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1067-5027
EI 1527-974X
J9 J AM MED INFORM ASSN
JI J. Am. Med. Inf. Assoc.
PD NOV
PY 2019
VL 26
IS 11
BP 1286
EP 1296
DI 10.1093/jamia/ocz089
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Health Care Sciences & Services;
   Information Science & Library Science; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Health Care Sciences & Services; Information Science &
   Library Science; Medical Informatics
GA JP3LQ
UT WOS:000498169400017
PM 31260038
OA Green Published
DA 2023-04-20
ER

PT J
AU Wingfield, B
   Coleman, S
   McGinnity, TM
   Bjourson, AJ
AF Wingfield, Benjamin
   Coleman, Sonya
   McGinnity, T. M.
   Bjourson, A. J.
TI Robust Microbial Markers for Non-Invasive Inflammatory Bowel Disease
   Identification
SO IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS
LA English
DT Article
DE Feature evaluation and selection; machine learning algorithms; pattern
   recognition; medicine
ID HUMAN GUT MICROBIOME; FEATURE-SELECTION; SHRUNKEN CENTROIDS;
   CROHNS-DISEASE; RISK-FACTORS; CANCER; DIAGNOSIS; CLASSIFICATION;
   EPIDEMIOLOGY; METABOLOMICS
AB Inflammatory Bowel Disease (IBD) is an umbrella term for a group of inflammatory diseases of the gastrointestinal tract, including Crohn's Disease and ulcerative colitis. Changes to the intestinal microbiome, the community of micro-organisms that resides in the human gut, have been shown to contribute to the pathogenesis of IBD. IBD diagnosis is often delayed due to its non-specific symptoms and because an invasive colonoscopy is required for confirmation, which leads to poor growth in children and worse treatment outcomes. Feature selection algorithms are often applied to microbial communities to identify bacterial groups that drive disease. It has been shown that aggregating Ensemble Feature Selection (EFS) can improve the robustness of feature selection algorithms, which is defined as the variation of feature selector output caused by small changes to the dataset. In this work, we apply a two-step filter and an EFS process to generate robust feature subsets that can non-invasively predict IBD subtypes from high-resolution microbiome data. The predictive power of the robust feature subsets is the highest reported in literature to date. Furthermore, we identify five biologically plausible bacterial species that have not previously been implicated in IBD aetiology.
C1 [Wingfield, Benjamin; Coleman, Sonya] Ulster Univ, Intelligent Syst Res Ctr, Derry BT48 7JL, North Ireland.
   [McGinnity, T. M.] Nottingham Trent Univ, Sch Sci & Technol, Nottingham NG1 4FQ, England.
   [McGinnity, T. M.] Intelligent Syst Res Ctr, Derry BT48 7JL, North Ireland.
   [Bjourson, A. J.] Ulster Univ, Northern Ireland Ctr Stratified Med, Derry BT48 7JL, North Ireland.
C3 Ulster University; Nottingham Trent University; Ulster University
RP Wingfield, B (通讯作者)，Ulster Univ, Intelligent Syst Res Ctr, Derry BT48 7JL, North Ireland.
EM wingfield-b@ulster.ac.uk; sa.coleman@ulster.ac.uk;
   martin.mcginnity@ntu.ac.uk; aj.bjourson@ulster.ac.uk
OI Coleman, Sonya/0000-0002-4676-7640; Wingfield,
   Benjamin/0000-0002-2913-0779; McGinnity, Thomas
   Martin/0000-0002-9897-4748; John, Anthony/0000-0002-1105-7147
FU Northern Ireland Department for Employment and Learning (DEL)
FX This work was completed under a PhD studentship supported by the
   Northern Ireland Department for Employment and Learning (DEL).
CR Aagaard K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036466
   Abeel T, 2009, BIOINFORMATICS, V25, pI313, DOI 10.1093/bioinformatics/btp191
   Ananthakrishnan AN, 2015, NAT REV GASTRO HEPAT, V12, P205, DOI 10.1038/nrgastro.2015.34
   Ang JC, 2016, IEEE ACM T COMPUT BI, V13, P971, DOI 10.1109/TCBB.2015.2478454
   Bezabeh T, 2009, MAGN RESON CHEM, V47, pS54, DOI 10.1002/mrc.2530
   Boettiger Carl, 2015, ACM SIGOPS Operating Systems Review, V49, P71
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Callahan Ben J, 2016, F1000Res, V5, P1492
   Callahan BJ, 2017, ISME J, V11, P2639, DOI 10.1038/ismej.2017.119
   Callahan BJ, 2016, NAT METHODS, V13, P581, DOI [10.1038/NMETH.3869, 10.1038/nmeth.3869]
   Caporaso JG, 2011, P NATL ACAD SCI USA, V108, P4516, DOI 10.1073/pnas.1000080107
   Caporaso JG, 2010, NAT METHODS, V7, P335, DOI 10.1038/nmeth.f.303
   Carter J, 2014, GECCO'14: PROCEEDINGS OF THE 2014 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P265
   Carter MJ, 2004, GUT, V53, DOI 10.1136/gut.2004.043372
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen CS, 2009, MOL CELL PROTEOMICS, V8, P1765, DOI 10.1074/mcp.M800593-MCP200
   Chen LP, 2014, MEDICINE, V93, DOI 10.1097/MD.0000000000000051
   Colgan SP, 2013, INFLAMM BOWEL DIS, V19, P2238, DOI 10.1097/MIB.0b013e31828dcaaf
   Determan CE, 2014, INT J BIOL, V7, P100, DOI DOI 10.5539/ijb.v7n1p100
   Di Tommaso P, 2017, NAT BIOTECHNOL, V35, P316, DOI 10.1038/nbt.3820
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Duncan SH, 2013, MATURITAS, V75, P44, DOI 10.1016/j.maturitas.2013.02.004
   Edgar R. C., 2016, BIORXIV
   Eren AM, 2015, ISME J, V9, P968, DOI 10.1038/ismej.2014.195
   Eren AM, 2013, METHODS ECOL EVOL, V4, P1111, DOI 10.1111/2041-210X.12114
   Forslund K, 2015, NATURE, V528, P262, DOI 10.1038/nature15766
   Gevers D, 2014, CELL HOST MICROBE, V15, P382, DOI 10.1016/j.chom.2014.02.005
   Guyon, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Hourigan SK, 2015, ALIMENT PHARM THER, V42, P741, DOI 10.1111/apt.13326
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Kalousis A, 2007, KNOWL INF SYST, V12, P95, DOI 10.1007/s10115-006-0040-8
   Kans J, 2013, ENTREZ DIRECT E UTIL
   Kostic AD, 2012, GENOME RES, V22, P292, DOI 10.1101/gr.126573.111
   Kursa MB, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i11
   Le Chatelier E, 2013, NATURE, V500, P541, DOI 10.1038/nature12506
   Leinonen R, 2011, NUCLEIC ACIDS RES, V39, pD19, DOI 10.1093/nar/gkq1019
   Loomba R, 2017, CELL METAB, V25, P1054, DOI 10.1016/j.cmet.2017.04.001
   LOVE MI, 2014, GENOME BIOL, V15, DOI DOI 10.1186/S13059-014-0550-8
   McMurdie PJ, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003531
   McMurdie PJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061217
   Molodecky NA, 2012, GASTROENTEROLOGY, V142, P46, DOI 10.1053/j.gastro.2011.10.001
   Morgan XC, 2012, GENOME BIOL, V13, DOI 10.1186/gb-2012-13-9-r79
   Motoda H., 2012, FEATURE SELECTION KN
   Oliveros J. C., 2015, VENNY INTERACTIVE TO
   Papa E, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039242
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Qi YJ, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P307, DOI 10.1007/978-1-4419-9326-7_11
   Qin JJ, 2012, NATURE, V490, P55, DOI 10.1038/nature11450
   Qin N, 2014, NATURE, V513, P59, DOI 10.1038/nature13568
   Quast Christian, 2013, Nucleic Acids Res, V41, pD590, DOI 10.1093/nar/gks1219
   Rappe MS, 2003, ANNU REV MICROBIOL, V57, P369, DOI 10.1146/annurev.micro.57.030502.090759
   Ricanek P, 2012, CLIN EXP GASTROENTER, V5, P173, DOI 10.2147/CEG.S33858
   Ruth W., 2016, ARXIV160605273
   Saeys Y, 2008, LECT NOTES ARTIF INT, V5212, P313, DOI 10.1007/978-3-540-87481-2_21
   Sakon H, 2008, INT J SYST EVOL MICR, V58, P970, DOI 10.1099/ijs.0.65456-0
   Sartor RB, 2006, NAT CLIN PRACT GASTR, V3, P390, DOI 10.1038/ncpgasthep0528
   Schloss PD, 2009, APPL ENVIRON MICROB, V75, P7537, DOI 10.1128/AEM.01541-09
   Schuffler PJ, 2013, LECT NOTES COMPUT SC, V8198, P1, DOI 10.1007/978-3-642-41083-3_1
   Silverberg MS, 2005, CAN J GASTROENTEROL, V19, p5A, DOI 10.1155/2005/269076
   Sokol H, 2008, P NATL ACAD SCI USA, V105, P16731, DOI 10.1073/pnas.0804812105
   Spray C, 2001, ACTA PAEDIATR, V90, P400, DOI 10.1080/080352501750126230
   Statnikov A, 2013, MICROBIOME, V1, DOI 10.1186/2049-2618-1-11
   Statnikov A, 2013, SCI REP-UK, V3, DOI 10.1038/srep02620
   Strauss J, 2011, INFLAMM BOWEL DIS, V17, P1971, DOI 10.1002/ibd.21606
   Swidsinski A, 2005, J CLIN MICROBIOL, V43, P3380, DOI 10.1128/JCM.43.7.3380-3389.2005
   Tange O, 2011, THE USENIX MAGAZINE, V36, P42, DOI DOI 10.5281/ZENODO.16303
   Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488
   Tietz A, 2005, J CLIN MICROBIOL, V43, P3017, DOI 10.1128/JCM.43.6.3017-3022.2005
   Tong MM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080702
   Triantafillidis JK, 2009, ANTICANCER RES, V29, P2727
   Van Rijsbergen CJ, 1979, INFORM RETRIEVAL
   Wang W, 2014, J CLIN MICROBIOL, V52, P398, DOI 10.1128/JCM.01500-13
   Wei Z, 2013, AM J HUM GENET, V92, P1008, DOI 10.1016/j.ajhg.2013.05.002
   Wingfield B, 2016, IEEE IJCNN, P1083, DOI 10.1109/IJCNN.2016.7727318
   Wooley JC, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000667
NR 80
TC 8
Z9 8
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1545-5963
EI 1557-9964
J9 IEEE ACM T COMPUT BI
JI IEEE-ACM Trans. Comput. Biol. Bioinform.
PD NOV-DEC
PY 2019
VL 16
IS 6
BP 2078
EP 2088
DI 10.1109/TCBB.2018.2831212
PG 11
WC Biochemical Research Methods; Computer Science, Interdisciplinary
   Applications; Mathematics, Interdisciplinary Applications; Statistics &
   Probability
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Computer Science; Mathematics
GA KD5RX
UT WOS:000507924300027
PM 29994028
OA Green Published, Green Accepted, Green Submitted
DA 2023-04-20
ER

PT J
AU Shi, CF
   Xue, Y
   Jiang, C
   Tian, H
   Liu, B
AF Shi, Chenfei
   Xue, Yan
   Jiang, Chuan
   Tian, Hui
   Liu, Bei
TI Gastroscopic Panoramic View: Application to Automatic Polyps Detection
   under Gastroscopy
SO COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE
LA English
DT Article
ID CANCER
AB Endoscopic diagnosis is an important means for gastric polyp detection. In this paper, a panoramic image of gastroscopy is developed, which can display the inner surface of the stomach intuitively and comprehensively. Moreover, the proposed automatic detection solution can help doctors locate the polyps automatically and reduce missed diagnosis. The main contributions of this paper are firstly, a gastroscopic panorama reconstruction method is developed. The reconstruction does not require additional hardware devices and can solve the problem of texture dislocation and illumination imbalance properly; secondly, an end-to-end multiobject detection for gastroscopic panorama is trained based on a deep learning framework. Compared with traditional solutions, the automatic polyp detection system can locate all polyps in the inner wall of the stomach in real time and assist doctors to find the lesions. Thirdly, the system was evaluated in the Affiliated Hospital of Zhejiang University. The results show that the average error of the panorama is less than 2mm, the accuracy of the polyp detection is 95%, and the recall rate is 99%. In addition, the research roadmap of this paper has guiding significance for endoscopy-assisted detection of other human soft cavities.
C1 [Shi, Chenfei; Xue, Yan; Jiang, Chuan; Tian, Hui; Liu, Bei] ZheJiang Univ, Sch Med, Womens Hosp, Hangzhou 310000, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Shi, CF (通讯作者)，ZheJiang Univ, Sch Med, Womens Hosp, Hangzhou 310000, Zhejiang, Peoples R China.
EM 21315079@zju.edu.cn
FU Medical Scientific Research Foundation of Zhejiang Province, China
   [2018PY022]
FX The project was supported by the Medical Scientific Research Foundation
   of Zhejiang Province, China (2018PY022).
CR Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheung G., 2017, P 2017 IEEE INT C CO
   Cohen A. R., 2017, WORLD NEUROSURGERY, V103
   Denzer UW, 2015, J CLIN GASTROENTEROL, V49, P101, DOI 10.1097/MCG.0000000000000110
   Gao MK, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0315-2
   Guneri EA, 2018, CLIN EXP OTORHINOLAR, V11, P89, DOI 10.21053/ceo.2017.00927
   Hu WL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153202
   Leonard S, 2018, IEEE T MED IMAGING, V37, P2185, DOI 10.1109/TMI.2018.2833868
   Li DA, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.204
   Liu JQ, 2015, IEEE T BIO-MED ENG, V62, P2296, DOI 10.1109/TBME.2015.2424438
   Liu W., 2016, SINGLE SHOT MULTIBOX
   Lovat LB, 2006, GUT, V55, P1078, DOI 10.1136/gut.2005.081467
   Ma J, 2016, J CANCER RES THER, V12, P271, DOI 10.4103/0973-1482.200755
   Rashmi K, 2013, INT J MED RES HEALTH, V2, P418, DOI 10.5958/j.2319-5886.2.3.073
   van der Post RS, 2018, GASTROINTEST ENDOSC, V87, P397, DOI 10.1016/j.gie.2017.04.016
   Vemuri A. S., 2019, SURVEY COMPUTER VISI
   Wang B, 2014, J MED IMAG HEALTH IN, V4, P797, DOI 10.1166/jmihi.2014.1323
   Wang B, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/974038
   Wickremeratne T, 2019, ALIMENT PHARM THER, V49, P1464, DOI 10.1111/apt.15282
   Ye M., 2016, ROBUST IMAGE DESCRIP
   Zeng J. L., 2017, P INT C ADV ENG THEO
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 22
TC 2
Z9 2
U1 2
U2 12
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1748-670X
EI 1748-6718
J9 COMPUT MATH METHOD M
JI Comput. Math. Method Med.
PD OCT 30
PY 2019
VL 2019
AR 4393124
DI 10.1155/2019/4393124
PG 8
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA JO1OO
UT WOS:000497354500002
PM 31885680
OA Green Published, Green Submitted, gold
DA 2023-04-20
ER

PT J
AU Souaidi, M
   El Ansari, M
AF Souaidi, Meryem
   El Ansari, Mohamed
TI Multi-scale analysis of ulcer disease detection from WCE images
SO IET IMAGE PROCESSING
LA English
DT Article
DE grey systems; diseases; medical image processing; image texture; image
   segmentation; support vector machines; image colour analysis;
   endoscopes; image classification; biomedical optical imaging; feature
   extraction; ulcer disease detection; wireless capsule endoscopy; great
   technology; entire digestive tract; automatic computer-aided design
   method; normal WCE images; multiscale analysis-based grey-level
   co-occurrence matrix; GLCM; sub-band Laplacian pyramid decomposition;
   common Haralick features; feature descriptor; ulcer detection;
   encouraging detection rate performance
ID CAPSULE; ENHANCEMENT; TEXTURE
AB Wireless capsule endoscopy (WCE) proves its robustness as a great technology to examine the entire digestive tract or the small intestine. An automatic computer-aided design method is proposed in this study, in a manner to differentiate between ulcer disease and normal WCE images. A multi-scale analysis-based grey-level co-occurrence matrix (GLCM) is conducted here. The main step, the co-occurrence matrix (GLCM), is computed from each sub-band Laplacian pyramid decomposition, so as to extract the common Haralick features. Moreover, the p-value and area under the curve are used to select the relevant characteristics from the feature descriptor. This proposed approach was separately applied to the components of CIELab colour space. Ulcer detection was performed using the support vector machine. The findings demonstrate an encouraging detection rate performance of 95.38% for accuracy and 97.42% for sensitivity based on the first dataset and an average accuracy of 99.25 and 98.51% of sensitivities for the second dataset.
C1 [Souaidi, Meryem; El Ansari, Mohamed] Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Souaidi, M (通讯作者)，Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, Agadir 80000, Morocco.
EM meryem.souaidi@edu.uiz.ac.ma
RI El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066
CR Abkenar MR, 2018, IET IMAGE PROCESS, V12, P2275, DOI 10.1049/iet-ipr.2018.5479
   Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   [Anonymous], 1962, ORG WEO CLIN ENDOSCO
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chaddad A., 2011, Proceedings of the 2011 First International Conference on Informatics and Computational Intelligence (ICI 2011), P55, DOI 10.1109/ICI.2011.20
   Chaddad A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149893
   Charfi S, 2019, IET IMAGE PROCESS, V13, P1023, DOI 10.1049/iet-ipr.2018.6232
   Charisis V., 2012, NEW ADV BASIC CLIN G, P185
   Charisis V.S., 2013, IEEE 26 INT S COMP B
   Chen Y, 2012, P 20 ACM INT C MULT, P1181, DOI DOI 10.1145/2393347.2396413
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Georgakopoulos SV, 2016, IEEE CONF IMAGING SY, P510, DOI 10.1109/IST.2016.7738279
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Htwe T.M., 2010, P 2 APSIPA ANN SUMM, P653
   Huang ZH, 2018, INFRARED PHYS TECHN, V94, P38, DOI 10.1016/j.infrared.2018.08.019
   Huang ZH, 2018, IEEE GEOSCI REMOTE S, V15, P759, DOI 10.1109/LGRS.2018.2796604
   Huang ZH, 2018, IET IMAGE PROCESS, V12, P254, DOI 10.1049/iet-ipr.2017.0518
   Huang ZH, 2018, BIOMED SIGNAL PROCES, V40, P131, DOI 10.1016/j.bspc.2017.09.019
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P137, DOI 10.1007/BFb0026683
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Lahmyed R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063011
   Lan LB, 2019, IEEE ACCESS, V7, P30017, DOI 10.1109/ACCESS.2019.2901568
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Liu YS, 2018, IEEE IND ELECTRON M, V12, P6, DOI 10.1109/MIE.2018.2825479
   Porebski A, 2008, 2008 1 WORKSHOPS IMA, P1, DOI [DOI 10.1109/IPTA.2008.4743780, 10.1109/IPTA.2008.4743780]
   Salehpour P, 2016, BIOMED ENG-APP BAS C, V28, DOI 10.4015/S1016237216500290
   Scheunders P., 1998, INT J COMPUTER SCI I, V1, P22, DOI 10.1.1.40.1818/
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Souaidi M., 2019, MULTIMED TOOLS APPL, V78, P1
   Souaidi M., 2017, P 2017 INT C ADV TEC, P1
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Yu LC, 2012, INT C PATT RECOG, P45
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zarie M, 2019, IET IMAGE PROCESS, V13, P1081, DOI 10.1049/iet-ipr.2018.5395
   Zulpe N., 2012, INT J COMPUTER SCI I, V9, P354
NR 44
TC 11
Z9 11
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-9659
EI 1751-9667
J9 IET IMAGE PROCESS
JI IET Image Process.
PD OCT 17
PY 2019
VL 13
IS 12
BP 2233
EP 2244
DI 10.1049/iet-ipr.2019.0415
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA JO6SP
UT WOS:000497707700022
DA 2023-04-20
ER

PT J
AU Yamada, M
   Saito, Y
   Imaoka, H
   Saiko, M
   Yamada, S
   Kondo, H
   Takamaru, H
   Sakamoto, T
   Sese, J
   Kuchiba, A
   Shibata, T
   Hamamoto, R
AF Yamada, Masayoshi
   Saito, Yutaka
   Imaoka, Hitoshi
   Saiko, Masahiro
   Yamada, Shigemi
   Kondo, Hiroko
   Takamaru, Hiroyuki
   Sakamoto, Taku
   Sese, Jun
   Kuchiba, Aya
   Shibata, Taro
   Hamamoto, Ryuji
TI Development of a real-time endoscopic image diagnosis support system
   using deep learning technology in colonoscopy
SO SCIENTIFIC REPORTS
LA English
DT Article
ID COLORECTAL-CANCER; TANDEM COLONOSCOPY; VALIDATION; ALGORITHM; RATES;
   PREVENTION; VISION; RISK
AB Gaps in colonoscopy skills among endoscopists, primarily due to experience, have been identified, and solutions are critically needed. Hence, the development of a real-time robust detection system for colorectal neoplasms is considered to significantly reduce the risk of missed lesions during colonoscopy. Here, we develop an artificial intelligence (AI) system that automatically detects early signs of colorectal cancer during colonoscopy; the AI system shows the sensitivity and specificity are 97.3% (95% confidence interval [CI] = 95.9%-98.4%) and 99.0% (95% CI = 98.6%-99.2%), respectively, and the area under the curve is 0.975 (95% CI = 0.964-0.986) in the validation set. Moreover, the sensitivities are 98.0% (95% CI = 96.6%-98.8%) in the polypoid subgroup and 93.7% (95% CI = 87.6%-96.9%) in the non-polypoid subgroup; To accelerate the detection, tensor metrics in the trained model was decomposed, and the system can predict cancerous regions 21.9 ms/image on average. These findings suggest that the system is sufficient to support endoscopists in the high detection against non-polypoid lesions, which are frequently missed by optical colonoscopy. This AI system can alert endoscopists in real-time to avoid missing abnormalities such as non-polypoid polyps during colonoscopy, improving the early detection of this disease.
C1 [Yamada, Masayoshi; Saito, Yutaka; Takamaru, Hiroyuki; Sakamoto, Taku] Natl Canc Ctr, Endoscopy Div, Tokyo, Japan.
   [Yamada, Masayoshi; Yamada, Shigemi; Kondo, Hiroko; Hamamoto, Ryuji] Natl Canc Ctr, Div Mol Modificat & Canc Biol, Tokyo, Japan.
   [Imaoka, Hitoshi; Saiko, Masahiro] NEC Corp Ltd, Biometr Res Labs, Kawasaki, Kanagawa, Japan.
   [Yamada, Shigemi; Kondo, Hiroko; Hamamoto, Ryuji] RIKEN, Adv Intelligence Project Ctr, Tokyo, Japan.
   [Sese, Jun] Natl Inst Adv Ind Sci & Technol, Artificial Intelligence Res Ctr, Tokyo, Japan.
   [Kuchiba, Aya; Shibata, Taro] Natl Canc Ctr, Biostat Div, Tokyo, Japan.
C3 National Cancer Center - Japan; National Cancer Center - Japan; NEC
   Corporation; RIKEN; National Institute of Advanced Industrial Science &
   Technology (AIST); National Cancer Center - Japan
RP Yamada, M (通讯作者)，Natl Canc Ctr, Endoscopy Div, Tokyo, Japan.; Yamada, M (通讯作者)，Natl Canc Ctr, Div Mol Modificat & Canc Biol, Tokyo, Japan.
EM masyamad@ncc.go.jp
RI Hamamoto, Ryuji/AAF-9600-2019
OI Hamamoto, Ryuji/0000-0002-2632-1334; Yamada,
   Masayoshi/0000-0003-3979-5560; Kuchiba, Aya/0000-0002-6786-3527
FU JST CREST [JPMJCR1689]; AMED [JP16ck0106028]
FX This work was supported by JST CREST Grant Number JPMJCR1689, Japan, and
   by AMED under Grant Number JP16ck0106028.
CR Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Benson AB, 2017, J NATL COMPR CANC NE, V15, P370, DOI 10.6004/jnccn.2017.0036
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   DeMarco DC, 2010, GASTROINTEST ENDOSC, V71, P542, DOI 10.1016/j.gie.2009.12.021
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Erhan D, 2014, COMPUTER VISION PATT
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Farris AB, 2008, AM J SURG PATHOL, V32, P30, DOI 10.1097/PAS.0b013e318093e40a
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gralnek IM, 2014, LANCET ONCOL, V15, P353, DOI 10.1016/S1470-2045(14)70020-8
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hori M, 2015, JPN J CLIN ONCOL, V45, P884, DOI 10.1093/jjco/hyv088
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kim Y.-D, 2016, ICLR
   le Clercq CMC, 2015, GASTROINTEST ENDOSC, V82, P325, DOI 10.1016/j.gie.2014.12.052
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leufkens AM, 2011, GASTROINTEST ENDOSC, V73, P480, DOI 10.1016/j.gie.2010.09.004
   Liu L, 2019, COMPUTER VISION PATT
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   McCarthy JF, 2004, ANN NY ACAD SCI, V1020, P239, DOI 10.1196/annals.1310.020
   Piegl L. A., 2005, Computer-Aided Design and Applications, V2, P685
   Redmon J, 2015, PROC CVPR IEEE, P779, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Riegler M, 2016, P 2016 14 INT WORKSH
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samadder NJ, 2014, GASTROENTEROLOGY, V146, P950, DOI 10.1053/j.gastro.2014.01.013
   Simonyan K, 2015, Arxiv
   Soetikno RM, 2008, JAMA-J AM MED ASSOC, V299, P1027, DOI 10.1001/jama.299.9.1027
   Stoffel EM, 2016, GASTROENTEROLOGY, V151, P870, DOI 10.1053/j.gastro.2016.07.010
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Waye JD, 2010, GASTROINTEST ENDOSC, V71, P551, DOI 10.1016/j.gie.2009.09.043
   WINAWER SJ, 1993, NEW ENGL J MED, V328, P901, DOI 10.1056/NEJM199304013281301
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 50
TC 99
Z9 100
U1 2
U2 11
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD OCT 8
PY 2019
VL 9
AR 14465
DI 10.1038/s41598-019-50567-5
PG 9
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA JC2IB
UT WOS:000489099500061
PM 31594962
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Horiuchi, Y
   Aoyama, K
   Tokai, Y
   Hirasawa, T
   Yoshimizu, S
   Ishiyama, A
   Yoshio, T
   Tsuchida, T
   Fujisaki, J
   Tada, T
AF Horiuchi, Yusuke
   Aoyama, Kazuharu
   Tokai, Yoshitaka
   Hirasawa, Toshiaki
   Yoshimizu, Shoichi
   Ishiyama, Akiyoshi
   Yoshio, Toshiyuki
   Tsuchida, Tomohiro
   Fujisaki, Junko
   Tada, Tomohiro
TI Convolutional Neural Network for Differentiating Gastric Cancer from
   Gastritis Using Magnified Endoscopy with Narrow Band Imaging
SO DIGESTIVE DISEASES AND SCIENCES
LA English
DT Article
DE Stomach neoplasm; Neural networks; Artificial intelligence; Endoscopy;
   Narrow band imaging
ID MUCOSAL RESECTION; MAGNIFYING ENDOSCOPY; DIAGNOSIS; LESIONS
AB Background Early detection of early gastric cancer (EGC) allows for less invasive cancer treatment. However, differentiating EGC from gastritis remains challenging. Although magnifying endoscopy with narrow band imaging (ME-NBI) is useful for differentiating EGC from gastritis, this skill takes substantial effort. Since the development of the ability to convolve the image while maintaining the characteristics of the input image (convolution neural network: CNN), allowing the classification of the input image (CNN system), the image recognition ability of CNN has dramatically improved. Aims To explore the diagnostic ability of the CNN system with ME-NBI for differentiating between EGC and gastritis. Methods A 22-layer CNN system was pre-trained using 1492 EGC and 1078 gastritis images from ME-NBI. A separate test data set (151 EGC and 107 gastritis images based on ME-NBI) was used to evaluate the diagnostic ability [accuracy, sensitivity, positive predictive value (PPV), and negative predictive value (NPV)] of the CNN system. Results The accuracy of the CNN system with ME-NBI images was 85.3%, with 220 of the 258 images being correctly diagnosed. The method's sensitivity, specificity, PPV, and NPV were 95.4%, 71.0%, 82.3%, and 91.7%, respectively. Seven of the 151 EGC images were recognized as gastritis, whereas 31 of the 107 gastritis images were recognized as EGC. The overall test speed was 51.83 images/s (0.02 s/image). Conclusions The CNN system with ME-NBI can differentiate between EGC and gastritis in a short time with high sensitivity and NPV. Thus, the CNN system may complement current clinical practice of diagnosis with ME-NBI.
C1 [Horiuchi, Yusuke; Tokai, Yoshitaka; Hirasawa, Toshiaki; Yoshimizu, Shoichi; Ishiyama, Akiyoshi; Yoshio, Toshiyuki; Tsuchida, Tomohiro; Fujisaki, Junko] Canc Inst Hosp, Dept Gastroenterol, Koto Ku, 3-10-6 Ariake, Tokyo 1358550, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] AI Med Serv Inc, Toshima Ku, Arai Bldg 2F,1-10-13 Minami Ikebukuro, Tokyo 1710022, Japan.
   [Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Minami Ku, 7-2-1 Bessho, Saitama 3360021, Japan.
C3 Japanese Foundation for Cancer Research
RP Horiuchi, Y (通讯作者)，Canc Inst Hosp, Dept Gastroenterol, Koto Ku, 3-10-6 Ariake, Tokyo 1358550, Japan.
EM yusuke.horiuchi@jfcr.or.jp; a.kazuharu@gmail.com;
   yoshitaka.tokai@jfcr.or.jp; toshiaki.hirasawa@jfcr.or.jp;
   shoichi.yoshimizu@jfcr.or.jp; akiyoshi.ishiyama@jfcr.or.jp;
   toshiyuki.yosio@jfer.or.jp; tomohiro.tsuchida@jfcr.or.jp;
   junko.fujisaki@jfcr.or.jp; tadatomo@ai-ms.com
RI Yoshio, Toshiyuki/ABC-4723-2021; Horiuchi, Yusuke/V-3881-2019
OI Yoshio, Toshiyuki/0000-0002-6546-0329; Horiuchi,
   Yusuke/0000-0001-8116-8152; Hirasawa, Toshiaki/0000-0002-6450-1934
FU Foundation for Promotion of Cancer Research in Japan
FX This work was supported in part by the Foundation for Promotion of
   Cancer Research in Japan.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ezoe Y, 2011, GASTROENTEROLOGY, V141, P2017, DOI 10.1053/j.gastro.2011.08.007
   Gotoda T, 1999, GASTROINTEST ENDOSC, V50, P560, DOI 10.1016/S0016-5107(99)70084-2
   Handelman GS, 2019, AM J ROENTGENOL, V212, P38, DOI 10.2214/AJR.18.20224
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Horiuchi Y, 2017, SURG ENDOSC, V31, P1906, DOI 10.1007/s00464-016-5192-3
   Horiuchi Y, 2016, GASTRIC CANCER, V19, P515, DOI 10.1007/s10120-015-0488-x
   Ishioka M, 2019, DIGEST ENDOSC, V31, pe34, DOI 10.1111/den.13306
   Japanese Gastr Canc Assoc, 2021, GASTRIC CANCER, V24, P1, DOI [10.1007/s10120-016-0622-4, 10.1007/s10120-020-01042-y]
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kimura K, 1969, ENDOSCOPY, V1, P87, DOI [10.1055/s-0028-1098086, DOI 10.1055/S-0028-1098086]
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Muto M, 2016, DIGEST ENDOSC, V28, P379, DOI 10.1111/den.12638
   Nakanishi H, 2017, ENDOSCOPY, V49, P957, DOI 10.1055/s-0043-111888
   Ohkuwa M, 2001, ENDOSCOPY, V33, P221, DOI 10.1055/s-2001-12805
   Ono H, 2001, GUT, V48, P225, DOI 10.1136/gut.48.2.225
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Yamamoto H, 2002, GASTROINTEST ENDOSC, V56, P507, DOI 10.1067/mge.2002.128108
NR 26
TC 64
Z9 67
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0163-2116
EI 1573-2568
J9 DIGEST DIS SCI
JI Dig. Dis. Sci.
PD MAY
PY 2020
VL 65
IS 5
BP 1355
EP 1363
DI 10.1007/s10620-019-05862-6
EA OCT 2019
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA LC7EO
UT WOS:000488939600001
PM 31584138
DA 2023-04-20
ER

PT J
AU Aoki, T
   Yamada, A
   Aoyama, K
   Saito, H
   Fujisawa, G
   Odawara, N
   Kondo, R
   Tsuboi, A
   Ishibashi, R
   Nakada, A
   Niikura, R
   Fujishiro, M
   Oka, S
   Ishihara, S
   Matsuda, T
   Nakahori, M
   Tanaka, S
   Koike, K
   Tada, T
AF Aoki, Tomonori
   Yamada, Atsuo
   Aoyama, Kazuharu
   Saito, Hiroaki
   Fujisawa, Gota
   Odawara, Nariaki
   Kondo, Ryo
   Tsuboi, Akiyoshi
   Ishibashi, Rei
   Nakada, Ayako
   Niikura, Ryota
   Fujishiro, Mitsuhiro
   Oka, Shiro
   Ishihara, Soichiro
   Matsuda, Tomoki
   Nakahori, Masato
   Tanaka, Shinji
   Koike, Kazuhiko
   Tada, Tomohiro
TI Clinical usefulness of a deep learning-based system as the first
   screening on small-bowel capsule endoscopy reading
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE artificial intelligence; capsule endoscopy; convolutional neural
   network; erosion or ulceration; reading-time
ID QUICKVIEW; SOFTWARE; MODE; TIME
AB Background and Aim To examine whether our convolutional neural network (CNN) system based on deep learning can reduce the reading time of endoscopists without oversight of abnormalities in the capsule-endoscopy reading process. Methods Twenty videos of the entire small-bowel capsule endoscopy procedure were prepared, each of which included 0-5 lesions of small-bowel mucosal breaks (erosions or ulcerations). At another institute, two reading processes were compared: (A) endoscopist-alone readings and (B) endoscopist readings after the first screening by the proposed CNN. In process B, endoscopists read only images detected by CNN. Two experts and four trainees independently read 20 videos each (10 for process A and 10 for process B). Outcomes were reading time and detection rate of mucosal breaks by endoscopists. Gold standard was findings at the original institute by two experts. Results Mean reading time of small-bowel sections by endoscopists was significantly shorter during process B (expert, 3.1 min; trainee, 5.2 min) compared to process A (expert, 12.2 min; trainee, 20.7 min) (P < 0.001). For 37 mucosal breaks, detection rate by endoscopists did not significantly decrease in process B (expert, 87%; trainee, 55%) compared to process A (expert, 84%; trainee, 47%). Experts detected all eight large lesions (>5 mm), but trainees could not, even when supported by the CNN. Conclusions Our CNN-based system for capsule endoscopy videos reduced the reading time of endoscopists without decreasing the detection rate of mucosal breaks. However, the reading level of endoscopists should be considered when using the system.
C1 [Aoki, Tomonori; Yamada, Atsuo; Fujisawa, Gota; Odawara, Nariaki; Kondo, Ryo; Ishibashi, Rei; Nakada, Ayako; Niikura, Ryota; Koike, Kazuhiko] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] AI Med Serv Inc, Tokyo, Japan.
   [Saito, Hiroaki; Matsuda, Tomoki; Nakahori, Masato] Sendai Kousei Hosp, Dept Gastroenterol, Sendai, Miyagi, Japan.
   [Tsuboi, Akiyoshi; Oka, Shiro; Tanaka, Shinji] Hiroshima Univ Hosp, Dept Endoscopy, Hiroshima, Japan.
   [Fujishiro, Mitsuhiro] Nagoya Univ, Grad Sch Med, Dept Gastroenterol & Hepatol, Nagoya, Aichi, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
C3 University of Tokyo; University of Tokyo; Sendai Kousei Hospital;
   Hiroshima University; Nagoya University
RP Aoki, T (通讯作者)，Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138655, Japan.
EM yamada-a@umin.ac.jp
RI 藤城, 光弘/AAN-3131-2020; Oka, Shiro/AAZ-8368-2021; SAITO,
   HIROAKI/HLH-2447-2023; Ishihara, Soichiro/AFK-1375-2022
OI SAITO, HIROAKI/0000-0002-0824-454X; Fujishiro,
   Mitsuhiro/0000-0002-4074-1140
CR Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Aoki T, 2018, J GASTROEN HEPATOL, V33, P1327, DOI 10.1111/jgh.14068
   Arieira C, 2018, GASTROINTEST ENDOSC, V87, pAB301
   Graham DY, 2005, CLIN GASTROENTEROL H, V3, P55, DOI 10.1016/S1542-3565(04)00603-2
   Hosoe N, 2012, CLIN RES HEPATOL GAS, V36, P66, DOI 10.1016/j.clinre.2011.09.009
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Koulaouzidis A, 2012, EUR J GASTROEN HEPAT, V24, P1099, DOI 10.1097/MEG.0b013e32835563ab
   Kyriakos N, 2012, EUR J GASTROEN HEPAT, V24, P1276, DOI 10.1097/MEG.0b013e32835718d2
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Shiotani A, 2012, J CLIN GASTROENTEROL, V46, pE92, DOI 10.1097/MCG.0b013e31824fff94
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
NR 14
TC 47
Z9 49
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD MAY
PY 2020
VL 32
IS 4
BP 585
EP 591
DI 10.1111/den.13517
EA OCT 2019
PG 7
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA LJ6VO
UT WOS:000488451800001
PM 31441972
OA Bronze
DA 2023-04-20
ER

PT J
AU Tsuboi, A
   Oka, S
   Aoyama, K
   Saito, H
   Aoki, T
   Yamada, A
   Matsuda, T
   Fujishiro, M
   Ishihara, S
   Nakahori, M
   Koike, K
   Tanaka, S
   Tada, T
AF Tsuboi, Akiyoshi
   Oka, Shiro
   Aoyama, Kazuharu
   Saito, Hiroaki
   Aoki, Tomonori
   Yamada, Atsuo
   Matsuda, Tomoki
   Fujishiro, Mitsuhiro
   Ishihara, Soichiro
   Nakahori, Masato
   Koike, Kazuhiko
   Tanaka, Shinji
   Tada, Tomohiro
TI Artificial intelligence using a convolutional neural network for
   automatic detection of small-bowel angioectasia in capsule endoscopy
   images
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE angioectasia; capsule endoscopy; convolutional neural network; deep
   learning; small bowel
ID VIDEO CAPSULE; BLEEDING DETECTION; PUSH-ENTEROSCOPY; CLASSIFICATION;
   VALIDATION; DIAGNOSIS; EFFICACY; DISEASE; PATIENT; LESIONS
AB Background and Aim Although small-bowel angioectasia is reported as the most common cause of bleeding in patients and frequently diagnosed by capsule endoscopy (CE) in patients with obscure gastrointestinal bleeding, a computer-aided detection method has not been established. We developed an artificial intelligence system with deep learning that can automatically detect small-bowel angioectasia in CE images. Methods We trained a deep convolutional neural network (CNN) system based on Single Shot Multibox Detector using 2237 CE images of angioectasia. We assessed its diagnostic accuracy by calculating the area under the receiver operating characteristic curve (ROC-AUC), sensitivity, specificity, positive predictive value, and negative predictive value using an independent test set of 10 488 small-bowel images, including 488 images of small-bowel angioectasia. Results The AUC to detect angioectasia was 0.998. Sensitivity, specificity, positive predictive value, and negative predictive value of CNN were 98.8%, 98.4%, 75.4%, and 99.9%, respectively, at a cut-off value of 0.36 for the probability score. Conclusions We developed and validated a new system based on CNN to automatically detect angioectasia in CE images. This may be well applicable to daily clinical practice to reduce the burden of physicians as well as to reduce oversight.
C1 [Tsuboi, Akiyoshi; Oka, Shiro; Tanaka, Shinji] Hiroshima Univ Hosp, Dept Endoscopy, Hiroshima, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] AI Med Serv Inc, Tokyo, Japan.
   [Aoki, Tomonori; Yamada, Atsuo; Koike, Kazuhiko] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Saito, Hiroaki; Matsuda, Tomoki; Nakahori, Masato] Sendai Kousei Hosp, Dept Gastroenterol, Sendai, Miyagi, Japan.
   [Fujishiro, Mitsuhiro] Nagoya Univ, Grad Sch Med, Dept Gastroenterol & Hepatol, Nagoya, Aichi, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
C3 Hiroshima University; University of Tokyo; University of Tokyo; Sendai
   Kousei Hospital; Nagoya University
RP Oka, S (通讯作者)，Hiroshima Univ Hosp, Dept Gastroenterol & Metab, Minami Ku, 1-2-3 Kasumi, Hiroshima 7348551, Japan.
EM oka4683@hiroshima-u.ac.jp
RI SAITO, HIROAKI/HLH-2447-2023; 藤城, 光弘/AAN-3131-2020; Ishihara,
   Soichiro/AFK-1375-2022; Oka, Shiro/AAZ-8368-2021
OI SAITO, HIROAKI/0000-0002-0824-454X; Fujishiro,
   Mitsuhiro/0000-0002-4074-1140; Oka, Shiro/0000-0002-1652-0743
CR Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Apostolopoulos P, 2006, ENDOSCOPY, V38, P1127, DOI 10.1055/s-2006-944736
   Apostolopoulos P, 2007, GASTROINTEST ENDOSC, V66, P1174, DOI 10.1016/j.gie.2007.06.058
   Bailey AA, 2006, AM J GASTROENTEROL, V101, P2237, DOI 10.1111/j.1572-0241.2006.00749.x
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   BHUTANI MS, 1995, GASTROINTEST ENDOSC, V42, P398, DOI 10.1016/S0016-5107(95)70038-2
   Delvaux M, 2004, ENDOSCOPY, V36, P1067, DOI 10.1055/s-2004-826034
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hartmann D, 2005, GASTROINTEST ENDOSC, V61, P826, DOI 10.1016/S0016-5107(05)00372-X
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Igawa A, 2015, BMC GASTROENTEROL, V15, DOI 10.1186/s12876-015-0337-8
   Imagawa H, 2011, SCAND J GASTROENTERO, V46, P1133, DOI 10.3109/00365521.2011.584899
   Imagawa H, 2011, GASTROINTEST ENDOSC, V73, P299, DOI 10.1016/j.gie.2010.10.016
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karagiannis S, 2006, WORLD J GASTROENTERO, V12, P5182
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li Feng, 2007, Gastroenterol Hepatol (N Y), V3, P777
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Meron GD, 2000, GASTROINTEST ENDOSC, V52, P817, DOI 10.1067/mge.2000.110204
   Minami-Kobayashi Y, 2016, SAUDI J GASTROENTERO, V22, P385, DOI 10.4103/1319-3767.191145
   Mylonaki M, 2003, GUT, V52, P1122, DOI 10.1136/gut.52.8.1122
   Noya F, 2017, IEEE ENG MED BIO, P3158, DOI 10.1109/EMBC.2017.8037527
   Pan G., 2009, Journal of Medical Engineering & Technology, V33, P575, DOI 10.1080/03091900903111974
   Pennazio M, 2004, GASTROENTEROLOGY, V126, P643, DOI 10.1053/j.gastro.2003.11.057
   ROSBOROUGH TK, 1978, AM J MED, V65, P96, DOI 10.1016/0002-9343(78)90698-8
   Schmit A, 1996, DIGEST DIS SCI, V41, P2348, DOI 10.1007/BF02100126
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Urbain D, 2006, ENDOSCOPY, V38, P408, DOI 10.1055/s-2005-921203
   Watari I, 2013, GASTROENT RES PRACT, V2013, DOI 10.1155/2013/915463
   Yamada A, 2015, WORLD J GASTROENTERO, V21, P7242, DOI 10.3748/wjg.v21.i23.7242
   Yano T, 2008, GASTROINTEST ENDOSC, V67, P169, DOI 10.1016/j.gie.2007.08.005
   Yung DE, 2017, ENDOSCOPY, V49, P258, DOI 10.1055/s-0042-122015
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 40
TC 69
Z9 73
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD MAR
PY 2020
VL 32
IS 3
BP 382
EP 390
DI 10.1111/den.13507
EA OCT 2019
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA KS3SS
UT WOS:000488451000001
PM 31392767
DA 2023-04-20
ER

PT J
AU Yasuda, T
   Hiroyasu, T
   Hiwa, S
   Okada, Y
   Hayashi, S
   Nakahata, Y
   Yasuda, Y
   Omatsu, T
   Obora, A
   Kojima, T
   Ichikawa, H
   Yagi, N
AF Yasuda, Takeshi
   Hiroyasu, Tomoyuki
   Hiwa, Satoru
   Okada, Yuto
   Hayashi, Sadanari
   Nakahata, Yuki
   Yasuda, Yuriko
   Omatsu, Tatsushi
   Obora, Akihiro
   Kojima, Takao
   Ichikawa, Hiroshi
   Yagi, Nobuaki
TI Potential of automatic diagnosis system with linked color imaging for
   diagnosis of Helicobacter pylori infection
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE artificial intelligence; Helicobacter pylori infection diagnosis; linked
   color imaging; machine learning; support vector machine
ID ARTIFICIAL-INTELLIGENCE; CANCER
AB Background and Aim It is necessary to establish universal methods for endoscopic diagnosis of Helicobacter pylori (HP) infection, such as computer-aided diagnosis. In the present study, we propose a multistage diagnosis algorithm for HP infection. Methods The aims of this study are to: (i) to construct an interpretable automatic diagnostic system using a support vector machine for HP infection; and (ii) to compare the diagnosis capability of our artificial intelligence (AI) system with that of endoscopists. Presence of an HP infection determined through linked color imaging (LCI) was learned through machine learning. Trained classifiers automatically diagnosed HP-positive and -negative patients examined using LCI. We retrospectively analyzed the new images from 105 consecutive patients; 42 were HP positive, 46 were post-eradication, and 17 were uninfected. Five endoscopic images per case taken from different areas were read into the AI system, and used in the HP diagnosis. Results Accuracy, sensitivity, specificity, positive predictive value, and negative predictive value of the diagnosis of HP infection using the AI system were 87.6%, 90.4%, 85.7%, 80.9%, and 93.1%, respectively. Accuracy of the AI system was higher than that of an inexperienced doctor, but there was no significant difference between the diagnosis of experienced physicians and the AI system. Conclusions The AI system can diagnose an HP infection with significant accuracy. There remains room for improvement, particularly for the diagnosis of post-eradication patients. By learning more images and considering a diagnosis algorithm for post-eradication patients, our new AI system will provide diagnostic support, particularly to inexperienced physicians.
C1 [Yasuda, Takeshi; Hayashi, Sadanari; Nakahata, Yuki; Yasuda, Yuriko; Omatsu, Tatsushi; Obora, Akihiro; Kojima, Takao; Yagi, Nobuaki] Asahi Univ Hosp, Dept Gastroenterol, 3-23 Hashimoto, Gifu 5008523, Japan.
   [Hiroyasu, Tomoyuki; Hiwa, Satoru; Ichikawa, Hiroshi] Doshisha Univ, Fac Life & Med Sci, Kyoto, Japan.
   [Okada, Yuto] Doshisha Univ, Grad Sch Life & Med Sci, Kyoto, Japan.
C3 Asahi University; Doshisha University; Doshisha University
RP Yasuda, T (通讯作者)，Asahi Univ Hosp, Dept Gastroenterol, 3-23 Hashimoto, Gifu 5008523, Japan.
EM t-yasuda@koto.kpu-m.ac.jp
RI Hiwa, Satoru/AAX-6939-2020
OI Hiwa, Satoru/0000-0001-6547-626X; Yasuda, Takeshi/0000-0002-7387-7511
CR CORREA P, 1992, CANCER RES, V52, P6735
   Dixon MF, 1996, AM J SURG PATHOL, V20, P1161, DOI 10.1097/00000478-199610000-00001
   Dohi O, 2016, ENDOSC INT OPEN, V4, pE800, DOI 10.1055/s-0042-109049
   Haruma K., 2017, KYOTO CLASSIFICATION
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Kimura K, 1969, ENDOSCOPY, V1, P87, DOI [10.1055/s-0028-1098086, DOI 10.1055/S-0028-1098086]
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Ono S, 2018, DIGESTION, V98, P222, DOI 10.1159/000489454
   Osawa H, 2018, CLIN ENDOSC, V51, P513, DOI 10.5946/ce.2018.132
   Shichijo S, 2019, SCAND J GASTROENTERO, V54, P158, DOI 10.1080/00365521.2019.1577486
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Sugano K, 2015, GUT, V64, P1353, DOI 10.1136/gutjnl-2015-309252
   Takeda T, 2020, DIGESTION, V101, P598, DOI 10.1159/000501534
   Uchiyama K, 2017, J CROHNS COLITIS, P1
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
NR 20
TC 31
Z9 31
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD MAR
PY 2020
VL 32
IS 3
BP 373
EP 381
DI 10.1111/den.13509
EA OCT 2019
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA KS3SS
UT WOS:000488450800001
PM 31398276
OA Bronze
DA 2023-04-20
ER

PT J
AU Ding, Z
   Shi, HY
   Zhang, H
   Meng, LJ
   Fan, MK
   Han, CQ
   Zhang, K
   Ming, FH
   Xie, XP
   Liu, H
   Liu, J
   Lin, R
   Hou, XH
AF Ding, Zhen
   Shi, Huiying
   Zhang, Hao
   Meng, Lingjun
   Fan, Mengke
   Han, Chaoqun
   Zhang, Kun
   Ming, Fanhua
   Xie, Xiaoping
   Liu, Hao
   Liu, Jun
   Lin, Rong
   Hou, Xiaohua
TI Gastroenterologist-Level Identification of Small-Bowel Diseases and
   Normal Variants by Capsule Endoscopy Using a Deep-Learning Model
SO GASTROENTEROLOGY
LA English
DT Article
DE Artificial Intelligence; Imaging; Intestine; Lesion
ID RETENTION RATES; COMPLETION; DIAGNOSIS
AB BACKGROUND & AIMS: Capsule endoscopy has revolutionized investigation of the small bowel. However, this technique produces a video that is 8-10 hours long, so analysis is time consuming for gastroenterologists. Deep convolutional neural networks (CNNs) can recognize specific images among a large variety. We aimed to develop a CNN-based algorithm to assist in the evaluation of small bowel capsule endoscopy (SB-CE) images. METHODS: We collected 113,426,569 images from 6970 patients who had SB-CE at 77 medical centers from July 2016 through July 2018. A CNN-based auxiliary reading model was trained to differentiate abnormal from normal images using 158,235 SB-CE images from 1970 patients. Images were categorized as normal, inflammation, ulcer, polyps, lymphangiectasia, bleeding, vascular disease, protruding lesion, lymphatic follicular hyperplasia, diverticulum, parasite, and other. The model was further validated in 5000 patients (no patient was overlap with the 1970 patients in the training set); the same patients were evaluated by conventional analysis and CNN-based auxiliary analysis by 20 gastroenterologists. If there was agreement in image categorization between the conventional analysis and CNN model, no further evaluation was performed. If there was disagreement between the conventional analysis and CNN model, the gastroenterologists re-evaluated the image to confirm or reject the CNN categorization. RESULTS: In the SB-CE images from the validation set, 4206 abnormalities in 3280 patients were identified after final consensus evaluation. The CNN-based auxiliary model identified abnormalities with 99.88% sensitivity in the per-patient analysis (95% CI, 99.67-99.96) and 99.90% sensitivity in the per-lesion analysis (95% CI, 99.74-99.97). Conventional reading by the gastroenterologists identified abnormalities with 74.57% sensitivity (95% CI, 73.05-76.03) in the per-patient analysis and 76.89% in the per-lesion analysis (95% CI, 75.58-78.15). The mean reading time per patient was 96.6 +/- 22.53 minutes by conventional reading and 5.9 +/- 2.23 minutes by CNN-based auxiliary reading (P < .001). CONCLUSIONS: We validated the ability of a CNN-based algorithm to identify abnormalities in SB-CE images. The CNN-based auxiliary model identified abnormalities with higher levels of sensitivity and significantly shorter reading times than conventional analysis by gastroenterologists. This algorithm provides an important tool to help gastroenterologists analyze SB-CE images more efficiently and more accurately.
C1 [Ding, Zhen; Shi, Huiying; Meng, Lingjun; Fan, Mengke; Han, Chaoqun; Zhang, Kun; Xie, Xiaoping; Liu, Jun; Lin, Rong; Hou, Xiaohua] Huazhong Univ Sci & Technol, Dept Gastroenterol, Union Hosp, Tongji Med Coll, Wuhan 430022, Hubei, Peoples R China.
   [Zhang, Hao; Ming, Fanhua; Liu, Hao] Ankon Med Technol Co Ltd, Shanghai, Peoples R China.
C3 Huazhong University of Science & Technology
RP Lin, R (通讯作者)，Huazhong Univ Sci & Technol, Dept Gastroenterol, Union Hosp, Tongji Med Coll, Wuhan 430022, Hubei, Peoples R China.
EM selinalin35@hotmail.com
OI lin, rong/0000-0001-9463-8942
FU National Natural Science Foundation of China [81770539, 81330014,
   81572428, 81272656]; National Key Research and Development program of
   China [2017YFC0110003]; Ankon
FX This study was supported by the National Natural Science Foundation of
   China (nos. 81770539, 81330014, 81572428, and 81272656), the National
   Key Research and Development program of China (no. 2017YFC0110003), and
   in part by Ankon. Wuhan Union Hospital and Ankon collaborated in this
   study.
CR Aktas H, 2012, BEST PRACT RES CL GA, V26, P209, DOI 10.1016/j.bpg.2012.03.007
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Costamagna G, 2002, GASTROENTEROLOGY, V123, P999, DOI 10.1053/gast.2002.35988
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Flemming J, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000010148
   Gerson LB, 2015, AM J GASTROENTEROL, V110, P1265, DOI 10.1038/ajg.2015.246
   Hu GC, 2011, CHIN J DIG ENDOSC, V28, P394
   Kaiming He XZ, DEEP RESIDUAL LEARNI
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Liao ZA, 2010, GASTROINTEST ENDOSC, V71, P280, DOI 10.1016/j.gie.2009.09.031
   Lim YJ, 2015, CLIN ENDOSC, V48, P399, DOI 10.5946/ce.2015.48.5.399
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Niv Y, 2005, DIGEST DIS SCI, V50, P2121, DOI 10.1007/s10620-005-3017-7
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Rondonotti E, 2018, ENDOSCOPY, V50, P423, DOI 10.1055/a-0576-0566
   Saurin JC, 2018, ENDOSC INT OPEN, V6, pE616, DOI 10.1055/a-0587-4788
   Saurin JC, 2012, DIGEST LIVER DIS, V44, P477, DOI 10.1016/j.dld.2011.12.021
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Viazis N, 2004, GASTROINTEST ENDOSC, V60, P534, DOI 10.1016/S0016-5107(04)01879-6
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wei W, 2008, AM J GASTROENTEROL, V103, P77, DOI 10.1111/j.1572-0241.2007.01633.x
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P43, DOI 10.1080/17474124.2017.1257384
   Zhang Y, 2018, J DIGEST DIS, V19, P33, DOI 10.1111/1751-2980.12568
   Zhao AJ, 2018, GASTROINTEST ENDOSC, V88, P466, DOI 10.1016/j.gie.2018.05.003
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 27
TC 135
Z9 155
U1 12
U2 85
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD OCT
PY 2019
VL 157
IS 4
BP 1044
EP +
DI 10.1053/j.gastro.2019.06.025
PG 16
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA IY7WH
UT WOS:000486605300029
PM 31251929
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Esmaeili, N
   Illanes, A
   Boese, A
   Davaris, N
   Arens, C
   Friebe, M
AF Esmaeili, Nazila
   Illanes, Alfredo
   Boese, Axel
   Davaris, Nikolaos
   Arens, Christoph
   Friebe, Michael
TI Novel automated vessel pattern characterization of larynx contact
   endoscopic video images
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Contact endoscopy; Larynx; Vascular pattern; Feature extraction;
   Classification
ID CANCEROUS LESIONS; CLASSIFICATION
AB Purpose Contact endoscopy (CE) is a minimally invasive procedure providing real-time information about the cellular and vascular structure of the superficial layer of laryngeal mucosa. This method can be combined with optical enhancement methods such as narrow band imaging (NBI). However, these techniques have some problems like subjective interpretation of vascular patterns and difficulty in differentiation between benign and malignant lesions. We propose a novel automated approach for vessel pattern characterization of larynx CE + NBI images in order to solve these problems. Methods In this approach, five indicators were computed to characterize the level of vessel's disorder based on evaluation of consistency of gradient and two-dimensional curvature analysis and then 24 features were extracted from these indicators. The method evaluated the ability of the extracted features to classify CE + NBI images based on the vascular pattern and based on the laryngeal lesions. Four datasets were generated from 32 patients involving 1485 images. The classification scenarios were implemented using four supervised classifiers. Results For classification of CE + NBI images based on the vascular pattern, polykernel support vector machine (SVM), SVM with radial basis function (RBF), k-nearest neighbor (kNN), and random forest (RF) show an accuracy of 97%, 96%, 96%, and 96%, respectively. For the classification based on the histopathology, Polykernel SVM showed an accuracy of 84%, 86% and 84%, RBF SVM showed an accuracy of 81%, 87% and 83%, kNN showed an accuracy of 89%, 87%, 91%, RF showed an accuracy of 90%, 88% and 91% for classification between benign histopathologies, between malignant histopathologies and between benign and malignant lesions, respectively. Conclusion These promising results show that the proposed method could solve the problem of subjectivity in interpretation of vascular patterns and also support the clinicians in the early detection of benign, pre-malignant and malignant lesions.
C1 [Esmaeili, Nazila; Illanes, Alfredo; Boese, Axel; Friebe, Michael] Otto von Guericke Univ, Inst Med Technol, INKA, Magdeburg, Germany.
   [Davaris, Nikolaos; Arens, Christoph] Magdeburg Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Magdeburg, Germany.
C3 Otto von Guericke University; University Hospital Magdeburg
RP Esmaeili, N (通讯作者)，Otto von Guericke Univ, Inst Med Technol, INKA, Magdeburg, Germany.
EM nazila.esmaeili@ovgu.de
RI Boese, Axel/AAA-8476-2020
OI Boese, Axel/0000-0002-5874-7145; Illanes, Alfredo/0000-0002-0118-0483
FU Federal Ministry of Education and Research (BMBF) [03IPT7100X]; Federal
   Ministry of Education and Research (BMBF) (EFRE) [ZS/2016/09//81061/IK
   01/2015]
FX This work was financially supported by the Federal Ministry of Education
   and Research (BMBF) in context of the 'INKA' project (Grand Number
   03IPT7100X and by EFRE funding in context of the ego.-INKUBATOR program
   (ZS/2016/09//81061/IK 01/2015)).
CR ANDREA M, 1995, ACTA OTO-LARYNGOL, V115, P314, DOI 10.3109/00016489509139318
   Arens C, 2003, ANN OTO RHINOL LARYN, V112, P113, DOI 10.1177/000348940311200203
   Arens C, 2016, EUR ARCH OTO-RHINO-L, V273, P1207, DOI 10.1007/s00405-015-3851-y
   Barbalata C, 2016, IEEE J BIOMED HEALTH, V20, P322, DOI 10.1109/JBHI.2014.2374975
   Boese Axel, 2018, Current Directions in Biomedical Engineering, V4, P75, DOI 10.1515/cdbme-2018-0019
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Carta F, 2016, EUR ARCH OTO-RHINO-L, V273, P1895, DOI 10.1007/s00405-015-3698-2
   Dalai N., 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Hermann Simon, 2003, MULTIGRID ANAL CURVA
   Hsu C. W., 2003, PRACTICAL GUIDE SUPP
   Mannelli G, 2016, CRIT REV ONCOL HEMAT, V106, P64, DOI 10.1016/j.critrevonc.2016.07.004
   Manriquez A.I., 2006, IFAC P, V39, P93
   Markou K, 2013, HIPPOKRATIA, V17, P313
   Mishra A., 2012, J LARYNGOL VOICE, V2, P53, DOI [10.4103/2230-9748.106978, DOI 10.4103/2230-9748.106978]
   Mishra Awadhesh Kumar, 2014, Med J Armed Forces India, V70, P257, DOI 10.1016/j.mjafi.2014.04.007
   Moccia S, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.3.034502
   Nanni L, 2018, APPL COMPUTING INFOR
   Peterson L.E., 2009, SCHOLARPEDIA, V4, P1883
   Piazza C, 2011, ACTA OTORHINOLARYNGO, V31, P70
   Puxeddu R., 2018, ENHANCED CONTACT END
   Puxeddu R, 2015, LARYNGOSCOPE, V125, P1600, DOI 10.1002/lary.25124
   Ring M, 2016, PATTERN RECOGN LETT, V84, P107, DOI 10.1016/j.patrec.2016.08.013
   Stefanescu DC, 2016, REV CHIM-BUCHAREST, V67, P1558
   Syarif I., 2016, TELKOMNIKA, V14, P1502, DOI DOI 10.12928/TELKOMNIKA.V14I4.3956
   Szeto C, 2011, J ONCOL, V2011, DOI 10.1155/2011/196302
   Tarnawski W, 2008, ADV MED SCI-POLAND, V53, P221, DOI 10.2478/v10039-008-0046-4
   Turkmen HI, 2015, COMPUT BIOL MED, V62, P76, DOI 10.1016/j.compbiomed.2015.02.001
   Yang SW, 2012, LARYNGOSCOPE, V122, P2754, DOI 10.1002/lary.23629
NR 29
TC 8
Z9 9
U1 2
U2 4
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD OCT
PY 2019
VL 14
IS 10
SI SI
BP 1751
EP 1761
DI 10.1007/s11548-019-02034-9
PG 11
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA JE8RH
UT WOS:000490957000013
PM 31352673
OA hybrid, Green Published
DA 2023-04-20
ER

PT J
AU Hwang, M
   Wang, D
   Jiang, WC
   Pan, X
   Fu, DL
   Hwang, KS
   Ding, KF
AF Hwang, Maxwell
   Wang, Da
   Jiang, Wei-Cheng
   Pan, Xiang
   Fu, Dongliang
   Hwang, Kao-Shing
   Ding, Kefeng
TI An Adaptive Regularization Approach to Colonoscopic Polyp Detection
   Using a Cascaded Structure of Encoder-Decoders
SO INTERNATIONAL JOURNAL OF FUZZY SYSTEMS
LA English
DT Article
DE Convolution neural networks; Encoder-decoder networks; Fuzzy logic
ID COLORECTAL-CANCER; MISS RATE; PARTICIPATION; PREVENTION; INCREASES;
   VISION
AB This research aims to segment colonoscopic images by automatically extracting polyp features by exploiting the strengths of convolution neural networks (CNN). The proposed model employs deep learning and adaptive regularization techniques. The model is structurally composed of two cascaded encoder-decoder networks, each of which is constructed by four CNN layers and two full connection layers. The front model is built on backpropagation learning for segmenting a colonoscopic polyp image. The output images from the precedent hetero-encoder are regarded as corrupted labeled images, especially during the time period close to the end of learning, and are selectively fed into the successive auto-encoder for denoising learning to enhance its discriminative power and relieve the problem of a lack of labeled data for medical image tasks. The performance of the proposed model can be further improved by a simple fuzzy logic approach setting the regularization parameter in the loss function. The proposed method utilizes features learned from some open medical datasets and our own collected dataset. The performance of the proposed architecture is compared with a state-of-the-art network. The evaluation shows the performances of the proposed method are consistent across all the datasets and often outperform the state-of-art model.
C1 [Hwang, Maxwell; Wang, Da; Pan, Xiang; Fu, Dongliang; Ding, Kefeng] Zhejiang Univ, Sch Med, Affiliated Hosp 2, Dept Colorectal Surg, Hangzhou, Zhejiang, Peoples R China.
   [Hwang, Maxwell; Wang, Da; Pan, Xiang; Fu, Dongliang; Ding, Kefeng] Zhejiang Univ, Affiliated Hosp 2, China Natl Minist Educ, Canc Inst,Key Lab Canc Prevent & Intervent, Hangzhou, Zhejiang, Peoples R China.
   [Hwang, Maxwell; Wang, Da; Pan, Xiang; Fu, Dongliang; Ding, Kefeng] Zhejiang Univ, Affiliated Hosp 2, Key Lab Mol Biol Med Sci, Sch Med, Hangzhou, Zhejiang, Peoples R China.
   [Jiang, Wei-Cheng] Tunghai Univ, Dept Elect Engn, Taichung, Taiwan.
   [Hwang, Kao-Shing] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Tunghai
   University; National Sun Yat Sen University
RP Ding, KF (通讯作者)，Zhejiang Univ, Sch Med, Affiliated Hosp 2, Dept Colorectal Surg, Hangzhou, Zhejiang, Peoples R China.; Ding, KF (通讯作者)，Zhejiang Univ, Affiliated Hosp 2, China Natl Minist Educ, Canc Inst,Key Lab Canc Prevent & Intervent, Hangzhou, Zhejiang, Peoples R China.; Ding, KF (通讯作者)，Zhejiang Univ, Affiliated Hosp 2, Key Lab Mol Biol Med Sci, Sch Med, Hangzhou, Zhejiang, Peoples R China.
EM himax26@126.com; wangda0618@zju.edu.cn; jiangwc@thu.edu.tw;
   panx@zju.edu.cn; 3120102932@zju.edu.cn; hwang@ccu.edu.tw;
   dingkefeng@zju.edu.cn
RI Hwang, Kao-Shing/AAD-2644-2020
OI Hwang, Kao-Shing/0000-0001-9234-4836
FU Key Technology Research and Development Program of Zhejiang Province
   [2017C03017]; National Natural Science Foundation of China [81672916,
   LQ17H160008]; National Key R&D Program of China [2017YFC0908200]
FX This work was supported in part by the Key Technology Research and
   Development Program of Zhejiang Province (2017C03017), the National
   Natural Science Foundation of China (81672916) and (LQ17H160008), and
   the National Key R&D Program of China (2017YFC0908200).
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Chatfield K., 2014, RETURN DEVIL DETAILS
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   El Khatib A, 2015, IEEE ENG MED BIO, P2669, DOI 10.1109/EMBC.2015.7318941
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin HF, 2019, INT J FUZZY SYST, V21, P1026, DOI 10.1007/s40815-018-00604-8
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Pan W, 2019, INT J FUZZY SYST, V21, P95, DOI 10.1007/s40815-018-0535-y
   Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383157
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2015, I S BIOMED IMAGING, P101, DOI 10.1109/ISBI.2015.7163826
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Silva J, 2013, IEEE ENG MED BIO, P5711, DOI 10.1109/EMBC.2013.6610847
   Simonyan K, 2015, Arxiv
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 32
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1562-2479
EI 2199-3211
J9 INT J FUZZY SYST
JI Int. J. Fuzzy Syst.
PD OCT
PY 2019
VL 21
IS 7
BP 2091
EP 2101
DI 10.1007/s40815-019-00694-y
PG 11
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA JI6HB
UT WOS:000493567300009
DA 2023-04-20
ER

PT J
AU Khan, MA
   Rashid, M
   Sharif, M
   Javed, K
   Akram, T
AF Khan, Muhammad Attique
   Rashid, Muhammad
   Sharif, Muhammad
   Javed, Kashif
   Akram, Tallha
TI Classification of gastrointestinal diseases of stomach from WCE using
   improved saliency-based method and discriminant features selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WCE; Active contour; Disease segmentation; Pixel-based fusion; Feature
   extraction; Reduction; Classification
ID COLORECTAL-CANCER STATISTICS; CAPSULE ENDOSCOPY IMAGES; WIRELESS;
   RECOGNITION
AB Wireless capsule endoscopy (WCE) is a new imaging procedure that is used to record internal conditions of gastrointestinal tract for medical diagnosis. However, due to the presence of bulk of WCE image data, it becomes difficult for the physician to investigate it thoroughly. Therefore, considering aforementioned constraint, lately gastrointestinal diseases are identified by computer-aided methods and with better classification accuracy. In this research, a new computer-based diagnosis method is proposed for the detection and classification of gastrointestinal diseases from WCE images. The proposed approach comprises of four fundamentalsteps:1) HSI color transformation before implementing automatic active contour segmentation; 2) implementation of a novel saliency-based method in YIQ color space; 3) fusion of images using proposed maximizing a posterior probability method; 4) fusion of extracted features, calculated using SVD, LBP, and GLCM, prior to final classification step. We perform our simulations on our own collected dataset - containing total 9000 samples of ulcer, bleeding and healthy. To prove the authenticity of proposed work, list of statistical measures is considered including classification accuracy, FNR, sensitivity, AUC, and Time. Further, a fair comparison of state-of-the-art classifiers is also provided which will be giving readers a deep inside of classifier's selection for this application. Simulation results clearly reveal that the proposed method shows improved performance in terms of segmentation and classification accuracy.
C1 [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci & Engn, Museum Rd, Taxila, Pakistan.
   [Khan, Muhammad Attique; Rashid, Muhammad; Sharif, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Wah Cantt, Pakistan.
   [Javed, Kashif] NUST, Sch Mech & Mfg Engn, H-12, Islamabad, Pakistan.
   [Akram, Tallha] COMSATS Univ Islamabad, Dept Elect & Comp Engn, Wah Cantt, Pakistan.
C3 NITEC University; COMSATS University Islamabad (CUI); National
   University of Sciences & Technology - Pakistan; COMSATS University
   Islamabad (CUI)
RP Akram, T (通讯作者)，COMSATS Univ Islamabad, Dept Elect & Comp Engn, Wah Cantt, Pakistan.
EM tallha@ciitwah.edu.pk
RI Sharif, Muhammad/ACD-2598-2022; Khan, Dr. Muhammad
   Attique/AAX-2644-2021; khan, sajid/HGE-2406-2022; Sharif,
   Muhammad/AAB-8376-2022; Javed, Kashif/AAF-8436-2020
OI Sharif, Muhammad/0000-0002-7258-8400; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Rashid, Muhammad/0000-0002-2557-6845
CR Akram T., 2018, J AMB INTEL HUM COMP, P1, DOI [10.1007/s12652-018-1051-5, DOI 10.1007/S12652-018-1051-5]
   Ali H, 2018, COMPUT METHODS PROG
   [Anonymous], MICROSC RES TECH
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Charfi S, 2017, ADV TECHN SIGN IM PR
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Duan QC, 2016, OPTIK, V127, P7418, DOI 10.1016/j.ijleo.2016.05.027
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Imran M, 2018, 2018 INTERNATIONAL CONFERENCE ON ENGINEERING & EMERGING TECHNOLOGIES (ICEET), P1
   Jeon G, 2013, INT J CONTROL AUTOM, V6, P157
   Khan M.A., 2019, MICROSC RES TECH
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   KHAN SA, 2019, MICROSC RES TECH
   Kundu A, 2017, REG 10 C TENCON 2017
   Kundu A, 2017, HUM TECHN C R10 HTC
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Maghsoudi O.H., 2018, ARXIV180202232
   Maghsoudi OH., 2016, SIGN PROC MED BIOL S
   Mergener Klaus, 2008, Gastroenterol Hepatol (N Y), V4, P107
   Pei S-C, 2017, IM PROC ICIP 2017 IE
   Ribeiro MG, 2019, EXPERT SYST APPL, V120, P262, DOI 10.1016/j.eswa.2018.11.034
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Sharif N, 2018, J OCUL PHARMACOL TH, V34, P1, DOI 10.1089/jop.2017.29037.int
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI 10.3322/caac.21220
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI 10.3322/caac.21395
   Sivakumar P, 2019, CONNECT TISSUE RES, V60, P62, DOI 10.1080/03008207.2018.1500557
   STEWART GW, 1993, SIAM REV, V35, P551, DOI 10.1137/1035134
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Xue Z, 2003, PATTERN RECOGN, V36, P2819, DOI 10.1016/S0031-3203(03)00181-X
   Yuan Y, 2017, IEEE T CYBERNETICS
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang SW, 2016, NEUROCOMPUTING, V205, P341, DOI 10.1016/j.neucom.2016.04.034
NR 39
TC 34
Z9 34
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27743
EP 27770
DI 10.1007/s11042-019-07875-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000044
DA 2023-04-20
ER

PT J
AU Li, XY
   Jiang, F
   Guo, Y
   Jin, ZD
   Wang, YY
AF Li, Xinyi
   Jiang, Fei
   Guo, Yi
   Jin, Zhendong
   Wang, Yuanyuan
TI Computer-aided diagnosis of gastrointestinal stromal tumors: a radiomics
   method on endoscopic ultrasound image
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Radiomics; Gastrointestinal stromal tumors; Endoscopic ultrasound image;
   Computer-aided diagnosis
AB Purpose The purpose of our study is to propose a preoperative computer-aided diagnosis system based on a radiomics method to differentiate gastrointestinal stromal tumors (GISTs) of the higher-risk group (HRG) from those of the lower-risk group (LRG) on endoscopic ultrasound (EUS) images. Materials and method Gastro-EUS (G-EUS) images of four different risk level GISTs were collected from 19 hospitals. The datasheet included 168 case HRG GISTs and 747 case LRG GISTs. A radiomics method with image segmentation, feature extraction, feature selection and classification was developed. Here 439 radiomics features were firstly extracted, and then, the least absolute shrinkage selection operator (lasso) model with a tenfold cross-validation and 31 bootstraps was used to reduce the dimension of feature sets. Finally, random forest was applied to establish the classification model. Results The proposed model differentiated 32 case HRG GISTs from 149 case LRG GISTs. Result for the testing set achieved the area under the receiver operating characteristic curve of 0.839, the accuracy of 0.823, the sensitivity of 0.813 and the specificity of 0.826. Conclusion The model could increase preoperative diagnostic accuracy and provide a valuable reference for the doctors.
C1 [Li, Xinyi; Guo, Yi; Wang, Yuanyuan] Fudan Univ, Dept Elect Engn, Shanghai, Peoples R China.
   [Jiang, Fei; Jin, Zhendong] Changhai Hosp, Dept Gastroenterol, Shanghai, Peoples R China.
C3 Fudan University; Naval Medical University
RP Guo, Y; Wang, YY (通讯作者)，Fudan Univ, Dept Elect Engn, Shanghai, Peoples R China.
EM guoyi@fudan.edu.cn; yywang@fudan.edu.cn
RI Li, xinyi/HJG-4670-2022; Wang, Yu/GZL-9655-2022; wangwangwang,
   yuanyaunyuan/HHN-6432-2022; Lv, Yuanjie/AER-0767-2022; Wang,
   Yuan/HHC-1520-2022; li, xinyi/GWZ-8941-2022; li, xin/HHS-9461-2022
FU National Natural Science Foundation of China [61871135, 81830058];
   Science and Technology Commission of Shanghai Municipality [18511102904]
FX This work was supported by the National Natural Science Foundation of
   China (Grants 61871135 and 81830058) and the Science and Technology
   Commission of Shanghai Municipality (Grant 18511102904).
CR Aerts HJWL, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5006
   Agaimy A, 2010, INT J CLIN EXP PATHO, V3, P461
   [Anonymous], 2012, NCCN GUIDELINE SOFT
   Blackstein ME, 2006, CAN J GASTROENTEROL, V20, P157, DOI 10.1155/2006/434761
   Blom G., 1994, PROBLEMS SNAPSHOTS W
   Demetri G, 2011, DEVITA HELLMAN ROSEN
   Fletcher CDM, 2002, HUM PATHOL, V33, P459, DOI 10.1053/hupa.2002.123545
   Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169
   Guo Y, 2018, CLIN BREAST CANCER, V18, pE335, DOI 10.1016/j.clbc.2017.08.002
   Hwang JH, 2006, GASTROENTEROLOGY, V130, P2217, DOI 10.1053/j.gastro.2006.04.033
   Miettinen M, 2005, AM J SURG PATHOL, V29, P52, DOI 10.1097/01.pas.0000146010.92933.de
   Saito T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118432
   SANTOSA F, 1986, SIAM J SCI STAT COMP, V7, P1307, DOI 10.1137/0907087
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Xu J, 2015, INT SURG, V100, P860, DOI 10.9738/INTSURG-D-14-00178.1
   Yu JH, 2017, EUR RADIOL, V27, P3509, DOI 10.1007/s00330-016-4653-3
NR 16
TC 9
Z9 9
U1 5
U2 17
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD OCT
PY 2019
VL 14
IS 10
SI SI
BP 1635
EP 1645
DI 10.1007/s11548-019-01993-3
PG 11
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA JE8RH
UT WOS:000490957000003
PM 31049803
DA 2023-04-20
ER

PT J
AU Wang, P
   Berzin, TM
   Brown, JRG
   Bharadwaj, S
   Becq, A
   Xiao, X
   Liu, PX
   Li, LP
   Song, Y
   Zhang, D
   Li, Y
   Xu, GR
   Tu, MT
   Liu, XG
AF Wang, Pu
   Berzin, Tyler M.
   Brown, Jeremy Romek Glissen
   Bharadwaj, Shishira
   Becq, Aymeric
   Xiao, Xun
   Liu, Peixi
   Li, Liangping
   Song, Yan
   Zhang, Di
   Li, Yi
   Xu, Guangre
   Tu, Mengtian
   Liu, Xiaogang
TI Real-time automatic detection system increases colonoscopic polyp and
   adenoma detection rates: a prospective randomised controlled study
SO GUT
LA English
DT Article
ID COLORECTAL-CANCER; MISS RATES; INATTENTIONAL BLINDNESS; SCREENING
   COLONOSCOPY; WIDE-ANGLE; TASK-FORCE; IMPACT; RISK; MULTICENTER;
   ENDOSCOPY
AB Objective The effect of colonoscopy on colorectal cancer mortality is limited by several factors, among them a certain miss rate, leading to limited adenoma detection rates (ADRs). We investigated the effect of an automatic polyp detection system based on deep learning on polyp detection rate and ADR.
   Design In an open, non-blinded trial, consecutive patients were prospectively randomised to undergo diagnostic colonoscopy with or without assistance of a real-time automatic polyp detection system providing a simultaneous visual notice and sound alarm on polyp detection. The primary outcome was ADR.
   Results Of 1058 patients included, 536 were randomised to standard colonoscopy, and 522 were randomised to colonoscopy with computer-aided diagnosis. The artificial intelligence (AI) system significantly increased ADR (29.1%vs20.3%, p<0.001) and the mean number of adenomas per patient (0.53vs0.31, p<0.001). This was due to a higher number of diminutive adenomas found (185vs102; p<0.001), while there was no statistical difference in larger adenomas (77vs58, p=0.075). In addition, the number of hyperplastic polyps was also significantly increased (114vs52, p<0.001).
   Conclusions In a low prevalent ADR population, an automatic polyp detection system during colonoscopy resulted in a significant increase in the number of diminutive adenomas detected, as well as an increase in the rate of hyperplastic polyps. The cost-benefit ratio of such effects has to be determined further.
C1 [Wang, Pu; Xiao, Xun; Liu, Peixi; Li, Liangping; Song, Yan; Zhang, Di; Li, Yi; Xu, Guangre; Tu, Mengtian; Liu, Xiaogang] Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Sichuan, Peoples R China.
   [Berzin, Tyler M.; Brown, Jeremy Romek Glissen; Bharadwaj, Shishira; Becq, Aymeric] Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Boston, MA 02215 USA.
   [Berzin, Tyler M.; Brown, Jeremy Romek Glissen; Bharadwaj, Shishira; Becq, Aymeric] Harvard Med Sch, Boston, MA 02115 USA.
C3 Sichuan Provincial People's Hospital; Harvard University; Beth Israel
   Deaconess Medical Center; Harvard University; Harvard Medical School
RP Liu, XG (通讯作者)，Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Sichuan, Peoples R China.
EM Gary.samsph@gmail.com
RI Tu, Mengtian/AAU-6816-2020
OI Wang, Pu/0000-0002-1234-309X; Berzin, Tyler/0000-0002-4364-6210; Glissen
   Brown, Jeremy/0000-0002-7204-7241
CR Adler A, 2012, CLIN GASTROENTEROL H, V10, P155, DOI 10.1016/j.cgh.2011.10.026
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   American Cancer Society, 2017, CANC FACTS FIG 2017
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Bai Y, 2018, ENDOSCOPY, V50, P128, DOI 10.1055/s-0043-119213
   Bailey CE, 2015, JAMA SURG, V150, P17, DOI 10.1001/jamasurg.2014.1756
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Burke Carol, 2017, Gastroenterol Hepatol (N Y), V13, P1
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai B, 2015, ONCOL LETT, V9, P2073, DOI 10.3892/ol.2015.3005
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chin M, 2016, WORLD J GASTROENTERO, V22, P9642, DOI 10.3748/wjg.v22.i43.9642
   Cohen J, 2017, J CLIN GASTROENTEROL, V51, P818, DOI 10.1097/MCG.0000000000000695
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Doubeni CA, 2013, ANN INTERN MED, V158, P312, DOI 10.7326/0003-4819-158-5-201303050-00003
   Halpern Z, 2015, ENDOSCOPY, V47, P238, DOI 10.1055/s-0034-1391437
   Horton N, 2016, AM J GASTROENTEROL, V111, P1330, DOI 10.1038/ajg.2016.273
   Jia H, 2017, AM J GASTROENTEROL, V112, P568, DOI 10.1038/ajg.2016.501
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Leufkens AM, 2011, GASTROINTEST ENDOSC, V73, P480, DOI 10.1016/j.gie.2010.09.004
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Memmert D, 2010, J GEN PSYCHOL, V137, P129, DOI 10.1080/00221301003645061
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Rex DK, 2003, AM J GASTROENTEROL, V98, P2000, DOI 10.1016/S0002-9270(03)00625-7
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2006, AM J GASTROENTEROL, V101, P2866, DOI 10.1111/j.1572-0241.2006.00905.x
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rogart JN, 2008, AM J GASTROENTEROL, V103, P2841, DOI 10.1111/j.1572-0241.2008.02085.x
   Sanchez W, 2004, AM J GASTROENTEROL, V99, P1941, DOI 10.1111/j.1572-0241.2004.40569.x
   Siddiki HA, 2017, GASTROINTEST ENDOSC, V85, pAB84, DOI 10.1016/j.gie.2017.03.116
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wolfe JM, 2006, VIS COGN, V14, P749, DOI 10.1080/13506280500195292
   Xu Y, 2018, SCAND J GASTROENTERO, V53, P365, DOI 10.1080/00365521.2018.1433230
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhou Haiping, 2018, Zhonghua Wei Chang Wai Ke Za Zhi, V21, P678
NR 48
TC 349
Z9 372
U1 17
U2 64
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0017-5749
EI 1468-3288
J9 GUT
JI Gut
PD OCT
PY 2019
VL 68
IS 10
BP 1813
EP 1819
DI 10.1136/gutjnl-2018-317500
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Gastroenterology & Hepatology
GA JM8XL
UT WOS:000496491100011
PM 30814121
OA hybrid, Green Published
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Xiong, H
   Lin, PL
   Yu, JG
   Ye, J
   Xiao, LC
   Tao, Y
   Jiang, ZB
   Lin, W
   Liu, MY
   Xu, JJ
   Hu, WJ
   Lu, YW
   Liu, HF
   Li, YQ
   Zheng, YQ
   Yang, HD
AF Xiong, Hao
   Lin, Peiliang
   Yu, Jin-Gang
   Ye, Jin
   Xiao, Lichao
   Tao, Yuan
   Jiang, Zebin
   Lin, Wei
   Liu, Mingyue
   Xu, Jingjing
   Hu, Wenjie
   Lu, Yuewen
   Liu, Huaifeng
   Li, Yuanqing
   Zheng, Yiqing
   Yang, Haidi
TI Computer-aided diagnosis of laryngeal cancer via deep learning based on
   laryngoscopic images
SO EBIOMEDICINE
LA English
DT Article
ID CONVOLUTIONAL NEURAL-NETWORK; CLASSIFICATION
AB Objective: To develop a deep convolutional neural network (DCNN) that can automatically detect laryngeal cancer (LCA) in laryngoscopic images.
   Methods: A DCNN-based diagnostic system was constructed and trained using 13,721 laryngoscopic images of LCA, precancerous laryngeal lesions (PRELCA), benign laryngeal tumors (BLT) and normal tissues (NORM) from 2 tertiary hospitals in China, including 2293 from 206 LCA subjects, 1807 from 203 PRELCA subjects, 6448 from 774 BLT subjects and 3191 from 633 NORM subjects. An independent test set of 1176 laryngoscopic images from other 3 tertiary hospitals in China, including 132 from 44 LCA subjects, 129 from 43 PRELCA subjects, 504 from 168 BLT subjects and 411 from 137 NORM subjects, was applied to the constructed DCNN to evaluate its performance against experienced endoscopists.
   Results: The DCCN achieved a sensitivity of 0.731, a specificity of 0.922, an AUC of 0.922, and the overall accuracy of 0.867 for detecting LCA and PRELCA among all lesions and normal tissues. When compared to human experts in an independent test set, the DCCN's performance on detection of LCA and PRELCA achieved a sensitivity of 0.720, a specificity of 0.948, an AUC of 0.953, and the overall accuracy of 0.897, which was comparable to that of an experienced human expert with 10-20 years of work experience. Moreover, the overall accuracy of DCNN for detection of LCA was 0.773, which was also comparable to that of an experienced human expert with 10-20 years of work experience and exceeded the experts with less than 10 years of work experience.
   Conclusions: The DCNN has high sensitivity and specificity for automated detection of LCA and PRELCA from BLT and NORM in laryngoscopic images. This novel and effective approach facilitates earlier diagnosis of early LCA, resulting in improved clinical outcomes and reducing the burden of endoscopists. (C) 2019 The Authors. Published by Elsevier B.V.
C1 [Xiong, Hao; Lin, Peiliang; Zheng, Yiqing; Yang, Haidi] Sun Yat Sen Univ, Sun Yat Sen Mem Hosp, Dept Otolaryngol, 107 West Yan Jiang Rd, Guangzhou 510120, Guangdong, Peoples R China.
   [Xiong, Hao; Lin, Peiliang; Zheng, Yiqing; Yang, Haidi] Sun Yat Sen Univ, Inst Hearing & Speech Language Sci, Guangzhou, Guangdong, Peoples R China.
   [Yu, Jin-Gang; Xiao, Lichao; Li, Yuanqing] South China Univ Technol, Sch Automat Sci & Engn, 381 Wushan Rd, Guangzhou 510641, Guangdong, Peoples R China.
   [Ye, Jin; Liu, Mingyue] Sun Yat Sen Univ, Affiliated Hosp 3, Dept Otolaryngol, Guangzhou, Guangdong, Peoples R China.
   [Tao, Yuan] Peking Univ, Dept Otolaryngol, Shenzhen Hosp, Beijing, Peoples R China.
   [Jiang, Zebin] Puning Peoples Hosp, Dept Otolaryngol, Jieyang, Peoples R China.
   [Lin, Wei] Taizhou First People S Hosp, Dept Otolaryngol, Taizhou, Peoples R China.
   [Xu, Jingjing; Hu, Wenjie; Lu, Yuewen; Liu, Huaifeng; Zheng, Yiqing; Yang, Haidi] Sun Yat Sen Univ, Xinhua Coll, Dept Hearing & Speech Language Sci, Guangzhou, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; South China University
   of Technology; Sun Yat Sen University; Peking University; Sun Yat Sen
   University
RP Zheng, YQ; Yang, HD (通讯作者)，Sun Yat Sen Univ, Sun Yat Sen Mem Hosp, Dept Otolaryngol, 107 West Yan Jiang Rd, Guangzhou 510120, Guangdong, Peoples R China.; Li, YQ (通讯作者)，South China Univ Technol, Sch Automat Sci & Engn, 381 Wushan Rd, Guangzhou 510641, Guangdong, Peoples R China.
EM auyqli@scut.edu.cn; zhengyiq@mail.sysu.edu.cn; yanghd@mail.sysu.edu.cn
RI xu, jingcheng/HJZ-3124-2023; 熊, 浩/HNI-9551-2023; xu, jing/GRR-8698-2022
FU National Key R&D Program of China [2017YFB1002505]; Guangzhou Science
   and Technology Program [201904010299, 201903010088]; National Natural
   Science Foundation of China [81570916, 81771018, 61703166, 81873699,
   81970887]
FX This work was supported by National Key R&D Program of China
   (2017YFB1002505), Guangzhou Science and Technology Program (201904010299
   and 201903010088) and National Natural Science Foundation of China
   (81570916, 81771018, 61703166 and 81873699, 81970887).
CR Barbalata C, 2016, IEEE J BIOMED HEALTH, V20, P322, DOI 10.1109/JBHI.2014.2374975
   Chmelik J, 2018, MED IMAGE ANAL, V49, P76, DOI 10.1016/j.media.2018.07.008
   De Vito A, 2017, CLIN OTOLARYNGOL, V42, P347, DOI 10.1111/coa.12728
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hay EA, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006628
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khosravi P, 2018, EBIOMEDICINE, V27, P317, DOI 10.1016/j.ebiom.2017.12.026
   Kraft M, 2016, HEAD NECK-J SCI SPEC, V38, P15, DOI 10.1002/hed.23838
   Liu ZY, 2016, SCI REP-UK, V6, DOI 10.1038/srep20410
   Marioni G, 2006, CANCER TREAT REV, V32, P504, DOI 10.1016/j.ctrv.2006.07.002
   Rose JM, 2011, HUM MOL GENET, V20, P16, DOI 10.1093/hmg/ddq428
   Sempere LF, 2006, J EXP ZOOL PART B, V306B, P575, DOI 10.1002/jez.b.21118
   Strodthoff N, 2019, PHYSIOL MEAS, V40, DOI 10.1088/1361-6579/aaf34d
   Sun CL, 2017, OTOLARYNG HEAD NECK, V156, P589, DOI 10.1177/0194599816685701
   Verikas A, 2007, COMPUT METH PROG BIO, V85, P257, DOI 10.1016/j.cmpb.2006.11.002
   Yang Y, 2017, CLIN OTOLARYNGOL, V42, P38, DOI 10.1111/coa.12654
NR 18
TC 40
Z9 42
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2352-3964
J9 EBIOMEDICINE
JI EBioMedicine
PD OCT
PY 2019
VL 48
BP 92
EP 99
DI 10.1016/j.ebiom.2019.08.075
PG 8
WC Medicine, General & Internal; Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine; Research & Experimental Medicine
GA JJ0CR
UT WOS:000493830800018
PM 31594753
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Ye, SP
   Nedzvedz, A
   Ye, FF
   Ablameyko, S
AF Ye, Shiping
   Nedzvedz, A.
   Ye, Fangfang
   Ablameyko, S.
TI Segmentation and Feature Extraction of Endoscopic Images for Making
   Diagnosis of Acute Appendicitis
SO PATTERN RECOGNITION AND IMAGE ANALYSIS
LA English
DT Article
DE endoscopic images segmentation; acute appendicitis diagnosis
AB In recent years, digital endoscopy has established as key technology for medical screenings and minimally invasive surgery. Endoscopy image processing techniques have been applied to the diagnosis of diseases. In this paper, an effective approach is proposed to process endoscopic images to detect acute appendicitis. For this purpose, we first introduced image enhancement techniques that allow us to improve quality of endoscopic image for further processing. A simple and effective image segmentation technique was developed to detect vessels and vermiform appendix. The hierarchical set of features have been extracted for detecting acute appendicitis. It includes geometrical, colorimetric, densitometric, and topological features. For each appendicitis feature discriminant indexes have been introduced for diagnosis. This method has achieved good results in clinical application.
C1 [Ye, Shiping; Ye, Fangfang] Zhejiang Shuren Univ, Hangzhou 310015, Peoples R China.
   [Nedzvedz, A.; Ablameyko, S.] Belarusian State Univ, Minsk 220030, BELARUS.
   [Nedzvedz, A.; Ablameyko, S.] Natl Acad Sci, United Inst Informat Problems, Minsk 220020, BELARUS.
C3 Zhejiang Shuren University; Belarusian State University; National
   Academy of Sciences of Belarus (NASB); United Institute of Informatics
   Problems of the National Academy of Sciences of Belarus
RP Ye, SP (通讯作者)，Zhejiang Shuren Univ, Hangzhou 310015, Peoples R China.
EM zisruysp@163.com; nedzveda@tut.by; cliney@zju.edu.cn; ablameyko@bsu.by
RI Fangfang, Ye/ABB-5578-2021
OI Ye, Shiping/0000-0002-9771-7168; Ablameyko, Sergey/0000-0001-9404-1206
FU National High-end Foreign Experts Program [GDW20183300463]; Joint Fund
   of Zhejiang Natural Science Foundation Committee [LSY19F010001,
   LGJ18F020001, LGJ19F020002]; Zhejiang Society of Mathematical Medicine
   [LSY19F010001, LGJ18F020001, LGJ19F020002]; projects of "Development and
   experimental research of descriptive methods for automatisation of
   biomedical images analysis" [BRFFI F18R-218]
FX This work is supported by the National High-end Foreign Experts Program
   (GDW20183300463) and Joint Fund of Zhejiang Natural Science Foundation
   Committee and Zhejiang Society of Mathematical Medicine (nos.
   LSY19F010001, LGJ18F020001, LGJ19F020002), This research was supported
   by projects of BRFFI F18R-218 "Development and experimental research of
   descriptive methods for automatisation of biomedical images analysis".
CR Aksenov SV, 2018, SOVREM TEHNOL MED, V10, P7, DOI 10.17691/stm2018.10.2.01
   Alexandrov V.B., 1998, ENDOSKOPICHESKAYA KH, V4, P4
   [Anonymous], 2010, SUPPORT WORLDWIDE TE
   Asari KV, 1999, IEEE T MED IMAGING, V18, P345, DOI 10.1109/42.768843
   Barrado JMD, 2009, BIBLIOTEC HIST, P1
   Bergen T, 2016, INT J COMPUT ASS RAD, V11, P397, DOI 10.1007/s11548-015-1273-3
   Daekeun You, 2014, 2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P289, DOI 10.1109/BIBM.2014.6999170
   Deeba F, 2016, IEEE IJCNN, P4650, DOI 10.1109/IJCNN.2016.7727810
   Dhanalakshmi M., 2012, INT J WISDOM BASED C, V2, P1
   Gono K, 2015, CLIN ENDOSC, V48, P476, DOI 10.5946/ce.2015.48.6.476
   Gschwandtner M., 2010, 10 IEEE INT C INF TE, P1, DOI [10.1109/itab.2010.5687708, DOI 10.1109/ITAB.2010.5687708]
   Hafner M, 2009, PATTERN ANAL APPL, V12, P407, DOI 10.1007/s10044-008-0136-8
   Kallemeyn Nicole A, 2007, Iowa Orthop J, V27, P52
   Kamphuis G., 2016, J CANC SCI THERAPY, V8, P71, DOI [10.4172/1948-5956.1000394, DOI 10.4172/1948-5956.1000394]
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kriger A G, 2000, Khirurgiia (Mosk), P14
   Laves MH, 2019, INT J COMPUT ASS RAD, V14, P483, DOI 10.1007/s11548-018-01910-0
   Liedlgruber M., 2011, 17 INT C DIG SIGN PR, P1, DOI [10.1109/ICDSP.2011.6004900, DOI 10.1109/ICDSP.2011.6004900]
   Lin BX, 2014, I S BIOMED IMAGING, P1295, DOI 10.1109/ISBI.2014.6868114
   Nedz'ved' A. M., 1998, Pattern Recognition and Image Analysis, V8, P436
   Nedzved A., 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P349, DOI 10.1109/3DTV.2008.4547880
   Stehle Thomas., 2009, BILDVERARBEITUNG MED, P142, DOI [10.1007/978-3-540-93860-6_29, DOI 10.1007/978-3-540-93860-6_29]
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Togashi K, 2009, GASTROINTEST ENDOSC, V69, P734, DOI 10.1016/j.gie.2008.10.063
   Weibel T, 2012, PATTERN RECOGN, V45, P4138, DOI 10.1016/j.patcog.2012.05.023
   Wimmer G, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.034504
   Xue ZY, 2015, PROC SPIE, V9418, DOI 10.1117/12.2081033
NR 27
TC 2
Z9 2
U1 0
U2 2
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 1054-6618
EI 1555-6212
J9 PATTERN RECOGN IMAGE
JI Pattern Recogn. Image Anal.
PD OCT
PY 2019
VL 29
IS 4
BP 738
EP 749
DI 10.1134/S1054661819040205
PG 12
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA WE5FD
UT WOS:000705650500017
DA 2023-04-20
ER

PT J
AU Wang, S
   Xing, YX
   Zhang, L
   Gao, HW
   Zhang, H
AF Wang, Sen
   Xing, Yuxiang
   Zhang, Li
   Gao, Hewei
   Zhang, Hao
TI Deep Convolutional Neural Network for Ulcer Recognition in Wireless
   Capsule Endoscopy: Experimental Feasibility and Optimization
SO COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE
LA English
DT Article
AB Wireless capsule endoscopy (WCE) has developed rapidly over the last several years and now enables physicians to examine the gastrointestinal tract without surgical operation. However, a large number of images must be analyzed to obtain a diagnosis. Deep convolutional neural networks (CNNs) have demonstrated impressive performance in different computer vision tasks. Thus, in this work, we aim to explore the feasibility of deep learning for ulcer recognition and optimize a CNN-based ulcer recognition architecture for WCE images. By analyzing the ulcer recognition task and characteristics of classic deep learning networks, we propose a HAnet architecture that uses ResNet-34 as the base network and fuses hyper features from the shallow layer with deep features in deeper layers to provide final diagnostic decisions. 1,416 independent WCE videos are collected for this study. The overall test accuracy of our HAnet is 92.05%, and its sensitivity and specificity are 91.64% and 92.42%, respectively. According to our comparisons of F1, F2, and ROC-AUC, the proposed method performs better than several off-the-shelf CNN models, including VGG, DenseNet, and Inception-ResNet-v2, and classical machine learning methods with handcrafted features for WCE image classification. Overall, this study demonstrates that recognizing ulcers in WCE images via the deep CNN method is feasible and could help reduce the tedious image reading work of physicians. Moreover, our HAnet architecture tailored for this problem gives a fine choice for the design of network structure.
C1 [Wang, Sen; Xing, Yuxiang; Zhang, Li; Gao, Hewei] Tsinghua Univ, Minist Educ, Key Lab Particle & Radiat Imaging, Beijing, Peoples R China.
   [Wang, Sen; Xing, Yuxiang; Zhang, Li; Gao, Hewei] Tsinghua Univ, Dept Engn Phys, Beijing 100084, Peoples R China.
   [Zhang, Hao] Ankon Technol Co Ltd, Shanghai, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Zhang, L (通讯作者)，Tsinghua Univ, Minist Educ, Key Lab Particle & Radiat Imaging, Beijing, Peoples R China.; Zhang, L (通讯作者)，Tsinghua Univ, Dept Engn Phys, Beijing 100084, Peoples R China.
EM wangsen14@mails.tsinghua.edu.cn; xingyx@mail.tsinghua.edu.cn;
   zli@tsinghua.edu.cn; hwgao@tsinghua.edu.cn; hao.zhang@ankoninc.com.cn
RI Xing, Yuxiang/H-4143-2012
OI Wang, Sen/0000-0001-6948-3264
FU Ankon Technologies Co. Ltd. (Wuhan, Shanghai, China); National Key
   Scientific Instrument and Equipment Development Project [2013YQ160439];
   Zhangjiang National Innovation Demonstration Zone Special Development
   Fund [ZJ2017-ZD-001]
FX Hao Zhang is currently an employee of Ankon Technologies Co., Ltd.
   (Wuhan, Shanghai, China). He helped in providing WCE data and organizing
   annotation. The authors would like to thank Ankon Technologies Co., Ltd.
   (Wuhan, Shanghai, China) for providing the WCE data (ankoninc.com.cn).
   They would also like to thank the participating engineers of Ankon
   Technologies Co., Ltd., for their thoughtful support and cooperation.
   This work was supported by a Research Project from Ankon Technologies
   Co. Ltd. (Wuhan, Shanghai, China), the National Key Scientific
   Instrument and Equipment Development Project under Grant no.
   2013YQ160439, and the Zhangjiang National Innovation Demonstration Zone
   Special Development Fund under Grant no. ZJ2017-ZD-001.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Charisis V., 2012, NEW ADV BASIC CLIN G, DOI [10.5772/32940, DOI 10.5772/32940]
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He K., 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Kundu AK, 2017, IEEE REG 10 HUMANIT, P734
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BU, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P2326, DOI 10.1109/ROBIO.2009.5420455
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liao ZA, 2016, CLIN GASTROENTEROL H, V14, P1266, DOI 10.1016/j.cgh.2016.05.013
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Lin T.Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Redmon J., 2017, PROC CVPR IEEE, P7263, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]
   Ribeiro E., 2016, COMPUT MATH METHOD M, V2016, P16, DOI DOI 10.1155/2016/6584725.ARTICLE
   Roth HR., 2017, HIERARCHICAL 3D FULL
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shamsudhin N, 2017, MED PHYS, V44, pE91, DOI [10.1002/mp.12299, 10.1002/mp.12446]
   Shen Lin, 2013, Lancet Oncol, V14, pe535, DOI 10.1016/S1470-2045(13)70436-4
   Shvets AA, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P612, DOI 10.1109/ICMLA.2018.00098
   Simonyan K, 2015, Arxiv
   Szegedy C., 2017, AAAI, V4, P12, DOI [DOI 10.1609/AAAI.V31I1.11231, DOI 10.1016/J.PATREC.2014.01.008]
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Turan M., 2018, UNSUPERVISED ODOMETR
   Wang CL, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293303
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ye M L, 2018, SELF SUPERVISED SIAM
   Yu LC, 2012, INT C PATT RECOG, P45
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou B., 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319
NR 44
TC 30
Z9 32
U1 2
U2 13
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1748-670X
EI 1748-6718
J9 COMPUT MATH METHOD M
JI Comput. Math. Method Med.
PD SEP 18
PY 2019
VL 2019
AR 7546215
DI 10.1155/2019/7546215
PG 14
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA JB7WM
UT WOS:000488776000001
PM 31641370
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Chao, WL
   Manickavasagan, H
   Krishna, SG
AF Chao, Wei-Lun
   Manickavasagan, Hanisha
   Krishna, Somashekar G.
TI Application of Artificial Intelligence in the Detection and
   Differentiation of Colon Polyps: A Technical Review for Physicians
SO DIAGNOSTICS
LA English
DT Review
DE colonoscopy; colon polyp; artificial intelligence; computer-aided
   diagnosis; machine learning
ID COMPUTER-AIDED DIAGNOSIS; COLORECTAL-CANCER; MISS RATE; TASK-FORCE;
   SYSTEM; CLASSIFICATION; PREVENTION; LESIONS; RISK; COLONOSCOPY
AB Research in computer-aided diagnosis (CAD) and the application of artificial intelligence (AI) in the endoscopic evaluation of the gastrointestinal tract is novel. Since colonoscopy and detection of polyps can decrease the risk of colon cancer, it is recommended by multiple national and international societies. However, the procedure of colonoscopy is performed by humans where there are significant interoperator and interpatient variations, and hence, the risk of missing detection of adenomatous polyps. Early studies involving CAD and AI for the detection and differentiation of polyps show great promise. In this appraisal, we review existing scientific aspects of AI in CAD of colon polyps and discuss the pitfalls and future directions for advancing the science. This review addresses the technical intricacies in a manner that physicians can comprehend to promote a better understanding of this novel application.
C1 [Chao, Wei-Lun] Cornell Univ, Dept Comp Sci, New York, NY 14853 USA.
   [Chao, Wei-Lun] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Manickavasagan, Hanisha; Krishna, Somashekar G.] Ohio State Univ, Wexner Med Ctr, Div Gastroenterol Hepatol & Nutr, Columbus, OH 43210 USA.
C3 Cornell University; University System of Ohio; Ohio State University;
   University System of Ohio; Ohio State University
RP Krishna, SG (通讯作者)，Ohio State Univ, Wexner Med Ctr, Div Gastroenterol Hepatol & Nutr, Columbus, OH 43210 USA.
EM Somashekar.krishna@osumc.edu
RI Krishna, Somashekar G/V-2593-2019; Krishna, Somashekar G/AAH-7145-2019
OI Krishna, Somashekar G/0000-0001-5748-7890; Krishna, Somashekar
   G/0000-0001-5748-7890
CR Abu-Mostafa YS, 2012, LEARNING FROM DATA, V4
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Bressler B, 2004, GASTROENTEROLOGY, V127, P452, DOI 10.1053/j.gastro.2004.05.032
   Burt RW, 2013, J NATL COMPR CANC NE, V11, P1538, DOI 10.6004/jnccn.2013.0180
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Division of Cancer Prevention and Control, COL CANC STAT
   Djinbachian Roupen, 2019, Curr Treat Options Gastroenterol, V17, P99, DOI 10.1007/s11938-019-00220-x
   Doubeni CA, 2013, ANN INTERN MED, V158, P312, DOI 10.7326/0003-4819-158-5-201303050-00003
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   LeCun Y., 1995, HDB BRAIN THEORY NEU, V3361, P1995, DOI 10.5555/303568.303704
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lin T Y, 2017, ARXIV170802002, DOI DOI 10.1109/ICCV.2017.324
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Patel SG, 2014, CLIN GASTROENTEROL H, V12, P7, DOI 10.1016/j.cgh.2013.04.027
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Rex DK, 2009, AM J GASTROENTEROL, V104, P739, DOI 10.1038/ajg.2009.104
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Than M, 2015, ANN GASTROENTEROL, V28, P94
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 46
TC 22
Z9 23
U1 0
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD SEP
PY 2019
VL 9
IS 3
AR 99
DI 10.3390/diagnostics9030099
PG 8
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA JA6WS
UT WOS:000487983100005
PM 31434208
OA Green Submitted, Green Published, gold
DA 2023-04-20
ER

PT J
AU Gu, Y
   Shen, ML
   Yang, J
   Yang, GZ
AF Gu, Yun
   Shen, Mali
   Yang, Jie
   Yang, Guang-Zhong
TI Reliable Label-Efficient Learning for Biomedical Image Recognition
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Deep neural networks; active learning; diverse-level experts
ID ACTIVE VISUAL RECOGNITION; CLASSIFICATION
AB The use of deep neural networks for biomedical image analysis requires a sufficient number of labeled datasets. To acquire accurate labels as the gold standard, multiple observers with specific expertise are required for both annotation and proofreading. This process can be time-consuming and labor-intensive, making high-quality, and large-annotated biomedical datasets difficult. To address this problem, we propose a deep active learning framework that enables the active selection of both informative queries and reliable experts. To measure the uncertainty of the unlabeled data, a dropout-based strategy is integrated with a similarity criterion for both data selection and random error elimination. To select the reliable labelers, we adopt an expertise estimator to learn the expertise levels of labelers via offline-testing and online consistency evaluation. The proposed method is applied to classification tasks on two types of medical images including confocal endomicroscopy images and gastrointestinal endoscopic images. The annotations are acquired from multiple labelers with diverse levels of expertise. The experiments demonstrate the efficiency and promising performance of the proposed method compared to a set of baseline methods.
C1 [Gu, Yun; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   [Gu, Yun; Yang, Jie] Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai 200240, Peoples R China.
   [Gu, Yun; Shen, Mali; Yang, Guang-Zhong] Imperial Coll London, Hamlyn Ctr Robot Surg, London SW7 2AZ, England.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Imperial
   College London
RP Yang, J (通讯作者)，Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.; Yang, J (通讯作者)，Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai 200240, Peoples R China.
EM jieyang@sjtu.edu.cn
OI Gu, Yun/0000-0002-4199-0675
FU NSFC, China [61572315]; Committee of Science and Technology, Shanghai,
   China [17JC1403000]; 973 Plan, China [2015CB856004]; UK Engineering and
   Physical Sciences Research Council [EP/N019318/1, EP/N027132/1,
   EP/N022521/1]; Engineering and Physical Sciences Research Council
   [EP/N019318/1] Funding Source: researchfish; EPSRC [EP/N027132/1,
   EP/J021199/1, EP/N022521/1, EP/P012779/1, EP/N019318/1] Funding Source:
   UKRI
FX This research is partly supported by NSFC, China (No: 61572315),
   Committee of Science and Technology, Shanghai, China No. 17JC1403000 and
   973 Plan, China (No. 2015CB856004). UK Engineering and Physical Sciences
   Research Council (EP/N019318/1, EP/N027132/1 and EP/N022521/1).
CR Ambati V., 2010, THESIS
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Caprara A, 1996, MATH PROGRAM, V74, P221, DOI 10.1007/BF02592196
   Chen H, 2017, MED IMAGE ANAL, V36, P135, DOI 10.1016/j.media.2016.11.004
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhungel Neeraj, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P106, DOI 10.1007/978-3-319-46723-8_13
   Erdogan TK, 2018, 2ND INTERNATIONAL CONGRESS OF NURSING (ICON-2018), P1
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Gal Y, 2017, PR MACH LEARN RES, V70
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gaur U, 2016, IEEE IMAGE PROC, P1943, DOI 10.1109/ICIP.2016.7532697
   Gu Y., 2017, INT C MEDICAL IMAGE, P64
   He K., 2016, P IEEE C COMP VIS PA
   Hua G, 2018, IEEE T PATTERN ANAL, V40, P582, DOI 10.1109/TPAMI.2017.2682082
   Huang S.-J, 2017, P 26 INT JOINT C ART, P1879, DOI DOI 10.24963/IJCAI.2017/261
   Kading C., 2016, CONT LEARN DEEP NETW
   Kingma DP., 2015, 3 INT C LEARN REPR I
   Lin CH, 2016, AAAI CONF ARTIF INTE, P1845
   Lin L, 2018, IEEE T PATTERN ANAL, V40, P7, DOI 10.1109/TPAMI.2017.2652459
   Long CJ, 2015, IEEE I CONF COMP VIS, P2839, DOI 10.1109/ICCV.2015.325
   Long CJ, 2016, INT J COMPUT VISION, V116, P136, DOI 10.1007/s11263-015-0834-9
   Long CJ, 2013, IEEE I CONF COMP VIS, P3000, DOI 10.1109/ICCV.2013.373
   Ochs RA, 2007, MED IMAGE ANAL, V11, P315, DOI 10.1016/j.media.2007.03.004
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Stanitsas P, 2017, IEEE IMAGE PROC, P1367
   Wang KZ, 2017, IEEE T CIRC SYST VID, V27, P2591, DOI 10.1109/TCSVT.2016.2589879
   Xie X., 2018, ARXIV180406670
   Xue WF, 2018, MED IMAGE ANAL, V43, P54, DOI 10.1016/j.media.2017.09.005
   Yan S., 2016, NEURIPS, P2128
   Yang L., 2017, INT C MED IM COMP CO, P399, DOI DOI 10.1007/978-3-319-66179-7_46
   Ye ML, 2016, MED IMAGE ANAL, V30, P144, DOI 10.1016/j.media.2015.10.003
   ZHANG C, 2015, ADV NEURAL INFORM PR, P703
   Zhou ZW, 2017, PROC CVPR IEEE, P4761, DOI 10.1109/CVPR.2017.506
   Zhu Y, 2014, PROCEEDINGS OF 2014 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (10TH), VOL I, P360
NR 35
TC 2
Z9 2
U1 0
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD SEP
PY 2019
VL 66
IS 9
BP 2423
EP 2432
DI 10.1109/TBME.2018.2889915
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA IT1BK
UT WOS:000482580800001
PM 30596566
DA 2023-04-20
ER

PT J
AU Hosoe, N
   Takabayashi, K
   Ogata, H
   Kanai, T
AF Hosoe, Naoki
   Takabayashi, Kaoru
   Ogata, Haruhiko
   Kanai, Takanori
TI Capsule endoscopy for small-intestinal disorders: Current status
SO DIGESTIVE ENDOSCOPY
LA English
DT Review
DE Crohn's disease; double-balloon enteroscopy; obscure gastrointestinal
   bleeding; small intestine; video capsule endoscopy
ID SUSPECTED BLOOD INDICATOR; BOWEL TRANSIT-TIME; DEVICE-ASSISTED
   ENTEROSCOPY; VIDEO-CAPSULE; DIAGNOSTIC YIELD; PATENCY CAPSULE;
   CLINICAL-PRACTICE; COMPLETION RATE; BLUE MODE; EUROPEAN-SOCIETY
AB Small-bowel capsule endoscopy (SBCE) is used widely because of its non-invasive and patient-friendly nature. SBCE can visualize entire small-intestinal mucosa and facilitate detection of small-intestinal abnormalities. In this review article, we focus on the current status of SBCE. Several platforms for SBCE are available worldwide. Third-generation SBCE (PillCam (R) SB3) has a high-resolution camera equipped with an adaptive frame rate system. Several software modes have been developed to reduce the reading time for capsule endoscopy and to minimize the possibility of missing lesions. The main complication of SBCE is capsule retention. Thus, the main contraindication for SBCE is known or suspected gastrointestinal obstruction unless intestinal patency is proven. Possible indications for SBCE are obscure gastrointestinal bleeding, Crohn's disease, small-intestinal polyps and tumors, and celiac disease. Colon capsule endoscopy (CCE) can observe inflamed colonic mucosa non-invasively, and allows for the continuous and non-invasive observation of the entire intestinal tract (pan-endoscopy). Recently, application of CCE as pan-enteric endoscopy for inflammatory bowel diseases (including Crohn's disease) has been reported. In the near future, reading for CE will be assisted by artificial intelligence, and reading CE videos for long periods will not be required.
C1 [Hosoe, Naoki; Takabayashi, Kaoru; Ogata, Haruhiko] Keio Univ, Ctr Diagnost & Therapeut Endoscopy, Tokyo, Japan.
   [Kanai, Takanori] Keio Univ, Sch Med, Dept Internal Med, Div Gastroenterol & Hepatol, Tokyo, Japan.
C3 Keio University; Keio University
RP Hosoe, N (通讯作者)，Keio Univ, Sch Med, Ctr Diagnost & Therapeut Endoscopy, Shinjuku Ku, 35 Shinanomachi, Tokyo 1608582, Japan.
EM nhosoe@z5.keio.jp
OI Hosoe, Naoki/0000-0002-4516-5648
CR Abdelaal UM, 2015, SAUDI J GASTROENTERO, V21, P418, DOI 10.4103/1319-3767.170954
   Albert JG, 2008, EUR J GASTROEN HEPAT, V20, P971, DOI 10.1097/MEG.0b013e3282fb2a53
   Almeida N, 2010, DIGEST DIS SCI, V55, P153, DOI 10.1007/s10620-008-0687-y
   Bahar R, 2019, DIGESTION, V99, P213, DOI 10.1159/000490942
   Bandorski D, 2016, WORLD J GASTROENTERO, V22, P9898, DOI 10.3748/wjg.v22.i45.9898
   Ben-Soussan E, 2005, GASTROINTEST ENDOSC, V62, P785, DOI 10.1016/j.gie.2005.07.040
   Ben-Soussan E, 2005, J CLIN GASTROENTEROL, V39, P381, DOI 10.1097/01.mcg.0000159271.43233.45
   Boal Carvalho Pedro, 2015, World J Gastroenterol, V21, P7233, DOI 10.3748/wjg.v21.i23.7233
   Buscaglia JM, 2008, CLIN GASTROENTEROL H, V6, P298, DOI 10.1016/j.cgh.2007.12.029
   Canas-Ventura A, 2013, WORLD J GASTRO ENDOS, V5, P551, DOI 10.4253/wjge.v5.i11.551
   Cheifetz AS, 2006, AM J GASTROENTEROL, V101, P2218, DOI 10.1111/j.1572-0241.2006.00761.x
   Choi EH, 2013, GASTROINTEST ENDOSC, V78, P325, DOI 10.1016/j.gie.2013.02.039
   D'Halluin PN, 2005, GASTROINTEST ENDOSC, V61, P243, DOI 10.1016/S0016-5107(04)02587-8
   Dolak W, 2012, ENDOSCOPY, V44, P1012, DOI 10.1055/s-0032-1310158
   Endo H, 2008, DIGEST DIS SCI, V53, P3201, DOI 10.1007/s10620-008-0292-0
   Enns RA, 2017, GASTROENTEROLOGY, V152, P497, DOI 10.1053/j.gastro.2016.12.032
   Esaki M, 2009, GASTROINTEST ENDOSC, V69, P94, DOI 10.1016/j.gie.2008.04.054
   Esaki M, 2010, DIGEST DIS SCI, V55, P2294, DOI 10.1007/s10620-009-1036-5
   Estevez E, 2006, EUR J GASTROEN HEPAT, V18, P881
   Fireman Z, 2004, ISRAEL MED ASSOC J, V6, P521
   Fisher L, 2010, GASTROINTEST ENDOSC, V72, P471, DOI 10.1016/j.gie.2010.04.032
   Friedrich K, 2013, J GASTROEN HEPATOL, V28, P1496, DOI 10.1111/jgh.12280
   Gay G, 2006, ENDOSCOPY, V38, P49, DOI 10.1055/s-2005-921176
   Gerson LB, 2015, AM J GASTROENTEROL, V110, P87
   Gomes C, 2018, WORLD J GASTRO ENDOS, V10, P74, DOI 10.4253/wjge.v10.i4.74
   Han S, 2018, GASTROENTEROL RES, V11, P106, DOI 10.14740/gr949w
   Hausmann J, 2017, SCAND J GASTROENTERO, V52, P840, DOI 10.1080/00365521.2017.1310289
   Herrerias JM, 2008, GASTROINTEST ENDOSC, V67, P902, DOI 10.1016/j.gie.2007.10.063
   Honda W, 2012, GASTROINTEST ENDOSC, V76, P344, DOI 10.1016/j.gie.2012.04.443
   Hosoe N, 2016, ENDOSC INT OPEN, V4, pE878, DOI 10.1055/s-0042-111389
   Hosoe N, 2015, DIGEST ENDOSC, V27, P205, DOI 10.1111/den.12380
   Hosoe N, 2013, J GASTROEN HEPATOL, V28, P1174, DOI 10.1111/jgh.12203
   Hosoe N, 2012, CLIN RES HEPATOL GAS, V36, P66, DOI 10.1016/j.clinre.2011.09.009
   Ida Y, 2012, GUT LIVER, V6, P339, DOI 10.5009/gnl.2012.6.3.339
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Imagawa H, 2011, GASTROINTEST ENDOSC, V73, P299, DOI 10.1016/j.gie.2010.10.016
   Kaffes AJ, 2007, GASTROINTEST ENDOSC, V66, P304, DOI 10.1016/j.gie.2007.02.044
   Kalantzis C, 2007, SCAND J GASTROENTERO, V42, P1120, DOI 10.1080/00365520701251601
   Kim SH, 2018, CLIN ENDOSC, V51, P329, DOI 10.5946/ce.2018.095
   Kotwal VS, 2014, EUR J GASTROEN HEPAT, V26, P137, DOI 10.1097/MEG.0b013e328365b9d4
   Koulaouzidis A, 2013, CURR MED RES OPIN, V29, P1171, DOI 10.1185/03007995.2013.818532
   Koulaouzidis A, 2012, J DIGEST DIS, V13, P621, DOI 10.1111/j.1751-2980.2012.00638.x
   Koulaouzidis A, 2012, EUR J GASTROEN HEPAT, V24, P1099, DOI 10.1097/MEG.0b013e32835563ab
   Krystallis C, 2011, DIGEST LIVER DIS, V43, P953, DOI 10.1016/j.dld.2011.07.018
   Lecleire S, 2012, ENDOSCOPY, V44, P337, DOI 10.1055/s-0031-1291614
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Leighton JA, 2017, GASTROINTEST ENDOSC, V85, P196, DOI 10.1016/j.gie.2016.09.009
   Lepileur L, 2012, CLIN GASTROENTEROL H, V10, P1376, DOI 10.1016/j.cgh.2012.05.024
   Leung WK, 2005, WORLD J GASTROENTERO, V11, P4865, DOI 10.3748/wjg.v11.i31.4865
   Li F, 2008, GASTROINTEST ENDOSC, V68, P174, DOI 10.1016/j.gie.2008.02.037
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Liao Z, 2010, ENDOSCOPY, V42, P360, DOI 10.1055/s-0029-1243993
   Liao ZA, 2010, WORLD J GASTROENTERO, V16, P2669, DOI 10.3748/wjg.v16.i21.2669
   Liao ZA, 2010, GASTROINTEST ENDOSC, V71, P280, DOI 10.1016/j.gie.2009.09.031
   Meron GD, 2000, GASTROINTEST ENDOSC, V52, P817, DOI 10.1067/mge.2000.110204
   Nakamura M, 2015, DIGEST ENDOSC, V27, P61, DOI 10.1111/den.12306
   Nakamura M, 2010, J GASTROENTEROL, V45, P592, DOI 10.1007/s00535-010-0202-z
   Nemeth A, 2016, ENDOSCOPY, V48, P373, DOI 10.1055/s-0034-1393560
   Neumann H, 2014, CURR OPIN GASTROEN, V30, P463, DOI 10.1097/MOG.0000000000000101
   Neumann H, 2013, DIGESTION, V87, P91, DOI 10.1159/000345346
   Niikura R, 2018, DIGEST ENDOSC, V30, P79, DOI 10.1111/den.12922
   Niv E, 2008, WORLD J GASTROENTERO, V14, P2561, DOI 10.3748/wjg.14.2561
   Ogata H, 2008, J GASTROENTEROL, V43, P186, DOI 10.1007/s00535-007-2140-y
   Omori T, 2018, ENDOSC INT OPEN, V6, pE669, DOI 10.1055/a-0599-5852
   Park S, 2012, GASTROENT RES PRACT, V2012, DOI 10.1155/2012/202935
   Park SC, 2011, DIGEST DIS SCI, V56, P1769, DOI 10.1007/s10620-010-1500-2
   Pennazio M, 2015, ENDOSCOPY, V47, P352, DOI 10.1055/s-0034-1391855
   Pohl J, 2010, ENDOSCOPY, V42, P490, DOI 10.1055/s-0029-1243994
   Postgate AJ, 2008, DIGEST DIS SCI, V53, P2732, DOI 10.1007/s10620-008-0210-5
   Rahman M, 2015, WORLD J GASTROENTERO, V21, P5542, DOI 10.3748/wjg.v21.i18.5542
   Raju Gottumukkala S, 2007, Gastroenterology, V133, P1694, DOI 10.1053/j.gastro.2007.06.008
   Rey JF, 2009, DIGEST LIVER DIS, V41, P486, DOI 10.1016/j.dld.2008.09.016
   Rezapour M, 2017, GASTROINTEST ENDOSC, V85, P1157, DOI 10.1016/j.gie.2016.12.024
   Robinson CA, 2011, GASTROINTEST ENDOSC, V74, P1061, DOI 10.1016/j.gie.2011.07.019
   Rondonotti E, 2008, ENDOSCOPY, V40, P488, DOI 10.1055/s-2007-995783
   Rondonotti E, 2005, GASTROINTEST ENDOSC, V62, P712, DOI 10.1016/j.gie.2005.05.002
   Rondonotti E, 2018, ENDOSCOPY, V50, P423, DOI 10.1055/a-0576-0566
   Rondonotti E, 2010, EUR J GASTROEN HEPAT, V22, P1380, DOI 10.1097/MEG.0b013e3283352ced
   Sakai E, 2012, BMC GASTROENTEROL, V12, DOI 10.1186/1471-230X-12-83
   Saurin JC, 2018, ENDOSC INT OPEN, V6, pE616
   Shim KN, 2013, CLIN ENDOSC, V46, P45, DOI 10.5946/ce.2013.46.1.45
   Sidhu R, 2009, J GASTROINTEST LIVER, V18, P273
   Signorelli C, 2006, DIGEST LIVER DIS, V38, P326, DOI 10.1016/j.dld.2006.01.010
   Signorelli C, 2005, ENDOSCOPY, V37, P1170, DOI 10.1055/s-2005-870410
   Singeap AM, 2011, EUR J GASTROEN HEPAT, V23, P886, DOI 10.1097/MEG.0b013e328349efa4
   Song HJ, 2016, GASTROENT RES PRACT, V2016, P6802810
   Song HJ, 2016, INTEST RES, V14, P21, DOI 10.5217/ir.2016.14.1.21
   Song HJ, 2013, CLIN ENDOSC, V46, P147, DOI 10.5946/ce.2013.46.2.147
   Spada C, 2005, ENDOSCOPY, V37, P793, DOI 10.1055/s-2005-870246
   Spada C, 2007, J CLIN GASTROENTEROL, V41, P576, DOI 10.1097/01.mcg.0000225633.14663.64
   Subramanian V, 2012, DIGEST DIS SCI, V57, P1624, DOI 10.1007/s10620-012-2074-y
   Tontini GE, 2017, GASTROINTEST ENDOSC, V85, P401, DOI 10.1016/j.gie.2016.07.063
   van Turenhout ST, 2010, J GASTROINTEST LIVER, V19, P141
   van Tuyl SAC, 2007, ENDOSCOPY, V39, P1037, DOI 10.1055/s-2007-966988
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wei W, 2008, AM J GASTROENTEROL, V103, P77, DOI 10.1111/j.1572-0241.2007.01633.x
   Wei W, 2007, J GASTROEN HEPATOL, V22, P1605, DOI 10.1111/j.1440-1746.2007.05064.x
   Westerhof J, 2009, GASTROINTEST ENDOSC, V69, P497, DOI 10.1016/j.gie.2008.05.070
   Xavier S, 2018, REV ESP ENFERM DIG, V110, P155, DOI 10.17235/reed.2017.5071/2017
   Yamada A, 2012, HEPATO-GASTROENTEROL, V59, P676, DOI 10.5754/hge12180
   Yamamoto H, 2017, DIGEST ENDOSC, V29, P519, DOI 10.1111/den.12883
   Yang L, 2017, GASTROENT RES PRACT, V2017, DOI 10.1155/2017/7468728
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P979, DOI 10.1080/17474124.2017.1359540
   Yung DE, 2017, ENDOSCOPY, V49, P258, DOI 10.1055/s-0042-122015
   Zhang W, 2014, J DIGEST DIS, V15, P345, DOI 10.1111/1751-2980.12152
   Zwinger LL, 2019, J CLIN GASTROENTEROL, V53, pE101, DOI 10.1097/MCG.0000000000000994
NR 106
TC 41
Z9 42
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD SEP
PY 2019
VL 31
IS 5
BP 498
EP 507
DI 10.1111/den.13346
PG 10
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA IW5YK
UT WOS:000485053800007
PM 30656743
OA Bronze
DA 2023-04-20
ER

PT J
AU Makristathis, A
   Hirschl, AM
   Megraud, F
   Bessede, E
AF Makristathis, Athanasios
   Hirschl, Alexander M.
   Megraud, Francis
   Bessede, Emilie
TI Review: Diagnosis of Helicobacter pylori infection
SO HELICOBACTER
LA English
DT Review
DE C-13 urea breath test; droplet digital PCR; endoscopic imaging;
   histology; real-time PCR; serology; stool antigen test
ID ENDOSCOPIC FINDINGS
AB Endoscopic imaging of the stomach is improving. In addition to narrow band imaging, other methods, for example, blue light imaging and linked color imaging, are now available and can be combined with artificial intelligence systems to obtain information on the gastric mucosa and detect early gastric cancer. Immunohistochemistry is only recommended as an ancillary stain in case of chronic active gastritis without Helicobacter pylori detection by standard staining, and recommendations to exclude false negative H. pylori results have been made. Molecular methods using real-time PCR, droplet digital PCR, or amplification refractory mutation system PCR have shown a high accuracy, both for detecting H. pylori and for clarithromycin susceptibility testing, and can now be used in clinical practice for targeted therapy. The most reliable non-invasive test remains the C-13-urea breath test. Large data sets show that DOB values are higher in women and that the cut-off for positivity could be decreased to 2.74 DOB. Stool antigen tests using monoclonal antibodies are widely used and may be a good alternative to UBT, particularly in countries with a high prevalence of H. pylori infection. Attempts to improve serology by looking at specific immunodominant antigens to distinguish current and past infection have been made. The interest of Gastropanel (R) which also tests pepsinogen levels was confirmed.
C1 [Makristathis, Athanasios; Hirschl, Alexander M.] Med Univ Vienna, Dept Lab Med, Div Clin Microbiol, Vienna, Austria.
   [Megraud, Francis; Bessede, Emilie] CHU Pellegrin, French Natl Reference Ctr Campylobacters & Helico, Bacteriol Lab, Bordeaux, France.
   [Megraud, Francis; Bessede, Emilie] Univ Bordeaux, BaRITOn, INSERM, UMR1053, Bordeaux, France.
C3 Medical University of Vienna; CHU Bordeaux; Institut National de la
   Sante et de la Recherche Medicale (Inserm); UDICE-French Research
   Universities; Universite de Bordeaux
RP Megraud, F (通讯作者)，CHU Pellegrin, French Natl Reference Ctr Campylobacters & Helico, Bacteriol Lab, Bordeaux, France.
EM francis.megraud@chu-bordeaux.fr
RI Bessede, Emilie/HKF-3098-2023
OI Megraud, Francis/0000-0002-2481-1612
CR Adachi K, 2019, INTERNAL MED, V58, P767, DOI 10.2169/internalmedicine.1751-18
   Akazawa Y, 2018, DIGESTION, V98, P175, DOI 10.1159/000489167
   Bachir M, 2018, J ANTIMICROB CHEMOTH, V73, P2034, DOI 10.1093/jac/dky167
   Baroni MR, 2018, REV ARGENT MICROBIOL, V50, P359, DOI 10.1016/j.ram.2017.11.005
   Bazin T, 2018, UNITED EUR GASTROENT, V6, P1267, DOI 10.1177/2050640618787055
   Bellolio E, 2019, PATHOL ONCOL RES, V25, P1135, DOI 10.1007/s12253-018-0532-3
   Benejat L, 2018, HELICOBACTER, V23, DOI 10.1111/hel.12512
   Benoit A, 2018, ANN PATHOL, V38, P363, DOI 10.1016/j.annpat.2018.03.009
   BERTGES Luiz Carlos, 2018, Arq. Gastroenterol., V55, P212, DOI [10.1590/S0004-2803.201800000-56, 10.1590/s0004-2803.201800000-56]
   Best LMJ, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD012080.pub2
   Blumel B, 2018, HELICOBACTER, V23, DOI 10.1111/hel.12494
   Boltin D, 2018, GASTROENT RES PRACT, V2018, P1
   Butt J, 2019, GASTROENTEROLOGY, V156, P175, DOI 10.1053/j.gastro.2018.09.054
   Capelle LG, 2010, GASTROINTEST ENDOSC, V71, P1150, DOI 10.1016/j.gie.2009.12.029
   Chen FM, 2019, ANN DIAGN PATHOL, V38, P106, DOI 10.1016/j.anndiagpath.2018.12.002
   Chen TH, 2018, J CHIN MED ASSOC, V81, P1033, DOI 10.1016/j.jcma.2018.03.006
   Cho JH, 2019, J GASTROEN HEPATOL, V34, P700, DOI 10.1111/jgh.14383
   Coelho LG, 2018, CLINICS, V73, DOI 10.6061/clinics/2018/e16-553
   Dechant FX, 2019, DIGESTION, V28, P1
   Dohi O, 2019, GASTROINTEST ENDOSC, V89, P47, DOI 10.1016/j.gie.2018.08.049
   Du Y, 2018, NANOMED-NANOTECHNOL, V14, P2259, DOI 10.1016/j.nano.2018.07.007
   Eisdorfer I, 2018, BIOL SEX DIFFER, V9, DOI 10.1186/s13293-017-0161-7
   El-Serag HB, 2018, CLIN GASTROENTEROL H, V16, P992, DOI 10.1016/j.cgh.2018.03.013
   El-Zimaity H, 2018, VIRCHOWS ARCH, V473, P533, DOI 10.1007/s00428-018-2454-6
   Epplein M, 2018, CANCER EPIDEM BIOMAR, V27, P1472, DOI [10.1158/1055-9965.EPI-18-0582, 10.1158/1055-9965.epi-18-0582]
   Graham DY, 2018, J ADV RES, V13, P51, DOI 10.1016/j.jare.2018.01.006
   Gweon TG, 2018, GUT LIVER, V12, P648, DOI 10.5009/gnl18079
   Hatano Y, 2018, DIGESTION, V98, P185, DOI 10.1159/000488796
   Hays C, 2019, HELICOBACTER, V24, DOI 10.1111/hel.12560
   Horiuchi Y, 2018, GASTRIC CANCER, V21, P988, DOI 10.1007/s10120-018-0819-9
   Hsieh MS, 2019, HELICOBACTER, V24, DOI 10.1111/hel.12568
   Iannone A, 2018, WORLD J GASTROENTERO, V24, P3021, DOI 10.3748/wjg.v24.i27.3021
   Kakiuchi T, 2019, J CLIN MICROBIOL, V57, DOI 10.1128/JCM.01825-18
   Kawano K, 2018, CHINESE MED J-PEKING, V131, P2252, DOI 10.4103/0366-6999.240818
   Kotachi T, 2018, DIGESTION, V98, P48, DOI 10.1159/000487045
   Mera RM, 2018, GUT, V67, P1239, DOI 10.1136/gutjnl-2016-311685
   Moubri M, 2019, J TROP PEDIATRICS, V65, P210, DOI 10.1093/tropej/fmy035
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Nishikawa Y, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193197
   Okamura T, 2018, CLIN ENDOSC, V51, P362, DOI 10.5946/ce.2017.177
   Osawa H, 2018, CLIN ENDOSC, V51, P513, DOI 10.5946/ce.2018.132
   Perets TT, 2019, J CLIN LAB ANAL, V33, DOI 10.1002/jcla.22674
   Pimentel-Nunes P, 2019, ENDOSCOPY, V51, P365, DOI 10.1055/a-0859-1883
   Rugge M, 2005, GASTROENTEROLOGY, V129, P1807, DOI 10.1053/j.gastro.2005.09.056
   Shafaie E, 2018, MICROB PATHOGENESIS, V119, P137, DOI 10.1016/j.micpath.2018.04.018
   Shichijo S, 2019, SCAND J GASTROENTERO, V54, P158, DOI 10.1080/00365521.2019.1577486
   Skrebinska S, 2018, SCAND J GASTROENTERO, V53, P777, DOI 10.1080/00365521.2018.1476909
   Sun L, 2018, J CLIN MICROBIOL, V56, DOI [10.1128/JCM.00019-18, 10.1128/jcm.00019-18]
   Syrjanen K, 2019, ANTICANCER RES, V39, P1091, DOI 10.21873/anticanres.13218
   Talarico S, 2018, HELICOBACTER, V23, DOI 10.1111/hel.12472
   Togo K, 2018, ENDOSC INT OPEN, V6, pE830, DOI 10.1055/a-0611-4825
   White JR, 2018, SCAND J GASTROENTERO, V53, P1611, DOI 10.1080/00365521.2018.1542455
   Yu J, 2019, J CELL BIOCHEM, V120, P1735, DOI 10.1002/jcb.27462
   Zhang XY, 2019, CANCER MED-US, V8, P1633, DOI 10.1002/cam4.1986
NR 54
TC 28
Z9 32
U1 2
U2 32
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1083-4389
EI 1523-5378
J9 HELICOBACTER
JI Helicobacter
PD SEP
PY 2019
VL 24
SU 1
SI SI
AR e12641
DI 10.1111/hel.12641
PG 7
WC Gastroenterology & Hepatology; Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Microbiology
GA IY0JD
UT WOS:000486077700003
PM 31486244
DA 2023-04-20
ER

PT J
AU Nakagawa, K
   Ishihara, R
   Aoyama, K
   Ohmori, M
   Nakahira, H
   Matsuura, N
   Shichijo, S
   Nishida, T
   Yamada, T
   Yamaguchi, S
   Ogiyama, H
   Egawa, S
   Kishida, O
   Tada, T
AF Nakagawa, Kentaro
   Ishihara, Ryu
   Aoyama, Kazuharu
   Ohmori, Masayasu
   Nakahira, Hiroko
   Matsuura, Noriko
   Shichijo, Satoki
   Nishida, Tsutomu
   Yamada, Takuya
   Yamaguchi, Shinjiro
   Ogiyama, Hideharu
   Egawa, Satoshi
   Kishida, Osamu
   Tada, Tomohiro
TI Classification for invasion depth of esophageal squamous cell carcinoma
   using a deep neural network compared with experienced endoscopists
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID MUSCULARIS MUCOSAE; RESECTION; CANCER
AB Background and Aims: Cancer invasion depth is a critical factor affecting the choice of treatment in patients with superficial squamous cell carcinoma (SCC). However, the diagnosis of invasion depth is currently subjective and liable to interobserver variability.
   Methods: We developed a deep learning-based artificial intelligence (AI) system based on Single Shot MultiBox Detector architecture for the assessment of superficial esophageal SCC. We obtained endoscopic images from patients with superficial esophageal SCC at our facility between December 2005 and December 2016.
   Results: After excluding poor-quality images, 8660 non-magnified endoscopic (non-ME) and 5678 ME images from 804 superficial esophageal SCCs with pathologic proof of cancer invasion depth were used as the training dataset, and 405 non-ME images and 509 ME images from 155 patients were selected for the validation set. Our system showed a sensitivity of 90.1%, specificity of 95.8%, positive predictive value of 99.2%, negative predictive value of 63.9%, and an accuracy of 91.0% for differentiating pathologic mucosal and submucosal microinvasive (SM1) cancers from submucosal deep invasive (SM2/3) cancers. Cancer invasion depth was diagnosed by 16 experienced endoscopists using the same validation set, with an overall sensitivity of 89.8%, specificity of 88.3%, positive predictive value of 97.9%, negative predictive value of 65.5%, and an accuracy of 89.6%.
   Conclusions: This newly developed AI system showed favorable performance for diagnosing invasion depth in patients with superficial esophageal SCC, with comparable performance to experienced endoscopists.
C1 [Nakagawa, Kentaro; Ishihara, Ryu; Ohmori, Masayasu; Nakahira, Hiroko; Matsuura, Noriko; Shichijo, Satoki] Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Osaka, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] AI Med Serv Inc, Tokyo, Japan.
   [Nishida, Tsutomu] Toyonaka City Hosp, Dept Gastroenterol, Osaka, Japan.
   [Yamada, Takuya] Osaka Rosai Hosp, Dept Gastroenterol, Osaka, Japan.
   [Yamaguchi, Shinjiro] Kansai Rosai Hosp, Dept Gastroenterol, Amagasaki, Hyogo, Japan.
   [Ogiyama, Hideharu] Itami City Hosp, Dept Gastroenterol, Itami, Hyogo, Japan.
   [Egawa, Satoshi] Osaka Police Hosp, Dept Gastroenterol, Osaka, Japan.
   [Kishida, Osamu] Sumitomo Hosp, Dept Gastroenterol, Osaka, Japan.
   [Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
   [Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
C3 Osaka Rosai Hospital; Kansai Rosai Hospital; Osaka Police Hospital;
   Sumitomo Hospital; University of Tokyo
RP Ishihara, R (通讯作者)，Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Chuo Ku, 3-1-69 Otemae, Osaka 5418567, Japan.
RI Nishida, Tsutomu/M-5744-2017
OI Nishida, Tsutomu/0000-0003-4037-9003
CR Akutsu Y, 2013, ANN SURG, V257, P1032, DOI 10.1097/SLA.0b013e31827017fc
   [Anonymous], 2016, DEEP LEARNING
   Arima M, 2007, STOMACH INTEST, V42, P589
   Birkmeyer JD, 2002, NEW ENGL J MED, V346, P1128, DOI 10.1056/NEJMsa012337
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chang AC, 2008, ANN THORAC SURG, V85, P424, DOI 10.1016/j.athoracsur.2007.10.007
   Ebi M, 2015, GASTROINTEST ENDOSC, V81, P1355, DOI 10.1016/j.gie.2014.11.015
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Igaki H, 2001, EUR J CARDIO-THORAC, V20, P1089, DOI 10.1016/S1010-7940(01)01003-X
   Ishihara R, 2017, BMC GASTROENTEROL, V17, DOI 10.1186/s12876-017-0574-0
   Katada C, 2007, ENDOSCOPY, V39, P779, DOI 10.1055/s-2007-966761
   Kitagawa Y, 2019, ESOPHAGUS-TOKYO, V16, P1, DOI 10.1007/s10388-018-0641-9
   Kodama M, 1998, SURGERY, V123, P432, DOI 10.1067/msy.1998.86778
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lee MW, 2014, SCAND J GASTROENTERO, V49, P853, DOI 10.3109/00365521.2014.915052
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Oyama T, 2017, ESOPHAGUS-TOKYO, V14, P105, DOI 10.1007/s10388-016-0527-7
   Pimentel-Nunes P, 2015, ENDOSCOPY, V47, P829, DOI 10.1055/s-0034-1392882
   Pouw RE, 2011, GASTROINTEST ENDOSC, V73, P662, DOI 10.1016/j.gie.2010.10.046
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shimizu Y, 2002, GASTROINTEST ENDOSC, V56, P387, DOI 10.1067/mge.2002.127100
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Tachimori Y, 2018, ESOPHAGUS-TOKYO, V15, P127, DOI 10.1007/s10388-018-0614-z
   Thosani N, 2012, GASTROINTEST ENDOSC, V75, P242, DOI 10.1016/j.gie.2011.09.016
   Yamamoto S, 2011, AM J GASTROENTEROL, V106, P1048, DOI 10.1038/ajg.2011.42
   Yamashina T, 2013, AM J GASTROENTEROL, V108, P544, DOI 10.1038/ajg.2013.8
   Yoshida T, 2004, GASTROINTEST ENDOSC, V59, P288, DOI 10.1016/S0016-5107(03)02532-X
   Yu TT, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/8591387
NR 34
TC 73
Z9 77
U1 4
U2 17
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD SEP
PY 2019
VL 90
IS 3
BP 407
EP 414
DI 10.1016/j.gie.2019.04.245
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA IR7UP
UT WOS:000481646800009
PM 31077698
DA 2023-04-20
ER

PT J
AU Ogawa, R
   Nishikawa, J
   Hideura, E
   Goto, A
   Koto, Y
   Ito, S
   Unno, M
   Yamaoka, Y
   Kawasato, R
   Hashimoto, S
   Okamoto, T
   Ogihara, H
   Hamamoto, Y
   Sakaida, I
AF Ogawa, Ryo
   Nishikawa, Jun
   Hideura, Eizaburo
   Goto, Atsushi
   Koto, Yurika
   Ito, Shunsuke
   Unno, Madoka
   Yamaoka, Yuko
   Kawasato, Ryo
   Hashimoto, Shinichi
   Okamoto, Takeshi
   Ogihara, Hiroyuki
   Hamamoto, Yoshihiko
   Sakaida, Isao
TI Objective Assessment of the Utility of Chromoendoscopy with a Support
   Vector Machine
SO JOURNAL OF GASTROINTESTINAL CANCER
LA English
DT Article
DE Gastric cancer; Diagnosis; Support vector machine; Chromoendoscopy;
   Acetic acid; Indigo carmine
ID COMPUTER-AIDED DIAGNOSIS; MAGNIFYING ENDOSCOPY; CANCER
AB Purpose The utility of chromoendoscopy for early gastric cancer (GC) was determined by machine learning using data of color differences.
   Methods Eighteen histopathologically confirmed early GC lesions were examined. We prepared images from white light endoscopy (WL), indigo carmine (Indigo), and acetic acid-indigo carmine chromoendoscopy (AIM). A border between cancerous and non-cancerous areas on endoscopic images was established from post-treatment pathological findings, and 2000 pixels with equivalent luminance values were randomly extracted from each image of cancerous and non-cancerous areas. Each pixel was represented as a three-dimensional vector with RGB values and defined as a sample. We evaluated the Mahalanobis distance using RGB values, indicative of color differences between cancerous and non-cancerous areas. We then conducted diagnosis test using a support vector machine (SVM) for each image. SVM was trained using the 100 training samples per class and determined which area each of 1900 test samples per class came from.
   Results The means of the Mahalanobis distances for WL, Indigo, and AIM were 1.52, 1.32, and 2.53, respectively and there were no significant differences in the three modalities. Diagnosability per endoscopy technique was assessed using the F1 measure. The means of F1 measures for WL, Indigo, and AIM were 0.636, 0.618, and 0.687, respectively. AIM images were better than WL and Indigo images for the diagnosis of GC.
   Conclusion Objective assessment by SVM found AIM to be suitable for diagnosis of early GC based on color differences.
C1 [Ogawa, Ryo; Hideura, Eizaburo; Goto, Atsushi; Koto, Yurika; Ito, Shunsuke; Unno, Madoka; Yamaoka, Yuko; Kawasato, Ryo; Hashimoto, Shinichi; Okamoto, Takeshi; Sakaida, Isao] Yamaguchi Univ, Grad Sch Med, Dept Gastroenterol & Hepatol, 1-1-1 Minamikogushi, Ube, Yamaguchi, Japan.
   [Nishikawa, Jun] Yamaguchi Univ, Grad Sch Med, Dept Lab Sci, 1-1-1 Minamikogushi, Ube, Yamaguchi, Japan.
   [Ogihara, Hiroyuki] Yamaguchi Univ, Grad Sch Med, Dept Biomol Engn Appl Mol Biosci, 2-16-1 Tokiwadai, Ube, Yamaguchi, Japan.
   [Hamamoto, Yoshihiko] Yamaguchi Univ, Grad Sch Sci & Technol Innovat, Div Elect Elect & Informat Engn, 2-16-1 Tokiwadai, Ube, Yamaguchi, Japan.
C3 Yamaguchi University; Yamaguchi University; Yamaguchi University;
   Yamaguchi University
RP Nishikawa, J (通讯作者)，Yamaguchi Univ, Grad Sch Med, Dept Lab Sci, 1-1-1 Minamikogushi, Ube, Yamaguchi, Japan.
EM junnis@yamaguchi-u.ac.jp
RI Nishikawa, Jun/AAE-5355-2020
CR [Anonymous], P NATL I SCI, DOI [DOI 10.1007/S13171-019-00164-5, DOI 10.1145/1390156.1390302]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang CC, 2017, COMPUT METH PROG BIO, V145, P45, DOI 10.1016/j.cmpb.2017.04.008
   Dinis-Ribeiro M, 2006, EUR J GASTROEN HEPAT, V18, P831, DOI 10.1097/00042737-200608000-00005
   Ezoe Y, 2011, GASTROENTEROLOGY, V141, P2017, DOI 10.1053/j.gastro.2011.08.007
   Hassanpour S, 2017, AM J ROENTGENOL, V208, P750, DOI 10.2214/AJR.16.16128
   Kaise M, 2010, GASTROENTEROL CLIN N, V39, P771, DOI 10.1016/j.gtc.2010.08.028
   Kawahara Y, 2009, DIGEST ENDOSC, V21, P14, DOI 10.1111/j.1443-1661.2008.00824.x
   Kiyotoki S, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.2.026010
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Lambert R, 2007, ENDOSCOPY, V39, P232, DOI 10.1055/s-2006-945109
   Li YJ, 2017, NEURAL NETWORKS, V93, P185, DOI 10.1016/j.neunet.2017.05.010
   Nagao M, 2016, GASTROENT RES PRACT, V2016, DOI 10.1155/2016/2439621
   Nishio M, 2017, ACAD RADIOL, V24, P328, DOI 10.1016/j.acra.2016.11.007
   Numata N, 2016, BMC GASTROENTEROL, V16, DOI 10.1186/s12876-016-0483-7
   Powers D. M., 2011, J MACHINE LEARNING T, V2, P37, DOI 10.1.1.214.9232
   Sugano Kentaro, 2015, Curr Treat Options Gastroenterol, V13, P398, DOI 10.1007/s11938-015-0070-y
   Sumie H, 2014, MOL CLIN ONCOL, V2, P129, DOI 10.3892/mco.2013.213
   Szaloki Tibor, 2002, Orv Hetil, V143, P25
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Vladimir N.V., 1995, NATURE STAT LEARNING
   Yao K, 2009, ENDOSCOPY, V41, P462, DOI 10.1055/s-0029-1214594
NR 22
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1941-6628
EI 1941-6636
J9 J GASTROINTEST CANC
JI J. Gastrointest. Cancer
PD SEP
PY 2019
VL 50
IS 3
BP 386
EP 391
DI 10.1007/s12029-018-0083-6
PG 6
WC Oncology; Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Oncology; Gastroenterology & Hepatology
GA IN3WX
UT WOS:000478608200004
PM 29504086
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Roberts, BM
   White, MG
   Patton, MH
   Chen, R
   Mathur, BN
AF Roberts, Bradley M.
   White, Michael G.
   Patton, Mary H.
   Chen, Rong
   Mathur, Brian N.
TI Ensemble encoding of action speed by striatal fast-spiking interneurons
SO BRAIN STRUCTURE & FUNCTION
LA English
DT Article
DE GABA; Inhibition; Basal ganglia; Striatum; Calcium imaging; Endoscope;
   Ensemble; Kinematics
ID BASAL GANGLIA; GAP-JUNCTIONS; PARVALBUMIN; NEURONS; INDIVIDUALS;
   NEOSTRIATUM; ACTIVATION; PLASTICITY; PATTERNS; CALCIUM
AB Striatal fast-spiking interneurons (FSIs) potently inhibit the output neurons of the striatum and, as such, powerfully modulate action learning. Through electrical synaptic coupling, FSIs are theorized to temporally coordinate their activity. This has important implications for their ability to temporally summate inhibition on downstream striatal projection neurons. While some in vivo single-unit electrophysiological recordings of putative FSIs support coordinated firing, others do not. Moreover, it is unclear as to what aspect of action FSIs encode. To address this, we used in vivo calcium imaging of genetically identified FSIs in freely moving mice and applied machine learning analyses to decipher the relationship between FSI activity and movement. We report that FSIs exhibit ensemble activity that encodes the speed of action sub-components, including ambulation and head movements. These results suggest FSI population dynamics fit within a Hebbian model for ensemble inhibition of striatal output guiding action.
C1 [Roberts, Bradley M.; White, Michael G.; Patton, Mary H.; Mathur, Brian N.] Univ Maryland, Sch Med, Dept Pharmacol, HSF 3 9179,670 West Baltimore St, Baltimore, MD 21201 USA.
   [Chen, Rong] Univ Maryland, Sch Med, Dept Diagnost Radiol & Nucl Med, Baltimore, MD 21201 USA.
C3 University System of Maryland; University of Maryland Baltimore;
   University System of Maryland; University of Maryland Baltimore
RP Mathur, BN (通讯作者)，Univ Maryland, Sch Med, Dept Pharmacol, HSF 3 9179,670 West Baltimore St, Baltimore, MD 21201 USA.
EM BMathur@som.umaryland.edu
RI Mathur, Brian/P-5986-2018
OI Mathur, Brian/0000-0003-2912-8625; Roberts, Bradley/0000-0002-5192-2545
FU National Institute on Alcohol Abuse and Alcoholism [K22AA021414,
   R01AA024845, F31AA024683]; National Institute of General Medical
   Sciences [T32008181]; National Institute of Neurological Disorders and
   Stroke [T32NS063391, R01NS110421]; Brain Initiative [R01NS110421];
   National Institute of Mental Health [F31MH112350]
FX The authors declare no financial and non-financial competing interests.
   All applicable international, national, and/or institutional guidelines
   for the care and use of animals were followed. All procedures performed
   in studies involving animals were in accordance with the ethical
   standards of the institution or practice at which the studies were
   conducted. This work was supported by: National Institute on Alcohol
   Abuse and Alcoholism grants K22AA021414, R01AA024845 (B.N.M.) and
   F31AA024683 (M.H.P.); National Institute of General Medical Sciences
   grant T32008181 (M.G.W.); National Institute of Neurological Disorders
   and Stroke grant T32NS063391 (M.G.W.); National Institute of
   Neurological Disorders and Stroke and Brain Initiative grant R01NS110421
   (R.C.); and National Institute of Mental Health grant F31MH112350
   (M.G.W.).
CR Bakhurin KI, 2016, J NEUROPHYSIOL, V115, P1521, DOI 10.1152/jn.01037.2015
   Barbera G, 2016, NEURON, V92, P202, DOI 10.1016/j.neuron.2016.08.037
   Barnes TD, 2011, J NEUROPHYSIOL, V105, P1861, DOI 10.1152/jn.00871.2010
   Berke JD, 2008, J NEUROSCI, V28, P10075, DOI 10.1523/JNEUROSCI.2192-08.2008
   Blomeley CP, 2011, NEUROPSYCHOPHARMACOL, V36, P1033, DOI 10.1038/npp.2010.241
   DELONG MR, 1981, HDB PHYSL NERVOUS SY, V2, P1017
   Duda R. O., 2001, PATTERN CLASSIFICATI, V2nd
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Gage GJ, 2010, NEURON, V67, P466, DOI 10.1016/j.neuron.2010.06.034
   Graybiel AM, 1998, NEUROBIOL LEARN MEM, V70, P119, DOI 10.1006/nlme.1998.3843
   Guizar-Sicairos M, 2008, OPT LETT, V33, P156, DOI 10.1364/OL.33.000156
   Hjorth J, 2009, J NEUROSCI, V29, P5276, DOI 10.1523/JNEUROSCI.6031-08.2009
   Jin X, 2014, NAT NEUROSCI, V17, P423, DOI 10.1038/nn.3632
   Jin X, 2010, NATURE, V466, P457, DOI 10.1038/nature09263
   Kalanithi PSA, 2005, P NATL ACAD SCI USA, V102, P13307, DOI 10.1073/pnas.0502624102
   Kataoka Y, 2010, J COMP NEUROL, V518, P277, DOI 10.1002/cne.22206
   Klaus A, 2017, NEURON, V95, P1171, DOI 10.1016/j.neuron.2017.08.015
   Koos T, 2004, J NEUROSCI, V24, P7916, DOI 10.1523/JNEUROSCI.2163-04.2004
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Lee K, 2017, NEURON, V93, P1451, DOI 10.1016/j.neuron.2017.02.033
   London TD, 2018, J NEUROSCI, V38, P3547, DOI 10.1523/JNEUROSCI.2693-17.2018
   Lovinger DM, 2010, NEUROPHARMACOLOGY, V58, P951, DOI 10.1016/j.neuropharm.2010.01.008
   Luk KC, 2001, NEUROSCIENCE, V104, P93, DOI 10.1016/S0306-4522(01)00038-0
   Mathur BN, 2013, NAT NEUROSCI, V16, P1275, DOI 10.1038/nn.3478
   O'Hare JK, 2017, ELIFE, V6, DOI 10.7554/eLife.26231
   Owen SF, 2018, CELL, V172, P683, DOI 10.1016/j.cell.2018.01.005
   Patton MH, 2019, NEUROPHARMACOLOGY, V144, P1, DOI 10.1016/j.neuropharm.2018.10.010
   Patton MH, 2016, NEUROPSYCHOPHARMACOL, V41, P1831, DOI 10.1038/npp.2015.353
   Pnevmatikakis EA, 2016, NEURON, V89, P285, DOI 10.1016/j.neuron.2015.11.037
   Reiner A, 2013, MOVEMENT DISORD, V28, P1691, DOI 10.1002/mds.25624
   Schlosser B, 1999, J COMP NEUROL, V405, P185, DOI 10.1002/(SICI)1096-9861(19990308)405:2<185::AID-CNE4>3.0.CO;2-B
   Tanahira C, 2009, NEUROSCI RES, V63, P213, DOI 10.1016/j.neures.2008.12.007
   Tepper JM, 2010, FRONT NEUROANAT, V4, DOI 10.3389/fnana.2010.00150
   Tepper JM, 2004, TRENDS NEUROSCI, V27, P662, DOI 10.1016/j.tins.2004.08.007
   White MG, 2017, J COMP NEUROL, V525, P1347, DOI 10.1002/cne.23970
   Wiltschko AB, 2010, NEUROPSYCHOPHARMACOL, V35, P1261, DOI 10.1038/npp.2009.226
   Yttri EA, 2016, NATURE, V533, P402, DOI 10.1038/nature17639
   Zhang MM, 2014, BIO-MED MATER ENG, V24, P2635, DOI 10.3233/BME-141080
NR 39
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1863-2653
EI 1863-2661
J9 BRAIN STRUCT FUNCT
JI Brain Struct. Funct.
PD SEP
PY 2019
VL 224
IS 7
BP 2567
EP 2576
DI 10.1007/s00429-019-01908-7
PG 10
WC Anatomy & Morphology; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Anatomy & Morphology; Neurosciences & Neurology
GA IS0JC
UT WOS:000481834500019
PM 31243530
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Sivakumar, P
   Kumar, BM
AF Sivakumar, P.
   Kumar, B. Muthu
TI A novel method to detect bleeding frame and region in wireless capsule
   endoscopy video
SO CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND
   APPLICATIONS
LA English
DT Article
DE Image color analysis; Hemorrhaging; Histograms; Feature extraction;
   Naive Bayes classifier; Visualization; Accuracy; Cloud computing
AB To detect the region and bleeding frame in the wireless capsule endoscopy video, an automatic computer-aided technique is highly demanded to reduce the burden of physicians. The wireless capsule endoscopy (WCE), is an imaging technology which is recently established and doesn't require any wired device. This device detects abnormalities in GI tract, i.e. (colon, esophagus, small intestine, and stomach). A WCE video consists of 57,000 images. It is very hard to examine by clinicians. To determine bleeding photos out of fifty-seven thousand WCE images makes the task very hard and expensive. The main goal is to develop an automatic obscure bleeding detection method by using superpixel segmentation and naive Bayes classifier. Naive Bayes and superpixel segmentation are used for this problem.
C1 [Sivakumar, P.] GRT Inst Engn & Technol, Dept Elect & Commun Engn, Tiruttani, Tamil Nadu, India.
   [Kumar, B. Muthu] Syed Ammal Engn Coll, Dept Comp Sci Engn, Ramanathapuram, Tamil Nadu, India.
C3 Syed Ammal Engineering College
RP Sivakumar, P (通讯作者)，GRT Inst Engn & Technol, Dept Elect & Commun Engn, Tiruttani, Tamil Nadu, India.
EM sivakumarp17@rediffmail.com
RI B, Dr. MUTHU KUMAR/AAY-8641-2021
CR Al-Rahayfeh A. A., 2010, INT J MULTIMEDIA APP, V2, P1
   Amin Morteza Moradi, 2015, J Med Signals Sens, V5, P49
   Ashok V, 2017, INT J BIOMED ENG TEC, V23, P303, DOI 10.1504/IJBET.2017.10003503
   Coimbra M., 2007, EURASIP NEWS LETT, V18, P1
   Dilna C, 2015, IEEE INT C COMP NETW, DOI [10.1109/CoCoNet.2015.7411289, DOI 10.1109/COCONET.2015.7411289]
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Hachama M, 2012, IEEE T IMAGE PROCESS, V21, P4080, DOI 10.1109/TIP.2012.2200495
   Hwang S., 2010, IEEE INT C AC SPEECH
   Maghsoudi O. H., 2016, PROC IEEE SIGNAL PRO, P1
   Maghsoudi Omid Haji, 2014, J ADV COMPUTING, V3, P12, DOI DOI 10.7726/jac.2014.1002a
   Murthi A, 2016, J ADV CHEM, V12, P5613
   Novozamsky A, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.12.126007
   Pan Guo-bing, 2010, Journal of Shanghai Jiaotong University (English Edition), V15, P218, DOI 10.1007/s12204-010-9716-z
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Priya K., 2015, INT J ADV COMPUT TEC, V4, P5
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Unnimadhavan R., 2017, J BIOMED OPT, V5, P218
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
NR 18
TC 6
Z9 6
U1 1
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1386-7857
EI 1573-7543
J9 CLUSTER COMPUT
JI Cluster Comput.
PD SEP
PY 2019
VL 22
SU 5
BP 12219
EP 12225
DI 10.1007/s10586-017-1584-y
PG 7
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU5VF
UT WOS:000501743500165
DA 2023-04-20
ER

PT J
AU Takamatsu, M
   Yamamoto, N
   Kawachi, H
   Chino, A
   Saito, S
   Ueno, M
   Ishikawa, Y
   Takazawa, Y
   Takeuchi, K
AF Takamatsu, Manabu
   Yamamoto, Noriko
   Kawachi, Hiroshi
   Chino, Akiko
   Saito, Shoichi
   Ueno, Masashi
   Ishikawa, Yuichi
   Takazawa, Yutaka
   Takeuchi, Kengo
TI Prediction of early colorectal cancer metastasis by machine learning
   using digital slide images
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE Colorectal cancer; Lymph node metastasis; Supervised machine learning;
   Random forest
ID LYMPH-NODE METASTASIS; SUBMUCOSAL INVASION; JSCCR GUIDELINES; COLON;
   DEPTH
AB Background and objectives: Prediction of lymph node metastasis (LNM) for early colorectal cancer (CRC) is critical for determining treatment strategies after endoscopic resection. Some histologic parameters for predicting LNM have been established, but evaluator error and inter-observer disagreement are unsolved issues. Here we describe an LNM prediction algorithm for submucosal invasive (T1) CRC based on machine learning.
   Methods: We conducted a retrospective single-institution study of 397 T1 CRCs. Several morphologic parameters were extracted from whole slide images of cytokeratin immunohistochemistry using Image J. A random forest algorithm for a training dataset (n=277) was executed and used to predict LNM for the test dataset (n=120). The results were compared with conventional histologic evaluation of hematoxylineosin staining.
   Results: Machine learning showed better LNM predictive ability than the conventional method on some datasets. Cross validation revealed no significant difference between the methods. Machine learning resulted in fewer false-negative cases than the conventional method.
   Conclusions: Machine learning on whole slide images is a potential alternative for determining treatment strategies for T1 CRC. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Takamatsu, Manabu; Yamamoto, Noriko; Kawachi, Hiroshi; Ishikawa, Yuichi; Takazawa, Yutaka; Takeuchi, Kengo] Japanese Fdn Canc Res, Canc Inst, Div Pathol, Tokyo, Japan.
   [Takamatsu, Manabu; Yamamoto, Noriko; Kawachi, Hiroshi; Ishikawa, Yuichi; Takazawa, Yutaka; Takeuchi, Kengo] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Pathol, Tokyo, Japan.
   [Chino, Akiko; Saito, Shoichi] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Endoscopy, Tokyo, Japan.
   [Ueno, Masashi] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Colorectal Surg, Tokyo, Japan.
C3 Japanese Foundation for Cancer Research; Japanese Foundation for Cancer
   Research; Japanese Foundation for Cancer Research; Japanese Foundation
   for Cancer Research
RP Takamatsu, M (通讯作者)，Japanese Fdn Canc Res, Canc Inst, Div Pathol, Tokyo, Japan.; Takamatsu, M (通讯作者)，Japanese Fdn Canc Res, Canc Inst Hosp, Dept Pathol, Tokyo, Japan.
EM manabu.takamatsu@jfcr.or.jp
RI Takamatsu, Manabu/ABE-5474-2021
CR Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Marin-Gabriel JC, 2016, WORLD J GASTRO ENDOS, V8, P40, DOI 10.4253/wjge.v8.i2.40
   Egashira Y, 2004, MODERN PATHOL, V17, P503, DOI 10.1038/modpathol.3800030
   Harris EI, 2008, AM J SURG PATHOL, V32, P1816, DOI 10.1097/PAS.0b013e3181816083
   Ichimasa K, 2018, ENDOSCOPY, V50, P230, DOI 10.1055/s-0043-122385
   Kai K, 2016, PATHOL INT, V66, P75, DOI 10.1111/pin.12374
   Kainz P, 2017, PEERJ, V5, DOI 10.7717/peerj.3874
   Kawachi H, 2015, MODERN PATHOL, V28, P872, DOI 10.1038/modpathol.2015.36
   Kitajima K, 2004, J GASTROENTEROL, V39, P534, DOI 10.1007/s00535-004-1339-4
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Lu Y., 2018, EUR RADIOL
   Puppa G, 2012, HISTOPATHOLOGY, V61, P562, DOI 10.1111/j.1365-2559.2012.04270.x
   R Development Core Team, 2021, R LANG ENV STAT COMP
   Schneider CA, 2012, NAT METHODS, V9, P671, DOI 10.1038/nmeth.2089
   Sperandei S, 2014, BIOCHEM MEDICA, V24, P12, DOI 10.11613/BM.2014.003
   Tateishi Y, 2010, MODERN PATHOL, V23, P1068, DOI 10.1038/modpathol.2010.88
   Ueno H, 2002, HISTOPATHOLOGY, V40, P127, DOI 10.1046/j.1365-2559.2002.01324.x
   Ueno H, 2010, AM J CLIN PATHOL, V134, P312, DOI 10.1309/AJCPMQ7I5ZTTZSOM
   Ueno H, 2014, J GASTROENTEROL, V49, P1314, DOI 10.1007/s00535-013-0881-3
   Urabe Y, 2015, Z GASTROENTEROL, V53, P291, DOI 10.1055/s-0034-1385764
   Valkonen M, 2017, CYTOM PART A, V91A, P555, DOI 10.1002/cyto.a.23089
   Watanabe T, 2015, INT J CLIN ONCOL, V20, P207, DOI 10.1007/s10147-015-0801-z
   Yamauchi H, 2008, SURG TODAY, V38, P905, DOI 10.1007/s00595-007-3751-x
NR 24
TC 24
Z9 24
U1 4
U2 20
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD SEP
PY 2019
VL 178
BP 155
EP 161
DI 10.1016/j.cmpb.2019.06.022
PG 7
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA IQ0HP
UT WOS:000480432000016
PM 31416544
DA 2023-04-20
ER

PT J
AU Yoon, HJ
   Kim, S
   Kim, JH
   Keum, JS
   Oh, SI
   Jo, J
   Chun, J
   Youn, YH
   Park, H
   Kwon, IG
   Choi, SH
   Noh, SH
AF Yoon, Hong Jin
   Kim, Seunghyup
   Kim, Jie-Hyun
   Keum, Ji-Soo
   Oh, Sang-Il
   Jo, Junik
   Chun, Jaeyoung
   Youn, Young Hoon
   Park, Hyojin
   Kwon, In Gyu
   Choi, Seung Ho
   Noh, Sung Hoon
TI A Lesion-Based Convolutional Neural Network Improves Endoscopic
   Detection and Depth Prediction of Early Gastric Cancer
SO JOURNAL OF CLINICAL MEDICINE
LA English
DT Article
DE early gastric cancer; artificial intelligence; convolutional neural
   networks; endoscopy
ID ARTIFICIAL-INTELLIGENCE; CONVENTIONAL ENDOSCOPY; STAGING DEPTH;
   ULTRASONOGRAPHY; INVASION
AB In early gastric cancer (EGC), tumor invasion depth is an important factor for determining the treatment method. However, as endoscopic ultrasonography has limitations when measuring the exact depth in a clinical setting as endoscopists often depend on gross findings and personal experience. The present study aimed to develop a model optimized for EGC detection and depth prediction, and we investigated factors affecting artificial intelligence (AI) diagnosis. We employed a visual geometry group(VGG)-16 model for the classification of endoscopic images as EGC (T1a or T1b) or non-EGC. To induce the model to activate EGC regions during training, we proposed a novel loss function that simultaneously measured classification and localization errors. We experimented with 11,539 endoscopic images (896 T1a-EGC, 809 T1b-EGC, and 9834 non-EGC). The areas under the curves of receiver operating characteristic curves for EGC detection and depth prediction were 0.981 and 0.851, respectively. Among the factors affecting AI prediction of tumor depth, only histologic differentiation was significantly associated, where undifferentiated-type histology exhibited a lower AI accuracy. Thus, the lesion-based model is an appropriate training method for AI in EGC. However, further improvements and validation are required, especially for undifferentiated-type histology.
C1 [Yoon, Hong Jin; Kim, Seunghyup; Kim, Jie-Hyun; Chun, Jaeyoung; Youn, Young Hoon; Park, Hyojin] Yonsei Univ, Gangnam Severance Hosp, Dept Internal Med, Coll Med, Seoul 06273, South Korea.
   [Keum, Ji-Soo; Oh, Sang-Il; Jo, Junik] SELVAS AI Inc, Seoul 08594, South Korea.
   [Kwon, In Gyu; Choi, Seung Ho; Noh, Sung Hoon] Yonsei Univ, Gangnam Severance Hosp, Dept Surg, Coll Med, Seoul 06273, South Korea.
C3 Yonsei University; Yonsei University Health System; Yonsei University;
   Yonsei University Health System
RP Kim, JH (通讯作者)，Yonsei Univ, Gangnam Severance Hosp, Dept Internal Med, Coll Med, Seoul 06273, South Korea.
EM otilia94@yuhs.ac
RI Chun, Jaeyoung/G-2921-2015; Oh, Sang-Il/B-8508-2016
OI Chun, Jaeyoung/0000-0002-4212-0380; Noh, Sung Hoon/0000-0003-4386-6886;
   Kwon, In Gyu/0000-0002-1489-467X; park, hyojin/0000-0003-4814-8330;
   Choi, Seung Ho/0000-0002-9872-3594; Kim, Seung Up/0000-0002-9658-8050;
   Youn, Young Hoon/0000-0002-0071-229X; Yoon, Hong
   Jin/0000-0002-4880-3262; Oh, Sang-Il/0000-0002-3972-5119; KIM,
   JIE-HYUN/0000-0002-9198-3326
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Choi J, 2010, ENDOSCOPY, V42, P705, DOI 10.1055/s-0030-1255617
   Choi J, 2011, GASTROINTEST ENDOSC, V73, P917, DOI 10.1016/j.gie.2010.11.053
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Goto O, 2009, ENDOSCOPY, V41, P118, DOI 10.1055/s-0028-1119452
   Han Y, 2016, ENDOSC ULTRASOUND, V5, P284, DOI 10.4103/2303-9027.191606
   He K., 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46493-0_38
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Kim JH, 2007, GASTROINTEST ENDOSC, V66, P901, DOI 10.1016/j.gie.2007.06.012
   Kim J, 2018, SURG ENDOSC, V32, P3789, DOI 10.1007/s00464-018-6104-5
   Kim TY, 2019, SURG ENDOSC, V33, P2169, DOI 10.1007/s00464-018-6496-2
   MARUYAMA K, 1987, SCAND J GASTROENTERO, V22, P63, DOI 10.3109/00365528709091021
   Mocellin S, 2011, GASTROINTEST ENDOSC, V73, P1122, DOI 10.1016/j.gie.2011.01.030
   Pei QS, 2015, J GASTROEN HEPATOL, V30, P1566, DOI 10.1111/jgh.13014
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmidt-Erfurth U, 2018, PROG RETIN EYE RES, V67, P1, DOI 10.1016/j.preteyeres.2018.07.004
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Simonyan K, 2015, Arxiv
   Simonyan Karen, 2013, ABS13126034 CORR
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Tsujii Y, 2015, GASTROINTEST ENDOSC, V82, P452, DOI 10.1016/j.gie.2015.01.022
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang J, 2012, SURG ONCOL, V21, P119, DOI 10.1016/j.suronc.2010.12.004
   Yanai H, 1997, GASTROINTEST ENDOSC, V46, P212, DOI 10.1016/S0016-5107(97)70088-9
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 27
TC 64
Z9 67
U1 3
U2 25
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0383
J9 J CLIN MED
JI J. Clin. Med.
PD SEP
PY 2019
VL 8
IS 9
AR 1310
DI 10.3390/jcm8091310
PG 10
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA JC3NA
UT WOS:000489184200044
PM 31454949
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Taninaga, J
   Nishiyama, Y
   Fujibayashi, K
   Gunji, T
   Sasabe, N
   Iijima, K
   Naito, T
AF Taninaga, Junichi
   Nishiyama, Yu
   Fujibayashi, Kazutoshi
   Gunji, Toshiaki
   Sasabe, Noriko
   Iijima, Kimiko
   Naito, Toshio
TI Prediction of future gastric cancer risk using a machine learning
   algorithm and comprehensive medical check-up data: A case-control study
SO SCIENTIFIC REPORTS
LA English
DT Article
ID HELICOBACTER-PYLORI INFECTION; STOMACH; SOCIETY; JAPAN
AB A comprehensive screening method using machine learning and many factors (biological characteristics, Helicobacter pylori infection status, endoscopic findings and blood test results), accumulated daily as data in hospitals, could improve the accuracy of screening to classify patients at high or low risk of developing gastric cancer. We used XGBoost, a classification method known for achieving numerous winning solutions in data analysis competitions, to capture nonlinear relations among many input variables and outcomes using the boosting approach to machine learning. Longitudinal and comprehensive medical check-up data were collected from 25,942 participants who underwent multiple endoscopies from 2006 to 2017 at a single facility in Japan. The participants were classified into a case group (y=1) or a control group (y= 0) if gastric cancer was or was not detected, respectively, during a 122-month period. Among 1,431 total participants (89 cases and 1,342 controls), 1,144 (80%) were randomly selected for use in training 10 classification models; the remaining 287 (20%) were used to evaluate the models. The results showed that XGBoost outperformed logistic regression and showed the highest area under the curve value (0.899). Accumulating more data in the facility and performing further analyses including other input variables may help expand the clinical utility.
C1 [Taninaga, Junichi; Nishiyama, Yu] Univ Electrocommun, Fac Informat & Engn, Tokyo, Japan.
   [Fujibayashi, Kazutoshi; Naito, Toshio] Juntendo Univ, Sch Med, Dept Gen Med, Tokyo, Japan.
   [Gunji, Toshiaki; Sasabe, Noriko; Iijima, Kimiko] NTT Med Ctr Tokyo, Ctr Prevent Med, Tokyo, Japan.
   [Fujibayashi, Kazutoshi] Juntendo Univ, Med Technol Innovat Ctr, Tokyo, Japan.
   [Fujibayashi, Kazutoshi] Juntendo Univ Hosp, Clin Res & Trial Ctr, Tokyo, Japan.
C3 University of Electro-Communications - Japan; Juntendo University; Kanto
   Medical Center NTT EC; Juntendo University; Juntendo University
RP Fujibayashi, K (通讯作者)，Juntendo Univ, Sch Med, Dept Gen Med, Tokyo, Japan.; Fujibayashi, K (通讯作者)，Juntendo Univ, Med Technol Innovat Ctr, Tokyo, Japan.; Fujibayashi, K (通讯作者)，Juntendo Univ Hosp, Clin Res & Trial Ctr, Tokyo, Japan.
EM kfujiba@juntendo.ac.jp
RI Naito, Toshio/AAR-5071-2021
OI Nishiyama, Yu/0000-0001-9158-7131; Naito, Toshio/0000-0003-1646-9930
FU Novartis Pharma K.K.
FX We thank Forte Science Communications, Inc. for editorial assistance
   with a draft of this manuscript. This study was funded in part by a
   grant received by Kazutoshi Fujibayashi from Novartis Pharma K.K. (no
   reference number).
CR [Anonymous], 2012, EST CANC INC MORT PR
   Brochu E., 2010, ARXIV10122599 U BRIT
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   CORREA P, 1988, CANCER RES, V48, P3554
   CORREA P, 1990, CANCER-AM CANCER SOC, V66, P2569, DOI 10.1002/1097-0142(19901215)66:12<2569::AID-CNCR2820661220>3.0.CO;2-I
   Evans JA, 2015, GASTROINTEST ENDOSC, V82, P1, DOI 10.1016/j.gie.2015.03.1967
   Feng F, 2018, BMC GASTROENTEROL, V18, DOI 10.1186/s12876-018-0877-9
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24783-4
   GENTA RM, 1998, GUT               S1, V43, pS3
   GitHub, XGBOOST DISTR DEEP M
   Hansson LE, 1996, NEW ENGL J MED, V335, P242, DOI 10.1056/NEJM199607253350404
   Hemminki K, 2010, ONCOLOGIST, V15, P548, DOI 10.1634/theoncologist.2009-0300
   Hinton DJ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02442-4
   Inoue M, 2006, ARCH INTERN MED, V166, P1871, DOI 10.1001/archinte.166.17.1871
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Jiang YY, 2016, CANCER BIOMARK, V16, P523, DOI 10.3233/CBM-160593
   Kashiwagi A, 2012, J DIABETES INVEST, V3, P39, DOI 10.1111/j.2040-1124.2012.00207.x
   Kikuchi S., 2000, MED PHARM, V43, P581
   Kim GH, 2016, GASTROINTEST ENDOSC, V84, P18, DOI 10.1016/j.gie.2016.02.028
   Krzanowski WJ, 2009, MONOGR STAT APPL PRO, V111, P1
   Landgren AM, 2011, CANCER-AM CANCER SOC, V117, P1163, DOI 10.1002/cncr.25524
   Liu RM, 2019, CHEM COMMUN, V55, P616, DOI 10.1039/c8cc08296k
   Longo-Mbenza B, 2007, INT J CARDIOL, V121, P229, DOI 10.1016/j.ijcard.2006.12.003
   Maeta K., 2018, JMIR DIABETES, V26
   Metz Charles E, 2006, J Am Coll Radiol, V3, P413, DOI 10.1016/j.jacr.2006.02.021
   Nashimoto A, 2013, GASTRIC CANCER, V16, P1, DOI 10.1007/s10120-012-0163-4
   Neugut AI, 1996, SEMIN ONCOL, V23, P281
   Nishio M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195875
   Qiao Z, 2018, STUD HEALTH TECHNOL, V247, P111, DOI 10.3233/978-1-61499-852-5-111
   Schistosomes liver flukes and Helicobacter pylori, 1994, IARC MONOGR EVAL CAR, V61, P1
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   SILVIS SE, 1976, JAMA-J AM MED ASSOC, V235, P928, DOI 10.1001/jama.235.9.928
   Takeno S, 2014, WORLD J GASTROENTERO, V20, P13734, DOI 10.3748/wjg.v20.i38.13734
   TATSUTA M, 1993, INT J CANCER, V53, P70, DOI 10.1002/ijc.2910530114
   Tsugane S, 2007, GASTRIC CANCER, V10, P75, DOI 10.1007/s10120-007-0420-0
   Vannella L, 2013, ALIMENT PHARM THER, V37, P375, DOI 10.1111/apt.12177
   Watabe H, 2005, GUT, V54, P764, DOI 10.1136/gut.2004.055400
   Woodward M, 2000, J CLIN EPIDEMIOL, V53, P175, DOI 10.1016/S0895-4356(99)00171-7
   Yang P, 2009, EUR J CANCER, V45, P2867, DOI 10.1016/j.ejca.2009.04.019
NR 42
TC 37
Z9 37
U1 0
U2 13
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD AUG 27
PY 2019
VL 9
AR 12384
DI 10.1038/s41598-019-48769-y
PG 9
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA IT2UK
UT WOS:000482708800002
PM 31455831
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Gulati, S
   Patel, M
   Emmanuel, A
   Haji, A
   Hayee, B
   Neumann, H
AF Gulati, Shraddha
   Patel, Mehul
   Emmanuel, Andrew
   Haji, Amyn
   Hayee, Bu'Hussain
   Neumann, Helmut
TI The future of endoscopy: Advances in endoscopic image innovations
SO DIGESTIVE ENDOSCOPY
LA English
DT Review
DE Computer-assisted diagnosis; endoscopic imaging; optical diagnosis;
   robotic endoscopy
ID HELICOBACTER-PYLORI INFECTION; COMPUTER-AIDED DIAGNOSIS; CONVOLUTIONAL
   NEURAL-NETWORKS; COLORECTAL POLYP HISTOLOGY; SQUAMOUS-CELL CARCINOMA;
   ARTIFICIAL-INTELLIGENCE; QUANTITATIVE-ANALYSIS; CAPSULE ENDOSCOPY;
   GASTRIC-CANCER; GAZE PATTERNS
AB The latest state of the art technological innovations have led to a palpable progression in endoscopic imaging and may facilitate standardisation of practice. One of the most rapidly evolving modalities is artificial intelligence with recent studies providing real-time diagnoses and encouraging results in the first randomised trials to conventional endoscopic imaging. Advances in functional hypoxia imaging offer novel opportunities to be used to detect neoplasia and the assessment of colitis. Three-dimensional volumetric imaging provides spatial information and has shown promise in the increased detection of small polyps. Studies to date of self-propelling colonoscopes demonstrate an increased caecal intubation rate and possibly offer patients a more comfortable procedure. Further development in robotic technology has introduced ex vivo automated locomotor upper gastrointestinal and small bowel capsule devices. Eye-tracking has the potential to revolutionise endoscopic training through the identification of differences in experts and non-expert endoscopist as trainable parameters. In this review, we discuss the latest innovations of all these technologies and provide perspective into the exciting future of diagnostic luminal endoscopy.
C1 [Gulati, Shraddha; Patel, Mehul; Emmanuel, Andrew; Haji, Amyn; Hayee, Bu'Hussain] Kings Coll Hosp NHS Fdn Trust, Kings Inst Therapeut Endoscopy, Denmark Hill, London SE5 9RS, England.
   [Neumann, Helmut] Univ Hosp Mainz, Dept Med, Mainz, Germany.
C3 King's College Hospital NHS Foundation Trust; University Hospital Mainz
RP Gulati, S (通讯作者)，Kings Coll Hosp NHS Fdn Trust, Kings Inst Therapeut Endoscopy, Denmark Hill, London SE5 9RS, England.
EM shraddha.gulati@nhs.net
OI Hayee, Bu'Hussain/0000-0003-1670-8815
CR Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Almansa C, 2011, AM J GASTROENTEROL, V106, P1070, DOI 10.1038/ajg.2011.26
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Biddlestone J, 2015, INT J MOL MED, V35, P859, DOI 10.3892/ijmm.2015.2079
   Borys Magdalena, 2017, EJMT, V3, P11
   Bozzinin P, 1806, J PRACTISCHEN ARZNEY, V24, P107
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Ching HL, 2017, GUT, V66, pA230, DOI 10.1136/gutjnl-2017-314472.447
   Colgan SP, 2016, ANNU REV PATHOL-MECH, V11, P77, DOI 10.1146/annurev-pathol-012615-044231
   Committee AI, 2011, GASTROINTEST ENDOSC, V73, P419
   Dik VK, 2016, EUR J GASTROEN HEPAT, V28, P1400, DOI 10.1097/MEG.0000000000000717
   Eickhoff A, 2007, AM J GASTROENTEROL, V102, P261, DOI 10.1111/j.1572-0241.2006.01002.x
   Eltzschig HK, 2011, NEW ENGL J MED, V364, P656, DOI 10.1056/NEJMra0910283
   Fan QN, 2018, PROC CVPR IEEE, P8944, DOI 10.1109/CVPR.2018.00932
   Giatromanolaki A, 2003, J CLIN PATHOL, V56, P209, DOI 10.1136/jcp.56.3.209
   Gluck N, 2016, GASTROINTEST ENDOSC, V83, P998, DOI 10.1016/j.gie.2015.08.083
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Groth S, 2011, AM J GASTROENTEROL, V106, P1075, DOI 10.1038/ajg.2011.52
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hafner M, 2009, LECT NOTES COMPUT SC, V5761, P247, DOI 10.1007/978-3-642-04268-3_31
   Heung H, 2017, 2016 IEEE INT C ROB, DOI 10.1109/robio.2016.7866371
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Ikematsu H, 2018, GASTROINTEST ENDOSC, V87, pAB160
   Ishioka M, 2019, DIGEST ENDOSC, V31, pe34, DOI 10.1111/den.13306
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Kandel P, 2019, GASTROINTEST ENDOSC, V89, pAB403, DOI 10.1016/j.gie.2019.03.613
   Kaneko K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099055
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kelly BS, 2016, RADIOLOGY, V280, P252, DOI 10.1148/radiol.2016150409
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Kumahara K, 2019, DIGEST ENDOSC, DOI 10.1111/den.13397
   Lami M, 2018, ENDOSCOPY, V50, P701, DOI 10.1055/s-0044-101026
   Liao ZA, 2016, CLIN GASTROENTEROL H, V14, P1266, DOI 10.1016/j.cgh.2016.05.013
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Matsumura T, 2017, ENDOSCOPY, V49, P717, DOI 10.1055/s-0043-105572
   Misawa M, 2019, GASTROINTEST ENDOSC, V89, pAB646, DOI 10.1016/j.gie.2019.03.1134
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Miyaki R, 2013, J GASTROEN HEPATOL, V28, P841, DOI 10.1111/jgh.12149
   Mori Y, 2018, DIGEST ENDOSC, V30, P2017
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Neumann H, 2013, GASTROINTEST ENDOSC, V77, pAB463
   Neumann H, 2019, DIGEST ENDOSC, V31, P389, DOI 10.1111/den.13391
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Papkovsky DB, 2018, CELL MOL LIFE SCI, V75, P2963, DOI 10.1007/s00018-018-2840-x
   Priestman S, 2016, J ISLAM ARCHAEOL, V3, P1, DOI 10.1558/jia.26266
   Qi X, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2337314
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rey JF, 2010, ENDOSCOPY, V42, P541, DOI 10.1055/s-0030-1255521
   Saito T., 2015, J BIOMED OPT, V20, DOI [10.1117/1.JBO.20.12.126011, DOI 10.1117/1.JBO.20.12.126011]
   Sakata S, 2016, GUT, V65, P730, DOI 10.1136/gutjnl-2016-311507
   SATAVA RM, 1993, SURG ENDOSC-ULTRAS, V7, P429, DOI 10.1007/BF00311737
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin D, 2016, GASTROINTEST ENDOSC, V83, P107, DOI 10.1016/j.gie.2015.06.045
   Shiroma S, 2019, GASTROINTEST ENDOSC, V89, pAB189, DOI 10.1016/j.gie.2019.03.142
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Tafreshi MK, 2014, LECT NOTES COMPUT SC, V8673, P89, DOI 10.1007/978-3-319-10404-1_12
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tang DH, 2019, GASTROINTEST ENDOSC, V89, pAB654, DOI 10.1016/j.gie.2019.03.1148
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Togashi K, 2019, DIGEST ENDOSC, V31, P270, DOI 10.1111/den.13354
   Tokai Y, 2019, GASTROINTEST ENDOSC, V89, pAB169, DOI 10.1016/j.gie.2019.03.100
   Tumino E, 2017, EUR REV MED PHARMACO, V21, P819
   Tumino E, 2010, WORLD J GASTROENTERO, V16, P5452, DOI 10.3748/wjg.v16.i43.5452
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Vantaram SR, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.4.040901
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Ye ML, 2017, INT J COMPUT ASS RAD, V12, P1281, DOI 10.1007/s11548-017-1620-7
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zhdanov AV, 2017, CELL MOL LIFE SCI, V74, P141, DOI 10.1007/s00018-016-2323-x
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 89
TC 25
Z9 27
U1 0
U2 24
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD MAY
PY 2020
VL 32
IS 4
BP 512
EP 522
DI 10.1111/den.13481
EA AUG 2019
PG 11
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA LJ6VO
UT WOS:000482864200001
PM 31286574
OA Bronze
DA 2023-04-20
ER

PT J
AU Nartowt, BJ
   Hart, GR
   Roffman, DA
   Llor, X
   Ali, I
   Muhammad, W
   Liang, Y
   Deng, J
AF Nartowt, Bradley J.
   Hart, Gregory R.
   Roffman, David A.
   Llor, Xavier
   Ali, Issa
   Muhammad, Wazir
   Liang, Ying
   Deng, Jun
TI Scoring colorectal cancer risk with an artificial neural network based
   on self-reportable personal health data
SO PLOS ONE
LA English
DT Article
ID VIRTUAL COLONOSCOPY; PREDICTION; HYPERTENSION; PROGNOSIS; MORTALITY;
   PATHOGENESIS; NEOPLASIA; TESTS; TOOL
AB Colorectal cancer (CRC) is third in prevalence and mortality among all cancers in the US. Currently, the United States Preventative Services Task Force (USPSTF) recommends anyone ages 50-75 and/or with a family history to be screened for CRC. To improve screening specificity and sensitivity, we have built an artificial neural network (ANN) trained on 12 to 14 categories of personal health data from the National Health Interview Survey (NHIS). Years 1997-2016 of the NHIS contain 583,770 respondents who had never received a diagnosis of any cancer and 1409 who had received a diagnosis of CRC within 4 years of taking the survey. The trained ANN has sensitivity of 0.57 +/- 0.03, specificity of 0.89 +/- 0.02, positive predictive value of 0.0075 +/- 0.0003, negative predictive value of 0.999 +/- 0.001, and concordance of 0.80 +/- 0.05 per the guidelines of Transparent Reporting of Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD) level 2a, comparable to current risk-scoring methods. To demonstrate clinical applicability, both USPSTF guidelines and the trained ANN are used to stratify respondents to the 2017 NHIS into low-, medium- and high-risk categories (TRIPOD levels 4 and 2b, respectively). The number of CRC respondents misclassified as low risk is decreased from 35% by screening guidelines to 5% by ANN (in 60 cases). The number of non-CRC respondents misclassified as high risk is decreased from 53% by screening guidelines to 6% by ANN (in 25,457 cases). Our results demonstrate a robustly-tested method of stratifying CRC risk that is non-invasive, cost-effective, and easy to implement publicly.
C1 [Nartowt, Bradley J.; Hart, Gregory R.; Ali, Issa; Muhammad, Wazir; Liang, Ying; Deng, Jun] Yale Univ, Sch Med, Dept Therapeut Radiol, New Haven, CT 06510 USA.
   [Roffman, David A.] Sun Nucl Corp, Melbourne, FL USA.
   [Llor, Xavier] Yale Univ, Sch Med, Dept Digest Dis, New Haven, CT USA.
C3 Yale University; Yale University
RP Deng, J (通讯作者)，Yale Univ, Sch Med, Dept Therapeut Radiol, New Haven, CT 06510 USA.
EM jun.deng@yale.edu
OI Liang, Ying/0000-0002-4939-8705
FU National Institute of Biomedical Imaging and Bioengineering of the
   National Institutes of Health [R01EB022589]
FX Research reported in this publication was solely supported by the
   National Institute of Biomedical Imaging and Bioengineering of the
   National Institutes of Health under Award Number R01EB022589. DAR was
   initially funded by R01EB022589 when writing the first working version
   of the ANN. BJN et al. took over and continued this study with the
   funding of R01EB022589 while DAR went on to be employed and supported
   with salary by Sun Nuclear Corporation. Sun Nuclear Corporation provided
   support in the form of salaries for authors DAR, but did not have any
   additional role in the study design, data collection and analysis,
   decision to publish, or preparation of the manuscript. The specific
   roles of these authors are articulated in the `author contributions'
   section. The specific role of DAR is articulated in the 'author
   contributions' section. The content is solely the responsibility of the
   authors and does not necessarily represent the official views of the
   National Institutes of Health or of Sun Nuclear Corporation.; Research
   reported in this publication was supported by the National Institute of
   Biomedical Imaging and Bioengineering of the National Institutes of
   Health under Award Number R01EB022589. DAR was funded by R01EB022589
   while writing the first working version of the ANN, which BJN et al
   continued under R01EB022589 while DAR went on to be supported with
   salary by Sun Nuclear Corporation. Sun Nuclear Corporation did not have
   any additional role in the study design, data collection and analysis,
   decision to publish, or preparation of the manuscript. The specific role
   of DAR is articulated in the 'author contributions' section. The content
   is solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institutes of Health or of
   Sun Nuclear Corporation.
CR AALTONEN LA, 1993, SCIENCE, V260, P812, DOI 10.1126/science.8484121
   AHMED FE, 2005, MOL CANCER, V4, DOI DOI 10.1186/1476-5498-4-29
   Aleksandrova K, 2014, BMC MED, V12, DOI 10.1186/s12916-014-0168-4
   Allison JE, 2007, JNCI-J NATL CANCER I, V99, P1462, DOI 10.1093/jnci/djm150
   Andoni A, 2014, PROC 31ST INT CONF M
   [Anonymous], 2018, NATIONAL HEALTH INTE
   Benard F, 2018, WORLD J GASTROENTERO, V24, P124, DOI 10.3748/wjg.v24.i1.124
   Bertsekas DP, 1998, INTRODUCTION TO PROB
   Betes M, 2003, AM J GASTROENTEROL, V98, P2648, DOI 10.1016/j.amjgastroenterol.2203.09.041
   Bujanda L, 2010, WORLD J GASTROENTERO, V16, P862, DOI 10.3748/wjg.v16.i7.862
   Chen GC, 2014, CHINESE J CANCER RES, V26, P4, DOI 10.3978/j.issn.1000-9604.2014.02.03
   Chiang PPC, 2015, BRIT J CANCER, V112, pS77, DOI 10.1038/bjc.2015.46
   Choi Y, 2017, SEMIN ONCOL, V44, P34, DOI 10.1053/j.seminoncol.2017.02.002
   Cohen MH, 2007, ONCOLOGIST, V12, P356, DOI 10.1634/theoncologist.12-3-356
   Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.7326/M14-0697, 10.1002/bjs.9736, 10.1016/j.eururo.2014.11.025, 10.1038/bjc.2014.639, 10.1016/j.jclinepi.2014.11.010, 10.1136/bmj.g7594, 10.1186/s12916-014-0241-z, 10.7326/M14-0698]
   Cruz JA, 2006, CANCER INFORM, V2, P59
   Deng  J., 2014, KEY ENHANCE CORE COM, V1, P1
   Doleman B, 2016, TECH COLOPROCTOL, V20, P517, DOI 10.1007/s10151-016-1498-3
   Driver JA, 2007, AM J MED, V120, P257, DOI 10.1016/j.amjmed.2006.05.055
   Hajian-Tilaki K, 2013, CASP J INTERN MED, V4, P627
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Hart GR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205264
   Hippisley-Cox J, 2017, QCANCER
   Hosmer D.W., 2000, WILEY PS TX, V2nd, P147
   Hurwitz H, 2004, NEW ENGL J MED, V350, P2335, DOI 10.1056/NEJMoa032691
   IRVINE EJ, 1988, GUT, V29, P1188, DOI 10.1136/gut.29.9.1188
   Kaminski MF, 2014, GUT, V63, P1112, DOI 10.1136/gutjnl-2013-304965
   Lin CC, 2014, J CHIN MED ASSOC, V77, P508, DOI 10.1016/j.jcma.2014.03.007
   Little RJA, 1988, STAT ANAL, V43
   Lofton-Day C, 2008, CLIN CHEM, V54, P414, DOI 10.1373/clinchem.2007.095992
   Ma GK, 2014, CLIN GASTROENTEROL H, V12, P1624, DOI 10.1016/j.cgh.2014.01.042
   MANDEL JS, 1993, NEW ENGL J MED, V328, P1365, DOI 10.1056/NEJM199305133281901
   Paterson WG, 2006, CAN J GASTROENTEROL, V20, P411, DOI 10.1155/2006/343686
   Picard RR, 2012, J AM STAT ASSOC, V79, P575
   Pineau BC, 2001, J GASTROINTEST CANC, V30, P133, DOI 10.1385/IJGC:30:3:133
   Pineau BC, 2003, GASTROENTEROLOGY, V125, P304, DOI 10.1016/S0016-5085(03)00885-0
   Quintero E, 2012, GASTROENTEROL ENDOSC, V54, P1510, DOI DOI 10.11280/GEE.54.1510
   Roffman D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19907-9
   Rothwell PM, 2010, LANCET, V376, P1741, DOI 10.1016/S0140-6736(10)61543-7
   Sargent DJ, 2001, CANCER-AM CANCER SOC, V91, P1636, DOI 10.1002/1097-0142(20010415)91:8+<1636::AID-CNCR1176>3.0.CO;2-D
   Scartozzi M, 2009, ANN ONCOL, V20, P227, DOI 10.1093/annonc/mdn637
   Senore C, 2014, NEW ENGL J MED, V371, P185, DOI [10.1056/NEJMc1405215, 10.1056/NEJMoa1311194]
   Sharara N, 2016, CAN J GASTROEN TEROL, V2016
   Shaukat A, 2017, DIGEST DIS SCI, V62, P2511, DOI 10.1007/s10620-017-4682-z
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Song LL, 2016, WORLD J GASTRO ONCOL, V8, P793, DOI 10.4251/wjgo.v8.i11.793
   Syrigos KN, 2011, BIODRUGS, V25, P159, DOI 10.2165/11590180-000000000-00000
   Tu JV, 1996, J CLIN EPIDEMIOL, V49, P1225, DOI 10.1016/S0895-4356(96)00002-9
   Usher-Smith JA, 2016, CANCER PREV RES, V9, P13, DOI 10.1158/1940-6207.CAPR-15-0274
   van de Poll-Franse LV, 2012, DIABETOLOGIA, V55, P2163, DOI 10.1007/s00125-012-2555-8
   Yeoh KG, 2011, GUT, V60, P1236, DOI 10.1136/gut.2010.221168
NR 51
TC 14
Z9 14
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD AUG 22
PY 2019
VL 14
IS 8
AR e0221421
DI 10.1371/journal.pone.0221421
PG 18
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA IW5RZ
UT WOS:000485036900069
PM 31437221
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Tanaka, I
   Hirasawa, D
   Saito, H
   Matsuda, T
   Nakahori, M
   Maeda, Y
   Okuzono, T
   Suzuki, K
   Igarashi, K
   Nawata, Y
   Ito, S
   Unno, S
   Chonan, A
AF Tanaka, Ippei
   Hirasawa, Dai
   Saito, Hiroaki
   Matsuda, Tomoki
   Nakahori, Masato
   Maeda, Yuki
   Okuzono, Toru
   Suzuki, Kenjiro
   Igarashi, Kimihiro
   Nawata, Yoshitaka
   Ito, Satoshi
   Unno, Shuhei
   Chonan, Akimichi
TI The sub-classification of type B2 vessels according to the magnifying
   endoscopic classification of the Japan Esophageal Society
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE Japan Esophageal Society classification; magnifying endoscopic
   diagnosis; narrow band imaging; squamous cell carcinoma; type B2 vessels
ID SQUAMOUS-CELL CARCINOMA; ARTIFICIAL-INTELLIGENCE; DEPTH; INVASION
AB Objectives Guidelines for magnified endoscopic diagnosis of esophageal squamous cell carcinoma (SCC) have been proposed by the Japan Esophageal Society. Type B1, B2, and B3 reflect increasing tumor invasion depths (within mucosal epithelium or into lamina propria mucosa [T1a-EP/LPM], into muscularis mucosa or superficial invasion into submucosa [T1a-MM/T1b-SM1], and into submucosa [T1b-SM2], respectively). The diagnostic accuracy of type B1 and B3 is high, but accuracy of type B2 is low. We aimed to improve the diagnostic accuracy of type B2. Methods We retrospectively reviewed 248 SCC lesions treated with endoscopic submucosal dissection between January 2012 and July 2018 and identified the B2 lesions. The maximum diameter of the area presenting B2 was measured and evaluated in relation to tumor invasion, for which receiver-operating characteristic (ROC) curves were generated. The optimal area size for distinguishing T1a-EP/LPM from T1a-MM or deeper invasion was determined. Results There were 78 lesions with B2, of which 26 (33%) were T1a-MM or T1b-SM1 SCCs. ROC curve analysis indicated that the optimal cut-off for the target area showing B2 was 4 mm. The invasion depth (EP/LPM: MM/SM1: SM2) of B2 observed in an area with a diameter <4 mm (B2-Narrow) and those with diameter >= 4 mm (B2-Broad) was 46:11:1 and 1:15:4, respectively. To predict T1a-MM or deeper invasion, B2-Broad had a sensitivity, specificity, positive predictive value, and negative predictive value of 61%, 98%, 95%, and 79%, respectively. Conclusion The diagnostic accuracy of type B2 was improved by evaluating the area of type B2.
C1 [Tanaka, Ippei; Hirasawa, Dai; Saito, Hiroaki; Matsuda, Tomoki; Nakahori, Masato; Maeda, Yuki; Okuzono, Toru; Suzuki, Kenjiro; Igarashi, Kimihiro; Nawata, Yoshitaka; Ito, Satoshi; Unno, Shuhei; Chonan, Akimichi] Sendai Kousei Hosp, Dept Gastroenterol, Sendai, Miyagi, Japan.
C3 Sendai Kousei Hospital
RP Tanaka, I (通讯作者)，Sendai Kousei Hosp, Dept Gastroenterol, Aoba Ku, 4-15 Hirose Machi, Sendai, Miyagi 9800873, Japan.
EM ippeitanaka777@gmail.com
RI SAITO, HIROAKI/HLH-2447-2023
OI SAITO, HIROAKI/0000-0002-0824-454X
CR Araki K, 2002, CANCER-AM CANCER SOC, V94, P570, DOI 10.1002/cncr.10190
   Arima H., 1998, GASTROENTEROL ENDOSC, V40, P1125
   Arima M., 2010, STOMACH INTEST, V45, P1515
   Arima M., 2005, ESOPHAGUS-TOKYO, V2, P191, DOI [DOI 10.1007/S10388-005-0060-6, 10.1007/s10388-005-0060-6]
   Dobashi A, 2014, STOMACH INTEST, V49, P153
   Everson M, 2019, UNITED EUR GASTROENT, V7, P297, DOI 10.1177/2050640618821800
   FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309
   Fujiwara J, 2014, STOMACH INTEST, V49, P174
   Inoue H., 1997, DIGEST ENDOSC, V9, P16, DOI [10.1111/j.1443-1661.1997.tb00453.x, DOI 10.1111/j.1443-1661.1997.tb00453.x]
   Ishihara R, 2017, BMC GASTROENTEROL, V17, DOI 10.1186/s12876-017-0574-0
   Japan Esophageal Society, 2008, JAP CLASS ES CANC, V10
   Kumagai Y, 2002, LANCET ONCOL, V3, P604, DOI 10.1016/S1470-2045(02)00874-4
   Kumagai Y, 2002, ENDOSCOPY, V34, P369, DOI 10.1055/s-2002-25285
   Kumagai Y, 2010, DIGEST ENDOSC, V22, P259, DOI 10.1111/j.1443-1661.2010.01010.x
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Momma K, 2011, STOMACH INTESTINE, V46, P650
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Murata Y, 1996, GASTROINTEST ENDOSC, V44, P23, DOI 10.1016/S0016-5107(96)70224-9
   Murata Y, 1987, Surg Endosc, V1, P11, DOI 10.1007/BF00703081
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Oyama T., 2011, ESOPHAGUS, V8, P247, DOI DOI 10.1007/S10388-011-0301-9
   Oyama T., 2012, ENDOSC DIG, V24, P466
   Oyama T, 2017, ESOPHAGUS-TOKYO, V14, P105, DOI 10.1007/s10388-016-0527-7
   Sato H, 2015, ENDOSCOPY, V47, P122, DOI 10.1055/s-0034-1390858
   Takahashi A., 2018, STOMACH INTESTINE, V53, P1362
   Takeuchi M., 2018, STOMACH INTESTINE, V53, P1343
   Tanaka S, 2002, ONCOL REP, V9, P1005
NR 27
TC 5
Z9 5
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JAN
PY 2020
VL 32
IS 1
BP 49
EP 55
DI 10.1111/den.13459
EA AUG 2019
PG 7
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA KA4LY
UT WOS:000481973500001
PM 31177563
DA 2023-04-20
ER

PT J
AU Azer, SA
AF Azer, Samy A.
TI Challenges Facing the Detection of Colonic Polyps: What Can Deep
   Learning Do?
SO MEDICINA-LITHUANIA
LA English
DT Review
DE deep learning; convolutional neural network (CNN); colonic polyps;
   colorectal cancer; adenoma; colonoscopy; artificial intelligence;
   computer-aided diagnosis; surveillance
ID ADENOMA DETECTION RATE; COLONOSCOPY WITHDRAWAL TIME; COLORECTAL-CANCER;
   QUALITY INDICATORS; RISK; CLASSIFICATION; CARCINOMA; PROPOSAL; CATENIN;
   RATES
AB Colorectal cancer (CRC) is one of the most common causes of cancer mortality in the world. The incidence is related to increases with age and western dietary habits. Early detection through screening by colonoscopy has been proven to effectively reduce disease-related mortality. Currently, it is generally accepted that most colorectal cancers originate from adenomas. This is known as the adenoma-carcinoma sequence, and several studies have shown that early detection and removal of adenomas can effectively prevent the development of colorectal cancer. The other two pathways for CRC development are the Lynch syndrome pathway and the sessile serrated pathway. The adenoma detection rate is an established indicator of a colonoscopy's quality. A 1% increase in the adenoma detection rate has been associated with a 3% decrease in interval CRC incidence. However, several factors may affect the adenoma detection rate during a colonoscopy, and techniques to address these factors have been thoroughly discussed in the literature. Interestingly, despite the use of these techniques in colonoscopy training programs and the introduction of quality measures in colonoscopy, the adenoma detection rate varies widely. Considering these limitations, initiatives that use deep learning, particularly convolutional neural networks (CNNs), to detect cancerous lesions and colonic polyps have been introduced. The CNN architecture seems to offer several advantages in this field, including polyp classification, detection, and segmentation, polyp tracking, and an increase in the rate of accurate diagnosis. Given the challenges in the detection of colon cancer affecting the ascending (proximal) colon, which is more common in women aged over 65 years old and is responsible for the higher mortality of these patients, one of the questions that remains to be answered is whether CNNs can help to maximize the CRC detection rate in proximal versus distal colon in relation to a gender distribution. This review discusses the current challenges facing CRC screening and training programs, quality measures in colonoscopy, and the role of CNNs in increasing the detection rate of colonic polyps and early cancerous lesions.
C1 [Azer, Samy A.] King Saud Univ, Dept Med Educ, Coll Med, Riyadh 11461, Saudi Arabia.
C3 King Saud University
RP Azer, SA (通讯作者)，King Saud Univ, Dept Med Educ, Coll Med, Riyadh 11461, Saudi Arabia.
EM azer2000@optusnet.com.au
RI Azer, Samy A./C-8485-2009
OI Azer, Samy A./0000-0001-5638-3256
FU College of Medicine Research Center, Deanship of Scientific Research,
   King Saud University, Riyadh, Saudi Arabia
FX This work was funded by the College of Medicine Research Center,
   Deanship of Scientific Research, King Saud University, Riyadh, Saudi
   Arabia.
CR Abdelfatah MM, 2017, SCAND J GASTROENTERO, V52, P1148, DOI 10.1080/00365521.2017.1339827
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   American Cancer Society, 2014, COL CANC FACTS FIG 2
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Baxter NN, 2011, GASTROENTEROLOGY, V140, P65, DOI 10.1053/j.gastro.2010.09.006
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Benedict M, 2015, WORLD J GASTROENTERO, V21, P12735, DOI 10.3748/wjg.v21.i45.12735
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Bourroul GM, 2016, EINSTEIN-SAO PAULO, V14, P135, DOI 10.1590/S1679-45082016AO3678
   Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012
   Brenner H, 2014, LANCET, V383, P1490, DOI 10.1016/S0140-6736(13)61649-9
   Brenner H, 2010, J NATL CANCER I, V102, P89, DOI 10.1093/jnci/djp436
   Canziani A., 2017, C ICLR
   Church J, 2014, SURG ONCOL CLIN N AM, V23, P1, DOI 10.1016/j.soc.2013.09.001
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dekker E, 2018, GASTROENTEROLOGY, V154, P1970, DOI 10.1053/j.gastro.2018.01.069
   Erichsen R, 2016, GASTROENTEROLOGY, V150, P895, DOI 10.1053/j.gastro.2015.11.046
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Haj-Hassan Hawraa, 2017, J Pathol Inform, V8, P1, DOI 10.4103/jpi.jpi_47_16
   HIXSON LJ, 1990, JNCI-J NATL CANCER I, V82, P1769, DOI 10.1093/jnci/82.22.1769
   Hoff G, 2017, ENDOSC INT OPEN, V5, pE489, DOI 10.1055/s-0043-106180
   Huang YL, 2012, DIGESTION, V86, P148, DOI 10.1159/000338680
   Hubel D, 2012, NEURON, V75, P182, DOI 10.1016/j.neuron.2012.07.002
   Jacob BJ, 2012, GASTROINTEST ENDOSC, V76, P355, DOI 10.1016/j.gie.2012.03.247
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Kainz P, 2017, PEERJ, V5, DOI 10.7717/peerj.3874
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kanczuga-Koda L, 2014, ONCOL LETT, V7, P1863, DOI 10.3892/ol.2014.1970
   Kim SE, 2015, WORLD J GASTROENTERO, V21, P5167, DOI 10.3748/wjg.v21.i17.5167
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee TJW, 2013, ENDOSCOPY, V45, P20, DOI 10.1055/s-0032-1325803
   Lund Martin, 2017, JBI Database System Rev Implement Rep, V15, P1991, DOI 10.11124/JBISRIR-2016-003241
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Men K, 2017, MED PHYS, V44, P6377, DOI 10.1002/mp.12602
   Oines M, 2017, BEST PRACT RES CL GA, V31, P419, DOI 10.1016/j.bpg.2017.06.004
   Pohl J, 2008, AM J GASTROENTEROL, V103, P562, DOI 10.1111/j.1572-0241.2007.01670.x
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2006, AM J GASTROENTEROL, V101, P2866, DOI 10.1111/j.1572-0241.2006.00905.x
   Rex DK, 2013, GASTROENTEROL CLIN N, V42, P429, DOI 10.1016/j.gtc.2013.05.009
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sanduleanu S, 2015, GUT, V64, P1257, DOI 10.1136/gutjnl-2014-307992
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Singh R, 2016, WORLD J GASTROENTERO, V22, P7754, DOI 10.3748/wjg.v22.i34.7754
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vavricka SR, 2016, ENDOSCOPY, V48, P256, DOI 10.1055/s-0035-1569674
   White BD, 2012, GASTROENTEROLOGY, V142, P219, DOI 10.1053/j.gastro.2011.12.001
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhao TY, 2019, IEEE T PATTERN ANAL, V41, P1072, DOI 10.1109/TPAMI.2018.2828821
   Zhu FC, 2019, HERED CANCER CLIN PR, V17, DOI 10.1186/s13053-019-0108-6
NR 55
TC 21
Z9 23
U1 3
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 1010-660X
EI 1648-9144
J9 MEDICINA-LITHUANIA
JI Med. Lith.
PD AUG
PY 2019
VL 55
IS 8
AR 473
DI 10.3390/medicina55080473
PG 13
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA IZ0GQ
UT WOS:000486769900072
PM 31409050
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Cogan, T
   Cogan, M
   Tamil, L
AF Cogan, Timothy
   Cogan, Maribeth
   Tamil, Lakshman
TI MAPGI: Accurate identification of anatomical landmarks and diseased
   tissue in gastrointestinal tract using deep learning
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Endoscopy; Gastrointestinal tract; Image enhancement; Machine learning;
   Neural network; Deep learning
AB Automatic detection of anatomical landmarks and diseases in medical images is a challenging task which could greatly aid medical diagnosis and reduce the cost and time of investigational procedures. Also, two particular challenges of digital image processing in medical applications are the sparsity of annotated medical images and the lack of uniformity across images and image classes. This paper presents methodologies for maximizing classification accuracy on a small medical image dataset, the Kvasir dataset, by performing robust image preprocessing and applying state-of-the-art deep learning. Images are classified as being or involving an anatomical landmark (pylorus, z-line, cecum), a diseased state (esophagitis, ulcerative colitis, polyps), or a medical procedure (dyed lifted polyps, dyed resection margins). A framework for modular and automatic preprocessing of gastrointestinal tract images (MAPGI) is proposed, which applies edge removal, contrast enhancement, filtering, color mapping and scaling to each image in the dataset. Gamma correction values are automatically calculated for individual images such that the mean pixel value for each image is normalized to 90 +/- 1 in a 0-255 pixel value range. Three state-of-the-art neural networks architectures, Inception-ResNet-v2, Inception-v4, and NASNet, are trained on the Kvasir dataset, and their classification performance is juxtaposed on validation data. In each case, 85% of the images from the Kvasir dataset are used for training, while the other 15% are reserved for validation. The resulting accuracies achieved using Inception-v4, Inception-ResNet-v2, and NASNet were 0.9845, 0.9848, and 0.9735, respectively. In addition, Inception-v4 achieved an average of 0.938 precision, 0.939 recall, 0.991 specificity, 0.938 F1 score, and 0.929 Matthews correlation coefficient (MCC). Bootstrapping provided NASNet, the worst performing model, a lower bound of 0.9723 accuracy on the 95% confidence interval.
C1 [Cogan, Timothy; Cogan, Maribeth; Tamil, Lakshman] Univ Texas Dallas, Dept Elect & Comp Engn, Qual Life Technol Lab, Richardson, TX 75080 USA.
C3 University of Texas System; University of Texas Dallas
RP Cogan, T (通讯作者)，Univ Texas Dallas, Dept Elect & Comp Engn, Qual Life Technol Lab, Richardson, TX 75080 USA.
EM timothy.cogan@utdallas.edu; mxr127730@utdallas.edu; laxman@utdallas.edu
OI Cogan, Timothy/0000-0002-2998-3915
CR Abadi, 2015, TENSORFLOW LARGE SCA
   Agrawal T., SCL UMD MED TASK MED
   Cogan T, 2019, COMPUT BIOL MED, V107, P18, DOI 10.1016/j.compbiomed.2019.01.024
   Domhan T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3460
   Furukawa H., 2017, SPACE AERONAUT NAVIG, V30, P13
   Gribbon KT, 2004, INT SYM ELECT DES TE, P126
   HADDAD RA, 1991, IEEE T SIGNAL PROCES, V39, P723, DOI 10.1109/78.80892
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kim M., 2017, DOCTORAL CONSORTIUM, P32
   Lau S., 2017, WALKTHROUGH CONVOLUT
   Liu Y., HKBU MEDIAEVAL 2017
   Naqvi S.S.A., ENSEMBLE TEXTURE FEA
   Peery AF, 2012, GASTROENTEROLOGY, V143, P1179, DOI 10.1053/j.gastro.2012.08.002
   Petscharnig S., 2017, INCEPTION LIKE CNN A
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Szegedy C., ABS1602201607261 COR
   Torres L., 1999, IEEE INT C IM PROC, V3, P627
   Zoph B., ABS1707201707012 COR
   Zuiderveld K., 1994, GRAPHICS GEMS
NR 20
TC 31
Z9 31
U1 4
U2 13
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD AUG
PY 2019
VL 111
AR 103351
DI 10.1016/j.compbiomed.2019.103351
PG 8
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA IX7HM
UT WOS:000485854400027
PM 31325742
DA 2023-04-20
ER

PT J
AU Dong, TS
   Kalani, A
   Aby, ES
   Le, L
   Luu, K
   Hauer, M
   Kamath, R
   Lindor, KD
   Tabibian, JH
AF Dong, Tien S.
   Kalani, Amir
   Aby, Elizabeth S.
   Long Le
   Luu, Kayti
   Hauer, Meg
   Kamath, Rahul
   Lindor, Keith D.
   Tabibian, James H.
TI Machine Learning-based Development and Validation of a Scoring System
   for Screening High-Risk Esophageal Varices
SO CLINICAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE CTP; INR; AST; BUN; Hemoglobin; Risk Analysis
ID COUNT/SPLEEN DIAMETER RATIO; BAVENO VI CRITERIA; PORTAL-HYPERTENSION;
   PREDICT; DIAGNOSIS; CIRRHOSIS
AB BACKGROUND & AIMS: Many patients with cirrhosis who undergo esophagogastroduodenoscopy (EGD) screening for esophageal varices (EVs) are found to have no or only small EVs. Endoscopic screening for EVs is therefore a potentially deferrable procedure that increases patient risk and healthcare cost. We developed and validated a scoring system, based on readily-available data, to reliably identify patients with EVs that need treatment.
   METHODS: We collected data from 238 patients with cirrhosis undergoing screening EGD from January 2016 through December 2017 at 3 separate hospitals in Los Angeles (training cohort). We abstracted data on patient sex, age, race/ethnicity, platelet counts, and levels of hemoglobin, serum sodium, aspartate aminotransferase, alanine aminotransferase, total bilirubin, international normalized ratio, albumin, urea nitrogen, and creatinine. We also included etiology of cirrhosis, presence of ascites, and presence of hepatic encephalopathy. We used a random forest algorithm to identify factors significantly associated with the presence of EVs and varices needing treatment (VNT) and calculated area under the receiver operating characteristic curve (AUROC). We called the resulting formula the EVendo score. We tested the accuracy of EVendo in a prospective study of 109 patients undergoing screening EGDs at the same medical centers from January 2018 through December 2018 (validation cohort).
   RESULTS: We developed an algorithm that identified patients with EVs and VNT based on international normalized ratio, level of aspartate aminotransferase, platelet counts, urea nitrogen, hemoglobin, and presence of ascites. The EVendo score identified patients with EVs in the training set with an AUROC of 0.84, patients with EVs in the validation set with and AUROC of 0.82, and EVs in patients with cirrhosis Child-Turcotte-Pugh class A (n = 235) with an AUROC of 0.81. The score identified patients with VNT in the training set with an AUROC of 0.74, VNT in the validation set with and AUROC of 0.75, and VNT in patients with cirrhosis Child-Turcotte-Pugh class A with and AUROC of 0.75. An EVendo score below 3.90 would have spared 30.5% patients from EGDs, missing only 2.8% of VNT. The same cutoff would have spared 40.0% of patients with Child-Turcotte-Pugh class A cirrhosis from EGDs, missing only 1.1% of VNT.
   CONCLUSIONS: We algorithmically developed a formula, called the EVendo score, that can be used to predict EVs and VNT based on readily available data in patients with cirrhosis. This score could help patients at low risk for VNT avoid unnecessary EGDs.
C1 [Dong, Tien S.; Kalani, Amir; Aby, Elizabeth S.; Luu, Kayti; Hauer, Meg; Kamath, Rahul] Univ Calif Los Angeles, David Geffen Sch Med, Dept Med, Vatche & Tamar Manoukian Div Digest Dis, Los Angeles, CA 90095 USA.
   [Long Le] Univ Calif Los Angeles, Olive View Internal Med Residency Program, Sylmar, CA USA.
   [Lindor, Keith D.] Arizona State Univ, Coll Hlth Solut, Phoenix, AZ USA.
   [Tabibian, James H.] Olive View UCLA Med Ctr, Dept Med, Div Gastroenterol, Sylmar, CA USA.
C3 University of California System; University of California Los Angeles;
   University of California Los Angeles Medical Center; David Geffen School
   of Medicine at UCLA; University of California System; University of
   California Los Angeles; Arizona State University; Arizona State
   University-Downtown Phoenix; University of California System; University
   of California Los Angeles
RP Tabibian, JH (通讯作者)，Olive View UCLA Med Ctr, Dept Med, 14445 Olive View Dr,2B-182, Sylmar, CA 91342 USA.
EM jtabibian@dhs.lacounty.gov
RI Aby, Elizabeth/AAF-9666-2021
OI Aby, Elizabeth/0000-0002-1809-2658; Tabibian, James/0000-0001-9104-1702;
   Le, Long/0000-0002-1450-6657
FU NIH [T32 DK 07180]
FX Grant support NIH T32 DK 07180 (T.D.).
CR Abraldes JG, 2016, HEPATOLOGY, V64, P2173, DOI 10.1002/hep.28824
   Augustin S, 2017, HEPATOLOGY, V66, P1980, DOI 10.1002/hep.29363
   Baig WW, 2008, CAN J GASTROENTEROL, V22, P825, DOI 10.1155/2008/287274
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chalasani N, 1999, AM J GASTROENTEROL, V94, P3285
   Chang ML, 2014, J HEPATOL, V61, P1407, DOI 10.1016/j.jhep.2014.08.033
   Colli A, 2017, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008759.pub2
   Correia LM, 2011, GASTROINTEST ENDOSC, V73, P45, DOI 10.1016/j.gie.2010.09.025
   de Franchis R, 2015, J HEPATOL, V63, P743, DOI 10.1016/j.jhep.2015.05.022
   Garcia-Tsao G, 2017, HEPATOLOGY, V65, P310, DOI 10.1002/hep.28906
   Giannini E, 2003, GUT, V52, P1200, DOI 10.1136/gut.52.8.1200
   Giannini EG, 2006, AM J GASTROENTEROL, V101, P2511, DOI 10.1111/j.1572-0241.2006.00874.x
   Kamath PS, 2001, HEPATOLOGY, V33, P464, DOI 10.1053/jhep.2001.22172
   Madhotra R, 2002, J CLIN GASTROENTEROL, V34, P81, DOI 10.1097/00004836-200201000-00016
   RIGO GP, 1992, GASTROINTEST ENDOSC, V38, P425, DOI 10.1016/S0016-5107(92)70470-2
   Sousa M, 2017, REV ESP ENFERM DIG, V109, P704, DOI 10.17235/reed.2017.5052/2017
   Sterling RK, 2006, HEPATOLOGY, V43, P1317, DOI 10.1002/hep.21178
   Suk KT, 2014, CLIN MOL HEPATOL, V20, P6, DOI 10.3350/cmh.2014.20.1.6
NR 18
TC 31
Z9 31
U1 2
U2 5
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1542-3565
EI 1542-7714
J9 CLIN GASTROENTEROL H
JI Clin. Gastroenterol. Hepatol.
PD AUG
PY 2019
VL 17
IS 9
BP 1894
EP +
DI 10.1016/j.cgh.2019.01.025
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA IK8RR
UT WOS:000476863400037
PM 30708109
DA 2023-04-20
ER

PT J
AU Hajabdollahi, M
   Esfandiarpoor, R
   Khadivi, P
   Soroushmehr, SMR
   Karimi, N
   Najarian, K
   Samavi, S
AF Hajabdollahi, M.
   Esfandiarpoor, R.
   Khadivi, P.
   Soroushmehr, S. M. R.
   Karimi, N.
   Najarian, K.
   Samavi, S.
TI Segmentation of bleeding regions in wireless capsule endoscopy for
   detection of informative frames
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Wireless capsule endoscopy; Neural network quantization; Neural network
   pruning; Hardware implementation
AB Wireless capsule endoscopy (WCE) is an effective means for diagnosis of gastrointestinal disorders. Detection of informative scenes in WCE video could reduce the length of transmitted videos and help the diagnosis procedure. In this paper, we investigate the problem of simplification of neural networks for automatic bleeding region segmentation inside capsule endoscopy device. Suitable color channels are selected as neural networks inputs, and image classification is conducted using a multi-layer perceptron (MLP) and a convolutional neural network (CNN) separately. Both CNN and MLP structures are simplified to reduce the number of computational operations. Performances of two simplified networks are evaluated on a WCE bleeding image dataset using the DICE score. Simulation results show that applying simplification methods on both MLP and CNN structures reduces the number of computational operations significantly with AUC-ROC greater than 0.97. Although CNN performs better in comparison with the simplified MLP, the simplified MLP segments bleeding regions with a significantly smaller number of computational operations. Concerning the importance of having a simple structure or a more accurate model, each of the designed structures could be selected for inside capsule implementation. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Hajabdollahi, M.; Esfandiarpoor, R.; Karimi, N.; Samavi, S.] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Khadivi, P.] Seattle Univ, Dept Comp Sci, Seattle, WA 98122 USA.
   [Soroushmehr, S. M. R.; Najarian, K.; Samavi, S.] Univ Michigan, Michigan Ctr Integrat Res Crit Care, Ann Arbor, MI 48109 USA.
   [Soroushmehr, S. M. R.; Najarian, K.] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA.
   [Najarian, K.] Univ Michigan, Emergency Med Dept, Ann Arbor, MI 48109 USA.
C3 Isfahan University of Technology; Seattle University; University of
   Michigan System; University of Michigan; University of Michigan System;
   University of Michigan; University of Michigan System; University of
   Michigan
RP Soroushmehr, SMR (通讯作者)，Univ Michigan, Michigan Ctr Integrat Res Crit Care, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA.
EM ssoroush@umich.edu
RI Esfandiarpoor, Reza/AAO-8957-2021
OI Esfandiarpoor, Reza/0000-0001-9234-975X
CR [Anonymous], KID KOULAOUZIDIS LAK
   Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123
   Courbariaux M., 2016, ARXIV, P9
   Deeba F., 2016, BLEEDING IMAGES CORR
   Deeba F, 2016, IEEE IJCNN, P4650, DOI 10.1109/IJCNN.2016.7727810
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ghosh T., 2018, COMPUT BIOL MED
   Gray RM, 2011, ENTROPY AND INFORMATION THEORY , SECOND EDITION, P395, DOI 10.1007/978-1-4419-7970-4
   Hajabdollahi M., 2018, INT J CIRCUIT THEORY
   Han S., 2015, P ADV NEUR INF PROC, P1135
   Hanson S. J., 1989, ADV NEURAL INFORM PR, P177
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Jarray N., 2015, 12 INT MULT SYST SIG
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Keuchel M., 2014, VIDEO CAPSULE ENDOSC, V20
   Khorsandi MA, 2016, IEEE ENG MED BIO, P2050, DOI 10.1109/EMBC.2016.7591130
   Li H., 2016, INT C LEARNING REPRE
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lukac R, 2007, IMAGE PROCESS SER, P1
   Mehmood I, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0109-y
   Miri M. S., 2011, IEEE T BIOMED ENG
   Nasr-Esfahani E, 2018, BIOMED SIGNAL PROCES, V40, P240, DOI 10.1016/j.bspc.2017.09.012
   Sekuboyina A.K., 2017, 2017 IEEE 14 INT S B
   Solla S. A., 1990, ADV NEURAL INFORM PR, P598
   Suman Sugandh, 2017, Biochemical and Cellular Archives, V17, P1
   Tan JH, 2017, INFORM SCIENCES, V420, P66, DOI 10.1016/j.ins.2017.08.050
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Turcza P, 2013, IEEE J BIOMED HEALTH, V17, P1046, DOI 10.1109/JBHI.2013.2266101
   Turcza P, 2011, SENSOR ACTUAT A-PHYS, V172, P552, DOI 10.1016/j.sna.2011.09.026
   Yuan Y, 2017, PROC INT CONF ANTI, P1
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
NR 38
TC 6
Z9 7
U1 1
U2 9
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD AUG
PY 2019
VL 53
AR 101565
DI 10.1016/j.bspc.2019.101565
PG 11
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA IW9SS
UT WOS:000485334600010
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Oumrani, S
   Histace, A
   Abou Ali, E
   Pietri, O
   Becq, A
   Houist, G
   Nion-Larmurier, I
   Camus, M
   Florent, C
   Dray, X
AF Oumrani, Sarra
   Histace, Aymeric
   Abou Ali, Einas
   Pietri, Olivia
   Becq, Aymeric
   Houist, Guy
   Nion-Larmurier, Isabelle
   Camus, Marine
   Florent, Christian
   Dray, Xavier
TI Multi-criterion, automated, high-performance, rapid tool for assessing
   mucosal visualization quality of still images in small bowel capsule
   endoscopy
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID CLEANSING SCORE; GRADING SYSTEM; VALIDATION; EVALUATE
AB Background and study aims Capsule endoscopy (CE) is the preferred method for small bowel (SB) exploration. Its diagnostic yield can be reduced by poor mucosal visualization. We aimed to evaluate three electronic parameters - colorimetry, abundance of bubbles, and brightness - to assess the adequacy of mucosal visualization of SB-CE images. Patients and methods Six-hundred still images were randomly extracted from 30 complete and normal SB-CEs. Three experts independently evaluated these images according to a 10-point assessment grid. Any frame with a mean score above seven was considered adequately cleansed. Each image was analyzed electronically according to the three preset parameters, individually and then combined, with the experts' score as reference. A random forests methodology was used for machine learning and testing. Results The combination of the three electronic parameters achieved better discrimination of adequately from inadequately cleansed frames as compared to each individual parameter taken separately (sensitivity 90.0 % [95 %C. I. 84.1 - 95.9], specificity 87.7 % [95 %C. I. 81.3 - 94.2]). Conclusion This multi-criterion score constitutes a comprehensive, reproducible, reliable, automated and rapid cleansing score for SB-CE frames. A patent is pending at the European patent office.
C1 [Oumrani, Sarra; Abou Ali, Einas; Pietri, Olivia; Becq, Aymeric; Houist, Guy; Nion-Larmurier, Isabelle; Camus, Marine; Florent, Christian; Dray, Xavier] St Antoine Hosp, AP HP, Dept Hepatol & Gastroenterol, Paris, France.
   [Becq, Aymeric; Camus, Marine; Florent, Christian; Dray, Xavier] Sorbonne Univ, Paris, France.
   [Histace, Aymeric; Dray, Xavier] Univ Cergy Pontoise, CNRS, ENSEA, ETIS, F-95014 Cergy Pontoise, France.
C3 UDICE-French Research Universities; Sorbonne Universite; Assistance
   Publique Hopitaux Paris (APHP); Hopital Universitaire Saint-Antoine -
   APHP; UDICE-French Research Universities; Sorbonne Universite; Centre
   National de la Recherche Scientifique (CNRS); CY Cergy Paris Universite
RP Dray, X (通讯作者)，Sorbonne Univ, Endoscopy Unit, 184 Rue Faubourg St Antoine, F-75012 Paris, France.; Dray, X (通讯作者)，St Antoine Hosp, AP HP, 184 Rue Faubourg St Antoine, F-75012 Paris, France.
EM xavier.dray@aphp.fr
RI camus, marine/O-8570-2017
OI camus, marine/0000-0003-2566-3866
CR Abou Ali E, 2018, ENDOSC INT OPEN, V6, pE646, DOI 10.1055/a-0581-8758
   Albert J, 2004, GASTROINTEST ENDOSC, V59, P487, DOI 10.1016/S0016-5107(04)00003-3
   [Anonymous], 1995, P 14 INT JOINT C ART
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brotz C, 2009, GASTROINTEST ENDOSC, V69, P262, DOI 10.1016/j.gie.2008.04.016
   Gkolfakis P, 2018, ENDOSCOPY, V50, P671, DOI 10.1055/s-0043-125207
   Goyal J, 2014, ENDOSC INT OPEN, V2, pE183, DOI 10.1055/s-0034-1377521
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Ninomiya K, 2012, DIGESTION, V86, P27, DOI 10.1159/000337937
   Park SC, 2010, WORLD J GASTROENTERO, V16, P875, DOI 10.3748/wjg.v16.i7.875
   Pietri O, 2018, ENDOSC INT OPEN, V6, pE462, DOI 10.1055/a-0573-1044
   Ponte A, 2016, WORLD J GASTRO ENDOS, V8, P600, DOI 10.4253/wjge.v8.i17.600
   Van Weyenberg SJB, 2011, ENDOSCOPY, V43, P406, DOI 10.1055/s-0030-1256228
NR 14
TC 8
Z9 8
U1 0
U2 0
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD AUG
PY 2019
VL 7
IS 8
BP E944
EP E948
DI 10.1055/a-0918-5883
PG 5
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA IM0SV
UT WOS:000477700400002
PM 31367673
OA gold, Green Submitted, Green Published
DA 2023-04-20
ER

PT J
AU Samel, NS
   Mashimo, H
AF Samel, Nicholas S.
   Mashimo, Hiroshi
TI Application of OCT in the Gastrointestinal Tract
SO APPLIED SCIENCES-BASEL
LA English
DT Review
DE gastrointestinal imaging; optical coherence tomography; Barrett's
   esophagus; artificial intelligence
ID OPTICAL COHERENCE TOMOGRAPHY; VOLUMETRIC LASER ENDOMICROSCOPY; TETHERED
   CAPSULE ENDOMICROSCOPY; BARRETTS-ESOPHAGUS; IN-VIVO; RADIOFREQUENCY
   ABLATION; BILIARY STRICTURES; MISS RATE; 3-DIMENSIONAL ENDOMICROSCOPY;
   ARTIFICIAL-INTELLIGENCE
AB Optical coherence tomography (OCT) is uniquely poised for advanced imaging in the gastrointestinal (GI) tract as it allows real-time, subsurface and wide-field evaluation at near-microscopic resolution, which may improve the current limitations or even obviate the need of superficial random biopsies in the surveillance of early neoplasias in the near future. OCT's greatest impact so far in the GI tract has been in the study of the tubular esophagus owing to its accessibility, less bends and folds and allowance of balloon employment with optimal contact to aid circumferential imaging. Moreover, given the alarming rise in the incidence of Barrett's esophagus and its progression to adenocarcinoma in the U.S., OCT has helped identify pathological features that may guide future therapy and follow-up strategy. This review will explore the current uses of OCT in the gastrointestinal tract and future directions, particularly with non-endoscopic office-based capsule OCT and the use of artificial intelligence to aid in diagnoses.
C1 [Samel, Nicholas S.] Dartmouth Coll, Hanover, NH 02090 USA.
   [Mashimo, Hiroshi] Harvard Med Sch, VA Boston Healthcare Syst, West Roxbury, MA 02132 USA.
C3 Dartmouth College; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); Harvard University; VA Boston Healthcare System
RP Mashimo, H (通讯作者)，Harvard Med Sch, VA Boston Healthcare Syst, West Roxbury, MA 02132 USA.
EM hmashimo@hms.harvard.edu
OI Samel, Nicholas/0000-0003-3420-440X
CR Adler DC, 2007, NAT PHOTONICS, V1, P709, DOI 10.1038/nphoton.2007.228
   Adler DC, 2009, OPT EXPRESS, V17, P784, DOI 10.1364/OE.17.000784
   Ahsen OO, 2019, ENDOSCOPY, V51, P355, DOI 10.1055/a-0725-7995
   Ahsen OO, 2017, THER ADV GASTROENTER, V10, P931, DOI 10.1177/1756283X17739503
   Antonelli MR, 2010, OPT EXPRESS, V18, P10200, DOI 10.1364/OE.18.010200
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Blechacz B, 2017, GUT LIVER, V11, P13, DOI 10.5009/gnl15568
   Bond A, 2015, WORLD J GASTRO ENDOS, V7, P969, DOI 10.4253/wjge.v7.i10.969
   Byrne MF, 2019, ENDOSCOPY, V51, P511, DOI 10.1055/a-0831-2549
   Cai SL, 2019, GASTROINTEST ENDOSC, V89, pAB654, DOI 10.1016/j.gie.2019.03.1149
   Cense B, 2004, OPT EXPRESS, V12, P2435, DOI 10.1364/OPEX.12.002435
   Chauhan SS, 2014, GASTROINTEST ENDOSC, V80, P928, DOI 10.1016/j.gie.2014.06.021
   Choma MA, 2003, OPT EXPRESS, V11, P2183, DOI 10.1364/OE.11.002183
   Cogliati A, 2016, OPT EXPRESS, V24, P13365, DOI 10.1364/OE.24.013365
   de Bellis M, 2002, GASTROINTEST ENDOSC, V56, P720, DOI 10.1067/mge.2002.129219
   de Boer JF, 2003, OPT LETT, V28, P2067, DOI 10.1364/OL.28.002067
   de Boer JF, 2017, BIOMED OPT EXPRESS, V8, P1838, DOI 10.1364/BOE.8.001838
   Endo T, 2002, GASTROINTEST ENDOSC, V55, P641, DOI 10.1067/mge.2002.123420
   Evans JA, 2006, CLIN GASTROENTEROL H, V4, P38, DOI 10.1016/S1542-3565(05)00746-9
   FERCHER AF, 1995, OPT COMMUN, V117, P43, DOI 10.1016/0030-4018(95)00119-S
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   GILGEN HH, 1989, J LIGHTWAVE TECHNOL, V7, P1225, DOI 10.1109/50.32387
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gora MJ, 2017, BIOMED OPT EXPRESS, V8, P2405, DOI 10.1364/BOE.8.002405
   Gora MJ, 2013, GASTROENTEROLOGY, V145, P723, DOI 10.1053/j.gastro.2013.07.053
   Gora MJ, 2013, NAT MED, V19, P238, DOI 10.1038/nm.3052
   Groff Rachel J, 2008, Curr Gastroenterol Rep, V10, P490, DOI 10.1007/s11894-008-0090-z
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Huo L, 2010, OPT EXPRESS, V18, P14375, DOI 10.1364/OE.18.014375
   Hur C, 2013, CANCER-AM CANCER SOC, V119, P1149, DOI 10.1002/cncr.27834
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Joshi V, 2017, GASTROINTEST ENDOSC, V85, pAB496, DOI 10.1016/j.gie.2017.03.1150
   Kamboj AK, 2019, DIS ESOPHAGUS, V32, DOI 10.1093/dote/doz037
   Kamboj AK, 2017, GASTROINTEST ENDOSC, V85, pAB518, DOI 10.1016/j.gie.2017.03.1193
   Kiesslich R, 2002, ENDOSCOPY, V34, P819, DOI 10.1055/s-2002-34259
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Ko TH, 2004, OPT EXPRESS, V12, P2112, DOI 10.1364/OPEX.12.002112
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Kurniawan N, 2017, COMPUT STRUCT BIOTEC, V15, P168, DOI 10.1016/j.csbj.2017.01.004
   Lagergren J, 2013, CA-CANCER J CLIN, V63, P232, DOI 10.3322/caac.21185
   Lee HC, 2017, GASTROINTEST ENDOSC, V86, P476, DOI 10.1016/j.gie.2017.01.034
   Lee HC, 2016, GASTROENTEROLOGY, V150, pS435, DOI 10.1016/S0016-5085(16)31511-6
   Lee MM, 2009, CAN J GASTROENTEROL, V23, P84, DOI 10.1155/2009/732481
   Leggett CL, 2016, GASTROINTEST ENDOSC, V83, P880, DOI 10.1016/j.gie.2015.08.050
   Leitgeb R, 2003, OPT EXPRESS, V11, P889, DOI 10.1364/OE.11.000889
   Lenz L, 2016, WORLD J GASTRO SURG, V8, P151, DOI 10.4240/wjgs.v8.i2.151
   Li XA, 2010, APPL PHYS LETT, V97, DOI 10.1063/1.3493659
   Li Y, 2018, OPT LETT, V43, P2074, DOI 10.1364/OL.43.002074
   Liang CP, 2019, BIOMED OPT EXPRESS, V10, P1207, DOI 10.1364/BOE.10.001207
   Liang KC, 2018, OPTICA, V5, P36, DOI 10.1364/OPTICA.5.000036
   Liang KC, 2017, OPT LETT, V42, P3193, DOI 10.1364/OL.42.003193
   Liang KC, 2015, BIOMED OPT EXPRESS, V6, P1146, DOI 10.1364/BOE.6.001146
   Liao Z, 2009, GASTROINTEST ENDOSC, V70, P201, DOI 10.1016/j.gie.2008.10.043
   Lu W, 2018, TRANSL VIS SCI TECHN, V7, DOI 10.1167/tvst.7.6.41
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Maes S, 2016, BEST PRACT RES CL GA, V30, P901, DOI 10.1016/j.bpg.2016.09.003
   Manfredi MA, 2015, GASTROINTEST ENDOSC, V81, P249, DOI 10.1016/j.gie.2014.06.020
   Masci E, 2009, DIGEST LIVER DIS, V41, P639, DOI 10.1016/j.dld.2009.02.002
   Masci E, 2007, J GASTROEN HEPATOL, V22, P2256, DOI 10.1111/j.1440-1746.2006.04725.x
   Mashimo H, 2013, CURR OPIN GASTROEN, V29, P454, DOI 10.1097/MOG.0b013e3283622796
   Mohri M., 2018, FDN MACHINE LEARNING
   Moon S, 2010, OPT EXPRESS, V18, P21183, DOI 10.1364/OE.18.021183
   Mu XJ, 2012, OPT EXPRESS, V20, P6325, DOI 10.1364/OE.20.006325
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V89, pAB191, DOI 10.1016/j.gie.2019.03.147
   Nojkov B, 2015, WORLD J GASTRO ENDOS, V7, P295, DOI 10.4253/wjge.v7.i4.295
   Pan YT, 2001, OPT LETT, V26, P1966, DOI 10.1364/OL.26.001966
   Park WG, 2015, AM J GASTROENTEROL, V110, P60, DOI 10.1038/ajg.2014.384
   Pfau PR, 2003, GASTROINTEST ENDOSC, V58, P196, DOI 10.1067/mge.2003.344
   Poneros JM, 2002, GASTROINTEST ENDOSC, V55, P84, DOI 10.1067/mge.2002.120098
   Popescu Dan P, 2011, Biophys Rev, V3, P155, DOI 10.1007/s12551-011-0054-7
   Pouw RE, 2009, AM J GASTROENTEROL, V104, P1366, DOI 10.1038/ajg.2009.88
   Pugliese V, 2001, GASTROINTEST ENDOSC, V54, P595, DOI 10.1067/mge.2001.119220
   Ramirez FC, 2008, GASTROINTEST ENDOSC, V68, P25, DOI 10.1016/j.gie.2007.10.040
   Robles FE, 2010, BIOMED OPT EXPRESS, V1, P310, DOI 10.1364/BOE.1.000310
   Rosch T, 2004, GASTROINTEST ENDOSC, V60, P390, DOI 10.1016/S0016-5107(04)01732-8
   Ryu SY, 2008, OPT LETT, V33, P2347, DOI 10.1364/OL.33.002347
   Sehgal V, 2014, GUT, V63, pA63, DOI 10.1136/gutjnl-2014-307263.132
   Seibel EJ, 2002, LASER SURG MED, V30, P177, DOI 10.1002/lsm.10029
   Seitz U, 2001, ENDOSCOPY, V33, P1018, DOI 10.1055/s-2001-18934
   Selvaggi SM, 2004, CYTOPATHOLOGY, V15, P74, DOI 10.1111/j.1365-2303.2004.00133.x
   Seward E, 2017, FRONTLINE GASTROENTE, V8, P90, DOI 10.1136/flgastro-2016-100764
   Sharma P, 2012, GASTROINTEST ENDOSC, V76, P252, DOI 10.1016/j.gie.2012.05.007
   Shen B, 2004, CLIN GASTROENTEROL H, V2, P1080, DOI 10.1016/S1542-3565(04)00621-4
   Shibata J, 2019, GASTROENTEROLOGY, V156, pS937
   Shimodate Y, 2017, ENDOSC INT OPEN, V5, pE722, DOI 10.1055/s-0043-110076
   Singh R, 2008, ENDOSCOPY, V40, P457, DOI 10.1055/s-2007-995741
   Song LMWK, 2007, GASTROINTEST ENDOSC, V66, P639, DOI 10.1016/j.gie.2007.05.029
   Song LMWK, 2011, GASTROINTEST ENDOSC, V73, P647, DOI 10.1016/j.gie.2010.11.006
   Souza RF, 2001, ALIMENT PHARM THER, V15, P1087, DOI 10.1046/j.1365-2036.2001.01046.x
   Steele D, 2019, WORLD J GASTROENTERO, V25, P2045, DOI 10.3748/wjg.v25.i17.2045
   Su JP, 2008, J BIOMED OPT, V13, DOI 10.1117/1.2938700
   Suter MJ, 2008, GASTROINTEST ENDOSC, V68, P745, DOI 10.1016/j.gie.2008.05.014
   Suter MJ, 2010, GASTROINTEST ENDOSC, V71, P346, DOI 10.1016/j.gie.2009.07.007
   Swager AF, 2017, GASTROINTEST ENDOSC, V85, P918, DOI 10.1016/j.gie.2016.09.012
   SWANSON EA, 1992, OPT LETT, V17, P151, DOI 10.1364/OL.17.000151
   SWANSON EA, 1993, OPT LETT, V18, P1864, DOI 10.1364/OL.18.001864
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   TAKADA K, 1987, APPL OPTICS, V26, P1603, DOI 10.1364/AO.26.001603
   Tearney GJ, 1997, SCIENCE, V276, P2037, DOI 10.1126/science.276.5321.2037
   Testoni PA, 2007, AM J GASTROENTEROL, V102, P269, DOI 10.1111/j.1572-0241.2006.00940.x
   Tokai Y, 2019, GASTROINTEST ENDOSC, V89, pAB169, DOI 10.1016/j.gie.2019.03.100
   Trindade AJ, 2018, UNITED EUR GASTROENT, V6, P838, DOI 10.1177/2050640618761701
   Trindade AJ, 2016, THER ADV GASTROENTER, V9, P128, DOI 10.1177/1756283X15615309
   Trindade AJ, 2015, GASTROINTEST ENDOSC, V82, P756, DOI 10.1016/j.gie.2015.03.1984
   Tsai TH, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.12.121716
   Tsai TH, 2014, GASTROENTEROLOGY, V147, P1219, DOI 10.1053/j.gastro.2014.08.034
   Tsai TH, 2014, DIAGNOSTICS, V4, P57, DOI 10.3390/diagnostics4020057
   Tsai TH, 2011, BIOMED OPT EXPRESS, V2, P2438, DOI 10.1364/BOE.2.002438
   Tumlinson AR, 2004, APPL OPTICS, V43, P113, DOI 10.1364/AO.43.000113
   Tyberg A, 2017, GASTROENTEROLOGY, V152, pS1032, DOI 10.1016/S0016-5085(17)33491-1
   Ughi GJ, 2016, BIOMED OPT EXPRESS, V7, P409, DOI 10.1364/BOE.7.000409
   Vakoc BJ, 2007, GASTROINTEST ENDOSC, V65, P898, DOI 10.1016/j.gie.2006.08.009
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang TS, 2016, JACC-CARDIOVASC IMAG, V9, P622, DOI 10.1016/j.jcmg.2015.08.010
   Wang Z, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122420
   Weston AP, 2001, AM J GASTROENTEROL, V96, P1355, DOI 10.1111/j.1572-0241.2001.03851.x
   Wieser W, 2010, OPT EXPRESS, V18, P14685, DOI 10.1364/OE.18.014685
   Wojtkowski M, 2004, AM J OPHTHALMOL, V138, P412, DOI 10.1016/j.ajo.2004.04.049
   Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457
   Wu JG, 2006, OPT LETT, V31, P1265, DOI 10.1364/OL.31.001265
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Xi JF, 2009, OPT LETT, V34, P1943, DOI 10.1364/OL.34.001943
   Yang Y, 2011, BIOMED OPT EXPRESS, V2, P2551, DOI 10.1364/BOE.2.002551
   Zagaynova E, 2008, J BIOPHOTONICS, V1, P114, DOI 10.1002/jbio.200710017
   Zhang N, 2014, OPT LETT, V39, P186, DOI 10.1364/OL.39.000186
   Zhou C, 2012, GASTROINTEST ENDOSC, V76, P32, DOI 10.1016/j.gie.2012.02.003
   Zhou Chao, 2009, Therap Adv Gastroenterol, V2, P149
   Zuccaro G, 2001, AM J GASTROENTEROL, V96, P2633
NR 129
TC 6
Z9 6
U1 3
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD AUG 1
PY 2019
VL 9
IS 15
AR 2991
DI 10.3390/app9152991
PG 16
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA IS4PB
UT WOS:000482134500046
OA gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Cho, M
   Kim, JH
   Hong, KS
   Kim, JS
   Kong, HJ
   Kim, S
AF Cho, Minwoo
   Kim, Jee Hyun
   Hong, Kyoung Sup
   Kim, Joo Sung
   Kong, Hyoun-Joong
   Kim, Sungwan
TI Identification of cecum time-location in a colonoscopy video by deep
   learning analysis of colonoscope movement
SO PEERJ
LA English
DT Article
DE Colonoscopy; Cecum; Cecal-location; Summary report; CNN; Deep learning
ID SCHUNCK OPTICAL-FLOW; ADENOMA DETECTION; MOLECULAR FUNCTIONS; WITHDRAWAL
   TIMES; INTUBATION; POLYP; INFORMATION; NETWORKS; IMAGES; YIELD
AB Background. Cecal intubation time is an important component for quality colonoscopy. Cecum is the turning point that determines the insertion and withdrawal phase of the colonoscope. For this reason, obtaining information related with location of the cecum in the endoscopic procedure is very useful. Also, it is necessary to detect the direction of colonoscope's movement and time-location of the cecum.
   Methods. In order to analysis the direction of scope's movement, the Horn-Schunck algorithm was used to compute the pixel's motion change between consecutive frames. Horn-Schunk-algorithm applied images were trained and tested through convolutional neural network deep learning methods, and classified to the insertion, withdrawal and stop movements. Based on the scope's movement, the graph was drawn with a value of +1 for insertion, -1 for withdrawal, and 0 for stop. We regarded the turning point as a cecum candidate point when the total graph area sum in a certain section recorded the lowest.
   Results. A total of 328,927 frame images were obtained from 112 patients. The overall accuracy, drawn from 5-fold cross-validation, was 95.6%. When the value of "t" was 30 s, accuracy of cecum discovery was 96.7%. In order to increase visibility, the movement of the scope was added to summary report of colonoscopy video. Insertion, withdrawal, and stop movements were mapped to each color and expressed with various scale. As the scale increased, the distinction between the insertion phase and the withdrawal phase became clearer.
   Conclusion. Information obtained in this study can be utilized as metadata for proficiency assessment. Since insertion and withdrawal are technically different movements, data of scope's movement and phase can be quantified and utilized to express pattern unique to the colonoscopist and to assess proficiency. Also, we hope that the findings of this study can contribute to the informatics field of medical records so that medical charts can be transmitted graphically and effectively in the field of colonoscopy.
C1 [Cho, Minwoo] Seoul Natl Univ, Grad Sch, Interdisciplinary Program Bioengn, Seoul, South Korea.
   [Kim, Jee Hyun] Seoul Natl Univ, Dept Gastroenterol, Boramae Med Ctr, Seoul, South Korea.
   [Hong, Kyoung Sup] Mediplex Sejong Hosp, Dept Gastroenterol, Incheon, South Korea.
   [Kim, Joo Sung] Seoul Natl Univ, Coll Med, Dept Internal Med, Seoul, South Korea.
   [Kong, Hyoun-Joong] Chungnam Natl Univ, Coll Med, Dept Biomed Engn, Daejeon, South Korea.
   [Kim, Sungwan] Seoul Natl Univ, Coll Med, Dept Biomed Engn, Seoul, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU); Seoul
   National University Hospital; Seoul National University (SNU); Chungnam
   National University; Seoul National University (SNU)
RP Kong, HJ (通讯作者)，Chungnam Natl Univ, Coll Med, Dept Biomed Engn, Daejeon, South Korea.; Kim, S (通讯作者)，Seoul Natl Univ, Coll Med, Dept Biomed Engn, Seoul, South Korea.
EM gongcop@cnu.ac.kr; sungwan@snu.ac.kr
FU National Research Foundation of Korea (NRF) - Korean Government
   [2018M1A3A3A02065779]; MSIT (Ministry of Science and ICT), Korea, under
   the ITRC (Information Technology Research Center) support program
   [IITP-2019-2018-0-01833]
FX This study was supported by the National Research Foundation of Korea
   (NRF) funded by the Korean Government (2018M1A3A3A02065779 to Sungwan
   Kim), and MSIT (Ministry of Science and ICT), Korea, under the ITRC
   (Information Technology Research Center) support program
   (IITP-2019-2018-0-01833) supervised by the IITP (Institute for
   Information & communications Technology Promotion). The funders had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
CR Ahn M, 2016, HEALTHC INFORM RES, V22, P270, DOI 10.4258/hir.2016.22.4.270
   Anderson BW, 2016, GASTROINTEST ENDOSC, V83, P201, DOI 10.1016/j.gie.2015.06.058
   Anderson JC, 2001, GASTROINTEST ENDOSC, V54, P558, DOI 10.1067/mge.2001.118950
   [Anonymous], 2014, J ELECTRON IMAGING
   Ballesteros C, 2016, PROGR PATTERN RECOGN, P401
   Barclay RL, 2008, CLIN GASTROENTEROL H, V6, P1091, DOI 10.1016/j.cgh.2008.04.018
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bernstein C, 2005, GASTROINTEST ENDOSC, V61, P72, DOI 10.1016/S0016-5107(04)02461-7
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Cherian S, 2004, AM J GASTROENTEROL, V99, P2324, DOI 10.1111/j.1572-0241.2004.40730.x
   Cho M, 2017, INT J COSMETIC SCI, V39, P426, DOI 10.1111/ics.12393
   Cho M, 2016, INT J COSMETIC SCI, V38, P399, DOI 10.1111/ics.12303
   Cho M, 2018, INT J COLORECTAL DIS, V33, P549, DOI 10.1007/s00384-018-2980-3
   Denny JC, 2010, J AM MED INFORM ASSN, V17, P383, DOI 10.1136/jamia.2010.004804
   Fallah M, 2017, HEALTHC INFORM RES, V23, P262, DOI 10.4258/hir.2017.23.4.262
   Fatima H, 2008, CLIN GASTROENTEROL H, V6, P109, DOI 10.1016/j.cgh.2007.10.009
   Gong XL, 2015, CHINESE J AERONAUT, V28, P1305, DOI 10.1016/j.cja.2015.07.005
   Greenhalgh T, 2010, BMJ-BRIT MED J, V340, DOI 10.1136/bmj.c3111
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu EZ, 2016, J MED BIOL ENG, V36, P344, DOI 10.1007/s40846-016-0138-8
   Jang Y, 2018, PEERJ, V6, DOI 10.7717/peerj.5764
   Kainz P, 2017, PEERJ, V5, DOI 10.7717/peerj.3874
   Le NQK, 2017, J MOL GRAPH MODEL, V73, P166, DOI 10.1016/j.jmgm.2017.01.003
   Lee HL, 2009, GASTROINTEST ENDOSC, V69, P503, DOI 10.1016/j.gie.2008.06.006
   Leiman DA, 2016, CLIN GASTROENTEROL H, V14, P333, DOI 10.1016/j.cgh.2015.12.001
   Leslie A, 2002, BRIT J SURG, V89, P845, DOI 10.1046/j.1365-2168.2002.02120.x
   MARSHALL JB, 1995, GASTROINTEST ENDOSC, V42, P287, DOI 10.1016/S0016-5107(95)70123-0
   MARSHALL JB, 1993, GASTROINTEST ENDOSC, V39, P518, DOI 10.1016/S0016-5107(93)70162-5
   Meinhardt-Llopis E, 2013, IMAGE PROCESS ON LIN, V3, P151, DOI 10.5201/ipol.2013.20
   Moritz V, 2012, ENDOSCOPY, V44, P476, DOI 10.1055/s-0032-1306898
   Munzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Nagasawa T, 2018, PEERJ, V6, DOI 10.7717/peerj.5696
   Le NQK, 2018, COMPUT BIOL CHEM, V77, P251, DOI 10.1016/j.compbiolchem.2018.10.010
   Le NQK, 2018, ANAL BIOCHEM, V555, P33, DOI 10.1016/j.ab.2018.06.011
   Le NQK, 2017, J COMPUT CHEM, V38, P2000, DOI 10.1002/jcc.24842
   Le NQK, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1163-x
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Park BE, 2016, HEALTHC INFORM RES, V22, P299, DOI 10.4258/hir.2016.22.4.299
   Qixin Cao, 1999, ACTA ELECT SINICA, V33, P880
   Quintero E, 2012, GASTROENT RES PRACT, V2012, DOI 10.1155/2012/846985
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Rex DK, 2001, ENDOSCOPY, V33, P60, DOI 10.1055/s-2001-11179
   Rex Douglas K, 2002, Gastrointest Endosc Clin N Am, V12, P65, DOI 10.1016/S1052-5157(03)00058-8
   Saifuddin T, 2000, GASTROINTEST ENDOSC, V51, P314, DOI 10.1016/S0016-5107(00)70361-0
   Simmons DT, 2006, ALIMENT PHARM THERAP, V24, P965, DOI 10.1111/j.1365-2036.2006.03080.x
   Snyder CW, 2010, AM SURGEON, V76, P743
   Spier BJ, 2010, GASTROINTEST ENDOSC, V71, P319, DOI 10.1016/j.gie.2009.05.012
   Taber A, 2010, GASTROINTEST ENDOSC, V71, P782, DOI 10.1016/j.gie.2009.12.008
   Taira RK, 2001, RADIOGRAPHICS, V21, P237, DOI 10.1148/radiographics.21.1.g01ja18237
   Taju SW, 2018, BIOINFORMATICS, V34, P3111, DOI 10.1093/bioinformatics/bty302
   Terada T, 2015, GASTROENTEROL REP, V3, P238, DOI 10.1093/gastro/gou093
   Vilarino F, 2007, LECT NOTES COMPUT SC, V4477, P290
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
NR 54
TC 4
Z9 4
U1 0
U2 3
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 2167-8359
J9 PEERJ
JI PeerJ
PD JUL 29
PY 2019
VL 7
AR e7256
DI 10.7717/peerj.7256
PG 17
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA IM0RN
UT WOS:000477696400004
PM 31392088
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Cohen, J
   Desilets, DJ
   Hwang, JH
   Baig, KRKK
   Leung, FW
   Maranki, JL
   Okolo, PI
   Swanstrom, LL
   Chak, A
AF Cohen, Jonathan
   Desilets, David J.
   Hwang, Joo Ha
   Baig, Kondal R. Kyanam Kabir
   Leung, Felix W.
   Maranki, Jennifer L.
   Okolo, Patrick I., III
   Swanstrom, Lee L.
   Chak, Amitabh
TI Gastrointestinal Endoscopy Editorial Board top 10 topics: advances in GI
   endoscopy in 2018
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID APPOSING METAL STENTS; FLUID COLLECTIONS; EFFICACY; SAFETY; ASSOCIATION;
   MANAGEMENT; OUTCOMES; NETWORK
AB The American Society for Gastrointestinal Endoscopy's Gastrointestinal Endoscopy Editorial Board reviewed original endoscopy-related articles published during 2018 in Gastrointestinal Endoscopy and 10 other leading medical and gastroenterology journals. Votes from each individual member were tallied to identify a consensus list of 10 topic areas of major advances in GI endoscopy. Individual board members summarized important findings published in these 10 areas of adenoma detection, bariatric endoscopy, EMR/submucosal dissection/full-thickness resection, artificial intelligence, expandable metal stents for palliation of biliary obstruction, pancreatic therapy with lumen-apposing metal stents, endoscope reprocessing, Barrett's esophagus, interventional EUS, and GI bleeding. This document summarizes these "Top 10" endoscopic advances of 2018.
OI Swanstrom, Lee/0000-0002-1740-463X; Hwang, Joo Ha/0000-0002-7534-230X
CR Abougergi MS, 2018, GASTROENTEROLOGY, V155, P38, DOI 10.1053/j.gastro.2018.03.033
   Akutsu D, 2018, GASTROINTEST ENDOSC, V88, P370, DOI 10.1016/j.gie.2018.04.2337
   Alqahtani A, 2019, GASTROINTEST ENDOSC, V89, P1132, DOI 10.1016/j.gie.2018.12.012
   Alsabah S, 2018, SURG OBES RELAT DIS, V14, P311, DOI 10.1016/j.soard.2017.12.001
   Amateau SK, 2018, OBES SURG, V28, P1445, DOI 10.1007/s11695-018-3171-6
   Anderloni A, 2019, GASTROINTEST ENDOSC, V89, P69, DOI 10.1016/j.gie.2018.08.047
   Andrisani G, 2019, DIGEST LIVER DIS, V51, P375, DOI 10.1016/j.dld.2018.09.030
   Balejko E, 2018, ANN NUTR METAB, V73, P290, DOI 10.1159/000493274
   Bang JY, 2018, GASTROINTEST ENDOSC, V88, P9, DOI 10.1016/j.gie.2018.03.012
   Bang JY, GUT
   Barakat MT, 2019, GASTROINTEST ENDOSC, V89, P124, DOI 10.1016/j.gie.2018.08.033
   Barakat MT, 2018, GASTROINTEST ENDOSC, V88, P601, DOI 10.1016/j.gie.2018.01.018
   Bartles RL, 2018, GASTROINTEST ENDOSC, V88, P306, DOI 10.1016/j.gie.2018.02.016
   Brandler J, 2018, CLIN GASTROENTEROL H, V16, P690, DOI 10.1016/j.cgh.2017.07.020
   Bukhari M, 2018, GASTROINTEST ENDOSC, V88, P486, DOI 10.1016/j.gie.2018.04.2356
   Caiazzo R, 2018, ENDOSCOPY, V50, P14, DOI 10.1055/s-0043-120439
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chen YI, 2018, GASTROINTEST ENDOSC, V88, P267, DOI 10.1016/j.gie.2018.03.021
   Chiang AL, 2018, GASTROINTEST ENDOSC, V88, P136, DOI 10.1016/j.gie.2018.02.035
   Codipilly DC, 2018, GASTROENTEROLOGY, V154, P2068, DOI 10.1053/j.gastro.2018.02.022
   Conio M, 2018, GASTROINTEST ENDOSC, V88, P283, DOI 10.1016/j.gie.2018.03.029
   Cook D, 2018, NEW ENGL J MED, V378, P2506, DOI 10.1056/NEJMra1605507
   Desai M, 2019, GASTROINTEST ENDOSC, V89, P453, DOI 10.1016/j.gie.2018.09.006
   Dulai GS, 2002, GASTROENTEROLOGY, V122, P26, DOI 10.1053/gast.2002.30297
   Facciorusso A, 2018, CLIN GASTROENTEROL H, V16, P1209, DOI 10.1016/j.cgh.2017.11.007
   Fuccio L, 2018, GASTROINTEST ENDOSC, V88, P589, DOI 10.1016/j.gie.2018.06.028
   Hadefi A, 2018, DIGEST DIS, V36, P322, DOI 10.1159/000487078
   Hammad T, 2018, DIGEST DIS SCI, V63, P289, DOI 10.1007/s10620-017-4851-0
   Higa JT, 2018, GASTROINTEST ENDOSC, V88, P223, DOI 10.1016/j.gie.2018.02.015
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Iyer PG, 2018, AM J GASTROENTEROL, V113, P1156, DOI 10.1038/s41395-018-0107-7
   Jang S, 2018, GASTROINTEST ENDOSC, V87, P1061, DOI 10.1016/j.gie.2017.08.024
   Jia H, J CLIN GASTROENTEROL
   Kadri SR, BMJ, V341
   Kinoshita S, 2018, GASTROINTEST ENDOSC, V87, P1079, DOI 10.1016/j.gie.2017.10.035
   Klein A, 2019, GASTROENTEROLOGY, V156, P604, DOI 10.1053/j.gastro.2018.10.003
   Kumbhari V, 2018, GASTROINTEST ENDOSC, V88, P175, DOI 10.1016/j.gie.2018.02.022
   Mohan BP, 2019, GASTROINTEST ENDOSC, V89, P238, DOI [10.1016/j.gie.2018.10.018, 10.1016/j.gie.2018.10.036]
   Moinova HR, 2018, SCI TRANSL MED, V10, DOI 10.1126/scitranslmed.aao5848
   Mok SRS, 2018, GASTROINTEST ENDOSC, V88, P919, DOI 10.1016/j.gie.2018.07.036
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mudireddy PR, 2018, GASTROINTEST ENDOSC, V87, P1256, DOI 10.1016/j.gie.2017.08.011
   Oakland K, 2018, GUT, V67, P654, DOI 10.1136/gutjnl-2016-313428
   Oh D, 2019, GASTROINTEST ENDOSC, V89, P289, DOI 10.1016/j.gie.2018.08.052
   Paik WH, 2018, AM J GASTROENTEROL, V113, P987, DOI 10.1038/s41395-018-0122-8
   Papastergiou V, 2018, ENDOSCOPY, V50, P403, DOI 10.1055/s-0043-118594
   Park JK, 2018, GASTROINTEST ENDOSC, V88, P277, DOI 10.1016/j.gie.2018.03.015
   Pittayanon R, 2018, GASTROINTEST ENDOSC, V87, P994, DOI 10.1016/j.gie.2017.11.013
   Quan E, 2018, AM J INFECT CONTROL, V46, P1272, DOI 10.1016/j.ajic.2018.04.224
   Ross-Innes CS, 2015, PLOS MED, V12, DOI 10.1371/journal.pmed.1001780
   Samarasena Jason B, 2018, VideoGIE, V3, P361, DOI 10.1016/j.vgie.2018.07.013
   Schmidt A, 2018, GASTROENTEROLOGY, V155, P674, DOI 10.1053/j.gastro.2018.05.037
   Schmidt A, 2018, GUT, V67, P1280, DOI 10.1136/gutjnl-2016-313677
   Schulman AR, 2018, GASTROINTEST ENDOSC, V87, P1222, DOI 10.1016/j.gie.2017.10.034
   Shi Xin, 2018, Oncotarget, V9, P30679, DOI 10.18632/oncotarget.25504
   Shirin H, 2019, GASTROINTEST ENDOSC, V89, P545, DOI 10.1016/j.gie.2018.09.028
   Tate CM, 2018, ADV THER, V35, P1, DOI 10.1007/s12325-017-0647-z
   Tsuchiya T, 2018, GASTROINTEST ENDOSC, V87, P1138, DOI 10.1016/j.gie.2017.08.017
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Visrodia K, 2018, GASTROINTEST ENDOSC, V87, P1396, DOI 10.1016/j.gie.2018.02.021
   Vyas D, 2017, WORLD J GASTROENTERO, V23, P7813, DOI 10.3748/wjg.v23.i44.7813
   Williet N, 2018, ENDOSCOPY, V50, P846, DOI 10.1055/a-0577-3500
   Yamada S, 2019, GASTROINTEST ENDOSC, V89, P950, DOI 10.1016/j.gie.2018.11.015
   Yan L, ENDOSC ULTRASOUND
   Zhang Z, 2018, DIGEST ENDOSC, V30, P321, DOI 10.1111/den.13012
   Zhao B, J GASTROINTEST SURG
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 68
TC 9
Z9 9
U1 0
U2 11
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JUL
PY 2019
VL 90
IS 1
BP 35
EP 43
DI 10.1016/j.gie.2019.03.020
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA ID9QI
UT WOS:000472021800004
PM 30928425
DA 2023-04-20
ER

PT J
AU Gomez, P
   Semmler, M
   Schutzenberger, A
   Bohr, C
   Dollinger, M
AF Gomez, Pablo
   Semmler, Marion
   Schuetzenberger, Anne
   Bohr, Christopher
   Doellinger, Michael
TI Low-light image enhancement of high-speed endoscopic videos using a
   convolutional neural network
SO MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING
LA English
DT Article
DE Convolutional neural network; Endoscopy; High-speed video; Image
   enhancement; Image processing
ID VOCAL FOLD VIBRATIONS; QUALITY ASSESSMENT; VOICE ASSESSMENT; REAL-TIME;
   RECONSTRUCTION; PREVALENCE
AB Laryngeal endoscopy is one of the primary diagnostic tools for laryngeal disorders. The main techniques are videostroboscopy and lately high-speed video endoscopy. Unfortunately, due to the restricting anatomy of the larynx and technical limitations of the recording equipment, many videos suffer from insufficient illumination, which complicates clinical examination and analysis. This work presents an approach to enhance low-light images from high-speed video endoscopy using a convolutional neural network. We introduce a new technique to generate realistically darkened training samples using Perlin noise. Extensive data augmentation is employed to cope with the limited training data allowing training with just 55 videos. The approach is compared against four state-of-the-art low-light enhancement methods and statistically significantly outperforms each on a no-reference (NIQE) and two full-reference (PSNR, SSIM) image quality metrics. The presented approach can be run on consumer-grade hardware and is thereby directly applicable in a clinical context. It is likely transferable to similar techniques such as videostroboscopy.
C1 [Gomez, Pablo; Semmler, Marion; Schuetzenberger, Anne; Doellinger, Michael] Friedrich Alexander Univ Erlangen Nurnberg, Univ Hosp Erlangen, Div Phoniatr & Pediat Audiol, Dept Otorhinolaryngol Head & Neck Surg, Waldstr 1, D-91054 Erlangen, Germany.
   [Bohr, Christopher] Univ Regensburg, Univ Hosp Regensburg, ENT Dept, Franz Josef Str Allee 11, D-93053 Regensburg, Germany.
C3 University of Erlangen Nuremberg; University of Regensburg
RP Gomez, P (通讯作者)，Friedrich Alexander Univ Erlangen Nurnberg, Univ Hosp Erlangen, Div Phoniatr & Pediat Audiol, Dept Otorhinolaryngol Head & Neck Surg, Waldstr 1, D-91054 Erlangen, Germany.
EM pablo.gomez@uk-erlangen.de; marion.semmler@uk-erlangen.de;
   anne.schuetzenberger@uk-erlangen.de; christopher.bohr@ukr.de;
   michael.doellinger@uk-erlangen.de
RI Gómez, Pablo/ACR-1278-2022; Gómez, Pablo/AAV-9527-2021
OI Gómez, Pablo/0000-0002-5631-8240; Gómez, Pablo/0000-0002-5631-8240;
   Doellinger, Michael/0000-0003-2717-4820
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [323308998, DO1247/8-1, BO4399/2-1]
FX This work was supported by Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation) - 323308998 under grant noS. DO1247/8-1 and
   BO4399/2-1.
CR Abadi, 2015, TENSORFLOW LARGE SCA
   Andrade-Miranda G, 2017, MED BIOL ENG COMPUT, V55, P2123, DOI 10.1007/s11517-017-1652-8
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Benjamin DJ, 2018, NAT HUM BEHAV, V2, P6, DOI 10.1038/s41562-017-0189-z
   Benninger MS, 2017, J VOICE, V31, P594, DOI 10.1016/j.jvoice.2017.01.011
   Bhattacharyya N, 2014, LARYNGOSCOPE, V124, P2359, DOI 10.1002/lary.24740
   Blau Y, 2017, ARXIV171106077
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Cohen SM, 2012, LARYNGOSCOPE, V122, P1582, DOI 10.1002/lary.23189
   Cutler JL, 2002, CURR OPIN OTOLARYNGO, V10, P462, DOI DOI 10.1097/00020840-200212000-00009
   Deliyski DD, 2008, FOLIA PHONIATR LOGO, V60, P33, DOI 10.1159/000111802
   Dollinger M, 2012, LARYNGOSCOPE, V122, P2511, DOI 10.1002/lary.23568
   Doellinger M, 2009, CURR BIOINFORM, V4, P101, DOI 10.2174/157489309788184774
   Dong XC, 2011, INT C PAR DISTRIB SY, P9, DOI 10.1109/ICPADS.2011.115
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Gloger O, 2015, IEEE T BIO-MED ENG, V62, P795, DOI 10.1109/TBME.2014.2364862
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Ioffe S., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099
   Kendall KA, 2012, CURR OPIN OTOLARYNGO, V20, P466, DOI 10.1097/MOO.0b013e328359840d
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Klambauer G., 2017, ADV NEURAL INFORM PR, P971, DOI DOI 10.5555/3294771.3294864
   Lagae A, 2010, COMPUT GRAPH FORUM, V29, P2579, DOI 10.1111/j.1467-8659.2010.01827.x
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lee JS, 2001, MED BIOL ENG COMPUT, V39, P273, DOI 10.1007/BF02345279
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lohscheller J, 2007, MED IMAGE ANAL, V11, P400, DOI 10.1016/j.media.2007.04.005
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Mehta DD, 2011, J ACOUST SOC AM, V130, P3999, DOI 10.1121/1.3658441
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Odena A., 2016, DISTILL, DOI [DOI 10.23915/DISTILL.00003, 10.23915/distill.00003.-URL]
   Patel R, 2008, ANN OTO RHINOL LARYN, V117, P413, DOI 10.1177/000348940811700603
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Rasp O, 2006, FOLIA PHONIATR LOGO, V58, P175, DOI 10.1159/000091731
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy N, 2013, AM J SPEECH-LANG PAT, V22, P212, DOI 10.1044/1058-0360(2012/12-0014)
   Semmler M, 2016, IEEE T MED IMAGING, V35, P1615, DOI 10.1109/TMI.2016.2521419
   Shen L., 2017, ARXIV171102488
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sommer DE, 2014, J ACOUST SOC AM, V136, P3290, DOI 10.1121/1.4900572
   Svec JG, 1996, J VOICE, V10, P201, DOI 10.1016/S0892-1997(96)80047-6
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tao LY, 2018, INT J PROD RES, V56, P1934, DOI 10.1080/00207543.2017.1394587
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang WJ, 2018, IEEE INT CONF AUTOMA, P751, DOI 10.1109/FG.2018.00118
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu SP, 2017, IETE TECH REV, V34, P223, DOI 10.1080/02564602.2016.1151385
   Zanartu M, 2011, J ACOUST SOC AM, V129, P326, DOI 10.1121/1.3514536
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Ziethe A, 2011, CURR BIOINFORM, V6, P270, DOI 10.2174/157489311796904682
NR 55
TC 29
Z9 29
U1 3
U2 34
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0140-0118
EI 1741-0444
J9 MED BIOL ENG COMPUT
JI Med. Biol. Eng. Comput.
PD JUL
PY 2019
VL 57
IS 7
BP 1451
EP 1463
DI 10.1007/s11517-019-01965-4
PG 13
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Mathematical & Computational Biology;
   Medical Informatics
GA IF3FW
UT WOS:000472967300005
PM 30900057
DA 2023-04-20
ER

PT J
AU Kudo, SE
   Mori, Y
   Misawa, M
   Takeda, K
   Kudo, T
   Itoh, H
   Oda, M
   Mori, K
AF Kudo, Shin-ei
   Mori, Yuichi
   Misawa, Masashi
   Takeda, Kenichi
   Kudo, Toyoki
   Itoh, Hayato
   Oda, Masahiro
   Mori, Kensaku
TI Artificial intelligence and colonoscopy: Current status and future
   perspectives
SO DIGESTIVE ENDOSCOPY
LA English
DT Review
DE automated; characterization; colon; detection
ID COMPUTER-AIDED DIAGNOSIS; CONFOCAL LASER ENDOMICROSCOPY; COLORECTAL
   POLYP HISTOLOGY; QUANTITATIVE-ANALYSIS; OPTICAL BIOPSY; PIT-PATTERN;
   SYSTEM; CLASSIFICATION; LESIONS; ENDOSCOPY
AB Background and Aim Application of artificial intelligence in medicine is now attracting substantial attention. In the field of gastrointestinal endoscopy, computer-aided diagnosis (CAD) for colonoscopy is the most investigated area, although it is still in the preclinical phase. Because colonoscopy is carried out by humans, it is inherently an imperfect procedure. CAD assistance is expected to improve its quality regarding automated polyp detection and characterization (i.e. predicting the polyp's pathology). It could help prevent endoscopists from missing polyps as well as provide a precise optical diagnosis for those detected. Ultimately, these functions that CAD provides could produce a higher adenoma detection rate and reduce the cost of polypectomy for hyperplastic polyps. Methods and Results Currently, research on automated polyp detection has been limited to experimental assessments using an algorithm based on ex vivo videos or static images. Performance for clinical use was reported to have >90% sensitivity with acceptable specificity. In contrast, research on automated polyp characterization seems to surpass that for polyp detection. Prospective studies of in vivo use of artificial intelligence technologies have been reported by several groups, some of which showed a >90% negative predictive value for differentiating diminutive (<= 5 mm) rectosigmoid adenomas, which exceeded the threshold for optical biopsy. Conclusion We introduce the potential of using CAD for colonoscopy and describe the most recent conditions for regulatory approval for artificial intelligence-assisted medical devices.
C1 [Kudo, Shin-ei; Mori, Yuichi; Misawa, Masashi; Takeda, Kenichi; Kudo, Toyoki] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
C3 Showa University; Nagoya University
RP Kudo, SE (通讯作者)，Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Tsuzuki Ku, 35-1 Chigasaki Tyuo, Yokohama, Kanagawa 2248503, Japan.
EM kudos@med.showa-u.ac.jp
RI Itoh, Hayato/AAM-4022-2021; Mori, Yuichi/AAU-5406-2020; Misawa,
   Masashi/H-9004-2019
OI Itoh, Hayato/0000-0002-1410-1078; Misawa, Masashi/0000-0002-8520-2036;
   Mori, Yuichi/0000-0003-2262-0334; Oda, Masahiro/0000-0001-7714-422X
CR Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Arita K, 2011, ONCOL REP, V26, P43, DOI 10.3892/or.2011.1287
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chinzei K, 2018, ADV BIOMED ENG, V7, P118, DOI 10.14326/abe.7.118
   Committee AT, 2015, GASTROINTEST ENDOSC, V81
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dept of Health and Human Services FDA, 2018, RAD DEV RECL MED IM
   Du N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155371
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hafner M, 2009, LECT NOTES COMPUT SC, V5761, P247, DOI 10.1007/978-3-642-04268-3_31
   Hirakawa T, 2014, IEEE ENG MED BIO, P4739, DOI 10.1109/EMBC.2014.6944683
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Jerebko A, 2006, LECT NOTES COMPUT SC, V4191, P169
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kiesslich R, 2004, GASTROENTEROLOGY, V127, P706, DOI 10.1053/j.gastro.2004.06.050
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2001, ENDOSCOPY, V33, P367
   Kudo S, 2014, J GASTROEN HEPATOL, V29, P83, DOI 10.1111/jgh.12374
   Kudo Shin-ei, 2008, Gastrointest Endosc Clin N Am, V18, P581, DOI 10.1016/j.giec.2008.05.013
   Kuiper T, 2011, ENDOSCOPY, V43, P1076, DOI 10.1055/s-0030-1256767
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2013, ENDOSCOPY, V45, P98, DOI 10.1055/s-0032-1325932
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2018, DIGEST ENDOSC, V30, P52, DOI 10.1111/den.13005
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Okamoto T, 2015, IEEE ENG MED BIO, P2997, DOI 10.1109/EMBC.2015.7319022
   Park SH, 2018, RADIOLOGY, V288, P910, DOI 10.1148/radiol.2018181310
   Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Plagianakos VP, 2006, COMPUT METH PROG BIO, V81, P228, DOI 10.1016/j.cmpb.2005.11.005
   Prieto SP, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.2.024502
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Renkoski TE, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.1.016005
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Tafreshi MK, 2014, LECT NOTES COMPUT SC, V8673, P89, DOI 10.1007/978-3-319-10404-1_12
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang HF, 2015, PHYS MED BIOL, V60, P7207, DOI 10.1088/0031-9155/60/18/7207
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 67
TC 65
Z9 69
U1 2
U2 25
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JUL
PY 2019
VL 31
IS 4
BP 363
EP 371
DI 10.1111/den.13340
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA IH2CK
UT WOS:000474302600006
PM 30624835
DA 2023-04-20
ER

PT J
AU Li, JY
   Zhang, J
   Chang, DD
   Hu, YJ
AF Li Jiangyun
   Zhang Jie
   Chang Dedan
   Hu Yaojun
TI Computer-Assisted Detection of Colonic Polyps Using Improved Faster
   R-CNN
SO CHINESE JOURNAL OF ELECTRONICS
LA English
DT Article
DE Colonic polyps; Deep learning; Improved Faster R-CNN; Object detection
AB The deficiencies of existing polyp detection methods remain: i) They primarily depend on the manually extracted features and require considerable amounts of preprocessing. ii) Most traditional methods cannot specify the location of the polyps in colonoscopy images, especially for the polyps with variable size. In order to derive the improvement and lift the accuracy, we propose a novel and scalable detection algorithm based on deep neural networks-an improved Faster Region-based Convolutional neural networks (Faster R-CNN)-by increasing the fusion of feature maps at different levels. It can be employed to detect and locate polyps, and even achieve a multi-object task for polyps in the future. The experimental consequences demonstrate that the best version among improved algorithms achieves 97.13% accuracy on the CVC-ClinicDB database, overtaking the previous methods.
C1 [Li Jiangyun; Zhang Jie; Chang Dedan] Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing 100083, Peoples R China.
   [Li Jiangyun; Zhang Jie; Chang Dedan] Minist Educ, Key Lab Knowledge Automat Ind Proc, Beijing 100083, Peoples R China.
   [Hu Yaojun] Capital Med Univ, Fu Xing Hosp, Dept Gastroenterol, Beijing 100038, Peoples R China.
C3 University of Science & Technology Beijing; Capital Medical University
RP Li, JY (通讯作者)，Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing 100083, Peoples R China.; Li, JY (通讯作者)，Minist Educ, Key Lab Knowledge Automat Ind Proc, Beijing 100083, Peoples R China.
EM leejy@ustb.edu.cn; m15810821883@163.com; cdedan210@163.com;
   42118878@qq.com
FU Fundamental Research Funds for the China Central Universities of USTB;
   Open Project Program of the National Laboratory of Pattern Recognition
   [201800027]
FX This work is supported by the Fundamental Research Funds for the China
   Central Universities of USTB (No.FRF-BR-17-004A, No.FRF-GF-17-B49),and
   the Open Project Program of the National Laboratory of Pattern
   Recognition (No.201800027).
CR Bale R, 2007, MINIM INVASIV THER, V16, P196, DOI 10.1080/13645700701520578
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   [毕威 Bi Wei], 2017, [电子学报, Acta Electronica Sinica], V45, P1902
   Girshick R., 2013, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hwang S., 2007, P 2007 IEEE INT C IM, DOI [DOI 10.1109/ICIP.2007.4379193, 10.1109/ICIP.2007.4379193]
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Kodogiannis V., 2004, P INT C MED SIGN PRO, P262
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin T.Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   [邱实 Qiu Shi], 2016, [电子学报, Acta Electronica Sinica], V44, P1413
   Qiu S, 2016, CHINESE J ELECTRON, V25, P711, DOI 10.1049/cje.2016.07.009
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Zhang RF, 2001, CHINESE J ORG CHEM, V21, P41
   Zheng MM, 2005, COMPUT BIOL MED, V35, P259, DOI 10.1016/j.compbiomed.2004.01.002
   [郑云飞 Zheng Yunfei], 2017, [电子学报, Acta Electronica Sinica], V45, P2593
NR 27
TC 6
Z9 8
U1 1
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1022-4653
EI 2075-5597
J9 CHINESE J ELECTRON
JI Chin. J. Electron.
PD JUL
PY 2019
VL 28
IS 4
BP 718
EP 724
DI 10.1049/cje.2019.03.005
PG 7
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA IM0OH
UT WOS:000477687600008
DA 2023-04-20
ER

PT J
AU Min, JK
   Kwak, MS
   Cha, JM
AF Min, Jun Ki
   Kwak, Min Seob
   Cha, Jae Myung
TI Overview of Deep Learning in Gastrointestinal Endoscopy
SO GUT AND LIVER
LA English
DT Review
DE Artificial intelligence; Convolutional neural network; Deep learning;
   Diagnosis, computer-assisted; Endoscopy
ID CONVOLUTIONAL NEURAL-NETWORK; HELICOBACTER-PYLORI INFECTION; CAPSULE
   ENDOSCOPY; ARTIFICIAL-INTELLIGENCE; DIABETIC-RETINOPATHY;
   CLASSIFICATION; VALIDATION; DIAGNOSIS; CANCER; IMAGES
AB Artificial intelligence is likely to perform several roles currently performed by humans, and the adoption of artificial intelligence-based medicine in gastroenterology practice is expected in the near future. Medical image-based diagnoses, such as pathology, radiology, and endoscopy, are expected to be the first in the medical field to be affected by artificial intelligence. A convolutional neural network, a kind of deeplearning method with multilayer perceptrons designed to use minimal preprocessing, was recently reported as being highly beneficial in the field of endoscopy, including esophagogastroduodenoscopy, colonoscopy, and capsule endoscopy. A convolutional neural network-based diagnostic program was challenged to recognize anatomical locations in esophago-gastroduodenoscopy images, Helicobacter pylori infection, and gastric cancer for esophagogastroduodenoscopy; to detect and classify colorectal polyps; to recognize celiac disease and hookworm; and to perform small intestine motility characterization of capsule endoscopy images. Artificial intelligence is expected to help endoscopists provide a more accurate diagnosis by automatically detecting and classifying lesions; therefore, it is essential that endoscopists focus on this novel technology. In this review, we describe the effects of artificial intelligence on gastroenterology with a special focus on automatic diagnosis, based on endoscopic findings.
C1 [Min, Jun Ki; Kwak, Min Seob; Cha, Jae Myung] Kyung Hee Univ, Dept Internal Med, Sch Med, Seoul, South Korea.
C3 Kyung Hee University
RP Cha, JM (通讯作者)，Kyung Hee Univ, Sch Med, Kyung Hee Univ Hosp Gangdong, Dept Internal Med, 892 Dongnam Ro, Seoul 05278, South Korea.
EM drcha@khu.ac.kr
OI Min, Jun Ki/0000-0003-0354-855X
FU Kyung Hee University [KHU-20181044]
FX This work was supported by a grant from Kyung Hee University in 2018
   (KHU-20181044).
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Bae J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171472
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cruz-Roa A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46450
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   McCarthy J, 2006, AI MAG, V27, P12
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   NVIDIA, 2016, WHATS DIFF ART INT M
   Russell S., 2009, ARTIF INTELL
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Trebeschi S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05728-9
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Yasaka K, 2018, RADIOLOGY, V287, P146, DOI 10.1148/radiol.2017171928
   Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 29
TC 72
Z9 76
U1 7
U2 63
PU EDITORIAL OFFICE GUT & LIVER
PI SEOUL
PA 305 LOTTE GOLD ROSE II, 890-59, DAECHI 4-DONG, GANGNAM-GU, SEOUL,
   135-839, SOUTH KOREA
SN 1976-2283
EI 2005-1212
J9 GUT LIVER
JI Gut Liver
PD JUL
PY 2019
VL 13
IS 4
BP 388
EP 393
DI 10.5009/gnl18384
PG 6
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA IH6TE
UT WOS:000474632100004
PM 30630221
OA gold, Green Published, Green Submitted
DA 2023-04-20
ER

PT J
AU Mori, Y
   Kudo, SE
   Mohmed, HEN
   Misawa, M
   Ogata, N
   Itoh, H
   Oda, M
   Mori, K
AF Mori, Yuichi
   Kudo, Shin-ei
   Mohmed, Hussein E. N.
   Misawa, Masashi
   Ogata, Noriyuki
   Itoh, Hayato
   Oda, Masahiro
   Mori, Kensaku
TI Artificial intelligence and upper gastrointestinal endoscopy: Current
   status and future perspective
SO DIGESTIVE ENDOSCOPY
LA English
DT Review
DE computer-aided; detection; esophagus; gastroscopy; stomach
ID HELICOBACTER-PYLORI INFECTION; COMPUTER-AIDED DIAGNOSIS; COLORECTAL
   POLYP HISTOLOGY; MAGNIFYING ENDOSCOPY; GASTRIC-CANCER; LESIONS; SYSTEM;
   ESOPHAGUS; IMAGES; ALGORITHM
AB With recent breakthroughs in artificial intelligence, computer-aided diagnosis (CAD) for upper gastrointestinal endoscopy is gaining increasing attention. Main research focuses in this field include automated identification of dysplasia in Barrett's esophagus and detection of early gastric cancers. By helping endoscopists avoid missing and mischaracterizing neoplastic change in both the esophagus and the stomach, these technologies potentially contribute to solving current limitations of gastroscopy. Currently, optical diagnosis of early-stage dysplasia related to Barrett's esophagus can be precisely achieved only by endoscopists proficient in advanced endoscopic imaging, and the false-negative rate for detecting gastric cancer is approximately 10%. Ideally, these novel technologies should work during real-time gastroscopy to provide on-site decision support for endoscopists regardless of their skill; however, previous studies of these topics remain ex vivo and experimental in design. Therefore, the feasibility, effectiveness, and safety of CAD for upper gastrointestinal endoscopy in clinical practice remain unknown, although a considerable number of pilot studies have been conducted by both engineers and medical doctors with excellent results. This review summarizes current publications relating to CAD for upper gastrointestinal endoscopy from the perspective of endoscopists and aims to indicate what is required for future research and implementation in clinical practice.
C1 [Mori, Yuichi; Kudo, Shin-ei; Misawa, Masashi; Ogata, Noriyuki] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Yokohama, Kanagawa, Japan.
   [Mohmed, Hussein E. N.] Showa Univ, Northern Yokohama Hosp, Int Ctr Endoscopy, Yokohama, Kanagawa, Japan.
   [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
   [Mohmed, Hussein E. N.] Ain Shams Univ, Dept Gastroenterol Trop Med, Cairo, Egypt.
C3 Showa University; Showa University; Nagoya University; Egyptian
   Knowledge Bank (EKB); Ain Shams University
RP Mori, Y (通讯作者)，Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Tsuzuki Ku, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
EM ibusiginjp@gmail.com
RI Mori, Yuichi/AAU-5406-2020; Misawa, Masashi/H-9004-2019; Itoh,
   Hayato/AAM-4022-2021
OI Misawa, Masashi/0000-0002-8520-2036; Itoh, Hayato/0000-0002-1410-1078;
   Mori, Yuichi/0000-0003-2262-0334; Oda, Masahiro/0000-0001-7714-422X
FU Japan Society for the Promotion of Science [17H05305]; Grants-in-Aid for
   Scientific Research [17H05305] Funding Source: KAKEN
FX THIS WORK WAS supported by Grants-in-Aid for Scientific Research (Number
   17H05305) from the Japan Society for the Promotion of Science. We
   express our deepest appreciation to Drs Toshiaki Hirasawa, Tomohiro
   Tada, Hirotaka Nakashima, Hiroshi Kawahira, Shigeto Yoshida, Noriya
   Uedo, Takashi Kanesaka, John Tsung-Chun Lee, Maarten Struyvenberg, and
   Jacques Bergman for providing the video and figures used in this
   article. We also thank Jane Charbonneau, DVM, from Edanz Group
   (www.edanzediting.com/ac) for editing a draft of this manuscript.
CR Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bretthauer M, 2016, JAMA INTERN MED, V176, P894, DOI 10.1001/jamainternmed.2016.0960
   Curvers WL, 2011, GASTROINTEST ENDOSC, V73, P195, DOI 10.1016/j.gie.2010.10.014
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hamashima C, 2015, WORLD J GASTROENTERO, V21, P2460, DOI 10.3748/wjg.v21.i8.2460
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kara MA, 2005, GASTROINTEST ENDOSC, V61, P671, DOI 10.1016/S0016-5107(04)02777-4
   Kato T, 2013, DIGEST ENDOSC, V25, P508, DOI 10.1111/den.12031
   Khan S, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS), P633, DOI 10.1109/ICCOINS.2016.7783289
   Kikuchi D, 2014, DIGEST ENDOSC, V26, P16, DOI 10.1111/den.12282
   Kimura-Tsuchiya R, 2017, GASTROENT RES PRACT, V2017, P1
   Kodashima S, 2007, DIGEST LIVER DIS, V39, P762, DOI 10.1016/j.dld.2007.03.004
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Kumagai Y, 2015, DIS ESOPHAGUS, V28, P269, DOI 10.1111/dote.12183
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Miyaki R, 2013, J GASTROEN HEPATOL, V28, P841, DOI 10.1111/jgh.12149
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mouri R, 2009, GASTROINTEST ENDOSC, V69, P1052, DOI 10.1016/j.gie.2008.08.032
   Muto M, 2010, J CLIN ONCOL, V28, P1566, DOI 10.1200/JCO.2009.25.4680
   Nakanishi H, 2017, ENDOSCOPY, V49, P957, DOI 10.1055/s-0043-111888
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Ockwell D, 2017, PATHWAYS SUSTAIN, P24
   Osawa H, 2014, DIGEST ENDOSC, V26, P105, DOI 10.1111/den.12205
   Osawa H, 2012, WORLD J GASTRO ENDOS, V4, P356, DOI 10.4253/wjge.v4.i8.356
   Philbrick KA, 2018, AM J ROENTGENOL, V211, P1184, DOI 10.2214/AJR.18.20331
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Safatle-Ribeiro AV, 2017, GASTROINTEST ENDOSC, V85, P1195, DOI 10.1016/j.gie.2016.09.031
   Sharma P, 2013, GUT, V62, P15, DOI 10.1136/gutjnl-2011-300962
   Sharma P, 2012, GASTROINTEST ENDOSC, V76, P252, DOI 10.1016/j.gie.2012.05.007
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shimizu Y, 2008, J GASTROEN HEPATOL, V23, P546, DOI 10.1111/j.1440-1746.2007.04990.x
   Shin D, 2015, CLIN GASTROENTEROL H, V13, P272, DOI 10.1016/j.cgh.2014.07.030
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
   Yao K, 2009, ENDOSCOPY, V41, P462, DOI 10.1055/s-0029-1214594
   Yeung S, 2018, NEW ENGL J MED, V378, P1271, DOI 10.1056/NEJMp1716891
   Yoshifuku Y, 2017, GASTROENT RES PRACT, V2017, P1
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 54
TC 69
Z9 73
U1 2
U2 22
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JUL
PY 2019
VL 31
IS 4
BP 378
EP 388
DI 10.1111/den.13317
PG 11
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA IH2CK
UT WOS:000474302600008
PM 30549317
DA 2023-04-20
ER

PT J
AU Owais, M
   Arsalan, M
   Choi, J
   Mahmood, T
   Park, KR
AF Owais, Muhammad
   Arsalan, Muhammad
   Choi, Jiho
   Mahmood, Tahir
   Park, Kang Ryoung
TI Artificial Intelligence-Based Classification of Multiple
   Gastrointestinal Diseases Using Endoscopy Videos for Clinical Diagnosis
SO JOURNAL OF CLINICAL MEDICINE
LA English
DT Article
DE Artificial intelligence (AI); deep learning; endoscopic video analysis;
   residual network (ResNet) and long short-term memory (LSTM) model;
   classification of multiple gastrointestinal (GI) diseases
ID CAPSULE ENDOSCOPY; FEATURES; IMAGES
AB Various techniques using artificial intelligence (AI) have resulted in a significant contribution to field of medical image and video-based diagnoses, such as radiology, pathology, and endoscopy, including the classification of gastrointestinal (GI) diseases. Most previous studies on the classification of GI diseases use only spatial features, which demonstrate low performance in the classification of multiple GI diseases. Although there are a few previous studies using temporal features based on a three-dimensional convolutional neural network, only a specific part of the GI tract was involved with the limited number of classes. To overcome these problems, we propose a comprehensive AI-based framework for the classification of multiple GI diseases by using endoscopic videos, which can simultaneously extract both spatial and temporal features to achieve better classification performance. Two different residual networks and a long short-term memory model are integrated in a cascaded mode to extract spatial and temporal features, respectively. Experiments were conducted on a combined dataset consisting of one of the largest endoscopic videos with 52,471 frames. The results demonstrate the effectiveness of the proposed classification framework for multi-GI diseases. The experimental results of the proposed model (97.057% area under the curve) demonstrate superior performance over the state-of-the-art methods and indicate its potential for clinical applications.
C1 [Owais, Muhammad; Arsalan, Muhammad; Choi, Jiho; Mahmood, Tahir; Park, Kang Ryoung] Dongguk Univ, Div Elect & Elect Engn, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.
C3 Dongguk University
RP Park, KR (通讯作者)，Dongguk Univ, Div Elect & Elect Engn, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.
EM parkgr@dongguk.edu
RI Owais, Muhammad/AAT-1573-2021; Arsalan, Muhammad/AAD-7655-2020; Owais,
   Muhammad/AFC-7124-2022
OI Owais, Muhammad/0000-0001-7679-081X; Owais,
   Muhammad/0000-0001-7679-081X; Arsalan, Muhammad/0000-0003-1868-5207;
   Mahmood, Tahir/0000-0003-1691-9532
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2018R1D1A1B07041921]; National Research Foundation of Korea (NRF) -
   Ministry of Science and ICT [NRF-2019R1F1A1041123]; Bio & Medical
   Technology Development Program of the NRF - Korean government, MSIT
   [NRF-2016M3A9E1915855]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2018R1D1A1B07041921), by the Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Science and ICT (NRF-2019R1F1A1041123), and by
   the Bio & Medical Technology Development Program of the NRF funded by
   the Korean government, MSIT (NRF-2016M3A9E1915855).
CR [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2015, ARTIF INTELL
   [Anonymous], NEURAL COMPUT
   [Anonymous], 2011, INT J COMPUT APPL
   Tran BX, 2019, J CLIN MED, V8, DOI 10.3390/jcm8030360
   Bottou Leon, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P421, DOI 10.1007/978-3-642-35289-8_25
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cheng CH, 2018, J CLIN MED, V7, DOI 10.3390/jcm7060124
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Nguyen DT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030699
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI 10.5121/ijdkp.2015.5201
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Iandola FN, 2016, SQUEEZENET ALEXNET L
   Ilin A, 2010, J MACH LEARN RES, V11, P1957
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Nakagawa S, 2007, BIOL REV, V82, P591, DOI 10.1111/j.1469-185X.2007.00027.x
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8040462
   Peng X, 2018, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2018.00237
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Vuong QH, 2019, J CLIN MED, V8, DOI 10.3390/jcm8020168
   Raychaudhuri S, 2008, 2008 WINTER SIMULATION CONFERENCE, VOLS 1-5, P91, DOI 10.1109/WSC.2008.4736059
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Wongcharoen S, 2016, INT JOINT CONF COMP, P76
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 46
TC 32
Z9 32
U1 2
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0383
J9 J CLIN MED
JI J. Clin. Med.
PD JUL
PY 2019
VL 8
IS 7
AR 986
DI 10.3390/jcm8070986
PG 33
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA IN9MO
UT WOS:000479003300071
PM 31284687
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Park, J
   Hwang, Y
   Yoon, JH
   Park, MG
   Kim, J
   Lim, YJ
   Chun, HJ
AF Park, Junseok
   Hwang, Youngbae
   Yoon, Ju-Hong
   Park, Min-Gyu
   Kim, Jungho
   Lim, Yun Jeong
   Chun, Hoon Jai
TI Recent Development of Computer Vision Technology to Improve Capsule
   Endoscopy
SO CLINICAL ENDOSCOPY
LA English
DT Review
DE Capsule endoscopy; Computer vision technology; Deep learning
AB Capsule endoscopy (CE) is a preferred diagnostic method for analyzing small bowel diseases. However, capsule endoscopes capture a sparse number of images because of their mechanical limitations. Post-procedural management using computational methods can enhance image quality. Additional information, including depth, can be obtained by using recently developed computer vision techniques. It is possible to measure the size of lesions and track the trajectory of capsule endoscopes using the computer vision technology, without requiring additional equipment. Moreover, the computational analysis of CE images can help detect lesions more accurately within a shorter time. Newly introduced deep leaning-based methods have shown more remarkable results over traditional computerized approaches. A large-scale standard dataset should be prepared to develop an optimal algorithms for improving the diagnostic yield of CE. The close collaboration between information technology and medical professionals is needed.
C1 [Park, Junseok] Soonchunhyang Univ, Coll Med, Digest Dis Ctr, Inst Digest Res,Dept Internal Med, Seoul, South Korea.
   [Hwang, Youngbae; Yoon, Ju-Hong; Park, Min-Gyu; Kim, Jungho] KETI, Intelligent Image Proc Res Ctr, Seongnam, South Korea.
   [Lim, Yun Jeong] Dongguk Univ, Ilsan Hosp, Coll Med, Dept Internal Med, 27 Dongguk Ro, Goyang 10326, South Korea.
   [Chun, Hoon Jai] Korea Univ, Coll Med, Inst Gastrointestinal Med Instrument Res, Dept Internal Med,Div Gastroenterol & Hepatol, Seoul, South Korea.
C3 Soonchunhyang University; Korea Electronics Technology Institute (KETI);
   Dongguk University; NHIS Ilsan Hospital; Korea University; Korea
   University Medicine (KU Medicine)
RP Lim, YJ (通讯作者)，Dongguk Univ, Ilsan Hosp, Coll Med, Dept Internal Med, 27 Dongguk Ro, Goyang 10326, South Korea.
EM limyj@dumc.or.kr
RI Park, Junseok/ABS-0095-2022
OI Park, Junseok/0000-0001-5607-1041
CR Bao G, 2013, 14 INT C BIOINF COMP
   Duda K, 2008, ICSES 2008 INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS, CONFERENCE PROCEEDINGS, P197, DOI 10.1109/ICSES.2008.4673391
   Faigel DO, 2005, GASTROINTEST ENDOSC, V61, P503, DOI 10.1016/S0016-5107(04)02781-6
   Fan YC, 2010, IEEE ENG MED BIO, P5149, DOI 10.1109/IEMBS.2010.5626182
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Gopi VP, 2012, COMM COM INF SC, V292, P220
   Guangyi Chen, 2013, Pattern Recognition and Image Analysis, V23, P211, DOI 10.1134/S1054661813020089
   Hafner M, 2014, INT WORK CONTENT MUL
   Hafner M, 2013, COMP MED SY, P185, DOI 10.1109/CBMS.2013.6627786
   He K., 2016, P IEEE C COMP VIS PA
   Hwang Y, 2018, CLIN ENDOSC, V51, P547, DOI 10.5946/ce.2018.173
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karargyris A, 2011, IEEE T MED IMAGING, V30, P957, DOI 10.1109/TMI.2010.2098882
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Liu HY, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P102, DOI 10.1109/PACRIM.2011.6032875
   Mahmoud N, ARXIV170509107
   Mahmoud N, 2017, LECT NOTES COMPUT SC, V10170, P72, DOI 10.1007/978-3-319-54057-3_7
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Marya N, 2014, GASTROINTEST ENDOSC, V79, P669, DOI 10.1016/j.gie.2013.11.022
   Obukhova N, 2018, 2018 22 C OP INN ASS, P204
   Park MG, 2018, LECT NOTES COMPUT SC, V11075, P48, DOI 10.1007/978-3-030-00500-9_6
   Peng L, 2017, 2017 IEEE VISUAL COM, P1
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Shim KN, 2017, CLIN ENDOSC, V50, P148, DOI 10.5946/ce.2017.030
   Simonyan K, 2015, Arxiv
   Singh S, 2014, INT J LIFE SCI PHARM, V4, P42
   Spyrou E, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/1/015002
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Turan M, 2017, INT J INTELL ROBOT, V1, P399, DOI 10.1007/s41315-017-0036-4
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P595, DOI 10.1109/ICDSP.2015.7251943
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zheng YP, 2012, AM J GASTROENTEROL, V107, P554, DOI 10.1038/ajg.2011.461
   Zhou R, 2013, IEEE INT C INT ROBOT, P3096, DOI 10.1109/IROS.2013.6696795
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 39
TC 17
Z9 18
U1 0
U2 6
PU KOREAN SOC GASTROINTESTINAL ENDOSCOPY
PI SEOUL
PA 2003 LG PALACE, 165-8 DONGGYO-DONG, MAPO-GU, SEOUL, 121-754, SOUTH KOREA
SN 2234-2400
EI 2234-2443
J9 CLIN ENDOSC
JI Clin. Endosc.
PD JUL
PY 2019
VL 52
IS 4
BP 328
EP 333
DI 10.5946/ce.2018.172
PG 6
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA IM3NR
UT WOS:000477901300008
PM 30786704
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Rau, A
   Edwards, PJE
   Ahmad, OF
   Riordan, P
   Janatka, M
   Lovat, LB
   Stoyanov, D
AF Rau, Anita
   Edwards, P. J. Eddie
   Ahmad, Omer F.
   Riordan, Paul
   Janatka, Mirek
   Lovat, Laurence B.
   Stoyanov, Danail
TI Implicit domain adaptation with conditional generative adversarial
   networks for depth prediction in endoscopy
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article; Proceedings Paper
CT 10th International Conference on Information Processing for
   Computer-Assisted Interventions (IPCAI)
CY JUN 18-19, 2019
CL FRANCE
DE Depth estimation; 3D reconstruction; Conditional GANs; Colonoscopy
ID 3D RECONSTRUCTION; POLYP DETECTION; COLONOSCOPY
AB PurposeColorectal cancer is the third most common cancer worldwide, and early therapeutic treatment of precancerous tissue during colonoscopy is crucial for better prognosis and can be curative. Navigation within the colon and comprehensive inspection of the endoluminal tissue are key to successful colonoscopy but can vary with the skill and experience of the endoscopist. Computer-assisted interventions in colonoscopy can provide better support tools for mapping the colon to ensure complete examination and for automatically detecting abnormal tissue regions.MethodsWe train the conditional generative adversarial network pix2pix, to transform monocular endoscopic images to depth, which can be a building block in a navigational pipeline or be used to measure the size of polyps during colonoscopy. To overcome the lack of labelled training data in endoscopy, we propose to use simulation environments and to additionally train the generator and discriminator of the model on unlabelled real video frames in order to adapt to real colonoscopy environments.ResultsWe report promising results on synthetic, phantom and real datasets and show that generative models outperform discriminative models when predicting depth from colonoscopy images, in terms of both accuracy and robustness towards changes in domains.ConclusionsTraining the discriminator and generator of the model on real images, we show that our model performs implicit domain adaptation, which is a key step towards bridging the gap between synthetic and real data. Importantly, we demonstrate the feasibility of training a single model to predict depth from both synthetic and real images without the need for explicit, unsupervised transformer networks mapping between the domains of synthetic and real data.
C1 [Rau, Anita; Edwards, P. J. Eddie; Ahmad, Omer F.; Janatka, Mirek; Lovat, Laurence B.; Stoyanov, Danail] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London, England.
   [Riordan, Paul] Digital Surg Ltd, London, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London
RP Rau, A (通讯作者)，UCL, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London, England.
EM a.rau.16@ucl.ac.uk; eddie.edwards@ucl.ac.uk; o.ahmad@ucl.ac.uk;
   paul.riordan@touchsurgery.com; mirek.janatka@ucl.ac.uk;
   l.lovat@ucl.ac.uk; danail.stoyanov@ucl.ac.uk
RI Lovat, Laurence/C-1986-2009
OI Lovat, Laurence/0000-0003-4542-3915; Rau, Anita/0000-0002-4759-2846
FU Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS)
   at UCL [203145Z/16/Z]; EPSRC [EP/N027078/1, EP/P012841/1, EP/P027938/1,
   EP/R004080/1]; European Commission Project-H2020-ICT-24-2015 (Endoo EU
   Project-G.A.) [688592]; National Institute for Health Research
   University College London Hospitals Biomedical Research Centre; CRUK
   Experimental Cancer Medicine Centre at UCL; Engineering and Physical
   Sciences Research Council [EP/R004080/1, EP/P012841/1, EP/P030084/1]
   Funding Source: researchfish; EPSRC [EP/N027078/1, EP/P030084/1,
   EP/P027938/1, EP/R004080/1, EP/P012841/1] Funding Source: UKRI
FX This work was supported by the Wellcome/EPSRC Centre for Interventional
   and Surgical Sciences (WEISS) at UCL (203145Z/16/Z), EPSRC
   (EP/N027078/1, EP/P012841/1, EP/P027938/1, EP/R004080/1) and the
   European Commission Project-H2020-ICT-24-2015 (Endoo EU Project-G.A.
   No.: 688592). LBL is supported by the National Institute for Health
   Research University College London Hospitals Biomedical Research Centre
   and the CRUK Experimental Cancer Medicine Centre at UCL.
CR Armin MA, 2017, LECT NOTES COMPUT SC, V10550, P50, DOI 10.1007/978-3-319-67543-5_5
   Armin MA, 2018, LECT NOTES COMPUT SC, V11041, P108, DOI 10.1007/978-3-030-01201-4_13
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brandao P., 2018, J MED ROBOT RES, V3, P1840002, DOI DOI 10.1142/S2424905X18400020
   Chen R. T. Q., 2018, ARXIV
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   Hong DH, 2014, COMPUT MED IMAG GRAP, V38, P22, DOI 10.1016/j.compmedimag.2013.10.005
   Isola P., 2017, PROC 30 IEEE C COMPU, P1125, DOI DOI 10.1109/CVPR.2017.632
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Liu XT, 2018, LECT NOTES COMPUT SC, V11041, P128, DOI 10.1007/978-3-030-01201-4_15
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Mirza M., 2014, CONDITIONAL GENERATI, DOI 10.48550/arXiv.1411.1784
   Odena A, 2017, PR MACH LEARN RES, V70
   Park T., 2017, ICCV, DOI DOI 10.1109/ICCV.2017.244
   Qingyu Zhao, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P439, DOI 10.1007/978-3-319-46720-7_51
   Radford A., 2015, COMPUTER SCI
   Rex DK, 2017, BEST PRACT RES CL GA, V31, P425, DOI 10.1016/j.bpg.2017.05.010
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Visentini-Scarzanella M, 2017, INT J COMPUT ASS RAD, V12, P1089, DOI 10.1007/s11548-017-1609-2
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 23
TC 53
Z9 53
U1 1
U2 14
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD JUL
PY 2019
VL 14
IS 7
SI SI
BP 1167
EP 1176
DI 10.1007/s11548-019-01962-w
PN 2
PG 10
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA ID4GM
UT WOS:000471635000007
PM 30989505
OA hybrid, Green Published
DA 2023-04-20
ER

PT J
AU Turan, M
   Almalioglu, Y
   Gilbert, HB
   Mahmood, F
   Durr, NJ
   Araujo, H
   Sari, AE
   Ajay, A
   Sitti, M
AF Turan, Mehmet
   Almalioglu, Yasin
   Gilbert, Hunter B.
   Mahmood, Faisal
   Durr, Nicholas J.
   Araujo, Helder
   Sari, Alp Eren
   Ajay, Anurag
   Sitti, Metin
TI Learning to Navigate Endoscopic Capsule Robots
SO IEEE ROBOTICS AND AUTOMATION LETTERS
LA English
DT Article
DE Deep reinforcement learning; model-free control learning; endoscopic
   capsule robot; actor-critic
ID LOCALIZATION
AB Deep reinforcement learning (DRL) techniques have been successful in several domains, such as physical simulations, computer games, and simulated robotic tasks, yet the transfer of these successful learning concepts from simulations into the real world scenarios remains still a challenge. In this letter, a DRL approach is proposed to learn the continuous control of a magnetically actuated soft capsule endoscope (MASCE). Proposed controller approach can alleviate the need for tedious modeling of complex and highly nonlinear physical phenomena, such as magnetic interactions, robot body dynamics and tissue-robot interactions. Experiments performed in real ex-vivo porcine stomachs prove the successful control of the MASCE with trajectory tracking errors on the order of millimeter.
C1 [Turan, Mehmet; Sitti, Metin] Max Planck Inst Intelligent Syst, Phys Intelligence Dept, D-70569 Stuttgart, Germany.
   [Almalioglu, Yasin] Univ Oxford, Comp Sci Dept, Oxford OX1 2JD, England.
   [Gilbert, Hunter B.] Louisiana State Univ, Dept Mech & Ind Engn, Baton Rouge, LA 70803 USA.
   [Mahmood, Faisal; Durr, Nicholas J.] Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA.
   [Araujo, Helder] Univ Coimbra, Inst Syst & Robot, P-3004531 Coimbra, Portugal.
   [Sari, Alp Eren] Middle East Tech Univ, Dept Elect & Elect Engn, TR-06800 Ankara, Turkey.
   [Ajay, Anurag] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
C3 Max Planck Society; University of Oxford; Louisiana State University
   System; Louisiana State University; Johns Hopkins University;
   Universidade de Coimbra; Middle East Technical University; Massachusetts
   Institute of Technology (MIT)
RP Turan, M (通讯作者)，Max Planck Inst Intelligent Syst, Phys Intelligence Dept, D-70569 Stuttgart, Germany.
EM turan@is.mpg.de; yasin.almalioglu@cs.ox.ac.uk; hbgilbert@lsu.edu;
   faisalm@jhu.edu; ndurr@jhu.edu; helder@isr.uc.pt; asari@metu.edu.tr;
   aajay@mit.edu; sitti@is.mpg.de
RI Turan, Mehmet/AGZ-7356-2022; Araujo, Helder/B-3554-2008; Sitti,
   Metin/AGP-6288-2022; Mahmood, Faisal/C-1021-2015; Durr,
   Nicholas/W-5517-2018
OI Araujo, Helder/0000-0002-9544-424X; Sitti, Metin/0000-0001-8249-3854;
   Gilbert, Hunter/0000-0001-8590-2596; Almalioglu,
   Yasin/0000-0002-9251-7853; Mahmood, Faisal/0000-0001-7587-1562; Durr,
   Nicholas/0000-0001-9808-7383
FU Alexander von Humboldt foundation
FX H. B. Gilbert would like to thank the Alexander von Humboldt foundation
   for support.
CR Albert JG, 2005, GUT, V54, P1721, DOI 10.1136/gut.2005.069427
   Ciuti G, 2010, ENDOSCOPY, V42, P148, DOI 10.1055/s-0029-1243808
   Ciuti G, 2016, J MICRO-BIO ROBOT, V11, P1, DOI 10.1007/s12213-016-0087-x
   Deisenroth MP, 2013, FOUND TRENDS ROBOT, V2, P1, DOI DOI 10.1561/2300000021
   Dhariwal Prafulla, 2017, OPENAI BASELINES
   Di Natali C, 2016, IEEE T ROBOT, V32, P327, DOI 10.1109/TRO.2016.2522433
   Hu C, 2008, IEEE ENG MED BIO, P2055, DOI 10.1109/IEMBS.2008.4649596
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Keller H, 2012, P IEEE RAS-EMBS INT, P859, DOI 10.1109/BioRob.2012.6290795
   Lillicrap T. P., 2015, ARXIV
   Mahoney AW, 2016, INT J ROBOT RES, V35, P129, DOI 10.1177/0278364914558006
   Mahoney AW, 2014, IEEE T ROBOT, V30, P411, DOI 10.1109/TRO.2013.2289019
   Miller KM, 2012, IEEE INT C INT ROBOT, P1994, DOI 10.1109/IROS.2012.6385708
   Mnih V, 2016, PR MACH LEARN RES, V48
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Petruska AJ, 2017, IEEE T MAGN, V53, DOI 10.1109/TMAG.2017.2653080
   Petruska AJ, 2013, IEEE INT CONF ROBOT, P822, DOI 10.1109/ICRA.2013.6630668
   Popek Katie M., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1154, DOI 10.1109/ICRA.2017.7989138
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Sitti M, 2015, P IEEE, V103, P205, DOI 10.1109/JPROC.2014.2385105
   Spada C, 2016, CLIN GASTROENTEROL H, V14, P1533, DOI 10.1016/j.cgh.2016.04.038
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tobin J, 2017, IEEE INT C INT ROBOT, P23
   Than TD, 2012, IEEE T BIO-MED ENG, V59, P2387, DOI 10.1109/TBME.2012.2201715
   Wu YH, 2017, ADV NEUR IN, V30
NR 25
TC 12
Z9 13
U1 6
U2 51
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2377-3766
J9 IEEE ROBOT AUTOM LET
JI IEEE Robot. Autom. Lett.
PD JUL
PY 2019
VL 4
IS 3
BP 3075
EP 3082
DI 10.1109/LRA.2019.2924846
PG 8
WC Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Robotics
GA IH6EV
UT WOS:000474587400012
DA 2023-04-20
ER

PT J
AU Vinsard, DG
   Mori, Y
   Misawa, M
   Kudo, S
   Rastogi, A
   Bagci, U
   Rex, DK
   Wallace, MB
AF Vinsard, Daniela Guerrero
   Mori, Yuichi
   Misawa, Masashi
   Kudo, Shin-ei
   Rastogi, Amit
   Bagci, Ulas
   Rex, Douglas K.
   Wallace, Michael B.
TI Quality assurance of computer-aided detection and diagnosis in
   colonoscopy
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
ID ADENOMA DETECTION RATE; COLORECTAL POLYP HISTOLOGY; DEEP-LEARNING
   ALGORITHM; ARTIFICIAL-INTELLIGENCE; GASTROINTESTINAL ENDOSCOPY; OPTICAL
   BIOPSY; SYSTEM; LESIONS; CLASSIFICATION; ENDOCYTOSCOPY
AB Recent breakthroughs in artificial intelligence (AI), specifically via its emerging sub-field "deep learning," have direct implications for computer-aided detection and diagnosis (CADe and/or CADx) for colonoscopy. AI is expected to have at least 2 major roles in colonoscopy practicedpolyp detection (CADe) and polyp characterization (CADx). CADe has the potential to decrease the polyp miss rate, contributing to improving adenoma detection, whereas CADx can improve the accuracy of colorectal polyp optical diagnosis, leading to reduction of unnecessary polypectomy of non-neoplastic lesions, potential implementation of a resect-and-discard paradigm, and proper application of advanced resection techniques. A growing number of medical-engineering researchers are developing both CADe and CADx systems, some of which allow real-time recognition of polyps or in vivo identification of adenomas, with over 90% accuracy. However, the quality of the developed AI systems as well as that of the study designs vary significantly, hence raising some concerns regarding the generalization of the proposed AI systems. Initial studies were conducted in an exploratory or retrospective fashion by using stored images and likely overestimating the results. These drawbacks potentially hinder smooth implementation of this novel technology into colonoscopy practice. The aim of this article is to review both contributions and limitations in recent machine-learning-based CADe and/or CADx colonoscopy studies and propose some principles that should underlie system development and clinical testing.
C1 [Vinsard, Daniela Guerrero] Showa Univ, Northern Yokohama Hosp, Int Ctr Endoscopy, Yokohama, Kanagawa, Japan.
   [Vinsard, Daniela Guerrero] Univ Connecticut, Div Internal Med, Hlth Ctr, Farmington, CT USA.
   [Mori, Yuichi; Misawa, Masashi; Kudo, Shin-ei] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Yokohama, Kanagawa, Japan.
   [Rastogi, Amit] Univ Kansas, Med Ctr, Div Gastroenterol, Kansas City, KS 66103 USA.
   [Bagci, Ulas] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA.
   [Rex, Douglas K.] Indiana Univ Sch Med, Div Gastroenterol & Hepatol, Indianapolis, IN 46202 USA.
   [Wallace, Michael B.] Mayo Clin, Div Gastroenterol & Hepatol, Jacksonville, FL 32224 USA.
C3 Showa University; University of Connecticut; Showa University;
   University of Kansas; University of Kansas Medical Center; State
   University System of Florida; University of Central Florida; Indiana
   University System; Indiana University Bloomington; Mayo Clinic
RP Mori, Y (通讯作者)，Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Tsuzuki Ku, 35-1 Chigasakichuo, Yokohama, Kanagawa 2248503, Japan.
RI Wallace, Michael/GZL-9731-2022; Misawa, Masashi/H-9004-2019; Mori,
   Yuichi/AAU-5406-2020; Bagci, Ulas/A-4225-2012
OI Wallace, Michael/0000-0002-6446-5785; Misawa,
   Masashi/0000-0002-8520-2036; Bagci, Ulas/0000-0001-7379-6829; Mori,
   Yuichi/0000-0003-2262-0334
FU NCI NIH HHS [R01 CA246704] Funding Source: Medline
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Aihara H, 2009, GASTROINTEST ENDOSC, V69, P726, DOI 10.1016/j.gie.2008.10.044
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   [Anonymous], 2016, DEEP LEARNING
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Brocklehurst P, 2017, LANCET, V389, P1719, DOI 10.1016/S0140-6736(17)30568-8
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cabitza F, 2017, JAMA-J AM MED ASSOC, V318, P517, DOI 10.1001/jama.2017.7797
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chinzei K, 2018, ADV BIOMED ENG, V7, P118, DOI 10.14326/abe.7.118
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   East JE, 2018, LANCET GASTROENTEROL, V3, P10, DOI 10.1016/S2468-1253(17)30366-7
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Food and Drug Administration, 2018, RAD DEV RECL MED IM, P25598
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hilsden RJ, 2016, AM J GASTROENTEROL, V111, P1743, DOI 10.1038/ajg.2016.449
   Hirata M, 2007, GASTROINTEST ENDOSC, V66, P945, DOI 10.1016/j.gie.2007.05.053
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Hussein S, IEEE T MED IMAGING
   Ichimasa K, 2014, DIGEST ENDOSC, V26, P403, DOI 10.1111/den.12164
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Justice AC, 1999, ANN INTERN MED, V130, P515, DOI 10.7326/0003-4819-130-6-199903160-00016
   Kahi CJ, 2014, GASTROINTEST ENDOSC, V79, P448, DOI 10.1016/j.gie.2013.10.013
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   KEITH RDF, 1995, BRIT J OBSTET GYNAEC, V102, P688, DOI 10.1111/j.1471-0528.1995.tb11425.x
   Khan S, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS), P633, DOI 10.1109/ICCOINS.2016.7783289
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   LaLonde R., 2018, 1 C MED IM DEEP LEAR
   Lami M, 2018, ENDOSCOPY, V50, P701, DOI 10.1055/s-0044-101026
   Leggett CL, 2016, GASTROINTEST ENDOSC, V84, P842, DOI 10.1016/j.gie.2016.07.045
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2018, DIGEST ENDOSC, V30, P52, DOI 10.1111/den.13005
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Mortazi Aliasghar, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P377, DOI 10.1007/978-3-319-66185-8_43
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Park SH, 2018, RADIOLOGY, V288, P910, DOI 10.1148/radiol.2018181310
   Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Rex DK, 2002, AM J GASTROENTEROL, V97, P1296, DOI 10.1016/S0002-9270(02)04168-0
   Rex DK, 2015, AM J GASTROENTEROL, V110, P72, DOI 10.1038/ajg.2014.385
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Torosdagli N, 2019, IEEE T MED IMAGING, V38, P919, DOI 10.1109/TMI.2018.2875814
   Tsai TL, 2003, J AM MED INFORM ASSN, V10, P478, DOI 10.1197/jamia.M1279
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang P, 2018, GASTROINTEST ENDOSC, V87, pAB490
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z
NR 83
TC 68
Z9 75
U1 0
U2 23
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JUL
PY 2019
VL 90
IS 1
BP 55
EP 63
DI 10.1016/j.gie.2019.03.019
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA ID9QI
UT WOS:000472021800006
PM 30926431
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Pogorelov, K
   Suman, S
   Hussin, FA
   Malik, AS
   Ostroukhova, O
   Riegler, M
   Halvorsen, P
   Ho, SH
   Goh, KL
AF Pogorelov, Konstantin
   Suman, Shipra
   Hussin, Fawnizu Azmadi
   Malik, Aamir Saeed
   Ostroukhova, Olga
   Riegler, Michael
   Halvorsen, Pal
   Ho, Shiaw Hooi
   Goh, Khean-Lee
TI Bleeding detection in wireless capsule endoscopy videos - Color versus
   texture features
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
LA English
DT Article
DE bleeding detection; color feature; machine learning; texture feature;
   wireless capsule endoscopy
AB Wireless capsule endoscopy (WCE) is an effective technology that can be used to make a gastrointestinal (GI) tract diagnosis of various lesions and abnormalities. Due to a long time required to pass through the GI tract, the resulting WCE data stream contains a large number of frames which leads to a tedious job for clinical experts to perform a visual check of each and every frame of a complete patient's video footage. In this paper, an automated technique for bleeding detection based on color and texture features is proposed. The approach combines the color information which is an essential feature for initial detection of frame with bleeding. Additionally, it uses the texture which plays an important role to extract more information from the lesion captured in the frames and allows the system to distinguish finely between borderline cases. The detection algorithm utilizes machine-learning-based classification methods, and it can efficiently distinguish between bleeding and nonbleeding frames and perform pixel-level segmentation of bleeding areas in WCE frames. The performed experimental studies demonstrate the performance of the proposed bleeding detection method in terms of detection accuracy, where we are at least as good as the state-of-the-art approaches. In this research, we have conducted a broad comparison of a number of different state-of-the-art features and classification methods that allows building an efficient and flexible WCE video processing system.
C1 [Pogorelov, Konstantin; Riegler, Michael; Halvorsen, Pal] Simula Res Lab, Dept Commun Syst, Fornebu, Norway.
   [Suman, Shipra; Hussin, Fawnizu Azmadi; Malik, Aamir Saeed] Univ Teknol PETRONAS, Ctr Intelligent Signal & Imaging, Res Grp, Tronoh, Perak, Malaysia.
   [Ostroukhova, Olga] NaAV Kalyaev, Res Inst Multiprocessor Computat Syst, Rostov Na Donu, Russia.
   [Ho, Shiaw Hooi; Goh, Khean-Lee] Univ Malaya, Dept Med, Med Ctr, Kuala Lumpur, Malaysia.
C3 Universiti Teknologi Petronas; Universiti Malaya
RP Suman, S (通讯作者)，Univ Teknol PETRONAS, Ctr Intelligent Signal & Imaging, Res Grp, Tronoh, Perak, Malaysia.
EM suman.shipra@ieee.org
RI suman, shipra/AAE-8903-2020; suman, shipra/GQP-7224-2022; Goh,
   Khean-Lee/B-6404-2009; Malik, Aamir S/C-6904-2009; Ho,
   Shiaw-Hooi/B-1606-2017; Riegler, Michael A/E-5443-2015
OI suman, shipra/0000-0002-1689-1704; Goh, Khean-Lee/0000-0002-9965-1561;
   Malik, Aamir S/0000-0003-1085-3157; Ho, Shiaw-Hooi/0000-0003-4992-7627;
   Riegler, Michael A/0000-0002-3153-2064
FU FRINATEK project "EONS", Norway [231687]
FX This work is founded by graduate assistantship (GA) scheme, Universiti
   Teknologi PETRONAS, Perak, Malaysia and by the FRINATEK project "EONS"
   #231687, Norway.
CR AARON HB, 1971, METALL TRANS, V2, P393, DOI 10.1007/BF02663326
   Angermann Q., 2015, COMPUTATIONAL INTELL, P325, DOI 10.1007/978-3-319-20071-2_12
   Calabrese C, 2013, INTERN EMERG MED, V8, P681, DOI 10.1007/s11739-011-0699-z
   Charisis VS, 2014, IFMBE P, P297
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   Francis R., 2004, 3 INT C CAPS END
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Gay G, 2004, ENDOSCOPY, V36, P913, DOI 10.1055/s-2004-825868
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P266, DOI 10.1109/RCAR.2016.7784037
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Lee YG., 2011, WORLD ACAD SCI ENG T, V59, P2526
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Liu DD, 2012, IEEE ENG MED BIO, P73, DOI 10.1109/EMBC.2012.6345874
   Mathew M, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1730, DOI 10.1109/ECS.2015.7124882
   Park SC, 2012, WORLD J GASTROENTERO, V18, P4169, DOI 10.3748/wjg.v18.i31.4169
   Ping Tian D., 2013, INT J MULTIMED UBIQU, V8, P385
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Riegler M., 2016, P ACM MM, P968, DOI DOI 10.1145/2964284.2976760
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Zuckerman GR, 2000, GASTROENTEROLOGY, V118, P201, DOI 10.1016/S0016-5085(00)70430-6
NR 34
TC 22
Z9 22
U1 4
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1526-9914
J9 J APPL CLIN MED PHYS
JI J. Appl. Clin. Med. Phys
PD AUG
PY 2019
VL 20
IS 8
BP 141
EP 154
DI 10.1002/acm2.12662
EA JUN 2019
PG 14
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA IS0EK
UT WOS:000473805300001
PM 31251460
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Sornapudi, S
   Meng, F
   Yi, S
AF Sornapudi, Sudhir
   Meng, Frank
   Yi, Steven
TI Region-Based Automated Localization of Colonoscopy and Wireless Capsule
   Endoscopy Polyps
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE colonoscopy; wireless capsule endoscopy; polyps; localization;
   segmentation; deep learning
ID COLORECTAL POLYPS; VALIDATION
AB The early detection of polyps could help prevent colorectal cancer. The automated detection of polyps on the colon walls could reduce the number of false negatives that occur due to manual examination errors or polyps being hidden behind folds, and could also help doctors locate polyps from screening tests such as colonoscopy and wireless capsule endoscopy. Losing polyps may result in lesions evolving badly. In this paper, we propose a modified region-based convolutional neural network (R-CNN) by generating masks around polyps detected from still frames. The locations of the polyps in the image are marked, which assists the doctors examining the polyps. The features from the polyp images are extracted using pre-trained Resnet-50 and Resnet-101 models through feature extraction and fine-tuning techniques. Various publicly available polyp datasets are analyzed with various pertained weights. It is interesting to notice that fine-tuning with balloon data (polyp-like natural images) improved the polyp detection rate. The optimum CNN models on colonoscopy datasets including CVC-ColonDB, CVC-PolypHD, and ETIS-Larib produced values (F1 score, F2 score) of (90.73, 91.27), (80.65, 79.11), and (76.43, 78.70) respectively. The best model on the wireless capsule endoscopy dataset gave a performance of (96.67, 96.10). The experimental results indicate the better localization of polyps compared to recent traditional and deep learning methods.
C1 [Sornapudi, Sudhir] Missouri Univ Sci & Technol, Rolla, MO 65401 USA.
   [Meng, Frank; Yi, Steven] Xyken LLC, Mclean, VA 22102 USA.
C3 University of Missouri System; Missouri University of Science &
   Technology
RP Yi, S (通讯作者)，Xyken LLC, Mclean, VA 22102 USA.
EM ssbw5@mst.edu; fmeng@xyken.com; syi@xyken.com
RI Sornapudi, Sudhir/Z-2626-2019
OI Sornapudi, Sudhir/0000-0001-5305-7797
FU NIH [5R43AG058269]
FX This research work was supported by NIH Grant 5R43AG058269.
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   [Anonymous], END VIS CHALL SUBCH
   [Anonymous], CANC FACTS FIG 2019
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Cheng DC, 2011, BIOMED ENG-APP BAS C, V23, P357, DOI 10.4015/S1016237211002761
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Figueiredo I., 2013, P 4 ECCOMAS THEM C C, DOI [10.1201/b15810-42, DOI 10.1201/B15810-42]
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang C, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1423, DOI 10.1145/3269206.3271793
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kohli MD, 2017, J DIGIT IMAGING, V30, P392, DOI 10.1007/s10278-017-9976-3
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Lin T.Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P471, DOI 10.1016/S0002-9270(02)05928-2
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Sargent D, 2016, PROC SPIE, V9784, DOI 10.1117/12.2217123
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sornapudi Sudhir, 2018, J Pathol Inform, V9, P5, DOI 10.4103/jpi.jpi_74_17
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
NR 44
TC 47
Z9 47
U1 3
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD JUN 2
PY 2019
VL 9
IS 12
AR 2404
DI 10.3390/app9122404
PG 15
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA IG4DR
UT WOS:000473754800013
OA gold
DA 2023-04-20
ER

PT J
AU Bobrow, TL
   Mahmood, F
   Inserni, M
   Durr, NJ
AF Bobrow, Taylor L.
   Mahmood, Faisal
   Inserni, Miguel
   Durr, Nicholas J.
TI DeepLSR: a deep learning approach for laser speckle reduction
SO BIOMEDICAL OPTICS EXPRESS
LA English
DT Article
ID OPTICAL COHERENCE TOMOGRAPHY; NOISE-REDUCTION; ALGORITHM; IMAGES
AB Speckle artifacts degrade image quality in virtually all modalities that utilize coherent energy, including optical coherence tomography, reflectance confocal microscopy, ultrasound, and widefield imaging with laser illumination. We present an adversarial deep learning framework for laser speckle reduction, called DeepLSR (https : / /durr . jhu . edu/DeepLSR), that transforms images from a source domain of coherent illumination to a target domain of speckle-free, incoherent illumination. We apply this method to widefield images of objects and tissues illuminated with a multi-wavelength laser, using light emitting diode-illuminated images as ground truth. In images of gastrointestinal tissues, DeepLSR reduces laser speckle noise by 6.4 dB, compared to a 2.9 dB reduction from optimized non-local means processing, a 3.0 dB reduction from BM3D, and a 3.7 dB reduction from an optical speckle reducer utilizing an oscillating diffuser. Further, DeepLSR can be combined with optical speckle reduction to reduce speckle noise by 9.4 dB. This dramatic reduction in speckle noise may enable the use of coherent light sources in applications that require small illumination sources and high-quality imaging, including medical endoscopy. (C) 2019 Optical Society of America under the terms of the OSA Open Access Publishing Agreement
C1 [Bobrow, Taylor L.; Mahmood, Faisal; Inserni, Miguel; Durr, Nicholas J.] Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA.
C3 Johns Hopkins University
RP Durr, NJ (通讯作者)，Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA.
EM ndurr@jhu.edu
RI ; Durr, Nicholas/W-5517-2018; Mahmood, Faisal/C-1021-2015
OI Bobrow, Taylor/0000-0002-3708-4565; Durr, Nicholas/0000-0001-9808-7383;
   Mahmood, Faisal/0000-0001-7587-1562
FU NIH Trailblazer Award [R21 EB024700]
FX NIH Trailblazer Award (R21 EB024700).
CR ABBOTT JG, 1979, ULTRASONIC IMAGING, V1, P303, DOI 10.1016/0161-7346(79)90024-5
   Abergel Remy, 2015, Scale Space and Variational Methods in Computer Vision. 5th International Conference, SSVM 2015. Proceedings: LNCS 9087, P178, DOI 10.1007/978-3-319-18461-6_15
   Adler DC, 2004, OPT LETT, V29, P2878, DOI 10.1364/OL.29.002878
   Agostinelli F., 2013, ADV NEURAL INFORM PR, V26, P1493
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahn B., 2017, BLOCK MATCHING CONVO
   Avanaki MRN, 2013, APPL OPTICS, V52, P5050, DOI 10.1364/AO.52.005050
   Bashkansky M, 2000, OPT LETT, V25, P545, DOI 10.1364/OL.25.000545
   Bindilatti AA, 2018, SIGNAL PROCESS, V144, P68, DOI 10.1016/j.sigpro.2017.10.001
   Bioucas-Dias JM, 2010, IEEE T IMAGE PROCESS, V19, P1720, DOI 10.1109/TIP.2010.2045029
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen R., 2018, RETHINKING MONOCULAR
   Dabov K, 2007, IEEE IMAGE PROC, P313, DOI 10.1109/icip.2007.4378954
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deledalle CA, 2010, IEEE IMAGE PROC, P801, DOI 10.1109/ICIP.2010.5653394
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dunn AK, 2001, J CEREBR BLOOD F MET, V21, P195, DOI 10.1097/00004647-200103000-00002
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Glazowski C, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.8.085001
   Goodman J. W., 2007, SPECKLE PHENOMENA OP
   GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145
   Graetzel C, 2015, PROC SPIE, V9430, DOI 10.1117/12.2086088
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Isola P., 2017, PROC 30 IEEE C COMPU, P1125, DOI DOI 10.1109/CVPR.2017.632
   Jian ZP, 2010, OPT EXPRESS, V18, P1024, DOI 10.1364/OE.18.001024
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Kurach K., 2018, GAN LANDSCAPE LOSSES
   Li S, 2018, OPTICA, V5, P803, DOI 10.1364/OPTICA.5.000803
   Li YZ, 2018, OPTICA, V5, P1181, DOI 10.1364/OPTICA.5.001181
   Liba O, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15845
   Louchet C, 2014, EUR SIGNAL PR CONF, P1592
   Ma YH, 2018, BIOMED OPT EXPRESS, V9, P5129, DOI 10.1364/BOE.9.005129
   Mahmood F, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aada93
   Mahmood F, 2018, IEEE T MED IMAGING, V37, P2572, DOI 10.1109/TMI.2018.2842767
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Meiniel W, 2018, IEEE T IMAGE PROCESS, V27, P3842, DOI 10.1109/TIP.2018.2819821
   Ono S, 2016, IEEE T COMPUT IMAG, V2, P204, DOI 10.1109/TCI.2016.2575740
   Radford A., 2015, COMPUTER SCI
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Salinas HM, 2007, IEEE T MED IMAGING, V26, P761, DOI 10.1109/TMI.2006.887375
   Salmon J, 2014, J MATH IMAGING VIS, V48, P279, DOI 10.1007/s10851-013-0435-6
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]
   Takeru M., 2018, ARXIV180205957, P1, DOI DOI 10.48550/ARXIV.1802.05957
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong A, 2010, OPT EXPRESS, V18, P8338, DOI 10.1364/OE.18.008338
NR 46
TC 14
Z9 14
U1 1
U2 23
PU Optica Publishing Group
PI WASHINGTON
PA 2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA
SN 2156-7085
J9 BIOMED OPT EXPRESS
JI Biomed. Opt. Express
PD JUN 1
PY 2019
VL 10
IS 6
BP 2869
EP 2882
DI 10.1364/BOE.10.002869
PG 14
WC Biochemical Research Methods; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
GA IB0NL
UT WOS:000469955600015
PM 31259057
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Vieira, PM
   Silva, CP
   Costa, D
   Vaz, IF
   Rolanda, C
   Lima, CS
AF Vieira, Pedro M.
   Silva, Catarina P.
   Costa, Dalila
   Vaz, Ismael F.
   Rolanda, Carla
   Lima, Carlos S.
TI Automatic Segmentation and Detection of Small Bowel Angioectasias in WCE
   Images
SO ANNALS OF BIOMEDICAL ENGINEERING
LA English
DT Article
DE Capsule endoscopy; EM segmentation; Machine learning; Markov Random
   Fields; Angioectasias
ID SUSPECTED BLOOD INDICATOR; CAPSULE ENDOSCOPY; BLEEDING DETECTION;
   ANGIODYSPLASIA; LESIONS; PERFORMANCE
AB Angioectasias are lesions that occur in the blood vessels of the bowel and are the cause of more than 8% of all gastrointestinal bleeding episodes. They are usually classified as bleeding related lesions, however current state-of-the-art bleeding detection algorithms present low sensitivity in the detection of these lesions. This paper proposes a methodology for the automatic detection of angioectasias in wireless capsule endoscopy (WCE) videos. This method relies on the automatic selection of a region of interest, selected by using an image segmentation module based on the Maximum a Posteriori (MAP) approach where a new accelerated version of the Expectation-Maximization (EM) algorithm is also proposed. Spatial context information is modeled in the prior probability density function by using Markov Random Fields with the inclusion of a weighted boundary function. Higher order statistics computed in the CIELab color space with the luminance component removed and intensity normalization of high reflectance regions, showed to be effective features regarding angioectasia detection. The proposed method outperforms some current state of the art algorithms, achieving sensitivity and specificity values of more than 96% in a database containing 800 WCE frames labeled by two gastroenterologists.
C1 [Vieira, Pedro M.; Lima, Carlos S.] Univ Minho, CMEMS Uminho Res Unit, Guimaraes, Portugal.
   [Vaz, Ismael F.] Univ Minho, Algoritmi Ctr, Guimaraes, Portugal.
   [Silva, Catarina P.; Costa, Dalila; Rolanda, Carla] Univ Minho, Life & Hlth Sci Res Inst, Campus Gualtar, P-4710057 Braga, Portugal.
   [Silva, Catarina P.; Costa, Dalila; Rolanda, Carla] ICVS 3Bs PT Govt Associate Lab, Braga, Portugal.
   [Costa, Dalila; Rolanda, Carla] Hosp Braga, Dept Gastroenterol, Braga, Portugal.
C3 Universidade do Minho; Universidade do Minho; Universidade do Minho;
   Hospital de Braga
RP Vieira, PM (通讯作者)，Univ Minho, CMEMS Uminho Res Unit, Guimaraes, Portugal.
EM pmpvieira@gmail.com
RI Rolanda, Carla/AAF-8616-2021; Vieira, Pedro/F-6676-2018; F. Vaz, A.
   Ismael/B-3925-2010; Lima, Carlos/M-5327-2013
OI Rolanda, Carla/0000-0002-6365-8032; Vieira, Pedro/0000-0001-5458-2307;
   F. Vaz, A. Ismael/0000-0002-9972-7474; Lima, Carlos/0000-0001-8523-5287
FU FCT (Fundacao para a Ciencia e Tecnologia) [UID/EEA/04436/2019,
   SFRH/BD/92143/2013]; Fundação para a Ciência e a Tecnologia
   [SFRH/BD/92143/2013, UID/EEA/04436/2019] Funding Source: FCT
FX This work is supported by FCT (Fundacao para a Ciencia e Tecnologia)
   with the reference Project UID/EEA/04436/2019 and with the PhD Grant
   SFRH/BD/92143/2013.
CR Barbosa DJC, 2008, IEEE ENG MED BIO, P3012, DOI 10.1109/IEMBS.2008.4649837
   BOAL CARVALHO Pedro, 2017, Arq. Gastroenterol., V54, P16, DOI [10.1590/s0004-2803.2017v54n1-03, 10.1590/S0004-2803.2017v54n1-03]
   D'Halluin PN, 2005, GASTROINTEST ENDOSC, V61, P243, DOI 10.1016/S0016-5107(04)02587-8
   Deeba F., 2016, 39 C CAN MED BIOL EN
   Deeba F, 2018, J MED BIOL ENG, V38, P325, DOI 10.1007/s40846-017-0299-0
   Fan GW, 2013, J DIGEST DIS, V14, P113, DOI 10.1111/1751-2980.12021
   Figueiredo IN, 2013, COMP M BIO BIO E-IV, V1, P198, DOI 10.1080/21681163.2013.796164
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   HEMINGWAY AP, 1988, POSTGRAD MED J, V64, P259, DOI 10.1136/pgmj.64.750.259
   Hwang S., 2006, MED IMAGING 2006 IMA
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jung YS, 2008, INT CONF BIOMED, P859, DOI 10.1109/BMEI.2008.216
   Karargyris A., 2008, P 8 IEEE INT C BIOIN, P1
   Kodogiannis VS, 2007, ENG APPL ARTIF INTEL, V20, P539, DOI 10.1016/j.engappai.2006.09.006
   Koulaouzidis A., 2016, KID KOULAOUZIDIS IAK
   Lau PY, 2007, P ANN INT IEEE EMBS, P5601, DOI 10.1109/IEMBS.2007.4353616
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Noya F, 2017, IEEE ENG MED BIO, P3158, DOI 10.1109/EMBC.2017.8037527
   Pan Guo-bing, 2010, Journal of Shanghai Jiaotong University (English Edition), V15, P218, DOI 10.1007/s12204-010-9716-z
   Plasse J. H, 2013, THESIS
   Pogorelov K., 2018, 2018 IEEE EMBS INT C, P365, DOI DOI 10.1109/BHI.2018.8333444
   Regula J, 2008, BEST PRACT RES CL GA, V22, P313, DOI 10.1016/j.bpg.2007.10.026
   Shvets A, 2018, CORR
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270
   Vieira P, 2012, IEEE ENG MED BIO, P4010, DOI 10.1109/EMBC.2012.6346846
   Vieira PM, 2016, IEEE ENG MED BIO, P1184, DOI 10.1109/EMBC.2016.7590916
   Walker HF, 2011, SIAM J NUMER ANAL, V49, P1715, DOI 10.1137/10078356X
   Warkentin TE, 2003, TRANSFUS MED REV, V17, P272, DOI 10.1016/S0887-7963(03)00037-3
   WEATHERALL IL, 1992, J INVEST DERMATOL, V99, P468, DOI 10.1111/1523-1747.ep12616156
   Woodland A., 2005, P INT C VIS VID GRAP, P29
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P43, DOI 10.1080/17474124.2017.1257384
   Zheng YP, 2012, AM J GASTROENTEROL, V107, P554, DOI 10.1038/ajg.2011.461
NR 36
TC 8
Z9 8
U1 1
U2 17
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0090-6964
EI 1573-9686
J9 ANN BIOMED ENG
JI Ann. Biomed. Eng.
PD JUN
PY 2019
VL 47
IS 6
BP 1446
EP 1462
DI 10.1007/s10439-019-02248-7
PG 17
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA HX4PR
UT WOS:000467382400012
PM 30919139
DA 2023-04-20
ER

PT J
AU Wu, LL
   Zhou, W
   Wan, XY
   Zhang, J
   Shen, L
   Hu, S
   Ding, QS
   Mu, GG
   Yin, AN
   Huang, X
   Liu, J
   Jiang, XD
   Wang, ZQ
   Deng, YC
   Liu, M
   Lin, R
   Ling, TS
   Li, P
   Wu, Q
   Jin, P
   Chen, J
   Yu, HG
AF Wu, Lianlian
   Zhou, Wei
   Wan, Xinyue
   Zhang, Jun
   Shen, Lei
   Hu, Shan
   Ding, Qianshan
   Mu, Ganggang
   Yin, Anning
   Huang, Xu
   Liu, Jun
   Jiang, Xiaoda
   Wang, Zhengqiang
   Deng, Yunchao
   Liu, Mei
   Lin, Rong
   Ling, Tingsheng
   Li, Peng
   Wu, Qi
   Jin, Peng
   Chen, Jie
   Yu, Honggang
TI A deep neural network improves endoscopic detection of early gastric
   cancer without blind spots
SO ENDOSCOPY
LA English
DT Article
ID GASTROINTESTINAL ENDOSCOPY; EUROPEAN-SOCIETY; SURVEILLANCE; DIAGNOSIS;
   ACCURATE
AB Background Gastric cancer is the third most lethal malignancy worldwide. A novel deep convolution neural network (DCNN) to perform visual tasks has been recently developed. The aim of this study was to build a system using the DCNN to detect early gastric cancer (EGC) without blind spots during esophagogastroduodenoscopy (EGD).
   Methods 3170 gastric cancer and 5981 benign images were collected to train the DCNN to detect EGC. A total of 24549 images from different parts of stomach were collected to train the DCNN to monitor blind spots. Class activation maps were developed to automatically cover suspicious cancerous regions. A grid model for the stomach was used to indicate the existence of blind spots in unprocessed EGD videos.
   Results The DCNN identified EGC from non-malignancy with an accuracy of 92.5%, a sensitivity of 94.0%, a specificity of 91.0%, a positive predictive value of 91.3%, and a negative predictive value of 93.8%, outperforming all levels of endoscopists. In the task of classifying gastric locations into 10 or 26 parts, the DCNN achieved an accuracy of 90% or 65.9%, on a par with the performance of experts. In realtime unprocessed EGD videos, the DCNN achieved automated performance for detecting EGC and monitoring blind spots.
   Conclusions We developed a system based on a DCNN to accurately detect EGC and recognize gastric locations better than endoscopists, and proactively track suspicious cancerous lesions and monitor blind spots during EGD.
C1 [Wu, Lianlian; Zhou, Wei; Wan, Xinyue; Zhang, Jun; Shen, Lei; Ding, Qianshan; Mu, Ganggang; Yin, Anning; Huang, Xu; Liu, Jun; Jiang, Xiaoda; Wang, Zhengqiang; Deng, Yunchao; Yu, Honggang] Wuhan Univ, Dept Gastroenterol, Renmin Hosp, 99 Zhangzhidong Rd, Wuhan 430060, Hubei, Peoples R China.
   [Wu, Lianlian; Zhou, Wei; Wan, Xinyue; Zhang, Jun; Shen, Lei; Ding, Qianshan; Mu, Ganggang; Yin, Anning; Huang, Xu; Jiang, Xiaoda; Wang, Zhengqiang; Deng, Yunchao; Yu, Honggang] Wuhan Univ, Renmin Hosp, Key Lab Hubei Prov Digest Syst Dis, Wuhan, Hubei, Peoples R China.
   [Wu, Lianlian; Zhou, Wei; Wan, Xinyue; Zhang, Jun; Shen, Lei; Ding, Qianshan; Mu, Ganggang; Yin, Anning; Huang, Xu; Liu, Jun; Jiang, Xiaoda; Wang, Zhengqiang; Deng, Yunchao; Yu, Honggang] Wuhan Univ, Renmin Hosp, Hubei Prov Clin Res Ctr Digest Dis Minimally Inva, Wuhan, Hubei, Peoples R China.
   [Hu, Shan] Wuhan Univ, Sch Resources & Environm Sci, Wuhan, Hubei, Peoples R China.
   [Liu, Mei] Huazhong Univ Sci & Technol, Tongji Hosp, Dept Gastroenterol, Wuhan, Hubei, Peoples R China.
   [Lin, Rong] Huazhong Univ Sci & Technol, Wuhan Union Hosp, Dept Gastroenterol, Wuhan, Hubei, Peoples R China.
   [Ling, Tingsheng] Nanjin Univ, Nanjing Drum Tower Hosp, Dept Gastroenterol, Nanjing, Peoples R China.
   [Li, Peng] Capital Univ Med Sci, Beijing Friendship Hosp, Dept Gastroenterol, Beijing, Peoples R China.
   [Wu, Qi] Peking Univ, Beijing Canc Hosp, Endoscopy Ctr, Beijing, Peoples R China.
   [Jin, Peng] Beijing Mil Hosp, Dept Gastroenterol, Beijing, Peoples R China.
   [Chen, Jie] Second Mil Med Univ, Changhai Hosp, Dept Gastroenterol, Shanghai, Peoples R China.
C3 Wuhan University; Wuhan University; Wuhan University; Wuhan University;
   Huazhong University of Science & Technology; Huazhong University of
   Science & Technology; Nanjing University; Capital Medical University;
   Peking University; Naval Medical University
RP Yu, HG (通讯作者)，Wuhan Univ, Dept Gastroenterol, Renmin Hosp, 99 Zhangzhidong Rd, Wuhan 430060, Hubei, Peoples R China.
EM yuhonggang1968@163.com
RI Yin, Anning/AAF-9617-2020
OI Jin, Peng/0000-0001-6685-1906; wan, xinyue/0000-0002-4507-2011
FU Research Funds for Key Laboratory of Hubei Province [2016CFA066];
   National Natural Science Foundation of China [81672387]; China Youth
   Development Foundation [81401959, 81703030]
FX This work was partly supported by a grant from the Research Funds for
   Key Laboratory of Hubei Province (No. 2016CFA066), the National Natural
   Science Foundation of China (grant nos. 81672387 [to Yu Honggang]), and
   the China Youth Development Foundation (grant no. 81401959 [to Zhou Wei]
   and grant no. 81703030 [to Ding Qianshan]).
CR Abadi, 2015, TENSORFLOW LARGE SCA
   Bisschops R, 2016, ENDOSCOPY, V48, P843, DOI 10.1055/s-0042-113128
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Ezoe Y, 2011, GASTROENTEROLOGY, V141, P2017, DOI 10.1053/j.gastro.2011.08.007
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Jun Liang Teh MH, 2011, GASTROINTEST ENDOSC, V73, pAB393, DOI DOI 10.1016/J.GIE.2011.03.878
   Jung Y, 2015, J NONPARAMETR STAT, V27, P167, DOI 10.1080/10485252.2015.1010532
   Kim GH, 2015, KOREAN J INTERN MED, V30, P747, DOI 10.3904/kjim.2015.30.6.747
   Laks S, 2017, SURG CLIN N AM, V97, P317, DOI 10.1016/j.suc.2016.11.007
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li SB, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081729
   O'Mahony S, 2000, ENDOSCOPY, V32, P483, DOI 10.1055/s-2000-649
   OHailey T., 2010, HYBRID ANIMATION INT
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Pasechnikov V, 2014, WORLD J GASTROENTERO, V20, P13842, DOI 10.3748/wjg.v20.i38.13842
   Prechelt L, 1998, NEURAL NETWORKS, V11, P761, DOI 10.1016/S0893-6080(98)00010-0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rutter MD, 2016, UNITED EUR GASTROENT, V4, P30, DOI 10.1177/2050640615624631
   Scaffidi MA, 2018, GASTROINTEST ENDOSC, V87, P827, DOI 10.1016/j.gie.2017.10.040
   Simonyan K., ARXIV14091556 CORR
   Soetikno R, 2005, J CLIN ONCOL, V23, P4490, DOI 10.1200/JCO.2005.19.935
   Song MAT, 2014, GASTROINTESTINAL INT, V3, P1, DOI DOI 10.1016/J.GII.2014.02.005
   TANNER MA, 1987, J AM STAT ASSOC, V82, P528, DOI 10.2307/2289457
   Torkamani A, 2017, CELL, V170, P828, DOI 10.1016/j.cell.2017.08.007
   Tsai TH, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.12.121716
   Wen ZY, 2017, AAAI CONF ARTIF INTE, P2768
   Yalamarthi S, 2004, ENDOSCOPY, V36, P874, DOI 10.1055/s-2004-825853
   Yao K, 2017, GASTRIC CANCER, V20, pS28, DOI 10.1007/s10120-016-0680-7
   Yao K, 2013, ANN GASTROENTEROL, V26, P11
   Zhang Q, 2016, GASTRIC CANCER, V19, P543, DOI 10.1007/s10120-015-0500-5
   Zhou B., 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319
NR 35
TC 107
Z9 121
U1 6
U2 50
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD JUN
PY 2019
VL 51
IS 6
BP 522
EP 531
DI 10.1055/a-0855-3532
PG 10
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA IC3UJ
UT WOS:000470887100022
PM 30861533
DA 2023-04-20
ER

PT J
AU Charfi, S
   El Ansari, M
   Balasingham, I
AF Charfi, Said
   El Ansari, Mohamed
   Balasingham, Ilangko
TI Computer-aided diagnosis system for ulcer detection in wireless capsule
   endoscopy images
SO IET IMAGE PROCESSING
LA English
DT Article
DE support vector machines; endoscopes; multilayer perceptrons; biomedical
   optical imaging; diseases; hidden Markov models; image classification;
   image texture; feature extraction; medical image processing; image
   segmentation; segmented regions; computer-aided diagnosis system; ulcer
   detection; wireless capsule endoscopy; gastrointestinal tract;
   traditional endoscopies; diagnosis time; detection accuracy; CAD system;
   WCE images; input images; saliency map-based texture; colour; ulcerous
   regions
ID CLASSIFICATION; TEXTURE; SEGMENTATION; MODEL; FEATURES; SALIENCY
AB Wireless capsule endoscopy (WCE) has revolutionised the diagnosis and treatment of gastrointestinal tract, especially the small intestine which is unreachable by traditional endoscopies. The drawback of the WCE is that it produces a large number of images to be inspected by the clinicians. Hence, the design of a computer-aided diagnosis (CAD) system will have a great potential to help reduce the diagnosis time and improve the detection accuracy. To address this problem, the authors propose a CAD system for automatic detection of ulcer in WCE images. Firstly, they enhance the input images to be better exploited in the main steps of the proposed method. Afterward, segmentation using saliency map-based texture and colour is applied to the WCE images in order to highlight ulcerous regions. Then, inspired by the existing feature extraction approaches, a new one has been proposed for the recognition of the segmented regions. Finally, a new recognition scheme is proposed based on hidden Markov model using the classification scores of the conventional methods (support vector machine, multilayer perceptron and random forest) as observations. Experimental results with two different datasets show that the proposed method gives promising results.
C1 [Charfi, Said; El Ansari, Mohamed] Ibn Zohr Univ, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
   [Balasingham, Ilangko] Oslo Univ Hosp, Oslo, Norway.
   [Balasingham, Ilangko] Norwegian Univ Sci & Technol, Dept Elect Syst, Trondheim, Norway.
C3 Ibn Zohr University of Agadir; University of Oslo; Norwegian University
   of Science & Technology (NTNU)
RP Charfi, S (通讯作者)，Ibn Zohr Univ, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
EM charfisaid@gmail.com
RI Balasingham, Ilangko/AGU-7268-2022; El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066
FU National Center for Scientific and Technical Research (CNRST) in Rabat
FX We gratefully acknowledge and express our thanks to the National Center
   for Scientific and Technical Research (CNRST) in Rabat for its research
   grant.
CR Achanta R., 2010, TECHNICAL REPORT
   Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   [Anonymous], 2018, C ENDOSCOPY CAPSULE, P1
   Banerji Sugata, 2011, Proceedings of the 2011 International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV 2011), P537
   Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246
   Boreczky JS, 1998, INT CONF ACOUST SPEE, P3741, DOI 10.1109/ICASSP.1998.679697
   Bosch A., 2007, P 6 ACM INT C IM VID, P401, DOI DOI 10.1145/1282280.1282340
   Buscaglia JM, 2008, CLIN GASTROENTEROL H, V6, P298, DOI 10.1016/j.cgh.2007.12.029
   Charfi S., 2018, IEEE T LEARN TECHNOL, P1, DOI DOI 10.1109/TLT.2017.2720670
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Chen HD, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/8147632
   El Ansari M., 2017, 2017 INT C WIR NETW
   Ghosh T., 2016, INT J SCI ENG RES, V7, P737
   Ghosh T, 2018, COMPUT BIOL MED, V94, P41, DOI 10.1016/j.compbiomed.2017.12.014
   Harel J., 2006, P ADV NEUR INF PROC, DOI DOI 10.7551/MITPRESS/7503.003.0073
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Hassan M, 2017, COMPUT METH PROG BIO, V151, P193, DOI 10.1016/j.cmpb.2017.08.023
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kopylov Uri, 2016, Gastrointest Endosc Clin N Am, V26, P611, DOI 10.1016/j.giec.2016.06.007
   Koshy NE, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1725, DOI 10.1109/ECS.2015.7124881
   Kundu AK, 2017, TENCON IEEE REGION, P1300
   Kundu AK, 2016, 2016 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2016), P242, DOI 10.1109/WIECON-ECE.2016.8009127
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li Zhaoshen, 2014, CURRENT MAIN TYPES C, P5
   Mitselos IV, 2015, WORLD J GASTRO ENDOS, V7, P643, DOI 10.4253/wjge.v7.i6.643
   Murugappan V, 2019, CLUSTER COMPUT, V22, P10979, DOI 10.1007/s10586-017-1269-6
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pohle J, 2017, J AGR BIOL ENVIR ST, V22, P270, DOI 10.1007/s13253-017-0283-8
   Ponte A., 2017, GASTROENTEROL HEPATO, V41, P245
   Qureshi WA, 2004, NAT REV DRUG DISCOV, V3, P447, DOI 10.1038/nrd1385
   Ren YF, 2014, INT CONF MACH LEARN, P7, DOI 10.1109/ICMLC.2014.7009083
   Rokkas T, 2010, GASTROINTEST ENDOSC, V71, P792, DOI 10.1016/j.gie.2009.10.050
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Sivakumar P, 2019, CONNECT TISSUE RES, V60, P62, DOI 10.1080/03008207.2018.1500557
   Souaidi M., 2017, P 2017 INT C ADV TEC, P1
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Suman S, 2016, ADV SCI LETT, V22, P2764, DOI 10.1166/asl.2016.7099
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Usman MA, 2016, COMPUT MED IMAG GRAP, V54, P16, DOI 10.1016/j.compmedimag.2016.09.005
   WE Organization, 1962, WEO CLIN END ATL
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Xia KJ, 2019, CLUSTER COMPUT, V22, P1515, DOI 10.1007/s10586-018-2026-1
   Yuan Y., 2016, IEEE T AUTOM SCI ENG, V7, P737
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   ZHENG Y, 2008, IEEE CONF ON COMPUTE, V2008, P1
NR 58
TC 22
Z9 23
U1 2
U2 26
PU INST ENGINEERING TECHNOLOGY-IET
PI HERTFORD
PA MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND
SN 1751-9659
EI 1751-9667
J9 IET IMAGE PROCESS
JI IET Image Process.
PD MAY
PY 2019
VL 13
IS 6
BP 1023
EP 1030
DI 10.1049/iet-ipr.2018.6232
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA HX5IZ
UT WOS:000467435800018
DA 2023-04-20
ER

PT J
AU de Groof, J
   van der Sommen, F
   van der Putten, J
   Struyvenberg, MR
   Zinger, S
   Curvers, ML
   Pech, O
   Meining, A
   Neuhaus, H
   Bisschops, R
   Schoon, EJ
   de With, PH
   Bergman, JJ
AF de Groof, Jeroen
   van der Sommen, Fons
   van der Putten, Joost
   Struyvenberg, Maarten R.
   Zinger, Sveta
   Curvers, Muter L.
   Pech, Oliver
   Meining, Alexander
   Neuhaus, Horst
   Bisschops, Raf
   Schoon, Erik J.
   de With, Peter H.
   Bergman, Jacques J.
TI The Argos project: The development of a computer-aided detection system
   to improve detection of Barrett's neoplasia on white light endoscopy
SO UNITED EUROPEAN GASTROENTEROLOGY JOURNAL
LA English
DT Article
DE Barrett's oesophagus; endoscopy; computer-aided detection; Barrett's
   neoplasia; artificial intelligence
ID COLORECTAL LESIONS; ADENOCARCINOMA; ESOPHAGUS; MANAGEMENT; HISTOLOGY
AB Background Computer-aided detection (CAD) systems might assist endoscopists in the recognition of Barrett's neoplasia. Aim To develop a CAD system using endoscopic images of Barrett's neoplasia. Methods White light endoscopy (WLE) overview images of 40 neoplastic Barrett's lesions and 20 non-dysplastic Barret's oesophagus (NDBO) patients were prospectively collected. Experts delineated all neoplastic images. The overlap area of at least four delineations was labelled as the 'sweet spot'. The area with at least one delineation was labelled as the 'soft spot'. The CAD system was trained on colour and texture features. Positive features were taken from the sweet spot and negative features from NDBO images. Performance was evaluated using leave-one-out cross-validation. Outcome parameters were diagnostic accuracy of the CAD system per image, and localization of the expert soft spot by CAD delineation (localization score) and its indication of preferred biopsy location (red-flag indication score). Results Accuracy, sensitivity and specificity for detection were 92, 95 and 85%, respectively. The system localized and red-flagged the soft spot in 100 and 90%, respectively. Conclusion This uniquely trained and validated CAD system detected and localized early Barrett's neoplasia on WLE images with high accuracy. This is an important step towards real-time automated detection of Barrett's neoplasia.
C1 [de Groof, Jeroen; Struyvenberg, Maarten R.; Bergman, Jacques J.] Univ Amsterdam, Dept Gastroenterol & Hepatol, Amsterdam, Netherlands.
   [van der Sommen, Fons; van der Putten, Joost; Zinger, Sveta; de With, Peter H.] Eindhoven Univ Technol, Dept Elect Engn, Eindhoven, Netherlands.
   [Curvers, Muter L.; Schoon, Erik J.] Catharina Hosp, Dept Gastroenterol & Hepatol, Eindhoven, Netherlands.
   [Pech, Oliver] Krankenhaus Barmherzige Bruder, Gastroenterol & Intervent Endoscopy, Regensburg, Germany.
   [Meining, Alexander] Ulm Univ, Ctr Internal Med, Ulm, Germany.
   [Neuhaus, Horst] Evangel Krankenhaus Dusseldorf, Internal Med, Dusseldorf, Germany.
   [Bisschops, Raf] Univ Hosp Leuven, Dept Gastroenterol & Hepatol, Leuven, Belgium.
C3 University of Amsterdam; Eindhoven University of Technology; Catharina
   Hospital; Ulm University; KU Leuven; University Hospital Leuven
RP Bergman, JJ (通讯作者)，Acad Med Ctr, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.
EM a.j.degroof@amc.uva.nl
RI Bergman, Jacques/AAS-2500-2021
OI Bergman, Jacques/0000-0001-7548-6955; van der Sommen,
   Fons/0000-0002-3593-2356; Bisschops, Raf/0000-0002-9994-8226
FU Dutch Cancer Society; Technology Foundation STW
FX This research is supported by the Dutch Cancer Society and Technology
   Foundation STW, as part of their joint strategic research programme
   'Technology for Oncology'.
CR de Groof J, 2018, GASTROENTEROLOGY, V154, pS209
   Hvid-Jensen F, 2011, NEW ENGL J MED, V365, P1375, DOI 10.1056/NEJMoa1103042
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Pech O, 2014, GASTROENTEROLOGY, V146, P652, DOI 10.1053/j.gastro.2013.11.006
   Scholvinck DW, 2017, ENDOSCOPY, V49, P113, DOI 10.1055/s-0042-118312
   Sikkema M, 2010, CLIN GASTROENTEROL H, V8, P235, DOI 10.1016/j.cgh.2009.10.010
   Spechler SJ, 2011, GASTROENTEROLOGY, V140, P1084, DOI 10.1053/j.gastro.2011.01.030
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Weusten B, 2017, ENDOSCOPY, V49, P191, DOI 10.1055/s-0042-122140
NR 16
TC 60
Z9 60
U1 2
U2 3
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2050-6406
EI 2050-6414
J9 UNITED EUR GASTROENT
JI United European Gastroenterol. J.
PD MAY
PY 2019
VL 7
IS 4
BP 538
EP 547
DI 10.1177/2050640619837443
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HV6XM
UT WOS:000466126100009
PM 31065371
OA Green Published, Green Accepted, hybrid
DA 2023-04-20
ER

PT J
AU Geng, WJ
   Tang, HL
   Sharma, A
   Zhao, YZ
   Yan, Y
   Hong, W
AF Geng, Wujun
   Tang, Hongli
   Sharma, Apurb
   Zhao, Yizhou
   Yan, Ye
   Hong, Wandong
TI An artificial neural network model for prediction of hypoxemia during
   sedation for gastrointestinal endoscopy
SO JOURNAL OF INTERNATIONAL MEDICAL RESEARCH
LA English
DT Article
DE Age; anaesthesia; endoscopic procedure; hypoxemia; risk factor;
   sedation; snoring
ID BODY-MASS INDEX; THYROMENTAL DISTANCE; DIFFICULT INTUBATION;
   ESOPHAGEAL-VARICES; COMPLICATIONS
AB Objective This study was designed to assess clinical predictors of hypoxemia and develop an artificial neural network (ANN) model for prediction of hypoxemia during sedation for gastrointestinal endoscopy examination. Methods A total of 220 patients were enrolled in this prospective observational study. Data on demographics, chronic concomitant disease information, neck circumference, thyromental distance and anaesthetic dose were collected and statistically analysed. Results Univariate analysis indicated that body mass index (BMI), habitual snoring and neck circumference were associated with hypoxemia. An ANN model was developed with three variables (BMI, habitual snoring and neck circumference). The area under the receiver operating characteristic curve for the ANN model was 0.80. Conclusions The ANN model developed here, comprising BMI, habitual snoring and neck circumference, was useful for prediction of hypoxemia during sedation for gastrointestinal endoscopy.
C1 [Geng, Wujun; Tang, Hongli] Wenzhou Med Univ, Affiliated Hosp 1, Dept Anesthesiol, Wenzhou, Peoples R China.
   [Sharma, Apurb] Nepal Mediciti Hosp, Dept Anesthesia Pain Management & Crit Care, Karyabinayak, Nepal.
   [Zhao, Yizhou] Zhejiang Univ, Sch Med, Dept Clin Med, Hangzhou, Zhejiang, Peoples R China.
   [Yan, Ye; Hong, Wandong] Wenzhou Med Univ, Affiliated Hosp 1, Dept Gastroenterol & Hepatol, Wenzhou 325000, Zhejiang, Peoples R China.
C3 Wenzhou Medical University; Zhejiang University; Wenzhou Medical
   University
RP Hong, W (通讯作者)，Wenzhou Med Univ, Affiliated Hosp 1, Dept Gastroenterol & Hepatol, Wenzhou 325000, Zhejiang, Peoples R China.
EM xhnk-hwd@163.com
OI Sharma, Apurb/0000-0002-1655-5997; Hong, Wandong/0000-0001-6857-4252;
   Tang, Hongli/0000-0003-2215-2294
FU National Natural Science Foundation of China [81774109]; Zhejiang
   Provincial Department of Education [Y201839270]; Wenzhou Science and
   Technology Plan Project [Y20180508]
FX This work was partly supported by the National Natural Science
   Foundation of China (81774109), Zhejiang Provincial Department of
   Education (Y201839270) and Wenzhou Science and Technology Plan Project
   (Y20180508).
CR Cote GA, 2010, CLIN GASTROENTEROL H, V8, P660, DOI 10.1016/j.cgh.2010.05.015
   Cote GA, 2010, CLIN GASTROENTEROL H, V8, P137, DOI 10.1016/j.cgh.2009.07.008
   Geng WJ, 2018, CLINICS, V73, DOI 10.6061/clinics/2018/e513
   Hong WD, 2013, CLINICS, V68, P27, DOI 10.6061/clinics/2013(01)RC01
   Hong WD, 2011, HEPAT MON, V11, P544
   Hong WD, 2009, BMC GASTROENTEROL, V9, DOI 10.1186/1471-230X-9-11
   Jones RL, 2006, CHEST, V130, P827, DOI 10.1378/chest.130.3.827
   Kendale SM, 2016, J CLIN ANESTH, V33, P97, DOI 10.1016/j.jclinane.2016.03.020
   Khan ZH, 2009, ANESTH ANALG, V109, P822, DOI 10.1213/ane.0b013e3181af7f0d
   Kim WH, 2011, BRIT J ANAESTH, V106, P743, DOI 10.1093/bja/aer024
   Mehta PP, 2014, GASTROINTEST ENDOSC, V79, P436, DOI 10.1016/j.gie.2013.09.022
   Sharma SK, 2006, CHEST, V130, P149, DOI 10.1378/chest.130.1.149
   Tripathi M, 2006, ANESTHESIOLOGY, V104, P1131, DOI 10.1097/00000542-200606000-00006
   Wani S, 2011, GASTROINTEST ENDOSC, V74, P1238, DOI 10.1016/j.gie.2011.09.006
NR 14
TC 4
Z9 4
U1 0
U2 0
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0300-0605
EI 1473-2300
J9 J INT MED RES
JI J. Int. Med. Res.
PD MAY
PY 2019
VL 47
IS 5
BP 2097
EP 2103
DI 10.1177/0300060519834459
PG 7
WC Medicine, Research & Experimental; Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine; Pharmacology & Pharmacy
GA IG0XI
UT WOS:000473513700028
PM 30913936
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Stidham, RW
   Liu, WS
   Bishu, S
   Rice, MD
   Higgins, PDR
   Zhu, J
   Nallamothu, BK
   Waljee, AK
AF Stidham, Ryan W.
   Liu, Wenshuo
   Bishu, Shrinivas
   Rice, Michael D.
   Higgins, Peter D. R.
   Zhu, Ji
   Nallamothu, Brahmajee K.
   Waljee, Akbar K.
TI Performance of a Deep Learning Model vs Human Reviewers in Grading
   Endoscopic Disease Severity of Patients With Ulcerative Colitis
SO JAMA NETWORK OPEN
LA English
DT Article
ID INFLAMMATORY-BOWEL-DISEASE; CLASSIFICATION
AB IMPORTANCE Assessing endoscopic disease severity in ulcerative colitis (UC) is a key element in determining therapeutic response, but its use in clinical practice is limited by the requirement for experienced human reviewers.
   OBJECTIVE To determine whether deep learning models can grade the endoscopic severity of UC as well as experienced human reviewers.
   DESIGN, SETTING, AND PARTICIPANTS In this diagnostic study, retrospective grading of endoscopic images using the 4-level Mayo subscore was performed by 2 independent reviewers with score discrepancies adjudicated by a third reviewer. Using 16 514 images from 3082 patients with UC who underwent colonoscopy at a single tertiary care referral center in the United States between January 1, 2007, and December 31, 2017, a 159-layer convolutional neural network (CNN) was constructed as a deep learning model to train and categorize images into 2 clinically relevant groups: remission (Mayo subscore 0 or 1) and moderate to severe disease (Mayo subscore, 2 or 3). Ninety percent of the cohort was used to build the model and 10% was used to test it; the process was repeated 10 times. A set of 30 full-motion colonoscopy videos, unseen by the model, was then used for external validation to mimic real-world application.
   MAIN OUTCOMES AND MEASURES Model performance was assessed using area under the receiver operating curve (AUROC), sensitivity and specificity, positive predictive value (PPV), and negative predictive value (NPV). Kappa statistics (kappa) were used to measure agreement of the CNN relative to adjudicated human reference cores.
   RESULTS The authors included 16 514 images from 3082 unique patients (median [IQR] age, 41.3 [26.1-61.8] years, 1678 [54.4%] female), with 3980 images (24.1%) classified as moderate-to-severe disease by the adjudicated reference score. The CNN was excellent for distinguishing endoscopic remission from moderate-to-severe disease with an AUROC of 0.966 (95% CI, 0.967-0.972); a PPV of 0.87 (95% CI, 0.85-0.88) with a sensitivity of 83.0% (95% CI, 80.8%-85.4%) and specificty of 96.0% (95% CI, 95.1%-97.1%); and NPV of 0.94 (95% CI, 0.93-0.95). Weighted kappa agreement between the CNN and the adjudicated reference score was also good for identifying exact Mayo subscores (kappa = 0.84; 95% CI, 0.83-0.86) and was similar to the agreement between experienced reviewers (kappa = 0.86; 95% CI, 0.85-0.87). Applying the CNN to entire colonoscopy videos had similar accuracy for identifying moderate to severe disease (AUROC, 0.97; 95% CI, 0.963-0.969).
   CONCLUSIONS AND RELEVANCE This study found that deep learning model performance was similar to experienced human reviewers in grading endoscopic severity of UC. Given its scalability, this approach could improve the use of colonoscopy for UC in both research and routine practice.
C1 [Stidham, Ryan W.; Liu, Wenshuo; Zhu, Ji; Nallamothu, Brahmajee K.; Waljee, Akbar K.] Univ Michigan, MiCHAMP, Ann Arbor, MI 48109 USA.
   [Stidham, Ryan W.; Bishu, Shrinivas; Rice, Michael D.; Higgins, Peter D. R.; Waljee, Akbar K.] Univ Michigan, Dept Internal Med, Div Gastroenterol & Hepatol, Ann Arbor, MI 48109 USA.
   [Zhu, Ji] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA.
   [Nallamothu, Brahmajee K.] Univ Michigan, Dept Internal Med, Div Cardiol, Ann Arbor, MI 48109 USA.
   [Nallamothu, Brahmajee K.; Waljee, Akbar K.] Vet Affairs Ctr Clin Management Res, Ann Arbor, MI USA.
   [Nallamothu, Brahmajee K.; Waljee, Akbar K.] Vet Affairs Ann Arbor Hlth Care Syst, Dept Internal Med, Ann Arbor, MI USA.
C3 University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan; University of Michigan System;
   University of Michigan; University of Michigan System; University of
   Michigan; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); VA Ann Arbor Healthcare System
RP Stidham, RW (通讯作者)，Univ Michigan, Sch Med, 1500 E Med Ctr Dr,3912 Taubman Ctr, Ann Arbor, MI 48109 USA.
EM ryanstid@med.umich.edu
RI Waljee, Akbar K/G-2067-2010; zhu, ji/HDM-1538-2022
OI Waljee, Akbar K/0000-0003-1964-8790; Bishu,
   Shrinivas/0000-0003-4823-5805
FU National Institutes of Health [K23-DK101687]; Michigan Institute for
   Data Science Challenge Award (MIDAS), University of Michigan
FX Data acquisition and analysis were supported by National Institutes of
   Health grant K23-DK101687 (Dr Stidham). Drs Liu, Nallamothu, andWaljee
   are supported by Michigan Institute for Data Science Challenge Award
   (MIDAS), University of Michigan.
CR Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Cardoso JS, 2007, J MACH LEARN RES, V8, P1393
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Colombel JF, 2011, GASTROENTEROLOGY, V141, P1194, DOI 10.1053/j.gastro.2011.06.054
   Cooney RM, 2007, TRIALS, V8, DOI 10.1186/1745-6215-8-17
   de Chambrun GP, 2010, NAT REV GASTRO HEPAT, V7, P15, DOI 10.1038/nrgastro.2009.203
   de Lange T, 2004, BMC GASTROENTEROL, V4, DOI 10.1186/1471-230X-4-9
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   European Medicines Agency, GUID DEV NEW MED PRO
   Feagan BG, 2013, GASTROENTEROLOGY, V145, P149, DOI 10.1053/j.gastro.2013.03.025
   Froslie KF, 2007, GASTROENTEROLOGY, V133, P412, DOI 10.1053/j.gastro.2007.05.051
   Gottlieb K, 2015, INFLAMM BOWEL DIS, V21, P2475, DOI 10.1097/MIB.0000000000000470
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hebuterne X, 2013, GUT, V62, P201, DOI 10.1136/gutjnl-2012-302262
   Hou JK, 2014, DIGEST DIS SCI, V59, P2406, DOI 10.1007/s10620-014-3174-7
   ImageNet, MATLAB TOOLB IMAGENE
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Kingma D., 2015, INT C LEARNING REPRE
   LACHIN JM, 1981, CONTROL CLIN TRIALS, V2, P177, DOI 10.1016/0197-2456(81)90012-X
   SCHROEDER KW, 1987, NEW ENGL J MED, V317, P1625, DOI 10.1056/NEJM198712243172603
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Travis SPL, 2012, GUT, V61, P535, DOI 10.1136/gutjnl-2011-300486
   United States Food and Drug Administration, 2016, ULC COL CLIN TRIAL E
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vashist NM, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD011450.pub2
NR 25
TC 102
Z9 102
U1 5
U2 11
PU AMER MEDICAL ASSOC
PI CHICAGO
PA 330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA
SN 2574-3805
J9 JAMA NETW OPEN
JI JAMA Netw. Open
PD MAY
PY 2019
VL 2
IS 5
AR e193963
DI 10.1001/jamanetworkopen.2019.3963
PG 10
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA IK7XE
UT WOS:000476806200057
PM 31099869
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Ji, XD
   Xu, TT
   Li, WH
   Liang, LY
AF Ji, Xiaodong
   Xu, Tingting
   Li, Wenhua
   Liang, Liyuan
TI Study on the classification of capsule endoscopy images
SO EURASIP JOURNAL ON IMAGE AND VIDEO PROCESSING
LA English
DT Article
DE Capsule endoscopy; Classification; Wavelet transform; Color histogram;
   Co-occurrence matrix
AB Wireless capsule endoscope allows painless endoscopic imaging of the gastrointestinal track of humans. However, the whole procedure will generate a large number of capsule endoscopy images (CEIs) for reading and recognizing. In order to save the time and energy of physicians, computer-aided analysis methods are imperatively needed. Due to the influence of air bubble, illumination, and shooting angle, however, it is difficult to classify CEIs into healthy and diseased categories correctly for a conventional classification method. To this end, in the paper, a new feature extraction method is proposed based on color histogram, wavelet transform, and co-occurrence matrix. First, an improved color histogram is calculated in the HSV (hue, saturation, value) space. Meanwhile, by using the wavelet transform, the low-frequency parts of the CEIs are filtered out, and then, the characteristic values of the reconstructed CEIs' co-occurrence matrix are calculated. Next, by employing the proposed feature extraction method and the BPNN (back propagation neural network), a novel computer-aided classification algorithm is developed, where the feature values of color histogram and co-occurrence matrix are normalized as the inputs of the BPNN for training and classification. Experimental results show that the accuracy of the proposed algorithm is up to 99.12% which is much better than the compared conventional methods.
C1 [Ji, Xiaodong; Xu, Tingting; Li, Wenhua; Liang, Liyuan] Nantong Univ, Sch Elect & Informat, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Ji, Xiaodong] Nantong Res Inst Adv Commun Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Wenhua] Wenluo Corp Elect Sci & Technol Jiangsu, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
C3 Nantong University
RP Ji, XD (通讯作者)，Nantong Univ, Sch Elect & Informat, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.; Ji, XD (通讯作者)，Nantong Res Inst Adv Commun Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
EM jxd@ntu.edu.cn
FU National Natural Science Foundation of China [61401238, 61871241];
   Nantong UniversityNantong Joint Research Center for Intelligent
   Information Technology [KFKT2017A03]
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant Nos. 61401238 and 61871241) and by the
   Nantong UniversityNantong Joint Research Center for Intelligent
   Information Technology (Grant No. KFKT2017A03).
CR Barbosa D. J., 2008, 30 ANN INT C IEEE EN, P1102, DOI [10.1109/IEMBS.2008.4649837, DOI 10.1109/IEMBS.2008.4649837]
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   [邓江洪 Deng Jianghong], 2016, [吉林大学学报. 理学版, Journal of Jilin University. Science Edition], V54, P862
   Dongbo Weng, 2016, 2016 IEEE 8th International Power Electronics and Motion Control Conference (IPEMC-ECCE Asia), P1102, DOI 10.1109/IPEMC.2016.7512441
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fuzhen Zhu, 2013, 2013 International Conference on Optoelectronics and Microelectronics (ICOM), P62, DOI 10.1109/ICoOM.2013.6626491
   Ghosh T, 2018, J MED BIOL ENG, V38, P482, DOI 10.1007/s40846-017-0318-1
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   JAIN R, 2016, IEEE INT CONF RECENT, P1970, DOI DOI 10.1109/RTEICT.2016.7808181
   Mathew M., 2015, ICECS 2015, V1730, DOI [10.1109/ECS.2015.7124882, DOI 10.1109/ECS.2015.7124882]
   Saini S, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503272
   SUCIATI N, 2015, IEEE INT CONF CONTRO, P178, DOI DOI 10.1109/ICCSCE.2015.7482180
   Sudarvizhi D., 2016, INT C REC TRENDS INF, P1, DOI [10.1109/ICRTIT. 2016.7569541, DOI 10.1109/ICRTIT.2016.7569541]
   SUMAN S, IEEE INT CONF SIGNAL, P1, DOI DOI 10.1109/ICONSIP.2016.7857440
   Yu X, 2015, J QINGHAI U NATURAL, V33, P68, DOI [10.13901/j.cnki.qhwxxbzk.2015.01.014, DOI 10.13901/J.CNKI.QHWXXBZK.2015.01.014]
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
NR 16
TC 2
Z9 2
U1 0
U2 9
PU SPRINGEROPEN
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 1687-5176
EI 1687-5281
J9 EURASIP J IMAGE VIDE
JI EURASIP J. Image Video Process.
PD APR 23
PY 2019
AR 55
DI 10.1186/s13640-019-0461-4
PG 7
WC Engineering, Electrical & Electronic; Imaging Science & Photographic
   Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Imaging Science & Photographic Technology
GA HU9AT
UT WOS:000465585700001
OA gold
DA 2023-04-20
ER

PT J
AU Yang, YJ
   Bang, CS
AF Yang, Young Joo
   Bang, Chang Seok
TI Application of artificial intelligence in gastroenterology
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Artificial intelligence; Convolutional neural network; Deep-learning;
   Computer-assisted; Gastroenterology; Endoscopy
ID HELICOBACTER-PYLORI INFECTION; COMPUTER-AIDED DIAGNOSIS; CONVOLUTIONAL
   NEURAL-NETWORK; QUANTITATIVE-ANALYSIS; COLORECTAL LESIONS; CAPSULE
   ENDOSCOPY; LEARNING ALGORITHM; SYSTEM; CLASSIFICATION; POLYPS
AB Artificial intelligence (AI) using deep-learning (DL) has emerged as a breakthrough computer technology. By the era of big data, the accumulation of an enormous number of digital images and medical records drove the need for the utilization of AI to efficiently deal with these data, which have become fundamental resources for a machine to learn by itself. Among several DL models, the convolutional neural network showed outstanding performance in image analysis. In the field of gastroenterology, physicians handle large amounts of clinical data and various kinds of image devices such as endoscopy and ultrasound. AI has been applied in gastroenterology in terms of diagnosis, prognosis, and image analysis. However, potential inherent selection bias cannot be excluded in the form of retrospective study. Because overfitting and spectrum bias (class imbalance) have the possibility of overestimating the accuracy, external validation using unused datasets for model development, collected in a way that minimizes the spectrum bias, is mandatory. For robust verification, prospective studies with adequate inclusion/exclusion criteria, which represent the target populations, are needed. DL has its own lack of interpretability. Because interpretability is important in that it can provide safety measures, help to detect bias, and create social acceptance, further investigations should be performed.
C1 [Yang, Young Joo; Bang, Chang Seok] Hallym Univ, Coll Med, Dept Internal Med, Sakju Ro 77, Chunchon 24253, Gangwon Do, South Korea.
C3 Hallym University
RP Bang, CS (通讯作者)，Hallym Univ, Coll Med, Dept Internal Med, Sakju Ro 77, Chunchon 24253, Gangwon Do, South Korea.
EM csbang@hallym.ac.kr
RI Bang, Chang SEOK/I-9689-2019
OI Bang, Chang Seok/0000-0003-4908-5431; YANG, YOUNGJOO/0000-0001-6325-1104
CR Bae HJ, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36047-2
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bishop Bishop C., 2006, J ELECTRON IMAGING, V16, P140
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   England JR, 2019, AM J ROENTGENOL, V212, P513, DOI 10.2214/AJR.18.20490
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gatos I, 2017, ULTRASOUND MED BIOL, V43, P1797, DOI 10.1016/j.ultrasmedbio.2017.05.002
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hardalac F, 2015, TURK J GASTROENTEROL, V26, P315, DOI 10.5152/tjg.2015.0199
   Hastie T., 2009, ELEMENTS STAT LEARNI
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Ho Park， Seong, 2018, [Journal of the Korean Society of Radiology (JKSR), 대한영상의학회지], V78, P301, DOI 10.3348/jksr.2018.78.5.301
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Ichimasa K, 2018, ENDOSCOPY, V50, P230, DOI 10.1055/s-0043-122385
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   k Geetha, 2016, Asian Pac J Cancer Prev, V17, P4869
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kevin PM, 2012, MACHINE LEARNING PRO, P1
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kodashima S, 2007, DIGEST LIVER DIS, V39, P762, DOI 10.1016/j.dld.2007.03.004
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kuppili V, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0797-1
   Lahner E, 2005, WORLD J GASTROENTERO, V11, P5867, DOI 10.3748/wjg.v11.i37.5867
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Liu X, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010149
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   McCulloch W., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Pace F, 2005, EUR J GASTROEN HEPAT, V17, P605, DOI 10.1097/00042737-200506000-00003
   Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920
   Peng JC, 2015, INT J COLORECTAL DIS, V30, P1267, DOI 10.1007/s00384-015-2250-6
   Pofahl WE, 1998, AM SURGEON, V64, P868
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Rotondano G, 2011, GASTROINTEST ENDOSC, V73, P218, DOI 10.1016/j.gie.2010.10.006
   Russell S.J., 2009, ARTIF INTELL, P1
   Sato F, 2005, CANCER-AM CANCER SOC, V103, P1596, DOI 10.1002/cncr.20938
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin D, 2015, CLIN GASTROENTEROL H, V13, P272, DOI 10.1016/j.cgh.2014.07.030
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Takayama T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0131197
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Tavanaei A, 2019, NEURAL NETWORKS, V111, P47, DOI 10.1016/j.neunet.2018.12.002
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Turing AM., 1950, MIND, V59, P433
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Wang HF, 2015, PHYS MED BIOL, V60, P7207, DOI 10.1088/0031-9155/60/18/7207
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yang HX, 2013, BRIT J CANCER, V109, P1109, DOI 10.1038/bjc.2013.379
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 70
TC 93
Z9 95
U1 6
U2 45
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD APR 14
PY 2019
VL 25
IS 14
BP 1666
EP 1683
DI 10.3748/wjg.v25.i14.1666
PG 18
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HT2FX
UT WOS:000464379700003
PM 31011253
OA Green Published, hybrid, Green Submitted
DA 2023-04-20
ER

PT J
AU Chen, X
   Hu, YQ
   Zhang, ZH
   Wang, BZ
   Zhang, LC
   Shi, FJ
   Chen, XJ
   Jiang, XY
AF Chen, Xu
   Hu, Yiqun
   Zhang, Zhihong
   Wang, Beizhan
   Zhang, Lichi
   Shi, Fei
   Chen, Xinjian
   Jiang, Xiaoyi
TI A graph-based approach to automated EUS image layer segmentation and
   abnormal region detection
SO NEUROCOMPUTING
LA English
DT Article
DE EUS image; Layer segmentation; Abnormal region detection; Early
   carcinoma diagnosis
ID ENDOSCOPIC ULTRASOUND; MATHEMATICAL-MODELS; LYMPH-NODES; VALIDATION;
   ALGORITHMS; MALIGNANCY; BENIGN; CANCER; MASSES
AB Endoscopic ultrasonography (EUS) has shown great advantages in the diagnosis and staging of gastrointestinal malignant tumors. However, EUS based diagnosis is limited by variability in the examiner's subjective interpretation to differentiate between normal and early esophageal carcinoma. In this paper, we propose a novel approach aiming at automatic abnormal region detection from the esophageal EUS images; the contribution is three-fold: first, we present a series of preprocessing strategies developed specifically for the enhancement of EUS images to aid the estimation in the subsequent works. Second, we provide an automatic layer segmentation method based on the multiple surface graph searching approach with incorporation of geometric constraints, which is applied to segment the EUS images into five discernible layers. Third, we introduce the novel feature extraction strategy by utilizing the features from each column in the segmented layers. The SVM classifier is then applied to fulfill the normal and early esophageal carcinoma classification. Subsequently, a clustering method is used to assemble the abnormal columns together so as to detect the abnormal region. Experimental results show that our method has demonstrated its robustness even facing noisy EUS images, and has achieved high accuracy in detecting abnormal region. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Chen, Xu; Zhang, Zhihong; Wang, Beizhan] Xiamen Univ, Xiamen, Peoples R China.
   [Hu, Yiqun] Xiamen Univ, Zhongshan Hosp, Xiamen, Peoples R China.
   [Zhang, Lichi] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Shi, Fei; Chen, Xinjian] Soochow Univ, Suzhou, Peoples R China.
   [Jiang, Xiaoyi] Univ Munster, Munster, Germany.
C3 Xiamen University; Xiamen University; Shanghai Jiao Tong University;
   Soochow University - China; University of Munster
RP Zhang, ZH (通讯作者)，Xiamen Univ, Xiamen, Peoples R China.
EM zhihong@xmu.edu.cn
RI Jiang, Xiaoyi/AAA-3532-2022
OI Jiang, Xiaoyi/0000-0001-7678-9528; Chen, Xu/0000-0002-0367-3003; Chen,
   Xinjian/0000-0002-0871-293X
FU National Natural Science Foundation of China [61402389]; Fundamental
   Research Funds for the Central Universities [20720160073]; Health joint
   fund of the Provincial Department of Science and Technology [2015J01534]
FX This work is supported by National Natural Science Foundation of China
   (Grant No. 61402389), the Fundamental Research Funds for the Central
   Universities (No. 20720160073) and the Health joint fund of the
   Provincial Department of Science and Technology (No. 2015J01534). The
   first two authors contribute equally to this paper.
CR Biggs DSC, 1997, APPL OPTICS, V36, P1766, DOI 10.1364/AO.36.001766
   BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Cao JP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077922
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen XJ, 2012, IEEE T MED IMAGING, V31, P1521, DOI 10.1109/TMI.2012.2191302
   Choi J, 2010, SURG ENDOSC, V24, P1380, DOI 10.1007/s00464-009-0783-x
   Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036
   Dominguez AR, 2007, MED PHYS, V34, P4256, DOI 10.1118/1.2791034
   Ester M., 1996, PROC 2 ACM INT C KNO, V96, P226
   Fleagle S. R., 1994, P SOC PHOTO-OPT INS, V50, P23
   Gao  E., 2017, SPIE MED IMAGING
   Hussein S, 2017, IEEE T MED IMAGING, V36, P734, DOI 10.1109/TMI.2016.2636188
   Kolios MC, 2002, ULTRASOUND MED BIOL, V28, P589, DOI 10.1016/S0301-5629(02)00492-1
   Li K, 2006, IEEE T PATTERN ANAL, V28, P119, DOI 10.1109/TPAMI.2006.19
   Li K, 2004, PROC SPIE, V5370, P620, DOI 10.1117/12.537048
   Lieberman E. L. B., 2009, BRIT J CANCER, V101, P368
   Loren DE, 2002, GASTROINTEST ENDOSC, V56, P742, DOI 10.1067/mge.2002.128920
   Misra S, 2012, SURG ENDOSC, V26, P518, DOI 10.1007/s00464-011-1911-y
   Napier KJ, 2014, WORLD J GASTRO ONCOL, V6, P112, DOI 10.4251/wjgo.v6.i5.112
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644
   Olowe K, 2007, GASTROINTEST ENDOSC, V65, pAB194, DOI 10.1016/j.gie.2007.03.370
   Pech O, 2010, ENDOSCOPY, V42, P456, DOI 10.1055/s-0029-1244022
   Saftoiu A, 2008, GASTROINTEST ENDOSC, V68, P1086, DOI 10.1016/j.gie.2008.04.031
   Shi F, 2015, IEEE T MED IMAGING, V34, P441, DOI 10.1109/TMI.2014.2359980
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Sun CM, 2005, IEEE T PATTERN ANAL, V27, P1923, DOI 10.1109/TPAMI.2005.247
   Sun CM, 2003, PATTERN RECOGN, V36, P709, DOI 10.1016/S0031-3203(02)00085-7
   Timp S, 2004, MED PHYS, V31, P958, DOI 10.1118/1.1688039
   Torrence B. F., 2009, HDB PRECALCULUS CALC
   Van Holsbeke C, 2007, CLIN CANCER RES, V13, P4440, DOI 10.1158/1078-0432.CCR-06-2958
   Van Holsbeke C, 2009, CLIN CANCER RES, V15, P684, DOI 10.1158/1078-0432.CCR-08-0113
   Wang VS, 2009, GASTROINTEST ENDOSC, V69, P777, DOI 10.1016/j.gie.2008.05.013
   Yu K, 2016, PROC SPIE, V9784, DOI 10.1117/12.2216229
   Zhang  M., 2004, GASTROINTEST ENDOSC, V72, P978
   Zhang ZH, 2016, MULTIMED TOOLS APPL, V75, P3993, DOI 10.1007/s11042-015-3108-1
   Zhou Y, 2013, MED IMAGE ANAL, V17, P892, DOI 10.1016/j.media.2013.05.009
NR 38
TC 4
Z9 4
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD APR 7
PY 2019
VL 336
SI SI
BP 79
EP 91
DI 10.1016/j.neucom.2018.03.083
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HP0LX
UT WOS:000461358600009
DA 2023-04-20
ER

PT J
AU Ayling, RM
   Lewis, SJ
   Cotter, F
AF Ayling, Ruth M.
   Lewis, Stephen J.
   Cotter, Finbarr
TI Potential roles of artificial intelligence learning and faecal
   immunochemical testing for prioritisation of colonoscopy in anaemia
SO BRITISH JOURNAL OF HAEMATOLOGY
LA English
DT Article
DE iron deficiency; anaemia; colorectal carcinoma; faecal immunochemical
   test; AI learning
ID IRON-DEFICIENCY ANEMIA; PRIMARY-CARE; RISK
AB Iron deficiency anaemia (IDA) is the most common cause of anaemia and a frequent indication for colonoscopy, although the prevalence of colorectal cancer (CRC) in IDA is low. Measurement of faecal haemoglobin by immunochemical techniques (FIT) is used to detect symptomatic patients. We studied FIT in patients with anaemia attending a gastroenterology clinic in Plymouth and looked at an artificial intelligence (AI) learning algorithm (ColonFlag) in these patients, together with a cohort who had undergone colonoscopy for IDA in London. Of 592 patients referred on the basis of haemoglobin concentration, 21 (3.5%) had CRC. Using ColonFlag, rather than haemoglobin concentration, in combination with symptoms, would have resulted in prioritisation of 304 patients for urgent referral rather than 592. One CRC would have been missed but might have been detected by FIT, which was not available in this case. In patients aged <55years in whom the incidence of CRC is low, 15 rather than 109 patients would have been prioritised for urgent referral with no cancers missed. FIT has a high negative predictive value in IDA so its use may enable some patients to avoid investigation and AI learning may be a more useful trigger than haemoglobin concentration for urgent referral for colonoscopy.
C1 [Ayling, Ruth M.] Univ Hosp Plymouth NHS Trust, Barts Hlth NHS Trust, Dept Clin Biochem, London, England.
   [Lewis, Stephen J.] Univ Hosp Plymouth NHS Trust, Dept Gastroenterol, Plymouth, Devon, England.
   [Cotter, Finbarr] Univ Hosp Plymouth NHS Trust, Barts Hlth NHS Trust, Dept Haematooncol, London, England.
C3 Barts Health NHS Trust; Barts Health NHS Trust
RP Ayling, RM (通讯作者)，Royal London Hosp, Dept Clin Biochem, Newark St, London E1 2ES, England.
EM ruthayling@clinicalbiochemistry.org.uk
RI Ayling, Ruth/AAI-4886-2020
OI Ayling, Ruth/0000-0003-4662-2502
CR Cancer Research UK, 2015, BOW CANC STAT
   Cilona A, 2011, DIGEST LIVER DIS, V43, P1022, DOI 10.1016/j.dld.2011.08.002
   Department for Communities and Local Government, 2015, ENGL IND DEPR 2015
   Fisher DA, 2011, GASTROINTEST ENDOSC, V74, P745, DOI 10.1016/j.gie.2011.07.025
   Goddard AF, 2011, GUT, V60, P1309, DOI 10.1136/gut.2010.228874
   Hamilton W, 2013, BRIT J GEN PRACT, V63, DOI 10.3399/bjgp13X660751
   Hippisley-Cox J, 2012, BRIT J GEN PRACT, V62, DOI 10.3399/bjgp12X616346
   Hornbrook MC, 2017, DIGEST DIS SCI, V62, P2719, DOI 10.1007/s10620-017-4722-8
   James MW, 2005, EUR J GASTROEN HEPAT, V17, P1197, DOI 10.1097/00042737-200511000-00008
   Jellema P, 2010, BMJ-BRIT MED J, V340, DOI 10.1136/bmj.c1269
   Kim NH, 2017, YONSEI MED J, V58, P910, DOI 10.3349/ymj.2017.58.5.910
   Kinar Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171759
   Kinar Y, 2016, J AM MED INFORM ASSN, V23, P879, DOI 10.1093/jamia/ocv195
   Lee YJ, 2006, YONSEI MED J, V47, P646, DOI 10.3349/ymj.2006.47.5.646
   Lin MS, 2012, HEPATO-GASTROENTEROL, V59, P1687, DOI 10.5754/hge12277
   Mankodi S, 2010, CLIN MED, V10, P115, DOI 10.7861/clinmedicine.10-2-115
   Moss S, 2017, GUT, V66, P1631, DOI 10.1136/gutjnl-2015-310691
   Mowat C, 2016, GUT, V65, P1463, DOI 10.1136/gutjnl-2015-309579
   National Institute for Health and Care Excellence (NICE), 2015, NICE GUID
   NHS Improvement, 2017, NAT TAR PAYM SYST 20
   NICE,, 2017, DG30 NICE
   ROCKEY DC, 1993, NEW ENGL J MED, V329, P1691, DOI 10.1056/NEJM199312023292303
   Shaw AG, 2008, COLORECTAL DIS, V10, P294, DOI 10.1111/j.1463-1318.2007.01364.x
   Snook J, 2014, FRONTLINE GASTROENTE, V5, P229, DOI 10.1136/flgastro-2014-100435
   Spell D.W., 2004, CANC DETECTION PREVE, V14, P1534
   Westwood M, 2017, HEALTH TECHNOL ASSES, V21, P1, DOI 10.3310/hta21330
   WHO, 2015, GLOB PREV AN 2011
NR 27
TC 13
Z9 13
U1 2
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0007-1048
EI 1365-2141
J9 BRIT J HAEMATOL
JI Br. J. Haematol.
PD APR
PY 2019
VL 185
IS 2
BP 311
EP 316
DI 10.1111/bjh.15776
PG 6
WC Hematology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Hematology
GA HY2TG
UT WOS:000467975200014
PM 30714125
OA Bronze
DA 2023-04-20
ER

PT J
AU Blanes-Vidal, V
   Baatrup, G
   Nadimi, ES
AF Blanes-Vidal, Victoria
   Baatrup, Gunnar
   Nadimi, Esmaeil S.
TI Addressing priority challenges in the detection and assessment of
   colorectal polyps from capsule endoscopy and colonoscopy in colorectal
   cancer screening using machine learning
SO ACTA ONCOLOGICA
LA English
DT Article
ID COLON CAPSULE; SIZE; MULTICENTER; SOCIETY
AB Background: Colorectal capsule endoscopy (CCE) is a potentially valuable patient-friendly technique for colorectal cancer screening in large populations. Before it can be widely applied, significant research priorities need to be addressed. We present two innovative data science algorithms which can considerably improve acquisition and analysis of relevant data on colorectal polyps obtained from capsule endoscopy. Material and methods: A fully paired study was performed (2015-2016), where 255 participants from the Danish national screening program had CCE, colonoscopy, and histopathology of all detected polyps. We developed: (1) a new algorithm to match CCE and colonoscopy polyps, based on objective measures of similarity between polyps, and (2) a deep convolutional neural network (CNN) for autonomous detection and localization of colorectal polyps in colon capsule endoscopy. Results and conclusion: Unlike previous matching methods, our matching algorithm is able to objectively quantify the similarity between CCE and colonoscopy polyps based on their size, morphology and location, and provides a one-to-one unequivocal match between CCE and colonoscopy polyps. Compared to previous methods, the autonomous detection algorithm showed unprecedented high accuracy (96.4%), sensitivity (97.1%) and specificity (93.3%), calculated in respect to the number of polyps detected by trained nurses and gastroenterologists after visualizing frame-by-frame the CCE videos.
C1 [Blanes-Vidal, Victoria; Nadimi, Esmaeil S.] Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Campusvej 55, DK-5230 Odense, Denmark.
   [Baatrup, Gunnar] Odense Univ Hosp, Dept Surg, Svendborg, Denmark.
   [Baatrup, Gunnar] Univ Southern Denmark, Dept Clin Res, Odense, Denmark.
C3 University of Southern Denmark; University of Southern Denmark; Odense
   University Hospital; University of Southern Denmark
RP Blanes-Vidal, V (通讯作者)，Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Campusvej 55, DK-5230 Odense, Denmark.
EM vbv@mmmi.sdu.dk
RI ; Blanes-Vidal, Victoria/B-5196-2019; Nadimi, Esmaeil/B-5289-2019
OI baatrup, gunnar/0000-0003-0300-5766; Blanes-Vidal,
   Victoria/0000-0002-9269-4526; Nadimi, Esmaeil/0000-0003-2613-2696
FU Research Foundation of the Health Care Region of Southern Denmark;
   Kraeftens Bekaempelse, Odense Universitets hospital and Syddansk
   Universitet
FX The study was financially supported by the Research Foundation of the
   Health Care Region of Southern Denmark, Kraeftens Bekaempelse, Odense
   Universitets hospital and Syddansk Universitet.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Allen JE, 2017, BEST PRACT RES CL GA, V31, P435, DOI 10.1016/j.bpg.2017.07.001
   Eliakim R, 2006, ENDOSCOPY, V38, P963, DOI 10.1055/s-2006-944832
   Eliakim R, 2009, ENDOSCOPY, V41, P1026, DOI 10.1055/s-0029-1215360
   Gopalswamy N, 1997, GASTROINTEST ENDOSC, V46, P497, DOI 10.1016/S0016-5107(97)70003-8
   GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kobaek-Larsen M, 2018, COLORECTAL DIS, V20, P479, DOI 10.1111/codi.13965
   Morales TG, 1996, GASTROINTEST ENDOSC, V43, P25
   Moug SJ, 2010, COLORECTAL DIS, V12, P646, DOI 10.1111/j.1463-1318.2009.01870.x
   Pilz JB, 2010, BMC GASTROENTEROL, V10, DOI 10.1186/1471-230X-10-66
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2015, GASTROENTEROLOGY, V148, P948, DOI 10.1053/j.gastro.2015.01.025
   Schoen RE, 1997, GASTROINTEST ENDOSC, V46, P492, DOI 10.1016/S0016-5107(97)70002-6
   Simonyan K, 2015, Arxiv
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Spada C, 2015, GUT, V64, P272, DOI 10.1136/gutjnl-2013-306550
   Spada C, 2011, GASTROINTEST ENDOSC, V74, P581, DOI 10.1016/j.gie.2011.03.1125
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   van Heijningen EMB, 2013, GASTROENTEROLOGY, V144, P1410, DOI 10.1053/j.gastro.2013.03.002
NR 20
TC 41
Z9 44
U1 4
U2 6
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0284-186X
EI 1651-226X
J9 ACTA ONCOL
JI Acta Oncol.
PD APR 1
PY 2019
VL 58
SU 1
SI SI
BP S29
EP S36
DI 10.1080/0284186X.2019.1584404
PG 8
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA HS5SB
UT WOS:000463930200006
PM 30836800
OA Bronze
DA 2023-04-20
ER

PT J
AU Ghatwary, N
   Zolgharni, M
   Ye, XJ
AF Ghatwary, Noha
   Zolgharni, Massoud
   Ye, Xujiong
TI Early esophageal adenocarcinoma detection using deep learning methods
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Deep learning; Esophageal adenocarcinoma detection; Barrett's esophagus;
   HD-WLE
ID BARRETTS-ESOPHAGUS; DIAGNOSIS; IMAGES
AB PurposeThis study aims to adapt and evaluate the performance of different state-of-the-art deep learning object detection methods to automatically identify esophageal adenocarcinoma (EAC) regions from high-definition white light endoscopy (HD-WLE) images.MethodSeveral state-of-the-art object detection methods using Convolutional Neural Networks (CNNs) were adapted to automatically detect abnormal regions in the esophagus HD-WLE images, utilizing VGG'16 as the backbone architecture for feature extraction. Those methods are Regional-based Convolutional Neural Network (R-CNN), Fast R-CNN, Faster R-CNN and Single-Shot Multibox Detector (SSD). For the evaluation of the different methods, 100 images from 39 patients that have been manually annotated by five experienced clinicians as ground truth have been tested.ResultsExperimental results illustrate that the SSD and Faster R-CNN networks show promising results, and the SSD outperforms other methods achieving a sensitivity of 0.96, specificity of 0.92 and F-measure of 0.94. Additionally, the Average Recall Rate of the Faster R-CNN in locating the EAC region accurately is 0.83.ConclusionIn this paper, recent deep learning object detection methods are adapted to detect esophageal abnormalities automatically. The evaluation of the methods proved its ability to locate abnormal regions in the esophagus from endoscopic images. The automatic detection is a crucial step that may help early detection and treatment of EAC and also can improve automatic tumor segmentation to monitor its growth and treatment outcome.
C1 [Ghatwary, Noha; Zolgharni, Massoud; Ye, Xujiong] Univ Lincoln, Lincoln, England.
   [Ghatwary, Noha] Arab Acad Sci & Technol, Alexandria, Egypt.
C3 University of Lincoln; Egyptian Knowledge Bank (EKB); Arab Academy for
   Science, Technology & Maritime Transport
RP Ghatwary, N (通讯作者)，Univ Lincoln, Lincoln, England.; Ghatwary, N (通讯作者)，Arab Acad Sci & Technol, Alexandria, Egypt.
EM nghatwary@lincoln.ac.uk; mzolgharni@lincoln.ac.uk; xye@lincoln.ac.uk
RI Zolgharni, Massoud/W-4774-2019
OI Zolgharni, Massoud/0000-0003-0904-2904; ye, xujiong/0000-0003-0115-0724
CR Antipov G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1263, DOI 10.1145/2733373.2806332
   Behrens A, 2011, DTSCH ARZTEBL INT, V108, P313, DOI 10.3238/arztebl.2011.0313
   de Souza LA, 2018, COMPUT BIOL MED, V96, P203, DOI 10.1016/j.compbiomed.2018.03.014
   Ghatwary N, 2017, COMM COM INF SC, V723, P897, DOI 10.1007/978-3-319-60964-5_78
   Ghatwary N, 2017, PROC SPIE, V10134, DOI 10.1117/12.2250364
   Girshick R., FAST R CNN, P1440
   Girshick R., 2013, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Janse MHA, 2015, PROC SPIE, V9785, DOI 10.1117/12.2208583
   Jiang Y, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.2.024502
   Juefei-Xu F, 2017, 2017 IEEE C COMP VIS, V1
   Li W., 2016, ARXIV160705066
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mendel R., 2017, BILDVERARBEITUNG MED, P80
   Mnih, 2013, P NIPS DEEP LEARN WO, DOI DOI 10.1038/NATURE14236
   Old OJ, 2017, ANALYST, V142, P1227, DOI 10.1039/c6an01871h
   Papa J.a.P., 2017, BILDVERARBEITUNG F R, P141, DOI [10.1007/978-3-662-54345-0, DOI 10.1007/978-3-662-54345-0]
   Qi X, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2337314
   Rajendra S, 2017, HEMATOL ONCOL CLIN N, V31, P409, DOI 10.1016/j.hoc.2017.01.003
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Setio A. A., 2013, PROC VISAPP, V1, P238
   Shen HY, 2016, INT CONF CLOUD COMP, P1, DOI [10.1109/CloudCom.2016.0017, 10.1109/CloudCom.2016.14]
   Simonyan K, 2015, Arxiv
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   Trovato C, 2013, DIGEST LIVER DIS, V45, P396, DOI 10.1016/j.dld.2012.12.016
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   van der Sommen F, 2013, PROC SPIE, V8670, DOI 10.1117/12.2001068
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Xian M, 2015, PATTERN RECOGN, V48, P485, DOI 10.1016/j.patcog.2014.07.026
NR 31
TC 40
Z9 41
U1 2
U2 15
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD APR
PY 2019
VL 14
IS 4
BP 611
EP 621
DI 10.1007/s11548-019-01914-4
PG 11
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA HP0IN
UT WOS:000461349600005
PM 30666547
OA Green Accepted, Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Kumagai, Y
   Takubo, K
   Kawada, K
   Aoyama, K
   Endo, Y
   Ozawa, T
   Hirasawa, T
   Yoshio, T
   Ishihara, S
   Fujishiro, M
   Tamaru, J
   Mochiki, E
   Ishida, H
   Tada, T
AF Kumagai, Youichi
   Takubo, Kaiyo
   Kawada, Kenro
   Aoyama, Kazuharu
   Endo, Yuma
   Ozawa, Tsuyoshi
   Hirasawa, Toshiaki
   Yoshio, Toshiyuki
   Ishihara, Soichiro
   Fujishiro, Mitsuhiro
   Tamaru, Jun-ichi
   Mochiki, Erito
   Ishida, Hideyuki
   Tada, Tomohiro
TI Diagnosis using deep-learning artificial intelligence based on the
   endocytoscopic observation of the esophagus
SO ESOPHAGUS
LA English
DT Article
DE Artificial intelligence; Deep learning; Convolutional neural network;
   Endocytoscopy system; Esophagus
ID NEWLY DEVELOPED ENDOCYTOSCOPE; COLORECTAL LESIONS; CLASSIFICATION;
   HISTOLOGY; CANCER
AB Background and aimsThe endocytoscopic system (ECS) helps in virtual realization of histology and can aid in confirming histological diagnosis in vivo. We propose replacing biopsy-based histology for esophageal squamous cell carcinoma (ESCC) by using the ECS. We applied deep-learning artificial intelligence (AI) to analyse ECS images of the esophagus to determine whether AI can support endoscopists for the replacement of biopsy-based histology.MethodsA convolutional neural network-based AI was constructed based on GoogLeNet and trained using 4715 ECS images of the esophagus (1141 malignant and 3574 non-malignant images). To evaluate the diagnostic accuracy of the AI, an independent test set of 1520 ECS images, collected from 55 consecutive patients (27 ESCCs and 28 benign esophageal lesions) were examined.ResultsOn the basis of the receiver-operating characteristic curve analysis, the areas under the curve of the total images, higher magnification pictures, and lower magnification pictures were 0.85, 0.90, and 0.72, respectively. The AI correctly diagnosed 25 of the 27 ESCC cases, with an overall sensitivity of 92.6%. Twenty-five of the 28 non-cancerous lesions were diagnosed as non-malignant, with a specificity of 89.3% and an overall accuracy of 90.9%. Two cases of malignant lesions, misdiagnosed as non-malignant by the AI, were correctly diagnosed as malignant by the endoscopist. Among the 3 cases of non-cancerous lesions diagnosed as malignant by the AI, 2 were of radiation-related esophagitis and one was of gastroesophageal reflux disease.ConclusionAI is expected to support endoscopists in diagnosing ESCC based on ECS images without biopsy-based histological reference.
C1 [Kumagai, Youichi; Mochiki, Erito; Ishida, Hideyuki] Saitama Med Univ, Saitama Med Ctr, Dept Digest Tract & Gen Surg, 1981 Kamoda, Kawagoe, Saitama 3508550, Japan.
   [Takubo, Kaiyo] Tokyo Metropolitan Inst Gerontol, Res Team Geriatr Pathol, Tokyo, Japan.
   [Kawada, Kenro] Tokyo Med & Dent Univ, Dept Esophageal & Gen Surg, Tokyo, Japan.
   [Aoyama, Kazuharu; Endo, Yuma; Tada, Tomohiro] AI Med Serv Inc, Tokyo, Japan.
   [Ozawa, Tsuyoshi] Teikyo Univ Hosp, Dept Surg, Tokyo, Japan.
   [Ozawa, Tsuyoshi; Hirasawa, Toshiaki; Yoshio, Toshiyuki; Ishihara, Soichiro; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
   [Hirasawa, Toshiaki; Yoshio, Toshiyuki] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Gastroenterol, Tokyo, Japan.
   [Ishihara, Soichiro] Int Univ Hlth & Welf, Sanno Hosp, Surg Dept, Tokyo, Japan.
   [Fujishiro, Mitsuhiro] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Tamaru, Jun-ichi] Saitama Med Univ, Saitama Med Ctr, Dept Pathol, Saitama, Japan.
C3 Saitama Medical University; Tokyo Metropolitan Institute of Gerontology;
   Tokyo Medical & Dental University (TMDU); Teikyo University; Japanese
   Foundation for Cancer Research; International University of Health &
   Welfare; University of Tokyo; Saitama Medical University
RP Kumagai, Y (通讯作者)，Saitama Med Univ, Saitama Med Ctr, Dept Digest Tract & Gen Surg, 1981 Kamoda, Kawagoe, Saitama 3508550, Japan.
EM kuma7srg1@gmail.com
RI Ishihara, Soichiro/AFK-1375-2022; Yoshio, Toshiyuki/ABC-4723-2021; 藤城,
   光弘/AAN-3131-2020
OI Yoshio, Toshiyuki/0000-0002-6546-0329; Fujishiro,
   Mitsuhiro/0000-0002-4074-1140; Hirasawa, Toshiaki/0000-0002-6450-1934
CR Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Inoue Haruhiro, 2004, Gastrointest Endosc Clin N Am, V14, P589, DOI 10.1016/j.giec.2004.03.013
   Kumagai Y, 2015, DIS ESOPHAGUS, V28, P269, DOI 10.1111/dote.12183
   Kumagai Y, 2004, ENDOSCOPY, V36, P590, DOI 10.1055/s-2004-814533
   Kumagai Y, 2010, DIS ESOPHAGUS, V23, P627, DOI 10.1111/j.1442-2050.2010.01074.x
   Kumagai Y, 2009, DIS ESOPHAGUS, V22, P505, DOI 10.1111/j.1442-2050.2009.00952.x
   Kumagai Y, 2017, ENDOSCOPY, V49, P176, DOI 10.1055/s-0042-119267
   Kumagai Y, 2016, ESOPHAGUS-TOKYO, V13, P200, DOI 10.1007/s10388-015-0517-1
   Kumagai Y, 2012, J DIGEST DIS, V13, P393, DOI 10.1111/j.1751-2980.2012.00612.x
   Kumagai Y, 2010, DIGEST ENDOSC, V22, P10, DOI 10.1111/j.1443-1661.2009.00931.x
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Sasajima K, 2006, GASTROINTEST ENDOSC, V63, P1010, DOI 10.1016/j.gie.2006.01.021
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Takubo K., 2017, PATHOLOGY ESOPHAGUS, P88
   Yoshida H, 2018, GASTRIC CANCER, V21, P249, DOI 10.1007/s10120-017-0731-8
NR 19
TC 51
Z9 60
U1 2
U2 23
PU SPRINGER JAPAN KK
PI TOKYO
PA CHIYODA FIRST BLDG EAST, 3-8-1 NISHI-KANDA, CHIYODA-KU, TOKYO, 101-0065,
   JAPAN
SN 1612-9059
EI 1612-9067
J9 ESOPHAGUS-TOKYO
JI Esophagus
PD APR
PY 2019
VL 16
IS 2
BP 180
EP 187
DI 10.1007/s10388-018-0651-7
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HR1WL
UT WOS:000462926700009
PM 30547352
DA 2023-04-20
ER

PT J
AU Li, XG
   Cao, L
   Tiong, AMH
   Phan, PT
   Phee, SJ
AF Li, Xiaoguo
   Cao, Lin
   Tiong, Anthony Meng Huat
   Phuoc Thien Phan
   Phee, Soo Jay
TI Distal-end force prediction of tendon-sheath mechanisms for flexible
   endoscopic surgical robots using deep learning
SO MECHANISM AND MACHINE THEORY
LA English
DT Article
DE Haptic feedback; Surgical robot; Tendon sheath mechanisms; Deep
   learning; Hysteresis
ID MINIMALLY INVASIVE SURGERY; HAPTIC FEEDBACK; FRICTION MODEL; HYSTERESIS;
   ELONGATION; SENSOR
AB Accurate haptic feedback is highly challenging for flexible endoscopic surgical robots due to space limitation for sensors on small end-effectors and critical force hysteresis of their tendon-sheath mechanisms (TSMs). This paper proposes a deep learning approach to predicting the distal force of TSMs when manipulating a biological tissue based on only proximal-end measurements. Both Multilayer Perceptron (MLP) and Recurrent Neural Network (RNN) were investigated to study their capabilities of making sequential distal force predictions. The results were compared with those of the conventional modelling approach. It was observed that, when sufficient data was provided for training, RNN achieved the most accurate prediction (RMSE = 0.0219 N) in experiments with constant system velocity. The effects of insufficient training data, varying system velocity and irregular motion trajectories on the performance of RNN were further studied. Notably, RNN could precisely identify the current system phase in the force hysteresis profile and can be applied to TSMs with realistic non-periodic movement such as manual manipulation trajectory (RSME = 0.2287 N). The proposed approach can be applied to any TSM-driven robotic systems for accurate haptic feedback without requiring sensors at the distal ends of the robots. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Li, Xiaoguo; Cao, Lin; Tiong, Anthony Meng Huat; Phuoc Thien Phan; Phee, Soo Jay] Nanyang Technol Univ, Robot Res Ctr, Sch Mech & Aerosp Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University
RP Cao, L (通讯作者)，Nanyang Technol Univ, Robot Res Ctr, Sch Mech & Aerosp Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM lin.cao@usask.ca
OI CAO, LIN/0000-0003-4769-775X
FU National Research Foundation (NRF) Singapore [NRFI2016-07]
FX Research supported by the National Research Foundation (NRF) Singapore
   (NRFI2016-07).
CR Akinbiyi Takintope, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P567
   Al-Bender F, 2005, WEAR, V258, P1630, DOI 10.1016/j.wear.2004.11.018
   Al-Bender F, 2004, INT J NONLINEAR MECH, V39, P1721, DOI 10.1016/j.ijnonlinmec.2004.04.005
   ARMSTRONGHELOUVRY B, 1994, AUTOMATICA, V30, P1083, DOI 10.1016/0005-1098(94)90209-7
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Dinh BK, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5670, DOI 10.1109/IROS.2016.7759834
   Calinon S, 2014, COMPUT METH PROG BIO, V116, P81, DOI 10.1016/j.cmpb.2013.12.015
   Connor J., 1991, IJCNN-91-Seattle: International Joint Conference on Neural Networks (Cat. No.91CH3049-4), P301, DOI 10.1109/IJCNN.1991.155194
   Do TN, 2015, MECH SYST SIGNAL PR, V60-61, P770, DOI 10.1016/j.ymssp.2015.01.001
   Do TN, 2015, MECH MACH THEORY, V85, P14, DOI 10.1016/j.mechmachtheory.2014.11.003
   Do TN, 2014, MECHATRONICS, V24, P12, DOI 10.1016/j.mechatronics.2013.11.003
   Do TN, 2014, MECH SYST SIGNAL PR, V42, P97, DOI 10.1016/j.ymssp.2013.08.014
   Ehrampoosh S, 2013, COMPUT AIDED SURG, V18, P129, DOI 10.3109/10929088.2013.839744
   Gers Felix A, 1999, LEARNING FORGET CONT
   Hamad GG, 2010, AM J SURG, V199, P263, DOI 10.1016/j.amjsurg.2009.05.008
   Hayward V., 2004, Sensor Review, V24, P16, DOI 10.1108/02602280410515770
   Hochreiter S., 2001, FIELD GUIDE DYNAMICA
   HOWE RD, 1995, IEEE ENG MED BIOL, V14, P318, DOI 10.1109/51.391770
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   KANEKO M, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1028, DOI 10.1109/ROBOT.1991.131727
   Kassahun Y, 2016, INT J COMPUT ASS RAD, V11, P553, DOI 10.1007/s11548-015-1305-z
   King DB, 2015, ACS SYM SER, V1214, P1
   Lai W., 2018, IEEE INT C ROB AUT I
   Lampaert V, 2002, IEEE T AUTOMAT CONTR, V47, P683, DOI 10.1109/9.995050
   Mayer H, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P543, DOI 10.1109/IROS.2006.282190
   Murtagh F., 1991, NEUROCOMPUTING, V2, P183, DOI [DOI 10.1016/0925-2312(91)90023-5, 10.1016/0925-2312(91)90023-5]
   Nho D. D. T., 2014, THESIS
   OHTSUKA T, 1995, ANN THORAC SURG, V60, P610, DOI 10.1016/0003-4975(95)00483-2
   Okamura AM, 2009, CURR OPIN UROL, V19, P102, DOI 10.1097/MOU.0b013e32831a478c
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Phee SJ, 2010, ROBOTICA, V28, P1073, DOI 10.1017/S026357470999083X
   Phee SJ, 2009, IEEE ENG MED BIO, P1192, DOI 10.1109/IEMBS.2009.5333413
   Piatkowski T, 2014, MECH MACH THEORY, V73, P91, DOI 10.1016/j.mechmachtheory.2013.10.009
   Reiley CE, 2010, IEEE ENG MED BIO, P967, DOI 10.1109/IEMBS.2010.5627594
   Rosen J, 1999, IEEE T BIO-MED ENG, V46, P1212, DOI 10.1109/10.790498
   Sun ZL, 2014, IEEE-ASME T MECH, V19, P1243, DOI 10.1109/TMECH.2013.2278613
   Tadano K, 2010, ADV ROBOTICS, V24, P1763, DOI 10.1163/016918610X522559
   Tavakoli M, 2006, SURG ENDOSC, V20, P1570, DOI 10.1007/s00464-005-0582-y
   Tholey G., 2004, DESIGN DEV TESTING A, P38
   Valdastri P, 2006, IEEE T BIO-MED ENG, V53, P2397, DOI 10.1109/TBME.2006.883618
   Wang Z, 2013, COMPUT METH PROG BIO, V112, P260, DOI 10.1016/j.cmpb.2013.01.018
   Xu W., 2016, INT J MED ROB COMPUT
NR 42
TC 37
Z9 40
U1 9
U2 75
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0094-114X
J9 MECH MACH THEORY
JI Mech. Mach. Theory
PD APR
PY 2019
VL 134
BP 323
EP 337
DI 10.1016/j.mechmachtheory.2018.12.035
PG 15
WC Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA HK2MU
UT WOS:000457747100018
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Lin, JY
   Walsted, ES
   Backer, V
   Hull, JH
   Elson, DS
AF Lin, Jianyu
   Walsted, Emil S.
   Backer, Vibeke
   Hull, James H.
   Elson, Daniel S.
TI Quantification and Analysis of Laryngeal Closure From Endoscopic Videos
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Laryngeal obstruction; convolutional neural networks; detection;
   segmentation; singular spectrum analysis
ID EXERCISE; OBSTRUCTION; PREVALENCE; EXTRACTION
AB Objective: At present, there are no objective techniques to quantify and describe laryngeal obstruction, and the reproducibility of subjective manual quantification methods is insufficient, resulting in diagnostic inaccuracy and a poor signal-to-noise ratio in medical research. In this work, a workflow is proposed to quantify laryngeal movements from laryngoscopic videos, to facilitate the diagnosis procedure. Methods: The proposed method analyses laryngoscopic videos, and delineates glottic opening, vocal folds, and supraglottic structures, using a convolutional neural networks (CNNs) based algorithm. The segmentation is divided into two steps: A bounding box which indicates the region of interest (Rol) is found, followed by segmentation using fully convolutional networks (FCNs). The segmentation results are statistically quantified along the temporal dimension and processed using singular spectrum analysis (SSA), to extract clear objective information that can be used by the clinicians in diagnosis. Results: The segmentation was validated on 400 images from 20 videos acquired using different endoscopic systems from different patients. The results indicated significant improvements over using FCN only in terms of both processing speed (16 FPS vs. 8 FPS) and segmentation result statistics. Five clinical cases on patients have also been provided to showcase the quantitative analysis results using the proposed method. Conclusion: The proposed method guarantees a robust and fast processing of laryngoscopic videos. Measurements of glottic angles and supraglottic index showed distinctive patterns in the provided clinical cases. Significance: The proposed automated and objective method extracts important temporal laryngeal movement information, which can be used to aid laryngeal closure diagnosis.
C1 [Lin, Jianyu; Elson, Daniel S.] Imperial Coll London, Hamlyn Ctr Robot Surg, London SW7 2AZ, England.
   [Lin, Jianyu] Imperial Coll London, Dept Comp, London SW7 2AZ, England.
   [Walsted, Emil S.; Backer, Vibeke] Bispebjerg Hosp, Resp Res Unit, Copenhagen, Denmark.
   [Walsted, Emil S.; Hull, James H.] Royal Brompton Hosp, Resp Dept, London, England.
   [Backer, Vibeke] Univ Copenhagen, Dept Clin Med, Copenhagen, Denmark.
   [Elson, Daniel S.] Imperial Coll London, Dept Surg & Canc, London, England.
C3 Imperial College London; Imperial College London; University of
   Copenhagen; Bispebjerg Hospital; Royal Brompton Hospital; University of
   Copenhagen; Imperial College London
RP Lin, JY (通讯作者)，Imperial Coll London, Hamlyn Ctr Robot Surg, London SW7 2AZ, England.; Lin, JY (通讯作者)，Imperial Coll London, Dept Comp, London SW7 2AZ, England.
EM xjtuljy@gmail.com
RI Backer, Vibeke/AAQ-9379-2021; Elson, Daniel/B-4921-2008
OI Lin, Jianyu/0000-0003-2801-7616; Elson, Daniel/0000-0002-5578-3941;
   Walsted, Emil/0000-0002-6640-7175
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Alexandrov T, 2009, REVSTAT-STAT J, V7, P1
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baz M, 2015, THORAX, V70, P251, DOI 10.1136/thoraxjnl-2014-205940
   Christensen P, 2010, EUR ARCH OTO-RHINO-L, V267, P401, DOI 10.1007/s00405-009-1113-6
   Christensen PM, 2011, EUR ARCH OTO-RHINO-L, V268, P1313, DOI 10.1007/s00405-011-1612-0
   Du XF, 2018, IEEE T MED IMAGING, V37, P1276, DOI 10.1109/TMI.2017.2787672
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Ghaderi F, 2011, IEEE T BIO-MED ENG, V58, P3360, DOI 10.1109/TBME.2011.2162728
   Gibson  E., 2017, SPIE MED IMAG
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Golyandina N., 2001, ANAL TIME SERIES STR
   Halvorsen  T., 2017, EUR RESPIR J, V50, P945
   He K, 2017, ARXIV170306870
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hull JH, 2016, AM J RESP CRIT CARE, V194, P1062, DOI 10.1164/rccm.201606-1249CI
   Kendall M. G., 1979, ADV THEORY STAT
   Lin T Y, 2017, ARXIV170802002, DOI DOI 10.1109/ICCV.2017.324
   Liyanagedara S, 2017, EUR ARCH OTO-RHINO-L, V274, P1781, DOI 10.1007/s00405-016-4338-1
   Lohscheller J, 2007, MED IMAGE ANAL, V11, P400, DOI 10.1016/j.media.2007.04.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maat RC, 2009, EUR ARCH OTO-RHINO-L, V266, P1929, DOI 10.1007/s00405-009-1030-8
   Mehlum CS, 2016, EUR ARCH OTO-RHINO-L, V273, P945, DOI 10.1007/s00405-015-3823-2
   Nielsen EW, 2013, MED SCI SPORT EXER, V45, P2030, DOI 10.1249/MSS.0b013e318298b19a
   Olin JT, 2014, LARYNGOSCOPE, V124, P2568, DOI 10.1002/lary.24812
   Olin JT, 2016, EUR RESP J
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanei S, 2012, IEEE T BIO-MED ENG, V59, P428, DOI 10.1109/TBME.2011.2173936
   Sermanet P., 2014, 2 INT C LEARNING REP
   Simonyan K, 2015, Arxiv
   Walsted ES, 2018, J APPL PHYSIOL, V124, P356, DOI 10.1152/japplphysiol.00691.2017
   Walsted Emil Schwarz, 2017, ERJ Open Res, V3, DOI 10.1183/23120541.00070-2017
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang Y, 2010, J VOICE, V24, P21, DOI 10.1016/j.jvoice.2008.03.003
NR 37
TC 17
Z9 17
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD APR
PY 2019
VL 66
IS 4
BP 1127
EP 1136
DI 10.1109/TBME.2018.2867636
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA HQ4EP
UT WOS:000462363300022
PM 30176579
DA 2023-04-20
ER

PT J
AU Lui, TKL
   Wong, KKY
   Mak, LLY
   Ko, MKL
   Tsao, SKK
   Leung, WK
AF Lui, Thomas K. L.
   Wong, Kenneth K. Y.
   Mak, Loey L. Y.
   Ko, Michael K. L.
   Tsao, Stephen K. K.
   Leung, Wai K.
TI Endoscopic prediction of deeply submucosal invasive carcinoma with use
   of artificial intelligence
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID PIT PATTERN; DIAGNOSIS
AB Background and study aims We evaluated use of artificial intelligence (AI) assisted image classifier in determining the feasibility of curative endoscopic resection of large colonic lesion based on non-magnified endoscopic images
   Methods AI image classifier was trained by 8,000 endoscopic images of large (2cm) colonic lesions. The independent validation set consisted of 567 endoscopic images from 76 colonic lesions. Histology of the resected specimens was used as gold standard. Curative endoscopic resection was defined as histology no more advanced than well-differentiated adenocarcinoma, 1mm submucosal invasion and without lymphovascular invasion, whereas non-curative resection was defined as any lesion that could not meet the above requirements. Performance of the trained AI image classifier was compared with that of endoscopists.
   Results In predicting endoscopic curative resection, AI had an overall accuracy of 85.5%. Images from narrow band imaging (NBI) had significantly higher accuracy (94.3% vs 76.0%; P <0.00001) and area under the ROC curve (AUROC) (0.934 vs 0.758; P =0.002) than images from white light imaging (WLI). AI was superior to two junior endoscopists in terms of accuracy (85.5% vs 61.9% or 82.0%, P <0.05), AUROC (0.837 vs 0.638 or 0.717, P <0.05) and confidence level (90.1% vs 83.7% or 78.3%, P <0.05). However, there was no statistical difference in accuracy and AUROC between AI and a senior endoscopist.
   Conclusions The trained AI image classifier based on non-magnified images can accurately predict probability of curative resection of large colonic lesions and is better than junior endoscopists. NBI images have better accuracy than WLI for AI prediction.
C1 [Mak, Loey L. Y.; Ko, Michael K. L.; Leung, Wai K.] Univ Hong Kong, Queen Mary Hosp, Dept Med, Hong Kong, Peoples R China.
   [Wong, Kenneth K. Y.] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Tsao, Stephen K. K.] Tan Tock Seng Hosp, Dept Gastroenterol, Singapore, Singapore.
C3 University of Hong Kong; University of Hong Kong; Tan Tock Seng Hospital
RP Leung, WK (通讯作者)，Univ Hong Kong, Queen Mary Hosp, Dept Med, Hong Kong, Peoples R China.
EM waikleung@hku.hk
RI Leung, Wai Keung/B-8140-2011; Wong, Kenneth Kwan Yee/C-1577-2009
OI Leung, Wai Keung/0000-0002-5993-1059; Wong, Kenneth Kwan
   Yee/0000-0001-8560-9007; Lui, Ka Luen, Thomas/0000-0002-2986-3681
CR Backes Y, 2017, AM J GASTROENTEROL, V112, P54, DOI 10.1038/ajg.2016.403
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Hayashi N, 2013, DIGESTION, V87, P53, DOI 10.1159/000343940
   Higashi R, 2010, GASTROINTEST ENDOSC, V72, P127, DOI 10.1016/j.gie.2010.01.054
   Kanao H, 2009, GASTROINTEST ENDOSC, V69, P631, DOI 10.1016/j.gie.2008.08.028
   Lee SP, 2015, J GASTROEN HEPATOL, V30, P872, DOI 10.1111/jgh.12886
   Matsuda T, 2011, TECH GASTROINTEST EN, V13, P24, DOI 10.1016/j.tgie.2011.01.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Oba S, 2010, SCAND J GASTROENTERO, V45, P1084, DOI 10.3109/00365521003734166
   Patrun J, 2018, GASTROENT RES PRACT, V2018, DOI 10.1155/2018/7531368
   Pimentel-Nunes P, 2015, ENDOSCOPY, V47, P829, DOI 10.1055/s-0034-1392882
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Tanaka S, 2015, DIGEST ENDOSC, V27, P417, DOI 10.1111/den.12456
   Zhang QW, 2017, ENDOSCOPY, V49, P564, DOI 10.1055/s-0043-103014
NR 17
TC 27
Z9 27
U1 0
U2 10
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD APR
PY 2019
VL 7
IS 4
BP E514
EP E520
DI 10.1055/a-0849-9548
PG 7
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA HT4KJ
UT WOS:000464532200004
PM 31041367
OA Green Submitted, Green Published, gold
DA 2023-04-20
ER

PT J
AU Thapa, S
   Fischbach, LA
   Delongchamp, R
   Faramawi, MF
   Orloff, MS
AF Thapa, Susan
   Fischbach, Lori A.
   Delongchamp, Robert
   Faramawi, Mohammed F.
   Orloff, Mohammed S.
TI Using Machine Learning to Predict Progression in the Gastric
   Precancerous Process in a Population from a Developing Country Who
   Underwent a Gastroscopy for Dyspeptic Symptoms
SO GASTROENTEROLOGY RESEARCH AND PRACTICE
LA English
DT Article
ID HIGH-RISK; INTESTINAL METAPLASIA; CROSS-VALIDATION; CANCER; ASSOCIATION;
   ERADICATION; MANAGEMENT; POTASSIUM; MORTALITY; MARKERS
AB Background. Gastric cancer is the fourth most common cancer and the third most common cause of cancer deaths worldwide. Morbidity and mortality from gastric cancer may be decreased by identification of those that are at high risk for progression in the gastric precancerous process so that they can be monitored over time for early detection and implementation of preventive strategies. Method. Using machine learning, we developed prediction models for gastric precancerous progression in a population from a developing country with a high rate of gastric cancer who underwent gastroscopies for dyspeptic symptoms. In the data imputed for completeness, we divided the data into a training and a validation test set. Using the training set, we used the random forest method to rank potential predictors based on their predictive importance. Using predictors identified by the random forest method, we conducted best subset linear regressions with the leave-one-out cross-validation approach to select predictors for overall progression and progression to dysplasia or cancer. We validated the models in the test set using leave-one-out cross-validation. Results. We observed for all models that complete intestinal metaplasia and incomplete intestinal metaplasia were the strongest predictors for further progression in the precancerous process. We also observed that a diagnosis of no gastritis, superficial gastritis, or antral diffuse gastritis at baseline was a predictor of no progression in the gastric precancerous process. The sensitivities and specificities were 86% and 79% for the general model and 100% and 82% for the location-specific model, respectively. Conclusion. We developed prediction models to identify gastroscopy patients that are more likely to progress in the gastric precancerous process, among whom routine follow-up gastroscopies can be targeted to prevent gastric cancer. Future external validation is needed.
C1 [Thapa, Susan; Fischbach, Lori A.; Delongchamp, Robert; Faramawi, Mohammed F.; Orloff, Mohammed S.] Univ Arkansas Med Sci, Coll Publ Hlth, Dept Epidemiol, Little Rock, AR 72205 USA.
   [Delongchamp, Robert; Faramawi, Mohammed F.] Univ Arkansas Med Sci, Coll Med, Dept Biomed Informat, Little Rock, AR 72205 USA.
C3 University of Arkansas System; University of Arkansas Medical Sciences;
   University of Arkansas System; University of Arkansas Medical Sciences
RP Fischbach, LA (通讯作者)，Univ Arkansas Med Sci, Coll Publ Hlth, Dept Epidemiol, Little Rock, AR 72205 USA.
EM lafischbach@uams.edu
OI Fischbach, Lori/0000-0003-0133-1891
FU Fulbright Scholarship; University of North Texas Health Science Center;
   University of Arkansas for Medical Sciences
FX We would to like to express our gratitude to Dr. Pelayo Correa, Dr. Luis
   Bravo, Alba Lucy Casabon, Tito Collazos, Juan Carlos Bravo, Hernan
   Ramirez, Jose Luis Realpe, and Bernardo Ruis for their contribution in
   the original cohort study. We would also like to thank DeAnn Hubberd and
   Jarod Daily, editors at the University of Arkansas for Medical Sciences
   Science Communication Group, for their help in editing the manuscript.
   This project was funded by Fulbright Scholarship, Internal Institutional
   Funding from the University of North Texas Health Science Center, and
   the University of Arkansas for Medical Sciences.
CR [Anonymous], 1994, IARC Monogr Eval Carcinog Risks Hum, V61, P1
   [Anonymous], SEER CANCER STATISTI
   Ayer T, 2010, RADIOGRAPHICS, V30, P13, DOI 10.1148/rg.301095057
   Chen J., 1992, FUJIAN MED COLL J, V26, P1168
   CHEN VW, 1990, NUTR CANCER, V13, P59, DOI 10.1080/01635589009514045
   CORREA P, 1983, JNCI-J NATL CANCER I, V70, P673
   CORREA P, 1976, JNCI-J NATL CANCER I, V57, P1027, DOI 10.1093/jnci/57.5.1027
   CORREA P, 1975, LANCET, V2, P58
   Correa P, 2012, J DIGEST DIS, V13, P2, DOI 10.1111/j.1751-2980.2011.00550.x
   Cross AJ, 2004, ENVIRON MOL MUTAGEN, V44, P44, DOI 10.1002/em.20030
   Dinis-Ribeiro M, 2012, ENDOSCOPY, V44, P74, DOI 10.1055/s-0031-1291491
   Dixon MF, 1996, AM J SURG PATHOL, V20, P1161, DOI 10.1097/00000478-199610000-00001
   Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703
   Eom BW, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132613
   Fang XX, 2015, EUR J CANCER, V51, P2820, DOI 10.1016/j.ejca.2015.09.010
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Fischbach LA, 2002, INT J EPIDEMIOL, V31, P128, DOI 10.1093/ije/31.1.128
   Fischbach LA, 2001, ALIMENT PHARM THER, V15, P831, DOI 10.1046/j.1365-2036.2001.00998.x
   Ge S, 2012, GASTROENT RES PRACT, V2012, DOI 10.1155/2012/808120
   Herrero R, 2014, BEST PRACT RES CL GA, V28, P1107, DOI 10.1016/j.bpg.2014.10.003
   Klass OS, 2006, ECON LETT, V90, P290, DOI 10.1016/j.econlet.2005.08.020
   Koo H, 2015, ANN LAB MED, V35, P238, DOI 10.3343/alm.2015.35.2.238
   Kusters JG, 2006, CLIN MICROBIOL REV, V19, P449, DOI 10.1128/CMR.00054-05
   Lauwers GY, 1999, GUT, V45, P784, DOI 10.1136/gut.45.5.784
   Leiba A, 2005, NUTRITION, V21, P462, DOI 10.1016/j.nut.2004.08.021
   Leung WK, 2018, GASTROINTEST ENDOSC, V87, P119, DOI 10.1016/j.gie.2017.06.013
   Maryam KJ., 2012, J Hypertension, V30, P305, DOI [10.1097/01.hjh.0000420507.92068.00, DOI 10.1097/01.HJH.0000420507.92068.00]
   Matsumoto S, 2013, AUST J RURAL HEALTH, V21, P319, DOI 10.1111/ajr.12064
   Rushing C, 2015, COMPUT BIOL MED, V57, P123, DOI 10.1016/j.compbiomed.2014.11.015
   Sung JK, 2016, KOREAN J INTERN MED, V31, P201, DOI 10.3904/kjim.2016.021
   Toyokawa T, 2010, J GASTROEN HEPATOL, V25, P544, DOI 10.1111/j.1440-1746.2009.05995.x
   Vannella L, 2011, DIGEST LIVER DIS, V43, P295, DOI 10.1016/j.dld.2010.10.012
   Voutilainen M, 1999, GUT, V45, P644, DOI 10.1136/gut.45.5.644
   Wallace ML, 2010, STAT MED, V29, P3004, DOI 10.1002/sim.4079
   Watabe H, 2005, GUT, V54, P764, DOI 10.1136/gut.2004.055400
   Wong BCY, 2004, JAMA-J AM MED ASSOC, V291, P187, DOI 10.1001/jama.291.2.187
   Zalpuri S, 2013, TRANSFUS MED REV, V27, P74, DOI 10.1016/j.tmrv.2013.02.002
   Zhang X, 2018, GASTROENTEROLOGY, V155, P347, DOI 10.1053/j.gastro.2018.04.026
NR 38
TC 5
Z9 5
U1 2
U2 4
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-6121
EI 1687-630X
J9 GASTROENT RES PRACT
JI Gastroenterol. Res. Pract.
PD APR 1
PY 2019
VL 2019
AR 8321942
DI 10.1155/2019/8321942
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA IS4QB
UT WOS:000482137500001
PM 31065263
OA Green Submitted, Green Published, gold
DA 2023-04-20
ER

PT J
AU Zhao, YY
   Xue, DX
   Wang, YL
   Zhang, R
   Sun, B
   Cai, YP
   Feng, H
   Cai, Y
   Xu, JM
AF Zhao, Yuan-Yuan
   Xue, Di-Xiu
   Wang, Ya-Lei
   Zhang, Rong
   Sun, Bin
   Cai, Yong-Ping
   Feng, Hui
   Cai, Yi
   Xu, Jian-Ming
TI Computer-assisted diagnosis of early esophageal squamous cell carcinoma
   using narrow-band imaging magnifying endoscopy
SO ENDOSCOPY
LA English
DT Article
ID AIDED DIAGNOSIS; LESIONS; CLASSIFICATION; SYSTEM
AB Background We developed a computer-assisted diagnosis model to evaluate the feasibility of automated classification of intrapapillary capillary loops (IPCLs) to improve the detection of esophageal squamous cell carcinoma (ESCC).
   Methods We recruited patients who underwent magnifying endoscopy with narrow-band imaging for evaluation of a suspicious esophageal condition. Case images were evaluated to establish a gold standard IPCL classification according to the endoscopic diagnosis and histological findings. A double-labeling fully convolutional network (FCN) was developed for image segmentation. Diagnostic performance of the model was compared with that of endoscopists grouped according to years of experience (senior >15 years; mid level 10-15 years; junior 5-10 years).
   Results Of the 1383 lesions in the study, the mean accuracies of IPCL classification were 92.0%, 82.0%, and 73.3%, for the senior, mid level, and junior groups, respectively. The mean diagnostic accuracy of the model was 89.2% and 93.0% at the lesion and pixel levels, respectively. The interobserver agreement between the model and the gold standard was substantial (kappa value, 0.719). The accuracy of the model for inflammatory lesions (92.5%) was superior to that of the mid level (88.1%) and junior (86.3%) groups ( P <0.001). For malignant lesions, the accuracy of the model (B1, 87.6%; B2, 93.9%) was significantly higher than that of the mid level (B1, 79.1%; B2, 90.0%) and junior (B1, 69.2%; B2, 79.3%) groups ( P <0.001).
   Conclusions Double-labeling FCN automated IPCL recognition was feasible and could facilitate early detection of ESCC.
C1 [Zhao, Yuan-Yuan; Wang, Ya-Lei; Sun, Bin; Feng, Hui; Cai, Yi; Xu, Jian-Ming] Anhui Med Univ, Dept Gastroenterol, Affiliated Hosp 1, Jixi Rd 218, Hefei 230022, Anhui, Peoples R China.
   [Xue, Di-Xiu] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei, Anhui, Peoples R China.
   [Zhang, Rong] Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei, Anhui, Peoples R China.
   [Cai, Yong-Ping] Anhui Med Univ, Affiliated Hosp 1, Dept Pathol, Hefei, Anhui, Peoples R China.
C3 Anhui Medical University; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS; Chinese Academy of Sciences; Anhui
   Medical University
RP Xu, JM (通讯作者)，Anhui Med Univ, Dept Gastroenterol, Affiliated Hosp 1, Jixi Rd 218, Hefei 230022, Anhui, Peoples R China.
EM xujm1017@163.com
FU Department of Gastroenterology of the First Affiliated Hospital of Anhui
   Medical University
FX This work was supported by the Department of Gastroenterology of the
   First Affiliated Hospital of Anhui Medical University. We thank Wei Han,
   Jing Hu, Wei-Juan Ma, Xiao-Yong Xu, and Ren-Yu Fan for image
   classifications.
CR [Anonymous], 2012, P ADV NEUR INF PROC
   Arnold M, 2015, GUT, V64, P381, DOI 10.1136/gutjnl-2014-308124
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Ciocirlan M, 2007, ENDOSCOPY, V39, P24, DOI 10.1055/s-2006-945182
   Deng J., 2009, 2009 IEEE COMP SOC C, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Dixon MF, 2002, GUT, V51, P130, DOI 10.1136/gut.51.1.130
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Fitzmaurice C, 2015, JAMA ONCOL, V1, P505, DOI 10.1001/jamaoncol.2015.0735
   Gwang H K, 2017, GASTROINTEST ENDOSC, V85, pAB571
   Inoue H, 2015, ANN GASTROENTEROL, V28, P41
   Japan Esophageal Society, 2009, ESOPHAGUS, V6, P71, DOI [10.1007/s10388-009-0193-0, DOI 10.1007/S10388-009-0193-0]
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Minami H, 2014, DIGESTION, V89, P6, DOI 10.1159/000356200
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   OYAMA T, 2012, GASTROINTEST ENDOS S, V75, P456
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Szegedy C., 2015, P IEEE C COMP VIS PA, P1
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Xue DX, 2017, PROC SPIE, V10420, DOI 10.1117/12.2282000
   Xue DX, 2016, J MED BIOL ENG, V36, P755, DOI 10.1007/s40846-016-0182-4
   Xue DX, 2015, 2015 INTERNATIONAL SYMPOSIUM ON BIOELECTRONICS AND BIOINFORMATICS (ISBB), P67, DOI 10.1109/ISBB.2015.7344925
   Zeng HM, 2015, INT J CANCER, V136, P1921, DOI 10.1002/ijc.29227
NR 29
TC 59
Z9 65
U1 0
U2 16
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD APR
PY 2019
VL 51
IS 4
BP 333
EP 341
DI 10.1055/a-0756-8754
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA HQ8HK
UT WOS:000462664900023
PM 30469155
DA 2023-04-20
ER

PT J
AU Zhu, Y
   Wang, QC
   Xu, MD
   Zhang, Z
   Cheng, J
   Zhong, YS
   Zhang, YQ
   Chen, WF
   Yao, LQ
   Zhou, PH
   Li, QL
AF Zhu, Yan
   Wang, Qiu-Cheng
   Xu, Mei-Dong
   Zhang, Zhen
   Cheng, Jing
   Zhong, Yun-Shi
   Zhang, Yi-Qun
   Chen, Wei-Feng
   Yao, Li-Qing
   Zhou, Ping-Hong
   Li, Quan-Lin
TI Application of convolutional neural network in the diagnosis of the
   invasion depth of gastric cancer based on conventional endoscopy
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID ULTRASONOGRAPHY; PREDICTION; EFFICACY
AB Background and Aims: According to guidelines, endoscopic resection should only be performed for patients whose early gastric cancer invasion depth is within the mucosa or submucosa of the stomach regardless of lymph node involvement. The accurate prediction of invasion depth based on endoscopic images is crucial for screening patients for endoscopic resection. We constructed a convolutional neural network computer-aided detection (CNN CAD) system based on endoscopic images to determine invasion depth and screen patients for endoscopic resection.
   Methods: Endoscopic images of gastric cancer tumors were obtained from the Endoscopy Center of Zhongshan Hospital. An artificial intelligence based CNN-CAD system was developed through transfer learning leveraging a state-of-the-art pretrained CNN architecture, ResNet50. A total of 790 images served as a development dataset and another 203 images as a test dataset. We used the CNN-CAD system to determine the invasion depth of gastric cancer and evaluated the system's classification accuracy by calculating its sensitivity, specificity, and area under the receiver operating characteristic curve.
   Results: The area under the receiver operating characteristic curve for the CNN-CAD system was.94 (95% confidence interval [CI],.90-.97). At a threshold value of.5, sensitivity was 76.47%, and specificity 95.56%. Overall accuracy was 89.16%. Positive and negative predictive values were 89.66% and 88.97%, respectively. The CNN CAD system achieved significantly higher accuracy (by 17.25%; 95% CI, 11.63-22.59) and specificity (by 32.21%; 95% CI, 26.78-37.44) than human endoscopists.
   Conclusions: We constructed a CNN-CAD system to determine the invasion depth of gastric cancer with high accuracy and specificity. This system distinguished early gastric cancer from deeper submucosal invasion and minimized overestimation of invasion depth, which could reduce unnecessary gastrectomy.
C1 [Zhu, Yan; Xu, Mei-Dong; Zhang, Zhen; Cheng, Jing; Zhong, Yun-Shi; Zhang, Yi-Qun; Chen, Wei-Feng; Yao, Li-Qing; Zhou, Ping-Hong; Li, Quan-Lin] Fudan Univ, Zhongshan Hosp, Endoscopy Ctr, Shanghai 200032, Peoples R China.
   [Zhu, Yan; Xu, Mei-Dong; Zhang, Zhen; Cheng, Jing; Zhong, Yun-Shi; Zhang, Yi-Qun; Chen, Wei-Feng; Yao, Li-Qing; Zhou, Ping-Hong; Li, Quan-Lin] Fudan Univ, Zhongshan Hosp, Endoscopy Res Inst, Shanghai 200032, Peoples R China.
   [Wang, Qiu-Cheng] Univ Calif Irvine, Dept Comp Sci, Irvine, CA USA.
C3 Fudan University; Fudan University; University of California System;
   University of California Irvine
RP Zhou, PH; Li, QL (通讯作者)，Fudan Univ, Zhongshan Hosp, Endoscopy Ctr, Shanghai 200032, Peoples R China.; Zhou, PH; Li, QL (通讯作者)，Fudan Univ, Zhongshan Hosp, Endoscopy Res Inst, Shanghai 200032, Peoples R China.
EM zhou.pinghong@zs-hospital.sh.cn; li.quanlin@zs-hospital.sh.cn
RI Zhong, Yun/HCH-6868-2022; Zhang, YiQun/HCI-2427-2022; Chen,
   Wei/GZK-7348-2022
OI Li, quanlin/0000-0002-9108-8786
FU National Natural Science Foundation of China [81873552, 81470811,
   81570595, 81670483]; Major Project of Shanghai Municipal Science and
   Technology Committee [18ZR1406700, 16411950400]; Chen Guang Program of
   Shanghai Municipal Education Commission [15CG04]; Outstanding Young
   Doctor Training Project of Shanghai Municipal Commission of Health and
   Family Planning [2017YQ026]; Project of Shanghai Municipal Commission of
   Health and Family Planning [SHDC12016203]
FX All authors disclosed no financial relationships relevant to this
   publication. Research support for this study was provided by the
   National Natural Science Foundation of China Nos. 81873552 (Li QL),
   81470811 (Zhou PH), 81570595 (Xu MD), and 81670483 (Zhou PH); Major
   Project of Shanghai Municipal Science and Technology Committee nos.
   18ZR1406700 (Li QL) and 16411950400 (Zhou PH); Chen Guang Program of
   Shanghai Municipal Education Commission no. 15CG04 (Li QL), Outstanding
   Young Doctor Training Project of Shanghai Municipal Commission of Health
   and Family Planning no. 2017YQ026 (Li QL), and the Project of Shanghai
   Municipal Commission of Health and Family Planning no. SHDC12016203
   (Zhou PH).
CR Abe S, 2011, GASTRIC CANCER, V14, P35, DOI 10.1007/s10120-011-0002-z
   [Anonymous], 2010, P 13 INT C ARTIFICIA
   Cheng JY, 2018, SURG ENDOSC, V32, P855, DOI 10.1007/s00464-017-5754-z
   Choi J, 2010, ENDOSCOPY, V42, P705, DOI 10.1055/s-0030-1255617
   Choi J, 2011, GASTROINTEST ENDOSC, V73, P917, DOI 10.1016/j.gie.2010.11.053
   Chung IK, 2009, GASTROINTEST ENDOSC, V69, P1228, DOI 10.1016/j.gie.2008.09.027
   Feng H, 2016, SCAND J GASTROENTERO, V51, P48, DOI 10.3109/00365521.2015.1054425
   Gandomkar Z, 2018, ARTIF INTELL MED, V88, P14, DOI 10.1016/j.artmed.2018.04.005
   Hasuike N, 2018, GASTRIC CANCER, V21, P114, DOI 10.1007/s10120-017-0704-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holland O, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500442
   Hornbrook MC, 2017, DIGEST DIS SCI, V62, P2719, DOI 10.1007/s10620-017-4722-8
   Hu J, 2018, BMC GASTROENTEROL, V18, DOI 10.1186/s12876-018-0908-6
   Isomoto H, 2009, GUT, V58, P331, DOI 10.1136/gut.2008.165381
   Japanese Gastric Canc Assoc, 2011, GASTRIC CANCER, V14, P101, DOI 10.1007/s10120-011-0041-5
   Kim SJ, 2017, SCAND J GASTROENTERO, V52, P864, DOI 10.1080/00365521.2017.1315167
   Ono H, 2001, GUT, V48, P225, DOI 10.1136/gut.48.2.225
   Ono H, 2016, DIGEST ENDOSC, V28, P3, DOI 10.1111/den.12518
   Park JM, 2011, J GASTRIC CANCER, V11, P109, DOI 10.5230/jgc.2011.11.2.109
   Philpotts LE, 2009, RADIOLOGY, V253, P17, DOI 10.1148/radiol.2531090689
   Polkowski M, 2004, ENDOSCOPY, V36, P617, DOI 10.1055/s-2004-814522
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SANO T, 1990, DIGEST DIS SCI, V35, P1340, DOI 10.1007/BF01536738
   Savides T, 2000, Gastrointest Endosc, V51, P635
   Simonyan K, 2015, Arxiv
   Tsujii Y, 2015, GASTROINTEST ENDOSC, V82, P452, DOI 10.1016/j.gie.2015.01.022
   Vasconcelos CN, 2017, CORR, V1
   Yamamoto S, 2012, GASTROENT RES PRACT, V2012, DOI 10.1155/2012/194530
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 30
TC 169
Z9 182
U1 14
U2 115
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD APR
PY 2019
VL 89
IS 4
BP 806
EP +
DI 10.1016/j.gie.2018.11.011
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HP6HG
UT WOS:000461784300021
PM 30452913
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Zhang, X
   Chen, F
   Yu, T
   An, JY
   Huang, ZX
   Liu, JQ
   Hu, WL
   Wang, LJ
   Duan, HL
   Si, JM
AF Zhang, Xu
   Chen, Fei
   Yu, Tao
   An, Jiye
   Huang, Zhengxing
   Liu, Jiquan
   Hu, Weiling
   Wang, Liangjing
   Duan, Huilong
   Si, Jianmin
TI Real-time gastric polyp detection using convolutional neural networks
SO PLOS ONE
LA English
DT Article
AB Computer-aided polyp detection in gastric gastroscopy has been the subject of research over the past few decades. However, despite significant advances, automatic polyp detection in real time is still an unsolved problem. In this paper, we report on a convolutional neural network (CNN) for polyp detection that is constructed based on Single Shot MultiBox Detector (SSD) architecture and which we call SSD for Gastric Polyps (SSD-GPNet). To take full advantages of feature maps information from the feature pyramid and to acquire higher accuracy, we re-use information that is abandoned by Max-Pooling layers. In other words, we reuse the lost data from the pooling layers and concatenate that data as extra feature maps to contribute to classification and detection. Meanwhile, in the feature pyramid, we concatenate feature maps of the lower layers and feature maps that are deconvolved from upper layers to make explicit relationships between layers and to effectively increase the number of channels. The results show that our enhanced SSD for gastric polyp detection can realize real-time polyp detection with 50 frames per second (FPS) and can improve the mean average precision (mAP) from 88.5% to 90.4%, with only a little loss in time-performance. And the further experiment shows that SSD-GPNet has excellent performance in improving polyp detection recalls over 10% (p = 0.00053), especially in small polyp detection. This can help endoscopic physicians more easily find missed polyps and decrease the gastric polyp miss rate. It may be applicable in daily clinical practice to reduce the burden on physicians.
C1 [Zhang, Xu; Yu, Tao; An, Jiye; Huang, Zhengxing; Liu, Jiquan; Duan, Huilong] Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Fei; Hu, Weiling; Wang, Liangjing; Si, Jianmin] Zhejiang Univ, Inst Gastroenterol, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Fei; Wang, Liangjing] Zhejiang Univ, Sch Med, Dept Gastroenterol, Affiliated Hosp 2, Hangzhou, Zhejiang, Peoples R China.
   [Hu, Weiling; Si, Jianmin] Zhejiang Univ, Sch Med, Sir Run Run Shaw Hosp, Dept Gastroenterol, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang
   University
RP An, JY; Huang, ZX; Liu, JQ (通讯作者)，Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou, Zhejiang, Peoples R China.; Hu, WL (通讯作者)，Zhejiang Univ, Inst Gastroenterol, Hangzhou, Zhejiang, Peoples R China.; Hu, WL (通讯作者)，Zhejiang Univ, Sch Med, Sir Run Run Shaw Hosp, Dept Gastroenterol, Hangzhou, Zhejiang, Peoples R China.
EM an_jiye@zju.edu.cn; zhengxinghuang@zju.edu.cn; liujq@zju.edu.cn;
   huweiling@zju.edu.cn
OI Yu, Tao/0000-0001-9617-7465; liu, jiquan/0000-0001-5994-6472
FU National Natural Science Foundation of China [31771072]; National Key
   Research and Development Program of China [2017YFC0114106]; Zhejiang
   Science and Technology Project [LGF18H160012]
FX Jiquan Liu is supported by National Natural Science Foundation of China
   (grant numbers 31771072). The URL is https://hfbic021dcb05d8e549bdh995u9bvnqn966605fiac.eds.tju.edu.cn/; Jiquan Liu
   is supported by National Key Research and Development Program of China
   (grant numbers 2017YFC0114106). The URL is
   https://hfbicf3d001a7e805482bh995u9bvnqn966605fiac.eds.tju.edu.cn/kjjh/.Weiling Hu is supported by Zhejiang Science
   and Technology Project (grant numbers LGF18H160012). The URL is
   https://hfbic8e5506313a874ee6h995u9bvnqn966605fiac.eds.tju.edu.cn/.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Baopu Li, 2010, 2010 IEEE International Conference on Automation and Logistics (ICAL), P126, DOI 10.1109/ICAL.2010.5585395
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Carmack SW, 2009, NAT REV GASTRO HEPAT, V6, P331, DOI 10.1038/nrgastro.2009.70
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Desai Anant M, 2004, Gastric Cancer, V7, P196, DOI 10.1007/s10120-004-0289-0
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.Y., 2017, ARXIV170106659
   Fu JJC, 2014, COMPUT MED IMAG GRAP, V38, P267, DOI 10.1016/j.compmedimag.2013.12.009
   Girshick R., 2013, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, 2015 IEEE INT C COMP, P7
   Hafner M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P365, DOI 10.1007/978-3-662-46224-9_63
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hwang S., 2007, P 2007 IEEE INT C IM, DOI [DOI 10.1109/ICIP.2007.4379193, 10.1109/ICIP.2007.4379193]
   Iakovidis DK, 2005, P IEEE INT S COMP BA
   Jeong J., 2017, BRIT MACH VIS C
   Jia Y., 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Park SY, 2016, MEDICAL IMAGING 2016
   Redmon J., 2017, PROC CVPR IEEE, P7263, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simmons DT, 2006, ALIMENT PHARM THERAP, V24, P965, DOI 10.1111/j.1365-2036.2006.03080.x
   Simonyan K, 2015, Arxiv
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sundaram P, 2008, MED IMAGE ANAL, V12, P99, DOI 10.1016/j.media.2007.08.001
   Taha B, 2017, IM PROC ICIP 2017 IE
   Tajbakhsh N, 2015, 2015 IEEE 12 INT S B
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zheng B, 2012, SURG ENDOSC, V26, P1352, DOI 10.1007/s00464-011-2038-x
NR 43
TC 57
Z9 59
U1 1
U2 23
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAR 25
PY 2019
VL 14
IS 3
AR e0214133
DI 10.1371/journal.pone.0214133
PG 16
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA HQ1KV
UT WOS:000462157600038
PM 30908513
OA Green Submitted, Green Published, gold
DA 2023-04-20
ER

PT J
AU Wimmer, G
   Gadermayr, M
   Wolkersdorfer, G
   Kwitt, R
   Tamaki, T
   Tischendorf, J
   Hafner, M
   Yoshida, S
   Tanaka, S
   Merhof, D
   Uhl, A
AF Wimmer, Georg
   Gadermayr, Michael
   Wolkersdoerfer, Gernot
   Kwitt, Roland
   Tamaki, Toru
   Tischendorf, Jens
   Haefner, Michael
   Yoshida, Shigeto
   Tanaka, Shinji
   Merhof, Dorit
   Uhl, Andreas
TI Quest for the best endoscopic imaging modality for computer-assisted
   colonic polyp staging
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Endoscopy; Colonic polyps; Automated diagnosis system; Narrow-band
   imaging; Chromoendoscopy; Imaging modalities; Image enhancement
   technologies
ID COLORECTAL POLYPS; HIGH-DEFINITION; I-SCAN; CLASSIFICATION; HISTOLOGY;
   DIAGNOSIS; NBI
AB BACKGROUND
   It was shown in previous studies that high definition endoscopy, high magnification endoscopy and image enhancement technologies, such as chromoendoscopy and digital chromoendoscopy [narrow-band imaging (NBI), i-Scan] facilitate the detection and classification of colonic polyps during endoscopic sessions. However, there are no comprehensive studies so far that analyze which endoscopic imaging modalities facilitate the automated classification of colonic polyps. In this work, we investigate the impact of endoscopic imaging modalities on the results of computer-assisted diagnosis systems for colonic polyp staging.
   AIM
   To assess which endoscopic imaging modalities are best suited for the computer-assisted staging of colonic polyps.
   METHODS
   In our experiments, we apply twelve state-of-the-art feature extraction methods for the classification of colonic polyps to five endoscopic image databases of colonic lesions. For this purpose, we employ a specifically designed experimental setup to avoid biases in the outcomes caused by differing numbers of images per image database. The image databases were obtained using different imaging modalities. Two databases were obtained by high-definition endoscopy in combination with i-Scan technology (one with chromoendoscopy and one without chromoendoscopy). Three databases were obtained by high-magnification endoscopy (two databases using narrow band imaging and one using chromoendoscopy). The lesions are categorized into non-neoplastic and neoplastic according to the histological diagnosis.
   RESULTS
   Generally, it is feature-dependent which imaging modalities achieve high results and which do not. For the high-definition image databases, we achieved overall classification rates of up to 79.2% with chromoendoscopy and 88.9% without chromoendoscopy. In the case of the database obtained by high-magnification chromoendoscopy, the classification rates were up to 81.4%. For the combination of high-magnification endoscopy with NBI, results of up to 97.4% for one database and up to 84% for the other were achieved. Non-neoplastic lesions were classified more accurately in general than non-neoplastic lesions. It was shown that the image recording conditions highly affect the performance of automated diagnosis systems and partly contribute to a stronger effect on the staging results than the used imaging modality.
   CONCLUSION
   Chromoendoscopy has a negative impact on the results of the methods. NBI is better suited than chromoendoscopy. High-definition and high-magnification endoscopy are equally suited.
C1 [Wimmer, Georg; Kwitt, Roland; Uhl, Andreas] Univ Salzburg, Dept Comp Sci, Jakob Haringer Str 2, A-5020 Salzburg, Austria.
   [Gadermayr, Michael; Merhof, Dorit] Rhein Westfal TH Aachen, Interdisciplinary Imaging & Vis Inst Aachen, D-52074 Aachen, Germany.
   [Wolkersdoerfer, Gernot] Paracelsus Med Univ, Dept Internal Med 1, Salzburger Landesklin SALK, A-5020 Salzburg, Austria.
   [Tamaki, Toru] Hiroshima Univ, Grad Sch Engn, Dept Informat Engn, Hiroshima 7398527, Japan.
   [Tischendorf, Jens] Univ Hosp Aachen, Internal Med & Gastroenterol, D-52146 Wurselen, Germany.
   [Haefner, Michael] Krankenhaus St Elisabeth, Dept Gastroenterol & Hepatol, A-1080 Vienna, Austria.
   [Yoshida, Shigeto] Hiroshima Univ, Grad Sch Biomed & Hlth Sci, Dept Endoscopy & Med, Hiroshima 7348551, Japan.
   [Tanaka, Shinji] Hiroshima Univ Hosp, Dept Endoscopy, Hiroshima 7348551, Japan.
C3 Salzburg University; RWTH Aachen University; Paracelsus Private Medical
   University; Hiroshima University; RWTH Aachen University; RWTH Aachen
   University Hospital; Hiroshima University; Hiroshima University
RP Wimmer, G (通讯作者)，Univ Salzburg, Dept Comp Sci, Jakob Haringer Str 2, A-5020 Salzburg, Austria.
EM gwimmer@cosy.sbg.ac.at
RI Tamaki, Toru/D-7091-2011; Kwitt, Roland/HII-6060-2022; Kwitt,
   Roland/AFS-8639-2022; Merhof, Dorit/AAV-7892-2021
OI Tamaki, Toru/0000-0001-9712-7777; , Michael/0000-0003-1450-9222
FU Austrian Science Fund (FWF), KLI project [429, TRP206]
FX Supported by the Austrian Science Fund (FWF), KLI project 429, No.
   TRP206.
CR Berr F, 2014, EARLY NEOPLASIAS GAS, DOI [10.1007/978-1-4614-8292-5, DOI 10.1007/978-1-4614-8292-5]
   Bhat YM, 2014, GASTROINTEST ENDOSC, V80, P919, DOI 10.1016/j.gie.2014.06.019
   Bouwens MWE, 2013, WORLD J GASTROENTERO, V19, P4334, DOI 10.3748/wjg.v19.i27.4334
   Chang CC, 2009, INT J COLORECTAL DIS, V24, P1413, DOI 10.1007/s00384-009-0760-9
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gross S, 2012, PROC SPIE, V8315, DOI 10.1117/12.911177
   Hafner M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P365, DOI 10.1007/978-3-662-46224-9_63
   Hafner M, 2012, COMPUT METH PROG BIO, V107, P565, DOI 10.1016/j.cmpb.2011.12.012
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hafner M, 2014, LARGE DATA MED IMAGI, P205, DOI [10.1007/978-3-319-05530-5_20, DOI 10.1007/978-3-319-05530-5_20]
   Hafner M, 2014, SHAPE SIZE ADAPTED L, DOI [10.1109/ICIP.2014.7025466, DOI 10.1109/ICIP.2014.7025466]
   Hoffman A, 2010, DIGEST LIVER DIS, V42, P45, DOI 10.1016/j.dld.2009.04.005
   Kodashima S, 2010, WORLD J GASTROENTERO, V16, P1043, DOI 10.3748/wjg.v16.i9.1043
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Manfredi MA, 2015, GASTROINTEST ENDOSC, V81, P249, DOI 10.1016/j.gie.2014.06.020
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Rameshshanker R, 2016, Curr Treat Options Gastroenterol, V14, P140, DOI 10.1007/s11938-016-0075-1
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   Wimmer G, 2016, INT CONF IMAG PROC
   Wimmer G, 2016, P 3 INT WORKSH COMP, P59, DOI [10.1007/978-3-319-54057-3_6, DOI 10.1007/978-3-319-54057-3_6]
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
NR 27
TC 2
Z9 2
U1 1
U2 2
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD MAR 14
PY 2019
VL 25
IS 10
BP 1197
EP 1209
DI 10.3748/wjg.v25.i10.1197
PG 13
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HO7ZO
UT WOS:000461169100003
PM 30886503
OA Green Submitted, Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Alaskar, H
   Hussain, A
   Al-Aseem, N
   Liatsis, P
   Al-Jumeily, D
AF Alaskar, Haya
   Hussain, Abir
   Al-Aseem, Nourah
   Liatsis, Panos
   Al-Jumeily, Dhiya
TI Application of Convolutional Neural Networks for Automated Ulcer
   Detection in Wireless Capsule Endoscopy Images
SO SENSORS
LA English
DT Article
DE deep learning networks; AlexNet; GoogLeNet; convolutional neural
   networks; wireless capsule endoscopy; ulcer detection
ID COLOR
AB Detection of abnormalities in wireless capsule endoscopy (WCE) images is a challenging task. Typically, these images suffer from low contrast, complex background, variations in lesion shape and color, which affect the accuracy of their segmentation and subsequent classification. This research proposes an automated system for detection and classification of ulcers in WCE images, based on state-of-the-art deep learning networks. Deep learning techniques, and in particular, convolutional neural networks (CNNs), have recently become popular in the analysis and recognition of medical images. The medical image datasets used in this study were obtained from WCE video frames. In this work, two milestone CNN architectures, namely the AlexNet and the GoogLeNet are extensively evaluated in object classification into ulcer or non-ulcer. Furthermore, we examine and analyze the images identified as containing ulcer objects to evaluate the efficiency of the utilized CNNs. Extensive experiments show that CNNs deliver superior performance, surpassing traditional machine learning methods by large margins, which supports their effectiveness as automated diagnosis tools.
C1 [Alaskar, Haya; Al-Aseem, Nourah] Prince Sattam Bin Abdulaziz Univ, Dept Comp Sci, Coll Comp Engn & Sci, Alkharj 11942, Saudi Arabia.
   [Hussain, Abir; Al-Jumeily, Dhiya] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
   [Liatsis, Panos] Khalifa Univ Sci & Technol, Dept Comp Sci, Abu Dhabi 127788, U Arab Emirates.
C3 Prince Sattam Bin Abdulaziz University; Liverpool John Moores
   University; University of Liverpool; Khalifa University of Science &
   Technology
RP Alaskar, H (通讯作者)，Prince Sattam Bin Abdulaziz Univ, Dept Comp Sci, Coll Comp Engn & Sci, Alkharj 11942, Saudi Arabia.
EM h.alaskar@psau.edu.sa; a.hussain@ljmu.ac.uk; N.alaseem@psau.edu.sa;
   panos.liatsis@ku.ac.ae; D.AlJumeily@ljmu.ac.uk
RI Alaskar, Haya/AAM-6119-2020; Liatsis, Panos/AAF-9675-2020; alaskar,
   haya/ABD-7547-2021; Al-Jumeily, Dhiya/AAE-8272-2020
OI Alaskar, Haya/0000-0002-1688-0669; Liatsis, Panos/0000-0002-5490-6030;
   alaskar, haya/0000-0002-1688-0669; Al-Jumeily, Dhiya/0000-0002-9170-0568
FU Specialized Research Grant program at Prince Sattam university
   [2017/01/7814]
FX Project supported by the Specialized Research Grant program at Prince
   Sattam university (reference NO. 2017/01/7814)
CR Adler DG., 2003, HOSP PHYS, V39, P14
   Alaskar H., 2018, IJCSNS INT J COMPUT, V18, DOI [10.1142/S2424922X18400065, DOI 10.1142/S2424922X18400065]
   Alaskar H, 2018, INT J ADV COMPUT SC, V9, P486
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Bchir O., 2018, COMPUT SCI INF TECHN, P1, DOI [10.5121/csit.2018.80501, DOI 10.5121/CSIT.2018.80501]
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Cheng PM, 2017, J DIGIT IMAGING, V30, P234, DOI 10.1007/s10278-016-9929-2
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI DOI 10.1561/2000000039
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Finlayson GD, 2006, INT J COMPUT VISION, V67, P93, DOI 10.1007/s11263-006-4100-z
   Fireman Z, 2002, ISR MED ASSOC J, V4, P717
   Georgakopoulos SV, 2016, IEEE CONF IMAGING SY, P510, DOI 10.1109/IST.2016.7738279
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Khan Sameer Ahmad, 2016, Advances in Machine Learning and Signal Processing, MALSIP 2015. Proceedings: LNEE 387, P293, DOI 10.1007/978-3-319-32213-1_26
   Khan S, 2017, ASIAPAC SIGN INFO PR, P1661
   Li BP, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P234, DOI 10.1109/WCICA.2008.4592930
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Linder T., 2017, THESIS LINKOPING U
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   Pei MQ, 2017, KNOWL-BASED SYST, V121, P163, DOI 10.1016/j.knosys.2017.01.023
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Souaidi M., 2017, P 2017 INT C ADV TEC, P1
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Sugimori H, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/1753480
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Vasilakakis MD, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/2026962
   Wang C., 2018, P SPIE MED IM MED IM, V10575
   WIMMER G, 2016, PROCEEDINGS OF THE I, V104, P113, DOI DOI 10.1109/CBI.2016.20
   Wolterink JM, 2016, MED IMAGE ANAL, V34, P123, DOI 10.1016/j.media.2016.04.004
   Yan Xu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1626, DOI 10.1109/ICASSP.2014.6853873
   Yosinski J., 2014, NIPS
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
NR 49
TC 84
Z9 84
U1 5
U2 28
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD MAR 2
PY 2019
VL 19
IS 6
AR 1265
DI 10.3390/s19061265
PG 16
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA HU8FG
UT WOS:000465520200003
PM 30871162
OA Green Accepted, Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Dai, JH
   He, X
   Li, ZY
   Li, K
   Yang, TT
   Ran, ZL
   Yin, LJ
   Chen, Y
   Zou, X
   Fang, DC
   Peng, GY
AF Dai, Jianhua
   He, Xiu
   Li, Zhuoyue
   Li, Kang
   Yang, Tingting
   Ran, Zengling
   Yin, Lijian
   Chen, Yao
   Zou, Xiang
   Fang, Dianchun
   Peng, Guiyong
TI Fiber-Optic Raman Spectrum Sensor for Fast Diagnosis of Esophageal
   Cancer
SO PHOTONIC SENSORS
LA English
DT Article
DE Fiber-optic; Raman spectrum; esophageal cancer
ID ENDOSCOPIC SUBMUCOSAL DISSECTION; BARRETTS-ESOPHAGUS; SPECTROSCOPY;
   TISSUE
AB A fiber-optic Raman spectrum sensor system is used for the fast diagnosis of esophageal cancer during clinical endoscopic examination. The system contains a 785 nm exciting laser, a Raman fiber-optic probe with 7 large core fibers and a focus lens, and a highly sensitive spectrum meter. The Raman spectrum of the tissue could be obtained within 1 second by using such a system. A signal baseline removal and denoising technology is used to improve the signal quality. A novel signal feature extraction method for differentiating the normal and esophageal cancer tissues is proposed, based on the differences in half-height width (HHW) in 1200 cm(1) to 1400 cm(1) frequency band and the ratios of the spectral integral energy between 1600 cm(1) - 1700 cm(1) and 1500 cm(1) - 1600 cm(1) band. It shows a high specificity and effectivity for the diagnosis of esophageal cancer.
C1 [Dai, Jianhua; Yin, Lijian; Chen, Yao; Fang, Dianchun; Peng, Guiyong] Army Med Univ, Southwest Hosp, Inst Digest Dis, Chongqing 40038, Peoples R China.
   [He, Xiu; Li, Zhuoyue; Li, Kang; Yang, Tingting; Ran, Zengling] Univ Elect Sci & Technol China, Minist Educ, Key Lab Opt Fiber Sensing & Commun, Fiber Opt Res Ctr, Chengdu 611731, Sichuan, Peoples R China.
   [Zou, Xiang] Zolix Instruments Co Ltd, Beijing 101102, Peoples R China.
C3 Army Medical University; University of Electronic Science & Technology
   of China
RP Fang, DC; Peng, GY (通讯作者)，Army Med Univ, Southwest Hosp, Inst Digest Dis, Chongqing 40038, Peoples R China.
EM fangdianchun@hotmail.com; pgy63@163.com
RI GUIYONG, PENG/AAM-7865-2020
FU multicenter clinical study of endoscopic diagnosis of early esophageal
   cancer [SWH2016ZDCX3007]; State 111 Project [B14039]; Application of
   endoscopic minimally invasive technique in diagnosis and treatment of
   digestive tract injury and disease [SWH2016ZDCX2011]; Study of effect on
   fibroblast transdifferentiation and prevention of postoperative
   esophagus stenosis through regulating the TRADD [81470907]; National
   Natural Science Foundation of China (NSFC) [51627806, 51875091];
   Application of Raman imaging in the diagnosis of gastric cancer
   [cstc2015shmszx10017]
FX This word was supported by multicenter clinical study of endoscopic
   diagnosis of early esophageal cancer (Grant No. SWH2016ZDCX3007); the
   State 111 Project (Grant No. B14039); Application of endoscopic
   minimally invasive technique in diagnosis and treatment of digestive
   tract injury and disease (Grant No. SWH2016ZDCX2011); Study of effect on
   fibroblast transdifferentiation and prevention of postoperative
   esophagus stenosis through regulating the TRADD (Grant No. 81470907);
   the National Natural Science Foundation of China (NSFC) (Grant Nos.
   51627806 and 51875091); Application of Raman imaging in the diagnosis of
   gastric cancer (Grant No. cstc2015shmszx10017).
CR Bergholt MS, 2014, GASTROENTEROLOGY, V146, P27, DOI 10.1053/j.gastro.2013.11.002
   Brown LM, 2008, J NATL CANCER I, V100, P1184, DOI 10.1093/jnci/djn211
   Choudhury SN, 2018, PHOTONIC SENS, V8, P193, DOI 10.1007/s13320-018-0501-1
   Cui SS, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8619342
   Devesa SS, 1998, CANCER, V83, P2049, DOI 10.1002/(SICI)1097-0142(19981115)83:10<2049::AID-CNCR1>3.0.CO;2-2
   Fleischmann C, 2018, MINERVA CHIR, V73, P378, DOI 10.23736/S0026-4733.18.07805-7
   Fujishiro M, 2006, CLIN GASTROENTEROL H, V4, P688, DOI 10.1016/j.cgh.2006.03.024
   Hu YG, 2008, SPECTROCHIM ACTA A, V69, P378, DOI 10.1016/j.saa.2007.04.009
   Huang ZW, 2009, OPT LETT, V34, P758, DOI 10.1364/OL.34.000758
   Jemal A, 2010, CA-CANCER J CLIN, V60, P277, DOI [10.3322/caac.20073, 10.3322/caac.20105]
   Krishnamoorthi R, 2016, GASTROINTEST ENDOSC, V83, P1090, DOI 10.1016/j.gie.2016.02.009
   Mizumoto T, 2018, DIGEST DIS SCI, V63, P1605, DOI 10.1007/s10620-018-5029-0
   Ohki T, 2012, GASTROENTEROLOGY, V143, P582, DOI 10.1053/j.gastro.2012.04.050
   Oyama Tsuneo, 2005, Clin Gastroenterol Hepatol, V3, pS67, DOI 10.1016/S1542-3565(05)00291-0
   Shetty G, 2006, BRIT J CANCER, V94, P1460, DOI 10.1038/sj.bjc.6603102
   Shim MG, 2000, PHOTOCHEM PHOTOBIOL, V72, P146, DOI 10.1562/0031-8655(2000)072<0146:IVNIRS>2.0.CO;2
   Sreedharan L, 2017, WORLD J GASTROENTERO, V23, P5508, DOI 10.3748/wjg.v23.i30.5508
   Wang TD, 2007, P NATL ACAD SCI USA, V104, P15864, DOI 10.1073/pnas.0707567104
   Xiao C, 2018, PHOTONIC SENS, V8, P278, DOI 10.1007/s13320-018-0497-6
NR 19
TC 4
Z9 6
U1 9
U2 32
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1674-9251
EI 2190-7439
J9 PHOTONIC SENS
JI Photonic Sens.
PD MAR
PY 2019
VL 9
IS 1
BP 53
EP 59
DI 10.1007/s13320-018-0516-7
PG 7
WC Instruments & Instrumentation; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Instruments & Instrumentation; Optics
GA HG9ZI
UT WOS:000455370900008
OA gold
DA 2023-04-20
ER

PT J
AU Diamantis, DE
   Iakovidis, DK
   Koulaouzidis, A
AF Diamantis, Dimitrios E.
   Iakovidis, Dimitris K.
   Koulaouzidis, Anastasios
TI Look-behind fully convolutional neural network for computer-aided
   endoscopy
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Computer-aided diagnosis; Endoscopy; Convolutional neural networks;
   Abnormality detection
ID CAPSULE ENDOSCOPY; IMAGES
AB In this paper, we propose a novel Fully Convolutional Neural Network (FCN) architecture aiming to aid the detection of abnormalities, such as polyps, ulcers and blood, in gastrointestinal (GI) endoscopy images. The proposed architecture, named Look-Behind FCN (LB-FCN), is capable of extracting multi-scale image features by using blocks of parallel convolutional layers with different filter sizes. These blocks are connected by Look-Behind (LB) connections, so that the features they produce are combined with features extracted from behind layers, thus preserving the respective information. Furthermore, it has a smaller number of free parameters than conventional Convolutional Neural Network (CNN) architectures, which makes it suitable for training with smaller datasets. This is particularly useful in medical image analysis, since data availability is usually limited due to ethicolegal constraints. The performance of LB-FCN is evaluated on both flexible and wireless capsule endoscopy datasets, reaching 99.72% and 93.50%, in terms of Area Under receiving operating Characteristic (AUC) respectively. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Diamantis, Dimitrios E.; Iakovidis, Dimitris K.] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
   [Koulaouzidis, Anastasios] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh, Midlothian, Scotland.
C3 Royal Infirmary of Edinburgh; University of Edinburgh
RP Iakovidis, DK (通讯作者)，Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
EM dimitris.iakovidis@ieee.org
RI Koulaouzidis, Anastasios/G-9060-2014
OI Koulaouzidis, Anastasios/0000-0002-2248-489X; Diamantis,
   Dimitrios/0000-0003-4384-8557; Iakovidis, Dimitris/0000-0002-5027-5323
CR Abadi Martin, 2016, arXiv
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   [Anonymous], 2008, 2008 IEEE Hot Chips 20 Symposium (HCS), DOI 10.1109/HOTCHIPS.2008.7476516
   Chen HH, 2017, NEUROCOMPUTING, V229, P77, DOI 10.1016/j.neucom.2016.06.077
   Chollet F., 2015, TECH REP
   Cong Y, 2016, NEUROCOMPUTING, V196, P150, DOI 10.1016/j.neucom.2015.10.130
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Du K. L., 2006, NEURAL NETWORKS SOFT, DOI [10.1007/1-84628-303-5, DOI 10.1007/1-84628-303-5]
   EndoVisSub-Abnormal, 2015, ENDOVISSUB ABNORMAL
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gers FA, 2000, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2000.861302
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   HE KM, 2015, PROC CVPR IEEE, P5353, DOI [DOI 10.1109/CVPR.2015.7299173, 10.1109/CVPR.2015.7299173]
   Hegenbart S, 2013, MED IMAGE ANAL, V17, P458, DOI 10.1016/j.media.2013.02.001
   Hinton G.E., 2012, COURSERA NEURAL NETW, P31
   Iakovidis D. K., 2018, IEEE T MED IMAGING
   Iakovidis DK, 2015, IEEE ENG MED BIO, P731, DOI 10.1109/EMBC.2015.7318466
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Jia Y., 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kiesslich Ralf, 2005, Gastrointest Endosc Clin N Am, V15, P715, DOI 10.1016/j.giec.2005.08.010
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Krizhevsky A., HDB SYSTEMIC AUTOIMM, V1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   MULLER AD, 1995, ANN INTERN MED, V123, P904, DOI 10.7326/0003-4819-123-12-199512150-00002
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Simonyan K, 2015, Arxiv
   Springenberg J. T., 2014, ARXIV14126806
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Swain P, 2008, WORLD J GASTROENTERO, V14, P4142, DOI 10.3748/wjg.14.4142
   Szegedy, 2013, ARXIV13126199, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C., 2017, INCEPTION V4 INCEPTI, P12
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   The Cleveland Clinic Foundation, 2017, DIG DIS GASTR DIS CL
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Vasilakakis M, 2017, LECT NOTES COMPUT SC, V10170, P96, DOI 10.1007/978-3-319-54057-3_9
   Wang S, 2016, IEEE T BIO-MED ENG, V63, P2347, DOI 10.1109/TBME.2016.2530141
   Wang S, 2015, IEEE IMAGE PROC, P3072, DOI 10.1109/ICIP.2015.7351368
   WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269
   Wimmer G., 2016, LNCS
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yao K, 2013, ZOOM GASTROSCOPY MAG
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 58
TC 31
Z9 31
U1 0
U2 13
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD MAR
PY 2019
VL 49
BP 192
EP 201
DI 10.1016/j.bspc.2018.12.005
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA HL7SY
UT WOS:000458942500017
DA 2023-04-20
ER

PT J
AU Everson, M
   Herrera, LCGP
   Li, W
   Luengo, IM
   Ahmad, O
   Banks, M
   Magee, C
   Alzoubaidi, D
   Hsu, HM
   Graham, D
   Vercauteren, T
   Lovat, L
   Ourselin, S
   Kashin, S
   Wang, HP
   Wang, WL
   Haidry, RJ
AF Everson, M.
   Herrera, L. C. G. P.
   Li, W.
   Luengo, I. Muntion
   Ahmad, O.
   Banks, M.
   Magee, C.
   Alzoubaidi, D.
   Hsu, H. M.
   Graham, D.
   Vercauteren, T.
   Lovat, L.
   Ourselin, S.
   Kashin, S.
   Wang, Hsiu-Po
   Wang, Wen-Lun
   Haidry, R. J.
TI Artificial intelligence for the real-time classification of
   intrapapillary capillary loop patterns in the endoscopic diagnosis of
   early oesophageal squamous cell carcinoma: A proof-of-concept study
SO UNITED EUROPEAN GASTROENTEROLOGY JOURNAL
LA English
DT Article
DE Artificial intelligence; computer-aided diagnosis; endoscopy; neural
   networks; oesophageal cancer; squamous cell cancer
ID LYMPH-NODE METASTASES; EPIDEMIOLOGY; CANCER; DEPTH
AB Background Intrapapillary capillary loops (IPCLs) represent an endoscopically visible feature of early squamous cell neoplasia (ESCN) which correlate with invasion depth - an important factor in the success of curative endoscopic therapy. IPCLs visualised on magnification endoscopy with Narrow Band Imaging (ME-NBI) can be used to train convolutional neural networks (CNNs) to detect the presence and classify staging of ESCN lesions. Methods A total of 7046 sequential high-definition ME-NBI images from 17 patients (10 ESCN, 7 normal) were used to train a CNN. IPCL patterns were classified by three expert endoscopists according to the Japanese Endoscopic Society classification. Normal IPCLs were defined as type A, abnormal as B1-3. Matched histology was obtained for all imaged areas. Results This CNN differentiates abnormal from normal IPCL patterns with 93.7% accuracy (86.2% to 98.3%) and sensitivity and specificity for classifying abnormal IPCL patterns of 89.3% (78.1% to 100%) and 98% (92% to 99.7%), respectively. Our CNN operates in real time with diagnostic prediction times between 26.17 ms and 37.48 ms. Conclusion Our novel and proof-of-concept application of computer-aided endoscopic diagnosis shows that a CNN can accurately classify IPCL patterns as normal or abnormal. This system could be used as an in vivo, real-time clinical decision support tool for endoscopists assessing and directing local therapy of ESCN.
C1 [Everson, M.; Ahmad, O.; Banks, M.; Magee, C.; Alzoubaidi, D.; Graham, D.; Lovat, L.; Haidry, R. J.] UCL, Div Surg & Intervent Sci, London, England.
   [Everson, M.; Banks, M.; Magee, C.; Alzoubaidi, D.; Graham, D.; Lovat, L.; Haidry, R. J.] Univ Coll Hosp NHS Fdn Trust, Dept Gastroenterol, London, England.
   [Herrera, L. C. G. P.; Li, W.; Luengo, I. Muntion; Ahmad, O.; Vercauteren, T.; Lovat, L.; Ourselin, S.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London, England.
   [Hsu, H. M.; Wang, Hsiu-Po] Natl Taiwan Univ, Dept Internal Med, Taipei, Taiwan.
   [Kashin, S.] Yaroslavl Reg Canc Hosp, Yaroslavl, Russia.
   [Wang, Wen-Lun] I Shou Univ, Dept Internal Med, E Da Hosp, Kaohsiung, Taiwan.
C3 University of London; University College London; University of London;
   University College London; UK Research & Innovation (UKRI); Engineering
   & Physical Sciences Research Council (EPSRC); University of London;
   University College London; National Taiwan University; E-Da Hospital; I
   Shou University
RP Haidry, RJ (通讯作者)，Univ Coll London Hosp, Dept Gastroenterol, 235 Euston Rd, London NW1 2BU, England.
EM r.haidry@ucl.ac.uk
RI Lovat, Laurence/C-1986-2009; Vercauteren, Tom K/I-7290-2013; Wang,
   Wen-Lun/AAJ-1281-2020; Ourselin, Sebastien/K-6960-2015
OI Lovat, Laurence/0000-0003-4542-3915; Vercauteren, Tom
   K/0000-0003-1794-0456; Ourselin, Sebastien/0000-0002-5694-5340
FU Wellcome Trust [WT101957, 203145Z/16/Z]; EPSRC [NS/A000027/1,
   NS/A000050/1]; National Institute for Health Research Biomedical
   Research Centre University College London (UCL) Hospitals/UCL High
   Impact Initiative; UCL Engineering and Physical Science Research Council
   Centres for Doctoral Training Scholarship Award [EP/L016478/1]
FX This work was supported by Wellcome Trust (WT101957, 203145Z/16/Z),
   EPSRC (NS/A000027/1, NS/A000050/1), National Institute for Health
   Research Biomedical Research Centre University College London (UCL)
   Hospitals/UCL High Impact Initiative and a UCL Engineering and Physical
   Science Research Council Centres for Doctoral Training Scholarship Award
   (EP/L016478/1).
CR Arima M., 2005, ESOPHAGUS-TOKYO, V2, P191, DOI [DOI 10.1007/S10388-005-0060-6, 10.1007/s10388-005-0060-6]
   Cho JW, 2014, CLIN ENDOSC, V47, P523, DOI 10.5946/ce.2014.47.6.523
   Eslick GD, 2009, GASTROENTEROL CLIN N, V38, P17, DOI 10.1016/j.gtc.2009.01.008
   Garcia-Peraza-Herrera LC, ARXIV180500632CSCV
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Hotta T., 2018, CLIN GASTROENTEROL H, V3, pS67
   Inoue H, 1996, DIGEST ENDOSC, V8, P134, DOI DOI 10.1111/J.1443-1661.1996.TB00429.X]
   Inoue H., 1997, DIGEST ENDOSC, V9, P16, DOI [10.1111/j.1443-1661.1997.tb00453.x, DOI 10.1111/j.1443-1661.1997.tb00453.x]
   Inoue H, 2001, DIG ENDOSC S, V13, P40, DOI DOI 10.1111/J.1443-1661.2001.0116B.X]
   Inoue H, 2015, ANN GASTROENTEROL, V28, P41
   Inoue Haruhiro, 2010, Gastrointest Endosc Clin N Am, V20, P25, DOI 10.1016/j.giec.2009.08.005
   Kaga M, 2011, ONCOL REP, V26, P1063, DOI 10.3892/or.2011.1398
   Kim SJ, 2017, WORLD J GASTROENTERO, V23, P4416, DOI 10.3748/wjg.v23.i24.4416
   Kodama M, 1998, SURGERY, V123, P432, DOI 10.1067/msy.1998.86778
   Kumagai Y, 2010, DIGEST ENDOSC, V22, P259, DOI 10.1111/j.1443-1661.2010.01010.x
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Oyama T., 2011, ESOPHAGUS, V8, P247, DOI DOI 10.1007/S10388-011-0301-9
   Oyama T, 2017, ESOPHAGUS-TOKYO, V14, P105, DOI 10.1007/s10388-016-0527-7
   Sato H, 2015, ENDOSCOPY, V47, P122, DOI 10.1055/s-0034-1390858
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Sgourakis G, 2011, EXPERT REV ANTICANC, V11, P601, DOI [10.1586/ERA.10.150, 10.1586/era.10.150]
   Shimada H, 2006, WORLD J SURG, V30, P1441, DOI 10.1007/s00268-005-0462-6
   Shimizu Y, 2002, GASTROINTEST ENDOSC, V56, P387, DOI 10.1067/mge.2002.127100
   Taylor PR, 2013, CANCER EPIDEM BIOMAR, V22, P540, DOI 10.1158/1055-9965.EPI-12-1347
   Wang WL, 2018, J GASTROEN HEPATOL, V33, P1248, DOI 10.1111/jgh.14071
   Zhang CZ, 2017, GASTROINTEST ENDOSC, V85, pAB587, DOI 10.1016/j.gie.2017.03.1354
   Zhang YW, 2013, WORLD J GASTROENTERO, V19, P5598, DOI 10.3748/wjg.v19.i34.5598
NR 27
TC 48
Z9 50
U1 0
U2 12
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2050-6406
EI 2050-6414
J9 UNITED EUR GASTROENT
JI United European Gastroenterol. J.
PD MAR
PY 2019
VL 7
IS 2
BP 297
EP 306
DI 10.1177/2050640618821800
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HN4XM
UT WOS:000460187000016
PM 31080614
OA Green Submitted, hybrid, Green Published
DA 2023-04-20
ER

PT J
AU Gu, Y
   Vyas, K
   Yang, J
   Yang, GZ
AF Gu, Yun
   Vyas, Khushi
   Yang, Jie
   Yang, Guang-Zhong
TI Transfer Recurrent Feature Learning for Endomicroscopy Image Recognition
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Probe-based confocal laser endomicroscopy; adversarial learning;
   recurrent neural networks
ID ATTENUATION
AB Probe-based confocal laser endomicroscopy (pCLE) is an emerging tool for epithelial cancer diagnosis, which enables in-vivo microscopic imaging during endoscopic procedures and facilitates the development of automatic recognition algorithms to identify the status of tissues. In this paper, we propose a transfer recurrent feature learning framework for classification tasks on pCLE videos. At the first stage, the discriminative feature of single pCLE frame is learned via generative adversarial networks based on both pCLE and histology modalities. At the second stage, we use recurrent neural networks to handle the varying length and irregular shape of pCLE mosaics taking the frame-based features as input. The experiments on real pCLE data sets demonstrate that our approach outperforms, with statistical significance, state-of-the-art approaches. A binary classification accuracy of 84.1% has been achieved.
C1 [Gu, Yun; Yang, Jie] Shanghai Jiao Tong Univ, Sch Biomed Engn, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   [Vyas, Khushi; Yang, Guang-Zhong] Imperial Coll London, Hamlyn Ctr Robot Surg, London SW7 2AZ, England.
C3 Shanghai Jiao Tong University; Imperial College London
RP Yang, J (通讯作者)，Shanghai Jiao Tong Univ, Sch Biomed Engn, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.; Yang, GZ (通讯作者)，Imperial Coll London, Hamlyn Ctr Robot Surg, London SW7 2AZ, England.
EM jieyang@sjtu.edu.cn; g.z.yang@imperial.ac.uk
OI Gu, Yun/0000-0002-4199-0675
FU U.K. Engineering and Physical Sciences Research Council [EP/N019318/1,
   EP/N027132/1, EP/N022521/1]; Committee of Science and Technology,
   Shanghai, China [17JC1403000]; 973 Plan, China [2015CB856004]; Chinese
   Scholarship Council;  [R-12047]; Engineering and Physical Sciences
   Research Council [EP/N019318/1] Funding Source: researchfish; EPSRC
   [EP/P012779/1, EP/N019318/1, EP/N027132/1, EP/N022521/1] Funding Source:
   UKRI
FX This work was supported by the U.K. Engineering and Physical Sciences
   Research Council under Grant EP/N019318/1, Grant EP/N027132/1, and Grant
   EP/N022521/1, in part by the Committee of Science and Technology,
   Shanghai, China, under Grant 17JC1403000, in part by the 973 Plan,
   China, under Grant 2015CB856004, and in part by the R-12047 Project. The
   work of Y. Gu was supported by the Chinese Scholarship Council.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Andre B, 2010, I S BIOMED IMAGING, P1419, DOI 10.1109/ISBI.2010.5490265
   Andre B, 2009, I S BIOMED IMAGING, P346, DOI 10.1109/ISBI.2009.5193055
   Andre B, 2012, IEEE T MED IMAGING, V31, P1276, DOI 10.1109/TMI.2012.2188301
   Andre B, 2011, LECT NOTES COMPUT SC, V6893, P297, DOI 10.1007/978-3-642-23626-6_37
   Andre B, 2011, MED IMAGE ANAL, V15, P460, DOI 10.1016/j.media.2011.02.003
   Aubreville M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12320-8
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   BYEON W, 2015, PROC CVPR IEEE, P3547, DOI DOI 10.1109/CVPR.2015.7298977
   Catana C, 2010, J NUCL MED, V51, P1431, DOI 10.2967/jnumed.109.069112
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang TP, 2015, BREAST CANCER RES TR, V153, P299, DOI 10.1007/s10549-015-3543-8
   Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Creswell A., 2016, TASK SPECIFIC ADVERS
   Denton E., 2016, SEMISUPERVISED LEARN
   Dobbs JL, 2015, BREAST CANCER RES, V17, DOI 10.1186/s13058-015-0617-9
   Gehring J, 2013, INT CONF ACOUST SPEE, P3377, DOI 10.1109/ICASSP.2013.6638284
   Giataganas P, 2015, INT J COMPUT ASS RAD, V10, P825, DOI 10.1007/s11548-015-1179-0
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gu Y, 2017, IEEE VTS VEH TECHNOL
   Gu Y, 2018, LECT NOTES COMPUT SC, V11071, P326, DOI 10.1007/978-3-030-00934-2_37
   Gu Y, 2016, IEEE COMPUT SOC CONF, P1315, DOI 10.1109/CVPRW.2016.166
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hughes M, 2016, BIOMED OPT EXPRESS, V7, P2257, DOI 10.1364/BOE.7.002257
   Isola P., 2017, PROC 30 IEEE C COMPU, P1125, DOI DOI 10.1109/CVPR.2017.632
   Jog A, 2014, I S BIOMED IMAGING, P987, DOI 10.1109/ISBI.2014.6868038
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Kumar  A., 2017, SEMISUPERVISED LEARN
   Lewis J. P., 1995, VIS INTERFACE, V10, P120
   Li D, 2016, LECT NOTES COMPUT SC, V9908, P678, DOI 10.1007/978-3-319-46493-0_41
   Meining A, 2007, CLIN GASTROENTEROL H, V5, P1261, DOI 10.1016/j.cgh.2007.05.019
   Newton RC, 2012, RESP MED, V106, P127, DOI 10.1016/j.rmed.2011.09.009
   Nie Dong, 2017, Med Image Comput Comput Assist Interv, V10435, P417, DOI 10.1007/978-3-319-66179-7_48
   Park T., 2017, ICCV, DOI DOI 10.1109/ICCV.2017.244
   Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Srivastava A., 2017, VEEGAN REDUCING MODE, P3310
   Tafreshi MK, 2014, LECT NOTES COMPUT SC, V8673, P89, DOI 10.1007/978-3-319-10404-1_12
   Vercauteren T., 2008, P SOC PHOTO-OPT INS, V6861, P68610
   Vyas K, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.2.020501
   ZAGORUYKO S, 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
   Zaidi H, 2003, MED PHYS, V30, P937, DOI 10.1118/1.1569270
   Zhang  L., 2016, AUTONOMOUS SCANNING
   Zhang L, 2017, IEEE ROBOT AUTOM MAG, V24, P63, DOI 10.1109/MRA.2017.2680543
NR 46
TC 9
Z9 9
U1 2
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD MAR
PY 2019
VL 38
IS 3
BP 791
EP 801
DI 10.1109/TMI.2018.2872473
PG 11
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA HO1JV
UT WOS:000460662400013
PM 30273147
DA 2023-04-20
ER

PT J
AU Laves, MH
   Bicker, J
   Kahrs, LA
   Ortmaier, T
AF Laves, Max-Heinrich
   Bicker, Jens
   Kahrs, Lueder A.
   Ortmaier, Tobias
TI A dataset of laryngeal endoscopic images with comparative study on
   convolution neural network-based semantic segmentation
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Computer vision; Larynx; Vocal folds; Soft tissue; Open-access dataset;
   Machine learning; Patient-to-patient fine-tuning
ID SOFT-TISSUE MOTION; CLASSIFICATION; TRACKING
AB PurposeAutomated segmentation of anatomical structures in medical image analysis is a prerequisite for autonomous diagnosis as well as various computer- and robot-aided interventions. Recent methods based on deep convolutional neural networks (CNN) have outperformed former heuristic methods. However, those methods were primarily evaluated on rigid, real-world environments. In this study, existing segmentation methods were evaluated for their use on a new dataset of transoral endoscopic exploration.MethodsFour machine learning-based methods SegNet, UNet, ENet and ErfNet were trained with supervision on a novel 7-class dataset of the human larynx. The dataset contains 536 manually segmented images from two patients during laser incisions. The Intersection-over-Union (IoU) evaluation metric was used to measure the accuracy of each method. Data augmentation and network ensembling were employed to increase segmentation accuracy. Stochastic inference was used to show uncertainties of the individual models. Patient-to-patient transfer was investigated using patient-specific fine-tuning.ResultsIn this study, a weighted average ensemble network of UNet and ErfNet was best suited for the segmentation of laryngeal soft tissue with a mean IoU of 84.7%. The highest efficiency was achieved by ENet with a mean inference time of 9.22ms per image. It is shown that 10 additional images from a new patient are sufficient for patient-specific fine-tuning.ConclusionCNN-based methods for semantic segmentation are applicable to endoscopic images of laryngeal soft tissue. The segmentation can be used for active constraints or to monitor morphological changes and autonomously detect pathologies. Further improvements could be achieved by using a larger dataset or training the models in a self-supervised manner on additional unlabeled data.
C1 [Laves, Max-Heinrich; Bicker, Jens; Kahrs, Lueder A.; Ortmaier, Tobias] Leibniz Univ Hannover, Appelstr 11A, D-30167 Hannover, Germany.
C3 Leibniz University Hannover
RP Laves, MH (通讯作者)，Leibniz Univ Hannover, Appelstr 11A, D-30167 Hannover, Germany.
EM laves@imes.uni-hannover.de
OI Kahrs, Lueder Alexander/0000-0001-5506-2768; Laves,
   Max-Heinrich/0000-0003-0156-7247
FU European Union
FX This research has received funding from the European Union as being part
   of the ERFE OPhonLas project.
CR Allin S, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P812
   [Anonymous], 2017, P 31 C NEUR INF PROC
   Aubreville M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12320-8
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barbalata C, 2016, IEEE J BIOMED HEALTH, V20, P322, DOI 10.1109/JBHI.2014.2374975
   Barkmeier-Kraemer JM, 2016, SEMIN SPEECH LANG, V37, P158, DOI 10.1055/s-0036-1583547
   Cabezas M, 2011, COMPUT METH PROG BIO, V104, pE158, DOI 10.1016/j.cmpb.2011.07.015
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Creswell A, 2018, IET COMPUT VIS, V12, P1105, DOI 10.1049/iet-cvi.2018.5243
   Doignon C, 2005, REAL-TIME IMAGING, V11, P429, DOI 10.1016/j.rti.2005.06.008
   Friedrich DT, 2015, ANN OTO RHINOL LARYN, V124, P655, DOI 10.1177/0003489415575548
   Gal Y, 2016, PR MACH LEARN RES, V48
   Garcia-Peraza-Herrera LC, 2017, LECT NOTES COMPUT SC, V10170, P84, DOI 10.1007/978-3-319-54057-3_8
   Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Kendall A., 2017, 31 ANN C NEUR INF PR, P5574
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Lin T.-Y., 2017, ICCV
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092
   Olabarriaga SD, 2001, MED IMAGE ANAL, V5, P127, DOI 10.1016/S1361-8415(00)00041-4
   Osma-Ruiz V, 2008, COMPUT MED IMAG GRAP, V32, P193, DOI 10.1016/j.compmedimag.2007.12.003
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Panek D, 2015, IEEE ENG MED BIO, P735, DOI 10.1109/EMBC.2015.7318467
   Paszke A., 2016, ARXIV E PRINTS
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Rajab MI, 2004, COMPUT MED IMAG GRAP, V28, P61, DOI 10.1016/S0895-6111(03)00054-5
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schoob A, 2017, MED IMAGE ANAL, V40, P80, DOI 10.1016/j.media.2017.06.004
   Schoob A, 2016, INT J COMPUT ASS RAD, V11, P2325, DOI 10.1007/s11548-016-1420-5
   Schoob A, 2016, OPT LASER ENG, V83, P71, DOI 10.1016/j.optlaseng.2016.03.002
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Turkmen HI, 2015, COMPUT BIOL MED, V62, P76, DOI 10.1016/j.compbiomed.2015.02.001
   Unger J, 2015, CANCER RES, V75, P31, DOI 10.1158/0008-5472.CAN-14-1458
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X
NR 37
TC 42
Z9 42
U1 3
U2 32
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD MAR
PY 2019
VL 14
IS 3
BP 483
EP 492
DI 10.1007/s11548-018-01910-0
PG 10
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA HM5SQ
UT WOS:000459535900007
PM 30649670
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Lee, BI
   Matsuda, T
AF Lee, Bo-In
   Matsuda, Takahisa
TI Estimation of Invasion Depth: The First Key to Successful Colorectal ESD
SO CLINICAL ENDOSCOPY
LA English
DT Review
DE Colonoscopy; Colorectal neoplasms; Narrow-band imaging; Neoplasm staging
ID ENDOSCOPIC SUBMUCOSAL DISSECTION; BAND IMAGING NBI; MAGNIFYING
   CHROMOENDOSCOPY; PIT PATTERNS; DIAGNOSIS; LESIONS; CLASSIFICATION;
   CANCER; COLONOSCOPY; ACCURACY
AB Colorectal tumors with superficial submucosal invasion, which cannot be removed by snaring, are one of the most optimal indications for colorectal endoscopic submucosal dissection (ESD). Therefore, estimation of the invasion depth is the first key to successful colorectal ESD. Although estimation of the invasion depth based on the gross morphology may be useful in selected cases, its diagnostic accuracy could not reach the clinical requirement. The Japan Narrow-band Imaging (NBI) Expert Team (JNET) classification of NBI magnifying endoscopy findings is a useful method for histologic prediction and invasion depth estimation. However, magnifying chromoendoscopy is still necessary for JNET type 2B lesions to reach a satisfactory diagnostic accuracy. Endocytoscopy with artificial intelligence is a promising technology in invasion depth estimation; however, more data are needed for its clinical application.
C1 [Lee, Bo-In] Catholic Univ Korea, Div Gastroenterol, Dept Internal Med, Coll Med, Seoul, South Korea.
   [Lee, Bo-In] Catholic Photomed Res Inst, Seoul, South Korea.
   [Matsuda, Takahisa] Natl Canc Ctr, Canc Screening Ctr, Endoscopy Div, Natl Canc Ctr Hosp,Div Screening Technol,Ctr Publ, Tokyo, Japan.
C3 Catholic University of Korea; National Cancer Center - Japan
RP Matsuda, T (通讯作者)，Natl Canc Ctr, Canc Screening Ctr, Endoscopy Div,Chuo Ku, Div Screening Technol,Ctr Publ Hlth Sci,Natl Canc, 5-1-1 Tsukiji, Tokyo 1040045, Japan.
EM tamatsud@ncc.go.jp
CR Aihara H, 2013, INT J COLORECTAL DIS, V28, P1, DOI 10.1007/s00384-012-1591-7
   Bahin FF, 2018, GUT, V67, P1965, DOI 10.1136/gutjnl-2017-313823
   Choi HJ, 2013, CLIN ENDOSC, V46, P168, DOI 10.5946/ce.2013.46.2.168
   Fujimori T, 2001, J GASTROENTEROL, V36, P587, DOI 10.1007/s005350170041
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Hewett DG, 2017, GASTROINTEST ENDOSC, V85, P822, DOI 10.1016/j.gie.2017.01.004
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hurlstone DP, 2005, GUT, V54, P1585, DOI 10.1136/gut.2005.069849
   Ikehara H, 2010, J GASTROEN HEPATOL, V25, P905, DOI 10.1111/j.1440-1746.2010.06275.x
   Iwatate M, 2018, DIGEST ENDOSC, V30, P642, DOI 10.1111/den.13065
   Kanao H, 2008, WORLD J GASTROENTERO, V14, P211, DOI 10.3748/wjg.14.211
   Kanao H, 2009, GASTROINTEST ENDOSC, V69, P631, DOI 10.1016/j.gie.2008.08.028
   Kim JS, 2014, GASTROENT RES PRACT, V2014, DOI 10.1155/2014/245396
   Kitajima K, 2004, J GASTROENTEROL, V39, P534, DOI 10.1007/s00535-004-1339-4
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P49, DOI 10.1159/000481230
   Kudo SE, 2011, ENDOSCOPY, V43, P869, DOI 10.1055/s-0030-1256663
   Kudo SE, 2008, GASTROINTEST ENDOSC, V68, pS3, DOI 10.1016/j.gie.2008.07.052
   Mani S, 2016, REV ENVIRON CONTAM T, V237, P71, DOI 10.1007/978-3-319-23573-8_4
   Matsuda T, 2008, AM J GASTROENTEROL, V103, P2700, DOI 10.1111/j.1572-0241.2008.02190.x
   Matsumoto T, 2002, GASTROINTEST ENDOSC, V56, P354, DOI 10.1067/mge.2002.127156
   MORSON BC, 1984, GUT, V25, P437, DOI 10.1136/gut.25.5.437
   Nishizawa T, 2017, CURR OPIN GASTROEN, V33, P315, DOI 10.1097/MOG.0000000000000388
   Onishi T, 2008, J GASTROENTEROL, V43, P291, DOI 10.1007/s00535-008-2161-1
   Park W, 2014, WORLD J GASTROENTERO, V20, P6586, DOI 10.3748/wjg.v20.i21.6586
   Pimentel-Nunes P, 2015, ENDOSCOPY, V47, P829, DOI 10.1055/s-0034-1392882
   Puig I, 2019, GASTROENTEROLOGY, V156, P75, DOI 10.1053/j.gastro.2018.10.004
   Repici A, 2012, ENDOSCOPY, V44, P137, DOI 10.1055/s-0031-1291448
   Sano Y, 2009, GASTROINTEST ENDOSC, V69, P278, DOI 10.1016/j.gie.2008.04.066
   Sano Y, 2018, DIGEST ENDOSC, V30, P543, DOI 10.1111/den.13072
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Shimura T, 2014, CLIN GASTROENTEROL H, V12, P662, DOI 10.1016/j.cgh.2013.06.022
   Sumimoto K, 2017, GASTROINTEST ENDOSC, V85, P816, DOI 10.1016/j.gie.2016.07.035
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Tanaka S, 2008, J GASTROENTEROL, V43, P641, DOI 10.1007/s00535-008-2223-4
   Tanaka S, 2015, DIGEST ENDOSC, V27, P417, DOI 10.1111/den.12456
   Wada Y, 2009, GASTROINTEST ENDOSC, V70, P522, DOI 10.1016/j.gie.2009.01.040
   Watanabe T, 2015, INT J CLIN ONCOL, V20, P207, DOI 10.1007/s10147-015-0801-z
NR 37
TC 17
Z9 17
U1 2
U2 7
PU KOREAN SOC GASTROINTESTINAL ENDOSCOPY
PI SEOUL
PA 2003 LG PALACE, 165-8 DONGGYO-DONG, MAPO-GU, SEOUL, 121-754, SOUTH KOREA
SN 2234-2400
EI 2234-2443
J9 CLIN ENDOSC
JI Clin. Endosc.
PD MAR
PY 2019
VL 52
IS 2
BP 100
EP 106
DI 10.5946/ce.2019.012
PG 7
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA HQ9GH
UT WOS:000462734300005
PM 30914629
OA Green Published, Green Submitted, gold
DA 2023-04-20
ER

PT J
AU Ruffle, JK
   Farmer, AD
   Aziz, Q
AF Ruffle, James K.
   Farmer, Adam D.
   Aziz, Qasim
TI Artificial Intelligence-Assisted Gastroenterology-Promises and Pitfalls
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
ID IRRITABLE-BOWEL-SYNDROME; CAPSULE ENDOSCOPY; CANCER
AB Technological advances in artificial intelligence (AI) represent an enticing opportunity to benefit gastroenterological practice. Moreover, AI, through machine or deep learning, permits the ability to develop predictive models from large datasets. Possibilities of predictive model development in machine learning are numerous dependent on the clinical question. For example, binary classifiers aim to stratify allocation to a categorical outcome, such as the presence or absence of a gastrointestinal disease. In addition, continuous variable fitting techniques can be used to predict quantity of a therapeutic response, thus offering a tool to predict which therapeutic intervention may be most beneficial to the given patient. Namely, this permits an important opportunity for personalization of medicine, including a movement from guideline-specific treatment algorithms to patient-specific ones, providing both clinician and patient the capacity for data-driven decision making. Furthermore, such analyses could predict the development of GI disease prior to the manifestation of symptoms, raising the possibility of prevention or pre-treatment. In addition, computer vision additionally provides an exciting opportunity in endoscopy to automatically detect lesions. In this review, we overview the recent developments in healthcare-based AI and machine learning and describe promises and pitfalls for its application to gastroenterology.
C1 [Ruffle, James K.; Farmer, Adam D.; Aziz, Qasim] Queen Mary Univ London, Barts & London Sch Med & Dent, Wingate Inst Neurogastroenterol, Ctr Neurosci & Trauma,Blizard Inst, 26 Ashfield St, London E1 2AJ, England.
   [Farmer, Adam D.] Univ Keele, Inst Appl Clin Sci, Keele ST5 5BG, Staffs, England.
C3 University of London; Queen Mary University London; Keele University
RP Ruffle, JK (通讯作者)，Queen Mary Univ London, Barts & London Sch Med & Dent, Wingate Inst Neurogastroenterol, Ctr Neurosci & Trauma,Blizard Inst, 26 Ashfield St, London E1 2AJ, England.
EM j.ruffle@qmul.ac.uk
RI Aziz, Qasim/AAC-4730-2020; Ruffle, James/GLT-4299-2022
OI Ruffle, James/0000-0001-6248-7203; Aziz, Qasim/0000-0002-2718-2065
CR AIMI, 2017, RSNA 2017 RADS WHO U
   Baruch J, 2016, NATURE, V536, P127, DOI 10.1038/536127a
   Bengio Y., 2017, DEEP LEARNING, V1
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Carey WD, 2000, CLEV CLIN J MED, V67, P315, DOI 10.3949/ccjm.67.5.315
   CellanJones Rory, 2014, BBC NEWS 1202
   East JE, 2018, LANCET GASTROENTEROL, V3, P10, DOI 10.1016/S2468-1253(17)30366-7
   Farmer AD, 2015, HAMDAN MED J, V8, P265
   Farmer A, 2017, TREND UROL MENS HEAL, V8, P13, DOI 10.1002/tre.569
   Gartner, 2017, TOP TRENDS GARTNER H
   Herman J, 2010, GENDER MED, V7, P240, DOI 10.1016/j.genm.2010.06.007
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Holzberger KAI, 2018, HEALTHCARE
   Huang A, 2010, PATTERN RECOGN LETT, V31, P1461, DOI 10.1016/j.patrec.2010.03.013
   Kinar Y, 2016, J AM MED INFORM ASSN, V23, P879, DOI 10.1093/jamia/ocv195
   Limdi JK, 2003, POSTGRAD MED J, V79, P307, DOI 10.1136/pmj.79.932.307
   Nigam VP, 2004, NEUROL RES, V26, P55, DOI 10.1179/016164104773026534
   Rao B., 2016, INT J COMPUT SCI INF, V7, P1174, DOI [DOI 10.21275/ART20203995, 10.21275/ART20203995]
   Russell SJ, 2009, ARTIFICIAL INTELIIGE
   Samuel A., 1988, COMPUTER GAMES
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sreedharan A, 2010, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD005415.pub3
   Waxman JA, 2010, AM J RESP CRIT CARE, V181, P727, DOI 10.1164/rccm.200907-1146OC
   Whitehead SJ, 2010, BRIT MED BULL, V96, P5, DOI 10.1093/bmb/ldq033
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 26
TC 61
Z9 66
U1 1
U2 17
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0002-9270
EI 1572-0241
J9 AM J GASTROENTEROL
JI Am. J. Gastroenterol.
PD MAR
PY 2019
VL 114
IS 3
BP 422
EP 428
DI 10.1038/s41395-018-0268-4
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HR5AP
UT WOS:000463159300010
PM 30315284
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Aoki, T
   Yamada, A
   Aoyama, K
   Saito, H
   Tsuboi, A
   Nakada, A
   Niikura, R
   Fujishiro, M
   Oka, S
   Ishihara, S
   Matsuda, T
   Tanaka, S
   Koike, K
   Tada, T
AF Aoki, Tomonori
   Yamada, Atsuo
   Aoyama, Kazuharu
   Saito, Hiroaki
   Tsuboi, Akiyoshi
   Nakada, Ayako
   Niikura, Ryota
   Fujishiro, Mitsuhiro
   Oka, Shiro
   Ishihara, Soichiro
   Matsuda, Tomoki
   Tanaka, Shinji
   Koike, Kazuhiko
   Tada, Tomohiro
TI Automatic detection of erosions and ulcerations in wireless capsule
   endoscopy images based on a deep convolutional neural network
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID VALIDATION; CANCER; SYSTEM
AB Background and Aims: Although erosions and ulcerations are the most common small-bowel abnormalities found on wireless capsule endoscopy (WCE), a computer-aided detection method has not been established. We aimed to develop an artificial intelligence system with deep learning to automatically detect erosions and ulcerations in WCE images.
   Methods: We trained a deep convolutional neural network (CNN) system based on a Single Shot Multibox Detector, using 5360 WCE images of erosions and ulcerations. We assessed its performance by calculating the area under the receiver operating characteristic curve and its sensitivity, specificity, and accuracy using an independent test set of 10,440 small-bowel images including 440 images of erosions and ulcerations.
   Results: The trained CNN required 233 seconds to evaluate 10,440 test images. The area under the curve for the detection of erosions and ulcerations was 0.958 (95% confidence interval [CI], 0.947-0.968). The sensitivity, specificity, and accuracy of the CNN were 88.2% (95% CI, 84.8%-91.0%), 90.9% (95% CI, 90.3%-91.4%), and 90.8% (95% CI, 90.2%-91.3%), respectively, at a cut-off value of 0.481 for the probability score.
   Conclusions: We developed and validated a new system based on CNN to automatically detect erosions and ulcerations in WCE images. This may be a crucial step in the development of daily-use diagnostic software for WCE images to help reduce oversights and the burden on physicians.
C1 [Aoki, Tomonori; Yamada, Atsuo; Nakada, Ayako; Niikura, Ryota; Fujishiro, Mitsuhiro; Koike, Kazuhiko] Univ Tokyo, Dept Gastroenterol, Grad Sch Med, Tokyo, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] AI Med Serv Inc, Tokyo, Japan.
   [Saito, Hiroaki; Matsuda, Tomoki] Sendai Kousei Hosp, Dept Gastroenterol, Sendai, Miyagi, Japan.
   [Tsuboi, Akiyoshi; Oka, Shiro; Tanaka, Shinji] Hiroshima Univ Hosp, Dept Endoscopy, Hiroshima, Japan.
   [Fujishiro, Mitsuhiro] Univ Tokyo, Dept Endoscopy & Endoscop Surg, Tokyo, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
   [Ishihara, Soichiro] Int Univ Hlth & Welf, Surg Dept, Sanno Hosp, Tokyo, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
C3 University of Tokyo; Sendai Kousei Hospital; Hiroshima University;
   University of Tokyo; International University of Health & Welfare;
   University of Tokyo
RP Aoki, T (通讯作者)，Univ Tokyo, Dept Gastroenterol, Grad Sch Med, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138655, Japan.
RI 藤城, 光弘/AAN-3131-2020; Oka, Shiro/AAZ-8368-2021; SAITO,
   HIROAKI/HLH-2447-2023; Ishihara, Soichiro/AFK-1375-2022
OI SAITO, HIROAKI/0000-0002-0824-454X; Fujishiro,
   Mitsuhiro/0000-0002-4074-1140
CR Aoki T, 2018, J GASTROEN HEPATOL, V33, P1327, DOI 10.1111/jgh.14068
   Aoki T, 2016, CLIN GASTROENTEROL H, V14, P1562, DOI 10.1016/j.cgh.2016.05.042
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Goenka MK, 2011, WORLD J GASTROENTERO, V17, P774, DOI 10.3748/wjg.v17.i6.774
   Graham DY, 2005, CLIN GASTROENTEROL H, V3, P55, DOI 10.1016/S1542-3565(04)00603-2
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Park SC, 2010, WORLD J GASTROENTERO, V16, P875, DOI 10.3748/wjg.v16.i7.875
   Schisterman EF, 2005, EPIDEMIOLOGY, V16, P73, DOI 10.1097/01.ede.0000147512.81966.ba
   Shahidi NC, 2012, CLIN GASTROENTEROL H, V10, P1381, DOI 10.1016/j.cgh.2012.08.035
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   YOUDEN WJ, 1950, BIOMETRICS, V6, P172, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 21
TC 149
Z9 157
U1 6
U2 48
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD FEB
PY 2019
VL 89
IS 2
BP 357
EP +
DI 10.1016/j.gie.2018.10.027
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HI0VU
UT WOS:000456163300021
PM 30670179
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Bchir, O
   Ben Ismail, M
   AlZahrani, N
AF Bchir, Ouiem
   Ben Ismail, Mohamed Maher
   AlZahrani, Nada
TI Multiple bleeding detection in wireless capsule endoscopy
SO SIGNAL IMAGE AND VIDEO PROCESSING
LA English
DT Article
DE Wireless capsule endoscopy; Multiple bleeding spots; Recognition;
   Clustering; Classification
AB Wireless capsule endoscopy (WCE) is an emerging technology that aims to detect pathology in the patient gastrointestinal tract. Physicians can use WCE to detect various gastrointestinal diseases at early stages. However, the diagnosis is tedious because it requires reviewing hundreds of frames extracted from the captured video. This tedious task has promoted researchers' efforts to propose automated diagnosis tools of WCE frames in order to detect symptoms of gastrointestinal diseases. In this paper, we propose an automatic multiple bleeding spots detection using WCE video. The proposed approach relies on two main components: (1) a feature extraction intended to capture the visual properties of the multiple bleeding spots, and (2) a supervised and unsupervised learning techniques which aim to accurately recognize multiple bleeding.
C1 [Bchir, Ouiem; Ben Ismail, Mohamed Maher; AlZahrani, Nada] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh, Saudi Arabia.
C3 King Saud University
RP Ben Ismail, M (通讯作者)，King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh, Saudi Arabia.
EM mbenismail@ksu.edu.sa
OI benismail, maher/0000-0001-7770-5752
FU Research Center of the College of Computer and Information Sciences,
   King Saud University
FX The authors are grateful for the support by the Research Center of the
   College of Computer and Information Sciences, King Saud University.
CR Alotaibi Sarah, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P402, DOI 10.1007/978-3-642-40246-3_50
   [Anonymous], 1997, ANNU REV COMPUT SCI
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Davis J.C., 1986, STAT DATA ANAL GEOLO, V646
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509
   Health N.I.o. Health U.D.o. Services H., 2009, OPPORTUNITIES CHALLE
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Kara A, 2009, INT J ELECTRON, V96, P205, DOI 10.1080/00207210802524302
   Khun P. C, 2009, BIOMEDICAL PHARM ENG, P1
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li B, 2007, P IEEE INT C IM PROC, P437
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li CY, 2014, SIGNAL IMAGE VIDEO P, V8, P1497, DOI 10.1007/s11760-012-0384-3
   Manjunath B. S., 2002, INTRO MPEG 7 MULTIME
   Martinez-Herrera SE, 2016, SIGNAL IMAGE VIDEO P, V10, P455, DOI 10.1007/s11760-015-0779-z
   McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02459570
   Meyer Y., 1995, WAVELETS OPERATORS, V1
   Okun O, 2007, SIGNAL PROCESS, V87, P2260, DOI 10.1016/j.sigpro.2007.02.006
   QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6
   Serej ND, 2016, SIGNAL IMAGE VIDEO P, V10, P983, DOI 10.1007/s11760-015-0849-2
   Shah S. K, 2007, C URINE ASEE
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Winstone B, 2017, IEEE SENS J, V17, P848, DOI 10.1109/JSEN.2016.2627798
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
NR 31
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1863-1703
EI 1863-1711
J9 SIGNAL IMAGE VIDEO P
JI Signal Image Video Process.
PD FEB
PY 2019
VL 13
IS 1
BP 121
EP 126
DI 10.1007/s11760-018-1336-3
PG 6
WC Engineering, Electrical & Electronic; Imaging Science & Photographic
   Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Imaging Science & Photographic Technology
GA HK5OW
UT WOS:000458017000015
DA 2023-04-20
ER

PT J
AU Figueiredo, PN
   Figueiredo, IN
   Pinto, L
   Kumar, S
   Tsai, YHR
   Mamonov, AV
AF Figueiredo, Pedro N.
   Figueiredo, Isabel N.
   Pinto, Luis
   Kumar, Sunil
   Tsai, Yen-Hsi Richard
   Mamonov, Alexander V.
TI Polyp detection with computer-aided diagnosis in white light
   colonoscopy: comparison of three different methods
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID CLASSIFICATION; VALIDATION
AB Background and study aims Detection of polyps during colonoscopy is essential for screening colorectal cancer and computer-aided-diagnosis (CAD) could be helpful for this objective. The goal of this study was to assess the efficacy of CADin detection of polyps in video colonoscopy by using three methods we have proposed and applied for diagnosis of polyps in wireless capsule colonoscopy.
   Patients and methods Forty-two patients were included in the study, each one bearing one polyp.A dataset was generated with a total of 1680 polyp instances and 1360 frames of normal mucosa. We used three methods, that are all binary classifiers, labelling a frame as either containing a polyp or not. Two of the methods (Methods 1 and 2) are threshold-based and address the problem of polyp detection (i.e. separation between normal mucosa frames and polyp frames) and the problem of polyp localization (i.e. the ability to locate the polyp in a frame). The third method (Method 3) belongs to the class of machine learning methods and only addresses the polyp detection problem. The mathematical techniques underlying these three methods rely on appropriate fusion of information about the shape, color and texture content of the objects presented in the medical images.
   Results Regarding polyp localization, the best method is Method 1 with a sensitivity of 71.8%. Comparing the performance of the three methods in the detection of polyps, independently of the precision in the location of the lesions, Method 3 stands out, achieving a sensitivity of 99.7%, an accuracy of 91.1%, and a specificity of 84.9%.
   Conclusion CAD, using the three studied methods, showed good accuracy in the detection of polyps with white light colonoscopy.
C1 [Figueiredo, Pedro N.] Ctr Hosp & Univ Coimbra, Dept Gastroenterol, Coimbra, Portugal.
   [Figueiredo, Pedro N.] Univ Coimbra, Fac Med, Coimbra, Portugal.
   [Figueiredo, Pedro N.] Ctr Cirurg Coimbra, Coimbra, Portugal.
   [Figueiredo, Isabel N.; Pinto, Luis] Univ Coimbra, Dept Math, CMUC, Coimbra, Portugal.
   [Kumar, Sunil] Indian Inst Technol BHU Varanasi, Dept Math Sci, Varanasi, Uttar Pradesh, India.
   [Tsai, Yen-Hsi Richard] Univ Texas Austin, Dept Math, Austin, TX 78712 USA.
   [Tsai, Yen-Hsi Richard] Univ Texas Austin, Inst Computat Engn & Sci, Austin, TX 78712 USA.
   [Mamonov, Alexander V.] Univ Houston, Dept Math, Houston, TX 77204 USA.
C3 Universidade de Coimbra; Centro Hospitalar e Universitario de Coimbra
   (CHUC); Universidade de Coimbra; Universidade de Coimbra; Universidade
   de Coimbra; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology BHU Varanasi (IIT BHU Varanasi); University of
   Texas System; University of Texas Austin; University of Texas System;
   University of Texas Austin; University of Houston System; University of
   Houston
RP Figueiredo, PN (通讯作者)，Univ Coimbra, Fac Med, Gastroenterol, Polo 1 Rua Larga, P-3000504 Coimbra, Portugal.
EM pnf11@sapo.pt
RI Figueiredo, Isabel Narra/ABD-7828-2020; Kumar, Sunil/ABU-7487-2022;
   Mamonov, Alexander V/M-5315-2014; Kumar, Sunil/Q-8557-2016
OI Figueiredo, Isabel Narra/0000-0002-0215-8851; Mamonov, Alexander
   V/0000-0002-1270-7535; Kumar, Sunil/0000-0001-9991-1012; Figueiredo,
   Pedro/0000-0001-9872-6341; Pinto, Luis/0000-0003-1121-1738
FU FCT [POCI-01-0145-FEDER-028960]; Portuguese Government through FCT/MEC
   [CMUC-UID/MAT/00324/2013]; FCT scholarship [SFRH/BPD/112687/2015];
   European Regional Development Fund through the Partnership Agreement
   PT2020
FX This work was partially supported by the FCT research project
   POCI-01-0145-FEDER-028960. The authors Isabel N. Figueiredo and Luis
   Pinto also acknowledge some support from CMUC-UID/MAT/00324/2013, funded
   by the Portuguese Government through FCT/MEC and co-funded by the
   European Regional Development Fund through the Partnership Agreement
   PT2020. Luis Pinto was also supported by FCT scholarship
   SFRH/BPD/112687/2015.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Calderwood AH, 2010, GASTROINTEST ENDOSC, V72, P686, DOI 10.1016/j.gie.2010.06.068
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Figueiredo I N, 2014, COMPUTATIONAL VISION, P235
   Figueiredo I N, 2010, 20101065 UCLA CAM, P10
   Figueiredo Pedro N, 2011, Diagn Ther Endosc, V2011, P182435, DOI 10.1155/2011/182435
   Globecan, 2012, EST CANC INC MORT PR
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rex DK, 2015, DIGEST DIS SCI, V60, P639, DOI 10.1007/s10620-014-3448-0
   Schanda J, 2007, COLORIMETRY: UNDERSTANDING THE CIE SYSTEM, P1, DOI 10.1002/9780470175637
   Shaukat A, 2009, CLIN GASTROENTEROL H, V7, P1335, DOI 10.1016/j.cgh.2009.07.027
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
NR 21
TC 19
Z9 21
U1 0
U2 0
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD FEB
PY 2019
VL 7
IS 2
BP E209
EP E215
DI 10.1055/a-0808-4456
PG 7
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA HI0SP
UT WOS:000456153900010
PM 30705955
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Maeda, Y
   Kudo, S
   Mori, Y
   Misawa, M
   Ogata, N
   Sasanuma, S
   Wakamura, K
   Oda, M
   Mori, K
   Ohtsuka, K
AF Maeda, Yasuharu
   Kudo, Shin-ei
   Mori, Yuichi
   Misawa, Masashi
   Ogata, Noriyuki
   Sasanuma, Seiko
   Wakamura, Kunihiko
   Oda, Masahiro
   Mori, Kensaku
   Ohtsuka, Kazuo
TI Fully automated diagnostic system with artificial intelligence using
   endocytoscopy to identify the presence of histologic inflammation
   associated with ulcerative colitis
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; COLORECTAL LESIONS; ENDOSCOPY; SEVERITY;
   RELAPSE; RISK
AB Background and Aims: In the treatment of ulcerative colitis (UC), an incremental benefit of achieving histologic healing beyond that of endoscopic mucosal healing has been suggested; persistent histologic inflammation increases the risk of exacerbation and dysplasia. However, identification of persistent histologic inflammation is extremely difficult using conventional endoscopy. Furthermore, the reproducibility of endoscopic disease activity is poor. We developed and evaluated a computer-aided diagnosis (CAD) system to predict persistent histologic inflammation using endocytoscopy (EC; 520-fold ultra-magnifying endoscope).
   Methods: We evaluated the accuracy of the CAD system using test image sets. First, we retrospectively reviewed the data of 187 patients with UC from whom biopsy samples were obtained after endocytoscopic observation. EC images and biopsy samples of each patient were collected from 6 colorectal segments: cecum, ascending colon, transverse colon, descending colon, sigmoid colon, and rectum. All EC images were tagged with reference to the biopsy sample's histologic activity. For validation samples, 525 validation sets of 525 independent segments were collected from 100 patients, and 12,900 EC images from the remaining 87 patients were used for machine learning to construct CAD. The primary outcome measure was the diagnostic ability of CAD to predict persistent histologic inflammation. Its reproducibility for all test images was also assessed.
   Results: CAD provided diagnostic sensitivity, specificity, and accuracy as follows: 74% (95% confidence interval, 65%-81%), 97% (95% confidence interval, 95%-99%), and 91% (95% confidence interval, 83%-95%), respectively. Its reproducibility was perfect (kappa = 1).
   Conclusions: Our CAD system potentially allows fully automated identification of persistent histologic inflammation associated with UC.
C1 [Maeda, Yasuharu; Kudo, Shin-ei; Mori, Yuichi; Misawa, Masashi; Ogata, Noriyuki; Sasanuma, Seiko; Wakamura, Kunihiko] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, 35-1 Tuzuki, Yokohama, Kanagawa 2248503, Japan.
   [Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
   [Ohtsuka, Kazuo] Tokyo Med & Dent Univ, Endoscopy Dept, Tokyo, Japan.
C3 Showa University; Nagoya University; Tokyo Medical & Dental University
   (TMDU)
RP Maeda, Y (通讯作者)，Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, 35-1 Tuzuki, Yokohama, Kanagawa 2248503, Japan.
RI Mori, Yuichi/AAU-5406-2020; Misawa, Masashi/H-9004-2019
OI Misawa, Masashi/0000-0002-8520-2036; Mori, Yuichi/0000-0003-2262-0334;
   Oda, Masahiro/0000-0001-7714-422X
CR Bessho R, 2011, J GASTROENTEROL, V46, P1197, DOI 10.1007/s00535-011-0439-1
   Bessissow T, 2012, AM J GASTROENTEROL, V107, P1684, DOI 10.1038/ajg.2012.301
   Bryant RV, 2016, GUT, V65, P408, DOI 10.1136/gutjnl-2015-309598
   Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.7326/M14-0697, 10.1002/bjs.9736, 10.1016/j.eururo.2014.11.025, 10.1038/bjc.2014.639, 10.1016/j.jclinepi.2014.11.010, 10.1136/bmj.g7594, 10.1186/s12916-014-0241-z, 10.7326/M14-0698]
   Colombel JF, 2017, GUT, V66, P2063, DOI 10.1136/gutjnl-2016-312307
   Geboes K, 2000, GUT, V47, P404, DOI 10.1136/gut.47.3.404
   Iacucci M, 2017, GASTROINTEST ENDOSC, V86, P1118, DOI 10.1016/j.gie.2017.03.012
   Iacucci M, 2015, ENDOSCOPY, V47, P726, DOI 10.1055/s-0034-1391863
   Karstensen JG, 2016, GASTROINTEST ENDOSC, V84, P279, DOI 10.1016/j.gie.2016.01.069
   Kiesslich R, 2017, GASTROINTEST ENDOSC, V85, P496, DOI 10.1016/j.gie.2016.10.034
   Kudo SE, 2015, GASTROINTEST ENDOSC, V82, P912, DOI 10.1016/j.gie.2015.04.039
   Leggett CL, 2016, GASTROINTEST ENDOSC, V84, P842, DOI 10.1016/j.gie.2016.07.045
   Li CQ, 2014, BMC GASTROENTEROL, V14, DOI 10.1186/1471-230X-14-45
   Li CQ, 2010, AM J GASTROENTEROL, V105, P1391, DOI 10.1038/ajg.2009.664
   Maeda Y, 2015, WORLD J GASTROENTERO, V21, P2108, DOI 10.3748/wjg.v21.i7.2108
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nakazato Y, 2017, ENDOSCOPY, V49, P560, DOI 10.1055/s-0043-106556
   Neurath MF, 2012, GUT, V61, P1619, DOI 10.1136/gutjnl-2012-302830
   Osada T, 2010, INFLAMM BOWEL DIS, V16, P192, DOI 10.1002/ibd.21000
   Rutter M, 2004, GASTROENTEROLOGY, V126, P451, DOI 10.1053/j.gastro.2003.11.010
   SCHROEDER KW, 1987, NEW ENGL J MED, V317, P1625, DOI 10.1056/NEJM198712243172603
   Shergill AK, 2015, GASTROINTEST ENDOSC, V81, P1101, DOI 10.1016/j.gie.2014.10.030
   Travis SPL, 2012, GUT, V61, P535, DOI 10.1136/gutjnl-2011-300486
   Zenlea T, 2016, AM J GASTROENTEROL, V111, P685, DOI 10.1038/ajg.2016.50
NR 28
TC 102
Z9 107
U1 4
U2 18
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD FEB
PY 2019
VL 89
IS 2
BP 408
EP 415
DI 10.1016/j.gie.2018.09.024
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HI0VU
UT WOS:000456163300028
PM 30268542
OA hybrid
DA 2023-04-20
ER

PT J
AU Nakata, N
AF Nakata, Norio
TI Recent technical development of artificial intelligence for diagnostic
   medical imaging
SO JAPANESE JOURNAL OF RADIOLOGY
LA English
DT Review
DE Artificial intelligence; Deep learning; Computer vision
AB Deep learning has caused a third boom of artificial intelligence and great changes of diagnostic medical imaging systems such as radiology, pathology, retinal imaging, dermatology inspection, and endoscopic diagnosis will be expected in the near future. However, various attempts and new methods of deep learning have been proposed in recent years, and their progress is extremely fast. Therefore, at the initial stage when medical artificial intelligence papers were published, the artificial intelligence technology itself may be old technology or well-known general-purpose common technology. Therefore, the author has reviewed state-of-the-art computer vision papers and presentations of 2018 using deep learning technologies, which will have future clinical potentials selected from the point of view of a radiologist such as generative adversarial network, knowledge distillation, and general image data sets for supervised learning.
C1 [Nakata, Norio] Jikei Univ, Sch Med, Dept Radiol, Minato Ku, 3-25-8 Nishi Shimbashi, Tokyo 1058461, Japan.
C3 Jikei University
RP Nakata, N (通讯作者)，Jikei Univ, Sch Med, Dept Radiol, Minato Ku, 3-25-8 Nishi Shimbashi, Tokyo 1058461, Japan.
EM nakata@jikei.ac.jp
FU Grants-in-Aid for Scientific Research [17K10374] Funding Source: KAKEN
CR Bengio Y., 2014, ARXIV14126550
   Choi Y., 2017, 1711 ARXIV
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Esuli A., 2009, COMPUTING RES REPOSI
   Furlanello T, 2018, PR MACH LEARN RES, V80
   Gao J, 2017, ARXIV171107607
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Hinton G., 2015, ARXIV
   Huang X, 2017, PROC CVPR IEEE, P1866, DOI 10.1109/CVPR.2017.202
   Isola P., 2017, PROC 30 IEEE C COMPU, P1125, DOI DOI 10.1109/CVPR.2017.632
   Japanese Ministry of Health Labor and Welfare, PROM AI HLTH CAR FIE
   Karras T, 2017, ARXIV71010196
   Li N., 2011, EDM 2011 P 4 INT C E, P31
   Mirza M., 2014, CONDITIONAL GENERATI, DOI 10.48550/arXiv.1411.1784
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   National Highway Traffic Safety Administration, PREL STAT POL AUT VE
   Odena A., 2017, ARXIV161009585
   Park T., 2017, ICCV, DOI DOI 10.1109/ICCV.2017.244
   Radford A., 2015, COMPUTER SCI
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Vondrick C, 2013, INT J COMPUT VISION, V101, P184, DOI 10.1007/s11263-012-0564-1
   Zhang H., 2018, ICML
NR 22
TC 17
Z9 18
U1 8
U2 61
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1867-1071
EI 1867-108X
J9 JPN J RADIOL
JI Jpn. J. Radiol.
PD FEB
PY 2019
VL 37
IS 2
BP 103
EP 108
DI 10.1007/s11604-018-0804-6
PG 6
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA HK3ZB
UT WOS:000457857100001
PM 30706381
DA 2023-04-20
ER

PT J
AU Ozawa, T
   Ishihara, S
   Fujishiro, M
   Saito, H
   Kumagai, Y
   Shichijo, S
   Aoyama, K
   Tada, T
AF Ozawa, Tsuyoshi
   Ishihara, Soichiro
   Fujishiro, Mitsuhiro
   Saito, Hiroaki
   Kumagai, Youichi
   Shichijo, Satoki
   Aoyama, Kazuharu
   Tada, Tomohiro
TI Novel computer-assisted diagnosis system for endoscopic disease activity
   in patients with ulcerative colitis
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID CONVOLUTIONAL NEURAL-NETWORKS; INFLAMMATORY-BOWEL-DISEASE; DEEP;
   INCREASE
AB Background and Aims: Evaluation of endoscopic disease activity for patients with ulcerative colitis (UC) is important when determining the treatment of choice. However, endoscopists require a certain period of training to evaluate the activity of inflammation properly, and interobserver variability exists. Therefore, we constructed a computer-assisted diagnosis (CAD) system using a convolutional neural network (CNN) and evaluated its performance using a large dataset of endoscopic images from patients with UC.
   Methods: A CNN-based CAD system was constructed based on GoogLeNet architecture. The CNN was trained using 26,304 colonoscopy images from a cumulative total of 841 patients with UC, which were tagged with anatomic locations and Mayo endoscopic scores. The performance of the CNN in identifying normal mucosa (Mayo 0) and mucosal healing state (Mayo 0-1) was evaluated in an independent test set of 3981 images from 114 patients with UC, by calculating the areas under the receiver operating characteristic curves (AUROCs). In addition, AUROCs in the right side of the colon, left side of the colon, and rectum were evaluated.
   Results: The CNN-based CAD system showed a high level of performance with AUROCs of 0.86 and 0.98 to identify Mayo 0 and 0-1, respectively. The performance of the CNN was better for the rectum than for the right side and left side of the colon when identifying Mayo 0 (AUROC = 0.92, 0.83, and 0.83, respectively).
   Conclusions: The performance of the CNN-based CAD system was robust when used to identify endoscopic inflammation severity in patients with UC, highlighting its promising role in supporting less-experienced endoscopists and reducing interobserver variability.
C1 [Ozawa, Tsuyoshi; Ishihara, Soichiro; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
   [Ozawa, Tsuyoshi] Teikyo Univ, Dept Surg, Sch Med, Tokyo, Japan.
   [Ishihara, Soichiro] Int Univ Hlth & Welf, Sanno Hosp, Dept Surg, Tokyo, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Fujishiro, Mitsuhiro] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Saito, Hiroaki] Sendai Kousei Hosp, Dept Gastroenterol, Sendai, Miyagi, Japan.
   [Kumagai, Youichi] Saitama Med Univ, Saitama Med Ctr, Dept Digest Tract & Gen Surg, Saitama, Japan.
   [Shichijo, Satoki] Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Osaka, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] Al Med Serv Inc, Tokyo, Japan.
C3 Teikyo University; International University of Health & Welfare;
   University of Tokyo; University of Tokyo; Sendai Kousei Hospital;
   Saitama Medical University
RP Ozawa, T (通讯作者)，Teikyo Univ, Dept Surg, Sch Med, Itabashi Ku, 2-11-1 Kaga, Tokyo, Japan.
RI Ishihara, Soichiro/AFK-1375-2022; SAITO, HIROAKI/HLH-2447-2023; 藤城,
   光弘/AAN-3131-2020
OI SAITO, HIROAKI/0000-0002-0824-454X; Fujishiro,
   Mitsuhiro/0000-0002-4074-1140
CR Araujo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   Bouguen G, 2014, INFLAMM BOWEL DIS, V20, P231, DOI 10.1097/01.MIB.0000437985.00190.aa
   Bryant RV, 2018, J GASTROEN HEPATOL, V33, P599, DOI 10.1111/jgh.13923
   D'Haens G, 2007, GASTROENTEROLOGY, V132, P763, DOI 10.1053/j.gastro.2006.12.038
   Daperno M, 2017, J CROHNS COLITIS, V11, P556, DOI 10.1093/ecco-jcc/jjw181
   Duijvestein Marjolijn, 2018, Curr Treat Options Gastroenterol, V16, P129, DOI 10.1007/s11938-018-0175-1
   Farrell RJ, 2002, LANCET, V359, P331, DOI 10.1016/S0140-6736(02)07499-8
   Feagan BG, 2013, GASTROENTEROLOGY, V145, P149, DOI 10.1053/j.gastro.2013.03.025
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Joo M, 2010, AM J SURG PATHOL, V34, P689, DOI 10.1097/PAS.0b013e3181db84cd
   Kaplan GG, 2017, GASTROENTEROLOGY, V152, P313, DOI 10.1053/j.gastro.2016.10.020
   Ket Shara Nguyen, 2015, Curr Gastroenterol Rep, V17, P50, DOI 10.1007/s11894-015-0470-0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mazzuoli S, 2013, DIGEST LIVER DIS, V45, P969, DOI 10.1016/j.dld.2013.06.010
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mohammed VN, 2018, COCHRANE DB SYST REV, V16
   Naganuma M, 2018, J GASTROENTEROL, V53, P494, DOI 10.1007/s00535-017-1376-4
   Reinink AR, 2016, INFLAMM BOWEL DIS, V22, P1859, DOI 10.1097/MIB.0000000000000816
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Xie TB, 2018, GASTROENTEROL REP, V6, P38, DOI 10.1093/gastro/gox016
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
NR 24
TC 94
Z9 99
U1 3
U2 24
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD FEB
PY 2019
VL 89
IS 2
BP 416
EP +
DI 10.1016/j.gie.2018.10.020
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HI0VU
UT WOS:000456163300029
PM 30367878
DA 2023-04-20
ER

PT J
AU Passos, LA
   de Souza, LA
   Mendel, R
   Ebigbo, A
   Probst, A
   Messmann, H
   Palm, C
   Papa, JP
AF Passos, Leandro A.
   de Souza, Luis A., Jr.
   Mendel, Robert
   Ebigbo, Alanna
   Probst, Andreas
   Messmann, Helmut
   Palm, Christoph
   Papa, Joao Paulo
TI Barrett's esophagus analysis using infinity Restricted Boltzmann
   Machines
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Barrett's esophagus; Infinity Restricted Boltzmann Machines;
   Meta-heuristics; Deep learning
ID NEURAL-NETWORKS; ALGORITHM; ADENOCARCINOMA; DYSPLASIA; FEATURES
AB The number of patients with Barret's esophagus (BE) has increased in the last decades. Considering the dangerousness of the disease and its evolution to adenocarcinoma, an early diagnosis of BE may provide a high probability of cancer remission. However, limitations regarding traditional methods of detection and management of BE demand alternative solutions. As such, computer-aided tools have been recently used to assist in this problem, but the challenge still persists. To manage the problem, we introduce the infinity Restricted Boltzmann Machines (iRBMs) to the task of automatic identification of Barrett's esophagus from endoscopic images of the lower esophagus. Moreover, since iRBM requires a proper selection of its meta-parameters, we also present a discriminative iRBM fine-tuning using six meta-heuristic optimization techniques. We showed that iRBMs are suitable for the context since it provides competitive results, as well as the meta-heuristic techniques showed to be appropriate for such task. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Passos, Leandro A.; de Souza, Luis A., Jr.] Univ Fed Sao Carlos, UFSCAR, Dept Comp, BR-13565905 Sao Carlos, SP, Brazil.
   [Ebigbo, Alanna; Probst, Andreas; Messmann, Helmut] Klinikum Augsburg III, Med Klin, D-86156 Augsburg, Germany.
   [Mendel, Robert; Palm, Christoph] OTH Regensburg, Ostbayer Tech Hsch Regensburg, Regensburg Med Image Comp ReMIC, D-93053 Regensburg, Germany.
   [Mendel, Robert; Palm, Christoph] OTH Regensburg, Regensburg Ctr Hlth Sci & Technol, D-93053 Regensburg, Germany.
   [Papa, Joao Paulo] Sao Paulo State Univ, UNESP, Dept Comp, BR-17033360 Bauru, Brazil.
C3 Universidade Federal de Sao Carlos; Klinikum Augsburg; Universidade
   Estadual Paulista
RP Papa, JP (通讯作者)，Sao Paulo State Univ, UNESP, Dept Comp, BR-17033360 Bauru, Brazil.
EM leandropassosjr@gmail.com; luis.souza@dc.ufscar.br;
   robert.mendel@st.oth-regensburg.de; alana.ebigbo@klinikum-augsburg.de;
   andreas.probst@klinikum-augsburg.de;
   helmut.messmann@klinikum-augsburg.de; christoph.palm@oth-regensburg.de;
   papa@fc.unesp.br
RI Passos, Leandro/AAV-9635-2020; Ebigbo, Alanna/ACP-0443-2022; Palm,
   Christoph/F-4943-2014; Messmann, Helmut/AAB-6758-2020; Papa, Joao
   Paulo/ABC-6283-2020; Messmann, Helmut/AAQ-3568-2021
OI Passos, Leandro/0000-0003-3529-3109; Palm,
   Christoph/0000-0001-9468-2871; Papa, Joao Paulo/0000-0002-6494-7514;
   Souza Jr., Luis Antonio/0000-0002-7060-6097
FU FAPESP [2013/07375-0, 2014/16250-9, 2014/12236-1, 2015/25739-4,
   2016/21243-7]; Capes; CNPq [306166/2014-3, 307066/2017-7];
   Capes/Alexander von Humboldt Foundation [BEX 0581-16-0]; Intel Al
   Academy program under FUNDUNESP [2597.2017]
FX The authors would like to thank FAPESP grants #2013/07375-0,
   #2014/16250-9, #2014/12236-1, #2015/25739-4 and #2016/21243-7, as well
   as Capes, and CNPq grants #306166/2014-3, #307066/2017-7 and
   Capes/Alexander von Humboldt Foundation grant #BEX 0581-16-0. This
   material is based upon work supported in part by funds provided by Intel
   Al Academy program under FUNDUNESP Grant No. 2597.2017.
CR [Anonymous], 2015, P GENETIC EVOLUTIONA
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cote MA, 2016, NEURAL COMPUT, V28, P1265, DOI 10.1162/NECO_a_00848
   Csurka G., 2004, WORKSH STAT LEARN CO, V44, P1, DOI DOI 10.1234/12345678
   da Silva LA, 2016, IADIS-INT J COMPUT S, V11, P99
   de Souza LA, 2018, COMPUT BIOL MED, V96, P203, DOI 10.1016/j.compbiomed.2018.03.014
   Dent J, 2011, J GASTROEN HEPATOL, V26, P11, DOI 10.1111/j.1440-1746.2010.06535.x
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Fiore U, 2013, NEUROCOMPUTING, V122, P13, DOI 10.1016/j.neucom.2012.11.050
   Geem ZW, 2009, STUD COMPUT INTELL, V191, P113
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Johnston MH, 2005, GASTROINTEST ENDOSC, V62, P842, DOI 10.1016/j.gie.2005.05.008
   Lagergren J., 2010, BMJ, V341
   Larochelle H., 2008, PROC 25 INT C MACH L, P536, DOI DOI 10.1145/1390156.1390224
   Larochelle H, 2012, J MACH LEARN RES, V13, P643
   Lepage C, 2008, AM J GASTROENTEROL, V103, P2694, DOI 10.1111/j.1572-0241.2008.02191.x
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mendel R., 2017, BARRETTS ESOPHAGUS A
   Montufar G, 2011, NEURAL COMPUT, V23, P1306, DOI 10.1162/NECO_a_00113
   Overholt BF, 2003, GASTROINTEST ENDOSC, V58, P183, DOI 10.1067/mge.2003.327
   Papa J.a.P., 2017, BILDVERARBEITUNG F R, P141, DOI [10.1007/978-3-662-54345-0, DOI 10.1007/978-3-662-54345-0]
   Papa JP, 2009, INT J IMAG SYST TECH, V19, P120, DOI 10.1002/ima.20188
   Papa J.P., ARXIV170405174
   Papa JP, 2015, J COMPUT SCI-NETH, V9, P14, DOI 10.1016/j.jocs.2015.04.014
   Papa JP, 2012, PATTERN RECOGN, V45, P512, DOI 10.1016/j.patcog.2011.07.013
   Papa JP, 2016, APPL SOFT COMPUT, V46, P875, DOI 10.1016/j.asoc.2015.08.043
   Passos LA, 2017, SIBGRAPI, P63, DOI 10.1109/SIBGRAPI.2017.15
   Peng X., ARXIV170903239
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Phoa KN, 2016, GUT, V65, P555, DOI 10.1136/gutjnl-2015-309298
   Rodrigues D, 2016, BIO-INSPIRED COMPUTATION AND APPLICATIONS IN IMAGE PROCESSING, P47, DOI 10.1016/B978-0-12-804536-7.00003-X
   Rodrigues D., 2015, RECENT ADV SWARM INT, P85, DOI DOI 10.1007/978-3-319-13826-8_5
   Rosa G., 2016, LEARNING PARAMETERS
   Rosa G, 2015, LECT NOTES COMPUT SC, V9423, P683, DOI 10.1007/978-3-319-25751-8_82
   Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Salakhutdinov R, 2012, NEURAL COMPUT, V24, P1967, DOI 10.1162/NECO_a_00311
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shaheen NJ, 2009, NEW ENGL J MED, V360, P2277, DOI 10.1056/NEJMoa0808145
   Sharma P, 2016, GASTROENTEROLOGY, V150, P591, DOI 10.1053/j.gastro.2015.11.037
   Shi YH, 2011, LECT NOTES COMPUT SC, V6728, P303, DOI 10.1007/978-3-642-21515-5_36
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   Taylor G. E., 2006, ADV NEURAL INFORM PR, P1345
   Tieleman Tijmen, 2008, P 25 INT C MACHINE L, P1064, DOI 10.1145/1390156.1390290
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
NR 52
TC 7
Z9 7
U1 3
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 475
EP 485
DI 10.1016/j.jvcir.2019.01.043
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600051
DA 2023-04-20
ER

PT J
AU Shichijo, S
   Endo, Y
   Aoyama, K
   Takeuchi, Y
   Ozawa, T
   Takiyama, H
   Matsuo, K
   Fujishiro, M
   Ishihara, S
   Ishihara, R
   Tada, T
AF Shichijo, Satoki
   Endo, Yuma
   Aoyama, Kazuharu
   Takeuchi, Yoshinori
   Ozawa, Tsuyoshi
   Takiyama, Hirotoshi
   Matsuo, Keigo
   Fujishiro, Mitsuhiro
   Ishihara, Soichiro
   Ishihara, Ryu
   Tada, Tomohiro
TI Application of convolutional neural networks for evaluating Helicobacter
   pylori infection status on the basis of endoscopic images
SO SCANDINAVIAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Eradication therapy; endoscopy; artificial intelligence; gastritis
ID GASTRIC-CANCER; INTESTINAL METAPLASIA; ERADICATION; CLASSIFICATION;
   PREVENTION; PREDICTORS; RESECTION; ANTIBODY; THERAPY
AB Background and aim: We recently reported the role of artificial intelligence in the diagnosis of Helicobacter pylori (H. pylori) gastritis on the basis of endoscopic images. However, that study included only H. pylori-positive and -negative patients, excluding patients after H. pylori-eradication. In this study, we constructed a convolutional neural network (CNN) and evaluated its ability to ascertain all H. pylori infection statuses.Methods: A deep CNN was pre-trained and fine-tuned on a dataset of 98,564 endoscopic images from 5236 patients (742 H. pylori-positive, 3649 -negative, and 845 -eradicated). A separate test data set (23,699 images from 847 patients; 70 positive, 493 negative, and 284 eradicated) was evaluated by the CNN.Results: The trained CNN outputs a continuous number between 0 and 1 as the probability index for H. pylori infection status per image (Pp, H. pylori-positive; Pn, negative; Pe, eradicated). The most probable (largest number) of the three infectious statuses was selected as the CNN diagnosis'. Among 23,699 images, the CNN diagnosed 418 images as positive, 23,034 as negative, and 247 as eradicated. Because of the large number of H. pylori negative findings, the probability of H. pylori-negative was artificially re-defined as Pn -0.9, after which 80% (465/582) of negative diagnoses were accurate, 84% (147/174) eradicated, and 48% (44/91) positive. The time needed to diagnose 23,699 images was 261seconds.Conclusion: We used a novel algorithm to construct a CNN for diagnosing H. pylori infection status on the basis of endoscopic images very quickly.Abbreviations:H. pylori: Helicobacter pylori; CNN: convolutional neural network; AI: artificial intelligence; EGD: esophagogastroduodenoscopies.
C1 [Shichijo, Satoki; Ishihara, Ryu] Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Osaka, Japan.
   [Endo, Yuma; Aoyama, Kazuharu; Tada, Tomohiro] AI Med Serv, Tokyo, Japan.
   [Takeuchi, Yoshinori] Univ Tokyo, Sch Publ Hlth, Grad Sch Med, Dept Biostat, Tokyo, Japan.
   [Ozawa, Tsuyoshi] Teikyo Univ Hosp, Dept Colorectal Surg, Tokyo, Japan.
   [Takiyama, Hirotoshi] Natl Inst Quantum & Radiol Sci & Technol, Hosp Natl Inst Radiol Sci, Chiba, Japan.
   [Matsuo, Keigo] Tokatsu Tsujinaka Hosp, Dept Gastroenterol, Chiba, Japan.
   [Fujishiro, Mitsuhiro] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Fujishiro, Mitsuhiro] Nagoya Univ, Grad Sch Med, Dept Gastroenterol, Nagoya, Aichi, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
C3 University of Tokyo; Teikyo University; National Institutes for Quantum
   Science & Technology; University of Tokyo; Nagoya University; University
   of Tokyo
RP Shichijo, S (通讯作者)，Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Chuo Ku, 3-1-69 Otemae, Osaka 5418567, Japan.
EM shichijiyou-tky@umin.ac.jp
RI Ishihara, Soichiro/AFK-1375-2022; 藤城, 光弘/AAN-3131-2020
OI Fujishiro, Mitsuhiro/0000-0002-4074-1140
CR [Anonymous], 2016, HELICOBACTER PYLORI, DOI DOI 10.1007/978-4-431-55705-0_10
   Asaka M, 2015, GASTROENTEROL CLIN N, V44, P639, DOI 10.1016/j.gtc.2015.05.010
   Asaka M, 2010, HELICOBACTER, V15, P1, DOI 10.1111/j.1523-5378.2009.00738.x
   Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Choi IJ, 2018, NEW ENGL J MED, V378, P1085, DOI 10.1056/NEJMoa1708423
   CORREA P, 1995, AM J SURG PATHOL, V19, pS37
   Correa P, 2007, GASTROENTEROLOGY, V133, P659, DOI 10.1053/j.gastro.2007.06.026
   de Vries AC, 2009, AM J GASTROENTEROL, V104, P1342, DOI 10.1038/ajg.2008.15
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ferwana M, 2015, WORLD J GASTROENTERO, V21, P1305, DOI 10.3748/wjg.v21.i4.1305
   FORD AC, 2014, BMJ-BRIT MED J, V348, DOI DOI 10.1136/BMJ.G3174
   Fukase K, 2008, LANCET, V372, P392, DOI 10.1016/S0140-6736(08)61159-9
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hori K, 2016, DIGEST DIS SCI, V61, P1641, DOI 10.1007/s10620-015-3887-2
   Kato M, 2000, HELICOBACTER, V5, P109, DOI 10.1046/j.1523-5378.2000.00017.x
   Kimura K, 1969, ENDOSCOPY, V1, P87, DOI [10.1055/s-0028-1098086, DOI 10.1055/S-0028-1098086]
   Kitamura Y, 2014, HELICOBACTER, V19, P289, DOI 10.1111/hel.12132
   Kodama M, 2012, J GASTROENTEROL, V47, P394, DOI 10.1007/s00535-011-0504-9
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Murakami K, 2011, CLIN LAB, V57, P481
   O'Connor A, 2017, NAT REV GASTRO HEPAT, V14, P230, DOI 10.1038/nrgastro.2016.195
   Ogura K, 2008, J CLIN GASTROENTEROL, V42, P279, DOI 10.1097/01.mcg.0000248006.80699.7f
   Sato M, 2012, J GASTROEN HEPATOL, V27, P23, DOI 10.1111/j.1440-1746.2012.07066.x
   Shichijo S, 2018, WORLD J GASTROENTERO, V24, P2163, DOI 10.3748/wjg.v24.i20.2163
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shichijo S, 2017, J GASTROEN HEPATOL, V32, P1581, DOI 10.1111/jgh.13764
   Shichijo S, 2016, GASTROINTEST ENDOSC, V84, P618, DOI 10.1016/j.gie.2016.03.791
   Shichijo S, 2015, J GASTROEN HEPATOL, V30, P1260, DOI 10.1111/jgh.12946
   Sugano K, 2015, GUT, V64, P1353, DOI 10.1136/gutjnl-2015-309252
   Suzuki H, 2018, J GASTROENTEROL, V53, P354, DOI 10.1007/s00535-017-1407-1
   Take S, 2015, J GASTROENTEROL, V50, P638, DOI 10.1007/s00535-014-1004-5
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
   Wong BCY, 2004, JAMA-J AM MED ASSOC, V291, P187, DOI 10.1001/jama.291.2.187
   Yoon SB, 2014, HELICOBACTER, V19, P243, DOI 10.1111/hel.12146
NR 39
TC 45
Z9 45
U1 3
U2 11
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0036-5521
EI 1502-7708
J9 SCAND J GASTROENTERO
JI Scand. J. Gastroenterol.
PD FEB 1
PY 2019
VL 54
IS 2
BP 158
EP 163
DI 10.1080/00365521.2019.1577486
PG 6
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HY9LR
UT WOS:000468463000005
PM 30879352
DA 2023-04-20
ER

PT J
AU Sundaram, PS
   Santhiyakumari, N
AF Sundaram, P. Shanmuga
   Santhiyakumari, N.
TI An Enhancement of Computer Aided Approach for Colon Cancer Detection in
   WCE Images Using ROI Based Color Histogram and SVM2
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Colon cancer; Computer aided approach; ROI extraction; Image clustering;
   Feature extraction; SVM2 classifier
ID CAPSULE ENDOSCOPY; DIAGNOSIS SYSTEM; DISEASE
AB The colon cancer is formed by uncontrollable growth of abnormal cells in large intestine or colon that can affect both men and women and it is third cancer disease in the world. At present, Wireless Capsule Endoscopy (WCE) screening method is utilized to identify colon cancer tumor at early stage to save the patient life who affected by the colon cancer. In this CTC method, the radiologist needs to analyze the colon polyps in digital image using computer aided approach with accurate automatic tumor classification to detect the cancer tumor at early stage. This kind of computer aided approach can operate as an intermediate between input digital image and radiologist. Therefore, in this paper, a novel computer aided approach is presented with ROI based color histogram and SVM2 to find the cancer tumor in WCE image. In this method, the digital WCE image can be preprocessed using filtering and ROI based color histogram depending on the salient region in colon. In common, the salient region can be distinctive because of low redundancy. Hence, the saliency is estimated by ROI based color histogram on the basis of color and structure contrast in given colon image for the further process of clustering and tumor classification in WCE image. The K-means clustering can be employed to cluster the preprocessed digital image to discover the tumor of colon. Subsequently, the features are extracted from the image in terms of contrast, correlation, energy and homogeneity by applying SGLDM method. The SVM2 classifier as input to classify the tumor is normal or malignancy using selected feature vectors. Here, the extracted features can also being combined to enhance the hybrid feature vector for the accurate tumor classification. Experimental results of proposed method can show that this presented technique can executes can tumor detection in colon image accurately reaching almost 95% in evaluation with existing algorithms.
C1 [Sundaram, P. Shanmuga; Santhiyakumari, N.] Knowledge Inst Technol, Dept Elect & Commun Engn, Salem, Tamil Nadu, India.
RP Sundaram, PS (通讯作者)，Knowledge Inst Technol, Dept Elect & Commun Engn, Salem, Tamil Nadu, India.
EM psece@kiot.ac.in
RI Nagaraj, Santhiyakumari/HGE-9332-2022
OI Nagaraj, Santhiyakumari/0000-0001-5746-6352
CR [Anonymous], PERS UBIQUIT COMPUT
   [Anonymous], 2018, DES AUTOM EMBED SYST
   BARBOSA DJC, 2008, 30 ANN INT IEEE EMBS
   Basha AA, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0055-z
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Gunasekaran M., 2018, J AMB INTEL HUM COMP, V58, P1
   Karargyris A, 2011, IEEE T MED IMAGING, V30, P957, DOI 10.1109/TMI.2010.2098882
   Karargyris A, 2009, I S BIOMED IMAGING, P554, DOI 10.1109/ISBI.2009.5193107
   Kumar PM, 2018, COMPUT NETW, V144, P154, DOI 10.1016/j.comnet.2018.07.001
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Lokesh S., 2018, NEURAL COMPUT APPL, V2018, P1
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Manogaran G., 2018, IEEE ACCESS
   Mittal Sareena Ajay, 2016, INT C INV COMP TECHN, V1, P1
   Park CH, 2007, DIGEST DIS SCI, V52, P1405, DOI 10.1007/s10620-006-9122-4
   Parthasarathy Panchatchram, 2018, World Review of Science, Technology and Sustainable Development, V14, P52
   Parthasarathy P., 2018, Informatics in Medicine Unlocked, V12, P143, DOI 10.1016/j.imu.2018.03.001
   Parthasarathy P, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0043-3
   Parthasarathy P., 2018, IOP C SERIES MAT SCI, V360
   Parthasarathy P., 2018, INT J COMPUT APPL, P1
   Parthasarathy P, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0058-9
   Rathore S, 2013, IEEE ACM T COMPUT BI, V10, P545, DOI 10.1109/TCBB.2013.84
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sundarasekar R, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1093-4
   Varatharajan R, 2018, MULTIMED TOOLS APPL, P1
   Vijayakumar V., 2018, MOBILE NETW APPL, P1
NR 27
TC 17
Z9 17
U1 1
U2 10
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD FEB
PY 2019
VL 43
IS 2
AR 29
DI 10.1007/s10916-018-1153-9
PG 8
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA HG3UU
UT WOS:000454901000006
PM 30612188
DA 2023-04-20
ER

PT J
AU Yoon, H
   Lee, J
   Oh, JE
   Kim, HR
   Lee, S
   Chang, HJ
   Sohn, DK
AF Yoon, Hongjun
   Lee, Joohyung
   Oh, Ji Eun
   Kim, Hong Rae
   Lee, Seonhye
   Chang, Hee Jin
   Sohn, Dae Kyung
TI Tumor Identification in Colorectal Histology Images Using a
   Convolutional Neural Network
SO JOURNAL OF DIGITAL IMAGING
LA English
DT Article
DE Colonoscopic biopsy; Convolutional neural network; Histology image;
   Visual geometry group
ID CLASSIFICATION
AB Colorectal cancer (CRC) is a major global health concern. Its early diagnosis is extremely important, as it determines treatment options and strongly influences the length of survival. Histologic diagnosis can be made by pathologists based on images of tissues obtained from a colonoscopic biopsy. Convolutional neural networks (CNNs)-i.e., deep neural networks (DNNs) specifically adapted to image data-have been employed to effectively classify or locate tumors in many types of cancer. Colorectal histology images of 28 normal and 29 tumor samples were obtained from the National Cancer Center, South Korea, and cropped into 6806 normal and 3474 tumor images. We developed five modifications of the system from the Visual Geometry Group (VGG), the winning entry in the classification task in the 2014 ImageNet Large Scale Visual Recognition Competition (ILSVRC) and examined them in two experiments. In the first experiment, we determined the best modified VGG configuration for our partial dataset, resulting in accuracies of 82.50%, 87.50%, 87.50%, 91.40%, and 94.30%, respectively. In the second experiment, the best modified VGG configuration was applied to evaluate the performance of the CNN model. Subsequently, using the entire dataset on the modified VGG-E configuration, the highest results for accuracy, loss, sensitivity, and specificity, respectively, were 93.48%, 0.4385, 95.10%, and 92.76%, which equates to correctly classifying 294 normal images out of 309 and 667 tumor images out of 719.
C1 [Yoon, Hongjun; Lee, Joohyung; Oh, Ji Eun; Kim, Hong Rae; Lee, Seonhye; Sohn, Dae Kyung] Natl Canc Ctr, Innovat Med Engn & Technol Branch, Res Inst & Hosp, Goyang, Gyeonggi, South Korea.
   [Yoon, Hongjun] Syracuse Univ, Coll Engn & Comp Sci, Syracuse, NY USA.
   [Chang, Hee Jin; Sohn, Dae Kyung] Natl Canc Ctr, Ctr Colorectal Canc, Res Inst & Hosp, 323 Ilsan Ro, Goyang Si 10408, Gyeonggi Do, South Korea.
C3 National Cancer Center - Korea (NCC); Syracuse University; National
   Cancer Center - Korea (NCC)
RP Sohn, DK (通讯作者)，Natl Canc Ctr, Innovat Med Engn & Technol Branch, Res Inst & Hosp, Goyang, Gyeonggi, South Korea.; Sohn, DK (通讯作者)，Natl Canc Ctr, Ctr Colorectal Canc, Res Inst & Hosp, 323 Ilsan Ro, Goyang Si 10408, Gyeonggi Do, South Korea.
EM gsgsbal@ncc.re.kr
RI Lee, Joohyung/U-6821-2019
OI Lee, Joohyung/0000-0002-3518-7915
FU National Cancer Center [NCC-1710070, NCC-1511670]; Chungcheongbukdo
   Value Creation Program; Osong Medical Innovation Foundation of Korea -
   (Chungcheongbuk-do)
FX This work was supported by the National Cancer Center (grant numbers
   NCC-1710070 and NCC-1511670) and the Chungcheongbukdo Value Creation
   Program (through the Osong Medical Innovation Foundation of Korea,
   funded by the Chungcheongbuk-do). The funding sources had no role in the
   study design: in the collection, analysis, and interpretation of data;
   in the writing of the manuscript; or in the decision to submit the
   manuscript for publication.
CR [Anonymous], 2014, IMAGENET LARGE SCALE
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Bengio Y, 2009, LEARNING DEEP ARCHIT
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Geron Aurelien, 2017, HANDS ON MACHINE LEA
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Joshi P, PERPETUAL ENIGMA
   Jung KW, 2018, CANCER RES TREAT, V50, P303, DOI 10.4143/crt.2018.143
   Nicholson CV, 2018, BEGINNERS GUIDE DEEP
   Simonyan K., 2015, INT C LEARNING REPRE
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Tang S, OBJECT DETECTION BAS
   Teramoto A, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/4067832
   Torre LA, 2015, CA-CANCER J CLIN, V65, P87, DOI 10.3322/caac.21262
NR 15
TC 26
Z9 27
U1 1
U2 19
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0897-1889
EI 1618-727X
J9 J DIGIT IMAGING
JI J. Digit. Imaging
PD FEB
PY 2019
VL 32
IS 1
BP 131
EP 140
DI 10.1007/s10278-018-0112-9
PG 10
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA HN1KG
UT WOS:000459945300014
PM 30066123
OA Green Published
DA 2023-04-20
ER

PT J
AU Ahmad, OF
   Soares, AS
   Mazomenos, E
   Brandao, P
   Vega, R
   Seward, E
   Stoyanov, D
   Chand, M
   Lovat, LB
AF Ahmad, Omer F.
   Soares, Antonio S.
   Mazomenos, Evangelos
   Brandao, Patrick
   Vega, Roser
   Seward, Edward
   Stoyanov, Danail
   Chand, Manish
   Lovat, Laurence B.
TI Artificial intelligence and computer-aided diagnosis in colonoscopy:
   current evidence and future directions
SO LANCET GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Review
ID COLORECTAL POLYP HISTOLOGY; ADENOMA DETECTION; EUROPEAN-SOCIETY; OPTICAL
   BIOPSY; SCREENING COLONOSCOPY; QUALITY INDICATORS; COLON POLYPS; SYSTEM;
   LESIONS; CLASSIFICATION
AB Computer-aided diagnosis offers a promising solution to reduce variation in colonoscopy performance. Pooled miss rates for polyps are as high as 22%, and associated interval colorectal cancers after colonoscopy are of concern. Optical biopsy, whereby in-vivo classification of polyps based on enhanced imaging replaces histopathology, has not been incorporated into routine practice because it is limited by interobserver variability and generally only meets accepted standards in expert settings. Real-time decision-support software has been developed to detect and characterise polyps, and also to offer feedback on the technical quality of inspection. Some of the current algorithms, particularly with recent advances in artificial intelligence techniques, match human expert performance for optical biopsy. In this Review, we summarise the evidence for clinical applications of computer-aided diagnosis and artificial intelligence in colonoscopy.
C1 [Ahmad, Omer F.; Mazomenos, Evangelos; Brandao, Patrick; Stoyanov, Danail; Lovat, Laurence B.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, London W1W 7TS, England.
   [Soares, Antonio S.; Chand, Manish; Lovat, Laurence B.] UCL, Div Surg & Intervent Sci, London, England.
   [Ahmad, Omer F.; Vega, Roser; Seward, Edward; Chand, Manish; Lovat, Laurence B.] Univ Coll London Hosp, Gastrointestinal Serv, London, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London; University of London; University College London; University
   College London Hospitals NHS Foundation Trust
RP Ahmad, OF (通讯作者)，UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, London W1W 7TS, England.
EM o.ahmad@ucl.ac.uk
RI Lovat, Laurence/C-1986-2009; Stoyanov, Danail/V-1043-2019
OI Lovat, Laurence/0000-0003-4542-3915; Stoyanov,
   Danail/0000-0002-0980-3227; Sampaio Soares, Antonio/0000-0001-7773-2427;
   Mazomenos, Evangelos/0000-0003-0357-5996
FU Engineering and Physical Sciences Research Council [EP/R004080/1]
   Funding Source: researchfish; EPSRC [EP/P027938/1] Funding Source: UKRI
CR Alexandre LA, 2008, INT C BIOMEDICAL ENG
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brandao P., 2018, J MED ROBOT RES, V3, P1840002, DOI DOI 10.1142/S2424905X18400020
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chen SC, 2007, AM J GASTROENTEROL, V102, P856, DOI 10.1111/j.1572-0241.2006.01054.x
   Coe SG, 2013, AM J GASTROENTEROL, V108, P219, DOI 10.1038/ajg.2012.417
   Corley DA, 2011, GASTROINTEST ENDOSC, V74, P656, DOI 10.1016/j.gie.2011.04.017
   Crockett SD, 2018, ENDOSCOPY, V50, P984, DOI 10.1055/a-0597-1740
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   East JE, 2018, LANCET GASTROENTEROL, V3, P10, DOI 10.1016/S2468-1253(17)30366-7
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Facciorusso A, 2018, CLIN GASTROENTEROL H, V16, P1209, DOI 10.1016/j.cgh.2017.11.007
   Ferlitsch M, 2017, ENDOSCOPY, V49, P270, DOI 10.1055/s-0043-102569
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Filip D, 2012, WORLD J GASTROENTERO, V18, P4270, DOI 10.3748/wjg.v18.i32.4270
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hazewinkel Y, 2013, GASTROINTEST ENDOSC, V77, P916, DOI 10.1016/j.gie.2012.12.018
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo SE, 2015, GASTROINTEST ENDOSC, V82, P912, DOI 10.1016/j.gie.2015.04.039
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   McGill SK, 2015, GUT, V64, P184, DOI 10.1136/gutjnl-2013-305743
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Morris EJA, 2015, GUT, V64, P1248, DOI 10.1136/gutjnl-2014-308362
   National Institute for Health and Care Excellence, 2017, VIRT CHROM ASS COL P
   Park S., 2016, SPIE MED IMAGING
   Prior F, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.124
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rembacken B, 2012, ENDOSCOPY, V44, P957, DOI 10.1055/s-0032-1325686
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samek W, 2017, IEEE T NEUR NET LEAR, V28, P2660, DOI 10.1109/TNNLS.2016.2599820
   Sawhney MS, 2008, GASTROENTEROLOGY, V135, P1892, DOI 10.1053/j.gastro.2008.08.024
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Stanek SR, 2013, COMPUT METH PROG BIO, V112, P407, DOI 10.1016/j.cmpb.2013.07.028
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Torre LA, 2015, CA-CANCER J CLIN, V65, P87, DOI 10.3322/caac.21262
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Vlugt M, 2016, ENDOSC INT OPEN, V4, pE778, DOI 10.1055/s-0042-107667
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2010, IEEE T BIO-MED ENG, V57, P685, DOI 10.1109/TBME.2009.2034466
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 71
TC 92
Z9 99
U1 6
U2 36
PU ELSEVIER INC
PI SAN DIEGO
PA 525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA
EI 2468-1253
J9 LANCET GASTROENTEROL
JI Lancet Gastroenterol. Hepatol.
PD JAN
PY 2019
VL 4
IS 1
BP 71
EP 80
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HG9MB
UT WOS:000455331500024
PM 30527583
OA Green Submitted, Green Accepted
DA 2023-04-20
ER

PT J
AU Allescher, HD
   Weingart, V
AF Allescher, Hans-Dieter
   Weingart, Vincens
TI Optimizing Screening Colonoscopy: Strategies and Alternatives
SO VISCERAL MEDICINE
LA English
DT Review
DE Adenoma detection rate; Polyp detection rate; Interval carcinoma;
   Colorectal cancer; Screening
ID ENDOCUFF-ASSISTED COLONOSCOPY; AIDED DIAGNOSTIC SYSTEM; ADENOMA
   DETECTION RATE; BALLOON COLONOSCOPE; POLYP DETECTION; COLORECTAL
   LESIONS; CECAL INTUBATION; MISS RATE; MULTICENTER; RISK
AB Screening colonoscopy is the most effective screening procedure for the prevention of colorectal cancer. The efficacy of colonoscopy is highly dependent on the overall quality of how this procedure is indicated, planned, prepared, and performed. The quality is directly linked to the number of polyps and/or adenomas detected or, in other words, to the number of polyps or adenomas missed during the procedure. The quality has a direct impact on the rate of interval carcinoma and on the range of how the incidence and occurrence of colorectal cancer is reduced. This review summarizes the current status on general measures and procedure improvements and standards as well as technical advances which have been suggested and established to improve the quality of polyp and adenoma detection rate. This includes selection and preparation of the patients, planning, methodological and technical performance of the procedure, and technical advances of the endoscope technology in order to improve screening results. It also covers new technologies with wide angle endoscopes (Ewave) and IT-based approaches using artificial intelligence to such as ai4GI for the polyp detection and image analysis. (C) 2019 S. Karger AG, Basel
C1 [Allescher, Hans-Dieter; Weingart, Vincens] Klinikum Garmisch Partenkirchen, Dept Gastroenterol, Garmisch Partenkirchen, Germany.
RP Allescher, HD (通讯作者)，Klinikum Garmisch Partenkirchen, Dept Gastroenterol, Ctr Internal Med, Auenstr 6, DE-82467 Garmisch Partenkirchen, Germany.
EM hans.allescher@klinikum-gap.de
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bevan R, 2016, ENDOSC INT OPEN, V4, pE205, DOI 10.1055/s-0041-107900
   Brenner H, 2010, J NATL CANCER I, V102, P89, DOI 10.1093/jnci/djp436
   Bronzwaer MES, 2018, ENDOSCOPY, V50, P63, DOI 10.1055/s-0043-120666
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Denzer U, 2015, Z Gastroenterol, V53, pE1, DOI 10.1055/s-0041-109598
   Dik VK, 2015, ENDOSCOPY, V47, P1151, DOI 10.1055/s-0034-1392421
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Floer M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114267
   Gralnek IM, 2015, DIGEST ENDOSC, V27, P223, DOI 10.1111/den.12382
   Gralnek IM, 2014, ENDOSCOPY, V46, P883, DOI 10.1055/s-0034-1377968
   Halpern Z, 2015, ENDOSCOPY, V47, P238, DOI 10.1055/s-0034-1391437
   Hasan N, 2014, GASTROINTEST ENDOSC, V80, P1135, DOI 10.1016/j.gie.2014.04.024
   Heitzer E, 2019, NAT REV GENET, V20, P71, DOI 10.1038/s41576-018-0071-5
   Heitzer E, 2017, NPJ PRECIS ONCOL, V1, DOI 10.1038/s41698-017-0039-5
   Hsu CM, 2012, J GASTROEN HEPATOL, V27, P76, DOI 10.1111/j.1440-1746.2011.06795.x
   Jung P, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000011253
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kondo S, 2007, AM J GASTROENTEROL, V102, P75, DOI 10.1111/j.1572-0241.2006.00897.x
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee SW, 2016, AM J GASTROENTEROL, V111, P63, DOI 10.1038/ajg.2015.354
   Lenze F, 2014, ENDOSCOPY, V46, P610, DOI 10.1055/s-0034-1365446
   Leung F, 2016, CLIN CHEM, V62, P1054, DOI 10.1373/clinchem.2016.260331
   Leung WK, 2014, AM J GASTROENTEROL, V109, P855, DOI 10.1038/ajg.2014.83
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Ng SC, 2012, AM J GASTROENTEROL, V107, P1165, DOI 10.1038/ajg.2012.135
   Omata F, 2014, SCAND J GASTROENTERO, V49, P222, DOI 10.3109/00365521.2013.863964
   Papanikolaou IS, 2017, ENDOSCOPY, V49, P468, DOI 10.1055/s-0042-124415
   Perakis S, 2017, BMC MED, V15, DOI 10.1186/s12916-017-0840-6
   Pohl J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126067
   Ristikankare M, 2016, SCAND J GASTROENTERO, V51, P368, DOI 10.3109/00365521.2015.1083611
   Sanaka MR, 2009, AM J GASTROENTEROL, V104, P1659, DOI 10.1038/ajg.2009.249
   Shaukat A, 2015, CANCER EPIDEM BIOMAR, V24, P913, DOI 10.1158/1055-9965.EPI-14-1321
   Sosna J, 2003, AM J ROENTGENOL, V181, P1593, DOI 10.2214/ajr.181.6.1811593
   Subramanian V, 2011, ENDOSCOPY, V43, P499, DOI 10.1055/s-0030-1256207
   Triantafyllou K, 2017, ENDOSCOPY, V49, P1051, DOI 10.1055/s-0043-114412
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Walter B, 2019, GASTROINTEST ENDOSC, V89, P506, DOI 10.1016/j.gie.2018.08.014
   Walter BM, 2016, JMIR MHEALTH UHEALTH, V4, P400, DOI 10.2196/mhealth.5289
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
NR 47
TC 6
Z9 6
U1 0
U2 7
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 2297-4725
EI 2297-475X
J9 VISC MED
JI Visc. Med.
PY 2019
VL 35
IS 4
BP 215
EP 225
DI 10.1159/000501835
PG 11
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA IP8BZ
UT WOS:000480273200004
PM 31602382
OA Green Published, Bronze
DA 2023-04-20
ER

PT J
AU Byrne, MF
   Chapados, N
   Soudan, F
   Oertel, C
   Perez, ML
   Kelly, R
   Iqbal, N
   Chandelier, F
   Rex, DK
AF Byrne, Michael F.
   Chapados, Nicolas
   Soudan, Florian
   Oertel, Clemens
   Linares Perez, Milagros
   Kelly, Raymond
   Iqbal, Nadeem
   Chandelier, Florent
   Rex, Douglas K.
TI Real-time differentiation of adenomatous and hyperplastic diminutive
   colorectal polyps during analysis of unaltered videos of standard
   colonoscopy using a deep learning model
SO GUT
LA English
DT Article
ID QUALITY INDICATORS; EUROPEAN-SOCIETY; SERRATED POLYPS; RISK; VALIDATION;
   CANCER; SYSTEM; PREVALENCE; DIAGNOSIS; HISTOLOGY
AB Background In general, academic but not community endoscopists have demonstrated adequate endoscopic differentiation accuracy to make the 'resect and discard' paradigm for diminutive colorectal polyps workable. Computer analysis of video could potentially eliminate the obstacle of interobserver variability in endoscopic polyp interpretation and enable widespread acceptance of 'resect and discard'.
   Study design and methods We developed an artificial intelligence (AI) model for real-time assessment of endoscopic video images of colorectal polyps. A deep convolutional neural network model was used. Only narrow band imaging video frames were used, split equally between relevant multiclasses. Unaltered videos from routine exams not specifically designed or adapted for AI classification were used to train and validate the model. The model was tested on a separate series of 125 videos of consecutively encountered diminutive polyps that were proven to be adenomas or hyperplastic polyps.
   Results T he AI model works with a confidence mechanism and did not generate sufficient confidence to predict the histology of 19 polyps in the test set, representing 15% of the polyps. For the remaining 106 diminutive polyps, the accuracy of the model was 94% (95% CI 86% to 97%), the sensitivity for identification of adenomas was 98% (95% CI 92% to 100%), specificity was 83% (95% CI 67% to 93%), negative predictive value 97% and positive predictive value 90%.
   Conclusions A n AI model trained on endoscopic video can differentiate diminutive adenomas from hyperplastic polyps with high accuracy. Additional study of this programme in a live patient clinical trial setting to address resect and discard is planned.
C1 [Byrne, Michael F.] Vancouver Gen Hosp, Div Gastroenterol, Vancouver, BC, Canada.
   [Chapados, Nicolas; Soudan, Florian; Oertel, Clemens; Chandelier, Florent] Imagia, Dept Technol, Montreal, PQ, Canada.
   [Chapados, Nicolas] Ecole Polytech Montreal, Dept Appl Math, Montreal, PQ, Canada.
   [Linares Perez, Milagros] Univ Buenos Aires, Dept Gastroenterol, Buenos Aires, DF, Argentina.
   [Kelly, Raymond] Beaumont Hosp, Dept Anaesthet, Dublin, Ireland.
   [Iqbal, Nadeem] St Lukes Hosp, Dept Gastroenterol, Kilkenny, Ireland.
   [Rex, Douglas K.] Indiana Univ, Div Gastroenterol & Hepatol, Med Ctr, Indianapolis, IN USA.
C3 University of British Columbia; Universite de Montreal; Polytechnique
   Montreal; University of Buenos Aires; Indiana University System; Indiana
   University-Purdue University Indianapolis
RP Byrne, MF (通讯作者)，Univ British Columbia, Div Gastroenterol, Vancouver Gen Hosp, Vancouver, BC V5Z 1M9, Canada.
EM mike@ai4gi.com
RI Iqbal, Nadeem/AAN-3196-2021
OI Iqbal, Nadeem/0000-0002-0602-8333
FU Satis Operations Inc; Imagia Cybernetics
FX This work was primarily supported by 'ai4gi', a joint venture between
   Satis Operations Inc and Imagia Cybernetics.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Chen SC, 2007, AM J GASTROENTEROL, V102, P856, DOI 10.1111/j.1572-0241.2006.01054.x
   Coe SG, 2013, AM J GASTROENTEROL, V108, P219, DOI 10.1038/ajg.2012.417
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Hetzel JT, 2010, AM J GASTROENTEROL, V105, P2656, DOI 10.1038/ajg.2010.315
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Ijspeert JE, 2015, GASTROINTEST ENDOSC, V81, pAB260, DOI 10.1016/j.gie.2015.03.1348
   Kahi CJ, 2012, GASTROINTEST ENDOSC, V75, P515, DOI 10.1016/j.gie.2011.08.021
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Pohl H, 2013, GASTROENTEROLOGY, V144, P74, DOI 10.1053/j.gastro.2012.09.043
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2017, GASTROINTEST ENDOSC, V85, P614, DOI 10.1016/j.gie.2016.10.011
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2012, AM J GASTROENTEROL, V107, P1315, DOI 10.1038/ajg.2012.161
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
NR 34
TC 328
Z9 352
U1 8
U2 101
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0017-5749
EI 1468-3288
J9 GUT
JI Gut
PD JAN
PY 2019
VL 68
IS 1
BP 94
EP 100
DI 10.1136/gutjnl-2017-314547
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HH4WU
UT WOS:000455727900015
PM 29066576
OA hybrid, Green Published
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Cai, HM
   Pang, XL
   Dong, D
   Ma, Y
   Huang, Y
   Fan, XJ
   Wu, PH
   Chen, HY
   He, F
   Cheng, YK
   Liu, S
   Yu, YZ
   Hong, MH
   Xiao, J
   Wan, XB
   Lv, YC
   Zheng, J
AF Cai, Hongmin
   Pang, Xiaolin
   Dong, Dong
   Ma, Yan
   Huang, Yan
   Fan, Xinjuan
   Wu, Peihuang
   Chen, Haiyang
   He, Fang
   Cheng, Yikan
   Liu, Shuai
   Yu, Yizhen
   Hong, Minghuang
   Xiao, Jian
   Wan, Xiangbo
   Lv, Yanchun
   Zheng, Jian
TI Molecular Decision Tree Algorithms Predict Individual Recurrence Pattern
   for Locally Advanced Nasopharyngeal Carcinoma
SO JOURNAL OF CANCER
LA English
DT Article
DE nasopharyngeal carcinoma; decision tree algorithms; classifiers;
   recurrence pattern
ID SALVAGE ENDOSCOPIC NASOPHARYNGECTOMY; INTENSITY-MODULATED RADIOTHERAPY;
   SUPPORT VECTOR MACHINES; LONG-TERM SURVIVAL; FEATURE-SELECTION;
   BREAST-CANCER; EXPRESSION; ASSAY; OUTCOMES; MODEL
AB Background: Recurrence remains one of the key reasons of relapse after the radical radiation for locally advanced nasopharyngeal carcinoma (NPC). Here, the multiple molecular and clinical variables integrated decision tree algorithms were designed to predict individual recurrence patterns (with VS without recurrence) for locally advanced NPC.
   Methods: A total of 136 locally advanced NPC patients retrieved from a randomized controlled phase III trial, were included. For each patient, the expression levels of 33 clinicopathological biomarkers in tumor specimen, 3 Epstein-Barr virus related serological antibody titer and 5 clinicopathological variables, were detected and collected to construct the decision tree algorithm. The expression level of 33 clinicopathological biomarkers in tumor specimen was evaluated by immunohistochemistry staining.
   Results: Three algorithm classifiers, augmented by the adaptive boosting algorithm for variable selection and classification, were designed to predict individual recurrence pattern. The classifiers were trained in the training subset and further tested using a 10-fold cross-validation scheme in the validation subset. In total, 13 molecules expression level in tumor specimen, including AKTI, Aurora-A, Box, Bcl-2, N-Cadherin, CENP-H, HIF-1a, LMP-1, C-Met, MMP-2, MMP-9, Pontin and Stathmin, and N stage were selected to construct three 10-fold cross-validation decision tree classifiers. These classifiers showed high predictive sensitivity (87.2-93.3%), specificity (69.0-100.0%), and overall accuracy (84.5-95.2%) to predict recurrence pattern individually. Multivariate analyses confirmed the decision tree classifier was an independent prognostic factor to predict individual recurrence (algorithm 1: hazard ration (HR) 0.07, 95% confidence interval (CI) 0.03-0.16, P < 0.01; algorithm 2: HR 0.13, 95% CI 0.04-0.44, P < 0.01; algorithm 3: HR 0.13, 95% CI 0.03-0.68, P = 0.02).
   Conclusion: Multiple molecular and clinicopathological variables integrated decision tree algorithms may individually predict the recurrence pattern for locally advanced NPC. This decision tree algorism provides a potential tool to select patients with high recurrence risk for intensive follow-up, and to diagnose recurrence at an earlier stage for salvage treatment in the NPC endemic region.
C1 [Cai, Hongmin; Pang, Xiaolin; Ma, Yan; Chen, Haiyang; He, Fang; Cheng, Yikan; Liu, Shuai; Yu, Yizhen; Hong, Minghuang; Zheng, Jian] Sun Yat Sen Univ, Affiliated Hosp 6, Dept Radiat Oncol, 26 Yuancun Erheng Rd, Guangzhou 510655, Guangdong, Peoples R China.
   [Cai, Hongmin] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Dong, Dong] Zhengzhou Univ, Dept Rhinol, Affiliated Hosp 1, Zhengzhou 450052, Henan, Peoples R China.
   [Huang, Yan; Fan, Xinjuan; Wu, Peihuang] Sun Yat Sen Univ, Affiliated Hosp 6, Dept Pathol, Guangzhou 510060, Guangdong, Peoples R China.
   [Xiao, Jian] Sun Yat Sen Univ, Canc Ctr, State Key Lab Oncol South China, Dept Nasopharyngeal Carcinoma, Guangzhou 510060, Guangdong, Peoples R China.
   [Wan, Xiangbo] Sun Yat Sen Univ, Affiliated Hosp 6, Dept Med Oncol, Guangzhou 510060, Guangdong, Peoples R China.
   [Lv, Yanchun] Sun Yat Sen Univ, Collaborat Innovat Ctr Canc Med, State Key Lab Oncol South China, Canc Ctr,Dept Med Radiol, 651 Dongfeng Rd East, Guangzhou 510060, Guangdong, Peoples R China.
C3 Sun Yat Sen University; South China University of Technology; Zhengzhou
   University; Sun Yat Sen University; State Key Lab Oncology South China;
   Sun Yat Sen University; Sun Yat Sen University; State Key Lab Oncology
   South China; Sun Yat Sen University
RP Zheng, J (通讯作者)，Sun Yat Sen Univ, Affiliated Hosp 6, Dept Radiat Oncol, 26 Yuancun Erheng Rd, Guangzhou 510655, Guangdong, Peoples R China.; Lv, YC (通讯作者)，Sun Yat Sen Univ, Collaborat Innovat Ctr Canc Med, State Key Lab Oncol South China, Canc Ctr,Dept Med Radiol, 651 Dongfeng Rd East, Guangzhou 510060, Guangdong, Peoples R China.
EM lvych@sysucc.org.cn; zhengj48@mail.sysu.edu.cn
RI Dong, Dong/AAI-1403-2020
OI Cai, Hongmin/0000-0002-2747-7234
FU Natural Science Foundation of China [61771007, 81572371, 81872188];
   International Centre for Genetic Engineering and Biotechnology Research
   Grant, China [CRP/CHIN16-04_EC]; Guangdong Natural Science Foundation
   for Distinguished Young Scholar, China [2014A030306016]; Guangdong
   Science and Technology Project, China [2017B090901065]; Special Support
   Planning Grant of Guangdong Province, China [2015TQ01R562]; Natural
   Science Foundation of Guangdong Province, China [2015A030313166,
   2016A030310187]; Foundation for Pearl River Science & Technology Young
   Scholars of Guangzhou, China [201610010059]
FX This work was supported by the Natural Science Foundation of China (No.
   61771007 to HMC, No. 81572371 to XJF, No. 81872188 to XBW),
   International Centre for Genetic Engineering and Biotechnology Research
   Grant, China (No. CRP/CHIN16-04_EC to XBW), Guangdong Natural Science
   Foundation for Distinguished Young Scholar, China (No. 2014A030306016 to
   XBW), Guangdong Science and Technology Project, China (No.
   2017B090901065 to XBW), the Special Support Planning Grant of Guangdong
   Province, China (No. 2015TQ01R562 to XBW), Natural Science Foundation of
   Guangdong Province, China (No. 2015A030313166 to XJF, 2016A030310187 to
   JX), Foundation for Pearl River Science & Technology Young Scholars of
   Guangzhou, China (No. 201610010059 to XJF).
CR Albain KS, 2010, LANCET ONCOL, V11, P55, DOI 10.1016/S1470-2045(09)70314-6
   Baselga J, 2014, J CLIN ONCOL, V32, P3753, DOI 10.1200/JCO.2013.54.5384
   Cai HM, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-70
   Chang ET, 2006, CANCER EPIDEM BIOMAR, V15, P1765, DOI 10.1158/1055-9965.EPI-06-0353
   Chen KC, 2015, HEAD NECK-J SCI SPEC, V37, P794, DOI 10.1002/hed.23671
   Chen MY, 2012, HEAD NECK-J SCI SPEC, V34, P1383, DOI 10.1002/hed.21928
   Chen Ming-Yuan, 2007, Ai Zheng, V26, P513
   Chua DTT, 2005, J CLIN ONCOL, V23, P1118, DOI 10.1200/JCO.2005.12.081
   Chua MLK, 2016, LANCET, V387, P1012, DOI 10.1016/S0140-6736(15)00055-0
   Fan XJ, 2012, BRIT J CANCER, V106, P1735, DOI 10.1038/bjc.2012.82
   Farrell PJ, 2005, NAT CLIN PRACT ONCOL, V2, P14, DOI 10.1038/ncponc0051
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Hong MH, 2000, CANCER, V89, P242, DOI 10.1002/1097-0142(20000715)89:2<242::AID-CNCR6>3.0.CO;2-Z
   Hornberger J, 2012, JNCI-J NATL CANCER I, V104, P1068, DOI 10.1093/jnci/djs261
   Huang PY, 2015, EUR J CANCER, V51, P1760, DOI 10.1016/j.ejca.2015.05.025
   Karam I, 2016, HEAD NECK S1, V38
   Levine MN, 2016, J CLIN ONCOL, V34, P1065, DOI 10.1200/JCO.2015.62.8503
   Paik S, 2004, NEW ENGL J MED, V351, P2817, DOI 10.1056/NEJMoa041588
   Qiu SF, 2012, INT J RADIAT ONCOL, V83, P676, DOI 10.1016/j.ijrobp.2011.07.006
   Rettig EM, 2015, JAMA ONCOL, V1, P907, DOI 10.1001/jamaoncol.2015.2524
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Scott JG, 2017, LANCET ONCOL, V18, P202, DOI 10.1016/S1470-2045(16)30648-9
   Sparano JA, 2015, NEW ENGL J MED, V373, P2005, DOI 10.1056/NEJMoa1510764
   Srivastava A, 2013, J IMMUNOL METHODS, V387, P284, DOI 10.1016/j.jim.2012.09.013
   Su SF, 2012, INT J RADIAT ONCOL, V82, P327, DOI 10.1016/j.ijrobp.2010.09.011
   Takemura A, 2010, IEEE T MED IMAGING, V29, P598, DOI 10.1109/TMI.2009.2022630
   Tang LQ, 2016, JNCI-J NATL CANCER I, V108, DOI 10.1093/jnci/djv291
   Tian YM, 2016, HEAD NECK-J SCI SPEC, V38, P225, DOI 10.1002/hed.23880
   Tolaney SM, 2015, NEW ENGL J MED, V372, P134, DOI 10.1056/NEJMoa1406281
   Wan XB, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090048
   Wan XB, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031989
   Wan XB, 2010, AUTOPHAGY, V6, P395, DOI 10.4161/auto.6.3.11303
   Wei WI, 2005, LANCET, V365, P2041, DOI 10.1016/S0140-6736(05)66698-6
   Xu J, 2010, J CLIN ONCOL, V28, P5202, DOI 10.1200/JCO.2009.25.6552
   Yetton BD, 2016, J NEUROSCI METH, V259, P72, DOI 10.1016/j.jneumeth.2015.11.015
   You R, 2015, RADIOTHER ONCOL, V115, P399, DOI 10.1016/j.radonc.2015.04.024
   Zhang JX, 2013, LANCET ONCOL, V14, P1295, DOI 10.1016/S1470-2045(13)70491-1
   Zhu ZH, 2009, J CLIN ONCOL, V27, P1091, DOI 10.1200/JCO.2008.16.6991
   Zou X, 2015, HEAD NECK-J SCI SPEC, V37, P1108, DOI 10.1002/hed.23719
NR 39
TC 3
Z9 3
U1 2
U2 10
PU IVYSPRING INT PUBL
PI LAKE HAVEN
PA PO BOX 4546, LAKE HAVEN, NSW 2263, AUSTRALIA
SN 1837-9664
J9 J CANCER
JI J. Cancer
PY 2019
VL 10
IS 15
BP 3323
EP 3332
DI 10.7150/jca.29693
PG 10
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA IC8ZZ
UT WOS:000471272200003
PM 31293635
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Domingues, I
   Sampaio, IL
   Duarte, H
   Santos, JAM
   Abreu, PH
AF Domingues, Ines
   Sampaio, Ines Lucena
   Duarte, Hugo
   Santos, Joao A. M.
   Abreu, Pedro H.
TI Computer Vision in Esophageal Cancer: A Literature Review
SO IEEE ACCESS
LA English
DT Review
DE Computed tomography; computer vision; computer aided analysis;
   endoscopy; esophageal cancer; positron emission tomography
ID TEXTURE ANALYSIS; F-18-FDG PET; PATHOLOGICAL RESPONSE; UPTAKE
   HETEROGENEITY; TUMOR HETEROGENEITY; FEATURES; CHEMORADIOTHERAPY;
   SEGMENTATION; PREDICTION; DIAGNOSIS
AB Esophageal cancer is a disease with a high prevalence that can be evaluated by a variety of imaging modalities, including endoscopy, computed tomography, and positron emission tomography. Computer-aided techniques could provide a valuable help in the analysis of these images, decreasing the medical workflow time and human errors. The goal of this paper is to review the existing literature on the application of computer vision techniques in the domain of esophageal cancer. After an initial phase where a set of keywords was chosen, the selected terms were used to retrieve papers from four well-known databases: Web of Science, Scopus, PubMed, and Springer. The results were scanned by merging identical entries, and eliminating the out of scope works, resulting in 47 selected papers. These were organized according to the image modality. Major results were then summarized and compared, and main shortcomings were identified. It could be concluded that, even though the scientific community has already paid attention to the esophageal cancer problem, there are still several open issues. Two majorfindings of this review are the nonexistence of works on MRI data and the under-exploration of recent techniques using deep learning strategies, showing the need for further investigation.
C1 [Domingues, Ines; Sampaio, Ines Lucena; Duarte, Hugo; Santos, Joao A. M.] IPO Porto Res Ctr CI IPOP, Med Phys Radiobiol & Radiat Protect Grp, P-4200072 Porto, Portugal.
   [Sampaio, Ines Lucena; Duarte, Hugo] Portuguese Inst Oncol Porto IPO Porto, Nucl Med Dept, P-4200072 Porto, Portugal.
   [Santos, Joao A. M.] Portuguese Inst Oncol Porto IPO Porto, Med Phys Dept, P-4200072 Porto, Portugal.
   [Santos, Joao A. M.] Univ Porto, Inst Ciencias Biomed Abel Salazar, P-4099002 Porto, Portugal.
   [Abreu, Pedro H.] Univ Coimbra, CISUC, P-3030789 Coimbra, Portugal.
C3 Universidade do Porto; Universidade de Coimbra
RP Domingues, I (通讯作者)，IPO Porto Res Ctr CI IPOP, Med Phys Radiobiol & Radiat Protect Grp, P-4200072 Porto, Portugal.
EM ines.domingues@isec.pt
RI Domingues, Inês/B-7335-2012; Abreu, Pedro Henriques/ABE-1698-2020;
   Santos, João/HHZ-5595-2022
OI Domingues, Inês/0000-0002-2334-7280; Abreu, Pedro
   Henriques/0000-0002-9278-8194; Miranda dos Santos, Joao
   Antonio/0000-0003-2465-5143
FU Norte Portugal Regional Operational Programme (NORTE 2020), under the
   PORTUGAL 2020 Partnership Agreement, through the European Regional
   Development Fund (ERDF) [NORTE-01-0145-FEDER-000027]
FX This work was supported by the Norte Portugal Regional Operational
   Programme (NORTE 2020), under the PORTUGAL 2020 Partnership Agreement,
   through the European Regional Development Fund (ERDF) under Project
   NORTE-01-0145-FEDER-000027.
CR Amin MB., 2017, AJCC CANC STAGING MA
   Anthony GJ, 2017, MED PHYS, V44, P3686, DOI 10.1002/mp.12282
   Berthon B, 2016, PHYS MED BIOL, V61, P4855, DOI 10.1088/0031-9155/61/13/4855
   Beukinga RJ, 2017, J NUCL MED, V58, P723, DOI 10.2967/jnumed.116.180299
   Brierley J, 2017, TNM CLASSIFICATION M, Veighth
   Carroll RE, 2009, INT J COMPUT VISION, V85, P307, DOI 10.1007/s11263-009-0264-7
   Cunliffe A, 2015, INT J RADIAT ONCOL, V91, P1048, DOI 10.1016/j.ijrobp.2014.11.030
   Desbordes P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173208
   Domingues I, 2018, IEEE IMAGE PROC, P1378, DOI 10.1109/ICIP.2018.8451510
   Dong XZ, 2013, NUCL MED COMMUN, V34, P40, DOI 10.1097/MNM.0b013e32835ae50c
   Doumou G, 2015, EUR RADIOL, V25, P2805, DOI 10.1007/s00330-015-3681-8
   Fechter T, 2017, MED PHYS, V44, P6341, DOI 10.1002/mp.12593
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Foley K, 2018, BEST PRACT RES CL GA, V36-37, P17, DOI 10.1016/j.bpg.2018.11.009
   Foley KG, 2018, EUR RADIOL, V28, P428, DOI 10.1007/s00330-017-4973-y
   Ganeshan B, 2012, CLIN RADIOL, V67, P157, DOI 10.1016/j.crad.2011.08.012
   Garcia-Peraza-Herrera L. C., 2018, ARXIV180500632
   Ghatwary N., 2017, P SOC PHOTO-OPT INS, V10134
   Ghatwary N, 2017, COMM COM INF SC, V723, P897, DOI 10.1007/978-3-319-60964-5_78
   Gore R. M., 2018, DIS ABDOMEN PELVIS, P91, DOI [10.1007/978-3-319-75019-4_10, DOI 10.1007/978-3-319-75019-4_10]
   Hatt M, 2015, J NUCL MED, V56, P38, DOI 10.2967/jnumed.114.144055
   Hatt M, 2013, EUR J NUCL MED MOL I, V40, P1662, DOI 10.1007/s00259-013-2486-8
   Hong JS, 2017, IEEE ENG MED BIO, P2892, DOI 10.1109/EMBC.2017.8037461
   Janse M. H. A., 2016, P SOC PHOTO-OPT INS, V9785
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Klomp S., 2017, P SOC PHOTO-OPT INS, V10134
   Lian CF, 2015, I S BIOMED IMAGING, P63, DOI 10.1109/ISBI.2015.7163817
   Lian CF, 2016, MED IMAGE ANAL, V32, P257, DOI 10.1016/j.media.2016.05.007
   Lordick F, 2016, ANN ONCOL, V27, pv50, DOI 10.1093/annonc/mdw329
   Luketich JD, 1999, ANN THORAC SURG, V68, P1133
   Malik V, 2015, DIGEST SURG, V32, P397, DOI 10.1159/000431292
   Martins Paula, 2007, 8 ANN C INT SPEECH C, P58
   Massari M, 1997, SURG LAPAROSC ENDOSC, V7, P162, DOI 10.1097/00019509-199704000-00021
   Matsunaga H, 2016, ADV INTELL SYST, V448, P939, DOI 10.1007/978-3-319-32467-8_81
   Munzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Nakajo M, 2017, ABDOM RADIOL, V42, P2882, DOI 10.1007/s00261-017-1207-3
   Nakajo M, 2017, EUR J NUCL MED MOL I, V44, P206, DOI 10.1007/s00259-016-3506-2
   Nogueira MA, 2017, ARTIF INTELL REV, V47, P531, DOI 10.1007/s10462-016-9492-8
   Ohura R, 2016, ADV INTELL SYST, V448, P929, DOI 10.1007/978-3-319-32467-8_80
   Rice TW, 2010, CANCER-AM CANCER SOC, V116, P3763, DOI 10.1002/cncr.25146
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saraf SS, 2009, J MECH MED BIOL, V9, P527, DOI 10.1142/S0219519409003097
   Shin D, 2016, GASTROINTEST ENDOSC, V83, P107, DOI 10.1016/j.gie.2015.06.045
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Tan S, 2013, MED PHYS, V40, DOI 10.1118/1.4820445
   Tan S, 2013, INT J RADIAT ONCOL, V85, P1375, DOI 10.1016/j.ijrobp.2012.10.017
   Tixier F, 2012, J NUCL MED, V53, P693, DOI 10.2967/jnumed.111.099127
   Tixier F, 2011, J NUCL MED, V52, P369, DOI 10.2967/jnumed.110.082404
   Trullo R, 2017, IEEE I C SIGNAL IMAG, P503, DOI 10.1109/ICSIPA.2017.8120664
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van der Sommen F, 2016, PROC SPIE, V9786, DOI 10.1117/12.2214450
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   van der Sommen F, 2013, PROC SPIE, V8670, DOI 10.1117/12.2001068
   van Riel S, 2018, IEEE IMAGE PROC, P1383, DOI 10.1109/ICIP.2018.8451771
   Van Rossum P. S. N., 2016, THESIS
   van Rossum PSN, 2016, J NUCL MED, V57, P691, DOI 10.2967/jnumed.115.163766
   van Westreenen H. L., 2005, THESIS
   Vemuri A. S., 2016, THESIS
   Wong MCS, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19819-8
   Xue DX, 2016, J MED BIOL ENG, V36, P755, DOI 10.1007/s40846-016-0182-4
   Yip C, 2015, DIS ESOPHAGUS, V28, P172, DOI 10.1111/dote.12170
   Yip C, 2014, RADIOLOGY, V270, P141, DOI 10.1148/radiol.13122869
   Yip SSF, 2016, FRONT ONCOL, V6, DOI 10.3389/fonc.2016.00072
   Yip SSF, 2016, PHYS MED BIOL, V61, P906, DOI 10.1088/0031-9155/61/2/906
   Ypsilantis PP, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137036
   Zhang H, 2014, INT J RADIAT ONCOL, V88, P195, DOI 10.1016/j.ijrobp.2013.09.037
   Zhang ZH, 2016, MULTIMED TOOLS APPL, V75, P3993, DOI 10.1007/s11042-015-3108-1
   Zwanenburg A., 2016, IMAGE BIOMARKER STAN
NR 69
TC 10
Z9 10
U1 3
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 103080
EP 103094
DI 10.1109/ACCESS.2019.2930891
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA IR8JN
UT WOS:000481688500216
OA Green Submitted, gold
DA 2023-04-20
ER

PT J
AU Du, WJ
   Rao, NN
   Liu, DY
   Jiang, HX
   Luo, CS
   Li, ZW
   Gan, T
   Zeng, B
AF Du, Wenju
   Rao, Nini
   Liu, Dingyun
   Jiang, Hongxiu
   Luo, Chengsi
   Li, Zhengwen
   Gan, Tao
   Zeng, Bing
TI Review on the Applications of Deep Learning in the Analysis of
   Gastrointestinal Endoscopy Images
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Cancer; Lesions; Image analysis; Endoscopes;
   Gastrointestinal tract; Gastrointestinal disease; gastrointestinal
   endoscopy image; deep learning; analysis; comparison
ID CONVOLUTIONAL NEURAL-NETWORK; HELICOBACTER-PYLORI INFECTION; CAPSULE
   ENDOSCOPY; FEATURE-EXTRACTION; COLORECTAL POLYPS; CANCER; DIAGNOSIS;
   CLASSIFICATION; SEGMENTATION; VALIDATION
AB Gastrointestinal (GI) disease is one of the most common diseases and primarily examined by GI endoscopy. Recently, deep learning (DL), in particular convolutional neural networks (CNNs) have made achievements in GI endoscopy image analysis. This review focuses on the applications of DL methods in the analysis of GI images. We summarized and compared the latest published literature related to the common clinical GI diseases and covers the key applications of DL in GI image detection, classification, segmentation, recognition, location, and other tasks. At the end, we give a discussion on the challenges and the research directions of GI image analysis based on DL in the future.
C1 [Du, Wenju; Rao, Nini; Liu, Dingyun; Luo, Chengsi; Li, Zhengwen] Univ Elect Sci & Technol China, Ctr Informat Biol, Chengdu 610054, Sichuan, Peoples R China.
   [Du, Wenju; Rao, Nini; Liu, Dingyun; Jiang, Hongxiu; Luo, Chengsi; Li, Zhengwen] Univ Elect Sci & Technol China, Ctr Informat Med, Chengdu 610054, Sichuan, Peoples R China.
   [Rao, Nini] UESTC, Inst Elect & Informat Engn, Dongguan 523107, Peoples R China.
   [Gan, Tao] Sichuan Univ, West China Hosp, Digest Endoscop Ctr, Chengdu 610017, Sichuan, Peoples R China.
   [Zeng, Bing] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 610054, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; University of Electronic
   Science & Technology of China; Sichuan University; University of
   Electronic Science & Technology of China
RP Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Ctr Informat Biol, Chengdu 610054, Sichuan, Peoples R China.; Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Ctr Informat Med, Chengdu 610054, Sichuan, Peoples R China.; Rao, NN (通讯作者)，UESTC, Inst Elect & Informat Engn, Dongguan 523107, Peoples R China.; Zeng, B (通讯作者)，Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 610054, Sichuan, Peoples R China.
EM raonn@uestc.edu.cn; eezeng@uestc.edu.cn
OI Rao, Nini/0000-0001-7979-2917
FU National Natural Science Foundation of China [61872405, 61720106004];
   Key Project of Natural Science Foundation of Guangdong Province
   [2016A030311040]; Sichuan Science and Technology Support Program
   [2015SZ0191]; Fundamental Research Funds for the Central Universities of
   China [ZYGX2016J189]; Scientific Platform Improvement Project of UESTC
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61872405 and Grant 61720106004, in part
   by the Key Project of Natural Science Foundation of Guangdong Province
   under Grant 2016A030311040, in part by the Sichuan Science and
   Technology Support Program under Grant 2015SZ0191, in part by the
   Fundamental Research Funds for the Central Universities of China under
   Grant ZYGX2016J189, and in part by the Scientific Platform Improvement
   Project of UESTC.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Andermatt S, 2016, LECT NOTES COMPUT SC, V10008, P142, DOI 10.1007/978-3-319-46976-8_15
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chandrakar M. K., 2018, J ADV RES DYN CONTRO, V10, P549
   Chen HH, 2017, NEUROCOMPUTING, V229, P77, DOI 10.1016/j.neucom.2016.06.077
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gao XT, 2015, IEEE T BIO-MED ENG, V62, P2693, DOI 10.1109/TBME.2015.2444389
   Ghosh T, 2018, IEEE IMAGE PROC, P3034, DOI 10.1109/ICIP.2018.8451300
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gondos A, 2008, EUR J CANCER, V44, P1463, DOI 10.1016/j.ejca.2008.03.010
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hajabdollahi M, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101565
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He YX, 2023, TRANSPORTMETRICA A, V19, DOI [10.1109/CVPR.2016.90, 10.1080/23249935.2022.2033348]
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hong JS, 2017, IEEE ENG MED BIO, P2892, DOI 10.1109/EMBC.2017.8037461
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karnes WE, 2017, GASTROINTEST ENDOSC, V85, pAB376, DOI 10.1016/j.gie.2017.03.871
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Lan LB, 2019, IEEE ACCESS, V7, P30017, DOI 10.1109/ACCESS.2019.2901568
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Li YX, 2018, I S BIOMED IMAGING, P182
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu B, 2018, P INT COMP SOFTW APP, P408, DOI 10.1109/COMPSAC.2018.10267
   Liu DY, 2015, J MED IMAG HEALTH IN, V5, P296, DOI 10.1166/jmihi.2015.1390
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Liu DY, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1063-x
   Liu XQ, 2020, NEUROCOMPUTING, V392, P253, DOI 10.1016/j.neucom.2018.10.100
   Liu XQ, 2018, IEEE IMAGE PROC, P1388, DOI 10.1109/ICIP.2018.8451067
   Lo SCB, 1995, IEEE T MED IMAGING, V14, P711, DOI 10.1109/42.476112
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mannath J, 2016, NAT REV GASTRO HEPAT, V13, P720, DOI 10.1038/nrgastro.2016.148
   Mastronardo C., 2017, ARXIV171203689
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Pogorelov K, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P363, DOI 10.1145/3204949.3208128
   Qu J, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8961781
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Rodriguez A, 2017, 2017 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS)
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Simonyan K., 2013, P ICLR
   Sun JY, 2018, COMP MED SY, P351, DOI 10.1109/CBMS.2018.00068
   Szegedy, 2013, ARXIV13126199, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Take I, 2015, TRANSL GASTROIN CANC, V4, P423, DOI 10.3978/j.issn.2224-4778.2015.09.04
   Tanabe S, 2016, CLIN ENDOSC, V49, P539, DOI 10.5946/ce.2016.004
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   van Riel S, 2018, IEEE IMAGE PROC, P1383, DOI 10.1109/ICIP.2018.8451771
   Washington K, 2010, ANN SURG ONCOL, V17, P3077, DOI 10.1245/s10434-010-1362-z
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Xiao WT, 2018, IEEE INT C ELECTR TA
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zhao BY, 2017, SHOCK VIB, V2017, DOI 10.1155/2017/4350437
   Zhou J., 2018, ARXIV181208434, DOI DOI 10.1016/J.AIOPEN.2021.01.001
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 92
TC 33
Z9 35
U1 4
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 142053
EP 142069
DI 10.1109/ACCESS.2019.2944676
PG 17
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA JN8QJ
UT WOS:000497156000158
OA gold
DA 2023-04-20
ER

PT J
AU Ghatwary, N
   Ye, XJ
   Zolgharni, M
AF Ghatwary, Noha
   Ye, Xujiong
   Zolgharni, Massoud
TI Esophageal Abnormality Detection Using DenseNet Based Faster R-CNN With
   Gabor Features
SO IEEE ACCESS
LA English
DT Article
DE Detection; DenseNet; esophageal adenocarcinoma; esophagitis; Faster
   R-CNN
ID BARRETTS-ESOPHAGUS; NETWORKS; LESIONS; IMAGES
AB Early detection of esophageal abnormalities can help in preventing the progression of the disease into later stages. During esophagus examination, abnormalities are often overlooked due to the irregular shape, variable size, and the complex surrounding area which requires a significant effort and experience. In this paper, a novel deep learning model which is based on faster region-based convolutional neural network (Faster R-CNN) is presented to automatically detect abnormalities in the esophagus from endoscopic images. The proposed detection system is based on a combination of Gabor handcrafted features with the CNN features. The densely connected convolutional networks (DenseNets) architecture is embraced to extract the CNN features providing a strengthened feature propagation between the layers and alleviate the vanishing gradient problem. To address the challenges of detecting abnormal complex regions, we propose fusing extracted Gabor features with the CNN features through concatenation to enhance texture details in the detection stage. Our newly designed architecture is validated on two datasets (Kvasir and MICCAI 2015). Regarding the Kvasir, the results show an outstanding performance with a recall of 90.2% and a precision of 92.1% with a mean of average precision (mAP) of 75.9%. While for the MICCAI 2015 dataset, the model is able to surpass the state-of-the-art performance with 95% recall and 91% precision with mAP value of 84%. The experimental results demonstrate that the system is able to detect abnormalities in endoscopic images with good performance without any human intervention.
C1 [Ghatwary, Noha; Ye, Xujiong] Univ Lincoln, Comp Sci Dept, Lincoln LN6 7TS, England.
   [Ghatwary, Noha] Arab Acad Sci Technol & Maritime Transport, Comp Engn Dept, Alexandria 1029, Egypt.
   [Zolgharni, Massoud] Univ West London, Sch Comp & Engn, London W5 5RF, England.
C3 University of Lincoln; Egyptian Knowledge Bank (EKB); Arab Academy for
   Science, Technology & Maritime Transport
RP Ghatwary, N (通讯作者)，Univ Lincoln, Comp Sci Dept, Lincoln LN6 7TS, England.; Ghatwary, N (通讯作者)，Arab Acad Sci Technol & Maritime Transport, Comp Engn Dept, Alexandria 1029, Egypt.
EM nghatwary@lincoln.ac.uk
OI Zolgharni, Massoud/0000-0003-0904-2904; ye, xujiong/0000-0003-0115-0724
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Cao ZT, 2017, LECT NOTES COMPUT SC, V10530, P121, DOI 10.1007/978-3-319-67434-6_14
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P2355, DOI 10.1109/LGRS.2017.2764915
   de Souza LA, 2018, COMPUT BIOL MED, V96, P203, DOI 10.1016/j.compbiomed.2018.03.014
   de Souza LA, 2018, SIBGRAPI, P166, DOI 10.1109/SIBGRAPI.2018.00028
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gao QY, 2015, BEST PRACT RES CL GA, V29, P885, DOI 10.1016/j.bpg.2015.09.018
   Ghatwary N., 2017, INT SOC OPT PHOTON, V3
   Ghatwary N, 2017, COMM COM INF SC, V723, P897, DOI 10.1007/978-3-319-60964-5_78
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosseini S., 2018, ARXIV180107848, P8
   Hu Y, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P386, DOI 10.1109/ICISCE.2016.91
   Huang G., 2018, DENSELY CONNECTED CO
   Janse M. H. A., 2016, INT SOC OPT PHOTON, V24
   Kwolek B, 2005, LECT NOTES COMPUT SC, V3696, P551, DOI 10.1007/11550822_86
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu W, 2018, P IEEE C COMPUTER VI
   Liu YJ, 2018, IEEE ACCESS, V6, P49080, DOI 10.1109/ACCESS.2018.2865544
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Mendel R., 2017, BILDVERARBEITUNG MED, P80
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Munzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Papa J.a.P., 2017, BILDVERARBEITUNG F R, P141, DOI [10.1007/978-3-662-54345-0, DOI 10.1007/978-3-662-54345-0]
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Scholvinck DW, 2017, ENDOSCOPY, V49, P113, DOI 10.1055/s-0042-118312
   Setio A. A., 2013, PROC VISAPP, V1, P238
   Shi QQ, 2018, IEEE ACCESS, V6, P38656, DOI 10.1109/ACCESS.2018.2853620
   Simonyan K, 2015, Arxiv
   Sommen F. V. D., 2013, INT SOC OPT PHOTON, V28
   Sommen F. V. D., 2016, P INT SOC OPT PHOT M, V24
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   van Riel S, 2018, IEEE IMAGE PROC, P1383, DOI 10.1109/ICIP.2018.8451771
   Vilarino F, 2006, INT C PATT RECOG, P719
   Wang YH, 2013, J ALLERGY CLIN IMMUN, V131, P1583, DOI 10.1016/j.jaci.2013.04.010
   Yi J., 2017, P IEEE C COMPUTER VI, P108
NR 42
TC 26
Z9 26
U1 1
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 84374
EP 84385
DI 10.1109/ACCESS.2019.2925585
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA IJ3JV
UT WOS:000475801900001
OA Green Accepted, gold
DA 2023-04-20
ER

PT J
AU Horie, Y
   Yoshio, T
   Aoyama, K
   Yoshimizu, S
   Horiuchi, Y
   Ishiyama, A
   Hirasawa, T
   Tsuchida, T
   Ozawa, T
   Ishihara, S
   Kumagai, Y
   Fujishiro, M
   Maetani, I
   Fujisaki, J
   Tada, T
AF Horie, Yoshimasa
   Yoshio, Toshiyuki
   Aoyama, Kazuharu
   Yoshimizu, Shoichi
   Horiuchi, Yusuke
   Ishiyama, Akiyoshi
   Hirasawa, Toshiaki
   Tsuchida, Tomohiro
   Ozawa, Tsuyoshi
   Ishihara, Soichiro
   Kumagai, Youichi
   Fujishiro, Mitsuhiro
   Maetani, Iruru
   Fujisaki, Junko
   Tada, Tomohiro
TI Diagnostic outcomes of esophageal cancer by artificial intelligence
   using convolutional neural networks
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID CLASSIFICATION; ENDOSCOPY
AB Background and Aims: The prognosis of esophageal cancer is relatively poor. Patients are usually diagnosed at an advanced stage when it is often too late for effective treatment. Recently, artificial intelligence (AI) using deep learning has made remarkable progress in medicine. However, there are no reports on its application for diagnosing esophageal cancer. Here, we demonstrate the diagnostic ability of AI to detect esophageal cancer including squamous cell carcinoma and adenocarcinoma.
   Methods: We retrospectively collected 8428 training images of esophageal cancer from 384 patients at the Cancer Institute Hospital, Japan. Using these, we developed deep learning through convolutional neural networks (CNNs). We also prepared 1118 test images for 47 patients with 49 esophageal cancers and 50 patients without esophageal cancer to evaluate the diagnostic accuracy.
   Results: The CNN took 27 seconds to analyze 1118 test images and correctly detected esophageal cancer cases with a sensitivity of 98%. CNN could detect all 7 small cancer lesions less than 10mmin size. Although the positive predictive value for each image was 40%, misdiagnosing shadows and normal structures led to a negative predictive value of 95%. The CNN could distinguish superficial esophageal cancer from advanced cancer with an accuracy of 98%.
   Conclusions: The constructed CNN system for detecting esophageal cancer can analyze stored endoscopic images in a short time with high sensitivity. However, more training would lead to higher diagnostic accuracy. This system can facilitate early detection in practice, leading to a better prognosis in the near future.
C1 [Horie, Yoshimasa; Yoshio, Toshiyuki; Yoshimizu, Shoichi; Horiuchi, Yusuke; Ishiyama, Akiyoshi; Hirasawa, Toshiaki; Tsuchida, Tomohiro; Fujisaki, Junko] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Gastroenterol, Tokyo, Japan.
   [Horie, Yoshimasa; Maetani, Iruru] Toho Univ, Div Gastroenterol & Hepatol, Dept Internal Med, Ohashi Med Ctr, Tokyo, Japan.
   [Yoshio, Toshiyuki; Hirasawa, Toshiaki; Ozawa, Tsuyoshi; Ishihara, Soichiro; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] Al Med Serv Inc, Tokyo, Japan.
   [Ozawa, Tsuyoshi; Ishihara, Soichiro] Int Univ Hlth & Welf, Sanno Hosp, Surg Dept, Tokyo, Japan.
   [Kumagai, Youichi] Saitama Med Univ, Dept Digest Tract & Gen Surg, Saitama Med Ctr, Saitama, Japan.
   [Fujishiro, Mitsuhiro] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
C3 Japanese Foundation for Cancer Research; Toho University; International
   University of Health & Welfare; Saitama Medical University; University
   of Tokyo; University of Tokyo
RP Yoshio, T (通讯作者)，Canc Inst Hosp, Dept Gastroenterol, Koto Ku, 3-8-31 Ariake, Tokyo 1358550, Japan.
RI Ishihara, Soichiro/AFK-1375-2022; 藤城, 光弘/AAN-3131-2020; Yoshio,
   Toshiyuki/ABC-4723-2021; Horiuchi, Yusuke/V-3881-2019
OI Yoshio, Toshiyuki/0000-0002-6546-0329; Horiuchi,
   Yusuke/0000-0001-8116-8152; Fujishiro, Mitsuhiro/0000-0002-4074-1140;
   Hirasawa, Toshiaki/0000-0002-6450-1934
CR [Anonymous], 2012, EST CANC INC MORT PR
   Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Ishihara R, 2010, DIS ESOPHAGUS, V23, P480, DOI 10.1111/j.1442-2050.2009.01039.x
   Kuraoka K, 2009, HEPATO-GASTROENTEROL, V56, P63
   Kuwano H, 2015, ESOPHAGUS-TOKYO, V12, P1, DOI 10.1007/s10388-014-0465-1
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee YC, 2009, GASTROINTEST ENDOSC, V69, P408, DOI 10.1016/j.gie.2008.05.033
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Nagami Y, 2014, AM J GASTROENTEROL, V109, P845, DOI 10.1038/ajg.2014.94
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Yoshida H, 2018, GASTRIC CANCER, V21, P249, DOI 10.1007/s10120-017-0731-8
NR 14
TC 210
Z9 226
U1 18
U2 100
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JAN
PY 2019
VL 89
IS 1
BP 25
EP 32
DI 10.1016/j.gie.2018.07.037
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HE5FA
UT WOS:000453397800004
PM 30120958
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Ito, N
   Kawahira, H
   Nakashima, H
   Uesato, M
   Miyauchi, H
   Matsubara, H
AF Ito, Nao
   Kawahira, Hiroshi
   Nakashima, Hirotaka
   Uesato, Masaya
   Miyauchi, Hideaki
   Matsubara, Hisahiro
TI Endoscopic Diagnostic Support System for cT1b Colorectal Cancer Using
   Deep Learning
SO ONCOLOGY
LA English
DT Article
DE Colorectal cancer; Endoscopy; Convolutional neural network; Diagnosis
ID BAND IMAGING NBI; HELICOBACTER-PYLORI INFECTION; CONVENTIONAL
   COLONOSCOPY; DIFFERENTIAL-DIAGNOSIS; OPTICAL DIAGNOSIS; CHROMOENDOSCOPY;
   LESIONS; CARCINOMA; POLYPS; CLASSIFICATION
AB Objective: This study aimed to use convolutional neural network (CNN), a deep learning software, to assist in cT1b diagnosis. Methods: This retrospective study used 190 colon lesion images from 41 cases of colon endoscopies performed between February 2015 and October 2016. Unenhanced colon endoscopy images (520 x 520 pixels) with white light were used. Images included 14 cTis cases with endoscopic resection and 14 cT1a and 13 cT1b cases with surgical resection. Protruding, flat, and recessed lesions were analyzed. AlexNet and Caffe were used for machine learning. Fine tuning of data to increase image numbers was performed. Oversampling for the training images was conducted to avoid impartiality in image numbers, and learning was carried out. The 3-fold cross-validation method was used. Sensitivity, specificity, accuracy, and area under the curve (AUC) values in the receiver operating characteristic curve were calculated for each group. Results: The results were the average of obtained values. With CNN learning, cT1b sensitivity, specificity, and accuracy were 67.5, 89.0, and 81.2%, respectively, and AUC was 0.871. Conclusion: Quantitative diagnosis is possible using an endoscopic diagnostic support system with machine learning, without relying on the skill and experience of endoscopists. Moreover, this system could be used to objectively evaluate endoscopic diagnoses. (C) 2018 S. Karger AG, Basel
C1 [Ito, Nao] Chiba Univ, Grad Sch Engn, Dept Med Syst Engn, Chiba, Japan.
   [Kawahira, Hiroshi] Chiba Univ, Ctr Frontier Med Engn, Chiba, Japan.
   [Nakashima, Hirotaka] Fdn Detect Early Gastr Carcinoma, Dept Gastroenterol, Tokyo, Japan.
   [Uesato, Masaya; Miyauchi, Hideaki; Matsubara, Hisahiro] Chiba Univ, Grad Sch Med, Dept Frontier Surg, Chiba, Japan.
C3 Chiba University; Chiba University; Chiba University
RP Kawahira, H (通讯作者)，Jichi Med Univ, Med Simulat Ctr, 3311-1 Yakushiji, Shimotuke, Tochigi 3290498, Japan.
EM kawahira@jichi.ac.jp
OI Ito, Nao/0000-0002-0929-4418; Nakashima, Hirotaka/0000-0002-2386-1933
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Apel D, 2006, GASTROINTEST ENDOSC, V63, P824, DOI 10.1016/j.gie.2005.09.013
   De Palma GD, 2006, WORLD J GASTROENTERO, V12, P2402
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Fu KI, 2004, ENDOSCOPY, V36, P1089, DOI 10.1055/s-2004-826039
   FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3
   Girshick R., 2013, P IEEE, P580
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Gono K, 2004, OPT LETT, V29, P971, DOI 10.1364/OL.29.000971
   Haruki S, 2012, GASTROENT RES PRACT, V2012, P1
   Hisabe T, 2018, ENDOSC INT OPEN, V6, pE156, DOI 10.1055/s-0043-121881
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Iwatate M, 2015, ENDOSC INT OPEN, V3, pE140, DOI 10.1055/s-0034-1391362
   Jia Y., 2014, CONVOLUTIONAL ARCHIT
   Kitajima K, 2004, J GASTROENTEROL, V39, P534, DOI 10.1007/s00535-004-1339-4
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P49, DOI 10.1159/000481230
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Kronborg O, 2004, ENDOSCOPY, V36, P3
   LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Sanomura M, 2016, DIGESTION, V94, P106, DOI 10.1159/000449284
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Stewart B.W., 2014, WORLD CANC REPORT 20
   Su MY, 2006, AM J GASTROENTEROL, V101, P2711, DOI 10.1111/j.1572-0241.2006.00932.x
   TANAKA S, 1995, J GASTROENTEROL, V30, P710, DOI 10.1007/BF02349636
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   Watanabe T, 2018, INT J CLIN ONCOL, V23, P1, DOI 10.1007/s10147-017-1101-6
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
NR 33
TC 37
Z9 38
U1 1
U2 12
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0030-2414
EI 1423-0232
J9 ONCOLOGY-BASEL
JI Oncology
PY 2019
VL 96
IS 1
BP 44
EP 50
DI 10.1159/000491636
PG 7
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA HG6BT
UT WOS:000455066700006
PM 30130758
DA 2023-04-20
ER

PT J
AU Jani, KK
   Srivastava, S
   Srivastava, R
AF Jani, Kuntesh K.
   Srivastava, Subodh
   Srivastava, Rajeev
TI Computer aided diagnosis system for ulcer detection in capsule endoscopy
   using optimized feature set
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Automated ulcer detection; CAD; capsule endoscopy; feature selection;
   HVLC
ID CLASSIFICATION; SELECTION; TEXTURE; INFORMATION
AB One of the most common lesions of the gastrointestinal tract (GIT) is an ulcer. Capsule endoscopy (CE) is a recent advancement in the field of gastroenterology for diagnosis of GIT abnormalities. However, CE video length ranges from 6 to 8 hours generating approximately 60000 images. For a medical expert, examination of such lengthy videos is time-consuming and tiresome. Also, the accuracy of diagnosis will largely depend upon individual expertise. A computer-aided diagnosis (CAD) system can significantly improve accuracy and reduce diagnosis time. In the proposed automated ulcer detection system, relevant features of the histogram of oriented gradients (HOG) and uniform local binary patterns (LBP) are optimally selected by high variance low correlation (HVLC) based novel feature selection technique and the classification task is performed using support vector machine (SVM). Proposed feature selection technique reduces the feature set by 96.53% and outperforms five other state of the art feature selection techniques. The performance of proposed system is compared with other systems and it performs with accuracy, F measure and sensitivity of 95%, 95.12%, and 97.5% respectively.
C1 [Jani, Kuntesh K.; Srivastava, Rajeev] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
   [Srivastava, Subodh] Natl Inst Technol, Dept Elect & Commun Engn, Patna, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); National Institute of
   Technology (NIT System); National Institute of Technology Patna
RP Jani, KK (通讯作者)，Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM kunteshj.rs.cse17@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016; Dr. Subodh Srivastava,
   Professor/AAB-6044-2019
OI Srivastava, Rajeev/0000-0002-0165-1556; Dr. Subodh Srivastava,
   Professor/0000-0001-6194-429X
CR Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Cho YJ, 2016, J MED BIOL ENG, V36, P871, DOI 10.1007/s40846-016-0190-4
   Dalai N., 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Doshi M., 2014, INT J COMPUT NETWORK, V6, P197, DOI [10.5121/ijcnc.2014.6315, DOI 10.5121/IJCNC.2014.6315]
   Du L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P209, DOI 10.1145/2783258.2783345
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jia YQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1631, DOI 10.1109/ROBIO.2015.7419005
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621
   Koshy NE, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1725, DOI 10.1109/ECS.2015.7124881
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Moradi M, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA)
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pathak SS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING AND TECHNOLOGY (ICETECH), P163
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Sahidan SI, 2008, IFMBE PROC, V21, P583
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh VP, 2017, TECHNOL HEALTH CARE, V25, P709, DOI 10.3233/THC-170851
   Spyrou E, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/1/015002
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Vu H, 2009, COMPUT BIOL MED, V39, P16, DOI 10.1016/j.compbiomed.2008.10.005
   Wang S, 2016, IEEE T BIO-MED ENG, V63, P2347, DOI 10.1109/TBME.2016.2530141
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
NR 27
TC 1
Z9 1
U1 0
U2 3
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2019
VL 37
IS 1
BP 1491
EP 1498
DI 10.3233/JIFS-182883
PG 8
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IH7WL
UT WOS:000474715000122
DA 2023-04-20
ER

PT J
AU Jani, KK
   Srivastava, R
AF Jani, Kuntesh Ketan
   Srivastava, Rajeev
TI A Survey on Medical Image Analysis in Capsule Endoscopy
SO CURRENT MEDICAL IMAGING
LA English
DT Review
DE CE; image-analysis; automated abnormality detection; non-invasive;
   gastroenterologist; medical image analysis
ID COLOR-SPACE; SMALL-BOWEL; SEGMENTATION; SYSTEM; COMPRESSION; TEXTURE
AB Background and Objective: Capsule Endoscopy (CE) is a non-invasive, patient-friendly alternative to conventional endoscopy procedure. However, CE produces 6 to 8 hrs long video posing a tedious challenge to a gastroenterologist for abnormality detection. Major challenges to an expert are lengthy videos, need of constant concentration and subjectivity of the abnormality. To address these challenges along with high diagnostic accuracy, design and development of automated abnormality detection system is a must. Machine learning and computer vision techniques are devised to develop such automated systems.
   Methods: Study presents a review of quality research papers published in IEEE, Scopus, and Science Direct database with search criteria as capsule endoscopy, engineering, and journal papers. The initial search retrieved 144 publications. After evaluating all articles, 62 publications pertaining to image analysis are selected.
   Results: This paper presents a rigorous review comprising all the aspects of medical image analysis concerning capsule endoscopy namely video summarization and redundant image elimination, Image enhancement and interpretation, segmentation and region identification, Computer-aided abnormality detection in capsule endoscopy, Image and video compression. The study provides a comparative analysis of various approaches, experimental setup, performance, strengths, and limitations of the aspects stated above.
   Conclusions: The analyzed image analysis techniques for capsule endoscopy have not yet overcome all current challenges mainly due to lack of dataset and complex nature of the gastrointestinal tract.
C1 [Jani, Kuntesh Ketan; Srivastava, Rajeev] Banaras Hindu Univ, Indian Inst Technol, Comp Sci & Engn Dept, Varanasi 221005, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi)
RP Jani, KK (通讯作者)，Banaras Hindu Univ, Indian Inst Technol, Comp Sci & Engn Dept, Varanasi 221005, Uttar Pradesh, India.
EM kunteshj.rs.cse17@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016
OI Srivastava, Rajeev/0000-0002-0165-1556
CR Arivazhagan S, 2014, INT J IMAGING ROBOT, V13, P134
   Baazaoui A, 2016, CURR MED IMAGING, V12, P13, DOI 10.2174/1573405612666151203204003
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Ben Ismail MM, 2016, J EXP THEOR ARTIF IN, V28, P629, DOI 10.1080/0952813X.2015.1020623
   Bonnel J, 2009, BIOMED SIGNAL PROCES, V4, P7, DOI 10.1016/j.bspc.2008.07.002
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Chen HH, 2017, NEUROCOMPUTING, V229, P77, DOI 10.1016/j.neucom.2016.06.077
   Deligiannis N, 2012, EURASIP J WIREL COMM, P1, DOI 10.1186/1687-1499-2012-106
   Drozdzal M, 2013, COMPUT MED IMAG GRAP, V37, P72, DOI 10.1016/j.compmedimag.2012.09.002
   Fante KA, 2016, CIRC SYST SIGNAL PR, V35, P1677, DOI 10.1007/s00034-015-0136-z
   Ghosh T, 2017, COMPUT BIOL MED, V2018, P41
   Graca C, 2017, J REAL-TIME IMAGE PR, V13, P227, DOI 10.1007/s11554-015-0517-3
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karargyris A, 2011, IEEE T MED IMAGING, V30, P957, DOI 10.1109/TMI.2010.2098882
   Kaur P, 2018, CURR MED IMAGING REV, V14, P675, DOI 10.2174/1573405613666170428154156
   Khan TH, 2011, ELECTRON LETT, V47, P1217, DOI 10.1049/el.2011.2211
   Khan TH, 2014, SIGNAL PROCESS-IMAGE, V29, P345, DOI 10.1016/j.image.2013.12.001
   Khan TH, 2011, VLSI DES, DOI 10.1155/2011/343787
   Khan TH, 2013, J REAL-TIME IMAGE PR, V8, P5, DOI 10.1007/s11554-011-0208-7
   Khan TH, 2011, IEEE T CIRC SYST VID, V21, P1534, DOI 10.1109/TCSVT.2011.2163985
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Kumar R, 2017, COMPUT METH PROG BIO, V146, P59, DOI 10.1016/j.cmpb.2017.05.003
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Lee HG, 2013, COMPUT BIOL MED, V43, P670, DOI 10.1016/j.compbiomed.2013.02.009
   Li BP, 2012, J MED SYST, V36, P2463, DOI 10.1007/s10916-011-9713-2
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Li C, 2012, SIGNAL IMAGE VIDEO P, V8, P1497
   Lin LH, 2018, CURR MED IMAGING, V14, P64, DOI 10.2174/1573405613666171003151036
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   Liu JG, 2009, OPTIM ENG, V10, P289, DOI 10.1007/s11081-008-9066-y
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Mamonov AV, 2013, ICES REP, V33, P1
   Masood S, 2015, CURR MED IMAGING, V11, P3, DOI 10.2174/157340561101150423103441
   Mehmood I, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0109-y
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Pan Guo-bing, 2010, Journal of Shanghai Jiaotong University (English Edition), V15, P218, DOI 10.1007/s12204-010-9716-z
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Ross BWW, 1964, MED ELECT BIOL ENG, V2, P349
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sevo I, 2016, COMPUT BIOL MED, V72, P138, DOI 10.1016/j.compbiomed.2016.03.017
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh VP, 2018, J X-RAY SCI TECHNOL, V26, P29, DOI 10.3233/XST-17306
   Singh VP, 2017, INTEGR MED RES, V38, P90
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Swift Stephen J., 2012, REDUCING SIZE IMPROV
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Szczypinski PM, 2009, MED IMAGE ANAL, V13, P312, DOI 10.1016/j.media.2008.12.002
   Thone J, 2010, PROCEDIA ENGINEER, V5, P208, DOI 10.1016/j.proeng.2010.09.084
   Turcza P, 2011, SENSOR ACTUAT A-PHYS, V172, P552, DOI 10.1016/j.sna.2011.09.026
   Turgis D, 2005, SENSOR ACTUAT A-PHYS, V123-24, P129, DOI 10.1016/j.sna.2005.05.016
   Usman MA, 2016, COMPUT MED IMAG GRAP, V54, P16, DOI 10.1016/j.compmedimag.2016.09.005
   Vilarino F, 2006, PATTERN RECOGN LETT, V27, P875, DOI 10.1016/j.patrec.2005.10.011
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Vu H, 2009, COMPUT BIOL MED, V39, P16, DOI 10.1016/j.compbiomed.2008.10.005
   Woo SH, 2010, MED BIOL ENG COMPUT, V48, P277, DOI 10.1007/s11517-009-0567-4
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Yanagawa Y, 2017, IPSJ T COMPUT VIS AP, V9, P1
   Yihua Lan, 2013, Information Technology Journal, V12, P3815, DOI 10.3923/itj.2013.3515.3519
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhao Q, 2015, COMPUT MED IMAG GRAP, V41, P108, DOI 10.1016/j.compmedimag.2014.05.011
NR 74
TC 6
Z9 6
U1 4
U2 11
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1573-4056
EI 1875-6603
J9 CURR MED IMAGING
JI Curr. Med. Imaging
PY 2019
VL 15
IS 7
BP 622
EP 636
DI 10.2174/1573405614666181102152434
PG 15
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA IU1NR
UT WOS:000483343500002
PM 32008510
DA 2023-04-20
ER

PT J
AU Kang, J
   Gwak, J
AF Kang, Jaeyong
   Gwak, Jeonghwan
TI Ensemble of Instance Segmentation Models for Polyp Segmentation in
   Colonoscopy Images
SO IEEE ACCESS
LA English
DT Article
DE Polyp segmentation; transfer learning; medical image analysis; deep
   learning; machine learning; artificial intelligence
ID CONVOLUTIONAL NEURAL-NETWORK; AUTOMATIC SEGMENTATION; DIAGNOSIS;
   VALIDATION
AB Colorectal cancer is the second most frequently diagnosed cancer in women and the third most frequently diagnosed cancer in men. At least 80%-95% of the colorectal cancers are evolved from intestinal polyps. Although colonoscopy is regarded as the most effective method for screening and diagnosis, the success of the procedure is highly dependent on the level of hand-eye coordination and the operator skills. Thus, we are primarily motivated by the need for obtaining an early and accurate diagnosis of polyps in the colonoscopy images. In this paper, we employed the powerful object detection neural network "Mask R-CNN'' to identify and segment polyps in the colonoscopy images. Also, we proposed an ensemble method to combine the two Mask R-CNN models with different backbone structures (ResNet50 and ResNet101) to enhance the performance. Mask R-CNNs in our model were first trained on COCO dataset, and then finely tuned using intestinal polyp dataset since a large number of annotated colonoscopy images are not easily accessible. In order to evaluate our proposed model, we used three open intestinal polyp datasets, CVC-ClinicDB, ETIS-Larib, and CVC-ColonDB. Our results show that our transfer learning-based ensemble model significantly outperforms state-of-the-art methods.
C1 [Kang, Jaeyong; Gwak, Jeonghwan] Seoul Natl Univ Hosp, Biomed Res Inst, Seoul 03080, South Korea.
   [Gwak, Jeonghwan] Seoul Natl Univ Hosp, Dept Radiol, Seoul 03080, South Korea.
   [Gwak, Jeonghwan] Seoul Natl Univ, Coll Med, Dept Radiol, Seoul 03080, South Korea.
C3 Seoul National University (SNU); Seoul National University Hospital;
   Seoul National University (SNU); Seoul National University Hospital;
   Seoul National University (SNU)
RP Gwak, J (通讯作者)，Seoul Natl Univ Hosp, Biomed Res Inst, Seoul 03080, South Korea.; Gwak, J (通讯作者)，Seoul Natl Univ Hosp, Dept Radiol, Seoul 03080, South Korea.; Gwak, J (通讯作者)，Seoul Natl Univ, Coll Med, Dept Radiol, Seoul 03080, South Korea.
EM james.han.gwak@gmail.com
OI Gwak, Jeonghwan/0000-0002-6237-0141
FU National Research Foundation of Korea (NRF), the Ministry of Education
   [NRF-2017R1D1A1B03036423]; NRF, the Ministry of Science, ICT and Future
   Planning (MSIT) [NRF-2016M3C7A1905477, NRF-2019M3C7A1020406];
   Engineering Research Center (ERC) Program of Extreme Exploitation of
   Dark Data through the Korean Government (MSIT) [NRF-2018R1A5A1060031]
FX This work was supported in part by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF), the Ministry of
   Education, under Grant NRF-2017R1D1A1B03036423, in part by the Brain
   Research Program through the NRF, the Ministry of Science, ICT and
   Future Planning (MSIT), under Grant NRF-2016M3C7A1905477 and Grant
   NRF-2019M3C7A1020406, and in part by the Engineering Research Center
   (ERC) Program of Extreme Exploitation of Dark Data through the Korean
   Government (MSIT) under Grant NRF-2018R1A5A1060031.
CR Akbari  M., 2018, POLYP SEGMENTATION C
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   de Brebisson Alexandre, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P20, DOI 10.1109/CVPRW.2015.7301312
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   He K., 2017, IEEE I CONF COMP VIS, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu X, 2010, P INT C MULT, P451, DOI DOI 10.1145/1873951.1874016
   Hu XT, 2012, IEEE T MULTIMEDIA, V14, P314, DOI 10.1109/TMM.2011.2172201
   Hwang S., 2007, P 2007 IEEE INT C IM, DOI [DOI 10.1109/ICIP.2007.4379193, 10.1109/ICIP.2007.4379193]
   Jia YQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1631, DOI 10.1109/ROBIO.2015.7419005
   Karargyris A, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P143, DOI 10.1109/LISSA.2009.4906730
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Nasr-Esfahani E, 2016, IEEE ENG MED BIO, P1373, DOI 10.1109/EMBC.2016.7590963
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Park S., 2015, POLYP DETECTION COLO
   Parkin M. C., 2008, GLOBOCAN 2008 V1 2 C
   Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Roth HR, 2015, PROC SPIE, V9413, DOI 10.1117/12.2081420
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Tulum G, 2017, INT J COMPUT ASS RAD, V12, P627, DOI 10.1007/s11548-017-1521-9
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang Z, 2004, PROC SPIE, V5370, P972, DOI 10.1117/12.535664
   Wolterink JM, 2015, LECT NOTES COMPUT SC, V9349, P589, DOI 10.1007/978-3-319-24553-9_72
   Xiang Ji, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3633, DOI 10.1109/ICIP.2011.6116505
   Zhang JL, 2018, GEOPHYS RES LETT, V45, P8665, DOI 10.1029/2018GL077787
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang YT, 2015, PROC CVPR IEEE, P249, DOI 10.1109/CVPR.2015.7298621
NR 47
TC 59
Z9 60
U1 4
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 26440
EP 26447
DI 10.1109/ACCESS.2019.2900672
PG 8
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA HP3GC
UT WOS:000461563700001
OA gold
DA 2023-04-20
ER

PT J
AU Lan, LB
   Ye, CX
   Wang, CL
   Zhou, SB
AF Lan, Libin
   Ye, Chunxiao
   Wang, Chengliang
   Zhou, Shangbo
TI Deep Convolutional Neural Networks for WCE Abnormality Detection: CNN
   Architecture, Region Proposal and Transfer Learning
SO IEEE ACCESS
LA English
DT Article
DE Convolutional neural networks; medical image analysis; region proposal;
   transfer learning; wireless capsule endoscopy; WCE abnormality detection
ID WIRELESS CAPSULE ENDOSCOPY; IMAGE SEGMENTATION; OBJECT DETECTION;
   RECOGNITION; ENTEROSCOPY; CANCER
AB Wireless capsule endoscopy (WCE) plays an important role in the diagnosis of gastrointestinal diseases. However, it is very time-consuming and fatiguing for a physician to review a large number of WCE images. Some methods to address this problem have recently been presented. However, these methods generally employ classification algorithms to discriminate abnormal from normal images, which do not localize, recognize, or detect abnormal patterns in abnormal images. We sought to identify a better method for the WCE abnormal pattern detection. In this paper, convolutional neural networks (CNNs) are used to implement detection function, and several methods are also adopted to boost the performance of WCE abnormality detection from aspects of the CNN architecture, region proposal, and transfer learning. First, we present a deep cascade network, namely, CascadeProposal, trained end-to-end to generate a small number of region proposals with high-recall by a region proposal rejection module and to simultaneously detect abnormal patterns using a detection module. Second, we use a multiregional combination (MRC) method to obtain good coverage of the regions of interest and employ the salient region segmentation (SRS) method to capture accurate region locations. Third, we use the dense region fusion (DRF) method for object boundary refinement. Fourth, we introduce negative category (Neg) and transfer learning (TL) strategies into our CNNs to obtain a better model performance. The extensive experiments are performed on our WCE image dataset of more than 7k annotated images. A final mean average precision (mAP) of 70.3% and a better mAP of 72.3% can be achieved via CascadeProposal with ZF and Fast R-CNN with VGG-16 networks, respectively, using MRC+Neg+TL method in the training stage and MRC+DRF+SRS method in the testing stage. The comprehensive results demonstrate that our method is efficient and effective for WCE abnormality detection with high-localization accuracy.
C1 [Lan, Libin; Ye, Chunxiao] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400030, Peoples R China.
   [Wang, Chengliang; Zhou, Shangbo] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
C3 Chongqing University; Chongqing University
RP Ye, CX (通讯作者)，Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400030, Peoples R China.
EM yecx@cqu.edu.cn
RI Lan, Libin/W-8052-2019
OI Lan, Libin/0000-0003-4754-813X; Zhou, Shangbo/0000-0001-5057-8431
FU National Natural Science Foundation of China [61672115]; Major Project
   of Fundamental Science and Frontier Technology Research of Chongqing
   CSTC [cstc2015jcyjBX0124]; Chongqing Social Undertakings and Livelihood
   Security Science and Technology Innovation Project Special Program
   [cstc2017shmsA30003]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61672115, in part by the Major Project
   of Fundamental Science and Frontier Technology Research of Chongqing
   CSTC under Grant cstc2015jcyjBX0124, and in part by the Chongqing Social
   Undertakings and Livelihood Security Science and Technology Innovation
   Project Special Program under Grant cstc2017shmsA30003.
CR Adler DG, 2004, GASTROINTEST ENDOSC, V59, P492, DOI 10.1016/S0016-5107(03)02862-1
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Alizadeh M, 2017, J BIOMED RES, V31, P419, DOI 10.7555/JBR.31.20160008
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Borji A., 2017, SALIENT OBJECT DETEC
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Deng Y, 2017, IEEE T FUZZY SYST, V25, P1006, DOI 10.1109/TFUZZ.2016.2574915
   Deng Y, 2016, IEEE T IMAGE PROCESS, V25, P4209, DOI 10.1109/TIP.2016.2588330
   Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296
   Gidaris S, 2016, PROC CVPR IEEE, P789, DOI 10.1109/CVPR.2016.92
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R., 2013, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Hajabdollahi M., 2018, MULTIPLE ABNORMALITY
   Hartmann D, 2005, GASTROINTEST ENDOSC, V61, P826, DOI 10.1016/S0016-5107(05)00372-X
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hosang J.H., 2014, BMVC
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Jia Y., 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Kuo WC, 2015, IEEE I CONF COMP VIS, P2479, DOI 10.1109/ICCV.2015.285
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Mackiewicz M., 2006, P IEEE AC SPEECH SIG, P2
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Maghsoudi O.H., 2014, J ADV COMPUT, V3, P12, DOI [10.7726/jac.2014.1002a, DOI 10.7726/JAC.2014.1002A]
   Maghsoudi O.H., 2017, SUPERPIXEL BASED SEG, VVolume 2018, P1, DOI [DOI 10.1109/SPMB.2017.8257027, 10.1109/SPMB.2017.8257027]
   Mohammed A, 2017, COMP MED SY, P728, DOI 10.1109/CBMS.2017.13
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Rajpurkar P, 2017, Arxiv
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Sermanet P., 2013, COMPUT VIS PATTERN R, V1312, P6229
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Wang Dayong, 2016, ARXIV160605718
   Xiao YW, 2018, COMPUT METH PROG BIO, V153, P1, DOI 10.1016/j.cmpb.2017.09.005
   Xu SJ, 2019, IEEE ACCESS, V7, P4466, DOI 10.1109/ACCESS.2018.2885997
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yuan YX, 2018, IEEE T CYBERNETICS, V48, P2074, DOI 10.1109/TCYB.2017.2726818
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 77
TC 23
Z9 24
U1 2
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 30017
EP 30032
DI 10.1109/ACCESS.2019.2901568
PG 16
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA HQ8CZ
UT WOS:000462652800001
OA gold
DA 2023-04-20
ER

PT J
AU Leenhardt, R
   Vasseur, P
   Li, C
   Saurin, JC
   Rahmi, G
   Cholet, F
   Becq, A
   Marteau, P
   Histace, A
   Dray, X
AF Leenhardt, Romain
   Vasseur, Pauline
   Li, Cynthia
   Saurin, Jean Christophe
   Rahmi, Gabriel
   Cholet, Franck
   Becq, Aymeric
   Marteau, Philippe
   Histace, Aymeric
   Dray, Xavier
CA CAD-CAP Database Working Grp
TI A neural network algorithm for detection of GI angiectasia during
   small-bowel capsule endoscopy
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID DIAGNOSIS
AB Background and Aims: GI angiectasia (GIA) is the most common small-bowel (SB) vascular lesion, with an inherent risk of bleeding. SB capsule endoscopy (SB-CE) is the currently accepted diagnostic procedure. The aim of this study was to develop a computer-assisted diagnosis tool for the detection of GIA.
   Methods: Deidentified SB-CE still frames featuring annotated typical GIA and normal control still frames were selected from a database. A semantic segmentation images approach associated with a convolutional neural network (CNN) was used for deep-feature extractions and classification. Two datasets of still frames were created and used for machine learning and for algorithm testing.
   Results: The GIA detection algorithm yielded a sensitivity of 100%, a specificity of 96%, a positive predictive value of 96%, and a negative predictive value of 100%. Reproducibility was optimal. The reading process for an entire SB-CE video would take 39 minutes.
   Conclusions: The developed CNN-based algorithm had high diagnostic performances, allowing detection of GIA in SB-CE still frames. This study paves the way for future automated CNN-based SB-CE reading softwares.
C1 [Leenhardt, Romain; Li, Cynthia; Becq, Aymeric; Marteau, Philippe; Dray, Xavier] Sorbonne Univ, St Antoine Hosp, AP HP, Dept Hepatogastroenterol, Paris, France.
   [Vasseur, Pauline; Histace, Aymeric; Dray, Xavier] Univ Cergy Pontoise, CNRS, ETIS, ENSEA, Cergy Pontoise, France.
   [Li, Cynthia] Drexel Univ, Coll Arts & Sci, Philadelphia, PA 19104 USA.
   [Saurin, Jean Christophe] Hop Edouard Herriot, Dept Endoscopy & Gastroenterol, Pavillon L, Lyon, France.
   [Rahmi, Gabriel] Georges Pompidou European Hosp, AP HP, Dept Gastroenterol & Endoscopy, Paris, France.
   [Cholet, Franck] Univ Hosp, Digest Endoscopy Unit, Brest, France.
C3 UDICE-French Research Universities; Sorbonne Universite; Assistance
   Publique Hopitaux Paris (APHP); Hopital Universitaire Saint-Antoine -
   APHP; Centre National de la Recherche Scientifique (CNRS); CY Cergy
   Paris Universite; Drexel University; CHU Lyon; UDICE-French Research
   Universities; Universite Paris Cite; Assistance Publique Hopitaux Paris
   (APHP); Hopital Universitaire Europeen Georges-Pompidou - APHP; CHU
   Brest
RP Leenhardt, R (通讯作者)，Sorbonne Univ, Dept Hepatogastroenterol, F-75012 Paris, France.
EM romainleni@gmail.com
RI saurin, jean christophe/AAB-4077-2020
OI GERARD, Romain/0000-0003-4674-7444; philippe,
   marteau/0000-0002-7621-6719
FU Societe Nationale Francaise de Gastroenterologie; Mayoly Spindler (MSD)
FX The Computer-Assisted Diagnosis for Capsule Endoscopy database is
   endorsed by the Societe Francaise d'Endoscopie Digestive. It has been
   made possible with the support of the Societe Nationale Francaise de
   Gastroenterologie and Mayoly Spindler (MSD).
CR Becq A, 2017, GASTROINTEST ENDOSC, V86, P792, DOI 10.1016/j.gie.2017.05.018
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Leenhardt R, 2018, GASTROINTEST ENDOSC, V87, pAB149
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Noya F, 2017, IEEE ENG MED BIO, P3158, DOI 10.1109/EMBC.2017.8037527
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Pennazio M, 2015, ENDOSCOPY, V47, P352, DOI 10.1055/s-0034-1391855
   Saurin JC, 2018, ENDOSC INT OPEN, V6, pE616, DOI 10.1055/a-0587-4788
   Saurin JC, 2012, DIGEST LIVER DIS, V44, P477, DOI 10.1016/j.dld.2011.12.021
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P43, DOI 10.1080/17474124.2017.1257384
NR 12
TC 112
Z9 119
U1 1
U2 29
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JAN
PY 2019
VL 89
IS 1
BP 189
EP 194
DI 10.1016/j.gie.2018.06.036
PG 6
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HE5FA
UT WOS:000453397800026
PM 30017868
DA 2023-04-20
ER

PT J
AU Liu, M
   Jiang, J
   Wang, ZN
AF Liu, Ming
   Jiang, Jue
   Wang, Zenan
TI Colonic Polyp Detection in Endoscopic Videos With Single Shot Detection
   Based Deep Convolutional Neural Network
SO IEEE ACCESS
LA English
DT Article
DE Colonic polyp detection; convolutional neural network; single shot
   detector (SSD)
ID MISS RATE; COLONOSCOPY; VALIDATION
AB A major rise in the prevalence and influence of colorectal cancer (CRC) leads to substantially increasing healthcare costs and even death. It is widely accepted that early detection and removal of colonic polyps can prevent CRC. Detection of colonic polyps in colonoscopy videos is problematic because of complex environment of colon and various shapes of polyps. Currently, researchers indicate feasibility of Convolutional Neural Network (CNN)-based detection of polyps but better feature extractors are needed to improve detection performance. In this paper, we investigated the potential of the single shot detector (SSD) framework for detecting polyps in colonoscopy videos. SSD is a one-stage method, which uses a feed-forward CNN to produce a collection of fixed-size bounding boxes for each object from different feature maps. Three different feature extractors, including ResNet50, VGG16, and InceptionV3 were assessed. Multi-scale feature maps integrated into SSD were designed for ResNet50 and InceptionV3, respectively. We validated this method on the 2015 MICCAI polyp detection challenge datasets, compared it with teams attended the challenge, YOLOV3 and two-stage method, Faster-RCNN. Our results demonstrated that the proposed method surpassed all the teams in MICCAI challenge and YOLOV3 and was comparable with two-stage method. Especially in detection speed aspect, our proposed method outperformed all the methods, met real-time application requirement. Meanwhile, we also indicated that among all the feature extractors, InceptionV3 obtained the best result of precision and recall. In conclusion, SSD- based method achieved excellent detection performance in polyp detection and can potentially improve diagnostic accuracy and efficiency.
C1 [Liu, Ming] Hunan Key Lab Nonferrous Resources & Geol Hazard, Changsha 410083, Hunan, Peoples R China.
   [Jiang, Jue] Mem Sloan Kettering Canc Ctr, Dept Med Phys, New York, NY 10065 USA.
   [Wang, Zenan] Capital Med Univ, Clin Med Coll 3, Beijing Chaoyang Hosp, Dept Gastroenterol, Beijing 100020, Peoples R China.
C3 Memorial Sloan Kettering Cancer Center; Capital Medical University
RP Wang, ZN (通讯作者)，Capital Med Univ, Clin Med Coll 3, Beijing Chaoyang Hosp, Dept Gastroenterol, Beijing 100020, Peoples R China.
EM wangzenan@outlook.com
FU Digestive Medical Coordinated Development Center of Beijing Hospitals
   Authority
FX This work was supported by the Digestive Medical Coordinated Development
   Center of Beijing Hospitals Authority, No. XXT12.
CR Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hassan C, 2013, ENDOSCOPY, V45, P842, DOI 10.1055/s-0033-1344548
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li P, 2005, PROC CVPR IEEE, P670
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ozawa T, 2018, GASTROINTEST ENDOSC, V87, pAB271
   Redmon J, 2015, PROC CVPR IEEE, P779, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   van Wijk C, 2010, IEEE T MED IMAGING, V29, P688, DOI 10.1109/TMI.2009.2031323
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 37
TC 37
Z9 38
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 75058
EP 75066
DI 10.1109/ACCESS.2019.2921027
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA IE8ZZ
UT WOS:000472664200001
PM 33604228
OA Green Accepted, gold
DA 2023-04-20
ER

PT J
AU Qadir, HA
   Solhusvik, J
   Bergsland, J
   Aabakken, L
   Balasingham, I
AF Qadir, Hemin Ali
   Solhusvik, Johannes
   Bergsland, Jacob
   Aabakken, Lars
   Balasingham, Ilangko
TI A Framework With a Fully Convolutional Neural Network for Semi-Automatic
   Colon Polyp Annotation
SO IEEE ACCESS
LA English
DT Article
DE Image segmentation; Decoding; Feature extraction; Manuals; Convolutional
   neural nets; Training; Colonic polyps; Colonoscopy; polyp segmentation;
   convolutional neural networks; semi-automatic; annotation;
   semi-supervised
ID VALIDATION; FEATURES
AB Deep learning has delivered promising results for automatic polyp detection and segmentation. However, deep learning is known for being data-hungry, and its performance is correlated with the amount of available training data. The lack of large labeled polyp training images is one of the major obstacles in performance improvement of automatic polyp detection and segmentation. Labeling is typically performed by an endoscopist, who performs pixel-level annotation of polyps. Manual polyp labeling of a video sequence is difficult and time-consuming. We propose a semi-automatic annotation framework powered by a convolutional neural network (CNN) to speed up polyp annotation in video-based datasets. Our CNN network requires only ground-truth (manually annotated masks) of a few frames in a video for training and annotating the rest of the frames in a semi-supervised manner. To generate masks similar to the ground-truth masks, we use some pre and post-processing steps such as different data augmentation strategies, morphological operations, Fourier descriptors, and a second stage fine-tuning. We use Fourier coefficients of the ground-truth masks to select similar generated output masks. The results show that it is possible to 1) produce 96 of Dice similarity score between the polyp masks provided by clinicians and the masks generated by our framework, and 2) save clinicians time as they need to manually annotate only a few frames instead of annotating the entire video, frame-by-frame.
C1 [Qadir, Hemin Ali; Bergsland, Jacob; Balasingham, Ilangko] Oslo Univ Hosp OUS, Intervent Ctr, N-0372 Oslo, Norway.
   [Qadir, Hemin Ali] OmniVis Technol Norway AS, N-0349 Oslo, Norway.
   [Qadir, Hemin Ali; Solhusvik, Johannes] Univ Oslo UiO, Dept Informat, N-0373 Oslo, Norway.
   [Aabakken, Lars] Univ Oslo UiO, Fac Med, Dept Transplantat, N-0372 Oslo, Norway.
   [Balasingham, Ilangko] Norwegian Univ Sci & Technol NTNU, Dept Elect Syst, N-7012 Trondheim, Norway.
C3 University of Oslo; University of Oslo; Norwegian University of Science
   & Technology (NTNU)
RP Qadir, HA (通讯作者)，Oslo Univ Hosp OUS, Intervent Ctr, N-0372 Oslo, Norway.; Qadir, HA (通讯作者)，OmniVis Technol Norway AS, N-0349 Oslo, Norway.; Qadir, HA (通讯作者)，Univ Oslo UiO, Dept Informat, N-0373 Oslo, Norway.
EM hqadir2011@my.fit.edu
RI Balasingham, Ilangko/AGU-7268-2022; Bergsland, Jacob/H-3966-2016
OI Bergsland, Jacob/0000-0002-3101-4064; Solhusvik,
   Johannes/0000-0002-4083-5964; Balasingham, Ilangko/0000-0001-5259-3221
FU Research Council of Norway [271542/O30]
FX This work was supported by the Research Council of Norway through the
   Industrial Ph.D. Project under Contract 271542/O30.
CR Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2019, INT J COMPUT ASS RAD, V14, P191, DOI 10.1007/s11548-018-1864-x
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Castrejon L, 2017, PROC CVPR IEEE, P4485, DOI 10.1109/CVPR.2017.477
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Hovde O, 2018, P BRIT MACH VIS C 20
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Kaiming He, 2020, IEEE Transactions on Pattern Analysis and Machine Intelligence, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liew JH, 2017, IEEE I CONF COMP VIS, P2746, DOI 10.1109/ICCV.2017.297
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Marki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87
   Maninis K.-K., 2017, PAMI
   Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   PRICE BL, 2010, PROC CVPR IEEE, P3161, DOI DOI 10.1109/CVPR.2010.5540079
   Qadir H. A., IEEE J BIOMED HLTH I
   Qadir H. Ali, 2019, INT S MED INF COMM T, P1, DOI [10.1109/ISMICT.2019.8743694, DOI 10.1109/ISMICT.2019.8743694]
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Thomaz VD, 2019, COMP MED SY, P192, DOI 10.1109/CBMS.2019.00047
   Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5
   Vezhnevets V., 2005, P 15 INT C COMPUTER, P150, DOI DOI 10.1016/J.AJ0D0.2004.07.036
   Xu N, 2016, PROC CVPR IEEE, P373, DOI 10.1109/CVPR.2016.47
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Yoon JS, 2017, IEEE I CONF COMP VIS, P2186, DOI 10.1109/ICCV.2017.238
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang Z, 2019, IEEE T BIG DATA, V5, P148, DOI 10.1109/TBDATA.2018.2797977
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3388, DOI 10.1109/TNNLS.2017.2727526
   Zhang Z, 2015, IEEE T KNOWL DATA EN, V27, P2362, DOI 10.1109/TKDE.2013.182
   Zhu Y., 2018, ARXIV181201593
NR 45
TC 11
Z9 11
U1 2
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 169537
EP 169547
DI 10.1109/ACCESS.2019.2954675
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA NB3ZQ
UT WOS:000560454900024
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Sun, MJ
   Zhang, X
   Qu, G
   Zou, MS
   Du, H
   Ma, LY
   Qu, YW
AF Sun, Mingjian
   Zhang, Xiao
   Qu, Ge
   Zou, Mengshu
   Du, Hai
   Ma, Liyong
   Qu, Yawei
TI Automatic Polyp Detection in Colonoscopy Images: Convolutional Neural
   Network, Dataset and Transfer Learning
SO JOURNAL OF MEDICAL IMAGING AND HEALTH INFORMATICS
LA English
DT Article
DE Polyp Detection; Deep Learning; Convolutional Neural Network; Transfer
   Learning
AB Colonoscopy plays an essential role in colorectal cancer prevention and diagnosis. Due to the high miss-rate of colon polyps the application of automated polyp detection technology in clinical is necessary. However, despite researchers made significant progress, automatic polyp detection is still a challenge task. In recent years, deep learning shines in medical image processing and achieved satisfactory result in different kinds of medical images. In this paper, we propose an end-to-end convolutional neural network (CNN) framework to deal with this challenge problem. The whole framework consists of 16 convolutional layers and 6 pooling layers. In order to improve the performance of the proposed method we employ transfer learning algorithm to fine tune the pre-trained model. Several effective tricks in deep learning also adopt to train the network we proposed. Compared with other methods employing traditional algorithms or hand-crafted features, CNN has the ability to reach lower error rate and faster speed. More importantly, we establish a novel colonoscopy dataset to train our neural network. The dataset consists of more than 10 thousand high resolution images which are carefully selected from hospital. We evaluate our classification system using precision, recall and F1 score analysis. The final model obtained 95.2% precision, 97.9% recall and 96.5% F1 score. In addition, we draw receiver operation characteristic (ROC) curve and the area under ROC curve can reach 96.6%. For location task, we employed Intersection over Union (IoU) to evaluate the model and get 0.65 IoU score.
C1 [Sun, Mingjian; Zhang, Xiao; Qu, Ge; Zou, Mengshu; Du, Hai; Ma, Liyong] Harbin Inst Technol, Sch Informat & Elect Engn, Weihai 264209, Shandong, Peoples R China.
   [Qu, Yawei] Harbin Inst Technol, Dept Control Sci & Engn, Harbin 150001, Heilongjiang, Peoples R China.
   [Qu, Yawei] Gen Hosp Chinese Peoples Armed Police Forces, Dept Gastroenterol, Beijing 100000, Peoples R China.
   [Sun, Mingjian; Ma, Liyong] Harbin Inst Technol, Shenzhen Engn Lab Med Intelligent Wireless Ultras, Harbin 518000, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Harbin
   Institute of Technology
RP Ma, LY (通讯作者)，Harbin Inst Technol, Sch Informat & Elect Engn, Weihai 264209, Shandong, Peoples R China.; Qu, YW (通讯作者)，Harbin Inst Technol, Dept Control Sci & Engn, Harbin 150001, Heilongjiang, Peoples R China.; Qu, YW (通讯作者)，Gen Hosp Chinese Peoples Armed Police Forces, Dept Gastroenterol, Beijing 100000, Peoples R China.; Ma, LY (通讯作者)，Harbin Inst Technol, Shenzhen Engn Lab Med Intelligent Wireless Ultras, Harbin 518000, Heilongjiang, Peoples R China.
RI Ma, Liyong/AAE-1074-2020; Ma, Liyong/A-3468-2009
OI Ma, Liyong/0000-0002-9515-7988; Ma, Liyong/0000-0002-0718-379X
FU National Natural Science Foundation of China [11574064]; Natural Science
   Foundation of Shandong Province [ZR2017MF041, ZR2018MF026]; Science and
   Technology Development Plan Project of Shandong Province [2016GGX103032,
   2018GGX103047]; Wego Group [2017011]; Shenzhen Basic Research Program
   [JCYJ201604291153 09834]; Development Plan of Chinese Academy of
   Sciences [2017011]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No. 11574064), Natural Science Foundation of Shandong
   Province (Grant Nos. ZR2017MF041 and ZR2018MF026), the Science and
   Technology Development Plan Project of Shandong Province (Grant Nos.
   2016GGX103032 and 2018GGX103047), Development Plan of Chinese Academy of
   Sciences and Wego Group (Grant No. 2017011), and Shenzhen Basic Research
   Program under grant JCYJ201604291153 09834.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Ioffe S., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin M., 2013, ARXIV E PRINTS
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., 2017, AAAI C ART INT, P65
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh N, 2014, I S BIOMED IMAGING, P97, DOI 10.1109/ISBI.2014.6867818
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
NR 23
TC 2
Z9 2
U1 1
U2 29
PU AMER SCIENTIFIC PUBLISHERS
PI VALENCIA
PA 26650 THE OLD RD, STE 208, VALENCIA, CA 91381-0751 USA
SN 2156-7018
EI 2156-7026
J9 J MED IMAG HEALTH IN
JI J. Med. Imaging Health Inform.
PD JAN
PY 2019
VL 9
IS 1
BP 126
EP 133
DI 10.1166/jmihi.2019.2550
PG 8
WC Mathematical & Computational Biology; Radiology, Nuclear Medicine &
   Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology; Radiology, Nuclear Medicine &
   Medical Imaging
GA HI3KH
UT WOS:000456348200020
DA 2023-04-20
ER

PT J
AU Zou, MY
   Hu, JR
   Zhang, H
   Wu, X
   He, J
   Xu, ZJ
   Zhong, Y
AF Zou, Maoyang
   Hu, Jinrong
   Zhang, Huan
   Wu, Xi
   He, Jia
   Xu, Zhijie
   Zhong, Yong
TI Rigid Medical Image Registration Using Learning-Based Interest Points
   and Features
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Medical image registration; CNN feature; interest point; deep learning
ID NEURAL-NETWORKS
AB For image-guided radiation therapy, radiosurgery, minimally invasive surgery, endoscopy and interventional radiology, one of the important techniques is medical image registration. In our study, we propose a learning-based approach named "FIPC-NNF" for rigid registration of medical image. Firstly, the pixel-level interest points are computed by the full convolution network (FCN) with self-supervise. Secondly, feature detection, descriptor and matching are trained by convolution neural network (CNN). Thirdly, random sample consensus (Ransac) is used to filter outliers, and the transformation parameters are found with the most inliers by iteratively fitting transforms. In addition, we propose "TrFIP-CNNF" which uses transfer learning and fine-tuning to boost performance of FIP-CNNF. The experiment is done with the dataset of nasopharyngeal carcinoma which is collected from West China Hospital. For the CT-CT and MR-MR image registration, TrFIP-CNNF performs better than scale invariant feature transform (SIFT) and FIP-CNNF slightly. For the CT-MR image registration, the precision, recall and target registration error (TRE) of the TrFIP-CNNF are much better than those of SIFT and FIP-CNNF, and even several times better than those of SIFT. The promising results are achieved by TrFIP-CNNF especially in the multimodal medical image registration, which demonstrates that a feasible approach can be built to improve image registration by using FCN interest points and CNN features.
C1 [Zou, Maoyang; Zhong, Yong] Univ Chinese Acad Sci, Chengdu Inst Comp Applicat, Chengdu, Peoples R China.
   [Zou, Maoyang; Hu, Jinrong; Zhang, Huan; Wu, Xi; He, Jia] Chengdu Univ Informat Technol, Chengdu, Peoples R China.
   [Xu, Zhijie] Univ Huddersfield, Sch Comp & Engn, Huddersfield, W Yorkshire, England.
C3 Chengdu Institute of Computer Application, CAS; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS; Chengdu
   University of Information Technology; University of Huddersfield
RP Zhong, Y (通讯作者)，Univ Chinese Acad Sci, Chengdu Inst Comp Applicat, Chengdu, Peoples R China.
EM 13981928503@139.com
FU National Natural Science Foundation of China [61806029]; Science and
   Technology Department of Sichuan Province [2017JY0011]; Education
   Department of Sichuan Province [17QNJJ0004]
FX We thank Xiaodong Yang for assistance in experiment. This work is
   supported by National Natural Science Foundation of China (Grant No.
   61806029), Science and Technology Department of Sichuan Province (Grant
   No. 2017JY0011), and Education Department of Sichuan Province (Grant No.
   17QNJJ0004).
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   [Anonymous], 2016, OPTIK INT J LIGHT EL, DOI DOI 10.1016/J.IJLEO.2015.10.145
   Bay H., 2006, LECT NOTES COMPUT SC, P404, DOI DOI 10.1007/11744023_32
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cao Xiaohuan, 2017, Med Image Comput Comput Assist Interv, V10433, P300, DOI 10.1007/978-3-319-66182-7_35
   Cheng X, 2018, COMP M BIO BIO E-IV, V6, P248, DOI 10.1080/21681163.2015.1135299
   Detone D., 2018, SUPERPOINT SELF SUPE
   Fang Chen, 2016, Medical Imaging and Augmented Reality. 7th International Conference, MIAR 2016. Proceedings: LNCS 9805, P292, DOI 10.1007/978-3-319-43775-0_26
   Fischer P., 2014, ABS14055769 CORR
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948
   He K., 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46493-0_38
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Juan L., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Miao S, 2016, IEEE T MED IMAGING, V35, P1352, DOI 10.1109/TMI.2016.2521800
   Mopuri KR, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301273
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Shan S, 2018, UNSUPERVISED END TO
   Simonovsky Martin, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9902, P10, DOI 10.1007/978-3-319-46726-9_2
   Sokooti H., 2017, INT C MED IM COMP CO, P232, DOI DOI 10.1007/978-3-319-66182-7_27
   Wu GR, 2013, LECT NOTES COMPUT SC, V8150, P649, DOI 10.1007/978-3-642-40763-5_80
   Xie LX, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P3, DOI 10.1145/2671188.2749289
   Yang ZQ, 2018, IEEE ACCESS, V6, P38544, DOI 10.1109/ACCESS.2018.2853100
   ZAGORUYKO S, 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
   Zou MY, 2018, SENS IMAGING, V19, DOI 10.1007/s11220-018-0191-1
NR 30
TC 7
Z9 7
U1 3
U2 7
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2019
VL 60
IS 2
BP 511
EP 525
DI 10.32604/cmc.2019.05912
PG 15
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA KH2BT
UT WOS:000510451800008
OA gold
DA 2023-04-20
ER

PT J
AU Liu, MM
   Wen, L
   Liu, YJ
   Cai, Q
   Li, LT
   Cai, YM
AF Liu, Mi-Mi
   Wen, Li
   Liu, Yong-Jia
   Cai, Qiao
   Li, Li-Ting
   Cai, Yong-Ming
TI Application of data mining methods to improve screening for the risk of
   early gastric cancer
SO BMC MEDICAL INFORMATICS AND DECISION MAKING
LA English
DT Article; Proceedings Paper
CT Sino-US Conference on Health Informatics
CY JUN 28-JUL 01, 2018
CL Guangzhou, PEOPLES R CHINA
DE C5; 0 decision tree; Tree augmented naive bayesian network; Multilayer
   perceptron; Logistic regression; SMOTE; Early gastric cancer; Stomach
   neoplasms
ID HELICOBACTER-PYLORI; CLASSIFICATION
AB BackgroundAlthough gastric cancer is a malignancy with high morbidity and mortality in China, the survival rate of patients with early gastric cancer (EGC) is high after surgical resection. To strengthen diagnosing and screening is the key to improve the survival and life quality of patients with EGC. This study applied data mining methods to improve screening for the risk of EGC on the basis of noninvasive factors, and displayed important influence factors for the risk of EGC.MethodsThe dataset was derived from a project of the First Hospital Affiliated Guangdong Pharmaceutical University. A series of questionnaire surveys, serological examinations and endoscopy plus pathology biopsy were conducted in 618 patients with gastric diseases. Their risk of EGC was categorized into low and high risk of EGC by the results of endoscopy plus pathology biopsy. The synthetic minority oversampling technique (SMOTE) was used to solve imbalance categories of the risk of EGC. Four classification models of the risk of EGC was established, including logistic regression (LR) and three data mining algorithms.ResultsThe three data mining models had higher accuracy than the LR model. Gain curves of the three data mining models were convexes more closer to ideal curves by contrast with that of the LR model. AUC of the three data mining models were larger than that of the LR model as well. The three data mining models predicted the risk of EGC more effectively in comparison with the LR model. Moreover, this study found 16 important influence factors for the risk of EGC, such as occupations, helicobacter pylori infection, drinking hot water and so on.ConclusionsThe three data mining models have optimal predictive behaviors over the LR model, therefore can effectively evaluate the risk of EGC and assist clinicians in improving the diagnosis and screening of EGC. Sixteen important influence factors for the risk of EGC were illustrated, which may helpfully assess gastric carcinogenesis, and remind to early prevention and early detection of gastric cancer. This study may also be conducive to clinical researchers in selecting and conducting the optimal predictive models.
C1 [Liu, Mi-Mi; Wen, Li; Cai, Qiao; Li, Li-Ting] Guangdong Pharmaceut Univ, Sch Publ Hlth, Guangzhou, Guangdong, Peoples R China.
   [Liu, Yong-Jia] Guangdong Pharmaceut Univ, Sch Clin Med, Guangzhou, Guangdong, Peoples R China.
   [Cai, Yong-Ming] Guangdong Pharmaceut Univ, Coll Med Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Cai, Yong-Ming] Guangdong Chinese Med Big Data Engn Res Ctr, Guangzhou, Guangdong, Peoples R China.
C3 Guangdong Pharmaceutical University; Guangdong Pharmaceutical
   University; Guangdong Pharmaceutical University
RP Cai, YM (通讯作者)，Guangdong Pharmaceut Univ, Coll Med Informat Engn, Guangzhou, Guangdong, Peoples R China.; Cai, YM (通讯作者)，Guangdong Chinese Med Big Data Engn Res Ctr, Guangzhou, Guangdong, Peoples R China.
EM 1172830392@qq.com; ymbruce@qq.com
FU Natural Science Foundation of Guangdong Province [2014A030313585];
   Guangdong Province innovative strong school project -"Guangdong
   University cloud computing based precision medicine big data engineering
   technology research center" of Guangdong Pharmaceutical University;
   Guangdong Provincial Government
FX Publication of this article was sponsored by the Natural Science
   Foundation of Guangdong Province grant 2014A030313585 and the Guangdong
   Province innovative strong school project -"Guangdong University cloud
   computing based precision medicine big data engineering technology
   research center" of Guangdong Pharmaceutical University which was
   sponsored by the Guangdong Provincial Government. These funding sources
   had no role in the design of the study and collection, analysis, and
   interpretation of data and in writing the manuscript.
CR Ali Z, 2012, J NANOSCI NANOTECHNO, V12, P8241, DOI 10.1166/jnn.2012.6692
   Browne A, 2002, NEURAL COMPUT, V14, P1739, DOI 10.1162/08997660260028692
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen L, 2016, J HAZARD MATER, V301, P381, DOI 10.1016/j.jhazmat.2015.08.041
   Chen SJ, 2016, CHIN J MED LIB INFOR, V25, P35
   Chen Wen, 2017, Computer Aided Engineering, V26, P1, DOI 10.13340/j.cae.2017.03.001
   [程时磊 Cheng Shilei], 2017, [中国公共卫生, China Journal of Public Health], V33, P1775
   Crowther PS, 2005, LECT NOTES ARTIF INT, V3684, P1
   Dai HL, 2015, APPL SOFT COMPUT, V31, P172, DOI 10.1016/j.asoc.2015.02.025
   Delen D, 2005, ARTIF INTELL MED, V34, P113, DOI 10.1016/j.artmed.2004.07.002
   Deng GH, 2017, CLIN J CHIN MED, V9, P146
   Dong M, 2016, CHIN J HLTH LAB TEC, V26, P2240
   Gao Y, 2011, CANCER EPIDEMIOL, V35, pE91, DOI 10.1016/j.canep.2011.06.006
   Hong JB, 2014, ONCOL LETT, V8, P2790, DOI 10.3892/ol.2014.2583
   Jang Jin Seok, 2009, Korean J Gastroenterol, V54, P99
   Karagulle M, 2014, J BUON, V19, P1076
   Kim YS, 2008, EXPERT SYST APPL, V34, P1227, DOI 10.1016/j.eswa.2006.12.017
   Kim YS, 2010, EXPERT SYST APPL, V37, P2292, DOI 10.1016/j.eswa.2009.07.043
   Krejs GJ, 2010, DIGEST DIS, V28, P600, DOI 10.1159/000320277
   Lawrence RL, 2015, REMOTE SENS ENVIRON, V170, P115, DOI 10.1016/j.rse.2015.09.008
   Li YX, 2015, CHIN J CANC PREV TRE, V22, P91
   Lopez V, 2013, INFORM SCIENCES, V250, P113, DOI 10.1016/j.ins.2013.07.007
   Luengo J, 2011, SOFT COMPUT, V15, P1909, DOI 10.1007/s00500-010-0625-8
   Madden MG, 2009, KNOWL-BASED SYST, V22, P489, DOI 10.1016/j.knosys.2008.10.006
   Malongane F, 2017, J SCI FOOD AGR, V97, P4679, DOI 10.1002/jsfa.8472
   Meng WB, 2015, DISCOV MED, V20, P285
   Nakamura M, 2013, BIODATA MIN, V6, DOI 10.1186/1756-0381-6-16
   Park CH, 2014, GASTROINTEST ENDOSC, V80, P253, DOI 10.1016/j.gie.2014.01.030
   Rafe V, 2014, J MED IMAG HEALTH IN, V4, P600, DOI 10.1166/jmihi.2014.1290
   Sekikawa A, 2014, EUR J CANCER, V50, P2065, DOI 10.1016/j.ejca.2014.05.020
   SUN Tao, 2012, BEIJING BIOMEDICAL E, V31, P528
   Tak DH, 2016, GASTROENT RES PRACT, V2016, DOI 10.1155/2016/2469521
   Ture M, 2009, EXPERT SYST APPL, V36, P8247, DOI 10.1016/j.eswa.2008.10.014
   [王永川 Wang Yongchuan], 2012, [中国肿瘤临床, Chinese Journal of Clinical Oncology], V39, P679
   Wu ZY, 2014, ZHEJIANG PREV MED, V26, P888
   Yaghoobi M, 2010, BRIT J CANCER, V102, P237, DOI 10.1038/sj.bjc.6605380
   Yamaguchi Y, 2016, DIGESTION, V93, P13, DOI 10.1159/000441742
   Zhang YJ, 2017, WORLD CHIN J DIGESTO, DOI [10. 11569/wcjd. v25. i2. 172., DOI 10.11569/WCJD.V25.I2.172]
   Zhu P, 2015, J INT MED CON PRACT, V10, P158
   Zou SuMin, 2016, Journal of Agricultural Resources and Environment, V33, P568
NR 40
TC 15
Z9 15
U1 2
U2 11
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
EI 1472-6947
J9 BMC MED INFORM DECIS
JI BMC Med. Inform. Decis. Mak.
PD DEC 7
PY 2018
VL 18
SU 5
AR 121
DI 10.1186/s12911-018-0689-4
PG 10
WC Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Medical Informatics
GA HD7NT
UT WOS:000452740300005
PM 30526601
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Bruzzone, P
   Trentino, P
   Negro, P
   Grimaldi, MR
   D'Amore, L
   Di Gioia, CR
   Gossetti, F
AF Bruzzone, Paolo
   Trentino, Paolo
   Negro, Paolo
   Grimaldi, Maria R.
   D'Amore, Linda
   Di Gioia, Cira R.
   Gossetti, Francesco
TI Widespread recurrence of pT1 colon cancer three years and three months
   after endoscopic mucosal resection
SO CHIRURGIA-ITALY
LA English
DT Article
DE Polyps; Neoplasms; Endoscopic mucosal resection; Colonoscopy; Artificial
   intelligence
ID LYMPH-NODE METASTASIS; SUBMUCOSAL DISSECTION; RISK; GUIDELINES
AB Most authors consider Endoscopic Mucosal Resection (EMR) a safe and effective procedure to treat sessile and pedunculated intramucosal colonic cancers (Tis), as very few cases of local or distant (lymph nodes, liver, lung) metastases have been reported. EMR can be effective also in T1 cancers, which infiltrates submucosa and are associated to an overall 10% rate of lymph nodes metastases, with a rate increasing parallel to their distal site. We report here the case of a 62 years old woman affected by Hashimoto's thyroiditis, sclerodermia and severe congestive heart failure, who, notwithstanding a strict endoscopic and imaging follow-up after EMR of a T1 sigmoid cancer, 3 years and 3 months later was admitted to the Emergency Room (ER) of our Hospital complaining of abdominal pain, and was diagnosed by a Ultrasounds (US) scan to have hepatic metastases, confirmed by a whole body Computed Tomography (CT) scan and a Positron Emission Tomography (PET)-CT scan which showed also local parietal recurrence and diffuse lymph nodes metastases. Four months later, the patient is doing well after 3 cycles of chemotherapy; a CT scan will be performed after the fourth cycle.
C1 [Bruzzone, Paolo; Trentino, Paolo; Negro, Paolo; Grimaldi, Maria R.; D'Amore, Linda; Gossetti, Francesco] Sapienza Univ Rome, Unit Abdominal Wall Surg, Umberto I Policlin, Rome, Italy.
   [Trentino, Paolo] Sapienza Univ Rome, Unit Diag & Parasurg Therapy Biliary Tract & Dige, Umberto I Policlin, Rome, Italy.
   [Di Gioia, Cira R.] Sapienza Univ Rome, Dept Radiol Oncol & Anatomopathol Sci, Unit Anat & Pathol Histol, Rome, Italy.
   [Di Gioia, Cira R.] Umberto I Univ Hosp, Dept Diagnost Serv, Rome, Italy.
   [Gossetti, Francesco] Sapienza Univ Rome, Paride Stefanini Dept Gen & Specialist Surg, Unit Abdominal Wall Surg, Rome, Italy.
   [Gossetti, Francesco] Umberto I Univ Hosp, Cardiothorac Vasc Dept, Surg & Organs Transplantat, Rome, Italy.
C3 Sapienza University Rome; University Hospital Sapienza Rome; Sapienza
   University Rome; University Hospital Sapienza Rome; Sapienza University
   Rome; Sapienza University Rome; University Hospital Sapienza Rome;
   Sapienza University Rome; Sapienza University Rome; University Hospital
   Sapienza Rome
RP Bruzzone, P (通讯作者)，Sapienza Univ Rome, Unit Abdominal Wall Surg, Umberto I Policlin, Rome, Italy.
EM bruzzonepaolo62@gmail.com
OI di Gioia, Cira/0000-0003-4696-0560
CR Beaton C, 2013, COLORECTAL DIS, V15, P788, DOI 10.1111/codi.12129
   Burgess NG, 2017, GASTROENTEROLOGY, V153, P732, DOI 10.1053/j.gastro.2017.05.047
   Glynne-Jones R, 2017, ANN ONCOL, V28, P22, DOI 10.1093/annonc/mdx224
   Ha Lee K, 2014, ANN COLOPROCTOL, V30, P141, DOI 10.3393/ac.2014.30.3.141
   Ichimasa K, 2018, ENDOSCOPY, V50, P230, DOI 10.1055/s-0043-122385
   Labianca R, 2013, ANN ONCOL, V24, P64, DOI 10.1093/annonc/mdt354
   Lee HJ, 2017, CLIN ENDOSC, V50, P91, DOI 10.5946/ce.2016.054
   National Comprehensive Cancer Network, 2017, RECT CANC VERS 1 201
   Okabe S, 2004, J GASTROINTEST SURG, V8, P1032, DOI 10.1016/j.gassur.2004.09.038
   Pai RK, 2017, MODERN PATHOL, V30, P113, DOI 10.1038/modpathol.2016.166
   Seo HJ, 2011, ENDOSCOPY, V43, pE374, DOI 10.1055/s-0030-1256705
   Shia J, 2008, AM J SURG PATHOL, V32, P1586, DOI 10.1097/PAS.0b013e31817ec2cd
   Wada H, 2013, INT J CLIN ONCOL, V18, P1025, DOI 10.1007/s10147-012-0490-9
   Watanabe T, 2018, INT J CLIN ONCOL, V23, P1, DOI 10.1007/s10147-017-1101-6
NR 14
TC 0
Z9 0
U1 0
U2 2
PU EDIZIONI MINERVA MEDICA
PI TURIN
PA CORSO BRAMANTE 83-85 INT JOURNALS DEPT., 10126 TURIN, ITALY
SN 0394-9508
EI 1827-1782
J9 CHIRURGIA-ITALY
JI Chirurgia-Italy
PD DEC
PY 2018
VL 31
IS 6
BP 268
EP 271
DI 10.23736/S0394-9508.18.04834-9
PG 4
WC Surgery
WE Emerging Sources Citation Index (ESCI)
SC Surgery
GA HI0EY
UT WOS:000456116100011
DA 2023-04-20
ER

PT J
AU Liu, DY
   Rao, NN
   Mei, XM
   Jiang, HX
   Li, QC
   Luo, CS
   Li, Q
   Zeng, CS
   Zeng, B
   Gan, T
AF Liu, Dingyun
   Rao, Nini
   Mei, Xinming
   Jiang, Hongxiu
   Li, Quanchi
   Luo, ChengSi
   Li, Qian
   Zeng, Chengshi
   Zeng, Bing
   Gan, Tao
TI Annotating Early Esophageal Cancers Based on Two Saliency Levels of
   Gastroscopic Images
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Gastroscopic image; Early esophageal cancer; Lesion annotation; Visual
   saliency; Superpixel segmentation
ID CHROMOENDOSCOPY IMAGES; TEXTURE DESCRIPTORS; FEATURE-EXTRACTION; CAPSULE
   ENDOSCOPY; COMPUTER; CLASSIFICATION; LESIONS
AB Early diagnoses of esophageal cancer can greatly improve the survival rate of patients. At present, the lesion annotation of early esophageal cancers (EEC) in gastroscopic images is generally performed by medical personnel in a clinic. To reduce the effect of subjectivity and fatigue in manual annotation, computer-aided annotation is required. However, automated annotation of EEC lesions using images is a challenging task owing to the fine-grained variability in the appearance of EEC lesions. This study modifies the traditional EEC annotation framework and utilizes visual salient information to develop a two saliency levels-based lesion annotation (TSL-BLA) for EEC annotations on gastroscopic images. Unlike existing methods, the proposed framework has a strong ability of constraining false positive outputs. What is more, TSL-BLA is also placed an additional emphasis on the annotation of small EEC lesions. A total of 871 gastroscopic images from 231 patients were used to validate TSL-BLA. 365 of those images contain 434 EEC lesions and 506 images do not contain any lesions. 101 small lesion regions are extracted from the 434 lesions to further validate the performance of TSL-BLA. The experimental results show that the mean detection rate and Dice similarity coefficients of TSL-BLA were 97.24 and 75.15%, respectively. Compared with other state-of-the-art methods, TSL-BLA shows better performance. Moreover, it shows strong superiority when annotating small EEC lesions. It also produces fewer false positive outputs and has a fast running speed. Therefore, The proposed method has good application prospects in aiding clinical EEC diagnoses.
C1 [Liu, Dingyun; Rao, Nini; Mei, Xinming; Jiang, Hongxiu; Li, Quanchi; Luo, ChengSi; Li, Qian; Zeng, Chengshi] Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu, Sichuan, Peoples R China.
   [Liu, Dingyun; Rao, Nini; Mei, Xinming; Jiang, Hongxiu; Li, Quanchi; Luo, ChengSi; Li, Qian; Zeng, Chengshi] Univ Elect Sci & Technol China, Ctr Informat Biol, Chengdu, Sichuan, Peoples R China.
   [Liu, Dingyun; Rao, Nini; Mei, Xinming; Jiang, Hongxiu; Li, Quanchi; Luo, ChengSi; Li, Qian; Zeng, Chengshi] Univ Elect Sci & Technol China, Minist Educ, Key Lab NeuroInformat, Chengdu, Sichuan, Peoples R China.
   [Mei, Xinming] UESTC Guangdong, Inst Elect & Informat Engn, Dongguan, Peoples R China.
   [Zeng, Bing] Univ Elect Sci & Technol China, Sch Commun & Informat Engn, Chengdu, Sichuan, Peoples R China.
   [Gan, Tao] Sichuan Univ, West China Hosp, Digest Endoscop Ctr, Chengdu, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; University of Electronic
   Science & Technology of China; University of Electronic Science &
   Technology of China; Sichuan University
RP Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu, Sichuan, Peoples R China.; Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Ctr Informat Biol, Chengdu, Sichuan, Peoples R China.; Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Minist Educ, Key Lab NeuroInformat, Chengdu, Sichuan, Peoples R China.; Gan, T (通讯作者)，Sichuan Univ, West China Hosp, Digest Endoscop Ctr, Chengdu, Sichuan, Peoples R China.
EM raonn@uestc.edu.cn; gantaowest@163.com
FU National Natural Science Foundation of China [61,872,405,
   61,720,106,004]; Sichuan Science and Technology Support Program
   [2015SZ0191]; Key Project of Natural Science Foundation of Guangdong
   Province [2016A030311040]; Fundamental Research Funds for the Central
   Universities of China [ZYGX2016J189]; Scientific Platform Improvement
   Project of UESTC
FX This work was funded by the National Natural Science Foundation of China
   (61,872,405 and 61,720,106,004), the Sichuan Science and Technology
   Support Program (2015SZ0191), Key Project of Natural Science Foundation
   of Guangdong Province (2016A030311040), the Fundamental Research Funds
   for the Central Universities of China (ZYGX2016J189) and Scientific
   Platform Improvement Project of UESTC.
CR Abdelsamea MM, 2015, NEUROCOMPUTING, V149, P820, DOI 10.1016/j.neucom.2014.07.052
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ali H, 2018, COMPUT METH PROG BIO, V157, P39, DOI 10.1016/j.cmpb.2018.01.013
   Ali H, 2017, COMPUT BIOL MED, V88, P84, DOI 10.1016/j.compbiomed.2017.07.002
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Boschetto D, 2016, PROC SPIE, V9788, DOI 10.1117/12.2216826
   Chang C., 2007, LIBSVM LIB SUPPORT V
   Chen H., 2017, MOB INF SYST, V2017, P1, DOI DOI 10.1155/2017/3906953
   Chen Yingju, 2012, Diagn Ther Endosc, V2012, P418037, DOI 10.1155/2012/418037
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   HUANG Siqi, 2015, PROC IEEE C COMPUT V, V32, P1546
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Kurihara M, 1981, Cancer Detect Prev, V4, P377
   Lee SM, 2013, RIJEKA, V7, P130
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Liu DY, 2015, J MED IMAG HEALTH IN, V5, P296, DOI 10.1166/jmihi.2015.1390
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Tao Xin-min, 2011, Control and Decision, V26, P1535
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   van der Sommen F, 2013, PROC SPIE, V8670, DOI 10.1117/12.2001068
   Whiteman DC., 2014, CURR EPIDEMIOL REP, V1, P138, DOI [10.1007/s40471-014-0015-3, DOI 10.1007/S40471-014-0015-3]
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang S W, 2016, Zhonghua Zhong Liu Za Zhi, V38, P709, DOI 10.3760/cma.j.issn.0253-3766.2016.09.014
NR 31
TC 6
Z9 6
U1 0
U2 21
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD DEC
PY 2018
VL 42
IS 12
AR 237
DI 10.1007/s10916-018-1063-x
PG 14
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA GX1ZC
UT WOS:000447516900004
PM 30327890
DA 2023-04-20
ER

PT J
AU Mohammed, MA
   Abd Ghani, MK
   Arunkumar, N
   Hamed, RI
   Abdullah, MK
   Burhanuddin, MA
AF Mohammed, Mazin Abed
   Abd Ghani, Mohd Khanapi
   Arunkumar, N.
   Hamed, Raed Ibraheem
   Abdullah, Mohamad Khir
   Burhanuddin, M. A.
TI A real time computer aided object detection of nasopharyngeal carcinoma
   using genetic algorithm and artificial neural network based on Haar
   feature fear
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
LA English
DT Article
DE Nasopharyngeal carcinoma; Machine learning approaches; Computer-aided
   object detection; Trainable segmentation; Haar feature; Artificial
   neural networks; Genetic algorithm; Endoscopic images
ID SEGMENTATION; DIAGNOSIS; CLASSIFICATION
AB Nasopharyngeal carcinoma (NPC) is a serious disease with diverse prognoses and the diffusive development of the tumors further complicates the diagnosis. However, in most cases, surgery is performed by resecting the tumor that decides the life expectancy of a patient. Certainly, the graphical portrayal is a fundamental factor to distinguish and examine an NPC tumor; and, the exact nasopharyngeal carcinoma perception remains an important errand. It is crucial to improve the extent of resection for the irregular tissues while sparing the normal ones. There are several methods to envision the nasopharyngeal carcinoma, but the main problem with these strategies is the inability to imagine the border points of the nasopharyngeal tumor accurately in detail. In addition, the inability to separate the normal tissues from the undesirable ones prompts the assessment and calculation of a wrong tumor measure. NPC diagnosis is a difficult and challenging process owing to the possible shapes and regions of tumors and intensity of the images. The pathological identification of the nasopharyngeal carcinoma and comparing typical and anomalous tissues require a set of scientific strategies for the extraction of features. The aim of this paper was to outline and assess a novel method using machine learning approaches based on genetic algorithm for NPC feature selection and artificial neural networks for an automated NPC detection of the NPC tissues from endoscopic images. The proposed approach was validated by comparing the number of NPC identified through this technique against the manual checking by the ENT specialists. The classifier lists a high precision of 96.22%, the sensitivity of 95.35%, and specificity of 94.55%. Additionally, the feature chosen process makes the Artificial Neural Networks classifier straightforward and more efficient. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Mohammed, Mazin Abed; Abd Ghani, Mohd Khanapi; Burhanuddin, M. A.] Univ Teknikal Malaysia Melaka, Fac Informat & Commun Technol, Biomed Comp & Engn Technol BIOCORE Appl Res Grp, Melaka, Malaysia.
   [Mohammed, Mazin Abed] Univ Anbar, Univ Headquarter, Planning & Follow Up Dept, Anbar, Iraq.
   [Arunkumar, N.] Sastra Univ, Sch EEE, Thanjavur, India.
   [Hamed, Raed Ibraheem] Univ Human Dev, Coll Sci & Technol, Dept IT, Sulaymaniyah Krg, Iraq.
   [Abdullah, Mohamad Khir] Hosp Pakar Sultanah Fatimah Muar, Dept Otorinolaringol, Johor Baharu, Malaysia.
C3 Universiti Teknologi Malaysia; University Teknikal Malaysia Melaka;
   University of Anbar; Shanmugha Arts, Science, Technology & Research
   Academy (SASTRA)
RP Mohammed, MA (通讯作者)，Univ Teknikal Malaysia Melaka, Fac Informat & Commun Technol, Biomed Comp & Engn Technol BIOCORE Appl Res Grp, Melaka, Malaysia.
EM mazin_top_86@yahoo.com; khanapi@utem.edu.my; arun.nura@gmail.com;
   raed.alfalahy@uhd.edu.iq; mdkhirmd@hotmail.com; burhanuddin@utem.edu.my
RI Mohammed, Mazin Abed/E-3910-2018; Ghani, Mohd Khanapi Abd/G-5943-2017;
   N, Arunkumar/S-3028-2018
OI Mohammed, Mazin Abed/0000-0001-9030-8102; N,
   Arunkumar/0000-0001-9719-4451; Abdullah, Mohamad
   Khir/0000-0001-5237-7879; Hamed, Raed/0000-0002-8194-8113
FU (UTeM Zamalah scheme) by Universiti Teknikal Malaysia Melaka, Malaysia
FX This research has been supported by fellowship scheme (UTeM Zamalah
   scheme) by Universiti Teknikal Malaysia Melaka, Malaysia.
CR Abdulhay E., 2018, J AMB INTEL HUM COMP, DOI 10.1007/s12652-018-0748-9
   Abdulhay E, 2018, FUTURE GENER COMP SY, V83, P366, DOI 10.1016/j.future.2018.02.009
   Abdulhay E, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0912-y
   Crichton N, 2002, J CLIN NURS, V11, P136
   Gonen M., 2006, SAS USERS GROUP INT, P210
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Gupta D, 2018, COMPUT ELECTR ENG, V68, P412, DOI 10.1016/j.compeleceng.2018.04.014
   Huang KW, 2015, IEEE ENG MED BIO, P2968, DOI 10.1109/EMBC.2015.7319015
   Huang W, 2013, J DIGIT IMAGING, V26, P472, DOI 10.1007/s10278-012-9520-4
   Men K, 2017, FRONT ONCOL, V7, DOI 10.3389/fonc.2017.00315
   Mohammed M. A., 2012, 2012 Proceedings of International Conference on Computer & Information Science (ICCIS 2012), P257, DOI 10.1109/ICCISci.2012.6297250
   Mohammed MA, 2018, COMPUT ELECTR ENG, V70, P871, DOI 10.1016/j.compeleceng.2018.01.033
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P241, DOI 10.1016/j.jocs.2017.04.006
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P283, DOI 10.1016/j.jocs.2017.03.021
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P263, DOI 10.1016/j.jocs.2017.03.026
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P255, DOI 10.1016/j.jocs.2017.04.003
   Mohammed MA, 2017, J COMPUT SCI-NETH, V20, P61, DOI 10.1016/j.jocs.2017.03.009
   Mostafa SA, 2018, ADV INTELL SYST, V700, P43, DOI 10.1007/978-3-319-72550-5_5
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Petersson F., 2015, SEM DIAGN PATH
   Pinheiro PR, 2018, TELEMAT INFORM, V35, P776, DOI 10.1016/j.tele.2017.04.008
   Reboucas PP, 2017, PATTERN RECOGN LETT, V94, P211, DOI 10.1016/j.patrec.2017.02.005
   Ruuskanen M, 2018, ACTA ONCOL, V57, P251, DOI 10.1080/0284186X.2017.1346378
   Siegel RL, 2015, CA-CANCER J CLIN, V65, P5, DOI 10.3322/caac.21254
   Tang F., 2016, INT J RADIOL MED IMA, V3, P117
   Tatanun C., 2010, 2010 2 INT C SIGN PR, V2, pV2, DOI DOI 10.1109/ICSPS.2010.5555663
   Tian X., 2017, INT C INT MULT COMP, P215
   Vardhana M, 2018, COGN SYST RES, V50, P10, DOI 10.1016/j.cogsys.2018.03.005
   Velikyan I, 2018, CONTRAST MEDIA MOL I, DOI 10.1155/2018/9713691
   Wei JL, 2018, FUTURE GENER COMP SY, V86, P355, DOI 10.1016/j.future.2018.03.048
   Wu BX, 2012, INT J COMPUT ASS RAD, V7, P635, DOI 10.1007/s11548-011-0669-y
   Zhang J, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON MEDICAL IMAGING PHYSICS AND ENGINEERING (ICMIPE), P11, DOI 10.1109/ICMIPE.2013.6864493
NR 32
TC 50
Z9 50
U1 1
U2 373
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-739X
EI 1872-7115
J9 FUTURE GENER COMP SY
JI Futur. Gener. Comp. Syst.
PD DEC
PY 2018
VL 89
BP 539
EP 547
DI 10.1016/j.future.2018.07.022
PG 9
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GT2WH
UT WOS:000444360500043
DA 2023-04-20
ER

PT J
AU Hilsden, RJ
   Heitman, SJ
   Mizrahi, B
   Narod, SA
   Goshen, R
AF Hilsden, Robert J.
   Heitman, Steven J.
   Mizrahi, Barak
   Narod, Steven A.
   Goshen, Ran
TI Prediction of findings at screening colonoscopy using a machine learning
   algorithm based on complete blood counts (ColonFlag)
SO PLOS ONE
LA English
DT Article
ID SOCIETY TASK-FORCE; COLORECTAL-CANCER; RECOMMENDATIONS
AB Adenomatous polyps are a common precursor lesion for colorectal cancer. ColonFlag is a machine-learning-based algorithm that uses basic patient information and complete blood cell counts (CBC) to identify individuals at elevated risk of colorectal cancer for intensified screening. The purpose of this study was to determine whether ColonFlag is also able to predict the presence of high risk adenomatous polyps at colonoscopy. This study was conducted at a large colon cancer screening center in Calgary, Alberta. The study population included asymptomatic individuals between the ages of 50 and 75 who underwent a screening colonoscopy between January 2013 and June 2015. All subjects had at least one CBC result within the year prior to colonoscopy. Based on age, sex, red blood cell parameters, inflammatory cells and platelets, the ColonFlag algorithm generated a score from 0 to 100. We compared the ability of the ColonFlag test result to discriminate between individuals who were found to have a high risk polyp and those with a normal colonoscopy. Among the 17,676 individuals who underwent a screening colonoscopy there were 1,014 found to have a high risk precancerous lesion (5.7%) and 60 were found to have colorectal cancer (0.3%). At a specificity of 95%, the odds ratio for a positive ColonFlag was 2.0 for those with an advanced precancerous lesion compared with those with a normal colonoscopy. The odds ratio did not vary according to patient subgroup, colorectal cancer location or stage. ColonFlag is a passive test that can use routine blood test results to help identify individuals at elevated risk for high risk precancerous polyps as well as frank colorectal cancer. These individuals may be targeted in an effort to achieve greater compliance with conventional screening tests.
C1 [Hilsden, Robert J.; Heitman, Steven J.] Univ Calgary, Cumming Sch Med, Dept Med, Calgary, AB, Canada.
   [Hilsden, Robert J.; Heitman, Steven J.] Univ Calgary, Cumming Sch Med, Dept Community Hlth Sci, Calgary, AB, Canada.
   [Mizrahi, Barak] Medial Canc Res, Kfar Malal, Israel.
   [Narod, Steven A.] Womens Coll Hosp, Womens Coll Res Inst, Familial Breast Canc Res Unit, Toronto, ON, Canada.
   [Narod, Steven A.] Univ Toronto, Dalla Lana Sch Publ Hlth, Toronto, ON, Canada.
   [Goshen, Ran] Medial Early Sign, Kfar Malal, Israel.
C3 University of Calgary; University of Calgary; University of Toronto;
   Womens College Hospital; University of Toronto
RP Hilsden, RJ (通讯作者)，Univ Calgary, Cumming Sch Med, Dept Med, Calgary, AB, Canada.; Hilsden, RJ (通讯作者)，Univ Calgary, Cumming Sch Med, Dept Community Hlth Sci, Calgary, AB, Canada.
EM rhilsden@ucalgary.ca
RI Narod, Steven A/AAA-6112-2022
OI Hilsden, Robert/0000-0003-1545-1093
FU Medial Early Sign Inc., Kfar Malal, Israel
FX This research was funded by a contract to the University of Calgary from
   Medial Early Sign Inc., Kfar Malal, Israel. RG, EC, DW, BM and RY are
   employees of Medial EarlySign, Inc and were involved in the study
   concept, development of the research protocol, statistical analysis and
   writing of the manuscript.
CR Altobelli E, 2014, PREV MED, V62, P132, DOI 10.1016/j.ypmed.2014.02.010
   [Anonymous], 2010, AJCC CANC STAGING HD
   Atkinson TM, 2015, J BEHAV MED, V38, P837, DOI 10.1007/s10865-015-9668-8
   Canadian Task Force Preventive Hlt, 2016, CAN MED ASSOC J, V188, P340, DOI 10.1503/cmaj.151125
   Driman DK, 2012, CAN J PATHOL, V4, P81
   Goshen R, 2017, BRIT J CANCER, V116, P944, DOI 10.1038/bjc.2017.53
   Hornbrook MC, 2017, DIGEST DIS SCI, V62, P2719, DOI 10.1007/s10620-017-4722-8
   Kinar Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171759
   Kinar Y, 2016, J AM MED INFORM ASSN, V23, P879, DOI 10.1093/jamia/ocv195
   Klabunde C, 2015, J MED SCREEN, V22, P119, DOI 10.1177/0969141315584694
   Ma GK, 2014, CLIN GASTROENTEROL H, V12, P1624, DOI 10.1016/j.cgh.2014.01.042
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2012, AM J GASTROENTEROL, V107, P1315, DOI 10.1038/ajg.2012.161
   Ritvo PG, 2015, CANCER EPIDEM BIOMAR, V24, P506, DOI 10.1158/1055-9965.EPI-14-0744
   Robertson DJ, 2017, GASTROINTEST ENDOSC, V85, P2, DOI 10.1016/j.gie.2016.09.025
   White A, 2017, MMWR-MORBID MORTAL W, V66, P1, DOI 10.15585/mmwr.mm6608a1
NR 16
TC 11
Z9 11
U1 0
U2 4
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD NOV 27
PY 2018
VL 13
IS 11
AR e0207848
DI 10.1371/journal.pone.0207848
PG 9
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA HB9UV
UT WOS:000451440000025
PM 30481208
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Zhang, RC
   Zhao, RX
   Zhao, XY
   Wu, D
   Zheng, WW
   Feng, X
   Zhou, FF
AF Zhang, Ruochi
   Zhao, Ruixue
   Zhao, Xinyang
   Wu, Di
   Zheng, Weiwei
   Feng, Xin
   Zhou, Fengfeng
TI pyHIVE, a health-related image visualization and engineering system
   using Python
SO BMC BIOINFORMATICS
LA English
DT Article
AB BackgroundImaging is one of the major biomedical technologies to investigate the status of a living object. But the biomedical image based data mining problem requires extensive knowledge across multiple disciplinaries, e.g. biology, mathematics and computer science, etc.ResultspyHIVE (a Health-related Image Visualization and Engineering system using Python) was implemented as an image processing system, providing five widely used image feature engineering algorithms. A standard binary classification pipeline was also provided to help researchers build data models immediately after the data is collected. pyHIVE may calculate five widely-used image feature engineering algorithms efficiently using multiple computing cores, and also featured the modules of Principal Component Analysis (PCA) based preprocessing and normalization.ConclusionsThe demonstrative example shows that the image features generated by pyHIVE achieved very good classification performances based on the gastrointestinal endoscopic images. This system pyHIVE and the demonstrative example are freely available and maintained at https://hfbic3feb9583d03b4427h995u9bvnqn966605fiac.eds.tju.edu.cn/supp/resources.php.
C1 [Zhang, Ruochi; Zhao, Ruixue; Zhao, Xinyang; Zheng, Weiwei; Feng, Xin; Zhou, Fengfeng] Jilin Univ, BioKnow Hlth Informat Lab, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Zhang, Ruochi; Zhao, Ruixue; Zhao, Xinyang; Zheng, Weiwei; Feng, Xin; Zhou, Fengfeng] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
   [Wu, Di] Jilin Univ, Coll Software, BioKnow Hlth Informat Lab, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Feng, X; Zhou, FF (通讯作者)，Jilin Univ, BioKnow Hlth Informat Lab, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.; Feng, X; Zhou, FF (通讯作者)，Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
EM zrc720@gmail.com; 573175490@qq.com; FengfengZhou@gmail.com
RI Zhou, Fengfeng/A-8932-2008
OI Zhou, Fengfeng/0000-0002-8108-6007
FU Strategic Priority Research Program of the Chinese Academy of Sciences
   [XDB13040400]; Jilin Provincial Key Laboratory of Big Data Intelligent
   Computing [20180622002JC]; Education Department of Jilin Province
   [JJKH20180145KJ]; Jilin University; Bioknow MedAI Institute
   [BMCPP-2018-001]; High Performance Computing Center of Jilin University,
   China
FX This work was supported by the Strategic Priority Research Program of
   the Chinese Academy of Sciences (XDB13040400), Jilin Provincial Key
   Laboratory of Big Data Intelligent Computing (20180622002JC), the
   Education Department of Jilin Province (JJKH20180145KJ), and the startup
   grant of the Jilin University. This work was also partially supported by
   the Bioknow MedAI Institute (BMCPP-2018-001) and the High Performance
   Computing Center of Jilin University, China.
CR Adetiba Emmanuel, 2015, ScientificWorldJournal, V2015, P786013, DOI 10.1155/2015/786013
   Ding Y, 2015, PHYS MED BIOL, V60, P8365, DOI 10.1088/0031-9155/60/21/8365
   Ding YC, 2017, IEEE ACM T COMPUT BI, V14, P1366, DOI 10.1109/TCBB.2016.2591520
   Ge RQ, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-0990-0
   Nair M, 2014, CURR CANCER DRUG TAR, V14, P477, DOI 10.2174/1568009614666140506111118
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Sharma S, 2017, CURR DRUG TARGETS, V18, P1039, DOI 10.2174/1389450118666170315111542
   Tang ZH, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0696-5
   Tursi T, 2010, J AM ACAD NURSE PRAC, V22, P640, DOI 10.1111/j.1745-7599.2010.00567.x
   Unay D, 2007, P ANN INT IEEE EMBS, P2098, DOI 10.1109/IEMBS.2007.4352735
   Vallieres M, 2013, MED PHYS, V40, DOI 10.1118/1.4815538
   Vlaisavljevich E, 2017, ULTRASOUND MED BIOL, V43, P1237, DOI 10.1016/j.ultrasmedbio.2017.01.016
   Wang Y, 2016, BIOMED OPT EXPRESS, V7, P4928, DOI 10.1364/BOE.7.004928
   Yang D, 2013, MED PHYS, V40, DOI 10.1118/1.4814288
   Yang DH, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179161
NR 16
TC 4
Z9 4
U1 2
U2 14
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 1471-2105
J9 BMC BIOINFORMATICS
JI BMC Bioinformatics
PD NOV 26
PY 2018
VL 19
AR 452
DI 10.1186/s12859-018-2477-7
PG 6
WC Biochemical Research Methods; Biotechnology & Applied Microbiology;
   Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology;
   Mathematical & Computational Biology
GA HB7ME
UT WOS:000451261300002
PM 30477418
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Gadermayr, M
   Wimmer, G
   Kogler, H
   Vecsei, A
   Merhof, D
   Uhl, A
AF Gadermayr, M.
   Wimmer, G.
   Kogler, H.
   Vecsei, A.
   Merhof, D.
   Uhl, A.
TI Automated classification of celiac disease during upper endoscopy:
   Status quo and quo vadis
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Celiac disease; Decision support; Computer-aided diagnosis; Deep
   learning; Observer independent; Classification
ID PATCHY VILLOUS ATROPHY; DECISION-SUPPORT; AT-RISK; DIAGNOSIS;
   PREVALENCE; HISTOPATHOLOGY; ACCURACY; IMAGES
AB A large amount of digital image material is routinely captured during esophagogastroduodenoscopies but, for the most part, is not used for confirming the diagnosis process of celiac disease which is primarily based on histological examination of biopsies. Recently, considerable effort has been undertaken to make use of image material by developing semi- or fully-automated systems to improve the diagnostic workup. Recently, focus was especially laid on developing state-of-the-art deep learning architectures, exploiting the endoscopist's expert knowledge and on making systems fully automated and thereby completely observer independent. In this work, we summarize recent trends in the field of computer-aided celiac disease diagnosis based on upper endoscopy and discuss about recent progress, remaining challenges, limitations currently prohibiting a deployment in clinical practice and future efforts to tackle them.
C1 [Gadermayr, M.; Merhof, D.] Rhein Westfal TH Aachen, Inst Imaging & Comp Vis, D-52074 Aachen, Germany.
   [Wimmer, G.; Uhl, A.] Univ Salzburg, Dept Comp Sci, A-5020 Salzburg, Austria.
   [Kogler, H.; Vecsei, A.] St Anna Childrens Hosp, Vienna, Austria.
C3 RWTH Aachen University; Salzburg University; Saint Anna Children's
   Hospital
RP Gadermayr, M (通讯作者)，Rhein Westfal TH Aachen, Inst Imaging & Comp Vis, D-52074 Aachen, Germany.
EM michael.gadermayr@lfb.rwth-aachen.de; gwimmer@cosy.sbg.ac.at;
   uhl@cosy.sbg.ac.at
RI Merhof, Dorit/AAV-7892-2021
OI , Michael/0000-0003-1450-9222
FU Austrian Science Fund (FWF) [KLI429]; German Research Foundation (DFG)
   [ME3737/3-1]
FX This work is partially funded by the Austrian Science Fund (FWF) under
   grant no. KLI429 and by the German Research Foundation (DFG) under grant
   no. ME3737/3-1.
CR Arguelles-Grande C, 2012, J CLIN PATHOL, V65, P242, DOI 10.1136/jclinpath-2011-200372
   Bonamico M, 2004, J PEDIATR GASTR NUTR, V38, P204, DOI 10.1097/00005176-200402000-00019
   Cammarota G, 2006, ALIMENT PHARM THER, V23, P61, DOI 10.1111/j.1365-2036.2006.02732.x
   Cammarota G, 2004, GASTROINTEST ENDOSC, V60, P223, DOI 10.1016/S0016-5107(04)01553-6
   Castano L, 2004, J PEDIATR GASTR NUTR, V39, P80, DOI 10.1097/00005176-200407000-00016
   Ciaccio E. J., BIOMEDICAL ENG ONLIN, V10
   Ciaccio E. J., BIOMEDICAL MAT ENG
   Ciaccio EJ, 2017, ANN TRANSL MED, V5, DOI 10.21037/atm.2017.05.06
   Ciaccio EJ, 2015, WORLD J GASTROENTERO, V21, P2577, DOI 10.3748/wjg.v21.i9.2577
   Ciaccio EJ, 2013, DIGEST DIS SCI, V58, P1167, DOI 10.1007/s10620-013-2618-9
   Ciaccio EJ, 2012, COMPUT METH PROG BIO, V108, P28, DOI 10.1016/j.cmpb.2011.12.008
   Ciaccio EJ, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-44
   Ciaccio EJ, 2010, COMPUT METH PROG BIO, V100, P39, DOI 10.1016/j.cmpb.2010.02.005
   Dube C, 2005, GASTROENTEROLOGY, V128, pS57, DOI 10.1053/j.gastro.2005.02.014
   Dydensborg S, 2012, ACTA PAEDIATR, V101, P179, DOI 10.1111/j.1651-2227.2011.02392.x
   Fasano A, 2003, ARCH INTERN MED, V163, P286, DOI 10.1001/archinte.163.3.286
   Gadermayr M., 2017, Pattern Recognition and Image Analysis, V27, P66, DOI 10.1134/S1054661817010035
   Gadermayr M, 2016, IRBM, V37, P31, DOI 10.1016/j.irbm.2015.09.009
   Gadermayr Michael, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P224, DOI 10.1007/978-3-319-19665-7_19
   Gadermayr Michael, 2014, Medical Computer Vision Large Data in Medical Imaging. Third International MICCAI Workshop, MCV 2013. Revised Selected Papers. LNCS: 8331, P175, DOI 10.1007/978-3-319-05530-5_17
   Gadermayr M, 2013, COMPUT METH PROG BIO, V112, P694, DOI 10.1016/j.cmpb.2013.07.001
   Gadermayr M., 2014, 201404 U SALZB DEP C
   Gadermayr M., 2014, MED COMPUTER VISION, V8331, P196
   Gadermayr M., 2014, 201401 U SALZB AUSTR
   Gadermayr M, 2016, 2016 6 INT C IM PROC, P1, DOI [10.1109/IPTA.2016.7821009, DOI 10.1109/IPTA.2016.7821009]
   Gadermayr M, 2016, WORLD J GASTROENTERO, V22, P7124, DOI 10.3748/wjg.v22.i31.7124
   Gadermayr M, 2015, INT CONF IMAG PROC, P446, DOI 10.1109/IPTA.2015.7367184
   Gadermayr M, 2014, LECT NOTES COMPUT SC, V8509, P620, DOI 10.1007/978-3-319-07998-1_71
   Gadermayr M, 2013, LECT NOTES COMPUT SC, V8034, P465, DOI 10.1007/978-3-642-41939-3_45
   Gadermayr M, 2013, LECT NOTES COMPUT SC, V8033, P50, DOI 10.1007/978-3-642-41914-0_6
   Hegenbart S, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P718
   Hegenbart S., 2012, SPRINGER LECT NOTES, P99, DOI [10.1007/978-3-642-36678-9, DOI 10.3748/WJG.V22.I31.7124]
   Hegenbart S., 2011, IMPACT HISTOGRAM SUB, P359, DOI [10.1007/978-3-642-19335-4_74, DOI 10.1007/978-3-642-19335-4_74]
   Hegenbart S., 2010, THESIS
   Hegenbart S., 2012, P IEEE INT S COMP BA, P1
   Hegenbart S, 2015, COMPUT BIOL MED, V65, P348, DOI 10.1016/j.compbiomed.2015.02.007
   Hegenbart S, 2011, LECT NOTES COMPUT SC, V6801, P498, DOI 10.1007/978-3-642-22092-0_41
   Hegenbart S, 2011, INT SYMP IMAGE SIG, P715
   Hopper AD, 2008, ENDOSCOPY, V40, P219, DOI 10.1055/s-2007-995361
   Husby S, 2012, J PEDIATR GASTR NUTR, V54, P136, DOI 10.1097/MPG.0b013e31821a23d0
   Kwitt R, 2014, LECT NOTES COMPUT SC, V8674, P454, DOI 10.1007/978-3-319-10470-6_57
   Liedlgruber M., 2011, 201101 U SALZB DEP C
   Mubarak A, 2011, SCAND J GASTROENTERO, V46, P1065, DOI 10.3109/00365521.2011.589471
   Oberhuber G, 1999, EUR J GASTROEN HEPAT, V11, P1185, DOI 10.1097/00042737-199910000-00019
   Taavela J., PLOS ONE, V8
   Werkstetter KJ, 2017, GASTROENTEROLOGY, V153, P924, DOI 10.1053/j.gastro.2017.06.002
   Wimmer A. Uhl, 2017, PROC IEEE 19 INT WOR, P1, DOI [10.1109/MISP.2017.8122221, DOI 10.1109/MMSP.2017.8122221]
   Wimmer G., 2016, INT WORKSH COMP ASS, P104, DOI [10.1007/978-3-319-54057-3, DOI 10.1007/978-3-319-54057-3]
   Wimmer G., 2016, P 6 INT C IM PROC TH
NR 49
TC 8
Z9 8
U1 0
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD NOV 1
PY 2018
VL 102
BP 221
EP 226
DI 10.1016/j.compbiomed.2018.04.020
PG 6
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA HA0IR
UT WOS:000449892200024
PM 29739614
OA hybrid
DA 2023-04-20
ER

PT J
AU Hwang, Y
   Park, J
   Lim, YJ
   Chun, HJ
AF Hwang, Youngbae
   Park, Junseok
   Lim, Yun Jeong
   Chun, Hoon Jai
TI Application of Artificial Intelligence in Capsule Endoscopy: Where Are
   We Now?
SO CLINICAL ENDOSCOPY
LA English
DT Review
DE Capsule endoscopy; Deep learning; Artificial intelligence; Lesion
   detection
ID SCALE; SHAPE
AB Unlike wired endoscopy, capsule endoscopy requires additional time for a clinical specialist to review the operation and examine the lesions. To reduce the tedious review time and increase the accuracy of medical examinations, various approaches have been reported based on artificial intelligence for computer-aided diagnosis. Recently, deep learning-based approaches have been applied to many possible areas, showing greatly improved performance, especially for image-based recognition and classification. By reviewing recent deep learning-based approaches for clinical applications, we present the current status and future direction of artificial intelligence for capsule endoscopy.
C1 [Hwang, Youngbae] KETI, Intelligent Image Proc Res Ctr, Seongnam, South Korea.
   [Park, Junseok] Soonchunhyang Univ, Inst Digest Res, Dept Internal Med, Digest Dis Ctr,Coll Med, Seoul, South Korea.
   [Lim, Yun Jeong] Dongguk Univ, Coll Med, Dept Internal Med, Ilsan Hosp, Goyang, South Korea.
   [Chun, Hoon Jai] Korea Univ, Div Gastroenterol & Hepatol, Dept Internal Med, Coll Med, Seoul, South Korea.
C3 Korea Electronics Technology Institute (KETI); Soonchunhyang University;
   Dongguk University; NHIS Ilsan Hospital; Korea University; Korea
   University Medicine (KU Medicine)
RP Lim, YJ (通讯作者)，Dongguk Univ, Dept Internal Med, Ilsan Hosp, 27 Dongguk Ro, Goyang 10326, South Korea.
EM drlimyj@gmail.com
OI Park, Junseok/0000-0001-5607-1041
FU Korean government [GK18P0200]
FX This work was supported by The Cross-Ministry Giga KOREA Project funded
   by the Korean government (no. GK18P0200: Development of 4D
   reconstruction and dynamic deformable action model-based hyper-realistic
   service technology).
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cogswell M., 2015, ARXIV151106068
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fisher LR, 2012, NAT REV GASTRO HEPAT, V9, P392, DOI 10.1038/nrgastro.2012.88
   Harris C, 1988, P 4 ALV VIS C, V15, P10
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Khan S, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS), P633, DOI 10.1109/ICCOINS.2016.7783289
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kwack WG, 2016, CLIN ENDOSC, V49, P8, DOI 10.5946/ce.2016.49.1.8
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lowe D., 1999, P 7 IEEE INT C COMPU, P1150
   Lv GL, 2011, IEEE ENG MED BIO, P6643, DOI 10.1109/IEMBS.2011.6091638
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Redmon J, 2015, PROC CVPR IEEE, P779, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Simonyan K, 2015, Arxiv
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 40
TC 20
Z9 20
U1 1
U2 10
PU KOREAN SOC GASTROINTESTINAL ENDOSCOPY
PI SEOUL
PA 2003 LG PALACE, 165-8 DONGGYO-DONG, MAPO-GU, SEOUL, 121-754, SOUTH KOREA
SN 2234-2400
EI 2234-2443
J9 CLIN ENDOSC
JI Clin. Endosc.
PD NOV
PY 2018
VL 51
IS 6
BP 547
EP 551
DI 10.5946/ce.2018.173
PG 5
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA HC6DE
UT WOS:000451891200009
PM 30508880
OA gold, Green Published, Green Submitted
DA 2023-04-20
ER

PT J
AU Mascharak, S
   Baird, BJ
   Holsinger, FC
AF Mascharak, Shamik
   Baird, Brandon J.
   Holsinger, F. Christopher
TI Detecting oropharyngeal carcinoma using multispectral, narrow-band
   imaging and machine learning
SO LARYNGOSCOPE
LA English
DT Article
DE Multispectral imaging; narrow-band imaging; machine learning; naive
   Bayesian classification; oropharyngeal carcinoma; surgical vision; head
   and neck
ID SQUAMOUS-CELL CARCINOMA; HUMAN-PAPILLOMAVIRUS; NECK; HEAD; ENDOSCOPY
AB Objective Study Design To determine if multispectral narrow-band imaging (mNBI) can be used for automated, quantitative detection of oropharyngeal carcinoma (OPC). Prospective cohort study. Methods Results Multispectral narrow-band imaging and white light endoscopy (WLE) were used to examine the lymphoepithelial tissues of the oropharynx in a preliminary cohort of 30 patients (20 with biopsy-proven OPC, 10 healthy). Low-level image features from five patients were then extracted to train naive Bayesian classifiers for healthy and malignant tissue. Tumors were classified by color features with 65.9% accuracy, 66.8% sensitivity, and 64.9% specificity under mNBI. In contrast, tumors were classified with 52.3% accuracy (P = 0.0108), 44.8% sensitivity (P = 0.0793), and 59.9% specificity (P = 0.312) under WLE. Receiver operating characteristic analysis yielded areas under the curve (AUC) of 72.3% and 54.6% for classification under mNBI and WLE, respectively (P = 0.00168). For classification by both color and texture features, AUC under mNBI increased (80.1%, P = 0.00230) but did not improve under WLE (below 55% for both models, P = 0.180). Cross-validation with five folds yielded an AUC above 80% for both mNBI models and below 55% for both WLE models (P = 0.0000410 and 0.000116). Conclusion Level of Evidence Compared to WLE, mNBI significantly enhanced the performance of a naive Bayesian classifier trained on low-level image features of oropharyngeal mucosa. These findings suggest that automated clinical detection of OPC might be used to enhance surgical vision, improve early diagnosis, and allow for high-throughput screening. NA. Laryngoscope, 2514-2520, 2018
C1 [Mascharak, Shamik; Baird, Brandon J.; Holsinger, F. Christopher] Stanford Univ, Sch Med, Dept Otolaryngol, Div Head & Neck Surg, Palo Alto, CA 94304 USA.
C3 Stanford University
RP Holsinger, FC (通讯作者)，Stanford Univ, 875 Blake Wilbur Dr, Stanford, CA 94305 USA.
EM holsinger@stanford.edu
OI Holsinger, Floyd Christopher/0000-0002-9594-1414
CR Barber D., 2012, BAYESIAN REASONING M
   Chaturvedi AK, 2011, J CLIN ONCOL, V29, P4294, DOI 10.1200/JCO.2011.36.4596
   D'Souza G, 2007, NEW ENGL J MED, V356, P1944, DOI 10.1056/NEJMoa065497
   Davnall F, 2012, INSIGHTS IMAGING, V3, P573, DOI 10.1007/s13244-012-0196-6
   DECKER J, 1982, NEW ENGL J MED, V306, P1151, DOI 10.1056/NEJM198205133061905
   Gillison ML, 2008, JNCI-J NATL CANCER I, V100, P407, DOI 10.1093/jnci/djn025
   Gono K, 2003, OPT REV, V10, P211, DOI 10.1007/s10043-003-0211-8
   Hansson BG, 2005, ACTA OTO-LARYNGOL, V125, P1337, DOI 10.1080/00016480510043945
   Hegyi A, 2015, OPT EXPRESS, V23, P28742, DOI 10.1364/OE.23.028742
   Holsinger FC, 2015, J CLIN ONCOL, V33, P3285, DOI 10.1200/JCO.2015.62.3157
   Katada C, 2010, ENDOSCOPY, V42, P185, DOI 10.1055/s-0029-1243963
   Lin YC, 2012, HEAD NECK-J SCI SPEC, V34, P1574, DOI 10.1002/hed.21964
   Lin YC, 2010, ARCH OTOLARYNGOL, V136, P234, DOI 10.1001/archoto.2009.230
   Masaki T, 2012, AURIS NASUS LARYNX, V39, P502, DOI 10.1016/j.anl.2012.01.007
   Masaki T, 2009, AURIS NASUS LARYNX, V36, P712, DOI 10.1016/j.anl.2009.01.008
   Piazza C, 2016, EUR ARCH OTO-RHINO-L, V273, P3347, DOI 10.1007/s00405-016-3925-5
   Siegel R, 2013, CA-CANCER J CLIN, V63, P11, DOI 10.3322/caac.21166
   Tirelli G, 2018, AM J OTOLARYNG, V39, P197, DOI 10.1016/j.amjoto.2017.11.004
   Tirelli G, 2015, ORAL ONCOL, V51, P908, DOI 10.1016/j.oraloncology.2015.07.005
NR 19
TC 28
Z9 31
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-852X
EI 1531-4995
J9 LARYNGOSCOPE
JI Laryngoscope
PD NOV
PY 2018
VL 128
IS 11
BP 2514
EP 2520
DI 10.1002/lary.27159
PG 7
WC Medicine, Research & Experimental; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine; Otorhinolaryngology
GA HC2IG
UT WOS:000451624900021
PM 29577322
DA 2023-04-20
ER

PT J
AU Petscharnig, S
   Schoffmann, K
AF Petscharnig, Stefan
   Schoeffmann, Klaus
TI Binary convolutional neural network features off-the-shelf for image to
   video linking in endoscopic multimedia databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based video retrieval; Endoscopic multimedia; CNNs
ID COLOR
AB With a rigorous long-term archival of endoscopic surgeries, vast amounts of video and image data accumulate. Surgeons are not able to spend their valuable time to manually search within endoscopic multimedia databases (EMDBs) or manually maintain links to interesting sections in order to quickly retrieve relevant surgery sections. Enabling the surgeons to quickly access the relevant surgery scenes, we utilize the fact that surgeons record external images additionally to the surgery video and aim to link them to the appropriate video sequence in the EMDB using a query-by-example approach. We propose binary Convolutional Neural Network (CNN) features off-the-shelf and compare them to several baselines: pixel-based comparison (PSNR), image structure comparison (SSIM), hand-crafted global features (CEDD and feature signatures), as well as CNN baselines Histograms of Class Confidences (HoCC) and Neural Codes (NC). For evaluation, we use 5.5 h of endoscopic video material and 69 query images selected by medical experts and compare the performance of the aforementioned image mathing methods in terms of video hit rate and distance to the true playback time stamp (PTS) for correct video predictions. Our evaluation shows that binary CNN features are compact, yet powerful image descriptors for retrieval in the endoscopic imaging domain. They are able to maintain state-of-the-art performance, while providing the benefit of low storage space requirements and hence provide the best compromise.
C1 [Petscharnig, Stefan; Schoeffmann, Klaus] Alpen Adria Univ Klagenfurt, Univ Str 65-67, A-9020 Klagenfurt Am Worthersee, Austria.
RP Petscharnig, S (通讯作者)，Alpen Adria Univ Klagenfurt, Univ Str 65-67, A-9020 Klagenfurt Am Worthersee, Austria.
EM stefan.petscharnig@itec.aau.at; ks@itec.aau.at
FU University of Klagenfurt
FX Open access funding provided by University of Klagenfurt.
CR Awad G, 2016, P TRECVID, V2016
   Babenko Artem, 2014, NEURAL CODES IMAGE R, P584
   Beecks Christian, 2015, P IEEE INT S MULT 20, P1
   Bois R., 2017, EXPLOITING MULTIMODA, P185
   Bosch A., 2007, P 6 ACM INT C IM VID, P401, DOI DOI 10.1145/1282280.1282340
   BVLC, 2016, CAFF MOD ZOO
   Carlisle J., 2015, P 2015 13 INT WORKSH, P1
   Chandrasekhar V, 2016, SIGNAL PROCESS, V128, P426, DOI 10.1016/j.sigpro.2016.05.021
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Cheng Z, 2015, CMU SMU TRECVID 2015
   Ercoli S, 2017, IEEE T MULTIMEDIA, V19, P2521, DOI 10.1109/TMM.2017.2697824
   Eskevich Maria, 2014, SEARCH HYPERLINKING
   Galuscakova P, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P299, DOI 10.1145/3078971.3079026
   Guo Jinma, 2015, ARXIV150901354
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Iakovidou C, 2014, CBMI, P1, DOI DOI 10.1109/CBMI.2014.6849821
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lokoc J., 2011, P 4 INT C SIMILARITY, P9, DOI [10.1145/1995412.1995417, DOI 10.1145/1995412.1995417]
   Lux M, 2008, P 16 ACM INT C MULT, P1085, DOI DOI 10.1145/1459359.1459577
   Munzer B, 2013, IEEE INT SYM MULTIM, P84, DOI 10.1109/ISM.2013.22
   OpenCV, 2015, OP SOURC COMP VIS LI
   Petscharnig S, 2018, MULTIMED TOOLS APPL, V77, P8061, DOI 10.1007/s11042-017-4699-5
   Petscharnig S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095737
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Schoeffmann K, 2016, CONTENT BASED RETRIE
   Schoeffmann K, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1957, DOI 10.1145/3123266.3130142
   Simon AR, 2015, TRECVID 2015 WORKSH
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Szegedy C., 2015, PROC IEEE C COMPUT V, P1
   Vukotic V, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P421, DOI 10.1145/3078971.3079038
   Vukotic V, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P343, DOI 10.1145/2911996.2912064
   Vukotic  Vedran, 2016, P 2016 ACM WORKSH VI, P37, DOI DOI 10.1145/2983563.2983567
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 35
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28817
EP 28842
DI 10.1007/s11042-018-6016-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500043
OA hybrid
DA 2023-04-20
ER

PT J
AU Shin, Y
   Balasingham, I
AF Shin, Younghak
   Balasingham, Ilangko
TI Automatic polyp frame screening using patch based combined feature and
   dictionary learning
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Article
DE Colonoscopy; Computer-aided detection; Shape and color feature;
   Dictionary learning; Polyp classification; Sparse coding
ID SPARSE; COLONOSCOPY; CLASSIFICATION; VALIDATION; DIAGNOSIS
AB Polyps in the colon can potentially become malignant cancer tissues where early detection and removal lead to high survival rate. Certain types of polyps can be difficult to detect even for highly trained physicians. Inspired by aforementioned problem our study aims to improve the human detection performance by developing an automatic polyp screening framework as a decision support tool. We use a small image patch based combined feature method. Features include shape and color information and are extracted using histogram of oriented gradient and hue histogram methods. Dictionary learning based training is used to learn features and final feature vector is formed using sparse coding. For classification, we use patch image classification based on linear support vector machine and whole image thresholding. The proposed framework is evaluated using three public polyp databases. Our experimental results show that the proposed scheme successfully classified polyps and normal images with over 95% of classification accuracy, sensitivity, specificity and precision. In addition, we compare performance of the proposed scheme with conventional feature based methods and the convolutional neural network (CNN) based deep learning approach which is the state of the art technique in many image classification applications. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Shin, Younghak] Norwegian Univ Sci & Technol NTNU, Dept Elect Syst, Trondheim, Norway.
   [Balasingham, Ilangko] Oslo Univ Hosp, Intervent Ctr, NO-0027 Oslo, Norway.
   [Balasingham, Ilangko] Univ Oslo, Inst Clin Med, Oslo, Norway.
   [Balasingham, Ilangko] Norwegian Univ Sci & Technol NTNU, Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU); University of Oslo;
   University of Oslo; Norwegian University of Science & Technology (NTNU)
RP Shin, Y (通讯作者)，Norwegian Univ Sci & Technol NTNU, Dept Elect Syst, Trondheim, Norway.
EM shinyh0919@gmail.com; ilangkob@medisin.uio.no
RI Balasingham, Ilangko/AGU-7268-2022
FU European Research Consortium for Informatics and Mathematics (ERCIM)
   'Alain Bensoussan' Fellowship Programme; Research Council of Norway
   through the MELODY project [225885/O70]
FX This work was supported by the European Research Consortium for
   Informatics and Mathematics (ERCIM) 'Alain Bensoussan' Fellowship
   Programme and Research Council of Norway through the MELODY project
   under the contract number 225885/O70.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Asif M., HOMOTOPY L, V1
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen Yingju, 2012, Diagn Ther Endosc, V2012, P418037, DOI 10.1155/2012/418037
   Condessa F.J.C., 2011, DETECTION CLASSIFICA
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Donoval D, 2006, TRANSISTOR LEVEL MODELING FOR ANALOG/ RF IC DESIGN, P1, DOI 10.1007/1-4020-4556-5_1
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Ghosh T, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P354, DOI 10.1109/ICCITechn.2014.7073100
   Hajian-Tilaki K, 2013, CASP J INTERN MED, V4, P627
   Hashem HF, 2009, NAT RADIO SCI CO, P918
   Hwang S., 2007, P IEEE INT C IM PROC, V2
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lieberman D, 2005, GASTROINTEST ENDOSC, V61, P392, DOI 10.1016/S0016-5107(05)00133-1
   Liu MZ, 2011, LECT NOTES COMPUT SC, V6893, P41, DOI 10.1007/978-3-642-23626-6_6
   Ma T, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P582, DOI 10.1109/ChinaSIP.2014.6889310
   Mairal J., 2009, PROC 26 INT C MACH L, P689
   Mallat Stephane, 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-0-12-374370-1.X0001-8
   Paclik P, 2000, PATTERN RECOGN LETT, V21, P1165, DOI 10.1016/S0167-8655(00)00078-7
   Park S., 2015, POLYP DETECTION COLO
   Park S., 2016, SPIE MED IMAGING
   Pujas P., 1995, 7 INT C ADV ROB ICAR
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P1186, DOI 10.1016/S0002-9270(03)00183-7
   Raina Rajat, 2007, LEARNING, P759, DOI DOI 10.1145/1273496.1273592
   Shin Y, 2016, IEEE ENG MED BIO, P223, DOI 10.1109/EMBC.2016.7590680
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang WT, 2007, I S INTELL SIG PROC, P746
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
NR 47
TC 18
Z9 18
U1 2
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD NOV
PY 2018
VL 69
BP 33
EP 42
DI 10.1016/j.compmedimag.2018.08.001
PG 10
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA GX2VS
UT WOS:000447578800004
PM 30172091
DA 2023-04-20
ER

PT J
AU Tachibana, R
   Nappi, JJ
   Ota, J
   Kohlhase, N
   Hironaka, T
   Kim, SH
   Regge, D
   Yoshida, H
AF Tachibana, Rie
   Nappi, Janne J.
   Ota, Junko
   Kohlhase, Nadja
   Hironaka, Toru
   Kim, Se Hyung
   Regge, Daniele
   Yoshida, Hiroyuki
TI Deep Learning Electronic Cleansing for Single- and Dual-Energy CT
   Colonography
SO RADIOGRAPHICS
LA English
DT Article
ID COMPUTED TOMOGRAPHIC COLONOGRAPHY; ADENOMATOUS POLYPS;
   COLORECTAL-CANCER; BOWEL PREPARATION; COLONOSCOPY; ALGORITHM; ACCURACY;
   IODINE
AB Electronic cleansing (EC) is used for computational removal of residual feces and fluid tagged with an orally administered contrast agent on CT colonographic images to improve the visibility of polyps during virtual endoscopic "fly-through" reading. A recent trend in CT colonography is to perform a low-dose CT scanning protocol with the patient having undergone reduced- or noncathartic bowel preparation. Although several EC schemes exist, they have been developed for use with cathartic bowel preparation and high-radiation-dose CT, and thus, at a low dose with noncathartic bowel preparation, they tend to generate cleansing artifacts that distract and mislead readers. Deep learning can be used for improvement of the image quality with EC at CT colonography. Deep learning EC can produce substantially fewer cleansing artifacts at dual-energy than at single-energy CT colonography, because the dual-energy information can be used to identify relevant material in the colon more precisely than is possible with the single x-ray attenuation value. Because the number of annotated training images is limited at CT colonography, transfer learning can be used for appropriate training of deep learning algorithms. The purposes of this article are to review the causes of cleansing artifacts that distract and mislead readers in conventional EC schemes, to describe the applications of deep learning and dual-energy CT colonography to EC of the colon, and to demonstrate the improvements in image quality with EC and deep learning at single-energy and dual-energy CT colonography with noncathartic bowel preparation. (C) RSNA, 2018
C1 [Tachibana, Rie; Nappi, Janne J.; Kohlhase, Nadja; Hironaka, Toru; Yoshida, Hiroyuki] Massachusetts Gen Hosp, Dept Radiol, Imaging Res Lab 3D, 25 New Chardon St,Suite 400C, Boston, MA 02114 USA.
   [Tachibana, Rie; Nappi, Janne J.; Kohlhase, Nadja; Hironaka, Toru; Yoshida, Hiroyuki] Harvard Med Sch, 25 New Chardon St,Suite 400C, Boston, MA 02114 USA.
   [Tachibana, Rie] Oshima Coll, Natl Inst Technol, Dept Informat Sci & Technol, Yamaguchi, Japan.
   [Ota, Junko] Osaka Univ, Grad Sch Med, Dept Med Phys & Engn, Suita, Osaka, Japan.
   [Kohlhase, Nadja] Univ Appl Sci Giessen, Dept Med Phys, Giessen, Germany.
   [Kim, Se Hyung] Seoul Natl Univ Hosp, Dept Radiol, Seoul, South Korea.
   [Regge, Daniele] Univ Torino, Dept Surg Sci, Turin, Italy.
   [Regge, Daniele] FPO IRCCS, Candiolo Canc Inst, Turin, Italy.
   [Ota, Junko; Kohlhase, Nadja] Natl Inst Quantum & Radiol Sci & Technol, Natl Inst Radiol Sci, Clin Res Cluster, Med Informat Sect, Chiba, Japan.
C3 Harvard University; Massachusetts General Hospital; Harvard University;
   Harvard Medical School; Osaka University; Seoul National University
   (SNU); Seoul National University Hospital; University of Turin; IRCCS
   Fondazione del Piemonte per l'Oncologia; National Institutes for Quantum
   Science & Technology
RP Yoshida, H (通讯作者)，Massachusetts Gen Hosp, Dept Radiol, Imaging Res Lab 3D, 25 New Chardon St,Suite 400C, Boston, MA 02114 USA.; Yoshida, H (通讯作者)，Harvard Med Sch, 25 New Chardon St,Suite 400C, Boston, MA 02114 USA.
EM yoshida.hiro@mgh.harvard.edu
RI Regge, Daniele/AAC-6816-2022; Nappi, Janne/B-9424-2008
OI Regge, Daniele/0000-0001-8267-5279; Ota, Junko/0000-0002-2526-5270;
   Nappi, Janne/0000-0002-0108-0992
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   ALVAREZ RE, 1976, PHYS MED BIOL, V21, P733, DOI 10.1088/0031-9155/21/5/002
   [Anonymous], 2018, CANC FACTS FIG 2018
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Cai WL, 2008, MED PHYS, V35, P3259, DOI 10.1118/1.2936413
   Cai WL, 2015, IEEE T BIO-MED ENG, V62, P754, DOI 10.1109/TBME.2014.2364837
   Cai WL, 2010, RADIOGRAPHICS, V30, P585, DOI 10.1148/rg.303095154
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Eliahou R, 2010, SEMIN ULTRASOUND CT, V31, P309, DOI 10.1053/j.sult.2010.05.005
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fulwadhva UP, 2016, RADIOGRAPHICS, V36, P393, DOI 10.1148/rg.2016150151
   Garcia-Garcia A, ARXIV2017170406857
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Iannaccone R, 2004, GASTROENTEROLOGY, V127, P1300, DOI 10.1053/j.gastro.2004.08.025
   Jensch S, 2010, EUR RADIOL, V20, P146, DOI 10.1007/s00330-009-1517-0
   Johnson TRC, 2007, EUR RADIOL, V17, P1510, DOI 10.1007/s00330-006-0517-6
   Jones N, 2014, NATURE, V505, P146, DOI 10.1038/505146a
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lefere P, 2004, AM J ROENTGENOL, V183, P945, DOI 10.2214/ajr.183.4.1830945
   Levin B, 2008, GASTROENTEROLOGY, V134, P1570, DOI 10.1053/j.gastro.2008.02.002
   Li JH, 2015, J APPL CLIN MED PHYS, V16, P418, DOI 10.1120/jacmp.v16i5.5519
   Lu L, 2013, LECT NOTES COMPUT SC, V8184, P57, DOI 10.1007/978-3-319-02267-3_8
   MILLNER M R, 1979, Medical Physics (Woodbury), V6, P70, DOI 10.1118/1.594555
   Nappi J, 2008, MED IMAGE ANAL, V12, P413, DOI 10.1016/j.media.2008.01.001
   Nappi JJ, 2016, P SOC PHOTO-OPT INS, V9785
   Neri E, 2013, EUR J RADIOL, V82, P1137, DOI 10.1016/j.ejrad.2012.11.006
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Ota J, 2016, RAD SOC N AM SCI ASS, V148
   Patino M, 2016, RADIOGRAPHICS, V36, P1087, DOI 10.1148/rg.2016150220
   Pickhardt PJ, 2015, DIGEST DIS SCI, V60, P647, DOI 10.1007/s10620-014-3454-2
   Pickhardt PJ, 2003, AM J ROENTGENOL, V181, P799, DOI 10.2214/ajr.181.3.1810799
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   Pratt L. Y., 1993, ADV NEURAL INFORM PR, P204, DOI DOI 10.5555/645753.668046
   Rockey DC, 2005, LANCET, V365, P305
   Serlie IWO, 2010, IEEE T BIO-MED ENG, V57, P1306, DOI 10.1109/TBME.2010.2040280
   Sharma K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01779-0
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Tachibana R, 2017, P SPIE MED IM 2017 C
   Tachibana R, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216446
   Yu LF, 2012, AM J ROENTGENOL, V199, pS9, DOI 10.2214/AJR.12.9121
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zalis ME, 2004, IEEE T MED IMAGING, V23, P1335, DOI 10.1109/TMI.2004.826050
   Zalis ME, 2012, ANN INTERN MED, V156, P692, DOI 10.7326/0003-4819-156-10-201205150-00005
NR 45
TC 19
Z9 19
U1 1
U2 14
PU RADIOLOGICAL SOC NORTH AMERICA (RSNA)
PI OAK BROOK
PA 820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES
SN 0271-5333
J9 RADIOGRAPHICS
JI Radiographics
PD NOV-DEC
PY 2018
VL 38
IS 7
BP 2034
EP 2050
DI 10.1148/rg.2018170173
PG 17
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA HA1AI
UT WOS:000449943400010
PM 30422761
OA Green Published, Green Submitted, Bronze
DA 2023-04-20
ER

PT J
AU Wimmer, G
   Gadermayr, M
   Kwitt, R
   Hafner, M
   Tamaki, T
   Yoshida, S
   Tanaka, S
   Merhof, D
   Uhl, A
AF Wimmer, Georg
   Gadermayr, Michael
   Kwitt, Roland
   Haefner, Michael
   Tamaki, Toru
   Yoshida, Shigeto
   Tanaka, Shinji
   Merhof, Dorit
   Uhl, Andreas
TI Training of polyp staging systems using mixed imaging modalities
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp staging; Narrow-band imaging; Chromoscopy; Endoscopy; I-scan;
   Computer-assisted diagnosis
ID PIT-PATTERN; CLASSIFICATION; COLONOSCOPY; ENDOSCOPY; FEATURES
AB Background: In medical image data sets, the number of images is usually quite small. The small number of training samples does not allow to properly train classifiers which leads to massive overfitting to the training data. In this work, we investigate whether increasing the number of training samples by merging datasets from different imaging modalities can be effectively applied to improve predictive performance. Further, we investigate if the extracted features from the employed image representations differ between different imaging modalities and if domain adaption helps to overcome these differences.
   Method: We employ twelve feature extraction methods to differentiate between non-neoplastic and neoplastic lesions. Experiments are performed using four different classifier training strategies, each with a different combination of training data. The specifically designed setup for these experiments enables a fair comparison between the four training strategies.
   Results: Combining high definition with high magnification training data and chromoscopic with non-chromoscopic training data partly improved the results. The usage of domain adaptation has only a small effect on the results compared to just using non-adapted training data.
   Conclusion: Merging datasets from different imaging modalities turned out to be partially beneficial for the case of combining high definition endoscopic data with high magnification endoscopic data and for combining chromoscopic with non-chromoscopic data. NBI and chromoendoscopy on the other hand are mostly too different with respect to the extracted features to combine images of these two modalities for classifier training.
C1 [Wimmer, Georg; Kwitt, Roland; Uhl, Andreas] Univ Salzburg, Dept Comp Sci, Jakob Haringerstr 2, A-5020 Salzburg, Austria.
   [Gadermayr, Michael; Merhof, Dorit] Rhein Westfal TH Aachen, Templergraben 55, D-52056 Aachen, Germany.
   [Haefner, Michael] St Elizabeth Hosp, Landstrasser Hauptstr 4a, A-1030 Vienna, Austria.
   [Tamaki, Toru; Yoshida, Shigeto; Tanaka, Shinji] Hiroshima Univ, 1-4-1 Kagamiyama, Hiroshima 7398527, Japan.
C3 Salzburg University; RWTH Aachen University; Hiroshima University
RP Wimmer, G (通讯作者)，Univ Salzburg, Dept Comp Sci, Jakob Haringerstr 2, A-5020 Salzburg, Austria.
EM gwimmer@cosy.sbg.ac.at; uhl@cosy.sbg.ac.at
RI Kwitt, Roland/AFS-8639-2022; Kwitt, Roland/HII-6060-2022; Merhof,
   Dorit/AAV-7892-2021; Tamaki, Toru/D-7091-2011
OI Tamaki, Toru/0000-0001-9712-7777; , Michael/0000-0003-1450-9222
FU Austrian Science Fund, TRP Project [206]
FX This work was supported by the Austrian Science Fund, TRP Project 206.
CR Chatfield K., 2014, BRIT MACH VIS C BMVC
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gono K, 2003, OPT REV, V10, P211, DOI 10.1007/s10043-003-0211-8
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Gross S., 2012, P SOC PHOTO-OPT INS, V8315
   Hafner M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P365, DOI 10.1007/978-3-662-46224-9_63
   Hafner M, 2012, COMPUT METH PROG BIO, V107, P565, DOI 10.1016/j.cmpb.2011.12.012
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hafner Michael, 2014, Medical Computer Vision Large Data in Medical Imaging. Third International MICCAI Workshop, MCV 2013. Revised Selected Papers. LNCS: 8331, P205, DOI 10.1007/978-3-319-05530-5_20
   Hafner M., 2014, P IEEE INT C IM PROC
   Hafner M., 2014, P 22 INT C PATT REC, P2734
   Kato S, 2006, WORLD J GASTROENTERO, V12, P1416, DOI 10.3748/wjg.v12.i9.1416
   Kiesslich R., 2009, EUR GASTROENTEROL HE, V5, P22
   Kodashima S, 2010, WORLD J GASTROENTERO, V16, P1043, DOI 10.3748/wjg.v16.i9.1043
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liedigruber M., 2012, IEEE REV BIOMEDICAL, V4, P73
   Ribeiro E., 2016, COMPUT MATH METHOD M, V2016, P16, DOI DOI 10.1155/2016/6584725.ARTICLE
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Wimmer G, 2016, P 3 INT WORKSH COMP, P59, DOI [10.1007/978-3-319-54057-3_6, DOI 10.1007/978-3-319-54057-3_6]
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yan K., 2016, CORR
NR 24
TC 2
Z9 2
U1 0
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD NOV 1
PY 2018
VL 102
BP 251
EP 259
DI 10.1016/j.compbiomed.2018.05.003
PG 9
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA HA0IR
UT WOS:000449892200028
PM 29773226
DA 2023-04-20
ER

PT J
AU Zhang, RK
   Zheng, YL
   Poon, CCY
   Shen, DG
   Lau, JYW
AF Zhang, Ruikai
   Zheng, Yali
   Poon, Carmen C. Y.
   Shen, Dinggang
   Lau, James Y. W.
TI Polyp detection during colonoscopy using a regression-based
   convolutional neural network with a tracker
SO PATTERN RECOGNITION
LA English
DT Article
DE Smart cancer screening; Therapeutic endoscopy; Endoscopic Informatics;
   Body Sensor Network; Deep Learning; Health Informatics
ID MOLECULAR PATHOLOGICAL EPIDEMIOLOGY; MISS RATE; COLORECTAL-CANCER;
   CLASSIFICATION; PATHWAYS; CAPSULE
AB A computer-aided detection (CAD) tool for locating and detecting polyps can help reduce the chance of missing polyps during colonoscopy. Nevertheless, state-of-the-art algorithms were either computationally complex or suffered from low sensitivity and therefore unsuitable to be used in real clinical setting. In this paper, a novel regression-based Convolutional Neural Network (CNN) pipeline is presented for polyp detection during colonoscopy. The proposed pipeline was constructed in two parts: 1) to learn the spatial features of colorectal polyps, a fast object detection algorithm named ResYOLO was pre-trained with a large non-medical image database and further fine-tuned with colonoscopic images extracted from videos; and 2) temporal information was incorporated via a tracker named Efficient Convolution Operators (ECO) for refining the detection results given by ResYOLO. Evaluated on 17,574 frames extracted from 18 endoscopic videos of the AsuMayoDB, the proposed method was able to detect frames with polyps with a precision of 88.6%, recall of 71.6% and processing speed of 6.5 frames per second, i.e. the method can accurately locate polyps in more frames and at a faster speed compared to existing methods. In conclusion, the proposed method has great potential to be used to assist endoscopists in tracking polyps during colonoscopy. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Zhang, Ruikai; Zheng, Yali; Poon, Carmen C. Y.; Lau, James Y. W.] Chinese Univ Hong Kong, Dept Surg, Hong Kong, Hong Kong, Peoples R China.
   [Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA.
   [Shen, Dinggang] Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA.
   [Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea.
C3 Chinese University of Hong Kong; University of North Carolina;
   University of North Carolina Chapel Hill; University of North Carolina;
   University of North Carolina Chapel Hill; Korea University
RP Poon, CCY (通讯作者)，Chinese Univ Hong Kong, Dept Surg, Hong Kong, Hong Kong, Peoples R China.; Shen, DG (通讯作者)，Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA.; Shen, DG (通讯作者)，Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA.
EM rzhang@surgery.cuhk.edu.hk; ylzheng@surgery.cuhk.edu.hk;
   cpoon@surgery.cuhk.edu.hk; dgshen@med.unc.edu;
   laujyw@surgery.cuhk.edu.hk
RI Zhang, Ruikai/W-9847-2019; Poon, Carmen C. Y./B-4616-2011; Zhang,
   Ruikai/W-9848-2019; Lau, James Y. W./O-2612-2016; Shen,
   Dinggang/ABF-6812-2020
OI Poon, Carmen C. Y./0000-0001-7717-4752; Zhang,
   Ruikai/0000-0001-8929-628X; Lau, James Y. W./0000-0003-0122-4068; Shen,
   Dinggang/0000-0002-7934-5698
FU General Research Fund [GRF/14202417]; Innovation and Technology Fund
   [ITF/337/16FP]
FX This project is supported in part by General Research Fund
   (GRF/14202417) and Innovation and Technology Fund (ITF/337/16FP).
CR Afridi MJ, 2018, PATTERN RECOGN, V73, P65, DOI 10.1016/j.patcog.2017.07.019
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bishehsari F, 2014, WORLD J GASTROENTERO, V20, P6055, DOI 10.3748/wjg.v20.i20.6055
   Colussi D, 2013, INT J MOL SCI, V14, P16365, DOI 10.3390/ijms140816365
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Jiao ZC, 2018, PATTERN RECOGN, V75, P292, DOI 10.1016/j.patcog.2017.07.008
   Kaminski MF, 2012, ENDOSCOPY, V44, P695, DOI 10.1055/s-0032-1306895
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   LeCun Y., 2015, NAT METHODS, V521, P436, DOI [DOI 10.1038/nature14539, 10.1038/nature14539, DOI 10.1038/nmeth.3707]
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Leung BHK, 2017, IEEE T BIO-MED ENG, V64, P1106, DOI 10.1109/TBME.2016.2591060
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Ogino S, 2016, EPIDEMIOLOGY, V27, P602, DOI 10.1097/EDE.0000000000000471
   Ogino S, 2011, GUT, V60, P397, DOI 10.1136/gut.2010.217182
   Park S., 2015, POLYP DETECTION COLO
   Park S. Y., 2016, MED IMAGING 2016 COP
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan ZJ, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254671
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 38
TC 89
Z9 93
U1 3
U2 76
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD NOV
PY 2018
VL 83
BP 209
EP 219
DI 10.1016/j.patcog.2018.05.026
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR0BL
UT WOS:000442172200016
PM 31105338
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Ellmann, S
   Langer, V
   Britzen-Laurent, N
   Hildner, K
   Huber, C
   Tripel, P
   Seyler, L
   Waldner, M
   Uder, M
   Sturzl, M
   Bauerle, T
AF Ellmann, Stephan
   Langer, Victoria
   Britzen-Laurent, Nathalie
   Hildner, Kai
   Huber, Carina
   Tripel, Philipp
   Seyler, Lisa
   Waldner, Maximilian
   Uder, Michael
   Stuerzl, Michael
   Baeuerle, Tobias
TI Application of machine learning algorithms for multiparametric MRI-based
   evaluation of murine colitis
SO PLOS ONE
LA English
DT Article
ID INFLAMMATORY-BOWEL-DISEASE; BLOOD-FLOW; MODELS; COLONOSCOPY; GAMMA
AB Magnetic resonance imaging (MRI) allows non-invasive evaluation of inflammatory bowel disease (IBD) by assessing pathologically altered gut. Besides morphological changes, relaxation times and diffusion capacity of involved bowel segments can be obtained by MRI. The aim of this study was to assess the use of multiparametric MRI in the diagnosis of experimentally induced colitis in mice, and evaluate the diagnostic benefit of parameter combinations using machine learning. This study relied on colitis induction by Dextran Sodium Sulfate (DSS) and investigated the colon of mice in vivo as well as ex vivo. Receiver Operating Characteristics were used to calculate sensitivity, specificity, positive- and negative-predictive values (PPV and NPV) of these single values in detecting DSS-treatment as a reference condition. A Model Averaged Neural Network (avNNet) was trained on the multiparametric combination of the measured values, and its predictive capacity was compared to those of the single parameters using exact binomial tests. Within the in vivo subgroup (n = 19), the avNNet featured a sensitivity of 91.3% (95% CI: 86.6-96.0%), specificity of 92.3% (95% CI: 85.1-99.6%), PPV of 96.9% (94.0-99.9%) and NPV of 80.0% (95% CI: 69.9-90.1%), significantly outperforming all single parameters in at least 2 accuracy measures (p < 0.003) and performing significantly worse compared to none of the single values. Within the ex vivo subgroup (n = 30), the avNNet featured a sensitivity of 87.4% (95% CI: 82.6-92.2%), specificity of 82.9% (95% CI: 76.1-89.7%), PPV of 88.9% (84.3-93.5%) and NPV of 80.8% (95% CI: 73.8-87.9%), significantly outperforming all single parameters in at least 2 accuracy measures (p < 0.015), exceeded by none of the single parameters. In experimental mouse colitis, multiparametric MRI and the combination of several single measured values to an avNNet can significantly increase diagnostic accuracy compared to the single parameters alone. This pilot study will provide new avenues for the development of an MR-derived colitis score for optimized diagnosis and surveillance of inflammatory bowel disease.
C1 [Ellmann, Stephan; Seyler, Lisa; Uder, Michael; Baeuerle, Tobias] Univ Hosp Erlangen, Inst Radiol, Maximilianspl 1, Erlangen, Germany.
   [Langer, Victoria; Britzen-Laurent, Nathalie; Stuerzl, Michael] Translat Res Ctr Erlangen, Div Mol & Expt Surg, Dept Surg, Erlangen, Germany.
   [Hildner, Kai; Huber, Carina; Waldner, Maximilian] Univ Hosp Erlangen, Dept Med 1, Kussmaul Campus Med Res, Erlangen, Germany.
   [Tripel, Philipp] Friedrich Alexander Univ Erlangen Nuremberg FAU, OICE, Erlangen, Germany.
C3 University of Erlangen Nuremberg; University of Erlangen Nuremberg;
   University of Erlangen Nuremberg; University of Erlangen Nuremberg
RP Ellmann, S (通讯作者)，Univ Hosp Erlangen, Inst Radiol, Maximilianspl 1, Erlangen, Germany.
EM stephan.ellmann@uk-erlangen.de
RI Britzen-Laurent, Nathalie/HDM-6965-2022; Ellmann, Stephan/P-3824-2016;
   Stürzl, Michael/B-3019-2015
OI Britzen-Laurent, Nathalie/0000-0002-0494-7117; Ellmann,
   Stephan/0000-0003-2737-5526; Stürzl, Michael/0000-0002-9276-2824;
   Bauerle, Tobias/0000-0002-0206-6199; Tripal, Philipp/0000-0003-0568-1725
FU Collaborative Research Center of the Deutsche Forschungsgemeinschaft DFG
   [1181, CRC 1181]; DFG [KFO257, FOR2438, BR5196/2-1]; W. Lutz Stiftung;
   Interdisciplinary Center for Clinical Research (IZKF) of the Clinical
   Center Erlangen
FX This work was in part funded by the Collaborative Research Center 1181
   of the Deutsche Forschungsgemeinschaft DFG (CRC 1181;
   https://hfbicf699ddff0fa54b68s995u9bvnqn966605fiac.eds.tju.edu.cn/), projects Z02 (T. Bauerle) and
   B05 (K. Hildner), and DFG grants KFO257, FOR2438 (M. Sturzl), and
   BR5196/2-1 (N. Britzen-Laurent), by the W. Lutz Stiftung (M. Sturzl),
   and by the Interdisciplinary Center for Clinical Research (IZKF) of the
   Clinical Center Erlangen. The funders had no role in study design, data
   collection and analysis, decision to publish, or preparation of the
   manuscript.
CR [Anonymous], 2015, RSTUDIO OPEN SOURCE
   Aoyagi T, 2010, HEPATO-GASTROENTEROL, V57, P468
   Arora G, 2009, GASTROINTEST ENDOSC, V69, P654, DOI 10.1016/j.gie.2008.09.008
   Baskerville TA, 2011, J CEREBR BLOOD F MET, V31, P1799, DOI 10.1038/jcbfm.2011.65
   Becker C, 2005, GUT, V54, P950, DOI 10.1136/gut.2004.061283
   Beltzer A, 2016, MOL IMAGING BIOL, V18, P697, DOI 10.1007/s11307-016-0937-x
   Bianchi A, 2016, INFLAMM BOWEL DIS, V22, P1286, DOI 10.1097/MIB.0000000000000755
   Brown JB, 2012, INFLAMM BOWEL DIS, V18, P323, DOI 10.1002/ibd.21779
   Bruckner M, 2016, WORLD J GASTROENTERO, V22, P996, DOI 10.3748/wjg.v22.i3.996
   Cawley GC, 2004, NEURAL NETWORKS, V17, P1467, DOI 10.1016/j.neunet.2004.07.002
   Celisse A, 2008, COMPUT STAT DATA AN, V52, P2350, DOI 10.1016/j.csda.2007.10.002
   Chang W, 2017, COMPREHENSIVE R ARCH
   Fuss IJ, 1996, J IMMUNOL, V157, P1261
   Gee MS, 2011, J MAGN RESON IMAGING, V33, P527, DOI 10.1002/jmri.22504
   GRUETTER R, 1993, MAGNET RESON MED, V29, P804, DOI 10.1002/mrm.1910290613
   Haas K, 2016, WORLD J RADIOL, V8, P124, DOI 10.4329/wjr.v8.i2.124
   Haep L, 2015, INFLAMM BOWEL DIS, V21, P2360, DOI 10.1097/MIB.0000000000000490
   Horos-Free DICOM Medical Image Viewer, 2015, HOROS FREE DICOM MED
   Jurjus Abdo R., 2004, Journal of Pharmacological and Toxicological Methods, V50, P81, DOI 10.1016/j.vascn.2003.12.002
   Kaser A, 2010, ANNU REV IMMUNOL, V28, P573, DOI 10.1146/annurev-immunol-030409-101225
   Klopfleisch R, 2013, BMC VET RES, V9, DOI 10.1186/1746-6148-9-123
   KROEKER RM, 1985, MAGNET RESON MED, V2, P1, DOI 10.1002/mrm.1910020102
   Kuhn M, 2016, CRAN PACKAGE CARET
   Larsson AE, 2006, INFLAMM BOWEL DIS, V12, P478, DOI 10.1097/00054725-200606000-00006
   Lemmens B, 2013, INFLAMM BOWEL DIS, V19, P1194, DOI 10.1097/MIB.0b013e318280e75f
   Melgar S, 2007, BIOCHEM BIOPH RES CO, V355, P1102, DOI 10.1016/j.bbrc.2007.02.090
   MOSER E, 1995, MAGN RESON IMAGING, V13, P429, DOI 10.1016/0730-725X(94)00135-P
   Mudter J, 2011, INFLAMM BOWEL DIS, V17, P1343, DOI 10.1002/ibd.21476
   Mustafi D, 2014, NMR BIOMED, V27, P272, DOI 10.1002/nbm.3060
   Mustafi D, 2010, MAGN RESON MED, V63, P922, DOI 10.1002/mrm.22229
   Packey CD, 2009, CURR OPIN INFECT DIS, V22, P292, DOI 10.1097/QCO.0b013e32832a8a5d
   Pendse DA, 2017, ABDOM RADIOL, V42, P115, DOI 10.1007/s00261-016-0863-z
   RAMSAY SC, 1993, J PHYSIOL-LONDON, V471, P521, DOI 10.1113/jphysiol.1993.sp019913
   Randhawa PK, 2014, KOREAN J PHYSIOL PHA, V18, P279, DOI 10.4196/kjpp.2014.18.4.279
   Sanchez-Munoz F, 2008, WORLD J GASTROENTERO, V14, P4280, DOI 10.3748/wjg.14.4280
   Sokol H, 2013, GASTROENTEROLOGY, V145, P591, DOI 10.1053/j.gastro.2013.05.047
   Stock C, CRAN PACKAGE DTCOMPA
   Walldorf J, 2015, EUR RADIOL, V25, P2984, DOI 10.1007/s00330-015-3714-3
   Wirtz S, 2007, NAT PROTOC, V2, P541, DOI 10.1038/nprot.2007.41
NR 39
TC 5
Z9 5
U1 0
U2 2
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD OCT 26
PY 2018
VL 13
IS 10
AR e0206576
DI 10.1371/journal.pone.0206576
PG 17
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA GY3KA
UT WOS:000448448700062
PM 30365545
OA Green Submitted, Green Published, gold
DA 2023-04-20
ER

PT J
AU Alagappan, M
   Brown, JRG
   Mori, Y
   Berzin, TM
AF Alagappan, Muthuraman
   Brown, Jeremy R. Glissen
   Mori, Yuichi
   Berzin, Tyler M.
TI Artificial intelligence in gastrointestinal endoscopy: The future is
   almost here
SO WORLD JOURNAL OF GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
DE Artificial intelligence; Machine learning; Gastrointestinal endoscopy;
   Computer-assisted decision making; Computer-aided detection; Colonic
   polyps; Colonoscopy; Computer-aided diagnosis; Colorectal adenocarcinoma
ID WIRELESS CAPSULE ENDOSCOPY; COMPUTER-AIDED DIAGNOSIS; IMAGING MAGNIFYING
   COLONOSCOPY; CONVOLUTIONAL NEURAL-NETWORK; SMALL COLORECTAL POLYPS;
   ADENOMA DETECTION RATE; OPTICAL MAGNIFICATION; DIABETIC-RETINOPATHY;
   BLEEDING DETECTION; CELIAC-DISEASE
AB Artificial intelligence (AI) enables machines to provide unparalleled value in a myriad of industries and applications. In recent years, researchers have harnessed artificial intelligence to analyze large-volume, unstructured medical data and perform clinical tasks, such as the identification of diabetic retinopathy or the diagnosis of cutaneous malignancies. Applications of artificial intelligence techniques, specifically machine learning and more recently deep learning, are beginning to emerge in gastrointestinal endoscopy. The most promising of these efforts have been in computer-aided detection and computer-aided diagnosis of colorectal polyps, with recent systems demonstrating high sensitivity and accuracy even when compared to expert human endoscopists. AI has also been utilized to identify gastrointestinal bleeding, to detect areas of inflammation, and even to diagnose certain gastrointestinal infections. Future work in the field should concentrate on creating seamless integration of AI systems with current endoscopy platforms and electronic medical records, developing training modules to teach clinicians how to use AI tools, and determining the best means for regulation and approval of new AI technology.
C1 [Alagappan, Muthuraman; Brown, Jeremy R. Glissen; Berzin, Tyler M.] Harvard Med, Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Boston, MA 02215 USA.
   [Mori, Yuichi] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Yokohama, Kanagawa, Japan.
C3 Harvard University; Beth Israel Deaconess Medical Center; Harvard
   Medical School; Showa University
RP Berzin, TM (通讯作者)，Harvard Med, Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Div Gastroenterol, 330 Brookline Ave, Boston, MA 02215 USA.
EM tberzin@bidmc.harvard.edu
RI Mori, Yuichi/AAU-5406-2020
OI Glissen Brown, Jeremy/0000-0002-7204-7241
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   BAH A, 1995, ENDOSCOPY, V27, P593, DOI 10.1055/s-2007-1005764
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chen JH, 2017, INT J MED INFORM, V102, P71, DOI 10.1016/j.ijmedinf.2017.03.006
   Coe SG, 2013, GASTROINTEST ENDOSC, V77, P631, DOI 10.1016/j.gie.2012.12.001
   Computer Vision Machine Learning Team, 2017, APPLE MACHINE LEARNI, P1
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Esgiar A N, 1998, IEEE Trans Inf Technol Biomed, V2, P197, DOI 10.1109/4233.735785
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fennerty M B, 1994, Gastrointest Endosc Clin N Am, V4, P297
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Goodwin CS, 1997, CLIN INFECT DIS, V25, P1017, DOI 10.1086/516077
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hotez PJ, 2004, NEW ENGL J MED, V351, P799, DOI 10.1056/NEJMra032492
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Inoue H, 2005, NAT CLIN PRACT GASTR, V2, P31, DOI 10.1038/ncpgasthep0072
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karkanis S, 1999, P WORKSH MACH LEARN
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karkanis SA, 2001, P IEEE INT C IM PROC, DOI [10.1109/ICIP.2001.958623, DOI 10.1109/ICIP.2001.958623]
   Karkanis SA, 2001, P IEEE INT C IM PROC, DOI [10.1109/ICIP.2001.959008, DOI 10.1109/ICIP.2001.959008]
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   KRISHNAN SM, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P610, DOI 10.1109/IEMBS.1994.411878
   Krishnan SM, 1998, P INT C IEEE ENG MED, DOI 10.1109/IEMBS.1998.745583
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li TB, 2016, GASTROINTEST ENDOSC, V83, pAB482, DOI 10.1016/j.gie.2016.03.671
   Magoulas GD, 2004, APPL SOFT COMPUT, V4, P369, DOI 10.1016/j.asoc.2004.01.005
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mitchell TM., 1997, MACH LEARN, P414
   Mori Y, 2017, UNITED EUR GASTROENT, V5, pA1
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Pan G., 2009, Journal of Medical Engineering & Technology, V33, P575, DOI 10.1080/03091900903111974
   Petroniene R, 2005, AM J GASTROENTEROL, V100, P685, DOI 10.1111/j.1572-0241.2005.41069.x
   Poole D.L., 1998, COMPUTATIONAL INTELL
   Radiya-Dixit E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-10324-y
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Russell S.J., 2010, ARTIFICIAL INTELLIGE, V3rd ed., P1132
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Sutskever I., 2011, GENERATING TEXT RECU
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takayama T, 1998, NEW ENGL J MED, V339, P1277, DOI 10.1056/NEJM199810293391803
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Wang P, 2001, P 23 IEEE ENG MED BI, DOI [10.1109/IEMBS.2001.1019637, DOI 10.1109/IEMBS.2001.1019637]
   Wang P, 2017, WORLD C GASTR 2017 O
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wilson Ana Ignjatovic, 2015, Gastrointest Endosc Clin N Am, V25, P287, DOI 10.1016/j.giec.2014.12.001
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zheng MM, 2005, COMPUT BIOL MED, V35, P259, DOI 10.1016/j.compbiomed.2004.01.002
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 74
TC 79
Z9 84
U1 0
U2 24
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 8226 REGENCY DR, PLEASANTON, CA 94588 USA
SN 1948-5190
J9 WORLD J GASTRO ENDOS
JI World J. Gastrointest. Endosc.
PD OCT 16
PY 2018
VL 10
IS 10
BP 239
EP 249
DI 10.4253/wjge.v10.i10.239
PG 11
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA GX8RT
UT WOS:000448058500002
PM 30364792
OA hybrid, Green Published, Green Submitted
DA 2023-04-20
ER

PT J
AU Eminaga, O
   Eminaga, N
   Semjonow, A
   Breil, B
AF Eminaga, Okyaz
   Eminaga, Nurettin
   Semjonow, Axel
   Breil, Bernhard
TI Diagnostic Classification of Cystoscopic Images Using Deep Convolutional
   Neural Networks
SO JCO CLINICAL CANCER INFORMATICS
LA English
DT Article
AB Purpose The recognition of cystoscopic findings remains challenging for young colleagues and depends on the examiner's skills. Computer-aided diagnosis tools using feature extraction and deep learning show promise as instruments to perform diagnostic classification.
   Materials and Methods Our study considered 479 patient cases that represented 44 urologic findings. Image color was linearly normalized and was equalized by applying contrast-limited adaptive histogram equalization. Because these findings can be viewed via cystoscopy from every possible angle and side, we ultimately generated images rotated in 10-degree grades and flipped them vertically or horizontally, which resulted in 18,681 images. After image preprocessing, we developed deep convolutional neural network (CNN) models (ResNet50, VGG-19, VGG-16, InceptionV3, and Xception) and evaluated these models using F1 scores. Furthermore, we proposed two CNN concepts: 90%-previous-layer filter size and harmonic-series filter size. A training set (60%), a validation set (10%), and a test set (30%) were randomly generated from the study data set. All models were trained on the training set, validated on the validation set, and evaluated on the test set.
   Results The Xception-based model achieved the highest F1 score (99.52%), followed by models that were based on ResNet50 (99.48%) and the harmonic-series concept (99.45%). All images with cancer lesions were correctly determined by these models. When the focus was on the images misclassified by the model with the best performance, 7.86% of images that showed bladder stones with indwelling catheter and 1.43% of images that showed bladder diverticulum were falsely classified.
   Conclusion The results of this study show the potential of deep learning for the diagnostic classification of cystoscopic images. Future work will focus on integration of artificial intelligence-aided cystoscopy into clinical routines and possibly expansion to other clinical endoscopy applications. (C) 2018 by American Society of Clinical Oncology
C1 [Eminaga, Okyaz] Stanford Med Sch, Stanford, CA USA.
   [Eminaga, Okyaz] Univ Hosp Cologne, Cologne, France.
   [Eminaga, Nurettin] St Mauritius Therapy Clin, Meerbusch, Germany.
   [Semjonow, Axel] Univ Hosp Muenster, Munster, Germany.
   [Breil, Bernhard] Niederrheim Univ Appl Sci, Krefeld, Germany.
C3 Stanford University; University of Munster
RP Eminaga, O (通讯作者)，Univ Hosp Cologne, Dept Urol, Cologne, France.; Eminaga, O (通讯作者)，Stanford Univ, Sch Med, Dept Urol, 300 Pasteur Dr, Stanford, CA 94305 USA.
EM eminaga@gmail.com
RI Eminaga, Okyaz/ABH-7208-2020
FU Dr Werner Jack Staedt-Foundation scholarship; School of Medicine Dean's
   Postdoctoral Fellowship
FX Supported by the Dr Werner Jack Staedt-Foundation scholarship (to O.E.)
   and School of Medicine Dean's Postdoctoral Fellowship (to O.E.).
CR Antropova N, 2017, MED PHYS, V44, P5162, DOI 10.1002/mp.12453
   Araujo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Cha KH, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09315-w
   Cha KH, 2016, MED PHYS, V43, P1882, DOI 10.1118/1.4944498
   Cheng RD, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.041302
   Chollet F, 2015, 3 INT C LEARN REPR S
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hand DJ, 2009, MACH LEARN, V77, P103, DOI 10.1007/s10994-009-5119-5
   He K, MASK R CNN
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang Y, 2017, IEEE J BIOMED HEALTH, V21, P1625, DOI 10.1109/JBHI.2017.2691738
   Kingma DP, 2015, P INT C LEARN REPRES, P1
   Klambauer G, ADV NEURAL INFO PROC
   Lapini A, 2012, SURG ENDOSC, V26, P3634, DOI 10.1007/s00464-012-2387-0
   Liu JM, 2017, MED PHYS, V44, P4630, DOI 10.1002/mp.12399
   Poplin R., 2018, BIORXIV, DOI [DOI 10.1101/201178, 10.1101/201178]
   Samplaski MK, 2009, BJU INT, V103, P154, DOI 10.1111/j.1464-410X.2008.08244.x
   Schonebeck J, 1985, ATLAS OF CYSTOSCOPY
   Simonyan K., 2014, ARXIV PREPRINT ARXIV
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Takahashi H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179790
   Velazquez ER, 2017, CANCER RES, V77, P3922, DOI 10.1158/0008-5472.CAN-17-0122
NR 23
TC 25
Z9 28
U1 0
U2 6
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 2473-4276
J9 JCO CLIN CANCER INFO
JI JCO Clin. Cancer Info.
PD OCT 11
PY 2018
VL 2
DI 10.1200/CCI.17.00126
PG 8
WC Oncology
WE Emerging Sources Citation Index (ESCI)
SC Oncology
GA HQ3JM
UT WOS:000462307200001
PM 30652604
OA Bronze
DA 2023-04-20
ER

PT J
AU Chunhapongpipat, K
   Boonklurb, R
   Chaopathomkul, B
   Sirisup, S
   Lipikorn, R
AF Chunhapongpipat, Krisorn
   Boonklurb, Ratinan
   Chaopathomkul, Bundit
   Sirisup, Sirod
   Lipikorn, Rajalida
TI Gradient Directional Second Derivative Pseudo-enhancement Correction and
   Modified Local Roughness Response Estimation for Electronic Cleansing in
   CT Colonography
SO JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING
LA English
DT Article
DE Computed tomography colonography; Electronic colon cleansing;
   Pseudo-enhancement correction; Partial volume effect
ID VIRTUAL COLONOSCOPY; IMAGE SEGMENTATION; POLYP DETECTION; SUBTRACTION
AB This paper proposes the gradient directional second derivative pseudo-enhancement (PEH) correction method to reduce the computed tomography (CT) attenuations of PEH soft-tissue voxels around fecal-tagging material (FTM) in CT colo-nography and the modified local roughness response estimation, which can efficiently separate air-tagging (AT) layers from air-tissue-tagging (ATT) layers. By integrating these two proposed methods into electronic colon cleansing (ECC), FTM can be effectively removed by a simple thresholding method. For subjective or clinical evaluation, a radiologist grades the quality of cleansing based on five causes of low quality cleansing. The average grade of our proposed method for clinical evaluation is 2.5714 out of 4. For objective evaluations, three cases exist: PEH correction, ECC, and visual assessment. First, PEH correction evaluation measures the success in the removal of PEH voxels with CT attenuations greater than or equal to 500 HU using the proposed PEH correction by comparing the results of this correction with the results from the existing method via CT attenuation profiles. Second, ECC is evaluated by comparing the results from applying our proposed methods with the ground truth. The results indicate that the goodness of cleansing is 0.01% and the global mean relative error is less than 0.016% with 99.99% confidence. Third, visual assessment of our ECC results confirms that soft-tissue components around FTM, especially ATT layers, are preserved.
C1 [Chunhapongpipat, Krisorn; Lipikorn, Rajalida] Chulalongkorn Univ, Fac Sci, Dept Math & Comp Sci, Machine Intelligence & Multimedia Informat Lab, Bangkok 10330, Thailand.
   [Boonklurb, Ratinan] Chulalongkorn Univ, Fac Sci, Dept Math & Comp Sci, Bangkok 10330, Thailand.
   [Chaopathomkul, Bundit] Chulalongkorn Univ, King Chulalongkorn Mem Hosp, Fac Med, Dept Radiol, Bangkok 10330, Thailand.
   [Sirisup, Sirod] Natl Elect & Comp Technol Ctr, Large Scale Simulat Res Lab, 112 Thailand Sci Pk, Pathum Thani 12120, Thailand.
C3 Chulalongkorn University; Chulalongkorn University; Chulalongkorn
   University; National Science & Technology Development Agency - Thailand;
   National Electronics & Computer Technology Center (NECTEC)
RP Lipikorn, R (通讯作者)，Chulalongkorn Univ, Fac Sci, Dept Math & Comp Sci, Machine Intelligence & Multimedia Informat Lab, Bangkok 10330, Thailand.
EM Krisorn.C@student.chula.ac.th; Ratinan.B@chula.ac.th;
   bchaopathomkul@hotmail.com; Sirod.sirisup@nectec.or.th;
   Rajalida.L@chula.ac.th
RI Lipikorn, Rajalida/AAV-7766-2021
OI Sirisup, Sirod/0000-0001-5308-1922
FU 90th Anniversary of Chulalongkorn University Fund (Ratchadaphiseksomphot
   Endowment Fund)
FX This research is partially supported by THE 90th Anniversary of
   Chulalongkorn University Fund (Ratchadaphiseksomphot Endowment Fund).
   The authors thank Dr. Richard Choi (Virtual Colonoscopy Center, Walter
   Reed Army Medical Center, Washington, DC) for providing the clinical CTC
   cases via the Walter Reed Army Medical Center Virtual Colonoscopy
   Collection. In order to use CTC data set from King Chulalongkorn
   Memorial Hospital, ethical consideration has been processed and approved
   in October 15, 2015 by the ethic committee of institutional review board
   from Faculty of Medicine, Chulalongkorn University where IRB No. 359/58
   and COA No. 725/2015.
CR American-Cancers-Society, 2011, COL CANC FACT FIG 20
   Boyes R, 2009, IEEE IMAGE PROC, P2509, DOI 10.1109/ICIP.2009.5414016
   Cai WL, 2008, MED PHYS, V35, P3259, DOI 10.1118/1.2936413
   Cai WL, 2011, IEEE T MED IMAGING, V30, P559, DOI 10.1109/TMI.2010.2087389
   Cai WL, 2010, RADIOGRAPHICS, V30, P585, DOI 10.1148/rg.303095154
   Callstrom MR, 2001, RADIOLOGY, V219, P693, DOI 10.1148/radiology.219.3.r01jn22693
   Hossain Z, 2010, IEEE T VIS COMPUT GR, V16, P1376, DOI 10.1109/TVCG.2010.147
   Ibanez L, 2005, ITK SOFTWARE GUIDE
   Johnson CD, 2008, AM J ROENTGENOL, V190, P361, DOI 10.2214/AJR.07.2700
   Johnson S. G., 2012, FFTW
   Law MWK, 2009, IEEE T IMAGE PROCESS, V18, P596, DOI 10.1109/TIP.2008.2010073
   Lee H, 2014, IEEE T BIO-MED ENG, V61, P2102, DOI 10.1109/TBME.2014.2313888
   Lee H, 2013, IEEE T BIO-MED ENG, V60, P1546, DOI 10.1109/TBME.2013.2238937
   Lefere PA, 2002, RADIOLOGY, V224, P393, DOI 10.1148/radiol.2241011222
   Li LH, 2002, PROC SPIE, V4683, P406, DOI 10.1117/12.463607
   Linguraru M. G., 2011, MED PHYS, V38
   Liu JM, 2008, MED PHYS, V35, P5664, DOI 10.1118/1.3013552
   Nappi J, 2008, MED IMAGE ANAL, V12, P413, DOI 10.1016/j.media.2008.01.001
   National-Cancer-Institute, 2012, ANN REP 2012 DEP MED
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   PROKOP M, 2002, SPIRAL MULTISLICE CO
   Serlie IWO, 2010, IEEE T BIO-MED ENG, V57, P1306, DOI 10.1109/TBME.2010.2040280
   Sethian J.A., 1996, P NAT ACAD SCI, V93, P4
   Sethian J.A., 1999, LEVEL SET METHODS FA
   Summers R, 2009, ACAD RADIOL, V16, P777, DOI 10.1016/j.acra.2009.04.001
   Tsagaan B, 2009, MED PHYS, V36, P3596, DOI 10.1118/1.3147201
   van Ravesteijn VF, 2013, IEEE T BIO-MED ENG, V60, P3036, DOI 10.1109/TBME.2013.2262046
   Wang S, 2008, MED PHYS, V35, P5787, DOI 10.1118/1.3013591
   Zalis ME, 2004, IEEE T MED IMAGING, V23, P1335, DOI 10.1109/TMI.2004.826050
   Zhang H, 2014, J X-RAY SCI TECHNOL, V22, P271, DOI 10.3233/XST-140424
NR 31
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1609-0985
EI 2199-4757
J9 J MED BIOL ENG
JI J. Med. Biol. Eng.
PD OCT
PY 2018
VL 38
IS 5
BP 757
EP 773
DI 10.1007/s40846-018-0385-y
PG 17
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA GT0JY
UT WOS:000444125600008
DA 2023-04-20
ER

PT J
AU Iakovidis, DK
   Georgakopoulos, SV
   Vasilakakis, M
   Koulaouzidis, A
   Plagianakos, VP
AF Iakovidis, Dimitris K.
   Georgakopoulos, Spiros V.
   Vasilakakis, Michael
   Koulaouzidis, Anastasios
   Plagianakos, Vassilis P.
TI Detecting and Locating Gastrointestinal Anomalies Using Deep Learning
   and Iterative Cluster Unification
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Endoscopy; gastrointestinal tract; computer-aided detection and
   diagnosis; machine learning
ID CONVOLUTIONAL NEURAL-NETWORKS; CAPSULE ENDOSCOPY; LESION DETECTION;
   POLYP DETECTION; ROC ANALYSIS; CLASSIFICATION
AB This paper proposes a novel methodology for automatic detection and localization of gastrointestinal (GI) anomalies in endoscopic video frame sequences. Training is performed with weakly annotated images, using only image-level, semantic labels instead of detailed, and pixel-level annotations. This makes it a cost-effective approach for the analysis of large videoendoscopy repositories. Other advantages of the proposed methodology include its capability to suggest possible locations of GI anomalies within the video frames, and its generality, in the sense that abnormal frame detection is based on automatically derived image features. It is implemented in three phases: 1) it classifies the video frames into abnormal or normal using a weakly supervised convolutional neural network (WCNN) architecture; 2) detects salient points from deeper WCNN layers, using a deep saliency detection algorithm; and 3) localizes GI anomalies using an iterative cluster unification (ICU) algorithm. ICU is based on a pointwise cross-feature-map (PCFM) descriptor extracted locally from the detected salient points using information derived from the WCNN. Results, from extensive experimentation using publicly available collections of gastrointestinal endoscopy video frames, are presented. The data sets used include a variety of GI anomalies. Both anomaly detection and localization performance achieved, in terms of the area under receiver operating characteristic (AUC), were >80%. The highest AUC for anomaly detection was obtained on conventional gastroscopy images, reaching 96%, and the highest AUC for anomaly localization was obtained on wireless capsule endoscopy images, reaching 88%.
C1 [Iakovidis, Dimitris K.; Georgakopoulos, Spiros V.; Vasilakakis, Michael; Plagianakos, Vassilis P.] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia 35131, Greece.
   [Koulaouzidis, Anastasios] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh EH16 4SA, Midlothian, Scotland.
C3 Royal Infirmary of Edinburgh; University of Edinburgh
RP Iakovidis, DK (通讯作者)，Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia 35131, Greece.
EM diakovidis@uth.gr; spirosgeorg@uth.gr; vasilaka@uth.gr;
   akoulaouzidis@hotmail.com; vpp@uth.gr
RI Koulaouzidis, Anastasios/G-9060-2014
OI Koulaouzidis, Anastasios/0000-0002-2248-489X; Iakovidis,
   Dimitris/0000-0002-5027-5323
FU Project Klearchos Koulaouzidis [5151]; Special Account of Research
   Grants of the University of Thessaly, Greece [5024]
FX This work was supported in part by the Project Klearchos Koulaouzidis
   under Grant 5151 and in part by the Special Account of Research Grants
   of the University of Thessaly, Greece, under Grant 5024.
CR Alemayehu D, 2012, ACAD RADIOL, V19, P1457, DOI 10.1016/j.acra.2012.09.006
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Beg S., 2017, FRONTLINE GASTROENTE
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bottou L, 1998, ONLINE LEARN
   BURGES CJC, 1996, P 13 INT C MACH LEAR, P71
   Carneiro G, 2017, IEEE T MED IMAGING, V36, P1405, DOI 10.1109/TMI.2017.2677479
   Chen HH, 2017, NEUROCOMPUTING, V229, P77, DOI 10.1016/j.neucom.2016.06.077
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cong Y, 2016, NEUROCOMPUTING, V196, P150, DOI 10.1016/j.neucom.2015.10.130
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Georgakopoulos SV, 2016, IEEE CONF IMAGING SY, P510, DOI 10.1109/IST.2016.7738279
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Guyon, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hoai M, 2014, PATTERN RECOGN, V47, P1523, DOI 10.1016/j.patcog.2013.09.028
   Huang Y, 2017, IEEE J BIOMED HEALTH, V21, P1625, DOI 10.1109/JBHI.2017.2691738
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jia YQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1631, DOI 10.1109/ROBIO.2015.7419005
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Oquab M., 2015, C COMP VIS PATT REC
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P43
   Qian RQ, 2016, INT CONF SIGN PROCES, P649, DOI 10.1109/ICSP.2016.7877912
   Reddi S. J., 2018, INT C LEARNING REPRE
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Rui T, 2018, MULTIMED TOOLS APPL, V77, P10635, DOI 10.1007/s11042-017-4684-z
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Soille P., 2013, MORPHOLOGICAL IMAGE
   SWETS JA, 1979, INVEST RADIOL, V14, P109, DOI 10.1097/00004424-197903000-00002
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tasoulis SK, 2013, PATTERN RECOGN LETT, V34, P131, DOI 10.1016/j.patrec.2012.09.008
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Vasilakakis M, 2017, LECT NOTES COMPUT SC, V10170, P96, DOI 10.1007/978-3-319-54057-3_9
   Wang S, 2016, IEEE T BIO-MED ENG, V63, P2347, DOI 10.1109/TBME.2016.2530141
   Wang S, 2015, IEEE IMAGE PROC, P3072, DOI 10.1109/ICIP.2015.7351368
   WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269
   Wimmer G, 2016, INT CONF IMAG PROC
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zheng YP, 2012, AM J GASTROENTEROL, V107, P554, DOI 10.1038/ajg.2011.461
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
NR 66
TC 90
Z9 93
U1 2
U2 56
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD OCT
PY 2018
VL 37
IS 10
BP 2196
EP 2210
DI 10.1109/TMI.2018.2837002
PG 15
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA GV7VN
UT WOS:000446342100004
PM 29994763
DA 2023-04-20
ER

PT J
AU Mohammed, MA
   Abd Ghani, MK
   Arunkumar, N
   Mostafa, SA
   Abdullah, MK
   Burhanuddin, MA
AF Mohammed, Mazin Abed
   Abd Ghani, Mohd Khanapi
   Arunkumar, N.
   Mostafa, Salama A.
   Abdullah, Mohamad Khir
   Burhanuddin, M. A.
TI Trainable model for segmenting and identifying Nasopharyngeal carcinoma
SO COMPUTERS & ELECTRICAL ENGINEERING
LA English
DT Article
DE Nasopharyngeal carcinoma; Trainable segmentation; Feature extraction;
   Texture feature; Artificial neural networks; Genetic algorithm; Support
   vector machine; Endoscopic images
ID LEVEL-SET EVOLUTION; TEXTURE FEATURES; SEGMENTATION; CLASSIFICATION;
   PERFORMANCE; DIAGNOSIS
AB Nasopharyngeal carcinoma (NPC) is a multifaceted cancer tumor that makes its diagnosis challenging. NPC has a consistently diffusive enlargement that makes its resection exceptionally challenging. The pathological identification of NPC and comparing typical and anomalous tissues require a set of advanced strategies for the extraction of features. The use of medical images to diagnoses NPC tumor depends on tumor shape, region, and intensity. This paper proposes a novel approach for diagnosing NPC from endoscopic images. The approach includes a trainable segmentation for identifying NPC tissues, genetic algorithm for selecting the best features, and support vector machine for classifying NPC. The proposed approach is validated by comparing the number of classified NPC cases against the manual approach of ENT specialists. The approach shows a high precision of 95.15%, sensitivity of 94.80%, and specificity of 95.20%. Additionally, the optimized feature selection provides straightforward and efficient classification results.
C1 [Mohammed, Mazin Abed; Abd Ghani, Mohd Khanapi; Burhanuddin, M. A.] Univ Tekn Malaysia Melaka, Fac Informat & Commun Technol, Biomed Comp & Engn Technol BIOCORE Appl Res Grp, Durian Tunggal 76100, Melaka, Malaysia.
   [Mohammed, Mazin Abed] Univ Anbar, Univ Headquarter, Planning & Follow Dept, Anbar, Iraq.
   [Arunkumar, N.] Sastra Univ, Sch EEE, Thanjavur, India.
   [Mostafa, Salama A.] Univ Tun Hussein Onn, Fac Comp Sci & Informat Technol, Johor Baharu, Malaysia.
   [Abdullah, Mohamad Khir] Hosp Pakar Sultanah Fatimah Muar, Dept Otorhinolaryngol, Johor Baharu, Malaysia.
C3 University Teknikal Malaysia Melaka; University of Anbar; Shanmugha
   Arts, Science, Technology & Research Academy (SASTRA); University of Tun
   Hussein Onn Malaysia
RP Mohammed, MA (通讯作者)，Univ Tekn Malaysia Melaka, Fac Informat & Commun Technol, Biomed Comp & Engn Technol BIOCORE Appl Res Grp, Durian Tunggal 76100, Melaka, Malaysia.
EM mazin_top_86@yahoo.com; khanapi@utem.edu.my; arun.nura@gmail.com;
   salama@uthm.edu.my; mdkhirmd@hotmail.com; burhanuddin@utem.edu.my
RI Mohammed, Mazin Abed/E-3910-2018; Ghani, Mohd Khanapi Abd/G-5943-2017;
   Mostafa, Salama/N-2437-2017; N, Arunkumar/S-3028-2018
OI Mohammed, Mazin Abed/0000-0001-9030-8102; Mostafa,
   Salama/0000-0001-5348-502X; Abdullah, Mohamad Khir/0000-0001-5237-7879;
   N, Arunkumar/0000-0001-9719-4451
FU Universiti Teknikal Malaysia Melaka, Malaysia
FX This research has been supported by fellowship scheme (UTeM Zamalah
   scheme) by Universiti Teknikal Malaysia Melaka, Malaysia.
CR Abdulhay E, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0912-y
   [Anonymous], 2010, 2010 2 INT C SIGN PR
   Chong VFH, 2004, RADIOLOGY, V231, P914, DOI 10.1148/radiol.2313030358
   Dewitte K, 2002, CLIN CHEM, V48, P799
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Ho S, 2002, INT C PATT RECOG, P532, DOI 10.1109/ICPR.2002.1044788
   Huang KW, 2015, IEEE ENG MED BIO, P2968, DOI 10.1109/EMBC.2015.7319015
   Huang W., 2008, P 5 INT C VIS INF EN
   Li B, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/515386
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Mohammed M. A., 2012, 2012 Proceedings of International Conference on Computer & Information Science (ICCIS 2012), P257, DOI 10.1109/ICCISci.2012.6297250
   Mohammed MA, 2018, COMPUT ELECTR ENG, V70, P871, DOI 10.1016/j.compeleceng.2018.01.033
   Mohammed MA, 2018, FUTURE GENER COMP SY, V89, P539, DOI 10.1016/j.future.2018.07.022
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P241, DOI 10.1016/j.jocs.2017.04.006
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P283, DOI 10.1016/j.jocs.2017.03.021
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P263, DOI 10.1016/j.jocs.2017.03.026
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P255, DOI 10.1016/j.jocs.2017.04.003
   Mohammed MA, 2017, J COMPUT SCI-NETH, V20, P61, DOI 10.1016/j.jocs.2017.03.009
   Mostafa SA, 2018, ADV INTELL SYST, V700, P43, DOI 10.1007/978-3-319-72550-5_5
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Smeets D, 2010, MED IMAGE ANAL, V14, P13, DOI 10.1016/j.media.2009.09.002
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Taheri S, 2010, IMAGE VISION COMPUT, V28, P26, DOI 10.1016/j.imavis.2009.04.005
   Wang JQ, 2008, IEEE T IMAGE PROCESS, V17, P235, DOI 10.1109/TIP.2007.914150
   Zhang J, 2004, INT WORKSH ADV IM TE, P207
   Zhou J, 2006, I S BIOMED IMAGING, P1364
   Zhou J, 2002, INT J INF TECHNOL, P8
   Zhou JY, 2003, COMPUT BIOL MED, V33, P407, DOI 10.1016/S0010-4825(03)00018-0
NR 29
TC 32
Z9 32
U1 0
U2 11
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0045-7906
EI 1879-0755
J9 COMPUT ELECTR ENG
JI Comput. Electr. Eng.
PD OCT
PY 2018
VL 71
BP 372
EP 387
DI 10.1016/j.compeleceng.2018.07.044
PG 16
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC2TW
UT WOS:000451655800030
DA 2023-04-20
ER

PT J
AU Urban, G
   Tripathi, P
   Alkayali, T
   Mittal, M
   Jalali, F
   Karnes, W
   Baldi, P
AF Urban, Gregor
   Tripathi, Priyam
   Alkayali, Talal
   Mittal, Mohit
   Jalali, Farid
   Karnes, William
   Baldi, Pierre
TI Deep Learning Localizes and Identifies Polyps in Real Time With 96%
   Accuracy in Screening Colonoscopy
SO GASTROENTEROLOGY
LA English
DT Article
DE Machine Learning; Convolutional Neural Networks; Colorectal Cancer
   Prevention; Adenoma Detection Rate Improving Technology
ID COLORECTAL-CANCER; ADENOMA DETECTION; PREVENTION
AB BACKGROUND & AIMS: The benefit of colonoscopy for colorectal cancer prevention depends on the adenoma detection rate (ADR). The ADR should reflect the adenoma prevalence rate, which is estimated to be higher than 50% in the screening-age population. However, the ADR by colonoscopists varies from 7% to 53%. It is estimated that every 1% increase in ADR lowers the risk of interval colorectal cancers by 3%-6%. New strategies are needed to increase the ADR during colonoscopy. We tested the ability of computer-assisted image analysis using convolutional neural networks (CNNs; a deep learning model for image analysis) to improve polyp detection, a surrogate of ADR. METHODS: We designed and trained deep CNNs to detect polyps using a diverse and representative set of 8,641 hand-labeled images from screening colonoscopies collected from more than 2000 patients. We tested the models on 20 colonoscopy videos with a total duration of 5 hours. Expert colonoscopists were asked to identify all polyps in 9 de-identified colonoscopy videos, which were selected from archived video studies, with or without benefit of the CNN overlay. Their findings were compared with those of the CNN using CNN-assisted expert review as the reference. RESULTS: When tested on manually labeled images, the CNN identified polyps with an area under the receiver operating characteristic curve of 0.991 and an accuracy of 96.4%. In the analysis of colonoscopy videos in which 28 polyps were removed, 4 expert reviewers identified 8 additional polyps without CNN assistance that had not been removed and identified an additional 17 polyps with CNN assistance (45 in total). All polyps removed and identified by expert review were detected by the CNN. The CNN had a false-positive rate of 7%. CONCLUSION: In a set of 8,641 colonoscopy images containing 4,088 unique polyps, the CNN identified polyps with a cross-validation accuracy of 96.4% and an area under the receiver operating characteristic curve of 0.991. The CNN system detected and localized polyps well within real-time constraints using an ordinary desktop machine with a contemporary graphics processing unit. This system could increase the ADR and decrease interval colorectal cancers but requires validation in large multicenter trials.
C1 [Urban, Gregor; Baldi, Pierre] Univ Calif Irvine, Dept Comp Sci, Irvine, CA USA.
   [Urban, Gregor; Baldi, Pierre] Univ Calif Irvine, Inst Genom & Bioinformat, Irvine, CA USA.
   [Baldi, Pierre] Univ Calif Irvine, Ctr Machine Learning & Intelligent Syst, Irvine, CA USA.
   [Tripathi, Priyam; Alkayali, Talal; Mittal, Mohit; Jalali, Farid; Karnes, William] Univ Calif Irvine, Dept Med, Irvine, CA 92717 USA.
   [Alkayali, Talal; Jalali, Farid; Karnes, William] Univ Calif Irvine, HH Chao Comprehens Digest Dis Ctr, Irvine, CA USA.
C3 University of California System; University of California Irvine;
   University of California System; University of California Irvine;
   University of California System; University of California Irvine;
   University of California System; University of California Irvine;
   University of California System; University of California Irvine
RP Baldi, P (通讯作者)，Univ Calif Irvine, 4038 Bren Hall, Irvine, CA 92697 USA.
EM pfbaldi@uci.edu
OI Alkayali, Talal/0000-0003-1802-8215; Karnes, William/0000-0002-6225-9080
FU NIH [GM123558]; NSF [IIS-1550705]
FX Supported in part by grants NIH GM123558 and NSF IIS-1550705 to PB.
CR Abadi M., 2015, ARXIV
   American Cancer Society, 2016, CANC FACTS FIG
   Anderson JC, 2015, CLIN TRANSL GASTROEN, V6, DOI 10.1038/ctg.2015.5
   Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412
   BALDI P, 1993, NEURAL COMPUT, V5, P402, DOI 10.1162/neco.1993.5.3.402
   Baldi P, 2018, ANNU REV BIOMED DA S, V1, P181, DOI 10.1146/annurev-biodatasci-080917-013343
   Baldi P, 2014, ARTIF INTELL, V210, P78, DOI 10.1016/j.artint.2014.02.004
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bond A, 2015, WORLD J GASTRO ENDOS, V7, P969, DOI 10.4253/wjge.v7.i10.969
   Chang P, 2018, AM J NEURORADIOL, V39, P1201, DOI 10.3174/ajnr.A5667
   Chatfield K, 2014, ARXIV PREPR ARXIV140
   Chollet F., 2015, TECH REP
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Di Lena P, 2012, BIOINFORMATICS, V28, P2449, DOI 10.1093/bioinformatics/bts475
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fooshee D, 2018, MOL SYST DES ENG, V3, P442, DOI 10.1039/c7me00107j
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hassan C, 2017, GUT, V66, P1949, DOI 10.1136/gutjnl-2016-311906
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton G. E., ARXIV201212070580
   Ioffe S, ARXIV201515020316
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Kuntz KM, 2011, MED DECIS MAKING, V31, P530, DOI 10.1177/0272989X11408730
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Park SY, 2016, SPIE MED IMAGING
   Patel SG, 2014, CLIN GASTROENTEROL H, V12, P7, DOI 10.1016/j.cgh.2013.04.027
   Pericas JM, 2016, NEW ENGL J MED, V375, P387, DOI [10.1056/NEJMra1513581, 10.1056/NEJMc1604867]
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   Redmon J, 2015, PROC CVPR IEEE, P779, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shimmin C, 2017, PHYS REV D, V96, DOI 10.1103/PhysRevD.96.074034
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv
   Soetikno R, 2006, GASTROENTEROLOGY, V130, P566, DOI 10.1053/j.gastro.2005.12.006
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Than M, 2015, ANN GASTROENTEROL, V28, P94
   Waldmann E, 2015, SURG ENDOSC, V29, P466, DOI 10.1007/s00464-014-3688-2
   Wang J, 2017, IEEE T MED IMAGING, V36, P1172, DOI 10.1109/TMI.2017.2655486
   Wang J, 2017, COMPUT BIOL MED, V84, P137, DOI 10.1016/j.compbiomed.2017.03.024
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wu L, 2008, NEURAL NETWORKS, V21, P1392, DOI 10.1016/j.neunet.2008.02.002
   Wu Y, ARXIV201616090814
NR 49
TC 341
Z9 356
U1 17
U2 70
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD OCT
PY 2018
VL 155
IS 4
BP 1069
EP +
DI 10.1053/j.gastro.2018.06.037
PG 18
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA GV7RI
UT WOS:000446327500033
PM 29928897
OA Green Accepted, Bronze
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Wang, P
   Xiao, X
   Brown, JRG
   Berzin, TM
   Tu, MT
   Xiong, F
   Hu, X
   Liu, PX
   Song, Y
   Zhang, D
   Yang, X
   Li, LP
   He, J
   Yi, X
   Liu, JJ
   Liu, XG
AF Wang, Pu
   Xiao, Xiao
   Brown, Jeremy R. Glissen
   Berzin, Tyler M.
   Tu, Mengtian
   Xiong, Fei
   Hu, Xiao
   Liu, Peixi
   Song, Yan
   Zhang, Di
   Yang, Xue
   Li, Liangping
   He, Jiong
   Yi, Xin
   Liu, Jingjia
   Liu, Xiaogang
TI Development and validation of a deep-learning algorithm for the
   detection of polyps during colonoscopy
SO NATURE BIOMEDICAL ENGINEERING
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; COLORECTAL-CANCER; MISS RATE; CLASSIFICATION;
   PARTICIPATION; POLYPECTOMY; MULTICENTER; GUIDELINES; INCREASES;
   HISTOLOGY
AB The detection and removal of precancerous polyps via colonoscopy is the gold standard for the prevention of colon cancer. However, the detection rate of adenomatous polyps can vary significantly among endoscopists. Here, we show that a machine-learning algorithm can detect polyps in clinical colonoscopies, in real time and with high sensitivity and specificity. We developed the deep-learning algorithm by using data from 1,290 patients, and validated it on newly collected 27,113 colonoscopy images from 1,138 patients with at least one detected polyp (per-image-sensitivity, 94.38%; per-image-specificity, 95.92%; area under the receiver operating characteristic curve, 0.984), on a public database of 612 polyp-containing images (per-image-sensitivity, 88.24%), on 138 colonoscopy videos with histologically confirmed polyps (per-image-sensitivity of 91.64%; per-polyp-sensitivity, 100%), and on 54 unaltered full-range colonoscopy videos without polyps (per-image-specificity, 95.40%). By using a multi-threaded processing system, the algorithm can process at least 25 frames per second with a latency of 76.80 +/- 5.60 ms in real-time video analysis. The software may aid endoscopists while performing colonoscopies, and help assess differences in polyp and adenoma detection performance among endoscopists.
C1 [Wang, Pu; Tu, Mengtian; Xiong, Fei; Hu, Xiao; Liu, Peixi; Song, Yan; Zhang, Di; Yang, Xue; Li, Liangping; Liu, Xiaogang] Sichuan Acad Med Sci, Chengdu, Sichuan, Peoples R China.
   [Wang, Pu; Tu, Mengtian; Xiong, Fei; Hu, Xiao; Liu, Peixi; Song, Yan; Zhang, Di; Yang, Xue; Li, Liangping; Liu, Xiaogang] Sichuan Prov Peoples Hosp, Chengdu, Sichuan, Peoples R China.
   [Xiao, Xiao; He, Jiong; Yi, Xin; Liu, Jingjia] Shanghai Wision Al Co Ltd, Shanghai, Peoples R China.
   [Brown, Jeremy R. Glissen; Berzin, Tyler M.] Beth Israel Deaconess Med Ctr, Boston, MA 02215 USA.
   [Brown, Jeremy R. Glissen; Berzin, Tyler M.] Harvard Med Sch, Ctr Adv Endoscopy, Boston, MA USA.
C3 Sichuan Provincial People's Hospital; Sichuan Provincial People's
   Hospital; Harvard University; Beth Israel Deaconess Medical Center;
   Harvard University; Harvard Medical School
RP Liu, XG (通讯作者)，Sichuan Acad Med Sci, Chengdu, Sichuan, Peoples R China.; Liu, XG (通讯作者)，Sichuan Prov Peoples Hosp, Chengdu, Sichuan, Peoples R China.
EM gary.samsph@gmail.com
RI Wang, Xuedan/ABG-5633-2021; Tu, Mengtian/AAU-6816-2020
OI Wang, Pu/0000-0002-1234-309X; Glissen Brown, Jeremy/0000-0002-7204-7241;
   Berzin, Tyler/0000-0002-4364-6210
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bandos AI, 2009, BIOMETRICS, V65, P247, DOI 10.1111/j.1541-0420.2008.01049.x
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brandao P., 2018, J MED ROBOT RES, V3, P1840002, DOI DOI 10.1142/S2424905X18400020
   Brenner H, 2011, ANN INTERN MED, V154, P22, DOI 10.7326/0003-4819-154-1-201101040-00004
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen JH, 2017, NEW ENGL J MED, V376, P2507, DOI 10.1056/NEJMp1702071
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chinese Society of Gastroenterology, 2011, CHIN J GASTROENTEROL, V20, P979, DOI DOI 10.3969/J.ISSN.1006-5709.2011.11.001
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dean J., 2012, P NIPS
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Edwards BK, 2010, CANCER-AM CANCER SOC, V116, P544, DOI 10.1002/cncr.24760
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gkolfakis P, 2017, WORLD J GASTROENTERO, V23, P3784, DOI 10.3748/wjg.v23.i21.3784
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuo S. M., 2013, REAL TIME DIGITAL SI
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Seeff LC, 2004, GASTROENTEROLOGY, V127, P1670, DOI 10.1053/j.gastro.2004.09.051
   Siegel R, 2013, CA-CANCER J CLIN, V63, P11, DOI 10.3322/caac.21166
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Winawer SJ, 1997, GASTROENTEROLOGY, V112, P594, DOI 10.1053/gast.1997.v112.agast970594
   Yao K, 2013, ANN GASTROENTEROL, V26, P11
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 41
TC 232
Z9 246
U1 9
U2 98
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2157-846X
J9 NAT BIOMED ENG
JI Nat. Biomed. Eng
PD OCT
PY 2018
VL 2
IS 10
BP 741
EP 748
DI 10.1038/s41551-018-0301-3
PG 8
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA GW4SN
UT WOS:000446910800008
PM 31015647
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Li, CF
   Jing, BZ
   Ke, LR
   Li, B
   Xia, WX
   He, CS
   Qian, CN
   Zhao, C
   Mai, HQ
   Chen, MY
   Cao, KJ
   Mo, HY
   Guo, L
   Chen, QY
   Tang, LQ
   Qiu, WZ
   Yu, YH
   Liang, H
   Huang, XJ
   Liu, GY
   Li, WZ
   Wang, L
   Sun, R
   Zou, X
   Guo, SS
   Huang, PY
   Luo, DH
   Qiu, F
   Wu, YS
   Hua, YJ
   Liu, KY
   Lv, SH
   Miao, JJ
   Xiang, YQ
   Sun, Y
   Guo, X
   Lv, X
AF Li, Chaofeng
   Jing, Bingzhong
   Ke, Liangru
   Li, Bin
   Xia, Weixiong
   He, Caisheng
   Qian, Chaonan
   Zhao, Chong
   Mai, Haiqiang
   Chen, Mingyuan
   Cao, Kajia
   Mo, Haoyuan
   Guo, Ling
   Chen, Qiuyan
   Tang, Linquan
   Qiu, Wenze
   Yu, Yahui
   Liang, Hu
   Huang, Xinjun
   Liu, Guoying
   Li, Wangzhong
   Wang, Lin
   Sun, Rui
   Zou, Xiong
   Guo, Shanshan
   Huang, Peiyu
   Luo, Donghua
   Qiu, Fang
   Wu, Yishan
   Hua, Yijun
   Liu, Kuiyuan
   Lv, Shuhui
   Miao, Jingjing
   Xiang, Yanqun
   Sun, Ying
   Guo, Xiang
   Lv, Xing
TI Development and validation of an endoscopic images-based deep learning
   model for detection with nasopharyngeal malignancies
SO CANCER COMMUNICATIONS
LA English
DT Article
DE Nasopharyngeal malignancy; Deep learning; Differential diagnosis;
   Automatic segmentation
ID CONVOLUTIONAL NEURAL-NETWORKS; RADICAL RADIOTHERAPY; CLASSIFICATION;
   CARCINOMA; DIAGNOSIS; CANCER; BIOPSY
AB Background: Due to the occult anatomic location of the nasopharynx and frequent presence of adenoid hyperplasia, the positive rate for malignancy identification during biopsy is low, thus leading to delayed or missed diagnosis for nasopharyngeal malignancies upon initial attempt. Here, we aimed to develop an artificial intelligence tool to detect nasopharyngeal malignancies under endoscopic examination based on deep learning.
   Methods: An endoscopic images-based nasopharyngeal malignancy detection model (eNPM-DM) consisting of a fully convolutional network based on the inception architecture was developed and fine-tuned using separate training and validation sets for both classification and segmentation. Briefly, a total of 28,966 qualified images were collected. Among these images, 27,536 biopsy-proven images from 7951 individuals obtained from January 1st, 2008, to December 31st, 2016, were split into the training, validation and test sets at a ratio of 7: 1: 2 using simple randomization. Additionally, 1430 images obtained from January 1st, 2017, to March 31st, 2017, were used as a prospective test set to compare the performance of the established model against oncologist evaluation. The dice similarity coefficient (DSC) was used to evaluate the efficiency of eNPM-DM in automatic segmentation of malignant area from the background of nasopharyngeal endoscopic images, by comparing automatic segmentation with manual segmentation performed by the experts.
   Results: All images were histopathologically confirmed, and included 5713 (19.7%) normal control, 19,107 (66.0%) nasopharyngeal carcinoma (NPC), 335 (1.2%) NPC and 3811 (13.2%) benign diseases. The eNPM-DM attained an overall accuracy of 88.7% (95% confidence interval (CI) 87.8%-89.5%) in detecting malignancies in the test set. In the prospective comparison phase, eNPM-DM outperformed the experts: the overall accuracy was 88.0% (95% CI 86.1%-89.6%) vs. 80.5% (95% CI 77.0%-84.0%). The eNPM-DM required less time (40 s vs. 110.0 +/- 5.8 min) and exhibited encouraging performance in automatic segmentation of nasopharyngeal malignant area from the background, with an average DSC of 0.78 +/- 0.24 and 0.75 +/- 0.26 in the test and prospective test sets, respectively.
   Conclusions: The eNPM-DM outperformed oncologist evaluation in diagnostic classification of nasopharyngeal mass into benign versus malignant, and realized automatic segmentation of malignant area from the background of nasopharyngeal endoscopic images.
C1 [Li, Chaofeng; Jing, Bingzhong; Ke, Liangru; Li, Bin; Xia, Weixiong; He, Caisheng; Qian, Chaonan; Zhao, Chong; Mai, Haiqiang; Chen, Mingyuan; Cao, Kajia; Mo, Haoyuan; Guo, Ling; Chen, Qiuyan; Tang, Linquan; Qiu, Wenze; Yu, Yahui; Liang, Hu; Huang, Xinjun; Liu, Guoying; Li, Wangzhong; Wang, Lin; Sun, Rui; Zou, Xiong; Guo, Shanshan; Huang, Peiyu; Luo, Donghua; Qiu, Fang; Wu, Yishan; Hua, Yijun; Liu, Kuiyuan; Lv, Shuhui; Miao, Jingjing; Xiang, Yanqun; Sun, Ying; Guo, Xiang; Lv, Xing] Collaborat Innovat Ctr Canc Med, State Key Lab Oncol South China, Guangzhou 510060, Guangdong, Peoples R China.
   [Li, Chaofeng; Jing, Bingzhong; Li, Bin; He, Caisheng] Sun Yat Sen Univ, Dept Informat, Canc Ctr, Guangzhou 510060, Guangdong, Peoples R China.
   [Ke, Liangru] Sun Yat Sen Univ, Dept Radiol, Canc Ctr, Guangzhou 510060, Guangdong, Peoples R China.
   [Xia, Weixiong; Qian, Chaonan; Zhao, Chong; Mai, Haiqiang; Chen, Mingyuan; Cao, Kajia; Mo, Haoyuan; Guo, Ling; Chen, Qiuyan; Tang, Linquan; Qiu, Wenze; Yu, Yahui; Liang, Hu; Huang, Xinjun; Liu, Guoying; Li, Wangzhong; Wang, Lin; Sun, Rui; Zou, Xiong; Guo, Shanshan; Huang, Peiyu; Luo, Donghua; Qiu, Fang; Wu, Yishan; Hua, Yijun; Liu, Kuiyuan; Lv, Shuhui; Miao, Jingjing; Xiang, Yanqun; Guo, Xiang; Lv, Xing] Sun Yat Sen Univ, Dept Nasopharyngeal Carcinoma, Canc Ctr, Guangzhou 510060, Guangdong, Peoples R China.
   [Li, Chaofeng] Sun Yat Sen Univ, Precis Med Ctr, Canc Ctr, Guangzhou 510060, Guangdong, Peoples R China.
   [Sun, Ying] Sun Yat Sen Univ, Dept Radiotherapy, Canc Ctr, Guangzhou 510060, Guangdong, Peoples R China.
   [Li, Chaofeng] Guangdong Key Lab Nasopharyngeal Carcinoma Diag &, Guangzhou 510060, Guangdong, Peoples R China.
C3 State Key Lab Oncology South China; Sun Yat Sen University; Sun Yat Sen
   University; Sun Yat Sen University; Sun Yat Sen University; Sun Yat Sen
   University
RP Guo, X; Lv, X (通讯作者)，Collaborat Innovat Ctr Canc Med, State Key Lab Oncol South China, Guangzhou 510060, Guangdong, Peoples R China.; Guo, X; Lv, X (通讯作者)，Sun Yat Sen Univ, Dept Nasopharyngeal Carcinoma, Canc Ctr, Guangzhou 510060, Guangdong, Peoples R China.
EM guoxiang@sysucc.org.cn; lvxing@sysucc.org.cn
RI Chen, Ming/GVU-8412-2022
OI Li, Wang-Zhong/0000-0002-2744-8775
FU National Natural Science Foundation of China [81572665, 81672680,
   81472525, 81702873]; International Cooperation Project of Science and
   Technology Plan of Guangdong Province [2016A050502011]; Health& Medical
   Collaborative Innovation Project of Guangzhou City, China [201604020003]
FX This work was supported by the National Natural Science Foundation of
   China [Grant Nos. 81572665, 81672680, 81472525, 81702873]; the
   International Cooperation Project of Science and Technology Plan of
   Guangdong Province [Grant No. 2016A050502011]; the Health& Medical
   Collaborative Innovation Project of Guangzhou City, China (Grant No.
   201604020003).
CR Abu-Ghanem S, 2015, RHINOLOGY, V53, P142, DOI [10.4193/Rhin14.130, 10.4193/Rhino14.130]
   Berkiten G, 2014, B-ENT, V10, P279
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cengiz K, 2013, CASE REP OTOLARYNGOL, V2013, DOI 10.1155/2013/653963
   Chan ATC, 2009, ANN ONCOL, V20, P123, DOI 10.1093/annonc/mdp150
   Chan KCA, 2014, CHIN J CANCER, V33, P598, DOI 10.5732/cjc.014.10192
   Ertosun Mehmet Gunhan, 2015, AMIA Annu Symp Proc, V2015, P1899
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Lee N, 2009, J CLIN ONCOL, V27, P3684, DOI 10.1200/JCO.2008.19.9109
   Liang H, 2017, EUR J CANCER, V73, P48, DOI 10.1016/j.ejca.2016.12.009
   Meng RL, 2016, CHINESE J CANCER RES, V28, P311, DOI 10.21147/j.issn.1000-9604.2016.03.05
   Miotto R, 2017, BRIEF BIOINFORM
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mori H, 2016, GASTROINTEST ENDOSC, V83, P262, DOI 10.1016/j.gie.2015.08.008
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Sharma H, 2017, COMPUT MED IMAG GRAP, V61, P2, DOI 10.1016/j.compmedimag.2017.06.001
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Stelow EB, 2017, HEAD NECK PATHOL, V11, P16, DOI 10.1007/s12105-017-0787-0
   Su Sheng-Fa, 2011, Chin J Cancer, V30, P565, DOI 10.5732/cjc.010.10547
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   van der Burgh HK, 2017, NEUROIMAGE-CLIN, V13, P361, DOI 10.1016/j.nicl.2016.10.008
   Wei KR, 2017, CHIN J CANCER, V36, DOI 10.1186/s40880-017-0257-9
   Wu YP, 2015, CHIN J CANCER, V34, DOI 10.1186/s40880-015-0005-y
   Yi JL, 2006, INT J RADIAT ONCOL, V65, P161, DOI 10.1016/j.ijrobp.2005.12.003
NR 33
TC 24
Z9 26
U1 1
U2 24
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2523-3548
J9 CANCER COMMUN
JI Cancer Commun.
PD SEP 25
PY 2018
VL 38
AR 59
DI 10.1186/s40880-018-0325-9
PG 11
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA GV2EX
UT WOS:000445901100002
PM 30253801
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Mori, Y
   Kudo, SE
   Misawa, M
   Saito, Y
   Ikematsu, H
   Hotta, K
   Ohtsuka, K
   Urushibara, F
   Kataoka, S
   Ogawa, Y
   Maeda, Y
   Takeda, K
   Nakamura, H
   Ichimasa, K
   Kudo, T
   Hayashi, T
   Wakamura, K
   Ishida, F
   Inoue, H
   Itoh, H
   Oda, M
   Mori, K
AF Mori, Yuichi
   Kudo, Shin-ei
   Misawa, Masashi
   Saito, Yutaka
   Ikematsu, Hiroaki
   Hotta, Kinichi
   Ohtsuka, Kazuo
   Urushibara, Fumihiko
   Kataoka, Shinichi
   Ogawa, Yushi
   Maeda, Yasuharu
   Takeda, Kenichi
   Nakamura, Hiroki
   Ichimasa, Katsuro
   Kudo, Toyoki
   Hayashi, Takemasa
   Wakamura, Kunihiko
   Ishida, Fumio
   Inoue, Haruhiro
   Itoh, Hayato
   Oda, Masahiro
   Mori, Kensaku
TI Real-Time Use of Artificial Intelligence in Identification of Diminutive
   Polyps During Colonoscopy A Prospective Study
SO ANNALS OF INTERNAL MEDICINE
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; SMALL COLORECTAL LESIONS; OPTICAL DIAGNOSIS;
   COLON POLYPS; ENDOSCOPY; SYSTEM; HISTOLOGY; CLASSIFICATION;
   ENDOCYTOSCOPY; RECOGNITION
AB Background: Computer-aided diagnosis (CAD) for colonoscopy may help endoscopists distinguish neoplastic polyps (adenomas) requiring resection from nonneoplastic polyps not requiring resection, potentially reducing cost.
   Objective: To evaluate the performance of real-time CAD with endocytoscopes (x520 ultramagnifying colonoscopes providing microvascular and cellular visualization of colorectal polyps after application of the narrow-band imaging [NBI] and methylene blue staining modes, respectively).
   Design: Single-group, open-label, prospective study. (UMIN [University hospital Medical Information Network] Clinical Trial Registry: UMIN000027360).
   Setting: University hospital.
   Participants: 791 consecutive patients undergoing colonoscopy and 23 endoscopists.
   Intervention: Real-time use of CAD during colonoscopy.
   Measurements: CAD-predicted pathology (neoplastic or nonneoplastic) of detected diminutive polyps (5 mm) on the basis of real-time outputs compared with pathologic diagnosis of the resected specimen (gold standard). The primary end point was whether CAD with the stained mode produced a negative predictive value (NPV) of 90% or greater for identifying diminutive rectosigmoid adenomas, the threshold required to "diagnose-and-leave" nonneoplastic polyps. Best- and worst-case scenarios assumed that polyps lacking either CAD diagnosis or pathology were true- or false-positive or true- or false-negative, respectively.
   Results: Overall, 466 diminutive (including 250 rectosigmoid) polyps from 325 patients were assessed by CAD, with a pathologic prediction rate of 98.1% (457 of 466). The NPVs of CAD for diminutive rectosigmoid adenomas were 96.4% (95% CI, 91.8% to 98.8%) (best-case scenario) and 93.7% (CI, 88.3% to 97.1%) (worst-case scenario) with stained mode and 96.5% (CI, 92.1% to 98.9%) (best-case scenario) and 95.2% (CI, 90.3% to 98.0%) (worst-case scenario) with NBI.
   Limitation: Two thirds of the colonoscopies were conducted by experts who had each experienced more than 200 endocytoscopies; 186 polyps not assessed by CAD were excluded.
   Conclusion: Real-time CAD can achieve the performance level required for a diagnose-and-leave strategy for diminutive, nonneoplastic rectosigmoid polyps.
C1 [Mori, Yuichi; Kudo, Shin-ei; Misawa, Masashi; Urushibara, Fumihiko; Kataoka, Shinichi; Ogawa, Yushi; Maeda, Yasuharu; Takeda, Kenichi; Nakamura, Hiroki; Ichimasa, Katsuro; Kudo, Toyoki; Hayashi, Takemasa; Wakamura, Kunihiko; Ishida, Fumio] Showa Univ, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.
   [Ikematsu, Hiroaki] Natl Canc Ctr Hosp East, Dept Gastroenterol & Endoscopy, 6-5-1 Kashiwanoha, Kashiwa, Chiba 2278577, Japan.
   [Hotta, Kinichi] Shizuoka Canc Ctr, Div Endoscopy, 1007 Shimonagakubo, Nagaizumi Tyo, Shizuoka 4118777, Japan.
   [Ohtsuka, Kazuo] Tokyo Med & Dent Univ, Dept Endoscopy, Bunkyo Ku, 1-5-45 Yushima, Tokyo 1138510, Japan.
   [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4640814, Japan.
   [Mori, Yuichi; Kudo, Shin-ei; Misawa, Masashi; Urushibara, Fumihiko; Kataoka, Shinichi; Ogawa, Yushi; Maeda, Yasuharu; Takeda, Kenichi; Nakamura, Hiroki; Ichimasa, Katsuro; Kudo, Toyoki; Hayashi, Takemasa; Wakamura, Kunihiko; Ishida, Fumio] Showa Univ, Northern Yokohama Hosp, Ctr Digest Dis, Tsuzuki Ku, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
   [Inoue, Haruhiro] Showa Univ, Koto Toyosu Hosp, Ctr Digest Dis, Koto Ku, 5-1-38 Toyosu, Tokyo 1358577, Japan.
C3 Showa University; National Cancer Center - Japan; National Cancer Center
   - Japan; Shizuoka Cancer Center; Tokyo Medical & Dental University
   (TMDU); Nagoya University; Showa University; Showa University
RP Mori, Y (通讯作者)，Showa Univ, Northern Yokohama Hosp, Ctr Digest Dis, Tsuzuki Ku, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
EM ibusiginjp@gmail.com
RI Ichimasa, Katsuro/AAP-6941-2021; Itoh, Hayato/AAM-4022-2021; Mori,
   Yuichi/AAU-5406-2020; Misawa, Masashi/H-9004-2019
OI Itoh, Hayato/0000-0002-1410-1078; Misawa, Masashi/0000-0002-8520-2036;
   Oda, Masahiro/0000-0001-7714-422X; Mori, Yuichi/0000-0003-2262-0334
FU Japan Society for the Promotion of Science [17H05305]; Grants-in-Aid for
   Scientific Research [17H05305] Funding Source: KAKEN
FX By Grants-in-Aid for Scientific Research (grant 17H05305) from the Japan
   Society for the Promotion of Science.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Fred T. B., 2010, WHO CLASSIFICATION T
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hetzel JT, 2010, AM J GASTROENTEROL, V105, P2656, DOI 10.1038/ajg.2010.315
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Iwatate M, 2015, ENDOSC INT OPEN, V3, pE140, DOI 10.1055/s-0034-1391362
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lahiff C, 2017, FRONTLINE GASTROENTE, V8, P98, DOI 10.1136/flgastro-2016-100777
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   National Institute for Health and Care Excellence, 2017, VIRT CHROM ASS COL P
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Singh R, 2017, WORLD J GASTRO ENDOS, V9, P273, DOI 10.4253/wjge.v9.i6.273
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Tanaka S, 2015, J GASTROENTEROL, V50, P252, DOI 10.1007/s00535-014-1021-4
NR 26
TC 249
Z9 256
U1 4
U2 59
PU AMER COLL PHYSICIANS
PI PHILADELPHIA
PA INDEPENDENCE MALL WEST 6TH AND RACE ST, PHILADELPHIA, PA 19106-1572 USA
SN 0003-4819
EI 1539-3704
J9 ANN INTERN MED
JI Ann. Intern. Med.
PD SEP 18
PY 2018
VL 169
IS 6
BP 357
EP +
DI 10.7326/M18-0249
PG 19
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA GT7CZ
UT WOS:000444679800012
PM 30105375
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Nigam, N
   Patel, P
   Sengupta, N
AF Nigam, Neha
   Patel, Parita
   Sengupta, Neil
TI Outcomes of Early Versus Delayed Colonoscopy in Lower Gastrointestinal
   Bleeding Using a Hospital Administrative Database
SO JOURNAL OF CLINICAL GASTROENTEROLOGY
LA English
DT Article
DE colonoscopy; lower gastrointestinal bleeding; mortality
ID URGENT COLONOSCOPY; ADVERSE OUTCOMES; TRIAL; TRANSFUSION; MANAGEMENT;
   HEMORRHAGE; IMPACT; STAY; RISK
AB Background:Limited data exist on whether early colonoscopy for lower gastrointestinal bleeding (LGIB) alters 30-day mortality, performance of endoscopic intervention, or need for blood transfusion. Our primary objective was to determine whether early colonoscopy in LGIB is associated with decreased 30-day mortality using a large hospital administrative database.Methods:Patients hospitalized between January 2008 and September 2015 were identified using a validated, machine learning algorithm for identifying patients with LGIB. Early colonoscopy occurred by day 2 of admission and late colonoscopy between days 3 and 5. A propensity score for early colonoscopy was constructed using plausible confounders. Univariable and multivariable logistic regression were used to determine factors associated with 30-day mortality, endoscopic intervention, and transfusion need. The propensity score was included as a confounding factor for mortality analysis in the multivariable model.Results:In total, 1204 patients underwent colonoscopy for LGIB. Of these, 295 patients (25%) underwent early colonoscopy, and these patients had a lower Charlson Comorbidity Index (P=0.001) and shorter length of stay (3 vs. 5d, P=0.0001). Early colonoscopy was not associated with decreased 30-day mortality [odds ratio (OR), 0.73; confidence interval (CI), 0.27-1.69], but was associated with increased endoscopic intervention (OR, 2.62; CI, 1.37-4.95) and decreased need for transfusion (OR, 0.65; CI, 0.49-0.87). On multivariable analysis adjusting for timing of colonoscopy, age, and propensity score for early colonoscopy, early colonoscopy was not associated with a decrease in 30-day mortality (OR, 1.37; CI, 0.50-3.79).Conclusions:Early colonoscopy does not affect 30-day mortality but may allow for earlier endoscopic intervention and decreased transfusion need.
C1 [Nigam, Neha; Sengupta, Neil] Univ Chicago, Med Ctr, Sect Gastroenterol Hepatol & Nutr, 5841 Maryland Ave,MC 4076, Chicago, IL 60637 USA.
   [Patel, Parita] Univ Chicago, Med Ctr, Dept Med, Chicago, IL 60637 USA.
C3 University of Chicago; University of Chicago Medical Center; University
   of Chicago; University of Chicago Medical Center
RP Sengupta, N (通讯作者)，Univ Chicago, Med Ctr, Sect Gastroenterol Hepatol & Nutr, 5841 Maryland Ave,MC 4076, Chicago, IL 60637 USA.
EM nsengupta@medicine.bsd.uchicago.edu
CR Davila RE, 2005, GASTROINTEST ENDOSC, V62, P656, DOI 10.1016/j.gie.2005.07.032
   Green BT, 2005, AM J GASTROENTEROL, V100, P2395, DOI 10.1111/j.1572-0241.2005.00306.x
   Hebert PC, 1999, NEW ENGL J MED, V340, P409, DOI 10.1056/NEJM199902113400601
   Jensen DM, 2000, NEW ENGL J MED, V342, P78, DOI 10.1056/NEJM200001133420202
   Kwok CS, 2015, JACC-CARDIOVASC INTE, V8, P436, DOI 10.1016/j.jcin.2014.09.026
   Laine L, 2010, AM J GASTROENTEROL, V105, P2636, DOI 10.1038/ajg.2010.277
   Lanas A, 2009, AM J GASTROENTEROL, V104, P1633, DOI 10.1038/ajg.2009.164
   Nagata N, 2016, CLIN GASTROENTEROL H, V14, P558, DOI 10.1016/j.cgh.2015.10.011
   Navaneethan U, 2014, GASTROINTEST ENDOSC, V79
   Schmulewitz N, 2003, GASTROINTEST ENDOSC, V58, P841, DOI 10.1016/S0016-5107(03)02304-6
   Sengupta N, 2017, J CLIN GASTROENTEROL, V51, P352, DOI 10.1097/MCG.0000000000000602
   Sengupta N, 2015, MAYO CLIN PROC, V90, P1021, DOI 10.1016/j.mayocp.2015.04.024
   Siddique J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138987
   Strate LL, 2016, AM J GASTROENTEROL, V111, P755, DOI 10.1038/ajg.2016.155
   Strate LL, 2003, AM J GASTROENTEROL, V98, P317, DOI 10.1016/S0002-9270(02)05900-2
NR 15
TC 11
Z9 12
U1 0
U2 0
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0192-0790
EI 1539-2031
J9 J CLIN GASTROENTEROL
JI J. Clin. Gastroenterol.
PD SEP
PY 2018
VL 52
IS 8
BP 721
EP 725
DI 10.1097/MCG.0000000000000937
PG 5
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA GQ7IO
UT WOS:000441911800010
PM 28961575
DA 2023-04-20
ER

PT J
AU Sanchez-Gonzalez, A
   Garcia-Zapirain, B
   Sierra-Sosa, D
   Elmaghraby, A
AF Sanchez-Gonzalez, Alain
   Garcia-Zapirain, Begonya
   Sierra-Sosa, Daniel
   Elmaghraby, Adel
TI Automatized colon polyp segmentation via contour region analysis
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp detection; Colonoscopy images; Image processing; Feature
   classification; Feature selection
ID SYSTEM
AB The increasing use of colorectal cancer screening programs has contributed to the growing number of colonoscopies performed by health centers. Hence, in recent years there has been a tendency to develop medical diagnosis support tools in order to assist specialists. This research has designed an automatized polyp detection system that allows a reduction in the rate of missed polyps that can lead to interval cancer; one of the main risks existing in colonoscopy. A characterization has therefore been made of the shape, color and curvature of edges and their regions, enabling the segmentation of polyps present in colonoscopy images. A 90.53% polyp detection rate has been achieved using the designed system, and 76.29% and 71.57% segmentation quality for the Annotated Area Covered and Dice Coefficient indicators respectively. This system aims to offer assistance with medical diagnosis that has a positive impact on patient health.
C1 [Sanchez-Gonzalez, Alain; Garcia-Zapirain, Begonya] Univ Deusto, eVida Res Grp, Av Univ 24, Bilbao 48007, Spain.
   [Sierra-Sosa, Daniel; Elmaghraby, Adel] Univ Louisville, Dept Comp Engn & Comp Sci CECS, Louisville, KY 40292 USA.
C3 University of Deusto; University of Louisville
RP Sierra-Sosa, D (通讯作者)，Univ Louisville, Dept Comp Engn & Comp Sci CECS, Louisville, KY 40292 USA.
EM d.sierrasosa@louisville.edu
RI Sierra-Sosa, Daniel/AAP-4610-2020; Sierra-Sosa, Daniel/AAP-4604-2020;
   Elmaghraby, Adel S/B-3353-2014
OI Sierra-Sosa, Daniel/0000-0003-1326-0867; Sierra-Sosa,
   Daniel/0000-0003-1326-0867; Elmaghraby, Adel S/0000-0001-5274-8596
FU Basque Government "Aids for health research projects"; Basque Government
   Department of Education (eVIDA Certified Group) [IT579-13]
FX This research was supported by the Basque Government "Aids for health
   research projects" and the publication fees supported by the Basque
   Government Department of Education (eVIDA Certified Group IT579-13).
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Arnold M., 2010, J IMAGE VIDEO PROCES, V2010, P9
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J., 2012, COMPUTATIONAL CLIN A, P76
   Bernal J., 2011, DEPTH VALLEYS ACCUMU, P71
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Bernal J, 2011, LECT NOTES COMPUT SC, V6669, P134
   Bernal Jorge, 2011, INTELLIGENT SYSTEMS, V1
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Condessa F, 2012, LECT NOTES COMPUT SC, V7325, P188, DOI 10.1007/978-3-642-31298-4_23
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gonzalez Rafael C, 2009, DIGITAL IMAGE PROCES, VSecond
   Hall M. A., 2000, P 17 INT C MACH LEAR
   Hao Chun Wang, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P564, DOI 10.1109/ISPACS.2012.6473553
   Herrera F., 2016, MULTILABEL CLASSIFIC, V416
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iwahori Y., 2013, MVA, P21
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Li BP, 2012, J MED SYST, V36, P2463, DOI 10.1007/s10916-011-9713-2
   Manivannan S, 2013, I S BIOMED IMAGING, P644
   Park S., 2015, POLYP DETECTION COLO
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Pearl J., 2003, ARTIFICIAL INTELLIGE, V2
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Tajbakhsh N., 2015, AUTOMATED POLYP DETE
   Tajbakhsh N, 2014, I S BIOMED IMAGING, P97, DOI 10.1109/ISBI.2014.6867818
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Tjoa M., 2003, BIOMEDICAL ENG ONLIN, V2, P1
   Tulum G, 2017, INT J COMPUT ASS RAD, V12, P627, DOI 10.1007/s11548-017-1521-9
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Wang Z, 2004, PROC SPIE, V5370, P972, DOI 10.1117/12.535664
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
NR 41
TC 25
Z9 27
U1 2
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD SEP 1
PY 2018
VL 100
BP 152
EP 164
DI 10.1016/j.compbiomed.2018.07.002
PG 13
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA GR5TH
UT WOS:000442704300018
PM 30015012
DA 2023-04-20
ER

PT J
AU Buijs, MM
   Ramezani, MH
   Herp, J
   Kroijer, R
   Kobaek-Larsen, M
   Baatrup, G
   Nadimi, ES
AF Buijs, Maria Magdalena
   Ramezani, Mohammed Hossain
   Herp, Jurgen
   Kroijer, Rasmus
   Kobaek-Larsen, Morten
   Baatrup, Gunnar
   Nadimi, Esmaeil S.
TI Assessment of bowel cleansing quality in colon capsule endoscopy using
   machine learning: a pilot study
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID COLONOSCOPY; VALIDATION; SCALE; RECOMMENDATIONS
AB Background and study aims The aim of this study was to develop a machine learning-based model to classify bowel cleansing quality and to test this model in comparison to a pixel analysis model and assessments by four colon capsule endoscopy (CCE) readers.
   Methods A pixel analysis and a machine learning-based model with four cleanliness classes (unacceptable, poor, fair and good) were developed to classify CCE videos. Cleansing assessments by four CCE readers in 41 videos from a previous study were compared to the results both models yielded in this pilot study.
   Results The machine learning-based model classified 47% of the videos in agreement with the averaged classification by CCE readers, as compared to 32% by the pixel analysis model. A difference of more than one class was detected in 12 % of the videos by the machine learning-based model and in 32% by the pixel analysis model, as the latter tended to overestimate cleansing quality. A specific analysis of unacceptable videos found that the pixel analysis model classified almost all of them as fair or good, whereas the machine learning-based model identified five out of 11 videos in agreement with at least one CCE reader as unacceptable.
   Conclusions The machine learning-based model was superior to the pixel analysis in classifying bowel cleansing quality, due to a higher sensitivity to unacceptable and poor cleansing quality. The machine learning-based model can be further improved by coming to a consensus on how to classify cleanliness of a complete CCE video, by means of an expert panel.
C1 [Buijs, Maria Magdalena; Kroijer, Rasmus; Baatrup, Gunnar] Odense Univ Hosp, Dept Surg, Baagoes Alle 15, DK-5700 Svendborg, Denmark.
   [Buijs, Maria Magdalena; Kroijer, Rasmus; Kobaek-Larsen, Morten; Baatrup, Gunnar] Univ Southern Denmark, Inst Clin Res, Odense, Denmark.
   [Ramezani, Mohammed Hossain] Univ Southern Denmark, Mads Clausen Inst, Sonderborg, Denmark.
   [Herp, Jurgen; Nadimi, Esmaeil S.] Univ Southern Denmark, Fac Engn, Embodied Syst Robot & Learning, Appl Stat Signal Proc Grp, Odense, Denmark.
C3 University of Southern Denmark; Odense University Hospital; University
   of Southern Denmark; University of Southern Denmark; University of
   Southern Denmark
RP Buijs, MM (通讯作者)，Odense Univ Hosp, Dept Surg, Baagoes Alle 15, DK-5700 Svendborg, Denmark.; Buijs, MM (通讯作者)，Univ Southern Denmark, Inst Clin Res, Odense, Denmark.
EM maria.magdalena.buijs@rsyd.dk
RI Ramezani, Mohammad Hossein/Q-2246-2018; Nadimi, Esmaeil/B-5289-2019;
   Herp, Jurgen/O-7963-2018
OI Ramezani, Mohammad Hossein/0000-0002-2273-1520; Nadimi,
   Esmaeil/0000-0003-2613-2696; Kroijer, Rasmus/0000-0003-4358-7916;
   Kobaek-Larsen, Morten/0000-0002-5097-9283; Herp,
   Jurgen/0000-0003-1799-8551; Buijs, Maria Magdalena/0000-0001-7206-0713;
   baatrup, gunnar/0000-0003-0300-5766
FU Odense University Hospital; Region of Southern Denmark; Danish Cancer
   Society
FX Funding for this study was provided through research funds from Odense
   University Hospital and the Region of Southern Denmark, as well as the
   Danish Cancer Society.
CR Aronchick CA, 1999, AM J GASTROENTEROL, V94, P2667
   Ben-Horin S, 2007, AM J GASTROENTEROL, V102, P2680, DOI 10.1111/j.1572-0241.2007.01486.x
   Calderwood AH, 2010, GASTROINTEST ENDOSC, V72, P686, DOI 10.1016/j.gie.2010.06.068
   Gerard DP, 2013, CLIN TRANSL GASTROEN, V4, DOI 10.1038/ctg.2013.16
   Halphen M, 2013, GASTROINTEST ENDOSC, V78, P121, DOI 10.1016/j.gie.2013.02.009
   Johnson DA, 2014, AM J GASTROENTEROL, V109, P1528, DOI 10.1038/ajg.2014.272
   Kobaek-Larsen M, 2018, COLORECTAL DIS, V20, P479, DOI 10.1111/codi.13965
   Leighton JA, 2011, ENDOSCOPY, V43, P123, DOI 10.1055/s-0030-1255916
   Parmar R, 2016, AM J GASTROENTEROL, V111, P197, DOI 10.1038/ajg.2015.417
   Rosa-Rizzotto E, 2015, ENDOSC INT OPEN, V3, pE501, DOI 10.1055/s-0034-1392109
   Rostom A, 2004, GASTROINTEST ENDOSC, V59, P482, DOI 10.1016/S0016-5107(03)02875-X
   Spada C, 2016, CLIN GASTROENTEROL H, V14, P1533, DOI 10.1016/j.cgh.2016.04.038
NR 12
TC 12
Z9 12
U1 0
U2 0
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD AUG
PY 2018
VL 6
IS 8
BP E1044
EP E1050
DI 10.1055/a-0627-7136
PG 7
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA HD1QK
UT WOS:000452286200005
PM 30105292
OA Green Published, Green Submitted, gold
DA 2023-04-20
ER

PT J
AU D'Journo, XB
AF D'Journo, Xavier Benoit
TI Clinical implication of the innovations of the 8th edition of the TNM
   classification for esophageal and esophago-gastric cancer
SO JOURNAL OF THORACIC DISEASE
LA English
DT Article; Proceedings Paper
CT 4th International Joint Meeting on Thoracic Surgery
CY 2018
CL Barcelona, SPAIN
DE Esophageal cancer; adenocarcinoma; squamous cell carcinoma (SCC);
   esophagectomy; neoadjuvant treatment; tumor; node and metastasis
   classification (TNM classification); staging
ID ENDOSCOPIC ULTRASOUND; JUNCTION; RECOMMENDATIONS; ACCURACY;
   ULTRASONOGRAPHY; CARCINOMA; SURVIVAL; PET/CT; STAGE
AB Epidemiology of esophageal cancer and esophagogastric junction (EGJ) has deeply changed for the past two decades with a dramatically increase of adenocarcinoma whereas squamous cell carcinoma (SCC) has slowly decreased. Moreover, the two histological types differ in a number of features including risks factors, tumor location, tumor biology and outcomes. In acknowledgement of these differences, the newest 8th edition of the American Joint Committee on Cancer (AJCC) tumor, node and metastasis (TNM) staging classification of epithelial cancers of the esophagus and EGJ has refined this histology-specific disease stage with incorporation of new anatomic and non-anatomic categories. Based on data-driven of patients collected through the Worldwide Esophageal Cancer Collaboration (WECC) group, the 8th edition database encompasses a six-continent cohort of 22,654 patients among 33 institutions including patients treated with surgery alone and, for the first time, patients treated after neoadjuvant treatment. Anatomic categories include T descriptors (tumor invasion), N descriptors (regional lymph node invasion) and M descriptors (distant site). Non anatomic categories include grade differentiation (G descriptors) and tumor location (L descriptors). Category descriptors are currently assessed by endoscopy with biopsy, by endoscopy ultrasound fine-needle aspiration (EUS-FNA), by thoracic-abdominal-pelvic computed tomography (CT) and whole body flurodeoxyglucose positron emission tomography (FDG-PET) fused with CT. The new 8th edition considers separate and temporally related cancer classification based on the treatment strategy: clinical cTNM (before any treatment), pathologic pTNM (after surgery alone) and postneoadjuvant pathologic ypTNM (after neoadjuvant treatment followed by surgery). The 8th edition permits a more robust and reliable random forest-based machine learning analysis. Refinement of each T, N, M categories and subcategories makes the 8th edition more accurate and more adaptable to the current practice including neoadjuvant regimen. The main objective of this review is to examine the current staging of esophageal cancer and the new aspects of the 8th edition with its applications to clinical practice.
C1 [D'Journo, Xavier Benoit] Aix Marseille Univ, North Hosp, Dept Thorac Surg, F-13915 Marseille, France.
C3 UDICE-French Research Universities; Aix-Marseille Universite; Assistance
   Publique-Hopitaux de Marseille
RP D'Journo, XB (通讯作者)，Aix Marseille Univ, North Hosp, Dept Thorac Surg, F-13915 Marseille, France.
EM xavier.djourno@ap-hm.fr
RI D'journo, Xavier Benoit/AAJ-4457-2021
OI D'journo, Xavier Benoit/0000-0001-6747-4583
CR Beseth BD, 2000, AM SURGEON, V66, P827
   Bhutani MS, 2002, ENDOSCOPY, V34, P461, DOI 10.1055/s-2002-31996
   Bonavina L, 1997, J SURG ONCOL, V65, P171, DOI 10.1002/(SICI)1096-9098(199707)65:3<171::AID-JSO5>3.0.CO;2-3
   Bruzzi JF, 2007, RADIOGRAPHICS, V27, P1635, DOI 10.1148/rg.276065742
   Chan DSY, 2013, BRIT J SURG, V100, P456, DOI 10.1002/bjs.9015
   Depypere L, 2018, DIS ESOPHAGUS, P31
   Griffin JM, 2012, ANN THORAC SURG, V93, P1855, DOI 10.1016/j.athoracsur.2011.12.095
   Haggitt RC, 2000, HUM PATHOL, V31, P1188
   Heidemann J, 2000, DIGEST SURG, V17, P219, DOI 10.1159/000018838
   Isenberg G, 1998, GASTROINTEST ENDOSC, V48, P158, DOI 10.1016/S0016-5107(98)70157-9
   Javeri H, 2009, CANCER-AM CANCER SOC, V115, P624, DOI 10.1002/cncr.24056
   Kalha I, 2004, CANCER-AM CANCER SOC, V101, P940, DOI 10.1002/cncr.20429
   Kutup A, 2007, ENDOSCOPY, V39, P715, DOI 10.1055/s-2007-966655
   Lerut T, 2000, ANN SURG, V232, P743, DOI 10.1097/00000658-200012000-00003
   Lightdale CJ, 2005, J CLIN ONCOL, V23, P4483, DOI 10.1200/JCO.2005.20.644
   Lordick F, 2007, LANCET ONCOL, V8, P797, DOI 10.1016/S1470-2045(07)70244-9
   MANDARD AM, 1994, CANCER, V73, P2680, DOI 10.1002/1097-0142(19940601)73:11<2680::AID-CNCR2820731105>3.0.CO;2-C
   Noble F, 2009, CLIN RADIOL, V64, P699, DOI 10.1016/j.crad.2009.03.003
   Ott Katja, 2008, Gastrointest Cancer Res, V2, P287
   Rice TW, 2016, DIS ESOPHAGUS, V29, P897, DOI 10.1111/dote.12533
   Rice TW, 2016, DIS ESOPHAGUS, V29, P715, DOI 10.1111/dote.12513
   Rice TW, 2016, DIS ESOPHAGUS, V29, P724, DOI 10.1111/dote.12520
   Rice T W, 2016, Dis Esophagus, V29, P707, DOI 10.1111/dote.12493
   Rice TW, 2009, DIS ESOPHAGUS, V22, P1, DOI 10.1111/j.1442-2050.2008.00901.x
   Rice TW, 2017, J THORAC ONCOL, V12, P36, DOI 10.1016/j.jtho.2016.10.016
   Rice TW, 2016, DIS ESOPHAGUS, V29, P913, DOI 10.1111/dote.12540
   Rice TW, 2016, DIS ESOPHAGUS, V29, P906, DOI 10.1111/dote.12538
   Rice TW, 2010, CANCER-AM CANCER SOC, V116, P3763, DOI 10.1002/cncr.25146
   Rice TW, 2003, J THORAC CARDIOV SUR, V125, P1091, DOI 10.1067/mtc.2003.404
   Smyth EC, 2017, NAT REV DIS PRIMERS, V3, DOI 10.1038/nrdp.2017.48
   Thies S, 2013, FRONT ONCOL, V3, DOI 10.3389/fonc.2013.00262
   van Vliet EPM, 2008, BRIT J CANCER, V98, P547, DOI 10.1038/sj.bjc.6604200
   Wiersema MJ, 1997, GASTROENTEROLOGY, V112, P1087, DOI 10.1016/S0016-5085(97)70164-1
NR 33
TC 35
Z9 36
U1 0
U2 6
PU AME PUBL CO
PI SHATIN
PA FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG
   00000, PEOPLES R CHINA
SN 2072-1439
EI 2077-6624
J9 J THORAC DIS
JI J. Thorac. Dis.
PD AUG
PY 2018
VL 10
SU 22
BP S2671
EP S2681
DI 10.21037/jtd.2018.03.182
PG 11
WC Respiratory System
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Respiratory System
GA GR2SZ
UT WOS:000442434500014
PM 30345104
OA Green Published
DA 2023-04-20
ER

PT J
AU Fan, SH
   Xu, LM
   Fan, YH
   Wei, KH
   Li, LH
AF Fan, Shanhui
   Xu, Lanmeng
   Fan, Yihong
   Wei, Kaihua
   Li, Lihua
TI Computer-aided detection of small intestinal ulcer and erosion in
   wireless capsule endoscopy images
SO PHYSICS IN MEDICINE AND BIOLOGY
LA English
DT Article
DE computer aided detection; ulcer; erosion; convolutional neural network;
   wireless capsule endoscopy
AB A novel computer-aided detection method based on deep learning framework was proposed to detect small intestinal ulcer and erosion in wireless capsule endoscopy (WCE) images. To the best of our knowledge, this is the first time that deep learning framework has been exploited on automated ulcer and erosion detection in WCE images. Compared with the traditional detection method, deep learning framework can produce image features directly from the data and increase recognition accuracy as well as efficiency, especially for big data. The developed method included image cropping and image compression. The AlexNet convolutional neural network was trained to the database with tens of thousands of WCE images to differentiate lesion and normal tissue. The results of ulcer and erosion detection reached a high accuracy of 95.16% and 95.34%, sensitivity of 96.80% and 93.67%, and specificity of 94.79% and 95.98%, correspondingly. The area under the receiver operating characteristic curve was over 0.98 in both of the networks. The promising results indicate that the proposed method has the potential to work in tandem with doctors to efficiently detect intestinal ulcer and erosion.
C1 [Fan, Shanhui; Xu, Lanmeng; Wei, Kaihua; Li, Lihua] Hangzhou Dianzi Univ, Coll Life Informat Sci & Instrument Engn, Hangzhou 310018, Zhejiang, Peoples R China.
   [Fan, Yihong] Zhejiang Prov Hosp Tradit Chinese Med, Dept Gastroenterol, Hangzhou 310006, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang Chinese Medical University
RP Li, LH (通讯作者)，Hangzhou Dianzi Univ, Coll Life Informat Sci & Instrument Engn, Hangzhou 310018, Zhejiang, Peoples R China.
EM lilh@hdu.edu.cn
RI fan, yi/GYU-1036-2022
OI Fan, Shanhui/0000-0003-3478-6630
FU National Natural Science Foundation of China [81601530]; Science and
   Technology Project of Zhejiang Province of China [2017C33143]
FX This work was supported by the National Natural Science Foundation of
   China (Grant number 81601530) and the Science and Technology Project of
   Zhejiang Province of China (Grant number 2017C33143). The authors have
   no conflicts of interest to disclose.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Chen Y, 2012, P 20 ACM INT C MULT, P1181, DOI DOI 10.1145/2393347.2396413
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   KIM Y., 2014, P 2014 C EMPIRICAL M, P1746, DOI [10.3115/v1/d14-1181, DOI 10.3115/V1/D14-1181, DOI 10.48550/ARXIV.1408.5882]
   Kundu AK, 2016, 2016 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2016), P242, DOI 10.1109/WIECON-ECE.2016.8009127
   Li BU, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P2326, DOI 10.1109/ROBIO.2009.5420455
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P1295, DOI 10.1016/S0002-9270(03)00245-4
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Yu LC, 2012, INT C PATT RECOG, P45
NR 20
TC 85
Z9 89
U1 7
U2 32
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0031-9155
EI 1361-6560
J9 PHYS MED BIOL
JI Phys. Med. Biol.
PD AUG
PY 2018
VL 63
IS 16
AR 165001
DI 10.1088/1361-6560/aad51c
PG 10
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA GQ0QS
UT WOS:000441324900001
PM 30033931
DA 2023-04-20
ER

PT J
AU Gibson, E
   Giganti, F
   Hu, Yp
   Bonmati, E
   Bandula, S
   Gurusamy, K
   Davidson, B
   Pereira, SP
   Clarkson, MJ
   Barratt, DC
AF Gibson, Eli
   Giganti, Francesco
   Hu, Yipeng
   Bonmati, Ester
   Bandula, Steve
   Gurusamy, Kurinchi
   Davidson, Brian
   Pereira, Stephen P.
   Clarkson, Matthew J.
   Barratt, Dean C.
TI Automatic Multi-Organ Segmentation on Abdominal CT With Dense V-Networks
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Abdominal CT; segmentation; deep learning; pancreas; gastrointestinal
   tract; stomach; duodenum; esophagus; liver; spleen; kidney; gallbladder
AB Automatic segmentation of abdominal anatomy on computed tomography (CT) images can support diagnosis, treatment planning, and treatment delivery workflows. Segmentation methods using statistical models and multi-atlas label fusion (MALF) require inter-subject image registrations, which are challenging for abdominal images, but alternative methods without registration have not yet achieved higher accuracy for most abdominal organs. We present a registration-free deep-learning-based segmentation algorithm for eight organs that are relevant for navigation in endoscopic pancreatic and biliary procedures, including the pancreas, the gastrointestinal tract (esophagus, stomach, and duodenum) and surrounding organs (liver, spleen, left kidney, and gallbladder). We directly compared the segmentation accuracy of the proposed method to the existing deep learning and MALF methods in a cross-validation on a multi-centredata set with 90 subjects. The proposed method yielded significantly higher Dice scores for all organs and lower mean absolute distances for most organs, including Dice scores of 0.78 versus 0.71, 0.74, and 0.74 for the pancreas, 0.90 versus 0.85, 0.87, and 0.83 for the stomach, and 0.76 versus 0.68, 0.69, and 0.66 for the esophagus. We conclude that the deep-learning-based segmentation represents a registration-free method for multi-organ abdominal CT segmentation whose accuracy can surpass current methods, potentially supporting image-guided navigation in gastrointestinal endoscopy procedures.
C1 [Gibson, Eli; Hu, Yipeng; Bonmati, Ester; Clarkson, Matthew J.; Barratt, Dean C.] UCL, Dept Med Phys & Biomed Engn, UCL Ctr Med Image Comp, London WC1E 6BT, England.
   [Gibson, Eli; Hu, Yipeng; Bonmati, Ester; Clarkson, Matthew J.; Barratt, Dean C.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, London WC1E 6BT, England.
   [Giganti, Francesco] Univ Coll Hosp Trust, Dept Radiol, London NW1 2BU, England.
   [Giganti, Francesco; Gurusamy, Kurinchi; Davidson, Brian] UCL, Div Surg & Intervent Sci, London WC1E 6BT, England.
   [Bandula, Steve] UCL, UCL Ctr Med Imaging, London WC1E 6BT, England.
   [Pereira, Stephen P.] UCL, Inst Liver & Digest Hlth, London WC1E 6BT, England.
C3 University of London; University College London; UK Research &
   Innovation (UKRI); Engineering & Physical Sciences Research Council
   (EPSRC); University of London; University College London; University of
   London; University College London; University of London; University
   College London; University of London; University College London;
   University of London; University College London
RP Gibson, E (通讯作者)，UCL, Dept Med Phys & Biomed Engn, UCL Ctr Med Image Comp, London WC1E 6BT, England.
EM eli.gibson@ucl.ac.uk
RI Hu, Yi/HSF-1862-2023; Gibson, Eli/E-2191-2016; Pereira,
   Stephen/C-5639-2009
OI Davidson, Brian/0000-0002-9152-5907; Hu, Yipeng/0000-0003-4902-0486;
   Gibson, Eli/0000-0001-9207-7280; Barratt, Dean/0000-0003-2916-655X;
   Giganti, Francesco/0000-0001-5218-6431; Clarkson,
   Matthew/0000-0002-5565-1252; Bonmati, Ester/0000-0001-9217-5438;
   Gurusamy, Kurinchi/0000-0002-0313-9134; Pereira,
   Stephen/0000-0003-0821-1809
FU Cancer Research U.K. under Multidisciplinary Grant [C28070/A19985];
   National Institute for Health Research UCL/UCL Hospitals Biomedical
   Research Centre
FX This work was supported in part by the Cancer Research U.K. under
   Multidisciplinary Grant C28070/A19985 and in part by the National
   Institute for Health Research UCL/UCL Hospitals Biomedical Research
   Centre.
CR [Anonymous], 2016, DISTILL
   BenTaieb Aicha, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P460, DOI 10.1007/978-3-319-46723-8_53
   Brust C. A., 2015, C COMP VIS PATT REC, P1
   Campadelli P., 2009, ELECT LETT COMPUT VI, V8, P1
   Cerrolaza JJ, 2015, MED IMAGE ANAL, V25, P11, DOI 10.1016/j.media.2015.04.003
   Chen H., 2017, NEUROIMAGE, DOI [10.1016/j.neuroimage.2017.04.041, DOI 10.1016/J.NEUROIMAGE.2017.04.041.]
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Eisen GM, 2001, GASTROINTEST ENDOSC, V54, P811, DOI 10.1016/S0016-5107(01)70082-X
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gerard PD, 2007, COMPUT STAT DATA AN, V51, P4622, DOI 10.1016/j.csda.2006.08.028
   Gibson E, 2017, INT C MED IM COMP CO, P728, DOI DOI 10.1007/978-3-319-66182-7_83
   He B, 2015, P CEUR WORKSH VISCER, P18
   He K., 2016, IDENTITY MAPPINGS DE
   Heimann T, 2009, MED IMAGE ANAL, V13, P543, DOI 10.1016/j.media.2009.05.004
   Heinrich MP, 2013, IEEE T MED IMAGING, V32, P1239, DOI 10.1109/TMI.2013.2246577
   Howe RD, 1999, ANNU REV BIOMED ENG, V1, P211, DOI 10.1146/annurev.bioeng.1.1.211
   Hu PJ, 2017, INT J COMPUT ASS RAD, V12, P399, DOI 10.1007/s11548-016-1501-5
   Huang G., 2017, 2017 P IEEE C COMP V, P4700, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S., 2015, INT C MACHINE LEARNI, P448
   Kechichian R., 2017, CLOUD BASED BENCHMAR, P185
   Kroon DJ, 2010, SMOOTH TRIANGULATED
   Landman B., 2012, MICCAI GRAND CHALL W
   Landman Bennett, 2017, MULTIATLAS LABELING
   Larsson M, 2017, LECT NOTES COMPUT SC, V10270, P41, DOI 10.1007/978-3-319-59129-2_4
   Litjens G, 2017, SURVEY DEEP LEARNING
   Lombaert H, 2014, LECT NOTES COMPUT SC, V8674, P496, DOI 10.1007/978-3-319-10470-6_62
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nair V., 2010, PROC 27 INT C MACH L, P807
   Oda M., 2011, ORGAN SEGMENTATION 3, P181
   Okada T, 2015, MED IMAGE ANAL, V26, P1, DOI 10.1016/j.media.2015.06.009
   Oktay O, 2018, IEEE T MED IMAGING, V37, P384, DOI 10.1109/TMI.2017.2743464
   Pereyra G., 2017, REGULARIZING NEURAL
   Pleiss G., 2017, MEMORY EFFICIENT IMP
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Roth HR., 2017, HIERARCHICAL 3D FULL
   Roth HR, 2016, CANC IMAGING ARCH
   Saxena S., 2016, BJMCS, P1, DOI DOI 10.9734/BJMCS/2016/20812
   Shimizu A, 2007, INT J COMPUT ASS RAD, V2, P135, DOI 10.1007/s11548-007-0135-z
   Suzuki M, 2012, LECT NOTES COMPUT SC, V7512, P418, DOI 10.1007/978-3-642-33454-2_52
   Sykes J, 2014, J MED RADIAT SCI, V61, P131, DOI 10.1002/jmrs.65
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Tong T, 2015, MED IMAGE ANAL, V23, P92, DOI 10.1016/j.media.2015.04.015
   van Ginneken B, 2011, RADIOLOGY, V261, P719, DOI 10.1148/radiol.11091710
   Veit Andreas, 2016, ADV NEURAL INFORM PR, P550
   Wang HZ, 2013, IEEE T PATTERN ANAL, V35, P611, DOI 10.1109/TPAMI.2012.143
   Wang ZH, 2014, LECT NOTES COMPUT SC, V8673, P666, DOI 10.1007/978-3-319-10404-1_83
   Xu ZB, 2016, IEEE T BIO-MED ENG, V63, P1563, DOI 10.1109/TBME.2016.2574816
   Xu ZB, 2015, MED IMAGE ANAL, V24, P18, DOI 10.1016/j.media.2015.05.009
   Yu F., 2015, MULTISCALE CONTEXT A
   Zhou XR, 2016, LECT NOTES COMPUT SC, V10008, P111, DOI 10.1007/978-3-319-46976-8_12
   Zografos V., 2015, P INT MICCAI WORKSH, P37
NR 54
TC 305
Z9 317
U1 21
U2 137
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD AUG
PY 2018
VL 37
IS 8
BP 1822
EP 1834
DI 10.1109/TMI.2018.2806309
PG 13
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA GP4CW
UT WOS:000440805800008
PM 29994628
OA Green Published, Green Accepted
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Lin, JY
   Clancy, NT
   Qi, J
   Hu, Y
   Tatla, T
   Stoyanov, D
   Maier-Hein, L
   Elson, DS
AF Lin, Jianyu
   Clancy, Neil T.
   Qi, Ji
   Hu, Yang
   Tatla, Taran
   Stoyanov, Danail
   Maier-Hein, Lena
   Elson, Daniel S.
TI Dual-modality endoscopic probe for tissue surface shape reconstruction
   and hyperspectral imaging enabled by deep neural networks
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article; Proceedings Paper
CT 20th Conference on Medical Image Computing and Computer Assisted
   Intervention (MICCAI)
CY SEP 10-14, 2017
CL Quebec, CANADA
DE Intra-operative imaging; 3D reconstruction; Structured light;
   Hyperspectral imaging; Deep learning; Super-spectral-resolution
ID LAPAROSCOPIC SURGERY; AUGMENTED REALITY; SYSTEM; 3D; ILLUMINATION;
   OXYGENATION; SATURATION; ROBUST
AB Surgical guidance and decision making could be improved with accurate and real-time measurement of intra-operative data including shape and spectral information of the tissue surface. In this work, a dual modality endoscopic system has been proposed to enable tissue surface shape reconstruction and hyperspectral imaging (HSI). This system centers around a probe comprised of an incoherent fiber bundle, whose fiber arrangement is different at the two ends, and miniature imaging optics. For 3D reconstruction with structured light (SL), a light pattern formed of randomly distributed spots with different colors is projected onto the tissue surface, creating artificial texture. Pattern decoding with a Convolutional Neural Network (CNN) model and a customized feature descriptor enables real-time 3D surface reconstruction at approximately 12 frames per second (FPS). In HSI mode, spatially sparse hyperspectral signals from the tissue surface can be captured with a slit hyperspectral imager in a single snapshot. A CNN based super-resolution model, namely "super-spectral-resolution" network (SSRNet), has also been developed to estimate pixel-level dense hypercubes from the endoscope cameras standard RGB images and the sparse hyperspectral signals, at approximately 2 FPS. The probe, with a 2.1 mm diameter, enables the system to be used with endoscope working channels. Furthermore, since data acquisition in both modes can be accomplished in one snapshot, operation of this system in clinical applications is minimally affected by tissue surface movement and deformation. The whole apparatus has been validated on phantoms and tissue (ex vivo and in vivo), while initial measurements on patients during laryngeal surgery show its potential in real-world clinical applications. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Lin, Jianyu; Clancy, Neil T.; Qi, Ji; Hu, Yang; Elson, Daniel S.] Imperial Coll London, Hamlyn Ctr Robot Surg, London, England.
   [Lin, Jianyu; Hu, Yang] Imperial Coll London, Dept Comp, London, England.
   [Clancy, Neil T.; Stoyanov, Danail] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London, England.
   [Clancy, Neil T.; Stoyanov, Danail] UCL, Ctr Med Image Comp, London, England.
   [Clancy, Neil T.; Stoyanov, Danail] UCL, Dept Comp Sci, London, England.
   [Clancy, Neil T.; Qi, Ji; Elson, Daniel S.] UCL, Dept Surg & Canc, London, England.
   [Tatla, Taran] Northwick Pk Hosp & Clin Res Ctr, Dept Otolaryngol, Harrow, Middx, England.
   [Maier-Hein, Lena] German Canc Res Ctr, Div Med & Biol Informat, Heidelberg, Germany.
C3 Imperial College London; Imperial College London; UK Research &
   Innovation (UKRI); Engineering & Physical Sciences Research Council
   (EPSRC); University of London; University College London; University of
   London; University College London; University of London; University
   College London; University of London; University College London;
   Imperial College London; Helmholtz Association; German Cancer Research
   Center (DKFZ)
RP Lin, JY; Clancy, NT; Elson, DS (通讯作者)，Imperial Coll London, Hamlyn Ctr Robot Surg, London, England.; Lin, JY (通讯作者)，Imperial Coll London, Dept Comp, London, England.; Clancy, NT (通讯作者)，UCL, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London, England.; Clancy, NT (通讯作者)，UCL, Ctr Med Image Comp, London, England.; Clancy, NT (通讯作者)，UCL, Dept Comp Sci, London, England.; Clancy, NT; Elson, DS (通讯作者)，UCL, Dept Surg & Canc, London, England.
EM xjtuljy@gmail.com; n.clancy@ucl.ac.uk; daniel.elson@imperial.ac.uk
RI Stoyanov, Danail/V-1043-2019; Elson, Daniel/B-4921-2008
OI Stoyanov, Danail/0000-0002-0980-3227; Elson, Daniel/0000-0002-5578-3941;
   Clancy, Neil/0000-0002-7240-5790; Lin, Jianyu/0000-0003-2801-7616
FU ERC [242991]; Imperial College Confidence in Concept award; IGHI
   scholarship; MRC [MC_PC_13064] Funding Source: UKRI
FX This work was funded by ERC 242991 and an Imperial College Confidence in
   Concept award. Jianyu Lin was supported by IGHI scholarship. The authors
   gratefully acknowledge infrastructure support from the Cancer Research
   UK Imperial Centre, the Imperial Experimental Cancer Medicine Centre and
   the National Institute for Health Research Imperial Biomedical Research
   Centre.
CR Abadi Martin, 2016, arXiv
   Aiazzi B, 2006, ANN GEOPHYS-ITALY, V49, P1
   Arad B., 2016, SPARSE RECOVERY HYPE, P19
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernhardt S, 2017, MED IMAGE ANAL, V37, P66, DOI 10.1016/j.media.2017.01.007
   Boppart SA, 2004, BREAST CANCER RES TR, V84, P85, DOI 10.1023/B:BREA.0000018401.13609.54
   Chan MH, 2003, APPL OPTICS, V42, P1888, DOI 10.1364/AO.42.001888
   Clancy NT, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.10.106006
   Clancy NT, 2015, BIOMED OPT EXPRESS, V6, P4179, DOI 10.1364/BOE.6.004179
   Clancy NT, 2011, BIOMED OPT EXPRESS, V2, P3119, DOI 10.1364/BOE.2.003119
   Darzi A, 2002, BMJ-BRIT MED J, V324, P31, DOI 10.1136/bmj.324.7328.31
   Davies B, 2006, P IEEE, V94, P1696, DOI 10.1109/JPROC.2006.880680
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Du XF, 2015, INT J COMPUT ASS RAD, V10, P1915, DOI 10.1007/s11548-015-1243-9
   Edgcumbe P, 2015, MED IMAGE ANAL, V25, P95, DOI 10.1016/j.media.2015.04.008
   Ferris D G, 2001, J Low Genit Tract Dis, V5, P65, DOI 10.1046/j.1526-0976.2001.005002065.x
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Hasegawa K, 2002, INT C PATT RECOG, P792, DOI 10.1109/ICPR.2002.1044878
   He Kaiming, 2016, 2016 IEEE C COMPUTER
   Jia Y., 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Jones G, 2017, IEEE T MED IMAGING, V36, P1491, DOI 10.1109/TMI.2017.2665627
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]
   King DR, 2015, BURNS, V41, P1478, DOI 10.1016/j.burns.2015.05.009
   Kumashiro R, 2016, ANTICANCER RES, V36, P3925
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lin J., 2017, ENDOSCOPIC DEPTH MEA, P39
   Lin J., 2015, TISSUE SURFACE RECON, P405
   Lin JY, 2016, ACSR ADV COMPUT, V41, P414
   Lin JY, 2015, INT J COMPUT ASS RAD, V10, P1941, DOI 10.1007/s11548-015-1264-4
   Loncan L, 2015, IEEE GEOSC REM SEN M, V3, P27, DOI 10.1109/MGRS.2015.2440094
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901
   Luo HF, 2014, OPT LASER ENG, V57, P6, DOI 10.1016/j.optlaseng.2014.01.010
   Maier-Hein L, 2013, MED IMAGE ANAL, V17, P974, DOI 10.1016/j.media.2013.04.003
   Marcu L., 2014, FLUORESCENCE LIFETIM
   Masi G, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070594
   Matsuda T, 2017, NAT REV GASTRO HEPAT, V14, P305, DOI 10.1038/nrgastro.2017.18
   Maurice X, 2012, IEEE ENG MED BIO, P5769, DOI 10.1109/EMBC.2012.6347305
   Nagengast WB, 2019, GUT, V68, P7, DOI 10.1136/gutjnl-2017-314953
   Obuch Joshua C, 2015, Curr Treat Options Gastroenterol, V13, P156, DOI 10.1007/s11938-015-0046-y
   Oktay Ozan, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9902, P246, DOI 10.1007/978-3-319-46726-9_29
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Pratt P, 2012, J ROBOT SURG, V6, P23, DOI 10.1007/s11701-011-0334-z
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salvi J, 2010, PATTERN RECOGN, V43, P2666, DOI 10.1016/j.patcog.2010.03.004
   Schmalz C, 2012, MED IMAGE ANAL, V16, P1063, DOI 10.1016/j.media.2012.04.001
   Schroeder W., 2006, VISUALIZATION TOOLKI
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sommer C, 2011, I S BIOMED IMAGING, P230, DOI 10.1109/ISBI.2011.5872394
   Sorg BS, 2005, J BIOMED OPT, V10, DOI 10.1117/1.2003369
   Velanovich V, 2000, SURG ENDOSC-ULTRAS, V14, P16, DOI 10.1007/s004649900003
   Weitzel L, 1996, ASTRON ASTROPHYS SUP, V119, P531, DOI 10.1051/aas:1996266
   Wirkert S.J., 2017, MED IMAGE COMPUTING, P134, DOI DOI 10.1007/978-3-319-66179-716
   Wirkert SJ, 2016, INT J COMPUT ASS RAD, V11, P909, DOI 10.1007/s11548-016-1376-5
   Wolfe WL., 1997, INTRO IMAGING SPECTR, DOI 10.1117/3263530
   Wu TT, 2007, OPT EXPRESS, V15, P10421, DOI 10.1364/OE.15.010421
   Zhong JY, 2016, SENS IMAGING, V17, DOI 10.1007/s11220-016-0135-6
   Zuzak KJ, 2011, ANAL CHEM, V83, P7424, DOI 10.1021/ac201467v
NR 58
TC 31
Z9 33
U1 1
U2 43
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD AUG
PY 2018
VL 48
SI SI
BP 162
EP 176
DI 10.1016/j.media.2018.06.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA GQ9BA
UT WOS:000442059700012
PM 29933116
OA Green Published, Green Submitted
DA 2023-04-20
ER

PT J
AU Mahmood, F
   Durr, NJ
AF Mahmood, Faisal
   Durr, Nicholas J.
TI Deep learning and conditional random fields-based depth estimation and
   topographical reconstruction from conventional endoscopy
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Endoscopy; Colonoscopy; Deep learning; Conditional random fields;
   Monocular depth estimation; Learned depth
ID MISS RATE; CT COLONOGRAPHY; NEURAL-NETWORKS; COLONOSCOPY; LESIONS;
   CANCER; CLASSIFICATION; POLYPS; IMAGES; COLON
AB Colorectal cancer is the fourth leading cause of cancer deaths worldwide and the second leading cause in the United States. The risk of colorectal cancer can be mitigated by the identification and removal of premalignant lesions through optical colonoscopy. Unfortunately, conventional colonoscopy misses more than 20% of the polyps that should be removed, due in part to poor contrast of lesion topography. Imaging depth and tissue topography during a colonoscopy is difficult because of the size constraints of the endoscope and the deforming mucosa. Most existing methods make unrealistic assumptions which limits accuracy and sensitivity. In this paper, we present a method that avoids these restrictions, using a joint deep convolutional neural network-conditional random field (CNN-CRF) framework for monocular endoscopy depth estimation. Estimated depth is used to reconstruct the topography of the surface of the colon from a single image. We train the unary and pairwise potential functions of a CRF in a CNN on synthetic data, generated by developing an endoscope camera model and rendering over 200,000 images of an anatomically-realistic colon. We validate our approach with real endoscopy images from a porcine colon, transferred to a synthetic-like domain via adversarial training, with ground truth from registered computed tomography measurements. The CNN-CRF approach estimates depths with a relative error of 0.152 for synthetic endoscopy images and 0.242 for real endoscopy images. We show that the estimated depth maps can be used for reconstructing the topography of the mucosa from conventional colonoscopy images. This approach can easily be integrated into existing endoscopy systems and provides a foundation for improving computer-aided detection algorithms for detection, segmentation and classification of lesions. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Mahmood, Faisal; Durr, Nicholas J.] Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA.
C3 Johns Hopkins University
RP Mahmood, F (通讯作者)，Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA.
EM faisalm@jhu.edu; ndurr@jhu.edu
RI Durr, Nicholas/W-5517-2018; Mahmood, Faisal/C-1021-2015
OI Durr, Nicholas/0000-0001-9808-7383; Mahmood, Faisal/0000-0001-7587-1562
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   ALOIMONOS J, 1988, BIOL CYBERN, V58, P345, DOI 10.1007/BF00363944
   [Anonymous], ARXIV171106606
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cicek O., 2016, MEDICAL IMAGE COMPUT, P424
   Claridge E, 2014, IEEE T MED IMAGING, V33, P822, DOI 10.1109/TMI.2013.2290697
   Cohen L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P416, DOI 10.1109/CVPR.1989.37880
   de Groen Piet C, 2010, Gastrointest Endosc Clin N Am, V20, P699, DOI 10.1016/j.giec.2010.07.012
   Dimas G, 2017, COMPUT BIOL MED, V89, P429, DOI 10.1016/j.compbiomed.2017.08.029
   Dimas G, 2017, MEAS SCI TECHNOL, V28, DOI 10.1088/1361-6501/aa7ebf
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Durr N. J., 2014, US Patent App, Patent No. [14/758,755, 14758755]
   Durr N.J., 2014, SPIE BIOS
   Durr N. J., 2014, 3D IMAGING TECHNIQUE
   Eigen D., 2014, ADV NEUR IN, V2, P2366, DOI DOI 10.5555/2969033.2969091
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Fedorov A, 2012, MAGN RESON IMAGING, V30, P1323, DOI 10.1016/j.mri.2012.05.001
   Fidler JL, 2002, ABDOM IMAGING, V27, P292, DOI 10.1007/s00261-001-0171-z
   Gonzalez G, 2014, LECT NOTES COMPUT SC, V8673, P642, DOI 10.1007/978-3-319-10404-1_80
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Hess R., 2007, ESSENTIAL BLENDER GU
   Holden M.S., 2017, INT J COMPUT ASSIST, P1
   Hong DH, 2014, COMPUT MED IMAG GRAP, V38, P22, DOI 10.1016/j.compmedimag.2013.10.005
   Hounnou G, 2002, SURG RADIOL ANAT, V24, P290, DOI 10.1007/s00276-002-0057-y
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Kak A.C., 2001, PRINCIPLES COMPUTERI, DOI [10.1137/1.9780898719277, DOI 10.1137/1.9780898719277]
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kang B., 2017, ARXIV170801818
   Karargyris A, 2011, IEEE T MED IMAGING, V30, P957, DOI 10.1109/TMI.2010.2098882
   Kim DH, 2007, NEW ENGL J MED, V357, P1403, DOI 10.1056/NEJMoa070543
   Kwak S, 2017, AAAI CONF ARTIF INTE, P4111
   Le Clercq C.M., 2013, GUT GUTJNL
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu YQ, 2013, IEEE T IMAGE PROCESS, V22, P1699, DOI 10.1109/TIP.2012.2218828
   Lobay A, 2006, INT J COMPUT VISION, V67, P71, DOI 10.1007/s11263-006-4068-8
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maier-Hein L, 2013, MED IMAGE ANAL, V17, P974, DOI 10.1016/j.media.2013.04.003
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Michels J., 2005, P 22 INT C MACHINE L, P593, DOI DOI 10.1145/1102351.1102426
   Mitchell D. P., 1988, Computer Graphics, V22, P221, DOI 10.1145/378456.378514
   Mylonaki M, 2003, GUT, V52, P1122, DOI 10.1136/gut.52.8.1122
   Nadeem S., 2016, COMPUTER AIDED DETEC, DOI 10.1117/12.2216996
   Nain D, 2001, WORKSHOP INTERACTIVE
   Noh W., 1976, LECTURE NOTES PHYSIC, P330, DOI DOI 10.1007/3-540-08004-X_336
   Pabby A, 2005, GASTROINTEST ENDOSC, V61, P385, DOI 10.1016/S0016-5107(04)02765-8
   Parot V, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.7.076017
   Pereira F. C. N, 2001, CONDITIONAL RANDOM F, DOI DOI 10.1038/NPROT.2006.61
   Peyre G, 2008, LECT NOTES COMPUT SC, V5304, P57, DOI 10.1007/978-3-540-88690-7_5
   Pickhardt PJ, 2003, AM J ROENTGENOL, V181, P799, DOI 10.2214/ajr.181.3.1810799
   Pickhardt PJ, 2004, AM J ROENTGENOL, V183, P1343, DOI 10.2214/ajr.183.5.1831343
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Pohl J, 2011, GUT, V60, P485, DOI 10.1136/gut.2010.229534
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Qin Tao, 2009, ADV NEURAL INFORM PR, P1281
   Radosavljevic V, 2010, FRONT ARTIF INTEL AP, V215, P809, DOI 10.3233/978-1-60750-606-5-809
   Ranftl R, 2016, PROC CVPR IEEE, P4058, DOI 10.1109/CVPR.2016.440
   Ransohoff DF, 2009, ANN INTERN MED, V150, P50, DOI 10.7326/0003-4819-150-1-200901060-00308
   Ravishankar H, 2016, LECT NOTES COMPUT SC, V10008, P188, DOI 10.1007/978-3-319-46976-8_20
   Reiter A, 2016, PROC SPIE, V9784, DOI 10.1117/12.2216296
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Ryer A., 1997, LIGHT MEASUREMENT HD
   Saxena A., 2006, ADV NEURAL INFORM PR, V18, P1161, DOI DOI 10.1109/TPAMI.2015.2505283A
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Schmalz C, 2012, MED IMAGE ANAL, V16, P1063, DOI 10.1016/j.media.2012.04.001
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI 10.3322/caac.21395
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Soetikno RM, 2008, JAMA-J AM MED ASSOC, V299, P1027, DOI 10.1001/jama.299.9.1027
   Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174
   Styner M., 1997, EVALUATION 2D 3D BIA, V179
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Visentini-Scarzanella M., 2017, INT J COMPUTER ASSIS, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Xu D., 2018, ARXIV180300891
   Xu D., 2017, ARXIV170402157
   Yap M.H., 2017, IEEE J BIOMED HLTH I
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
NR 95
TC 72
Z9 75
U1 5
U2 52
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD AUG
PY 2018
VL 48
SI SI
BP 230
EP 243
DI 10.1016/j.media.2018.06.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA GQ9BA
UT WOS:000442059700017
PM 29990688
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Al Hajj, H
   Lamard, M
   Conze, PH
   Cochener, B
   Quellec, G
AF Al Hajj, Hassan
   Lamard, Mathieu
   Conze, Pierre-Henri
   Cochener, Beatrice
   Quellec, Gwenole
TI Monitoring tool usage in surgery videos using boosted convolutional and
   recurrent neural networks
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Cataract and cholecystectomy surgeries; Tool usage monitoring; Video
   analysis; Convolutional and recurrent neural networks; Boosting
ID REAL-TIME SEGMENTATION; CATARACT-SURGERY; RECOGNITION; CLASSIFICATION;
   TASKS
AB This paper investigates the automatic monitoring of tool usage during a surgery, with potential applications in report generation, surgical training and real-time decision support. Two surgeries are considered: cataract surgery, the most common surgical procedure, and cholecystectomy, one of the most common digestive surgeries. Tool usage is monitored in videos recorded either through a microscope (cataract surgery) or an endoscope (cholecystectomy). Following state-of-the-art video analysis solutions, each frame of the video is analyzed by convolutional neural networks (CNNs) whose outputs are fed to recurrent neural networks (RNNs) in order to take temporal relationships between events into account. Novelty lies in the way those CNNs and RNNs are trained. Computational complexity prevents the endto-end training of "CNN+RNN" systems. Therefore, CNNs are usually trained first, independently from the RNNs. This approach is clearly suboptimal for surgical tool analysis: many tools are very similar to one another, but they can generally be differentiated based on past events. CNNs should be trained to extract the most useful visual features in combination with the temporal context. A novel boosting strategy is proposed to achieve this goal: the CNN and RNN parts of the system are simultaneously enriched by progressively adding weak classifiers (either CNNs or RNNs) trained to improve the overall classification accuracy. Experiments were performed in a dataset of 50 cataract surgery videos, where the usage of 21 surgical tools was manually annotated, and a dataset of 80 cholecystectomy videos, where the usage of 7 tools was manually annotated. Very good classification performance are achieved in both datasets: tool usage could be labeled with an average area under the ROC curve of A(z) = 0.9961 and A(z) = 0.9939, respectively, in offline mode (using past, present and future information), and A(z) = 0.9957 and A(z) = 0.9936, respectively, in online mode (using past and present information only). (C) 2018 Elsevier B.V. All rights reserved.
C1 [Al Hajj, Hassan; Lamard, Mathieu; Conze, Pierre-Henri; Cochener, Beatrice; Quellec, Gwenole] INSERM, UMR 1101, F-29200 Brest, France.
   [Lamard, Mathieu; Cochener, Beatrice] Univ Bretagne Occidentale, F-29200 Brest, France.
   [Conze, Pierre-Henri] Inst Mines Telecom Atlantique, F-29200 Brest, France.
   [Cochener, Beatrice] CHRU Brest, Serv Ophtalmol, F-29200 Brest, France.
C3 Institut National de la Sante et de la Recherche Medicale (Inserm);
   Universite de Bretagne Occidentale; Universite de Bretagne Occidentale;
   IMT - Institut Mines-Telecom; IMT Atlantique; CHU Brest; Universite de
   Bretagne Occidentale
RP Quellec, G (通讯作者)，CHRU Morvan, LaTIM, IBRBS, 12 Av Foch, F-29609 Brest, France.
EM gwenole.quellec@inserm.fr
RI Quellec, Gwenole/L-9946-2015; Conze, Pierre-Henri/AAE-9248-2020
OI Quellec, Gwenole/0000-0003-1669-7140; Conze,
   Pierre-Henri/0000-0003-2214-3654
CR Al Hajj H., 2017, P IEEE EMBC
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Bouget D, 2017, MED IMAGE ANAL, V35, P633, DOI 10.1016/j.media.2016.09.003
   Cadene R., 2016, ARXIV161005541CS
   Charriere K, 2017, MULTIMED TOOLS APPL, V76, P22473, DOI 10.1007/s11042-017-4793-8
   Chen HF, 2017, CHINA COMMUN, V14, P163, DOI 10.1109/CC.2017.7868164
   Cho K., 2014, PROC WORKSHOP SYNTAX, DOI [10.3115/v1/W14-40, 10.3115/v1/w14-4012]
   Dergachyova O, 2016, INT J COMPUT ASS RAD, V11, P1081, DOI 10.1007/s11548-016-1371-x
   DiPietro Robert, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P551, DOI 10.1007/978-3-319-46720-7_64
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Feng Y, 2016, INT C PATT RECOG, P325, DOI 10.1109/ICPR.2016.7899654
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gammulle H, 2017, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2017.27
   Gao YZ, 2016, IEEE IJCNN, P1333, DOI 10.1109/IJCNN.2016.7727352
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu X., 2017, TECHNICAL REPORT
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jin Y., 2016, TECHNICAL REPORT, P1649, DOI [10.1109/1CRA.2016.7487305, DOI 10.1109/1CRA.2016.7487305]
   Khorrami P, 2016, IEEE IMAGE PROC, P619, DOI 10.1109/ICIP.2016.7532431
   Lalys F, 2014, INT J COMPUT ASS RAD, V9, P495, DOI 10.1007/s11548-013-0940-5
   Lea C, 2016, LECT NOTES COMPUT SC, V9915, P47, DOI 10.1007/978-3-319-49409-8_7
   Lea C, 2016, IEEE INT CONF ROBOT, P1642, DOI 10.1109/ICRA.2016.7487305
   MarKalkaite G., 2017, TECHNICAL REPORT
   Mason L, 2000, ADV NEUR IN, V12, P512
   Mietkowski P., 2017, ARXIV170203684CS
   Mishra K, 2017, IEEE COMPUT SOC CONF, P2233, DOI 10.1109/CVPRW.2017.277
   Moghimi M., 2016, P BMVC
   Primus MJ, 2018, LECT NOTES COMPUT SC, V10704, P241, DOI 10.1007/978-3-319-73603-7_20
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Quellec G, 2015, IEEE T MED IMAGING, V34, P877, DOI 10.1109/TMI.2014.2366726
   Quellec G, 2014, IEEE T MED IMAGING, V33, P2352, DOI 10.1109/TMI.2014.2340473
   Raju A, 2016, TECHNICAL REPORT
   Roychowdhury S., 2017, TECHNICAL REPORT
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sahu M., 2016, ARXIV161008854CSCV
   Sahu M, 2017, INT J COMPUT ASS RAD, V12, P1013, DOI 10.1007/s11548-017-1565-x
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Simonyan K., 2014, ICLR WORKSH CALG CAN
   Simonyan K, 2015, Arxiv
   Simonyan Karen, 2014, ADV NEURAL INFORM PR, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tao LL, 2013, LECT NOTES COMPUT SC, V8151, P339, DOI 10.1007/978-3-642-40760-4_43
   Tran DT, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/1985796
   Trikha S, 2013, EYE, V27, P461, DOI 10.1038/eye.2012.293
   Twinanda A. P., 2016, ARXIV161008844CS
   Twinanda AP, 2017, IEEE T MED IMAGING, V36, P86, DOI 10.1109/TMI.2016.2593957
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Zappella L, 2013, MED IMAGE ANAL, V17, P732, DOI 10.1016/j.media.2013.04.007
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P1793, DOI 10.1109/TGRS.2015.2488681
   Zia A., 2016, TECHNICAL REPORT
   Zoph Barret, 2017, ARXIV170707012CSSTAT
NR 60
TC 44
Z9 44
U1 1
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD JUL
PY 2018
VL 47
BP 203
EP 218
DI 10.1016/j.media.2018.05.001
PG 16
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA GL7OB
UT WOS:000437390100015
PM 29778931
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Hirasawa, T
   Aoyama, K
   Tanimoto, T
   Ishihara, S
   Shichijo, S
   Ozawa, T
   Ohnishi, T
   Fujishiro, M
   Matsuo, K
   Fujisaki, J
   Tada, T
AF Hirasawa, Toshiaki
   Aoyama, Kazuharu
   Tanimoto, Tetsuya
   Ishihara, Soichiro
   Shichijo, Satoki
   Ozawa, Tsuyoshi
   Ohnishi, Tatsuya
   Fujishiro, Mitsuhiro
   Matsuo, Keigo
   Fujisaki, Junko
   Tada, Tomohiro
TI Application of artificial intelligence using a convolutional neural
   network for detecting gastric cancer in endoscopic images
SO GASTRIC CANCER
LA English
DT Article
DE Stomach neoplasms; Neural networks (computer); Artificial intelligence;
   Endoscopy
ID SUBMUCOSAL DISSECTION; DIAGNOSIS; GASTROSCOPY; ACCURACY; OUTCOMES
AB Background Image recognition using artificial intelligence with deep learning through convolutional neural networks (CNNs) has dramatically improved and been increasingly applied to medical fields for diagnostic imaging. We developed a CNN that can automatically detect gastric cancer in endoscopic images.
   Methods A CNN-based diagnostic system was constructed based on Single Shot MultiBox Detector architecture and trained using 13,584 endoscopic images of gastric cancer. To evaluate the diagnostic accuracy, an independent test set of 2296 stomach images collected from 69 consecutive patients with 77 gastric cancer lesions was applied to the constructed CNN.
   Results The CNN required 47 s to analyze 2296 test images. The CNN correctly diagnosed 71 of 77 gastric cancer lesions with an overall sensitivity of 92.2%, and 161 non-cancerous lesions were detected as gastric cancer, resulting in a positive predictive value of 30.6%. Seventy of the 71 lesions 98.6%) with a diameter of 6 mm or more as well as all invasive cancers were correctly detected. All missed lesions were superficially depressed and differentiated-type intramucosal cancers that were difficult to distinguish from gastritis even for experienced endoscopists. Nearly half of the false-positive lesions were gastritis with changes in color tone or an irregular mucosal surface.
   Conclusion The constructed CNN system for detecting gastric cancer could process numerous stored endoscopic images in a very short time with a clinically relevant diagnostic ability. It may be well applicable to daily clinical practice to reduce the burden of endoscopists.
C1 [Hirasawa, Toshiaki; Fujisaki, Junko] Japanese Fdn Canc Res, Canc Inst Hosp Ariake, Dept Gastroenterol, Koto Ku, 3-10-6 Ariake, Tokyo 1358550, Japan.
   [Hirasawa, Toshiaki; Ishihara, Soichiro; Ozawa, Tsuyoshi; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
   [Aoyama, Kazuharu; Tada, Tomohiro] AI Med Serv Inc, Tokyo, Japan.
   [Tanimoto, Tetsuya] Med Governance Res Inst, Tokyo, Japan.
   [Tanimoto, Tetsuya] Navitas Clin, Tokyo, Japan.
   [Ishihara, Soichiro; Ozawa, Tsuyoshi] Int Univ Hlth & Welf, Sanno Hosp, Surg Dept, Tokyo, Japan.
   [Shichijo, Satoki] Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Osaka, Japan.
   [Ohnishi, Tatsuya] Lalaport Yokohama Clin, Kanagawa, Japan.
   [Fujishiro, Mitsuhiro] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Matsuo, Keigo] Tokatsu Tsujinaka Hosp, Dept Coloproctol, Chiba, Japan.
   [Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
C3 Japanese Foundation for Cancer Research; International University of
   Health & Welfare; University of Tokyo; University of Tokyo
RP Hirasawa, T (通讯作者)，Japanese Fdn Canc Res, Canc Inst Hosp Ariake, Dept Gastroenterol, Koto Ku, 3-10-6 Ariake, Tokyo 1358550, Japan.; Hirasawa, T (通讯作者)，Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
EM toshiaki.hirasawa@jfcr.or.jp
RI 藤城, 光弘/AAN-3131-2020; Ishihara, Soichiro/AFK-1375-2022
OI Fujishiro, Mitsuhiro/0000-0002-4074-1140; Hirasawa,
   Toshiaki/0000-0002-6450-1934
CR Ahn JY, 2013, CLIN ENDOSC, V46, P463, DOI 10.5946/ce.2013.46.5.463
   Amin A, 2002, J ROY COLL SURG EDIN, V47, P681
   Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   Choi MK, 2013, SURG ENDOSC, V27, P4250, DOI 10.1007/s00464-013-3030-4
   Crew KD, 2006, WORLD J GASTROENTERO, V12, P354, DOI 10.3748/wjg.v12.i3.354
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   FUJITA S, 1978, PATHOL RES PRACT, V163, P297, DOI 10.1016/S0344-0338(78)80028-4
   Gotoda T, 2010, BRIT J SURG, V97, P868, DOI 10.1002/bjs.7033
   Gotoda T, 2016, DIGEST ENDOSC, V28, P2, DOI 10.1111/den.12623
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hosokawa O, 1998, ENDOSCOPY, V30, P669, DOI 10.1055/s-2007-1001386
   Hosokawa O, 2007, HEPATO-GASTROENTEROL, V54, P442
   Isomoto H, 2009, GUT, V58, P331, DOI 10.1136/gut.2008.165381
   ITOH H, 1989, AM J SURG, V158, P14, DOI 10.1016/0002-9610(89)90305-X
   Japanese Gastric Canc Assoc, 2011, GASTRIC CANCER, V14, P101, DOI 10.1007/s10120-011-0041-5
   Jeon HK, 2018, GASTRIC CANCER, V21, P133, DOI 10.1007/s10120-017-0719-4
   Katai H, 2018, GASTRIC CANCER, V21, P144, DOI 10.1007/s10120-017-0716-7
   Kimura K, 1969, ENDOSCOPY, V1, P87, DOI [10.1055/s-0028-1098086, DOI 10.1055/S-0028-1098086]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Sano T, 2017, GASTRIC CANCER, V20, P217, DOI 10.1007/s10120-016-0601-9
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tsubono Yoshitaka, 2000, Gastric Cancer, V3, P9, DOI 10.1007/PL00011692
   Voutilainen ME, 2005, EUR J GASTROEN HEPAT, V17, P1345, DOI 10.1097/00042737-200512000-00013
   Yalamarthi S, 2004, ENDOSCOPY, V36, P874, DOI 10.1055/s-2004-825853
   Yamazato T, 2012, INTERNAL MED, V51, P1461, DOI 10.2169/internalmedicine.51.7414
   Yao K, 2014, GASTRIC CANCER, V17, P669, DOI 10.1007/s10120-013-0332-0
   Yeoh KG, 2007, J GASTROEN HEPATOL, V22, P970, DOI 10.1111/j.1440-1746.2007.04956.x
   Yoshida H, 2018, GASTRIC CANCER, V21, P249, DOI 10.1007/s10120-017-0731-8
   YOSHIDA S, 1984, JPN J CLIN ONCOL, V14, P225
   Yoshimizu S, 2018, DIGEST ENDOSC, V30, P71, DOI 10.1111/den.12916
   Zhang Q, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000000384
NR 34
TC 355
Z9 385
U1 32
U2 143
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1436-3291
EI 1436-3305
J9 GASTRIC CANCER
JI Gastric Cancer
PD JUL
PY 2018
VL 21
IS 4
BP 653
EP 660
DI 10.1007/s10120-018-0793-2
PG 8
WC Oncology; Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology; Gastroenterology & Hepatology
GA GJ4ZP
UT WOS:000435391300008
PM 29335825
OA Bronze
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Kacmaz, RN
   Yilmaz, B
   Dundar, MS
   Dogan, S
AF Kacmaz, Rukiye Nur
   Yilmaz, Bulent
   Dundar, Mehmet Sait
   Dogan, Serkan
TI Motion artifact detection in colonoscopy images
SO EUROBIOTECH JOURNAL
LA English
DT Article
DE Image processing; motion-artifact; colonoscopy
AB Computer-aided detection is an integral part of medical image evaluation process because examination of each image takes a long time and generally experts' do not have enough time for the elimination of images with motion artifact (blurred images). Computer-aided detection is required for both increasing accuracy rate and saving experts' time. Large intestine does not have straight structure thus camera of the colonoscopy should be moved continuously to examine inside of the large intestine and this movement causes motion artifact on colonoscopy images. In this study, images were selected from open-source colonoscopy videos and obtained at Kayseri Training and Research Hospital. Totally 100 images were analyzed half of which were clear. Firstly, a modified version of histogram equalization was applied in the pre-processing step to all images in our dataset, and then, used Laplacian, wavelet transform (WT), and discrete cosine transform-based (DCT) approaches to extract features for the discrimination of images with no artifact (clear) and images with motion artifact. The Laplacian-based feature extraction method was used for the first time in the literature on colonoscopy images. The comparison between Laplacian-based features and previously used methods such as WT and DCT has been performed. In the classification phase of our study, support vector machines (SVM), linear discriminant analysis (LDA), and k nearest neighbors (k-NN) were used as the classifiers. The results showed that Laplacian-based features were more successful in the detection of images with motion artifact when compared to popular methods used in the literature. As a result, a combination of features extracted using already existing approaches (WT and DCT) and the Laplacian-based methods reached 85% accuracy levels with SVM classification approach.
C1 [Kacmaz, Rukiye Nur; Yilmaz, Bulent; Dundar, Mehmet Sait] Abdullah Gul Univ, Grad Sch Engn & Nat Sci, Dept Elect & Comp Engn, Kayseri, Turkey.
   [Yilmaz, Bulent] Abdullah Gul Univ, Sch Engn, Dept Elect Elect Engn, Kayseri, Turkey.
   [Yilmaz, Bulent] Abdullah Gul Univ, Grad Sch Engn & Nat Sci, Dept Bioengn, Kayseri, Turkey.
   [Kacmaz, Rukiye Nur; Yilmaz, Bulent; Dundar, Mehmet Sait] Abdullah Gul Univ, Sch Engn, Biomed Instrumentat & Signal Anal Lab BISA, Kayseri, Turkey.
   [Dogan, Serkan] Training & Res Hosp, Gastroenterol Clin, Kayseri, Turkey.
C3 Abdullah Gul University; Abdullah Gul University; Abdullah Gul
   University; Abdullah Gul University; Kayseri Training & Research
   Hospital
RP Kacmaz, RN (通讯作者)，Abdullah Gul Univ, Grad Sch Engn & Nat Sci, Dept Elect & Comp Engn, Kayseri, Turkey.; Kacmaz, RN (通讯作者)，Abdullah Gul Univ, Sch Engn, Biomed Instrumentat & Signal Anal Lab BISA, Kayseri, Turkey.
EM rukiyenurkacmaz@gmail.com
RI Dundar, M. Sait/H-4318-2016
OI Dundar, M. Sait/0000-0002-0336-4825
FU Turkish Higher Education Council's 100/2000 Program
FX The authors, RNK and MSD, are supported by the Turkish Higher Education
   Council's 100/2000 Program with a monthly stipend.
CR Al-qinani IH, 2017, INT RES J ENG TECHNO, V4, P2354
   Arnold M, 2009, 2009 13TH INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, P47, DOI 10.1109/IMVIP.2009.16
   Entezari-Maleki R., 2009, J CONVERGENCE INF TE, V4, P94, DOI 10.4156/JCIT.VOL4.ISSUE3.14
   Jain A, P 2011 4 INT C INT N, P73
   Kovacs L, 2007, IEEE T PATTERN ANAL, V29, P1080, DOI 10.1109/TPAMI.2007.1079
   Kurt B., 2010, 7 UL TIP BIL K 14 17, P67
   Marichal X., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P386, DOI 10.1109/ICIP.1999.822923
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Mohammad S, 2015, PEERJ PREPRINTS, V3, P872
   NILL NB, 1992, OPT ENG, V31, P813, DOI 10.1117/12.56114
   Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Tong HH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P17, DOI 10.1109/ICME.2004.1394114
   van Dongen NC, 2016, I S BIOMED IMAGING, P119, DOI 10.1109/ISBI.2016.7493225
NR 14
TC 1
Z9 1
U1 0
U2 2
PU SCIENDO
PI WARSAW
PA DE GRUYTER POLAND SP Z O O, BOGUMILA ZUGA 32A STR, 01-811 WARSAW, POLAND
EI 2564-615X
J9 EUROBIOTECH J
JI EuroBiotech J.
PD JUL
PY 2018
VL 2
IS 3
BP 171
EP 175
DI 10.2478/ebtj-2018-0022
PG 5
WC Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Science & Technology - Other Topics
GA HY2UP
UT WOS:000467978800005
OA gold
DA 2023-04-20
ER

PT J
AU van der Sommen, F
   Klomp, SR
   Swager, AF
   Zinger, S
   Curvers, WL
   Bergman, JJGHM
   Schoon, EJ
   de With, PHN
AF van der Sommen, Fons
   Klomp, Sander R.
   Swager, Anne-Fre
   Zinger, Svitlana
   Curvers, Wouter L.
   Bergman, Jacques J. G. H. M.
   Schoon, Erik J.
   de With, Peter H. N.
TI Predictive features for early cancer detection in Barrett's esophagus
   using Volumetric Laser Endomicroscopy
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Article
DE Computer-aided detection and diagnosis; Endoscopy; Esophageal
   adenocarcinoma; Optical Coherence Tomography; Barrett's Esophagus
ID OPTICAL COHERENCE TOMOGRAPHY; ENDOSCOPIC RESECTION; NEOPLASIA; RISK;
   CLASSIFICATION; SURVEILLANCE; DYSPLASIA; EXPERTS; MODEL
AB The incidence of Barrett cancer is increasing rapidly and current screening protocols often miss the disease at an early, treatable stage. Volumetric Laser Endomicroscopy (VLE) is a promising new tool for finding this type of cancer early, capturing a full circumferential scan of Barrett's Esophagus (BE), up to 3-mm depth. However, the interpretation of these VLE scans can be complicated, due to the large amount of cross-sectional images and the subtle grayscale variations. Therefore, algorithms for automated analysis of VLE data can offer a valuable contribution to its overall interpretation. In this study, we broadly investigate the potential of Computer-Aided Detection (CADe) for the identification of early Barrett's cancer using VLE. We employ a histopathologically validated set of ex-vivo VLE images for evaluating and comparing a considerable set of widely-used image features and machine learning algorithms. In addition, we show that incorporating clinical knowledge in feature design, leads to a superior classification performance and additional benefits, such as low complexity and fast computation time. Furthermore, we identify an optimal tissue depth for classification of 0.5-1.0 mm, and propose an extension to the evaluated features that exploits this phenomenon, improving their predictive properties for cancer detection in VLE data. Finally, we compare the performance of the CADe methods with the classification accuracy of two VLE experts. With a maximum Area Under the Curve (AUC) in the range of 0.90-0.93 for the evaluated features and machine learning methods versus an AUC of 0.81 for the medical experts, our experiments show that computer-aided methods can achieve a considerably better performance than trained human observers in the analysis of VLE data.
C1 [van der Sommen, Fons; Klomp, Sander R.; Zinger, Svitlana; de With, Peter H. N.] Eindhoven Univ Technol, Dept Elect Engn, POB 513, NL-5600 MB Eindhoven, Netherlands.
   [van der Sommen, Fons; Swager, Anne-Fre; Curvers, Wouter L.; Bergman, Jacques J. G. H. M.] Acad Med Ctr, Dept Gastroenterol, Postbus 22660, NL-1100 DD Amsterdam, Netherlands.
   [Curvers, Wouter L.; Schoon, Erik J.] Catharina Hosp, Dept Gastroenterol & Hepathol, POB 1350, NL-5602 ZA Eindhoven, Netherlands.
C3 Eindhoven University of Technology; University of Amsterdam; Academic
   Medical Center Amsterdam; Catharina Hospital
RP van der Sommen, F (通讯作者)，Eindhoven Univ Technol, Dept Elect Engn, POB 513, NL-5600 MB Eindhoven, Netherlands.
EM F.v.d.Sommen@tue.nl; S.R.Klomp@student.tue.nl; A.Swager@amc.uva.nl;
   S.Zinger@tue.nl; Wouter.Curvers@catharinaziekenhuis.nl;
   support@elsevier.com; Erik.Schoon@catharinaziekenhuis.nl;
   P.H.N.de.With@tue.nl
RI Bergman, Jacques/AAS-2500-2021
OI Klomp, Sander/0000-0002-0874-4720; van der Sommen,
   Fons/0000-0002-3593-2356; Bergman, Jacques/0000-0001-7548-6955
FU NinePoint Medical (NinePoint Medical Inc., Bedford, MA, USA)
FX The authors gratefully acknowledge the support from NinePoint Medical
   (NinePoint Medical Inc., Bedford, MA, USA), who granted us the
   permission to use the VLE scans for this work.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cook MB, 2012, GASTROENTEROLOGY, V142, P744, DOI 10.1053/j.gastro.2011.12.049
   Corley DA, 2013, GASTROENTEROLOGY, V145, P312, DOI 10.1053/j.gastro.2013.05.004
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dalai N., 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ell C, 2007, GASTROINTEST ENDOSC, V65, P3, DOI 10.1016/j.gie.2006.04.033
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gonzalo N, 2010, REV ESP CARDIOL, V63, P893, DOI 10.1016/S0300-8932(10)70201-3
   Gora MJ, 2013, NAT MED, V19, P238, DOI 10.1038/nm.3052
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hayeck TJ, 2010, DIS ESOPHAGUS, V23, P451, DOI 10.1111/j.1442-2050.2010.01054.x
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Orlando JI, 2017, PROC SPIE, V10160, DOI 10.1117/12.2255740
   Jannin P, 2006, INT J COMPUT ASS RAD, V1, P63, DOI 10.1007/s11548-006-0044-6
   Klomp S.R, 2017, P SPIE, V10134
   Lagergren J, 2011, NAT REV GASTRO HEPAT, V8, P340, DOI 10.1038/nrgastro.2011.73
   Odze RD, 2006, J CLIN PATHOL, V59, P1029, DOI 10.1136/jcp.2005.035337
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Peters FP, 2008, DIS ESOPHAGUS, V21, P475, DOI 10.1111/j.1442-2050.2008.00813.x
   Qi X, 2010, BIOMED OPT EXPRESS, V1, P825, DOI 10.1364/BOE.1.000825
   Reid BJ, 2000, AM J GASTROENTEROL, V95, P3089, DOI 10.1111/j.1572-0241.2000.03182.x
   Rodriguez-Diaz E, 2015, GASTROENTEROLOGY, V148, pS91
   Rollins AM, 1999, OPT LETT, V24, P1358, DOI 10.1364/OL.24.001358
   Rollins AM, 1998, OPT EXPRESS, V3, P219, DOI 10.1364/OE.3.000219
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Shaheen NJ, 2009, LANCET, V373, P850, DOI 10.1016/S0140-6736(09)60487-6
   Solaymani-Dodaran M, 2004, GUT, V53, P1070, DOI 10.1136/gut.2003.028076
   Swager A, 2016, DIS ESOPHAGUS, V29, P505, DOI 10.1111/dote.12371
   Swager A, 2016, GASTROINTEST ENDOSC
   Swager AF, 2016, GASTROINTEST ENDOSC, V83, pAB573, DOI 10.1016/j.gie.2016.03.1180
   Swager AF, 2016, GASTROENTEROLOGY, V150, pS628, DOI 10.1016/S0016-5085(16)32158-8
   Ughi G. J., 2016, BIOMED OPT EXPRESS, V7, P660
   van Soest EM, 2005, GUT, V54, P1062, DOI 10.1136/gut.2004.063685
   Wolfsen HC, 2015, GASTROINTEST ENDOSC, V3, P1
NR 39
TC 15
Z9 16
U1 0
U2 6
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD JUL
PY 2018
VL 67
BP 9
EP 20
DI 10.1016/j.compmedimag.2018.02.007
PG 12
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA GW9WV
UT WOS:000447358800002
PM 29684663
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Wimmer, G
   Vecsei, A
   Hafner, M
   Uhl, A
AF Wimmer, Georg
   Vecsei, Andreas
   Haefner, Michael
   Uhl, Andreas
TI Fisher encoding of convolutional neural network features for endoscopic
   image classification
SO JOURNAL OF MEDICAL IMAGING
LA English
DT Article
DE colonic polyps; celiac disease; convolutional neural networks; Fisher
   encoding; endoscopy
ID CELIAC-DISEASE
AB We propose an approach for the automated diagnosis of celiac disease (CD) and colonic polyps (CP) based on applying Fisher encoding to the activations of convolutional layers. In our experiments, three different convolutional neural network (CNN) architectures (AlexNet, VGG-f, and VGG-16) are applied to three endoscopic image databases (one CD database and two CP databases). For each network architecture, we perform experiments using a version of the net that is pretrained on the ImageNet database, as well as a version of the net that is trained on a specific endoscopic image database. The Fisher representations of convolutional layer activations are classified using support vector machines. Additionally, experiments are performed by concatenating the Fisher representations of several layers to combine the information of these layers. We will show that our proposed CNN-Fisher approach clearly outperforms other CNN- and non-CNN-based approaches and that our approach requires no training on the target dataset, which results in substantial time savings compared with other CNN-based approaches. (C) The Authors. Published by SPIE under a Creative Commons Attribution 3.0 Unported License.
C1 [Wimmer, Georg; Uhl, Andreas] Univ Salzburg, Dept Comp Sci, Salzburg, Austria.
   [Vecsei, Andreas] St Anna Childrens Hosp, Vienna, Austria.
   [Haefner, Michael] St Elizabeth Hosp, Vienna, Austria.
C3 Salzburg University; Saint Anna Children's Hospital
RP Wimmer, G (通讯作者)，Univ Salzburg, Dept Comp Sci, Salzburg, Austria.
EM gwimmer@cosy.sbg.ac.at
FU Austrian Science Fund (FWF), KLI Project [429]
FX This work was supported by the Austrian Science Fund (FWF), KLI Project
   429.
CR [Anonymous], 2010, P 13 INT C ARTIFICIA
   Biagi F, 2010, NAT REV GASTRO HEPAT, V7, P158, DOI 10.1038/nrgastro.2010.2
   Chatfield K., 2014, ABS14053531 CORR
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fasano A, 2003, ARCH INTERN MED, V163, P286, DOI 10.1001/archinte.163.3.286
   Gadermayr M, 2016, I S BIOMED IMAGING, P355, DOI 10.1109/ISBI.2016.7493282
   Gadermayr Michael, 2014, Medical Computer Vision Large Data in Medical Imaging. Third International MICCAI Workshop, MCV 2013. Revised Selected Papers. LNCS: 8331, P175, DOI 10.1007/978-3-319-05530-5_17
   Gasbarrini A, 2003, GASTROINTEST ENDOSC, V57, P348, DOI 10.1067/mge.2003.116
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gross S, 2012, PROC SPIE, V8315, DOI 10.1117/12.911177
   Hafner M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P365, DOI 10.1007/978-3-662-46224-9_63
   Hafner M, 2012, COMPUT METH PROG BIO, V107, P565, DOI 10.1016/j.cmpb.2011.12.012
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hafner Michael, 2014, Medical Computer Vision Large Data in Medical Imaging. Third International MICCAI Workshop, MCV 2013. Revised Selected Papers. LNCS: 8331, P205, DOI 10.1007/978-3-319-05530-5_20
   Hegenbart S, 2015, COMPUT BIOL MED, V65, P348, DOI 10.1016/j.compbiomed.2015.02.007
   Hegenbart S, 2011, LECT NOTES COMPUT SC, V6801, P498, DOI 10.1007/978-3-642-22092-0_41
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Mohedano E, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P327, DOI 10.1145/2911996.2912061
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Simonyan K., 2014, ARXIV PREPRINT ARXIV
   Song Y, 2017, I S BIOMED IMAGING, P600, DOI 10.1109/ISBI.2017.7950592
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Uhl A, 2011, LECT NOTES COMPUT SC, V6669, P742
   Uhl A, 2011, INT SYMP IMAGE SIG, P727
   Vecsei A, 2011, COMPUT BIOL MED, V41, P313, DOI 10.1016/j.compbiomed.2011.03.009
   Vecsei A., 2008, 4 IET INT C ADV MED, P1, DOI [10.1049/cp:20080465, DOI 10.1049/CP:20080465]
   Vecsei A, 2009, COMPUT METH PROG BIO, V95, pS68, DOI 10.1016/j.cmpb.2009.02.017
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wimmer G, 2016, INT CONF IMAG PROC
   Wimmer G., 2016, INT WORKSH COMP ASS, P104, DOI [10.1007/978-3-319-54057-3, DOI 10.1007/978-3-319-54057-3]
   Wimmer G, 2016, INT C PATT RECOG, P2150, DOI 10.1109/ICPR.2016.7899954
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yu Z, 2017, I S BIOMED IMAGING, P301, DOI 10.1109/ISBI.2017.7950524
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 39
TC 13
Z9 13
U1 0
U2 0
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 2329-4302
EI 2329-4310
J9 J MED IMAGING
JI J. Med. Imaging
PD JUL
PY 2018
VL 5
IS 3
AR 034504
DI 10.1117/1.JMI.5.3.034504
PG 11
WC Radiology, Nuclear Medicine & Medical Imaging
WE Emerging Sources Citation Index (ESCI)
SC Radiology, Nuclear Medicine & Medical Imaging
GA GX5KX
UT WOS:000447787300023
PM 30840751
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Eschenfeldt, PC
   Kartoun, U
   Heberle, CR
   Kong, CY
   Nishioka, NS
   Ng, K
   Kamarthi, S
   Hur, C
AF Eschenfeldt, Patrick C.
   Kartoun, Uri
   Heberle, Curtis R.
   Kong, Chung Yin
   Nishioka, Norman S.
   Ng, Kenney
   Kamarthi, Sagar
   Hur, Chin
TI Analysis of factors associated with extended recovery time after
   colonoscopy
SO PLOS ONE
LA English
DT Article
ID PATIENT; MODELS; CLASSIFICATION; PREDICTION; REGRESSION; PROPOFOL;
   FENTANYL
AB Background & aims
   A common limiting factor in the throughput of gastrointestinal endoscopy units is the availability of space for patients to recover post-procedure. This study sought to identify predictors of abnormally long recovery time after colonoscopy performed with procedural sedation. In clinical research, this type of study would be performed using only one regression modeling approach. A goal of this study was to apply various "machine learning" techniques to see if better prediction could be achieved.
   Methods
   Procedural data for 31,442 colonoscopies performed on 29,905 adult patients at Massachusetts General Hospital from 2011 to 2015 were analyzed to identify potential predictors of long recovery times. These data included the identities of hospital personnel, and the initial statistical analysis focused on the impact of these personnel on recovery time via multivariate logistic regression. Secondary analyses included more information on patient vitals both to identify secondary predictors and to predict long recoveries using more complex techniques.
   Results
   In univariate analysis, the endoscopist, procedure room nurse, recovery room nurse, and surgical technician all showed a statistically significant relationship to long recovery times, with p-value below 0.0001 in all cases. In the multivariate logistic regression, the most significant predictor of a long recovery time was the identity of the recovery room nurse, with the endoscopist also showing a statistically significant relationship with a weaker effect. Complex techniques led to a negligible improvement over simple techniques in prediction of long recovery periods.
   Conclusion
   The hospital personnel involved in performing a colonoscopy show a strong association with the likelihood of a patient spending an abnormally long time recovering from the procedure, with the most pronounced effect for the nurse in the recovery room. The application of more advanced approaches to improve prediction in this clinical data set only yielded modest improvements.
C1 [Eschenfeldt, Patrick C.; Heberle, Curtis R.; Kong, Chung Yin; Hur, Chin] Massachusetts Gen Hosp, Inst Technol Assessment, Boston, MA 02114 USA.
   [Eschenfeldt, Patrick C.; Heberle, Curtis R.; Nishioka, Norman S.; Hur, Chin] Massachusetts Gen Hosp, Gastrointestinal Unit, Boston, MA 02114 USA.
   [Eschenfeldt, Patrick C.; Kong, Chung Yin; Nishioka, Norman S.; Hur, Chin] Harvard Med Sch, Boston, MA 02115 USA.
   [Kartoun, Uri; Ng, Kenney] IBM Res, Ctr Computat Hlth, Cambridge, MA USA.
   [Kamarthi, Sagar] Northeastern Univ, Coll Engn, Boston, MA 02115 USA.
C3 Harvard University; Massachusetts General Hospital; Harvard University;
   Massachusetts General Hospital; Harvard University; Harvard Medical
   School; International Business Machines (IBM); Northeastern University
RP Hur, C (通讯作者)，Massachusetts Gen Hosp, Inst Technol Assessment, Boston, MA 02114 USA.; Hur, C (通讯作者)，Massachusetts Gen Hosp, Gastrointestinal Unit, Boston, MA 02114 USA.; Hur, C (通讯作者)，Harvard Med Sch, Boston, MA 02115 USA.
EM chur@mgh.harvard.edu
RI Jovani, Manol/AAF-5333-2020
CR [Anonymous], 2017, R LANG ENV STAT COMP
   Austin PC, 2013, J CLIN EPIDEMIOL, V66, P398, DOI 10.1016/j.jclinepi.2012.11.008
   Beam AL, 2017, SCI REP-UK, V7, DOI 10.1038/srep42282
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   BURNS LR, 1991, MED CARE, V29, P251, DOI 10.1097/00005650-199103000-00007
   Churpek MM, 2016, CRIT CARE MED, V44, P368, DOI 10.1097/CCM.0000000000001571
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Ehrenfeld JM, JOINT COMM J QUAL IM, V38, P73, DOI [10.1016/31553-7250(12)38010-0, DOI 10.1016/31553-7250(12)38010-0]
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Ho WM, 2012, BMC GASTROENTEROL, V12, DOI 10.1186/1471-230X-12-164
   Hothorn T, 2006, J COMPUT GRAPH STAT, V15, P651, DOI 10.1198/106186006X133933
   Jonas DE, 2007, AM J GASTROENTEROL, V102, P2401, DOI 10.1111/j.1572-0241.2007.01387.x
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Lazaraki G, 2007, SURG ENDOSC, V21, P1631, DOI 10.1007/s00464-007-9215-y
   Lin CC, 2010, INJURY, V41, P869, DOI 10.1016/j.injury.2010.04.023
   Meyer D., 2017, PROBABILITY THEORY G
   Ripley B, 2016, CLASSIFICATION REGRE
   Sipe BW, 2002, GASTROINTEST ENDOSC, V55, P815, DOI 10.1067/mge.2002.124636
   Tambuyzer T, 2017, J CLIN MONIT COMPUT, V31, P407, DOI 10.1007/s10877-016-9870-4
   Therneau Terry., 2017, RPART RECURSIVE PART
   Tsugawa Y, 2017, BMJ-BRIT MED J, V357, DOI 10.1136/bmj.j1797
   Veelo DP, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172806
   Venables W. N., 2002, MODERN APPL STAT USI
   Wanderer JP, 2013, ANESTHESIOLOGY, V119, P516, DOI 10.1097/ALN.0b013e31829ce8fd
   Wanderer JP, 2013, ANESTH ANALG, V117, P494, DOI 10.1213/ANE.0b013e318294fb64
   Wu JL, 2010, MED CARE, V48, pS106, DOI 10.1097/MLR.0b013e3181de9e17
   Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735
NR 27
TC 2
Z9 2
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JUN 21
PY 2018
VL 13
IS 6
AR e0199246
DI 10.1371/journal.pone.0199246
PG 16
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA GK0LV
UT WOS:000435802500062
PM 29927978
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Ghosh, T
   Fattah, SA
   Wahid, KA
AF Ghosh, Tonmoy
   Fattah, Shaikh Anowarul
   Wahid, Khan Arif
TI Automatic Computer Aided Bleeding Detection Scheme for Wireless Capsule
   Endoscopy (WCE) Video Based on Higher and Lower Order Statistical
   Features in a Composite Color
SO JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING
LA English
DT Article
DE Bleeding detection; Bleeding zone; Color intensity ratio; Feature
   extraction; Wireless capsule endoscopy
AB Wireless capsule endoscopy (WCE) offers non--nvasive means to diagnose intestinal anomalies like bleeding. However, one of the problems here is the time consuming complex reviewing process which calls for automatic computer aided bleeding detection techniques to reduce the burden of the physicians. In this paper, pixel based holistic feature extraction scheme is proposed for bleeding frame detection of WCE recordings. Unlike conventional methods, instead of directly using RGB (red, green, blue) color space, a transform color domain is introduced. Higher and lower order statistical analysis on that composite color domain are carried out to extract features from the given WCE image. Feature-based supervised classification using support vector machine is performed to differentiate bleeding and non-bleeding images. Next, in order to improve the bleeding frame detection performance in WCE video, a post-processing scheme is developed utilizing the variation in temporal characteristics of consecutive frames. Finally, a zone detection algorithm is proposed to identify bleeding regions in the detected bleeding images where some morphological operations are also used. Extensive experimentation is carried out on a numerous number of WCE images and videos. It is observed that the proposed algorithm can detect bleeding frame and zones from WCE video recordings with a satisfactory level of performance.
C1 [Ghosh, Tonmoy] Pabna Univ Sci & Technol, Dept EEE, Pabna 6600, Bangladesh.
   [Fattah, Shaikh Anowarul] Bangladesh Univ Engn & Technol, Dept EEE, Dhaka 1000, Bangladesh.
   [Wahid, Khan Arif] Univ Saskatchewan, Dept ECE, Saskatoon, SK S7N 5A9, Canada.
C3 Bangladesh University of Engineering & Technology (BUET); University of
   Saskatchewan
RP Fattah, SA (通讯作者)，Bangladesh Univ Engn & Technol, Dept EEE, Dhaka 1000, Bangladesh.
EM tghosh.eee@pust.ac.bd; fattah@eee.bust.ac.bd; khan.wahid@usask.ca
RI Ghosh, Tonmoy/AAP-7360-2020
OI Ghosh, Tonmoy/0000-0003-1460-2267
CR Adler DG., 2003, HOSP PHYS, V39, P14
   ALTMAN DG, 1994, BRIT MED J, V308, P1552, DOI 10.1136/bmj.308.6943.1552
   [Anonymous], 2014, INT C INFORMATICS EL
   Conversano F., 2014, P IEEE MED MEAS APPL, P1
   Conversano F, 2011, ACAD RADIOL, V18, P461, DOI 10.1016/j.acra.2010.11.015
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Gao WS, 2010, INT CONF COMP SCI, P67, DOI 10.1109/ICCSIT.2010.5563693
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Liu JG, 2009, OPTIM ENG, V10, P289, DOI 10.1007/s11081-008-9066-y
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sainju S, 2013, CAN CON EL COMP EN, P539
   Scholkopf B, 2002, ENCY BIOSTATISTICS
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
NR 16
TC 8
Z9 8
U1 0
U2 12
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1609-0985
EI 2199-4757
J9 J MED BIOL ENG
JI J. Med. Biol. Eng.
PD JUN
PY 2018
VL 38
IS 3
BP 482
EP 496
DI 10.1007/s40846-017-0318-1
PG 15
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA GG3ZF
UT WOS:000432631500013
DA 2023-04-20
ER

PT J
AU Liaqat, A
   Khan, MA
   Shah, JH
   Sharif, M
   Yasmin, M
   Fernandes, SL
AF Liaqat, Amna
   Khan, Muhammad Attique
   Shah, Jamal Hussain
   Sharif, Muhammad
   Yasmin, Mussarat
   Fernandes, Steven Lawrence
TI AUTOMATED ULCER AND BLEEDING CLASSIFICATION FROM WCE IMAGES USING
   MULTIPLE FEATURES FUSION AND SELECTION
SO JOURNAL OF MECHANICS IN MEDICINE AND BIOLOGY
LA English
DT Article
DE WCE; contrast stretching; lesion segmentation; feature extraction;
   feature selection; classification
ID SEGMENTATION; RECOGNITION
AB In the area of medical imaging and computer vision, automatic diagnosis of ulcer and bleeding from wireless capsule endoscopy images has been an active research domain. It contains several challenges including low contrast, complex background, lesion shape and color which affect its segmentation and classification accuracy. In this article, a novel method for automated detection and classification of stomach infection is implemented. The proposed method consists of four major steps including preprocessing, lesion segmentation, image representation and classification. The lesion contrast is improved in preprocessing step by employing 3D-box filtering, 3D-median filtering and HSV transformation. In the second step, geometric features are extracted and applied to the saturated channel to give a binary image. The binary image is further improved by fusion of generated mask. After that, extraction of three types of features including color, shape and surf is performed from HSV and binary segmented images and their information is fused by a serial based method. A principal component analysis (PCA) and correlation coefficient based feature selection approach is proposed which are classified by multi class support vector machine (M-SVM). The proposed method is evaluated on personally collected images of three different classes including ulcer, bleeding and healthy. The M-SVM performs well with a maximum accuracy of 98.3% which shows the authenticity of presented method.
C1 [Liaqat, Amna; Khan, Muhammad Attique; Shah, Jamal Hussain; Sharif, Muhammad; Yasmin, Mussarat] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
   [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci & Engn, Museum Rd, Taxila, Pakistan.
   [Fernandes, Steven Lawrence] Sahyadri Coll Engn & Management, Dept Elect & Commun Engn, Mangalore, Karnataka, India.
C3 COMSATS University Islamabad (CUI); NITEC University
RP Khan, MA (通讯作者)，COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.; Khan, MA (通讯作者)，HITEC Univ, Dept Comp Sci & Engn, Museum Rd, Taxila, Pakistan.
EM attique.khan440@gmail.com
RI khan, sajid/HGE-2406-2022; Shah, Jamal Hussain/AAA-7034-2021; Yasmin,
   Mussarat/HPC-9476-2023; Sharif, Muhammad/ACD-2598-2022; Khan, Dr.
   Muhammad Attique/AAX-2644-2021; Sharif, Muhammad/AAB-8376-2022
OI Sharif, Muhammad/0000-0002-7258-8400; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Sharif, Muhammad/0000-0002-1355-2168
CR Ali H, 2017, COMPUT BIOL MED, V88, P84, DOI 10.1016/j.compbiomed.2017.07.002
   Amin Javeria, 2016, Immunology Endocrine & Metabolic Agents in Medicinal Chemistry, V16, P82, DOI 10.2174/187152221602161221215304
   Amin J, 2017, J COMPUT SCI-NETH, V19, P153, DOI 10.1016/j.jocs.2017.01.002
   [Anonymous], 2018, PATTERN RECOGN LETT
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bokhari STF, 2018, CURR MED IMAGING REV, V14, P77, DOI 10.2174/1573405613666170405145913
   Charfi S., 2018, IEEE T LEARN TECHNOL, P1, DOI DOI 10.1109/TLT.2017.2720670
   Charisis V, 2010, IEEE ENG MED BIO, P3674, DOI 10.1109/IEMBS.2010.5627648
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Chumerin Nikolay, 2006, Proceedings of the 2006 IEEE Signal Processing Society Workshop, P343
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Karargyris A, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P143, DOI 10.1109/LISSA.2009.4906730
   Khan MA, 2017, IET IMAGE PROCESS
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Mackiewicz M, 2011, CAPSULE ENDOSCOPY ST
   Masood S, 2015, CURR MED IMAGING, V11, P272, DOI 10.2174/157340561104150727171246
   Masood S, 2015, CURR MED IMAGING, V11, P3, DOI 10.2174/157340561101150423103441
   Mathew M, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1730, DOI 10.1109/ECS.2015.7124882
   Motoda H.H., 2002, COMMUN I INF COMPUT, V5, P67, DOI DOI 10.1016/J.PATCOG.2016.08.027
   Mughal B, 2017, EUR PHYS J PLUS, V132, DOI 10.1140/epjp/i2017-11523-8
   Mussarat Y, 2013, KSII T INTERNET INF, V7, P3149, DOI 10.3837/tiis.2013.12.011
   Naqi SM, 2018, CURR MED IMAGING, V14, P108, DOI 10.2174/1573405613666170306114320
   Nasir M, 2018, MICROSCOPY RES TECH
   Nida N, 2016, IIOAB J, V7, P202
   Qureshi I, 2016, CURR MED IMAGING, V12, P234, DOI 10.2174/1573405611666150929234644
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Shah JH, 2017, J MECH MED BIOL, V17, DOI 10.1142/S0219519417400115
   Sharif M, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0236-8
   Sivakumar P, 2019, CONNECT TISSUE RES, V60, P62, DOI 10.1080/03008207.2018.1500557
   Suman S, 2017, P 15 INT WORKSH CONT, P17
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Suman S, 2014, LECT NOTES COMPUT SC, V8836, P276, DOI 10.1007/978-3-319-12643-2_34
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Xu YW, 2013, BIOSYST ENG, V115, P144, DOI 10.1016/j.biosystemseng.2013.03.011
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yasmin Mussarat, 2015, International Journal of Advanced Networking and Applications, V7, P2724
   Yasmin M, 2014, J APPL RES TECHNOL, V12, P877, DOI 10.1016/S1665-6423(14)70594-2
   Yasmin M., COMBINING MULTIPLE C
   Yasmin M, 2017, PATTERN RECOGN LETT
   Yasmin M, 2013, RES J RECENT SCI, P2502
   Yasmin M, 2014, CURR MED IMAGING, V10, P163, DOI 10.2174/157340561003141003154606
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
NR 49
TC 86
Z9 88
U1 2
U2 21
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-5194
EI 1793-6810
J9 J MECH MED BIOL
JI J. Mech. Med. Biol.
PD JUN
PY 2018
VL 18
IS 4
AR 1850038
DI 10.1142/S0219519418500380
PG 25
WC Biophysics; Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biophysics; Engineering
GA GL6YI
UT WOS:000437340800003
DA 2023-04-20
ER

PT J
AU Ross, T
   Zimmerer, D
   Vemuri, A
   Isensee, F
   Wiesenfarth, M
   Bodenstedt, S
   Both, F
   Kessler, P
   Wagner, M
   Muller, B
   Kenngott, H
   Speidel, S
   Kopp-Schneider, A
   Maier-Hein, K
   Maier-Hein, L
AF Ross, Tobias
   Zimmerer, David
   Vemuri, Anant
   Isensee, Fabian
   Wiesenfarth, Manuel
   Bodenstedt, Sebastian
   Both, Fabian
   Kessler, Philip
   Wagner, Martin
   Mueller, Beat
   Kenngott, Hannes
   Speidel, Stefanie
   Kopp-Schneider, Annette
   Maier-Hein, Klaus
   Maier-Hein, Lena
TI Exploiting the potential of unlabeled endoscopic video data with
   self-supervised learning
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Information Processing for
   Computer-Assisted Interventions (IPCAI) in conjunction with the Congress
   on Computer Assisted Radiology and Surgery (CARS)
CY JUN 20-21, 2018
CL Berlin, GERMANY
DE Self-supervised learning; Endoscopic instrument segmentation; Transfer
   learning; Endoscopic image processing; Computer vision
AB Surgical data science is a new research field that aims to observe all aspects of the patient treatment process in order to provide the right assistance at the right time. Due to the breakthrough successes of deep learning-based solutions for automatic image annotation, the availability of reference annotations for algorithm training is becoming a major bottleneck in the field. The purpose of this paper was to investigate the concept of self-supervised learning to address this issue.
   Our approach is guided by the hypothesis that unlabeled video data can be used to learn a representation of the target domain that boosts the performance of state-of-the-art machine learning algorithms when used for pre-training. Core of the method is an auxiliary task based on raw endoscopic video data of the target domain that is used to initialize the convolutional neural network (CNN) for the target task. In this paper, we propose the re-colorization of medical images with a conditional generative adversarial network (cGAN)-based architecture as auxiliary task. A variant of the method involves a second pre-training step based on labeled data for the target task from a related domain. We validate both variants using medical instrument segmentation as target task.
   The proposed approach can be used to radically reduce the manual annotation effort involved in training CNNs. Compared to the baseline approach of generating annotated data from scratch, our method decreases exploratively the number of labeled images by up to 75% without sacrificing performance. Our method also outperforms alternative methods for CNN pre-training, such as pre-training on publicly available non-medical (COCO) or medical data (MICCAI EndoVis2017 challenge) using the target task (in this instance: segmentation).
   As it makes efficient use of available (non-)public and (un-)labeled data, the approach has the potential to become a valuable tool for CNN (pre-)training.
C1 [Ross, Tobias; Vemuri, Anant; Maier-Hein, Lena] German Canc Res Ctr, Comp Assisted Med Intervent, Neuenheimer Feld 581, D-69210 Heidelberg, Germany.
   [Zimmerer, David; Isensee, Fabian; Maier-Hein, Klaus] German Canc Res Ctr, Med Image Comp, Neuenheimer Feld 581, D-69210 Heidelberg, Germany.
   [Wiesenfarth, Manuel; Kopp-Schneider, Annette] German Canc Res Ctr, Div Biostat, Neuenheimer Feld 581, D-69210 Heidelberg, Germany.
   [Bodenstedt, Sebastian; Speidel, Stefanie] Natl Ctr Tumor Dis NCT, Translat Surg Oncol, Fetscherstr 74, D-01307 Dresden, Germany.
   [Wagner, Martin; Mueller, Beat; Kenngott, Hannes] Heidelberg Univ, Dept Gen Visceral & Transplant Surg, Neuenheimer Feld 110, D-69210 Heidelberg, Germany.
   [Both, Fabian; Kessler, Philip] Understand Ai, Hirschstr 71, D-76133 Karlsruhe, Germany.
C3 Helmholtz Association; German Cancer Research Center (DKFZ); Helmholtz
   Association; German Cancer Research Center (DKFZ); Helmholtz
   Association; German Cancer Research Center (DKFZ); Helmholtz
   Association; German Cancer Research Center (DKFZ); Ruprecht Karls
   University Heidelberg; Ruprecht Karls University Heidelberg
RP Ross, T (通讯作者)，German Canc Res Ctr, Comp Assisted Med Intervent, Neuenheimer Feld 581, D-69210 Heidelberg, Germany.
EM t.ross@dkfz-heidelberg.de
RI Speidel, Stefanie/K-1959-2017; Mueller, Beat/G-2662-2012;
   Kopp-Schneider, Annette/ABU-4024-2022; Wagner, Martin/GXH-1661-2022;
   Maier-Hein, Klaus Hermann/AAF-8487-2020
OI Speidel, Stefanie/0000-0002-4590-1908; Kopp-Schneider,
   Annette/0000-0002-1810-0267; Wagner, Martin/0000-0002-9831-9110;
   Maier-Hein, Klaus Hermann/0000-0002-6626-2463; Isensee,
   Fabian/0000-0002-3519-5886; Ross, Tobias/0000-0002-7094-4926;
   Bodenstedt, Sebastian/0000-0002-2203-9729
FU European Research Council [ERC-2015-StG-37960]; Intuitive Surgical;
   Federal Ministry of Economics and Energy (BMWi); German Aerospace Center
   (DLR) [OP 4.1]
FX We acknowledge the support of the European Research Council
   (ERC-2015-StG-37960). This work was support by Intuitive Surgical who
   providing us with the raw video data, from which the Medical Image
   Computing and Computer Assisted Intervention conference 2017 robotic
   challange data were extracted. We further acknowledge the support of the
   Federal Ministry of Economics and Energy (BMWi) and the German Aerospace
   Center (DLR) within the OP 4.1 projekt. Finally, we would like to thank
   Simon Kohl inspiring us to this paper.
CR Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13
   Baur C, 2017, INT C MED IM COMP CO
   Bittel S, 2017, CREATE LARGEST IN VI
   Garcia-Peraza-Herrera LC, 2017, P 2017 IEEE RSJ INT
   Garcia-Peraza-Herrera LC, 2017, LECT NOTES COMPUT SC, V10170, P84, DOI 10.1007/978-3-319-54057-3_8
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   He YX, 2023, TRANSPORTMETRICA A, V19, DOI [10.1109/CVPR.2016.90, 10.1080/23249935.2022.2033348]
   Heim E, 2017, IEEE T PATTERN ANAL
   Isola P., 2017, PROC 30 IEEE C COMPU, P1125, DOI DOI 10.1109/CVPR.2017.632
   Kamnitsas K, 2017, LECT NOTES COMPUT SC, V10265, P597, DOI 10.1007/978-3-319-59050-9_47
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Larsson G, 2017, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2017.96
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Maier-Hein L, 2016, LECT NOTES COMPUTER
   Maier-Hein L, 2017, NAT BIOMED ENG, V1, P691, DOI 10.1038/s41551-017-0132-7
   Maier-Hein L, 2014, LECT NOTES COMPUT SC, V8674, P438, DOI 10.1007/978-3-319-10470-6_55
   Mao Xudong, 2017, P IEEE INT C COMPUTE, DOI DOI 10.1109/ICCV.2017.304
   MCCULLOCH CE, 2001, GEN LINEAR MIXED MOD
   Mietkowski P., 2017, ARXIV170203684CS
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Pakhomov D, 2017, ARXIV170308580CS
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ravishankar H, 2016, LECT NOTES COMPUTER
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sonderby C. K., 2016, ARXIV161004490
   Tajbakhsh N, 2017, ADV COMPUT VIS PATT, P181, DOI 10.1007/978-3-319-42999-1_11
   Twinanda AP, 2017, IEEE T MED IMAGING, V36, P86, DOI 10.1109/TMI.2016.2593957
   Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhou ZW, 2017, PROC CVPR IEEE, P4761, DOI 10.1109/CVPR.2017.506
NR 31
TC 60
Z9 62
U1 0
U2 20
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD JUN
PY 2018
VL 13
IS 6
SI SI
BP 925
EP 933
DI 10.1007/s11548-018-1772-0
PG 9
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA GH5SN
UT WOS:000433496100019
PM 29704196
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Takiyama, H
   Ozawa, T
   Ishihara, S
   Fujishiro, M
   Shichijo, S
   Nomura, S
   Miura, M
   Tada, T
AF Takiyama, Hirotoshi
   Ozawa, Tsuyoshi
   Ishihara, Soichiro
   Fujishiro, Mitsuhiro
   Shichijo, Satoki
   Nomura, Shuhei
   Miura, Motoi
   Tada, Tomohiro
TI Automatic anatomical classification of esophagogastroduodenoscopy images
   using deep convolutional neural networks
SO SCIENTIFIC REPORTS
LA English
DT Article
ID ENDOSCOPY
AB The use of convolutional neural networks (CNNs) has dramatically advanced our ability to recognize images with machine learning methods. We aimed to construct a CNN that could recognize the anatomical location of esophagogastroduodenoscopy (EGD) images in an appropriate manner. A CNN-based diagnostic program was constructed based on GoogLeNet architecture, and was trained with 27,335 EGD images that were categorized into four major anatomical locations (larynx, esophagus, stomach and duodenum) and three subsequent sub-classifications for stomach images (upper, middle, and lower regions). The performance of the CNN was evaluated in an independent validation set of 17,081 EGD images by drawing receiver operating characteristics (ROC) curves and calculating the area under the curves (AUCs). ROC curves showed high performance of the trained CNN to classify the anatomical location of EGD images with AUCs of 1.00 for larynx and esophagus images, and 0.99 for stomach and duodenum images. Furthermore, the trained CNN could recognize specific anatomical locations within the stomach, with AUCs of 0.99 for the upper, middle, and lower stomach. In conclusion, the trained CNN showed robust performance in its ability to recognize the anatomical location of EGD images, highlighting its significant potential for future application as a computer-aided EGD diagnostic system.
C1 [Takiyama, Hirotoshi; Ozawa, Tsuyoshi; Ishihara, Soichiro; Miura, Motoi; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
   [Takiyama, Hirotoshi; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Ozawa, Tsuyoshi; Ishihara, Soichiro] Int Univ Hlth & Welf, Sanno Hosp, Dept Surg, Tokyo, Japan.
   [Fujishiro, Mitsuhiro] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Shichijo, Satoki] Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Osaka, Japan.
   [Nomura, Shuhei] Univ Tokyo, Grad Sch Med, Dept Global Hlth Policy, Tokyo, Japan.
   [Nomura, Shuhei] Imperial Coll London, Sch Publ Hlth, Dept Epidemiol & Biostat, London, England.
   [Miura, Motoi] Teikyo Univ, Grad Sch Publ Hlth, Tokyo, Japan.
C3 University of Tokyo; International University of Health & Welfare;
   University of Tokyo; University of Tokyo; Imperial College London;
   Teikyo University
RP Ozawa, T (通讯作者)，Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.; Ozawa, T (通讯作者)，Int Univ Hlth & Welf, Sanno Hosp, Dept Surg, Tokyo, Japan.
EM tsuozawa244@gmail.com
RI Nomura, Shuhei/HCH-5356-2022; 藤城, 光弘/AAN-3131-2020; Ishihara,
   Soichiro/AFK-1375-2022
OI Nomura, Shuhei/0000-0002-2963-7297; Fujishiro,
   Mitsuhiro/0000-0002-4074-1140; Shichijo, Satoki/0000-0002-5750-0976;
   Miura, Motoi/0000-0001-8032-7086
CR Adler DG, 2012, GASTROINTEST ENDOSC, V75, P231, DOI 10.1016/j.gie.2011.09.008
   Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   Cruz-Roa A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46450
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Faulx AL, 2017, GASTROINTEST ENDOSC, V85, P273, DOI 10.1016/j.gie.2016.10.036
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Huang SS, 2011, LECT NOTES COMPUT SC, V6524, P208
   Japanese Gastric Canc Assoc, 2011, GASTRIC CANCER, V14, P101, DOI 10.1007/s10120-011-0041-5
   Kriegmair MC, 2017, UROLOGY, V104, P235, DOI 10.1016/j.urology.2017.02.019
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Park WG, 2015, GASTROINTEST ENDOSC, V81, P17, DOI 10.1016/j.gie.2014.07.057
   Prinzen M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P455, DOI 10.1007/978-3-662-46224-9_78
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Roth HR, 2015, I S BIOMED IMAGING, P101, DOI 10.1109/ISBI.2015.7163826
   Shibagaki K, 2016, ENDOSCOPY, V48, P16, DOI 10.1055/s-0034-1392542
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Trebeschi S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05728-9
   Yamashita H, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3135-z
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 21
TC 72
Z9 76
U1 0
U2 13
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAY 14
PY 2018
VL 8
AR 7497
DI 10.1038/s41598-018-25842-6
PG 8
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA GF4SY
UT WOS:000431955100002
PM 29760397
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Ahn, J
   Loc, HN
   Balan, RK
   Lee, Y
   Ko, J
AF Ahn, Jungmo
   Loc, Huynh Nguyen
   Balan, Rajesh Krishna
   Lee, Youngki
   Ko, JeongGil
TI Finding Small-Bowel Lesions: Challenges in Endoscopy-Image-Based
   Learning Systems
SO COMPUTER
LA English
DT Article
ID CAPSULE ENDOSCOPY; DIAGNOSTIC YIELD
AB Capsule endoscopy identifies damaged areas in a patient's small intestine but often outputs poor-quality images or misses lesions, leading to either misdiagnosis or repetition of the lengthy procedure. The authors propose applying deep-learning models to automatically process the captured images and identify lesions in real time, enabling the capsule to take additional images of a specific location, adjust its focus level, or improve image quality. The authors also describe the technical challenges in realizing a viable automated capsule-endoscopy system.
C1 [Ahn, Jungmo; Ko, JeongGil] Ajou Univ, Dept Software & Comp Engn, Coll Informat Technol, Suwon, South Korea.
   [Loc, Huynh Nguyen] Singapore Management Univ, Sch Informat Syst, Singapore, Singapore.
   [Balan, Rajesh Krishna] Singapore Management Univ, LiveLabs Urban Lifestyle Innovat Platform, Singapore, Singapore.
   [Lee, Youngki] Singapore Management Univ, Informat Syst, Singapore, Singapore.
   [Ko, JeongGil] Ajou Univ, Dept Biomed Informat, Sch Med, Suwon, South Korea.
C3 Ajou University; Singapore Management University; Singapore Management
   University; Singapore Management University; Ajou University
RP Ahn, J (通讯作者)，Ajou Univ, Dept Software & Comp Engn, Coll Informat Technol, Suwon, South Korea.
EM ajm100@ajou.ac.kr; nlhuynh.2014@phdis.smu.edu.sg; rajesh@smu.edu.sg;
   youngkilee@smu.edu.sg; jgko@ajou.ac.kr
RI Ko, JeongGil/CAF-8134-2022
FU Korean Ministry of Science and ICT under the ITRC program
   [IITP-2018-2016-0-00309-002]; DGIST Research and Development Program
   (CPS Global Center)
FX This work was supported by the Korean Ministry of Science and ICT under
   the ITRC program (IITP-2018-2016-0-00309-002) and also by the DGIST
   Research and Development Program (CPS Global Center) for the project
   "Identifying Unmet Requirements for Future Wearable Devices in Designing
   Autonomous Clinical Event Detection Applications."
CR Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huynh LN, 2017, MOBISYS'17: PROCEEDINGS OF THE 15TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P82, DOI 10.1145/3081333.3081360
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Kang B, 2016, ICT EXPRESS, V2, P67, DOI 10.1016/j.icte.2016.05.001
   Lane N.D., 2016, P 15 ACM IEEE INT C, P1
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Lee HG, 2013, COMPUT BIOL MED, V43, P670, DOI 10.1016/j.compbiomed.2013.02.009
   Liao Z, 2010, ENDOSCOPY, V42, P360, DOI 10.1055/s-0029-1243993
   Liu H, 2013, J DIGIT IMAGING, V26, P287, DOI 10.1007/s10278-012-9519-x
   NVIDIA Corp, 2014, CISC VIS NETW IND GL
   Ou G, 2015, WORLD J GASTROENTERO, V21, P2677, DOI 10.3748/wjg.v21.i9.2677
   Rahman M, 2015, WORLD J GASTROENTERO, V21, P5542, DOI 10.3748/wjg.v21.i18.5542
   Simonyan K, 2015, Arxiv
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 16
TC 10
Z9 11
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0018-9162
EI 1558-0814
J9 COMPUTER
JI Computer
PD MAY
PY 2018
VL 51
IS 5
BP 68
EP 76
DI 10.1109/MC.2018.2381116
PG 9
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GH3RC
UT WOS:000433318900008
OA Green Published
DA 2023-04-20
ER

PT J
AU de Souza, LA
   Palm, C
   Mendel, R
   Hook, C
   Ebigbo, A
   Probst, A
   Messmann, H
   Weber, S
   Papa, JP
AF de Souza Jr, Luis A.
   Palm, Christoph
   Mendel, Robert
   Hook, Christian
   Ebigbo, Alanna
   Probst, Andreas
   Messmann, Helmut
   Weber, Silke
   Papa, Joao P.
TI A survey on Barrett's esophagus analysis using machine learning
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Barrett's esophagus; Machine learning; Adenocarcinoma; Image processing;
   Pattern recognition; Computer-aided diagnosis
ID LASER ENDOMICROSCOPY; RADIOFREQUENCY ABLATION; ENDOSCOPY; CARCINOMA;
   DIAGNOSIS; ADENOCARCINOMA; IDENTIFICATION; DYSPLASIA; FEATURES; CANCER
AB This work presents a systematic review concerning recent studies and technologies of machine learning for Barrett's esophagus (BE) diagnosis and treatment. The use of artificial intelligence is a brand new and promising way to evaluate such disease. We compile some works published at some well-established databases, such as Science Direct, IEEEXplore, PubMed, Plos One, Multidisciplinary Digital Publishing Institute (MDPI), Association for Computing Machinery (ACM), Springer, and Hindawi Publishing Corporation. Each selected work has been analyzed to present its objective, methodology, and results. The BE progression to dysplasia or adenocarcinoma shows a complex pattern to be detected during endoscopic surveillance. Therefore, it is valuable to assist its diagnosis and automatic identification using computer analysis. The evaluation of the BE dysplasia can be performed through manual or automated segmentation through machine learning techniques. Finally, in this survey, we reviewed recent studies focused on the automatic detection of the neoplastic region for classification purposes using machine learning methods.
C1 [de Souza Jr, Luis A.; Papa, Joao P.] Sao Paulo State Univ, UNESP, Dept Comp, Sao Paulo, Brazil.
   [de Souza Jr, Luis A.; Palm, Christoph; Mendel, Robert; Hook, Christian] Ostbayer Tech Hsch Regensburg OTH Regensburg, Regensburg Med Image Comp ReMIC, Regensburg, Germany.
   [Palm, Christoph] OTH Regensburg, RCBE, Regensburg, Germany.
   [Palm, Christoph] Regensburg Univ, Regensburg, Germany.
   [Weber, Silke] Sao Paulo State Univ, Dept Otorhinolaryngol, Sao Paulo, Brazil.
   [Ebigbo, Alanna; Probst, Andreas; Messmann, Helmut] Klinikum Augsburg, Med Klin 3, Augsburg, Germany.
C3 Universidade Estadual Paulista; University of Regensburg; Universidade
   Estadual Paulista; Klinikum Augsburg
RP Papa, JP (通讯作者)，Sao Paulo State Univ, UNESP, Dept Comp, Sao Paulo, Brazil.
EM papa@fc.unesp.br
RI Weber, Silke Anna Theresa/H-9340-2019; Ebigbo, Alanna/ACP-0443-2022;
   Palm, Christoph/F-4943-2014; Messmann, Helmut/AAQ-3568-2021; Messmann,
   Helmut/AAB-6758-2020; Palm, Christoph/AAI-7959-2020; Papa, Joao
   Paulo/ABC-6283-2020
OI Palm, Christoph/0000-0001-9468-2871; Papa, Joao
   Paulo/0000-0002-6494-7514; Weber, Silke Anna
   Theresa/0000-0003-3194-3039; Souza Jr., Luis Antonio/0000-0002-7060-6097
FU DFG [PA 1595/3-1]; Capes/Alexander von Humboldt Foundation [BEX
   0581-16-0]; CNPq [306166/2014-3, 307066/2017-7]; FAPESP [2013/07375-0,
   2014/12236-1, 2016/19403-6]
FX The authors thank DFG grant PA 1595/3-1, Capes/Alexander von Humboldt
   Foundation grant number BEX 0581-16-0, CNPq grants 306166/2014-3 and
   307066/2017-7, as well as FAPESP grants 2013/07375-0, 2014/12236-1, and
   2016/19403-6.
CR Abrams JA, 2009, CLIN GASTROENTEROL H, V7, P736, DOI 10.1016/j.cgh.2008.12.027
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boschetto D., 2016, P SPIE MED IMAGING 2, V9788, P1
   Chan D. K., 2016, GASTROENTEROLOGY, P1
   Curvers WL, 2016, GASTROINTEST ENDOSC, V83, P115, DOI 10.1016/j.gie.2015.08.057
   Dent J, 2011, J GASTROEN HEPATOL, V26, P11, DOI 10.1111/j.1440-1746.2010.06535.x
   Georgakopoulos SV, 2016, IEEE CONF IMAGING SY, P510, DOI 10.1109/IST.2016.7738279
   Ghatwary N., 2017, 21 ANN C MIUA 2017 E, P897
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Hong J., 2017, CONVOLUTIONAL NEURAL, V2017, P2892
   Hopkins J., 2008, GASTROENTEROLOGY HEP, P1
   Johnston MH, 2005, GASTROINTEST ENDOSC, V62, P842, DOI 10.1016/j.gie.2005.05.008
   Kandemir M, 2014, I S BIOMED IMAGING, P1348, DOI 10.1109/ISBI.2014.6868127
   Klomp S., 2017, P SOC PHOTO-OPT INS, V10134
   Koulaouzidis A., KID KOULAOUZIDIS IAK
   Lagergren J., BMJ, V341
   Lepage C, 2008, AM J GASTROENTEROL, V103, P2694, DOI 10.1111/j.1572-0241.2008.02191.x
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li C, 2015, J BIOMED INFORM, V57, P358, DOI 10.1016/j.jbi.2015.08.017
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mendel R., 2017, BILDVERARBEITUNG MED, P80
   MICCAI, 2015, 18 INT C MED IM COMP
   Muldoon TJ, 2010, J BIOMED OPT, V15, DOI 10.1117/1.3406386
   Nancarrow D. J., 2011, PLOS ONE, V6, P1
   Overholt BF, 2003, GASTROINTEST ENDOSC, V58, P183, DOI 10.1067/mge.2003.327
   Papa JP, 2009, INT J IMAG SYST TECH, V19, P120, DOI 10.1002/ima.20188
   Papa JP, 2012, PATTERN RECOGN, V45, P512, DOI 10.1016/j.patcog.2011.07.013
   Pech O, 2008, CLIN GASTROENTEROL H, V6, P89, DOI 10.1016/j.cgh.2007.10.013
   Phoa KN, 2016, GUT, V65, P555, DOI 10.1136/gutjnl-2015-309298
   Pu WL, 2017, CLIN EPIGENETICS, V9, DOI 10.1186/s13148-017-0430-7
   Rajan P., 2010, AUTOMATED DIAGNOSIS, P2189
   Rodriguez-Diaz E, 2016, GASTROENTEROLOGY, V150, pS434, DOI 10.1016/S0016-5085(16)31506-2
   Rosenfeld A, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE SCIENCE, TECHNOLOGY AND ENGINEERING (SWSTE), P65, DOI 10.1109/SWSTE.2014.21
   Sattlecker M, 2014, TRAC-TREND ANAL CHEM, V59, P17, DOI 10.1016/j.trac.2014.02.016
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Serpa-Andrade L, 2015, IEEE INT AUT MEET
   Shaheen NJ, 2009, NEW ENGL J MED, V360, P2277, DOI 10.1056/NEJMoa0808145
   Sharma P, 2016, GASTROENTEROLOGY, V150, P591, DOI 10.1053/j.gastro.2015.11.037
   Sharma P, 2015, CLIN GASTROENTEROL H, V13, P2209, DOI 10.1016/j.cgh.2015.09.017
   Souza L. A., 2017, P WORKSH VOM 12 BIS, P141
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Swager AF, 2017, GASTROINTEST ENDOSC, V85, P918, DOI 10.1016/j.gie.2016.09.012
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van der Sommen F., P SPIE INT SOC OPTIC, V8670
   Veronese E., 2013, 2013 IEEE 10th International Symposium on Biomedical Imaging: From Nano to Macro (ISBI 2013), P362
   Wang Z, 2016, GASTROENTEROLOGY, V150, pS434, DOI 10.1016/S0016-5085(16)31507-4
   Yoshida H., 2017, ACTA OTO-LARYNGOL, P1
   Yu J., 2015, P 2015 IEEE C ROB BI, P6
   Zhang ZH, 2016, MULTIMED TOOLS APPL, V75, P3993, DOI 10.1007/s11042-015-3108-1
   Zhou Z.-H., 2009, P 26 ANN INT C MACH, P1249, DOI [DOI 10.1145/1553374.1553534, 10.1145/1553374]
   Zopf S, 2009, GASTROINTEST ENDOSC, V69, pAB376, DOI 10.1016/j.gie.2009.03.1133
NR 52
TC 24
Z9 25
U1 0
U2 23
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD MAY 1
PY 2018
VL 96
BP 203
EP 213
DI 10.1016/j.compbiomed.2018.03.014
PG 11
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA GG5WY
UT WOS:000432767700020
PM 29626734
OA Green Published
DA 2023-04-20
ER

PT J
AU Du, XF
   Kurmann, T
   Chang, PL
   Allan, M
   Ourselin, S
   Sznitman, R
   Kelly, JD
   Stoyanov, D
AF Du, Xiaofei
   Kurmann, Thomas
   Chang, Ping-Lin
   Allan, Maximilian
   Ourselin, Sebastien
   Sznitman, Raphael
   Kelly, John D.
   Stoyanov, Danail
TI Articulated Multi-Instrument 2-D Pose Estimation Using Fully
   Convolutional Networks
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Surgical instrument detection; articulated pose estimation; fully
   convolutional networks; surgical vision
ID SURGICAL TOOL DETECTION; 3D TRACKING
AB Instrument detection, pose estimation, and tracking in surgical videos are an important vision component for computer-assisted interventions. While significant advances have been made in recent years, articulation detection is still a major challenge. In this paper, we propose a deep neural network for articulated multi-instrument 2-D pose estimation, which is trained on detailed annotations of endoscopic and microscopic data sets. Our model is formed by a fully convolutional detection-regression network. Joints and associations between joint pairs in our instrument model are located by the detection subnetwork and are subsequently refined through a regression sub-network. Based on the output from the model, the poses of the instruments are inferred using maximum bipartite graph matching. Our estimation framework is powered by deep learning techniques without any direct kinematic information from a robot. Our framework is tested on single-instrument RMIT data, and also on multi-instrument EndoVis and in vivo data with promising results. In addition, the data set annotations are publicly released along with our code and model.
C1 [Du, Xiaofei; Allan, Maximilian; Ourselin, Sebastien; Stoyanov, Danail] UCL, Ctr Med Image Comp, London WC1E 6BT, England.
   [Kurmann, Thomas; Sznitman, Raphael] Univ Bern, ARTORG Ctr Biomed Engn Res, CH-3012 Bern, Switzerland.
   [Chang, Ping-Lin] Umbo Comp Vis Inc, San Francisco, CA 94105 USA.
   [Kelly, John D.] UCL, Div Surg & Intervent Sci, London WC1E 6BT, England.
C3 University of London; University College London; University of Bern;
   University of London; University College London
RP Du, XF (通讯作者)，UCL, Ctr Med Image Comp, London WC1E 6BT, England.
EM xiaofei.du.13@ucl.ac.uk; thomas.kurmann@artorg.unibe.ch;
   ping-lin.chang@umbocv.com; maximilian.allan.11@ucl.ac.uk;
   s.ourselin@ucl.ac.uk; raphael.sznitman@artorg.unibe.ch;
   j.d.kelly@ucl.ac.uk; danail.stoyanov@ucl.ac.uk
RI Stoyanov, Danail/V-1043-2019; Allan, Max/AAF-7272-2019; Ourselin,
   Sebastien/K-6960-2015
OI Stoyanov, Danail/0000-0002-0980-3227; Ourselin,
   Sebastien/0000-0002-5694-5340
FU EPSRC [EP/N013220/1, EP/N022750/1, EP/N027078/1, NS/A000027/1,
   EP/P012841/1]; Wellcome Trust [WT101957, 201080/Z/16/Z]; EU-Horizon2020
   Project EndoVESPA [H2020-ICT-2015-688592]; China Scholarship Council
   Scholarship; EPSRC [EP/P012841/1, EP/N027078/1, EP/N022750/1,
   EP/N013220/1] Funding Source: UKRI; Engineering and Physical Sciences
   Research Council [EP/N027078/1, EP/P012841/1, EP/N022750/1,
   EP/N013220/1, 1091178] Funding Source: researchfish
FX This work was supported in part by EPSRC under Grant EP/N013220/1, Grant
   EP/N022750/1, Grant EP/N027078/1, Grant NS/A000027/1, and Grant
   EP/P012841/1, in part by the Wellcome Trust under Grant WT101957 and
   Grant 201080/Z/16/Z, and in part by the EU-Horizon2020 Project EndoVESPA
   under Grant H2020-ICT-2015-688592. The work of X. Du was supported by
   the China Scholarship Council Scholarship. (Corresponding author:
   Xiaofei Du.)
CR Allan M, 2015, LECT NOTES COMPUT SC, V9349, P331, DOI 10.1007/978-3-319-24553-9_41
   Bouget D, 2017, MED IMAGE ANAL, V35, P633, DOI 10.1016/j.media.2016.09.003
   Bouget D, 2015, IEEE T MED IMAGING, V34, P2603, DOI 10.1109/TMI.2015.2450831
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Cao Z., 2016, REALTIME MULTIPERSON
   Du XF, 2016, INT J COMPUT ASS RAD, V11, P1109, DOI 10.1007/s11548-016-1393-4
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Garcia-Peraza-Herrera L. C., 2017, TOOLNET HOLISTICALLY
   Garcia-Peraza-Herrera LC, 2017, LECT NOTES COMPUT SC, V10170, P84, DOI 10.1007/978-3-319-54057-3_8
   Kurmann Thomas, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P505, DOI 10.1007/978-3-319-66185-8_57
   Laina Iro, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P664, DOI 10.1007/978-3-319-66185-8_75
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Menglong Ye, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P386, DOI 10.1007/978-3-319-46720-7_45
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Pezzementi Z, 2009, IEEE INT CONF ROBOT, P1225
   Reiter A., 2012, PROC COMPUT ASSIST R, P1
   Reiter A, 2012, P IEEE COMP SOC C CO, P38
   Reiter A, 2012, LECT NOTES COMPUT SC, V7511, P592, DOI 10.1007/978-3-642-33418-4_73
   Richa R, 2011, IEEE INT C INT ROBOT, P2953, DOI 10.1109/IROS.2011.6048295
   Rieke Nicola, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P422, DOI 10.1007/978-3-319-46720-7_49
   Rieke N, 2015, LECT NOTES COMPUT SC, V9349, P266, DOI 10.1007/978-3-319-24553-9_33
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahu M, 2017, INT J COMPUT ASS RAD, V12, P1013, DOI 10.1007/s11548-017-1565-x
   Sarikaya D, 2017, IEEE T MED IMAGING, V36, P1542, DOI 10.1109/TMI.2017.2665671
   Schwartz J, 2005, LECT NOTES COMPUT SC, V3503, P476
   Springenberg J. T., 2014, ARXIV14126806
   SZNITMAN R, 2014, PROC INT CONF MED, V8674, P692
   Sznitman R, 2012, LECT NOTES COMPUT SC, V7511, P568, DOI 10.1007/978-3-642-33418-4_70
   Twinanda AP, 2017, IEEE T MED IMAGING, V36, P86, DOI 10.1109/TMI.2016.2593957
   Wellons C., NOISE FRACTALS CLOUD
   Wolf R, 2011, LECT NOTES COMPUT SC, V6891, P203, DOI 10.1007/978-3-642-23623-5_26
NR 31
TC 63
Z9 66
U1 6
U2 42
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD MAY
PY 2018
VL 37
IS 5
BP 1276
EP 1287
DI 10.1109/TMI.2017.2787672
PG 12
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA GE9IX
UT WOS:000431544500019
PM 29727290
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Garcia-Figueiras, R
   Baleato-Gonzalez, S
   Padhani, AR
   Luna-Alcala, A
   Marhuenda, A
   Vilanova, JC
   Osorio-Vazquez, I
   Martinez-de-Alegria, A
   Gomez-Caamano, A
AF Garcia-Figueiras, Roberto
   Baleato-Gonzalez, Sandra
   Padhani, Anwar R.
   Luna-Alcala, Antonio
   Marhuenda, Ana
   Vilanova, Joan C.
   Osorio-Vazquez, Iria
   Martinez-De-Alegria, Anxo
   Gomez-Caamano, Antonio
TI Advanced Imaging Techniques in Evaluation of Colorectal Cancer
SO RADIOGRAPHICS
LA English
DT Article; Proceedings Paper
CT 102nd Scientific Assembly and Annual Meeting of the
   Radiological-Society-of-North-America (RSNA)
CY NOV 27-DEC 02, 2016
CL Chicago, IL
SP Radiol Soc N Amer
ID APPARENT DIFFUSION-COEFFICIENT; ADVANCED RECTAL-CANCER;
   CONTRAST-ENHANCED MRI; PATHOLOGICAL COMPLETE RESPONSE;
   POSITRON-EMISSION-TOMOGRAPHY; INTRAVOXEL INCOHERENT MOTION; F-18-FDG
   PET/PERFUSION CT; MESORECTAL LYMPH-NODES; TUMOR TEXTURE ANALYSIS;
   WHOLE-BODY PET/MRI
AB Imaging techniques are clinical decision-making tools in the evaluation of patients with colorectal cancer (CRC). The aim of this article is to discuss the potential of recent advances in imaging for diagnosis, prognosis, therapy planning, and assessment of response to treatment of CRC. Recent developments and new clinical applications of conventional imaging techniques such as virtual colonoscopy, dual-energy spectral computed tomography, elastography, advanced computing techniques (including volumetric rendering techniques and machine learning), magnetic resonance (MR) imaging-based magnetization transfer, and new liver imaging techniques, which may offer additional clinical information in patients with CRC, are summarized. In addition, the clinical value of functional and molecular imaging techniques such as diffusion-weighted MR imaging, dynamic contrast material-enhanced imaging, blood oxygen level-dependent imaging, lymphography with contrast agents, positron emission tomography with different radiotracers, and MR spectroscopy is reviewed, and the advantages and disadvantages of these modalities are evaluated. Finally, the future role of imaging-based analysis of tumor heterogeneity and multiparametric imaging, the development of radiomics and radiogenomics, and future challenges for imaging of patients with CRC are discussed. (C) RSNA, 2018.
C1 [Garcia-Figueiras, Roberto; Baleato-Gonzalez, Sandra; Osorio-Vazquez, Iria; Martinez-De-Alegria, Anxo] Univ Santiago de Compostela, Hosp Clin, Dept Radiol, Choupana S-N, Santiago De Compostela 15706, Spain.
   [Gomez-Caamano, Antonio] Univ Santiago de Compostela, Hosp Clin, Dept Radiat Oncol, Choupana S-N, Santiago De Compostela 15706, Spain.
   [Padhani, Anwar R.] Mt Vernon Canc Ctr, Paul Strickland Scanner Ctr, Northwood, Middx, England.
   [Luna-Alcala, Antonio] Hlth Time, Jaen, Spain.
   [Luna-Alcala, Antonio] Case Western Reserve Univ, Univ Hosp Cleveland, Dept Radiol, Cleveland, OH 44106 USA.
   [Marhuenda, Ana] Inst Valenciano Oncol, Dept Radiol, Valencia, Spain.
   [Vilanova, Joan C.] Clin Girona & IDI, Dept Radiol, Girona, Spain.
C3 Complexo Hospitalario Universitario de Santiago de Compostela;
   Universidade de Santiago de Compostela; Complexo Hospitalario
   Universitario de Santiago de Compostela; Universidade de Santiago de
   Compostela; Mount Vernon Cancer Centre; Case Western Reserve University;
   Case Western Reserve University Hospital; University Hospitals of
   Cleveland; Instituto Valenciano De Oncologia
RP Garcia-Figueiras, R (通讯作者)，Univ Santiago de Compostela, Hosp Clin, Dept Radiol, Choupana S-N, Santiago De Compostela 15706, Spain.
EM roberto.garcia.figueiras@sergas.es
RI Vilanova, Joan C/H-6104-2015
OI Vilanova, Joan C/0000-0003-2148-6751; Padhani,
   Anwar/0000-0002-5830-5777; Gomez-Caamano, Antonio/0000-0002-9773-4590;
   Osorio Vazquez, Iria/0000-0002-8281-036X
CR Alberda WJ, 2013, INT J COLORECTAL DIS, V28, P573, DOI 10.1007/s00384-012-1576-6
   Attenberger UI, 2017, ANTICANCER RES, V37, P215, DOI 10.21873/anticanres.11309
   Balyasnikova S, 2016, CURR COLORECT CANC R, V12, P162, DOI 10.1007/s11888-016-0321-x
   Brendle C, 2016, EUR J NUCL MED MOL I, V43, P123, DOI 10.1007/s00259-015-3137-z
   Brush J, 2011, HEALTH TECHNOL ASSES, V15, P1, DOI 10.3310/hta15350
   Catalano OA, 2017, ABDOM RADIOL, V42, P1141, DOI 10.1007/s00261-016-0985-3
   Cerny M, 2016, CLIN NUCL MED, V41, P289, DOI 10.1097/RLU.0000000000001172
   Chen SW, 2015, CLIN NUCL MED, V40, P621, DOI 10.1097/RLU.0000000000000830
   Choi MH, 2016, J MAGN RESON IMAGING, V44, P212, DOI 10.1002/jmri.25117
   Cui CY, 2011, EUR RADIOL, V21, P2318, DOI 10.1007/s00330-011-2182-7
   Culverwell AD, 2012, ABDOM IMAGING, V37, P1021, DOI 10.1007/s00261-012-9855-9
   Curvo-Semedo L, 2012, J MAGN RESON IMAGING, V35, P1365, DOI 10.1002/jmri.23589
   De Cecco CN, 2016, ABDOM RADIOL, V41, P1728, DOI 10.1007/s00261-016-0733-8
   De Cecco CN, 2015, INVEST RADIOL, V50, P239, DOI 10.1097/RLI.0000000000000116
   de Geus-Oei Lioe-Fee, 2006, Cancer Imaging, V6, pS71, DOI 10.1102/1470-7330.2006.9014
   De Vos N, 2014, ACTA CHIR BELG, V114, P370, DOI 10.1080/00015458.2014.11681046
   Dietz DW, 2008, DIS COLON RECTUM, V51, P1641, DOI 10.1007/s10350-008-9420-3
   Dighe S, 2013, RADIOLOGY, V268, P400, DOI 10.1148/radiol.13112460
   Dinapoli N, 2016, TRANSL CANCER RES, V5, P424, DOI 10.21037/tcr.2016.06.08
   Dzik-Jurasz ASK, 2002, MAGNET RESON MED, V47, P809, DOI 10.1002/mrm.10108
   Er HC, 2014, DIAGN INTERV RADIOL, V20, P105, DOI 10.5152/dir.2013.13275
   Esgiar AN, 2002, IEEE T INF TECHNOL B, V6, P54, DOI 10.1109/4233.992163
   Fischer MA, 2014, EUR J NUCL MED MOL I, V41, P1563, DOI 10.1007/s00259-014-2752-4
   Fitzmaurice C, 2015, JAMA ONCOL, V1, P505, DOI 10.1001/jamaoncol.2015.0735
   Fortuin AS, 2018, WILEY INTERDISCIP RE, V10
   Fulwadhva UP, 2016, RADIOGRAPHICS, V36, P393, DOI 10.1148/rg.2016150151
   Figueiras RG, 2010, AM J ROENTGENOL, V195, P54, DOI 10.2214/AJR.10.4422
   Garcia-Figueiras R, 2016, INSIGHTS IMAGING, V7, P285, DOI 10.1007/s13244-016-0465-x
   Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169
   Goh V, 2014, BRIT J RADIOL, V87, DOI 10.1259/bjr.20130811
   Goh V, 2008, RADIOLOGY, V249, P510, DOI 10.1148/radiol.2492071365
   Goh V, 2012, J NUCL MED, V53, P687, DOI 10.2967/jnumed.111.098525
   Goh V, 2009, EUR RADIOL, V19, P1358, DOI 10.1007/s00330-009-1304-y
   Gollub MJ, 2017, EUR RADIOL, V27, P1605, DOI 10.1007/s00330-016-4493-1
   Gong HX, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147756
   Gong JY, 2015, GASTROENTEROL REP, V3, P128, DOI 10.1093/gastro/gou078
   Granata V, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142876
   Grosu S, 2016, EUR J RADIOL, V85, P1265, DOI 10.1016/j.ejrad.2016.04.006
   Gu J, 2011, J MAGN RESON IMAGING, V33, P340, DOI 10.1002/jmri.22405
   Harisinghani MG, 1999, AM J ROENTGENOL, V172, P1347, DOI 10.2214/ajr.172.5.10227514
   Havelund BM, 2013, NUCL MED COMMUN, V34, P155, DOI 10.1097/MNM.0b013e32835bd5bc
   Hayano K, 2014, WORLD J GASTROENTERO, V20, P17345, DOI 10.3748/wjg.v20.i46.17345
   Hotker AM, 2016, EUR RADIOL, V26, P4303, DOI 10.1007/s00330-016-4283-9
   Hong HS, 2013, YONSEI MED J, V54, P123, DOI 10.3349/ymj.2013.54.1.123
   Huang YQ, 2016, J CLIN ONCOL, V34, P2157, DOI 10.1200/JCO.2015.65.9128
   Intven M, 2015, ACTA ONCOL, V54, P1729, DOI 10.3109/0284186X.2015.1037010
   Jalil O, 2017, COLORECTAL DIS, V19, P349, DOI 10.1111/codi.13496
   Janssen MHM, 2012, INT J RADIAT ONCOL, V82, P849, DOI 10.1016/j.ijrobp.2010.10.029
   Jhaveri KS, 2015, AM J ROENTGENOL, V205, pW42, DOI 10.2214/AJR.14.14201
   Jia HY, 2015, INT J CLIN EXP MED, V8, P17333
   Joye I, 2014, RADIOTHER ONCOL, V113, P158, DOI 10.1016/j.radonc.2014.11.026
   Kang B, 2016, AM J ROENTGENOL, V206, pW10, DOI 10.2214/AJR.14.13818
   Kato T, 2015, EJSO-EUR J SURG ONC, V41, P1464, DOI 10.1016/j.ejso.2015.08.154
   Kim HJ, 2015, RADIOLOGY, V274, P712, DOI 10.1148/radiol.14140390
   Kim JH, 2016, AM J ROENTGENOL, V207, pW26, DOI 10.2214/AJR.15.15683
   Kim MJ, 2012, MAGN RESON IMAGING, V30, P848, DOI 10.1016/j.mri.2012.02.013
   Kino A, 2017, ABDOM RADIOL, V42, P1132, DOI 10.1007/s00261-016-0983-5
   Ko EY, 2007, AM J ROENTGENOL, V188, P785, DOI 10.2214/AJR.06.0476
   Koh DM, 2011, AM J ROENTGENOL, V196, P1351, DOI 10.2214/AJR.10.5515
   Kukuk GM, 2014, EUR RADIOL, V24, P2482, DOI 10.1007/s00330-014-3291-x
   Lambregts DMJ, 2013, ABDOM IMAGING, V38, P720, DOI 10.1007/s00261-012-9957-4
   Lambregts DMJ, 2011, EUR J CANCER, V47, P2107, DOI 10.1016/j.ejca.2011.05.013
   Larue RTHM, 2017, BRIT J RADIOL, V90, DOI 10.1259/bjr.20160665
   Laurens ST, 2015, PET CLIN, V10, P345, DOI 10.1016/j.cpet.2015.03.007
   Lee DH, 2017, J MAGN RESON IMAGING, V45, P21, DOI 10.1002/jmri.25337
   Lee HJ, 2014, MAGN RESON MED, V71, P1554, DOI 10.1002/mrm.24810
   Lee SJ, 2015, CLIN NUCL MED, V40, pE392, DOI 10.1097/RLU.0000000000000812
   Levine MS, 2014, RADIOLOGY, V273, pS160, DOI 10.1148/radiol.14140531
   Li ZH, 2017, ONCOTARGETS THER, V10, P2297, DOI 10.2147/OTT.S131008
   Liang CS, 2016, ONCOTARGET, V7, P31401, DOI 10.18632/oncotarget.8919
   Lim MC, 2014, CLIN RADIOL, V69, P887, DOI 10.1016/j.crad.2013.12.021
   Liu LH, 2017, J MAGN RESON IMAGING, V45, P1798, DOI 10.1002/jmri.25460
   Lollert A, 2014, J MAGN RESON IMAGING, V39, P1436, DOI 10.1002/jmri.24301
   Lovinfosse P, 2016, BRIT J RADIOL, V89, DOI 10.1259/bjr.20160212
   Lubner MG, 2015, ABDOM IMAGING, V40, P2331, DOI 10.1007/s00261-015-0438-4
   Maffione AM, 2015, AM J ROENTGENOL, V204, P1261, DOI 10.2214/AJR.14.13210
   Marcus C, 2016, AM J ROENTGENOL, V207, P257, DOI 10.2214/AJR.15.15806
   Martens MH, 2016, EUR RADIOL, V26, P390, DOI 10.1007/s00330-015-3856-3
   Martens MH, 2015, INT J RADIAT ONCOL, V93, P1005, DOI 10.1016/j.ijrobp.2015.09.008
   Mazurowski MA, 2015, J AM COLL RADIOL, V12, P862, DOI 10.1016/j.jacr.2015.04.019
   Meijerink MR, 2010, ULTRASOUND MED BIOL, V36, P1626, DOI 10.1016/j.ultrasmedbio.2010.06.015
   Miles KA, 2014, J NUCL MED, V55, P386, DOI 10.2967/jnumed.113.120485
   Monguzzi L, 2013, EUR J RADIOL, V82, P234, DOI 10.1016/j.ejrad.2012.09.027
   Muijs CT, 2011, RADIOTHER ONCOL, V98, P357, DOI 10.1016/j.radonc.2010.12.008
   Nakajo M, 2013, EUR J NUCL MED MOL I, V40, P1223, DOI 10.1007/s00259-013-2424-9
   Ng F, 2013, RADIOLOGY, V266, P177, DOI 10.1148/radiol.12120254
   Nie K, 2016, CLIN CANCER RES, V22, P5256, DOI 10.1158/1078-0432.CCR-15-2997
   O'Connor JPB, 2015, CLIN CANCER RES, V21, P249, DOI 10.1158/1078-0432.CCR-14-0990
   O'Connor JPB, 2009, INT J RADIAT ONCOL, V75, P1209, DOI 10.1016/j.ijrobp.2008.12.040
   Orlhac F, 2014, J NUCL MED, V55, P414, DOI 10.2967/jnumed.113.129858
   Padhani AR, 2010, RADIOLOGY, V256, P348, DOI 10.1148/radiol.10091760
   Permutt Z, 2012, ALIMENT PHARM THER, V36, P22, DOI 10.1111/j.1365-2036.2012.05121.x
   Petrillo M, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/514740
   Pham TT, 2017, BRIT J RADIOL, V90, DOI 10.1259/bjr.20151078
   Rao SX, 2014, UNITED EUR GASTROENT, V2, P530, DOI 10.1177/2050640614552463
   Rendl G, 2015, ANN NUCL MED, V29, P284, DOI 10.1007/s12149-014-0938-2
   Robinson C, 2011, BRIT J RADIOL, V84, P435, DOI 10.1259/bjr/17848340
   Roels S, 2008, ACTA ONCOL, V47, P1237, DOI 10.1080/02841860802256434
   Rosenkrantz AB, 2015, J MAGN RESON IMAGING, V42, P1190, DOI 10.1002/jmri.24985
   Ryan JE, 2015, COLORECTAL DIS, V17, P849, DOI 10.1111/codi.13081
   Sala E, 2017, CLIN RADIOL, V72, P3, DOI 10.1016/j.crad.2016.09.013
   Shin YR, 2016, ANTICANCER RES, V36, P4799, DOI 10.21873/anticanres.11039
   Song BW, 2014, INT J COMPUT ASS RAD, V9, P1021, DOI 10.1007/s11548-014-0991-2
   Sun HL, 2014, ACAD RADIOL, V21, P750, DOI 10.1016/j.acra.2014.02.011
   Sun YS, 2010, RADIOLOGY, V254, P170, DOI 10.1148/radiol.2541082230
   Taouli B, 2016, J MAGN RESON IMAGING, V44, P521, DOI 10.1002/jmri.25196
   Thornton E, 2010, RADIOGRAPHICS, V30, P201, DOI 10.1148/rg.301095519
   Tixier F, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099567
   Tong T, 2014, J MAGN RESON IMAGING, V40, P738, DOI 10.1002/jmri.24398
   Vag T, 2014, CLIN IMAG, V38, P845, DOI 10.1016/j.clinimag.2014.06.011
   van der Paardt MP, 2013, RADIOLOGY, V269, P101, DOI 10.1148/radiol.13122833
   van Heeswijk MM, 2017, ABDOM RADIOL, V42, P1627, DOI 10.1007/s00261-017-1062-2
   van Heeswijk MM, 2017, AM J ROENTGENOL, V208, pW79, DOI 10.2214/AJR.16.17117
   van Laarhoven HWM, 2005, RADIOLOGY, V237, P181, DOI 10.1148/radiol.2371041397
   Waage JER, 2015, COLORECTAL DIS, V17, P124, DOI 10.1111/codi.12845
   Wagner F, 2017, MOL IMAGING BIOL, V19, P795, DOI 10.1007/s11307-017-1066-x
   Wang H, 2009, J NUCL MED, V50, P1857, DOI 10.2967/jnumed.109.064238
   Wieder HA, 2007, EUR J NUCL MED MOL I, V34, P878, DOI 10.1007/s00259-006-0292-2
   Xu YY, 2018, EUR RADIOL, V28, P3059, DOI 10.1007/s00330-018-5329-y
   Xu YY, 2015, ACAD RADIOL, V22, P1529, DOI 10.1016/j.acra.2015.08.023
   Yeo DM, 2015, J MAGN RESON IMAGING, V41, P474, DOI 10.1002/jmri.24541
   Yu J, 2017, EUR RADIOL, V27, P1848, DOI 10.1007/s00330-016-4529-6
   Yu J, 2016, J MAGN RESON IMAGING, V44, P221, DOI 10.1002/jmri.25137
   Yu XP, 2016, J HUAZHONG U SCI-MED, V36, P594, DOI 10.1007/s11596-016-1631-6
   Yu XP, 2016, ACAD RADIOL, V23, P479, DOI 10.1016/j.acra.2015.12.013
   Zhang GW, 2016, SCI REP-UK, V6, DOI 10.1038/srep38782
   Zhu HB, 2017, J MAGN RESON IMAGING, V46, P175, DOI 10.1002/jmri.25567
   Zhu L, 2017, RADIOLOGY, V284, P66, DOI 10.1148/radiol.2016160094
   Zhuang H, 2012, COLORECTAL DIS, V14, P181, DOI 10.1111/j.1463-1318.2011.02546.x
NR 129
TC 32
Z9 32
U1 1
U2 25
PU RADIOLOGICAL SOC NORTH AMERICA
PI OAK BROOK
PA 820 JORIE BLVD, OAK BROOK, IL 60523 USA
SN 0271-5333
J9 RADIOGRAPHICS
JI Radiographics
PD MAY-JUN
PY 2018
VL 38
IS 3
BP 740
EP 765
DI 10.1148/rg.2018170044
PG 26
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Radiology, Nuclear Medicine & Medical Imaging
GA GG0UO
UT WOS:000432395200008
PM 29676964
OA Bronze
DA 2023-04-20
ER

PT J
AU He, JY
   Wu, X
   Jiang, YG
   Peng, Q
   Jain, R
AF He, Jun-Yan
   Wu, Xiao
   Jiang, Yu-Gang
   Peng, Qiang
   Jain, Ramesh
TI Hookworm Detection in Wireless Capsule Endoscopy Images With Deep
   Learning
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Hookworm detection; deep learning; convolutional neural network;
   computer-aided detection; wireless capsule endoscopy
ID CONVOLUTIONAL NEURAL-NETWORKS; SEGMENTATION; CLASSIFICATION
AB As one of the most common human helminths, hookworm is a leading cause of maternal and child morbidity, which seriously threatens human health. Recently, wireless capsule endoscopy (WCE) has been applied to automatic hookworm detection. Unfortunately, it remains a challenging task. In recent years, deep convolutional neural network (CNN) has demonstrated impressive performance in various image and video analysis tasks. In this paper, a novel deep hookworm detection framework is proposed for WCE images, which simultaneously models visual appearances and tubular patterns of hookworms. This is the first deep learning framework specifically designed for hookworm detection in WCE images. Two CNN networks, namely edge extraction network and hookworm classification network, are seamlessly integrated in the proposed framework, which avoid the edge feature caching and speed up the classification. Two edge pooling layers are introduced to integrate the tubular regions induced from edge extraction network and the feature maps from hookworm classification network, leading to enhanced feature maps emphasizing the tubular regions. Experiments have been conducted on one of the largest WCE datasets with 440K WCE images, which demonstrate the effectiveness of the proposed hookworm detection framework. It significantly outperforms the state-of-the-art approaches. The high sensitivity and accuracy of the proposed method in detecting hookworms shows its potential for clinical application.
C1 [He, Jun-Yan; Wu, Xiao; Peng, Qiang] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Xipu Campus, Chengdu 611756, Sichuan, Peoples R China.
   [Jiang, Yu-Gang] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
   [Jain, Ramesh] Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA.
C3 Southwest Jiaotong University; Fudan University; University of
   California System; University of California Irvine
RP Wu, X (通讯作者)，Southwest Jiaotong Univ, Sch Informat Sci & Technol, Xipu Campus, Chengdu 611756, Sichuan, Peoples R China.
EM junyanhe1989@gmail.com; wuxiaohk@swjtu.edu.cn; ygj@fudan.edu.cn;
   qpeng@swjtu.edu.cn; jain@ics.uci.edu
OI He, Jun-Yan/0000-0002-6628-6924; Wu, Xiao/0000-0002-8322-8558
FU National Natural Science Foundation of China [61772436, 61373121,
   61272290]; Sichuan Science and Technology Innovation Seedling Fund
   [2017RZ0015, 2017018]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772436, Grant 61373121, and Grant
   61272290, and in part by the Sichuan Science and Technology Innovation
   Seedling Fund under Grant 2017RZ0015 and Grant 2017018. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Dr. Alin M. Achim. (Corresponding author: Xiao Wu.)
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Boyd S., 2004, CONVEX OPTIMIZATION, DOI 10.1017/CBO9780511804441
   Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen HH, 2013, INT CONF BIOMED, P116, DOI 10.1109/BMEI.2013.6746918
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Fenwick A, 2012, PUBLIC HEALTH, V126, P233, DOI 10.1016/j.puhe.2011.11.015
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   He Kaiming, 2016, 2016 IEEE C COMPUTER
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia Y., 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Masko D., 2015, OAIDIVAORGKTH166451
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   van Tulder G, 2016, IEEE T MED IMAGING, V35, P1262, DOI 10.1109/TMI.2016.2526687
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 42
TC 83
Z9 91
U1 1
U2 71
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PD MAY
PY 2018
VL 27
IS 5
BP 2379
EP 2392
DI 10.1109/TIP.2018.2801119
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FX7LU
UT WOS:000426272000023
PM 29470172
DA 2023-04-20
ER

PT J
AU van der Sommen, F
   Curvers, WL
   Nagengast, WB
AF van der Sommen, Fons
   Curvers, Wouter L.
   Nagengast, Wouter B.
TI Novel Developments in Endoscopic Mucosal Imaging
SO GASTROENTEROLOGY
LA English
DT Article
DE Endoscopy; Computer Aided Detection; Molecular Imaging
ID COMPUTER-AIDED DETECTION; VOLUMETRIC LASER ENDOMICROSCOPY; CONVOLUTIONAL
   NEURAL-NETWORKS; BARRETTS-ESOPHAGUS; COLORECTAL POLYPS; CT COLONOGRAPHY;
   2ND READER; SYSTEM; DIAGNOSIS; LESIONS
AB Endoscopic techniques such as high-definition and optical-chromoendoscopy have had enormous impact on endoscopy practice. Since these techniques allow assessment of most subtle morphological mucosal abnormalities, further improvements in endoscopic practice lay in increasing the detection efficacy of endoscopists. Several new developments could assist in this. First, web based training tools could improve the skills of the endoscopist for enhancing the detection and classification of lesions. Secondly, incorporation of computer aided detection will be the next step to raise endoscopic quality of the captured data. These systems will aid the endoscopist in interpreting the increasing amount of visual information in endoscopic images providing real-time objective second reading. In addition, developments in the field of molecular imaging open opportunities to add functional imaging data, visualizing biological parameters, of the gastrointestinal tract to white-light morphology imaging. For the successful implementation of abovementioned techniques, a true multi-disciplinary approach is of vital importance.
C1 [van der Sommen, Fons] Eindhoven Univ Technol, Dept Elect Engn, Eindhoven, Netherlands.
   [Curvers, Wouter L.] Catharina Hosp, Dept Gastroenterol & Hepatol, Eindhoven, Netherlands.
   [Nagengast, Wouter B.] Univ Groningen, Univ Med Ctr Groningen, Dept Gastroenterol & Hepatol, Groningen, Netherlands.
C3 Eindhoven University of Technology; Catharina Hospital; University of
   Groningen
RP Nagengast, WB (通讯作者)，Univ Med Ctr Groningen, Dept Gastroenterol & Hepatol, POB 30-001, NL-9700 RB Groningen, Netherlands.
EM w.b.nagengast@umcg.nl
OI van der Sommen, Fons/0000-0002-3593-2356
FU surgVision BV (the Netherlands)
FX The authors disclose the following: WBN, the UMCG received an
   unrestricted research grant for molecular imaging development from
   surgVision BV (the Netherlands). The remaining authors disclose no
   conflicts.
CR Atreya R, 2014, NAT MED, V20, P313, DOI 10.1038/nm.3462
   Bergman J, 2017, GASTROINTEST ENDOSC, V85, pAB48, DOI 10.1016/j.gie.2017.03.040
   Bird-Lieberman EL, 2012, NAT MED, V18, P315, DOI 10.1038/nm.2616
   Burggraaf J, 2015, NAT MED, V21, P955, DOI 10.1038/nm.3641
   Curvers WL, 2008, ENDOSCOPY, V40, P799, DOI 10.1055/s-2008-1077596
   Curvers W, 2008, GASTROENTEROLOGY, V134, P670, DOI 10.1053/j.gastro.2008.01.003
   de Vries EGE, 2011, CANCER DISCOV, V1, P25, DOI 10.1158/2159-8274.CD-11-0051
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gilbert FJ, 2008, NEW ENGL J MED, V359, P1675, DOI 10.1056/NEJMoa0803545
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Gora MJ, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.10.104001
   Gora MJ, 2013, NAT MED, V19, P238, DOI 10.1038/nm.3052
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Halligan S, 2006, GASTROENTEROLOGY, V131, P1690, DOI 10.1053/j.gastro.2006.09.051
   Harlaar NJ, 2016, LANCET GASTROENTEROL, V1, P283, DOI 10.1016/S2468-1253(16)30082-6
   Hartmans E, 2018, THERANOSTICS, V8, P1458, DOI 10.7150/thno.22033
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Joshi BP, 2017, GASTROENTEROLOGY, V152, P1002, DOI 10.1053/j.gastro.2016.12.009
   Joshi BP, 2016, GASTROENTEROLOGY, V150, P1084, DOI 10.1053/j.gastro.2016.02.075
   Joshi BP, 2016, ENDOSCOPY, V48, pA1, DOI 10.1055/s-0034-1392803
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kodashima S, 2010, WORLD J GASTROENTERO, V16, P1043, DOI 10.3748/wjg.v16.i9.1043
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Lamberts LE, 2017, CLIN CANCER RES, V23, P2730, DOI 10.1158/1078-0432.CCR-16-0437
   Leggett CL, 2016, GASTROINTEST ENDOSC, V83, P880, DOI 10.1016/j.gie.2015.08.050
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Middelburg TA, 2015, J DERMATOL SCI, V79, P64, DOI 10.1016/j.jdermsci.2015.03.017
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Nagengast WB, 2019, GUT, V68, P7, DOI 10.1136/gutjnl-2017-314953
   Ntziachristos V, 2005, NAT BIOTECHNOL, V23, P313, DOI 10.1038/nbt1074
   Petrick N, 2008, RADIOLOGY, V246, P148, DOI 10.1148/radiol.2453062161
   Pohl J, 2007, ENDOSCOPY, V39, P80, DOI 10.1055/s-2006-945045
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   Regge D, 2013, RADIOLOGY, V266, P168, DOI 10.1148/radiol.12120376
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Shin D, 2016, GASTROINTEST ENDOSC, V83, P107, DOI 10.1016/j.gie.2015.06.045
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Siddiqi AM, 2008, CANCER CYTOPATHOL, V114, P13, DOI 10.1002/cncr.23286
   Stoffel EM, 2008, CANCER PREV RES, V1, P470, DOI 10.1158/1940-6207.CAPR-08-0098
   Sturm MB, 2013, SCI TRANSL MED, V5, DOI 10.1126/scitranslmed.3004733
   Swager A, 2016, DIS ESOPHAGUS, V29, P505, DOI 10.1111/dote.12371
   Swager A, 2015, BEST PRACT RES CL GA, V29, P97, DOI 10.1016/j.bpg.2014.11.011
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P464, DOI 10.1016/j.gie.2017.01.030
   Swager AF, 2017, GASTROINTEST ENDOSC, V85, P918, DOI 10.1016/j.gie.2016.09.012
   Swager AF, 2016, GASTROINTEST ENDOSC, V83, pAB573, DOI 10.1016/j.gie.2016.03.1180
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Tjalma JJ, 2016, J NUCL MED, V57, P480, DOI 10.2967/jnumed.115.166975
   Ughi G. J., 2016, BIOMED OPT EXPRESS, V7, P660
   van Dam GM, 2011, NAT MED, V17, P1315, DOI 10.1038/nm.2472
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Wolfsen HC, 2015, GASTROINTEST ENDOSC, V82, P631, DOI 10.1016/j.gie.2015.03.1968
   Yoshida N, 2015, GASTROINTEST ENDOSC, V82, P542, DOI 10.1016/j.gie.2015.01.030
   Yun SH, 2006, NAT MED, V12, P1429, DOI 10.1038/nm1450
NR 61
TC 22
Z9 23
U1 0
U2 7
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD MAY
PY 2018
VL 154
IS 7
SI SI
BP 1876
EP 1886
DI 10.1053/j.gastro.2018.01.070
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA GG1RW
UT WOS:000432465500003
PM 29462601
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Yuan, XH
   Xie, LJ
   Abouelenien, M
AF Yuan, Xiaohui
   Xie, Lijun
   Abouelenien, Mohamed
TI A regularized ensemble framework of deep learning for cancer detection
   from multi-class, imbalanced training data
SO PATTERN RECOGNITION
LA English
DT Article
DE Ensemble; Deep learning; Imbalanced data; Cancer detection
ID DATA-SETS; CLASSIFICATION; PREDICTION
AB In medical diagnosis, e.g. bowel cancer detection, a large number of examples of normal cases exists with a much smaller number of positive cases. Such data imbalance usually complicates the learning process, especially for the classes with fewer representative examples, and results in miss detection. In this article, we introduce a regularized ensemble framework of deep learning to address the imbalanced, multi-class learning problems. Our method employs regularization that accommodates multi-class data sets and automatically determines the error bound. The regularization penalizes the classifier when it misclassifies examples that were correctly classified in the previous learning phase. Experiments are conducted using capsule endoscopy videos of bowel cancer symptoms and synthetic data sets with moderate to high imbalance ratios. The results demonstrate the superior performance of our method compared to several state-of-the-art algorithms for imbalanced, multi-class classification problems. More importantly, the sensitivity gain of the minority classes is accompanied by the improvement of the overall accuracy for all classes. With regularization, a diverse group of classifiers is created and the maximum accuracy improvement is at 24.7%. The reduction in computational cost is also noticeable and as the volume of training data increase, the gain of efficiency by our method becomes more significant. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Yuan, Xiaohui] China Univ Geosci, Coll Informat Engn, Wuhan, Hubei, Peoples R China.
   [Yuan, Xiaohui; Abouelenien, Mohamed] Univ North Texas, Dept Comp Sci & Engn, Denton, TX USA.
   [Xie, Lijun] Zhejiang Univ, Sch Med, Affiliated Hosp 2, Hangzhou, Zhejiang, Peoples R China.
C3 China University of Geosciences; University of North Texas System;
   University of North Texas Denton; Zhejiang University
RP Xie, LJ (通讯作者)，Zhejiang Univ, Sch Med, Affiliated Hosp 2, Hangzhou, Zhejiang, Peoples R China.
EM xyuan@cse.unt.edu
RI Xie, li/HGE-6052-2022; Yuan, Xiaohui/AAQ-1172-2020
OI Yuan, Xiaohui/0000-0001-6897-4563
CR [Anonymous], 1997, P 14 INT C MACHINE L
   Bache K., 2013, UCI MACHINE LEARNING
   Bae MH, 2010, EXPERT SYST APPL, V37, P4955, DOI 10.1016/j.eswa.2009.12.018
   Barua S, 2014, IEEE T KNOWL DATA EN, V26, P405, DOI 10.1109/TKDE.2012.232
   Cao H, 2013, IEEE T KNOWL DATA EN, V25, P2809, DOI 10.1109/TKDE.2013.37
   Chawla N.V., 2004, ACM SIGKDD EXPLOR NE, V6, P1, DOI DOI 10.1145/1007730.1007733
   Chawla NV, 2003, LECT NOTES ARTIF INT, V2838, P107, DOI 10.1007/978-3-540-39804-2_12
   Chen S, 2010, IEEE T NEURAL NETWOR, V21, P1624, DOI 10.1109/TNN.2010.2066988
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Debowski B, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P113, DOI 10.1109/ICMLA.2012.144
   Drown DJ, 2009, IEEE T SYST MAN CY A, V39, P1097, DOI 10.1109/TSMCA.2009.2020804
   Fernandez A, 2013, KNOWL-BASED SYST, V42, P97, DOI 10.1016/j.knosys.2013.01.018
   Fernandez-Navarro F, 2011, PATTERN RECOGN, V44, P1821, DOI 10.1016/j.patcog.2011.02.019
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Garcia S, 2012, KNOWL-BASED SYST, V25, P3, DOI 10.1016/j.knosys.2011.01.012
   Geiler O. J., 2010, INT MULT ENG COMP SC
   Ghanem Amal S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2881, DOI 10.1109/ICPR.2010.706
   Ghanem AS, 2008, INT C PATT RECOG, P436
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Jeatrakul P., 2012, 2012 INT JOINT C NEU, P1
   Karakoulas G, 1999, ADV NEUR IN, V11, P253
   Liu Y, 2011, INFORM PROCESS MANAG, V47, P617, DOI 10.1016/j.ipm.2010.11.007
   Lopez V, 2012, EXPERT SYST APPL, V39, P6585, DOI 10.1016/j.eswa.2011.12.043
   Mukherjee I, 2013, J MACH LEARN RES, V14, P437
   Murphey YL, 2007, IEEE IJCNN, P406, DOI 10.1109/IJCNN.2007.4370991
   Palade V., 2010, P INT JOINT C NEUR N, P1, DOI DOI 10.1109/IJCNN.2010.5596787
   Piras L, 2012, PATTERN RECOGN LETT, V33, P2198, DOI 10.1016/j.patrec.2012.08.003
   Qi ZQ, 2016, KNOWL-BASED SYST, V107, P54, DOI 10.1016/j.knosys.2016.05.055
   Rasti R, 2017, PATTERN RECOGN, V72, P381, DOI 10.1016/j.patcog.2017.08.004
   Saadi H. E., 2012, INT J COMPUT APPL, V57, P41
   Saberian M. J, 2011, ADV NEURAL INFORM PR, P2124
   Schapire R. E., 1999, MACH LEARN, V37, P80
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Tong LI, 2011, EXPERT SYST APPL, V38, P4222, DOI 10.1016/j.eswa.2010.09.087
   Wang S., 2010, INT JOINT C NEUR NET, P1, DOI DOI 10.1109/IJCNN.2010.5596702
   Wang S, 2012, 2012 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2012.6252696, DOI 10.1109/IJCNN.2012.6252696]
   Wang S, 2012, IEEE T SYST MAN CY B, V42, P1119, DOI 10.1109/TSMCB.2012.2187280
   Wasikowski M, 2010, IEEE T KNOWL DATA EN, V22, P1388, DOI 10.1109/TKDE.2009.187
   Weiss GM., 2004, ACM SIGKDD EXPLORATI, V6, P7, DOI DOI 10.1145/1007730.1007734
   Xiao YW, 2018, COMPUT METH PROG BIO, V153, P1, DOI 10.1016/j.cmpb.2017.09.005
   Yen SJ, 2009, EXPERT SYST APPL, V36, P5718, DOI 10.1016/j.eswa.2008.06.108
   Yu HL, 2013, NEUROCOMPUTING, V101, P309, DOI 10.1016/j.neucom.2012.08.018
   Yuan B, 2012, PROCEEDINGS OF THE 2012 IEEE INTERNATIONAL SYMPOSIUM ON RADIO-FREQUENCY INTEGRATION TECHNOLOGY (RFIT), P25, DOI 10.1109/RFIT.2012.6401602
   Yuan X., 2015, INT J GRANUL COMPUT, V4, P13, DOI DOI 10.1504/IJGCRSIS.2015.074722
   Yuan XH, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P119, DOI 10.1109/ICMLA.2012.141
   Zhou LG, 2013, KNOWL-BASED SYST, V41, P16, DOI 10.1016/j.knosys.2012.12.007
   Zhu J, 2009, STAT INTERFACE, V2, P349
NR 49
TC 98
Z9 107
U1 6
U2 105
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD MAY
PY 2018
VL 77
BP 160
EP 172
DI 10.1016/j.patcog.2017.12.017
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FX6UM
UT WOS:000426222800014
DA 2023-04-20
ER

PT J
AU Ali, H
   Yasmin, M
   Sharif, M
   Rehmani, MH
AF Ali, Hussam
   Yasmin, Mussarat
   Sharif, Muhammad
   Rehmani, Mubashir Husain
TI Computer assisted gastric abnormalities detection using hybrid texture
   descriptors for chromoendoscopy images
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE Chromoendoscopy; Co-occurrence matrix; Filter bank; Texture analysis;
   Gabor filter; Stomach cancer
ID AUTOMATIC DETECTION; FEATURE-EXTRACTION; ENDOSCOPY; DIAGNOSIS;
   CLASSIFICATION; FEATURES; LESIONS
AB Background and Objective: The early diagnosis of stomach cancer can be performed by using a proper screening procedure. Chromoendoscopy (CH) is an image-enhanced video endoscopy technique, which is used for inspection of the gastrointestinal-tract by spraying dyes to highlight the gastric mucosal structures. An endoscopy session can end up with generating a large number of video frames. Therefore, inspection of every individual endoscopic-frame is an exhaustive task for the medical experts. In contrast with manual inspection, the automated analysis of gastroenterology images using computer vision based techniques can provide assistance to endoscopist, by finding out abnormal frames from the whole endoscopic sequence.
   Methods: In this paper, we have presented a new feature extraction method named as Gabor-based gray-level co-occurrence matrix (G2LCM) for computer-aided detection of CH abnormal frames. It is a hybrid texture extraction approach which extracts a combination both local and global texture descriptors. Moreover, texture information of a CH image is represented by computing the gray level co-occurrence matrix of Gabor filters responses. Furthermore, the second-order statistics of these co-occurrence matrices are computed to represent images' texture.
   Results: The obtained results show the possibility to correctly classifying abnormal from normal frames, with sensitivity, specificity, accuracy, and area under the curve as 91%, 82%, 87% and 0.91 respectively, by using a support vector machine classifier and G2LCM texture features.
   Conclusion: It is apparent from results that the proposed system can be used for providing aid to the gastroenterologist in the screening of the gastric tract. Ultimately, the time taken by an endoscopic procedure will be sufficiently reduced. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Ali, Hussam; Yasmin, Mussarat; Sharif, Muhammad] COMSATS Inst Informat Technol Wah, Wah Cantt, Pakistan.
   [Rehmani, Mubashir Husain] WIT, TSSG, Waterford, Ireland.
C3 COMSATS University Islamabad (CUI); South East Technological University
   (SETU)
RP Ali, H (通讯作者)，COMSATS Inst Informat Technol Wah, Wah Cantt, Pakistan.
EM hussam@ciitwah.edu.pk
RI Sharif, Muhammad/ACD-2598-2022; Ali, Hussam/I-4217-2016; Sharif,
   Muhammad/AAB-8376-2022; Rehmani, Mubashir Husain/E-8059-2014; Yasmin,
   Mussarat/HPC-9476-2023
OI Sharif, Muhammad/0000-0002-7258-8400; Ali, Hussam/0000-0002-9520-5185;
   Rehmani, Mubashir Husain/0000-0002-3565-7390; Sharif,
   Muhammad/0000-0002-1355-2168
CR Ali H, 2017, COMPUT BIOL MED, V88, P84, DOI 10.1016/j.compbiomed.2017.07.002
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Andre B, 2010, LECT NOTES COMPUT SC, V5853, P18, DOI 10.1007/978-3-642-11769-5_2
   Cho WY, 2011, CLIN ENDOSC, V44, P65, DOI 10.5946/ce.2011.44.2.65
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Constantinescu A. F., 2015, Applied Medical Informatics, V36, P31
   Dahal A, 2015, INT WORK CONTENT MUL
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Iakovidis DK, 2015, IEEE ENG MED BIO, P731, DOI 10.1109/EMBC.2015.7318466
   Janse M. H. A., 2016, P SOC PHOTO-OPT INS, V9785
   Karargyris A, 2009, I S BIOMED IMAGING, P554, DOI 10.1109/ISBI.2009.5193107
   Koshy NE, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1725, DOI 10.1109/ECS.2015.7124881
   Lau KC, 2016, IEEE T IND INFORM, V12, P2365, DOI 10.1109/TII.2016.2576960
   Lee TC, 2013, IEEE ENG MED BIO, P4430, DOI 10.1109/EMBC.2013.6610529
   Leggett CL, 2015, TECH GASTROINTEST EN, V17, P161, DOI 10.1016/j.tgie.2016.01.001
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Liu DY, 2015, J MED IMAG HEALTH IN, V5, P296, DOI 10.1166/jmihi.2015.1390
   Lopez-Ceron M, 2013, GASTROINTEST ENDOSC, V77, P542, DOI 10.1016/j.gie.2012.11.033
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Martins MM, 2010, IEEE ENG MED BIO, P5557, DOI 10.1109/IEMBS.2010.5626780
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Nam JH, 2012, CANCER-AM CANCER SOC, V118, P4953, DOI 10.1002/cncr.27495
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Riaz F., 2015, IEEE J BIOMED HLTH I
   Riaz F, 2013, IEEE T BIO-MED ENG, V60, P1191, DOI 10.1109/TBME.2012.2230174
   Riaz F, 2012, IEEE T BIO-MED ENG, V59, P2893, DOI 10.1109/TBME.2012.2212440
   Serpa-Andrade L, 2015, IEEE INT AUT MEET
   Sevo I, 2016, COMPUT BIOL MED, V72, P138, DOI 10.1016/j.compbiomed.2016.03.017
   Siegel RL, 2015, CA-CANCER J CLIN, V65, P5, DOI 10.3322/caac.21254
   Sousa A, 2009, IEEE IMAGE PROC, P681, DOI 10.1109/ICIP.2009.5414082
   Sweeney S. M., 2014, AM ASS CANC RES, P126
   Yuan Y., 2015, IEEE J BIOMED HEALTH, V2194, P1, DOI DOI 10.1109/ICSPCC.2015.7338853
   Yuan YX, 2015, IEEE INT CONF ROBOT, P1310, DOI 10.1109/ICRA.2015.7139360
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
NR 36
TC 29
Z9 30
U1 0
U2 75
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD APR
PY 2018
VL 157
BP 39
EP 47
DI 10.1016/j.cmpb.2018.01.013
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA FX2NJ
UT WOS:000425897400006
PM 29477434
DA 2023-04-20
ER

PT J
AU Shao, F
   Huang, Q
   Wang, C
   Qiu, LJ
   Hu, YG
   Zha, SY
AF Shao, Feng
   Huang, Qiang
   Wang, Chen
   Qiu, LuJun
   Hu, Yuan Guo
   Zha, Shu Yun
TI Artificial Neural Networking Model for the Prediction of Early Occlusion
   of Bilateral Plastic Stent Placement for Inoperable Hilar
   Cholangiocarcinoma
SO SURGICAL LAPAROSCOPY ENDOSCOPY & PERCUTANEOUS TECHNIQUES
LA English
DT Article
DE stent occlusion; endoscopic retrograde cholangiopancreatography; hilar
   cholangiocarcinoma
ID HEPATOCELLULAR-CARCINOMA; BILIARY OBSTRUCTION; METAL STENTS; SURVIVAL;
   DISEASE; CANCER; STAGE
AB Background:This study aimed to determine whether the back-propagation artificial neural network (BP-ANN) model could be constructed to accurately in predicting early occlusion of bilateral plastic stent placement for inoperable hilar cholangiocarcinoma (HCA).Methods:A total of 288 patients from the An Hui provincial Hospital were randomly divided into the training cohort (80%) and the internal testing cohort (20%). The predictive accuracy of the BP-ANN for predicting early occlusion of bilateral plastic stent placement of inoperable HCA was measured by the area under the curve (AUC) on receiver operating characteristic (ROC) curve analysis. The results were compared with those obtained using the conventional multivariate logistic regression analysis.Results:Multivariate analysis revealed that cancer stage (P=0.005) and Bismuth stage (P=0.003) were independently and significantly associated with early stent occlusion. In the training cohort, BP-ANN had larger AUC than the multivariate logistic regression model (P=0.00049). In the internal testing cohort, the AUC of the BP-ANN had larger AUC than the multivariate logistic regression model (P=0.02142).Conclusions:This study showed that the BP-ANN model is a good predictive tool. It performed better than the conventional and commonly used statistical model in predicting early occlusion of bilateral plastic stent placement for inoperable HCA.
C1 [Shao, Feng; Huang, Qiang; Wang, Chen; Qiu, LuJun; Hu, Yuan Guo; Zha, Shu Yun] Anhui Med Univ, Anhui Prov Hosp, Dept Gen Surg, Hefei 230001, Anhui, Peoples R China.
C3 Anhui Medical University
RP Huang, Q (通讯作者)，Anhui Med Univ, Anhui Prov Hosp, Dept Gen Surg, Hefei 230001, Anhui, Peoples R China.
EM Tagsmile1985@163.com
CR Ansari D, 2013, AM J SURG, V205, P1, DOI 10.1016/j.amjsurg.2012.05.032
   BAXT WG, 1991, ANN INTERN MED, V115, P843, DOI 10.7326/0003-4819-115-11-843
   Burke HB, 1997, CANCER, V79, P857, DOI 10.1002/(SICI)1097-0142(19970215)79:4<857::AID-CNCR24>3.0.CO;2-Y
   Costa L, 2001, BIOMATERIALS, V22, P3113, DOI 10.1016/S0142-9612(01)00060-6
   Costamagna G, 2004, J CLIN GASTROENTEROL, V38, P59, DOI 10.1097/00004836-200401000-00013
   CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2
   Cucchetti A, 2007, GUT, V56, P253, DOI 10.1136/gut.2005.084434
   Cucchetti A, 2010, J HEPATOL, V52, P880, DOI 10.1016/j.jhep.2009.12.037
   de Groen PC, 1999, NEW ENGL J MED, V341, P1368, DOI 10.1056/NEJM199910283411807
   HANLEY JA, 1989, CRIT REV DIAGN IMAG, V29, P307
   Jovanovic P, 2014, GASTROINTEST ENDOSC, V80, P260, DOI 10.1016/j.gie.2014.01.023
   JUTTIJUDATA P, 1984, AM J SURG, V147, P360, DOI 10.1016/0002-9610(84)90167-3
   Khashab MA, 2012, DIGEST DIS SCI, V57, P2446, DOI 10.1007/s10620-012-2178-4
   LEUNG JWC, 1988, GASTROINTEST ENDOSC, V34, P19, DOI 10.1016/S0016-5107(88)71223-7
   Levy MJ, 2004, CLIN GASTROENTEROL H, V2, P273, DOI 10.1016/S1542-3565(04)00055-2
   MATSUDA Y, 1991, AM J GASTROENTEROL, V86, P843
   Paik WH, 2009, GASTROINTEST ENDOSC, V69, P55, DOI 10.1016/j.gie.2008.04.005
   Qiao GL, 2014, J GASTROEN HEPATOL, V29, P2014, DOI 10.1111/jgh.12672
   Siddiqui A, 2013, CLIN GASTROENTEROL H, V11, P1169, DOI 10.1016/j.cgh.2013.05.035
   Snow PB, 1999, UROLOGY, V54, P787, DOI 10.1016/S0090-4295(99)00327-1
   Vienne A, 2010, GASTROINTEST ENDOSC, V72, P728, DOI 10.1016/j.gie.2010.06.040
   Zeidenberg M, 1990, NEURAL NETWORKS ARTI
NR 22
TC 5
Z9 6
U1 0
U2 9
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 1530-4515
EI 1534-4908
J9 SURG LAPARO ENDO PER
JI Surg. Laparosc. Endosc. Pct. Tech.
PD APR
PY 2018
VL 28
IS 2
BP E54
EP E58
DI 10.1097/SLE.0000000000000502
PG 5
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA GC0CL
UT WOS:000429444200004
PM 29252936
DA 2023-04-20
ER

PT J
AU Ghosh, T
   Fattah, SA
   Wahid, KA
   Zhu, WP
   Ahmad, MO
AF Ghosh, Tonmoy
   Fattah, Shaikh Anowarul
   Wahid, Khan A.
   Zhu, Wei-Ping
   Ahmad, M. Omair
TI Cluster based statistical feature extraction method for automatic
   bleeding detection in wireless capsule endoscopy video
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Bleeding detection; Bleeding zone delineation; Feature extraction;
   Unsupervised clustering; Wireless capsule endoscopy
AB Wireless capsule endoscopy (WCE) is capable of demonstrating the entire gastrointestinal tract at an expense of exhaustive reviewing process for detecting bleeding disorders. The main objective is to develop an automatic method for identifying the bleeding frames and zones from WCE video. Different statistical features are extracted from the overlapping spatial blocks of the preprocessed WCE image in a transformed color plane containing green to red pixel ratio. The unique idea of the proposed method is to first perform unsupervised clustering of different blocks for obtaining two clusters and then extract cluster based features (CBFs). Finally, a global feature consisting of the CBFs and differential CBE is used to detect bleeding frame via supervised classification. In order to handle continuous WCE video, a post-processing scheme is introduced utilizing the feature trends in neighboring frames. The CBF along with some morphological operations is employed to identify bleeding zones. Based on extensive experimentation on several WCE videos, it is found that the proposed method offers significantly better performance in comparison to some existing methods in terms of bleeding detection accuracy, sensitivity, specificity and precision in bleeding zone detection. It is found that the bleeding detection performance obtained by using the proposed CBF based global feature is better than the feature extracted from the non-clustered image. The proposed method can reduce the burden of physicians in investigating WCE video to detect bleeding frame and zone with a high level of accuracy.
C1 [Ghosh, Tonmoy; Fattah, Shaikh Anowarul] Bangladesh Univ Engn & Technol, Dept Elect & Elect Engn, Dhaka, Bangladesh.
   [Wahid, Khan A.] Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK, Canada.
   [Zhu, Wei-Ping; Ahmad, M. Omair] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
C3 Bangladesh University of Engineering & Technology (BUET); University of
   Saskatchewan; Concordia University - Canada
RP Fattah, SA (通讯作者)，Bangladesh Univ Engn & Technol, Dept Elect & Elect Engn, Dhaka, Bangladesh.
EM fattah@eee.buet.ac.bd
RI Ghosh, Tonmoy/AAP-7360-2020
OI Ghosh, Tonmoy/0000-0003-1460-2267; Zhu, Wei-Ping/0000-0001-7955-7044
CR Adler DG., 2003, HOSP PHYS, V39, P14
   ALTMAN DG, 1994, BRIT MED J, V308, P1552, DOI 10.1136/bmj.308.6943.1552
   [Anonymous], 2014, INT C INFORMATICS EL
   Conversano F., 2014, P IEEE MED MEAS APPL, P1
   Conversano F, 2011, ACAD RADIOL, V18, P461, DOI 10.1016/j.acra.2010.11.015
   Dong G, 2005, IEEE T NEURAL NETWOR, V16, P925, DOI 10.1109/TNN.2005.849822
   Figueiredo IN, 2013, COMP M BIO BIO E-IV, V1, P198, DOI 10.1080/21681163.2013.796164
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ghosh T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1293, DOI 10.1109/ICDSP.2015.7252090
   Ghosh T, 2014, IEEE ENG MED BIO, P4683, DOI 10.1109/EMBC.2014.6944669
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Kandwal R., INT J ADV RES COMPUT, V4
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kundu AK, 2015, 2015 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (WIECON-ECE), P455, DOI 10.1109/WIECON-ECE.2015.7443966
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Liu JG, 2009, OPTIM ENG, V10, P289, DOI 10.1007/s11081-008-9066-y
   Mackiewicz M., 2008, P SPIE MED IM, P1
   Novozamsky A, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.12.126007
   Ramaraj M, 2014, J MED IMAG HEALTH IN, V4, P500, DOI 10.1166/jmihi.2014.1297
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Sainju S, 2013, CAN CON EL COMP EN, P539
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   SPATH H, 1985, CLUSTER DISSECTION A
   Suman S., 2016, INT C SIGN INF PROC, P1
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   Yuan Y., 2015, IEEE J BIOMED HEALTH, V2194, P1, DOI DOI 10.1109/ICSPCC.2015.7338853
NR 27
TC 14
Z9 14
U1 1
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD MAR 1
PY 2018
VL 94
BP 41
EP 54
DI 10.1016/j.compbiomed.2017.12.014
PG 14
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA FX6XF
UT WOS:000426229900005
PM 29407997
DA 2023-04-20
ER

PT J
AU Ichimasa, K
   Kudo, S
   Mori, Y
   Misawa, M
   Matsudaira, S
   Kouyama, Y
   Baba, T
   Hidaka, E
   Wakamura, K
   Hayashi, T
   Kudo, T
   Ishigaki, T
   Yagawa, Y
   Nakamura, H
   Takeda, K
   Haji, A
   Hamatani, S
   Mori, K
   Ishida, F
   Miyachi, H
AF Ichimasa, Katsuro
   Kudo, Shin-ei
   Mori, Yuichi
   Misawa, Masashi
   Matsudaira, Shingo
   Kouyama, Yuta
   Baba, Toshiyuki
   Hidaka, Eiji
   Wakamura, Kunihiko
   Hayashi, Takemasa
   Kudo, Toyoki
   Ishigaki, Tomoyuki
   Yagawa, Yusuke
   Nakamura, Hiroki
   Takeda, Kenichi
   Haji, Amyn
   Hamatani, Shigeharu
   Mori, Kensaku
   Ishida, Fumio
   Miyachi, Hideyuki
TI Artificial intelligence may help in predicting the need for additional
   surgery after endoscopic resection of T1 colorectal cancer
SO ENDOSCOPY
LA English
DT Article
ID LYMPH-NODE METASTASIS; CLINICAL-PRACTICE GUIDELINES; AIDED DIAGNOSTIC
   SYSTEM; SUPPORT VECTOR MACHINE; RECTAL-CANCER; RISK-FACTORS; CARCINOMA;
   METAANALYSIS; LESIONS; COLON
AB Background and study aims Decisions concerning additional surgery after endoscopic resection of T1 colorectal cancer (CRC) are difficult because preoperative prediction of lymph node metastasis (LNM) is problematic. We investigated whether artificial intelligence can predict LNM presence, thus minimizing the need for additional surgery.
   Patients and methods Data on 690 consecutive patients with T1 CRCs that were surgically resected in 2001 - 2016 were retrospectively analyzed. We divided patients into two groups according to date: data from 590 patients were used for machine learning for the artificial intelligence model, and the remaining 100 patients were included for model validation. The artificial intelligence model analyzed 45 clinicopathological factors and then predicted positivity or negativity for LNM. Operative specimens were used as the gold standard for the presence of LNM. The artificial intelligence model was validated by calculating the sensitivity, specificity, and accuracy for predicting LNM, and comparing these data with those of the American, European, and Japanese guidelines.
   Results Sensitivity was 100% (95% confidence interval [CI] 72% to 100 %) in all models. Specificity of the artificial intelligence model and the American, European, and Japanese guidelines was 66% (95%CI 56% to 76%), 44% (95 %CI 34% to 55%), 0% (95%CI 0% to 3%), and 0% (95 %CI 0% to 3%), respectively; and accuracy was 69% (95 %CI 59% to 78%), 49% (95 %CI 39% to 59 %), 9% (95%CI 4% to 16%), and 9% (95 %CI 4%-16 %), respectively. The rates of unnecessary additional surgery attributable to misdiagnosing LNM-negative patients as having LNM were: 77% (95 %CI 62% to 89 %) for the artificial intelligence model, and 85% (95 %CI 73% to 93%; P < 0.001), 91% (95 %CI 84% to 96%; P < 0.001), and 91% (95 %CI 84% to 96 %; P < 0.001) for the American, European, and Japanese guidelines, respectively.
   Conclusions Compared with current guidelines, artificial intelligence significantly reduced unnecessary additional surgery after endoscopic resection of T1 CRC without missing LNM positivity.
C1 [Ichimasa, Katsuro; Kudo, Shin-ei; Mori, Yuichi; Misawa, Masashi; Matsudaira, Shingo; Kouyama, Yuta; Baba, Toshiyuki; Hidaka, Eiji; Wakamura, Kunihiko; Hayashi, Takemasa; Kudo, Toyoki; Ishigaki, Tomoyuki; Yagawa, Yusuke; Nakamura, Hiroki; Takeda, Kenichi; Ishida, Fumio; Miyachi, Hideyuki] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Yokohama, Kanagawa, Japan.
   [Haji, Amyn] Kings Coll Hosp London, Kings Inst Therapeut Endoscopy, London, England.
   [Hamatani, Shigeharu] Jikei Univ, Dept Pathol, Sch Med, Tokyo, Japan.
   [Mori, Kensaku] Nagoya Univ, Informat & Commun, Nagoya, Aichi, Japan.
   [Miyachi, Hideyuki] Miyachi Clin, Kakogawa, Hyogo, Japan.
C3 Showa University; King's College Hospital NHS Foundation Trust; King's
   College Hospital; Jikei University; Nagoya University
RP Kudo, S (通讯作者)，Showa Univ, Yokohama Northern Hosp, Digest Dis Ctr, Tsuzuki Ku, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
EM kudos@med.showa-u.ac.jp
RI Ichimasa, Katsuro/AAP-6941-2021; Misawa, Masashi/H-9004-2019; Mori,
   Yuichi/AAU-5406-2020
OI Misawa, Masashi/0000-0002-8520-2036; HAJI, AMYN/0000-0003-0866-981X;
   Mori, Kensaku/0000-0002-0100-4797; Mori, Yuichi/0000-0003-2262-0334
FU Japan Society for the Promotion of Science [17K15972]; Grants-in-Aid for
   Scientific Research [17K15972, 17K15971, 17H05305] Funding Source: KAKEN
FX The authors thank Chiaki Nishimura for advising on statistical analyses,
   and Takashi Wakisaka and Kaneda Takashi for helping to develop the
   artificial intelligence model. This study was supported by a
   Grant-in-Aid for Scientific Research (Number 17K15972) from the Japan
   Society for the Promotion of Science. We also thank Tom Buckle, MSc,
   from Edanz Group (www.edanzediting.com/ac) for editing a draft of this
   manuscript.
CR [Anonymous], 2017, NCCN CLIN PRACT GUID
   [Anonymous], 2010, WHO CLASSIFICATION T
   Beaton C, 2013, COLORECTAL DIS, V15, P788, DOI 10.1111/codi.12129
   Bosch SL, 2013, ENDOSCOPY, V45, P827, DOI 10.1055/s-0033-1344238
   COVERLIZZA S, 1989, CANCER-AM CANCER SOC, V64, P1937, DOI 10.1002/1097-0142(19891101)64:9<1937::AID-CNCR2820640929>3.0.CO;2-X
   Glimelius B, 2013, ANN ONCOL, V24, P81, DOI 10.1093/annonc/mdt240
   Ichimasa K, 2017, MOL CLIN ONCOL, V6, P517, DOI 10.3892/mco.2017.1172
   Iversen LH, 2010, COLORECTAL DIS, V12, pE31, DOI 10.1111/j.1463-1318.2009.01888.x
   Kitamura K, 1997, HEPATO-GASTROENTEROL, V44, P108
   Kobayashi H, 2011, J GASTROENTEROL, V46, P203, DOI 10.1007/s00535-010-0341-2
   Kobayashi Y, 2011, INT J COLORECTAL DIS, V26, P1531, DOI 10.1007/s00384-011-1246-0
   Labianca R, 2013, ANN ONCOL, V24, P64, DOI 10.1093/annonc/mdt354
   Lee W, 2003, SURG ENDOSC, V17, P1283, DOI 10.1007/s00464-002-8814-x
   Macias-Garcia F, 2015, INT J COLORECTAL DIS, V30, P761, DOI 10.1007/s00384-015-2164-3
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Miyachi H, 2016, J GASTROEN HEPATOL, V31, P1126, DOI 10.1111/jgh.13257
   Moons KGM, 2015, ADV ANAT PATHOL, V22, P303, DOI 10.1097/PAP.0000000000000072
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Mourao-Miranda J, 2005, NEUROIMAGE, V28, P980, DOI 10.1016/j.neuroimage.2005.06.070
   Nascimbeni R, 2002, DIS COLON RECTUM, V45, P200, DOI 10.1007/s10350-004-6147-7
   Overwater A, 2018, GUT, V67, P284, DOI 10.1136/gutjnl-2015-310961
   Paulson EC, 2008, ANN SURG, V248, P675, DOI 10.1097/SLA.0b013e318187a757
   Takeuchi Y, 2010, AM J GASTROENTEROL, V105, P314, DOI 10.1038/ajg.2009.547
   TANAKA S, 1995, J GASTROENTEROL, V30, P710, DOI 10.1007/BF02349636
   Tateishi Y, 2010, MODERN PATHOL, V23, P1068, DOI 10.1038/modpathol.2010.88
   Wada H, 2015, J GASTROENTEROL, V50, P727, DOI 10.1007/s00535-015-1057-0
   Wada H, 2013, INT J CLIN ONCOL, V18, P1025, DOI 10.1007/s10147-012-0490-9
   Watanabe T, 2018, INT J CLIN ONCOL, V23, P1, DOI 10.1007/s10147-017-1101-6
   Wu HY, 2016, SCI REP-UK, V6, DOI 10.1038/srep27041
   Yang HX, 2013, BRIT J CANCER, V109, P1109, DOI 10.1038/bjc.2013.379
NR 30
TC 64
Z9 67
U1 5
U2 30
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD MAR
PY 2018
VL 50
IS 3
BP 230
EP 240
DI 10.1055/s-0043-122385
PG 11
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA GE5NR
UT WOS:000431269800024
PM 29272905
DA 2023-04-20
ER

PT J
AU Waljee, AK
   Liu, B
   Sauder, K
   Zhu, J
   Govani, SM
   Stidham, RW
   Higgins, PDR
AF Waljee, A. K.
   Liu, B.
   Sauder, K.
   Zhu, J.
   Govani, S. M.
   Stidham, R. W.
   Higgins, P. D. R.
TI Predicting corticosteroid-free endoscopic remission with vedolizumab in
   ulcerative colitis
SO ALIMENTARY PHARMACOLOGY & THERAPEUTICS
LA English
DT Article
ID INFLAMMATORY-BOWEL-DISEASE; NETWORK METAANALYSIS; AGENTS; EFFICACY;
   THERAPY
AB Background: Vedolizumab is an effective therapy for ulcerative colitis (UC), but costly and slow to work. New clinical responses occur after 30 weeks of therapy.
   Aims: To enable physicians, patients, and insurers to predict whether a patient with UC will respond to vedolizumab at an early time point after starting therapy.
   Methods: The clinical study data request website provided the phase 3 clinical trial data for vedolizumab. Random forest models were trained on 70% and tested on 30% of the data to predict corticosteroid-free endoscopic remission at week 52. Models were constructed using baseline data, or data through week 6 of vedolizumab therapy from 491 subjects.
   Results: The AuROC for prediction of corticosteroid-free endoscopic remission at week 52 using baseline data was only 0.62 (95% CI: 0.53-0.72), but was 0.73 (95% CI: 0.65-0.82) when using data through week 6. A total of 47% of subjects were predicted to be remitters, and 59% of these subjects achieved corticosteroid-free endoscopic remission, in contrast to 21% of the predicted non-remitters. A week 6 prediction using FCP <= 234 mu g/g was nearly as accurate.
   Conclusions: A machine learning algorithm using laboratory data through week 6 of vedolizumab therapy was able to accurately identify which UC patients would achieve corticosteroid-free endoscopic remission on vedolizumab at week 52. Application of this algorithm could have significant implications for clinical decisions on whom to continue on this costly medication when the benefits of the vedolizumab are not clinically apparent in the first 6 weeks of therapy.
C1 [Waljee, A. K.] VA Ann Arbor Hlth Care Syst, VA Ctr Clin Management Res, Ann Arbor, MI USA.
   [Waljee, A. K.; Sauder, K.; Govani, S. M.; Stidham, R. W.; Higgins, P. D. R.] Univ Michigan Hlth Syst, Dept Internal Med, Div Gastroenterol & Hepatol, Ann Arbor, MI USA.
   [Liu, B.; Zhu, J.] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA.
C3 US Department of Veterans Affairs; Veterans Health Administration (VHA);
   VA Ann Arbor Healthcare System; University of Michigan System;
   University of Michigan; University of Michigan System; University of
   Michigan
EM awaljee@med.umich.edu
RI Waljee, Akbar K/G-2067-2010
OI Waljee, Akbar K/0000-0003-1964-8790
FU United States Department of Veterans Affairs [CDA 11-217]; National
   Institutes of Health
FX United States Department of Veterans Affairs, Grant/Award Number: CDA
   11-217; National Institutes of Health
CR Amiot A, 2017, ALIMENT PHARM THER, V46, P310, DOI 10.1111/apt.14167
   [Anonymous], ENTV VED INJ 300MG S
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cohen BL, 2017, BMJ-BRIT MED J, V357, DOI 10.1136/bmj.j2505
   Dulai PS, 2016, AM J GASTROENTEROL, V111, P1147, DOI 10.1038/ajg.2016.236
   Feagan BG, 2013, NEW ENGL J MED, V369, P699, DOI 10.1056/NEJMoa1215734
   Furfaro F, 2017, EXPERT REV CLIN IMMU, V13, P457, DOI 10.1080/1744666X.2017.1279055
   Loftus EV, 2004, GASTROENTEROLOGY, V126, P1504, DOI 10.1053/j.gastro.2004.01.063
   Olivera P, 2017, EXPERT REV CLIN IMMU, V13, P693, DOI 10.1080/1744666X.2017.1291342
   Romero J, 2016, HIIJ, V5, P1
   Stallmach A, 2016, ALIMENT PHARM THER, V44, P1199, DOI 10.1111/apt.13813
   Stidham RW, 2014, ALIMENT PHARM THER, V39, P1349, DOI 10.1111/apt.12749
   Stidham RW, 2014, ALIMENT PHARM THER, V39, P660, DOI 10.1111/apt.12644
NR 13
TC 55
Z9 55
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0269-2813
EI 1365-2036
J9 ALIMENT PHARM THER
JI Aliment. Pharmacol. Ther.
PD MAR
PY 2018
VL 47
IS 6
BP 763
EP 772
DI 10.1111/apt.14510
PG 10
WC Gastroenterology & Hepatology; Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Pharmacology & Pharmacy
GA FW2EN
UT WOS:000425115500006
PM 29359519
OA Green Accepted, Green Published, Bronze
DA 2023-04-20
ER

PT J
AU Togo, R
   Ishihara, K
   Mabe, K
   Oizumi, H
   Ogawa, T
   Kato, M
   Sakamoto, N
   Nakajima, S
   Asaka, M
   Haseyama, M
AF Togo, Ren
   Ishihara, Kenta
   Mabe, Katsuhiro
   Oizumi, Harufumi
   Ogawa, Takahiro
   Kato, Mototsugu
   Sakamoto, Naoya
   Nakajima, Shigemi
   Asaka, Masahiro
   Haseyama, Miki
TI Preliminary study of automatic gastric cancer risk classification from
   photofluorography
SO WORLD JOURNAL OF GASTROINTESTINAL ONCOLOGY
LA English
DT Article
DE Gastric cancer; Helicobacter pylori; Mass screening; Photofluorography;
   Automatic data processing
ID HELICOBACTER-PYLORI INFECTION; ENDOSCOPIC SUBMUCOSAL DISSECTION; ABC D
   STRATIFICATION; X-RAY; PREVALENCE; PEPSINOGEN; ANTIBODY; JAPANESE;
   ASSOCIATION; CARCINOMA
AB AIM
   To perform automatic gastric cancer risk classification using photofluorography for realizing effective mass screening as a preliminary study.
   METHODS
   We used data for 2100 subjects including X-ray images, pepsinogen. and. levels, PG I/PG II ratio, Helicobacter pylori (H. pylori) antibody, H. pylori eradication history and interview sheets. We performed two-stage classification with our system. In the first stage, H. pylori infection status classification was performed, and H. pylori -infected subjects were automatically detected. In the second stage, we performed atrophic level classification to validate the effectiveness of our system.
   RESULTS
   Sensitivity, specificity and Youden index (YI) of H. pylori infection status classification were 0.884, 0.895 and 0.779, respectively, in the first stage. In the second stage, sensitivity, specificity and YI of atrophic level classification for H. pylori -infected subjects were 0.777, 0.824 and 0.601, respectively.
   CONCLUSION
   Although further improvements of the system are needed, experimental results indicated the effectiveness of machine learning techniques for estimation of gastric cancer risk.
C1 [Togo, Ren; Ishihara, Kenta; Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan.
   [Mabe, Katsuhiro; Kato, Mototsugu] Natl Hosp Org Hakodate Hosp, Dept Gastroenterol, 18-16 Kawahara Cho, Sapporo, Hokkaido 0418512, Japan.
   [Oizumi, Harufumi] Yamagata City Med Assoc, Med Examinat Ctr, Yamagata 9902473, Japan.
   [Sakamoto, Naoya] Hokkaido Univ, Grad Sch Med, Dept Gastroenterol, Sapporo, Hokkaido 0608648, Japan.
   [Nakajima, Shigemi] Japan Community Healthcare Org Shiga Hosp, Dept Gen Med, Otsu, Shiga 5200846, Japan.
   [Asaka, Masahiro] Hlth Sci Univ Hokkaido, Sapporo, Hokkaido 0610293, Japan.
C3 Hokkaido University; Hokkaido University; Health Sciences University of
   Hokkaido
RP Mabe, K (通讯作者)，Natl Hosp Org Hakodate Hosp, Dept Gastroenterol, 18-16 Kawahara Cho, Sapporo, Hokkaido 0418512, Japan.
EM kmabe@hnh.hosp.go.jp
RI Nakajima, Shigemi/GQA-3579-2022; Nakajima, Shigemi/ABH-2265-2021;
   Haseyama, Miki/A-6163-2012
OI Nakajima, Shigemi/0000-0003-1386-0985; Ogawa,
   Takahiro/0000-0001-5332-8112
FU JSPS KAKENHI [JP17H01744]
FX Supported by JSPS KAKENHI Grant, No. JP17H01744.
CR Akaho S., 2007, ARXIV COMPUT SCI E P, V40, P263
   [Anonymous], 2012, LANCET, V379, P1851, DOI 10.1016/S0140-6736(12)60790-9
   Brown LM, 2000, EPIDEMIOL REV, V22, P283, DOI 10.1093/oxfordjournals.epirev.a018040
   Chen HF, 2009, CHEM BIOL DRUG DES, V74, P142, DOI 10.1111/j.1747-0285.2009.00840.x
   Choi KS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050041
   Compare D, 2014, WORLD J GASTROENTERO, V20, P13681, DOI 10.3748/wjg.v20.i38.13681
   CORREA P, 1990, CANCER-AM CANCER SOC, V66, P2569, DOI 10.1002/1097-0142(19901215)66:12<2569::AID-CNCR2820661220>3.0.CO;2-I
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Ford AC, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g3174
   FORMAN D, 1991, BRIT MED J, V302, P1302, DOI 10.1136/bmj.302.6788.1302
   Fukase K, 2008, LANCET, V372, P392, DOI 10.1016/S0140-6736(08)61159-9
   Hamashima C, 2008, JPN J CLIN ONCOL, V38, P259, DOI 10.1093/jjco/hyn017
   Hamashima C, 2016, WORLD J GASTROENTERO, V22, P6385, DOI 10.3748/wjg.v22.i28.6385
   Ishihara K., 2016, ITE T MEDIA TECHNOL, V4, P337, DOI DOI 10.3169/MTA.4.337
   Itoh T, 2015, JPN J RADIOL, V33, P636, DOI 10.1007/s11604-015-0469-3
   Kudo T, 2011, WORLD J GASTROENTERO, V17, P4793, DOI 10.3748/wjg.v17.i43.4793
   Lee HY, 2010, WORLD J GASTROENTERO, V16, P245, DOI 10.3748/wjg.v16.i2.245
   Lee S, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000000533
   Matsuo T, 2011, HELICOBACTER, V16, P415, DOI 10.1111/j.1523-5378.2011.00889.x
   Miura K, 2016, DIGESTION, V94, P17, DOI 10.1159/000446771
   Mizuno S, 2010, DIGEST DIS SCI, V55, P3132, DOI 10.1007/s10620-010-1154-0
   Nashimoto A, 2013, GASTRIC CANCER, V16, P1, DOI 10.1007/s10120-012-0163-4
   Ono S, 2012, DIGESTION, V86, P59, DOI 10.1159/000339176
   Peleteiro B, 2015, DIGEST DIS SCI, V60, P2470, DOI 10.1007/s10620-015-3624-x
   Shichijo S, 2017, J GASTROEN HEPATOL, V32, P1581, DOI 10.1111/jgh.13764
   Shimoyama T, 2012, GASTRIC CANCER, V15, P331, DOI 10.1007/s10120-012-0141-x
   Sugano K, 2015, BEST PRACT RES CL GA, V29, P895, DOI 10.1016/j.bpg.2015.09.013
   Ueda J, 2014, HELICOBACTER, V19, P105, DOI 10.1111/hel.12110
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   VAINIO H, 1994, ENVIRON HEALTH PERSP, V102, P590, DOI 10.1289/ehp.94102590
   Watabe H, 2005, GUT, V54, P764, DOI 10.1136/gut.2004.055400
   Watanabe T, 1998, GASTROENTEROLOGY, V115, P642, DOI 10.1016/S0016-5085(98)70143-X
   Yamaguchi Y, 2016, DIGESTION, V93, P13, DOI 10.1159/000441742
   Yamamichi N, 2016, GASTRIC CANCER, V19, P670, DOI 10.1007/s10120-015-0515-y
   Yamamichi N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111359
   Yoshida T, 2014, INT J CANCER, V134, P1445, DOI 10.1002/ijc.28470
NR 36
TC 4
Z9 4
U1 1
U2 8
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 8226 REGENCY DR, PLEASANTON, CA 94588 USA
SN 1948-5204
J9 WORLD J GASTRO ONCOL
JI World J. Gastrointest. Oncol.
PD FEB 15
PY 2018
VL 10
IS 2
BP 62
EP 70
DI 10.4251/wjgo.v10.i2.62
PG 9
WC Oncology; Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology; Gastroenterology & Hepatology
GA FV6LO
UT WOS:000424692700001
PM 29467917
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Billah, M
   Waheed, S
AF Billah, Mustain
   Waheed, Sajjad
TI Gastrointestinal polyp detection in endoscopic images using an improved
   feature extraction method
SO BIOMEDICAL ENGINEERING LETTERS
LA English
DT Article
DE Endoscopic image; Video endoscopy; Convolutional neural network (CNN);
   Color wavelet features; Support vector machine (SVM); Improved method
ID SYSTEM
AB Gastrointestinal polyps are treated as the precursors of cancer development. So, possibility of cancers can be reduced at a great extent by early detection and removal of polyps. The most used diagnostic modality for gastrointestinal polyps is video endoscopy. But, as an operator dependant procedure, several human factors can lead to miss detection of polyps. In this peper, an improved computer aided polyp detection method has been proposed. Proposed improved method can reduce polyp miss detection rate and assists doctors in finding the most important regions to pay attention. Color wavelet features and convolutional neural network features are extracted from endoscopic images, which are used for training a support vector machine. Then a target endoscopic image will be given to the classifier as input in order to find whether it contains any polyp or not. If polyp is found, it will be marked automatically. Experiment shows that, color wavelet features and convolutional neural network features together construct a highly representative of endoscopic polyp images. Evaluations on standard public databases show that, proposed system outperforms state-of-the-art methods, gaining accuracy of 98.34%, sensitivity of 98.67% and specificity of 98.23%. In this paper, the strength of color wavelet features and power of convolutional neural network features are combined. Fusion of these two methodology and use of support vector machine results in an improved method for gastrointestinal polyp detection. An analysis of ROC reveals that, proposed method can be used for polyp detection purposes with greater accuracy than state-of-the-art methods.
C1 [Billah, Mustain; Waheed, Sajjad] Mawlana Bhashani Sci & Technol Univ, Dept Informat & Commun Technol ICT, Tangail, Bangladesh.
C3 Mawlana Bhashani Science & Technology University
RP Billah, M (通讯作者)，Mawlana Bhashani Sci & Technol Univ, Dept Informat & Commun Technol ICT, Tangail, Bangladesh.
EM mustainbillahx@gmail.com
OI Billah, Mustain/0000-0003-3649-5909
CR Alexandre LA, 2008, INT C BIOM ENG INF 2, V2
   [Anonymous], 2007, INT J INF TECHNOL
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   DONAHUE J, 2014, ICML, V32
   El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   Goszczynski J, 2003, PATTERN RECOGN, V36, P2883
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Jia X, 2016, 2016 IEEE 38 ANN INT
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2009, 2009 IEEE INT C ROB
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Park SY, 2016, SPIE MED IMAGING
   Ribeiro E, 2016, 2016 IEEE 29 INT S C
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, P368
   Tajbakhsh N, 2015, 2015 IEEE 12 INT S B
   Tajbakhsh N, 2014, INT C MED IM COMP CO
   West D, 2000, ARTIF INTELL MED, V20, P183, DOI 10.1016/S0933-3657(00)00063-4
   Zhu R, 2015, 2015 8 INT C IM SIGN
   Zou Y, 2015, 2015 IEEE INT C DIG
NR 24
TC 18
Z9 19
U1 2
U2 10
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2093-9868
EI 2093-985X
J9 BIOMED ENG LETT
JI Biomed. Eng. Lett.
PD FEB
PY 2018
VL 8
IS 1
SI SI
BP 69
EP 75
DI 10.1007/s13534-017-0048-x
PG 7
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA GP2ML
UT WOS:000440667700006
PM 30603191
OA Green Published
DA 2023-04-20
ER

PT J
AU Chen, PJ
   Lin, MC
   Lai, MJ
   Lin, JC
   Lu, HHS
   Tseng, VS
AF Chen, Peng-Jen
   Lin, Meng-Chiung
   Lai, Mei-Ju
   Lin, Jung-Chun
   Lu, Henry Horng-Shing
   Tseng, Vincent S.
TI Accurate Classification of Diminutive Colorectal Polyps Using
   Computer-Aided Analysis
SO GASTROENTEROLOGY
LA English
DT Article
DE Colon Cancer Detection; Machine Learning; Cost-effectiveness; Magnifying
ID CONVENTIONAL COLONOSCOPY; OPTICAL MAGNIFICATION; DIAGNOSIS; HISTOLOGY;
   CANCER; SYSTEM; CHROMOENDOSCOPY; POLYPECTOMY; PREVENTION; STRATEGY
AB BACKGROUND & AIMS: Narrow-band imaging is an image-enhanced form of endoscopy used to observed microstructures and capillaries of the mucosal epithelium which allows for real-time prediction of histologic features of colorectal polyps. However, narrow-band imaging expertise is required to differentiate hyperplastic from neoplastic polyps with high levels of accuracy. We developed and tested a system of computer-aided diagnosis with a deep neural network (DNN-CAD) to analyze narrow-band images of diminutive colorectal polyps. METHODS: We collected 1476 images of neoplastic polyps and 681 images of hyperplastic polyps, obtained from the picture archiving and communications system database in a tertiary hospital in Taiwan. Histologic findings from the polyps were also collected and used as the reference standard. The images and data were used to train the DNN. A test set of images (96 hyperplastic and 188 neoplastic polyps, smaller than 5 mm), obtained from patients who underwent colonoscopies from March 2017 through August 2017, was then used to test the diagnostic ability of the DNN-CAD vs endoscopists (2 expert and 4 novice), who were asked to classify the images of the test set as neoplastic or hyperplastic. Their classifications were compared with findings from histologic analysis. The primary outcome measures were diagnostic accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and diagnostic time. The accuracy, sensitivity, specificity, PPV, NPV, and diagnostic time were compared among DNN-CAD, the novice endoscopists, and the expert endoscopists. The study was designed to detect a difference of 10% in accuracy by a 2-sided McNemar test. RESULTS: In the test set, the DNN-CAD identified neoplastic or hyperplastic polyps with 96.3% sensitivity, 78.1% specificity, a PPV of 89.6%, and a NPV of 91.5%. Fewer than half of the novice endoscopists classified polyps with a NPV of 90% (their NPVs ranged from 73.9% to 84.0%). DNN-CAD classified polyps as neoplastic or hyperplastic in 0.45 +/- 0.07 seconds-shorter than the time required by experts (1.54 +/- 1.30 seconds) and nonexperts (1.77 +/- 1.37 seconds) (both P < .001). DNN-CAD classified polyps with perfect intra-observer agreement (kappa score of 1). There was a low level of intra-observer and inter-observer agreement in classification among endoscopists. CONCLUSIONS: We developed a system called DNN-CAD to identify neoplastic or hyperplastic colorectal polyps less than 5 mm. The system classified polyps with a PPV of 89.6%, and a NPV of 91.5%, and in a shorter time than endoscopists. This deep-learning model has potential for not only endoscopic image recognition but for other forms of medical image analysis, including sonography, computed tomography, and magnetic resonance images.
C1 [Chen, Peng-Jen; Lin, Jung-Chun] Triserv Gen Hosp, Natl Def Med Ctr, Div Gastroenterol, 325,Sec 2,Chenggong Rd, Taipei 114, Taiwan.
   [Lin, Meng-Chiung] Natl Chiao Tung Univ, Dept Biol Sci & Technol, Hsinchu, Taiwan.
   [Lin, Meng-Chiung] Taichung Armed Forces Gen Hosp, Div Gastroenterol, Taichung, Taiwan.
   [Lai, Mei-Ju] Triserv Gen Hosp, Natl Def Med Ctr, Dept Pathol, Taipei, Taiwan.
   [Lu, Henry Horng-Shing] Natl Chiao Tung Univ, Big Data Res Ctr, Hsinchu, Taiwan.
   [Lu, Henry Horng-Shing] Natl Chiao Tung Univ, Inst Stat, Hsinchu, Taiwan.
   [Tseng, Vincent S.] Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
C3 National Defense Medical Center; Tri-Service General Hospital; National
   Yang Ming Chiao Tung University; National Defense Medical Center;
   Tri-Service General Hospital; National Yang Ming Chiao Tung University;
   National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University
RP Chen, PJ (通讯作者)，Triserv Gen Hosp, Natl Def Med Ctr, Div Gastroenterol, 325,Sec 2,Chenggong Rd, Taipei 114, Taiwan.; Tseng, VS (通讯作者)，Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM endoscopy@mail.ndmctsgh.edu.tw; vtseng@cs.nctu.edu.tw
OI Chen, Peng Jen/0000-0001-5400-905X
FU Ministry of Science and Technology, Taiwan [106-2218-E-009-031]
FX This research was partially supported by the Ministry of Science and
   Technology, Taiwan, under grant no. 106-2218-E-009-031.
CR Abadi M, 2016, PROC 12 USENIX S OPE
   Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Chiu HM, 2007, GUT, V56, P373, DOI 10.1136/gut.2006.099614
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Iwatate M, 2015, ENDOSC INT OPEN, V3, pE140, DOI 10.1055/s-0034-1391362
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Liou JM, 2007, DIS COLON RECTUM, V50, P630, DOI 10.1007/s10350-006-0857-y
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Ranzato M., DEVISE DEEP VISUAL S
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Rosenberg C., IMPROVING PHOTO SEAR
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Su MY, 2006, AM J GASTROENTEROL, V101, P2711, DOI 10.1111/j.1572-0241.2006.00932.x
   Szegedy C, 2015, P IEEE C COMP VIS PA, P1
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tanaka S, 2011, DIGEST ENDOSC, V23, P131, DOI 10.1111/j.1443-1661.2011.01106.x
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Walsh JME, 2003, JAMA-J AM MED ASSOC, V289, P1288, DOI 10.1001/jama.289.10.1288
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 28
TC 220
Z9 245
U1 8
U2 89
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD FEB
PY 2018
VL 154
IS 3
BP 568
EP 575
DI 10.1053/j.gastro.2017.10.010
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA FV7CW
UT WOS:000424741500029
PM 29042219
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Deeba, F
   Islam, M
   Bui, FM
   Wahid, KA
AF Deeba, Farah
   Islam, Monzurul
   Bui, Francis M.
   Wahid, Khan A.
TI Performance assessment of a bleeding detection algorithm for endoscopic
   video based on classifier fusion method and exhaustive feature selection
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Capsule endoscopy; Color features; Automated bleeding detection;
   Classifier fusion; Nested cross validation; SVM score
ID CAPSULE ENDOSCOPY
AB Capsule Endoscopy (CE) is a non-invasive clinical procedure that allows examination of the entire gastrointestinal tract including parts of small intestine beyond the scope of conventional endoscope. It requires computer-aided approach for the assessment of video frames to reduce diagnosis time. This paper presents a computer-assisted method based on a classifier fusion algorithm which combines two optimized Support Vector Machine (SVM) classifiers to automatically detect bleeding regions present in CE frames. The classifiers are based on RGB and HSV color spaces; the image regions are characterized on the basis of statistical features derived from the first-order histogram probability of respective color channels. A nested cross validation strategy has been adopted for the parameter tuning and feature selection to optimize the classifiers. The optimum feature sets for the best performance are evaluated after exhaustive analysis. The proposed fusion approach achieves an average accuracy of 95%, sensitivity of 94% and specificity of 95.3% for a dataset of 8872 CE frames, which is higher than that obtained from a single classifier. Comparison with the state-of-the-art algorithms exhibits that the proposed method yields superior performance for diverse dataset. (C) 2017 Elsevier Ltd. All rights reserved.
C1 [Deeba, Farah; Islam, Monzurul; Bui, Francis M.; Wahid, Khan A.] Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK S7N 5A9, Canada.
C3 University of Saskatchewan
RP Deeba, F (通讯作者)，Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK S7N 5A9, Canada.
EM farah.deeba@usask.ca
RI Deeba, Farah/AAJ-1923-2020
OI Bui, Francis/0000-0002-8799-5965
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX This work was supported by the Natural Sciences and Engineering Research
   Council of Canada (NSERC).
CR Chen Y., 2012, DIAGN THER ENDOSCOPY, P2012
   Deeba F, 2016, IEEE IJCNN, P4650, DOI 10.1109/IJCNN.2016.7727810
   Deeba F, 2016, IEEE ENG MED BIO, P3871, DOI 10.1109/EMBC.2016.7591573
   Faigel DO, 2008, CAPSULE ENDOSCOPY
   Filip Dobromir, 2011, INT J INFORM TECHNOL, V5, P3
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Goldfarb A., 2004, DIS MANAGE, V5, P123
   Hwang S., 2006, P SPIE
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jung YS, 2008, INT CONF BIOMED, P859, DOI 10.1109/BMEI.2008.216
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Katz L.B., 1999, SEMINARS GASTROINTES
   Koulaouzidis A, 2013, WORLD J GASTROENTERO, V19, P3726, DOI 10.3748/wjg.v19.i24.3726
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906
   Kurniawan N., 2014, VIDEO CAPSUL ENDOSC, P15, DOI [10.1007/978-3-662-44062-9_3, DOI 10.1007/978-3-662-44062-9_3]
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Lv G., 2011, C P IEEE ENG MED BIO
   Mackiewicz M, 2008, P SPIE
   Pan G., 2009, Journal of Medical Engineering & Technology, V33, P575, DOI 10.1080/03091900903111974
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Park SC, 2012, WORLD J GASTROENTERO, V18, P4169, DOI 10.3748/wjg.v18.i31.4169
   Platt J.C, 1999, ADV LARGE MARGIN CLA, P61
   Powers D., 2011, J MACH LEARN TECHNOL, V2, P37
   Rao R.B, 2017, SDM, P588
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sergyan S., 2008, COLOR HISTOGRAM FEAT
   Shrestha R., 2015, CIRC SYST ISCAS 2015
   Sun K., 2012, P 2 SIN FOR INT C IN
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Vapnik V, 1998, STAT LEARNING THEORY
   Varma S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-91
   Yuan Y., 2015, BIOMED HLTH INF IEEE, V99
   Zheng Y., 2008, P IEEE C COMP VIS PA
NR 35
TC 20
Z9 21
U1 2
U2 14
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD FEB
PY 2018
VL 40
BP 415
EP 424
DI 10.1016/j.bspc.2017.10.011
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA FQ2TQ
UT WOS:000418211300044
DA 2023-04-20
ER

PT J
AU Itoh, T
   Kawahira, H
   Nakashima, H
   Yata, N
AF Itoh, Takumi
   Kawahira, Hiroshi
   Nakashima, Hirotaka
   Yata, Noriko
TI Deep learning analyzes Helicobacter pylori infection by upper
   gastrointestinal endoscopy images
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID GASTRIC-CANCER; JAPAN; DIAGNOSIS
AB Background and study aims Helicobacter pylori (HP)-associated chronic gastritis can cause mucosal atrophy and intestinal metaplasia, both of which increase the risk of gastric cancer. The accurate diagnosis of HP infection during routine medical checks is important. We aimed to develop a convolutional neural network (CNN), which is a machine-learning algorithm similar to deep learning, capable of recognizing specific features of gastric endoscopy images. The goal behind developing such a system was to detect HP infection early, thus preventing gastric cancer.
   Patients and methods For the development of the CNN, we used 179 upper gastrointestinal endoscopy images obtained from 139 patients (65 were HP-positive: 10 U/mL and 74 were HP-negative: <3 U/mL on HP IgG antibody assessment). Of the 179 images, 149 were used as training images, and the remaining 30 (15 from HP-negative patients and 15 from HP-positive patients) were set aside to be used as test images. The 149 training images were subjected to data augmentation, which yielded 596 images. We used the CNN to create a learning tool that would recognize HP infection and assessed the decision accuracy of the CNN with the 30 test images by calculating the sensitivity, specificity, and area under the receiver operating characteristic (ROC) curve (AUC).
   Results The sensitivity and specificity of the CNN for the detection of HP infection were 86.7% and 86.7%, respectively, and the AUC was 0.956.
   Conclusions CNN-aided diagnosis of HP infection seems feasible and is expected to facilitate and improve diagnosis during health check-ups.
C1 [Itoh, Takumi] Chiba Univ, Grad Sch Engn, Dept Med Syst Engn, Chiba, Japan.
   [Kawahira, Hiroshi] Chiba Univ, Ctr Frontier Med Engn, Chiba, Japan.
   [Kawahira, Hiroshi] Chiba Univ, Grad Sch Med, Dept Frontier Surg, Chiba, Japan.
   [Nakashima, Hirotaka] Fdn Detect Early Gastr Carcinoma, Dept Gastroenterol, Tokyo, Japan.
   [Yata, Noriko] Chiba Univ, Grad Sch Adv Integrat Sci, Dept Informat Proc & Comp Sci, Chiba, Japan.
C3 Chiba University; Chiba University; Chiba University; Chiba University
RP Kawahira, H (通讯作者)，Chiba Univ, Ctr Frontier Med Engn, Inage Ku, 1-33 Yayoi Cho, Chiba 2638522, Japan.
EM hk@faculty.chiba-u.jp
OI Yata, Noriko/0000-0001-8891-594X; Nakashima,
   Hirotaka/0000-0002-2386-1933
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Asaka M, 2001, HELICOBACTER, V6, P294, DOI 10.1046/j.1523-5378.2001.00042.x
   BAH A, 1995, ENDOSCOPY, V27, P593, DOI 10.1055/s-2007-1005764
   Bornschein J, 2011, LANGENBECK ARCH SURG, V396, P729, DOI 10.1007/s00423-011-0810-y
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Di Rienzo TA, 2013, EUR REV MED PHARMACO, V17, P51
   Girshick R., 2013, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   Goodwin CS, 1997, CLIN INFECT DIS, V25, P1017, DOI 10.1086/516077
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Ji R, 2014, WORLD J GASTROENTERO, V20, P9314, DOI 10.3748/wjg.v20.i28.9314
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kato M, 2000, HELICOBACTER, V5, P109, DOI 10.1046/j.1523-5378.2000.00017.x
   Kimura K, 1969, ENDOSCOPY, V1, P87, DOI [10.1055/s-0028-1098086, DOI 10.1055/S-0028-1098086]
   LAINE L, 1995, GASTROINTEST ENDOSC, V42, P420, DOI 10.1016/S0016-5107(95)70043-9
   Lee SY, 2014, WORLD J GASTROENTERO, V20, P1493, DOI 10.3748/wjg.v20.i6.1493
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nakagawa S, 2003, GASTROINTEST ENDOSC, V58, P71, DOI 10.1067/mge.2003.316
   Naylor GM, 2006, GUT, V55, P1545, DOI 10.1136/gut.2005.080358
   Nomura S, 2013, DIGEST ENDOSC, V25, P136, DOI 10.1111/j.1443-1661.2012.01357.x
   Okubo M, 2011, DIGESTION, V83, P161, DOI 10.1159/000321799
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sugano K, 2015, GUT, V64, P1353, DOI 10.1136/gutjnl-2015-309252
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tahara T, 2007, DIGESTION, V75, P54, DOI 10.1159/000101775
   Tahara T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163700
   Tahara T, 2009, GASTROINTEST ENDOSC, V70, P246, DOI 10.1016/j.gie.2008.11.046
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
NR 29
TC 96
Z9 101
U1 1
U2 16
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD FEB
PY 2018
VL 6
IS 2
BP E139
EP E144
DI 10.1055/s-0043-120830
PG 6
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA GC5HC
UT WOS:000429816800003
PM 29399610
OA Green Published, Green Submitted, gold
DA 2023-04-20
ER

PT J
AU Vennalaganti, PR
   Kaul, V
   Wang, KK
   Falk, GW
   Shaheen, NJ
   Infantolino, A
   Johnson, DA
   Eisen, G
   Gerson, LB
   Smith, MS
   Iyer, PG
   Lightdale, CJ
   Schnoll-Sussman, F
   Gupta, N
   Gross, SA
   Abrams, J
   Haber, GB
   Chuttani, R
   Pleskow, DK
   Kothari, S
   Goldblum, JR
   Zhang, YX
   Sharma, P
AF Vennalaganti, Prashanth R.
   Kaul, Vivek
   Wang, Kenneth K.
   Falk, Gary W.
   Shaheen, Nicholas J.
   Infantolino, Anthony
   Johnson, David A.
   Eisen, Glenn
   Gerson, Lauren B.
   Smith, Michael S.
   Iyer, Prasad G.
   Lightdale, Charles J.
   Schnoll-Sussman, Felice
   Gupta, Neil
   Gross, Seth A.
   Abrams, Julian
   Haber, Gregory B.
   Chuttani, Ram
   Pleskow, Douglas K.
   Kothari, Shivangi
   Goldblum, John R.
   Zhang, Yaxia
   Sharma, Prateek
TI Increased detection of Barrett's esophagus-associated neoplasia using
   wide-area trans-epithelial sampling: a multicenter, prospective,
   randomized trial
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID ENDOSCOPIC BIOPSY; SURVEILLANCE; DYSPLASIA; ADENOCARCINOMA; MANAGEMENT;
   DIAGNOSIS; PROTOCOL; CANCER
AB Background and Aims: Wide-area transepithelial sampling (WATS) with computer-assisted 3-dimensional analysis is a sampling technique that combines abrasive brushing of the Barrett's esophagus (BE) mucosa followed by neural network analysis to highlight abnormal-appearing cells.
   Methods: We performed a randomized trial of referred BE patients undergoing surveillance at 16 medical centers. Subjects received either biopsy sampling followed by WATS or WATS followed by biopsy sampling. The primary outcome was rate of detection of high-grade dysplasia/esophageal adenocarcinoma (HGD/EAC) using WATS in conjunction with biopsy sampling compared with biopsy sampling alone using standard histopathologic criteria. Secondary aims included evaluating neoplasia detection rates based on the procedure order (WATS vs biopsy sampling first), of each procedure separately, and the additional time required for WATS.
   Results: One hundred sixty patients (mean age, 63.4 years; 76% men; 95% white) completed the trial. The median circumferential and maximal BE extents were 1.0 cm (interquartile range: .0-5.0) and 4.0 cm (interquartile range, 2.0-8.0), respectively. The diagnostic yield for biopsy sampling alone was as follows: HGD/EAC, 7 (4.4%); low-grade dysplasia (LGD), 28 (17.5%); nondysplastic BE (NDBE), 106 (66.25%); and no BE, 19 (11.9%). The addition of WATS to biopsy sampling yielded an additional 23 cases of HGD/EAC (absolute increase, 14.4%; 95% confidence interval, 7.5%-21.2%). Among these 23 patients, 11 were classified by biopsy sampling as NDBE and 12 as LGD/indefinite for dysplasia (IND); 14 received biopsy sampling first and 9 WATS first (not significant) and most (n = 21; 91.7%) had a prior dysplasia history. WATS added an average of 4.5 minutes to the procedure.
   Conclusion: Results of this multicenter, prospective, randomized trial demonstrate that the use of WATS in a referral BE population increases the detection of HGD/EAC.
C1 [Vennalaganti, Prashanth R.; Sharma, Prateek] Vet Affairs Med Ctr, Dept Gastroenterol & Hepatol, Kansas City, MO USA.
   [Kaul, Vivek; Kothari, Shivangi] Univ Rochester, Dept Gastroenterol, Rochester, NY USA.
   [Wang, Kenneth K.; Iyer, Prasad G.] Mayo Clin, Dept Gastroenterol, Rochester, MN USA.
   [Falk, Gary W.] Univ Penn, Sch Med, Dept Gastroenterol, Philadelphia, PA 19104 USA.
   [Shaheen, Nicholas J.] Univ N Carolina, Sch Med, Dept Gastroenterol, Chapel Hill, NC USA.
   [Infantolino, Anthony] Thomas Jefferson Univ, Sch Med, Dept Gastroenterol, Philadelphia, PA 19107 USA.
   [Johnson, David A.] Eastern VA Med Sch, Dept Gastroenterol, Norfolk, VA USA.
   [Eisen, Glenn; Gerson, Lauren B.] Stanford Univ, Dept Gastroenterol, Palo Alto, CA 94304 USA.
   [Smith, Michael S.] Temple Univ, Sch Med, Dept Gastroenterol, Philadelphia, PA 19122 USA.
   [Lightdale, Charles J.; Abrams, Julian] Columbia Univ, Sch Med, Dept Gastroenterol, New York, NY USA.
   [Schnoll-Sussman, Felice] Weill Cornell Med Ctr, Dept Gastroenterol, New York, NY USA.
   [Gupta, Neil] Loyola Univ Med Ctr, Dept Gastroenterol, Maywood, IL 60153 USA.
   [Gross, Seth A.; Haber, Gregory B.] New York City Langone Med Ctr, Dept Gastroenterol, New York, NY USA.
   [Chuttani, Ram; Pleskow, Douglas K.] Beth Israel Deaconess Med Ctr, Boston, MA 02215 USA.
   [Goldblum, John R.; Zhang, Yaxia] Cleveland Clin, Dept Anat Pathol, Cleveland, OH 44106 USA.
   [Vennalaganti, Prashanth R.; Sharma, Prateek] Univ Kansas, Sch Med, Dept Gastroenterol, Kansas City, KS USA.
C3 US Department of Veterans Affairs; Veterans Health Administration (VHA);
   University of Rochester; Mayo Clinic; University of Pennsylvania;
   University of North Carolina; University of North Carolina Chapel Hill;
   University of North Carolina School of Medicine; Jefferson University;
   Eastern Virginia Medical School; Stanford University; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); Temple University;
   Columbia University; Cornell University; Weill Cornell Medicine; Loyola
   University Chicago; Harvard University; Beth Israel Deaconess Medical
   Center; Cleveland Clinic Foundation; University of Kansas; University of
   Kansas Medical Center
RP Sharma, P (通讯作者)，Dept Vet Affairs Med Ctr, Gastroenterol 111, Med, 4801 E Linwood Blvd, Kansas City, MO 64128 USA.
EM psharma@kumc.edu
RI Johnson, David/HKE-8207-2023; Pleskow, Douglas K/F-3319-2016
OI Pleskow, Douglas K/0000-0003-0092-9496; Gupta, Neil/0000-0002-3715-5781
FU CDx Diagnostics; Medtronic; CSA Medical; C2 Therapeutics; CDx Medical;
   Interpace Diagnostics; Boston Scientific; Exact Sciences; Cook Medical;
   Cosmo Pharmaceuticals; Olympus; Effexus Pharmaceuticals
FX The following authors disclosed financial relationships relevant to this
   publication: K. K. Wang: Research support recipient from CDx
   Diagnostics; advisory board member for Olympus and Boston Scientific. N.
   J. Sheheen: Research support recipient from Medtronic, CSA Medical, C2
   Therapeutics, CDx Medical, Interpace Diagnostics, and Boston Scientific;
   consultant for Shire and Cook Medical. D. A. Johnson: Consultant for
   WebMD, CRH Medical, C3Jain, HyGIeaCare, and Pfizer. L. B. Gerson:
   Consultant for CDx Diagnostics. M. S. Smith: Advisory board member and
   research support recipient from CDx Diagnostics. P. G. Iyer: Research
   support recipient from Exact Sciences and C2 Therapeutics. N. Gupta:
   Research support recipient from Cook Medical, CDx Diagnostics, and Cosmo
   Pharmaceuticals; speaker for Taewoong Medical. R. Chuttani: Consultant
   for Boston Scientific and Olympus. D. Pleskow: Consultant for Boston
   Scientific Medtronic, and Olympus. P. Sharma: Research support recipient
   from Olympus, Effexus Pharmaceuticals, and Cosmo Pharmaceuticals. All
   other authors disclosed no financial relationships relevant to this
   publication. Research support for this study was provided by CDx
   Diagnostics.
CR Abrams JA, 2009, CLIN GASTROENTEROL H, V7, P736, DOI 10.1016/j.cgh.2008.12.027
   Anandasabapathy S, 2011, DIGEST DIS SCI, V56, P761, DOI 10.1007/s10620-010-1459-z
   Bergman JJGHM, 2005, GUT, V54, pI38, DOI 10.1136/gut.2004.041590
   Choi SE, 2012, CURR OPIN GASTROEN, V28, P377, DOI 10.1097/MOG.0b013e328353d58e
   Curvers WL, 2010, GASTROENTEROLOGY, V139, P1106, DOI 10.1053/j.gastro.2010.06.045
   di Pietro M, 2015, GUT, V64, P49, DOI 10.1136/gutjnl-2013-305975
   Falk GW, 1999, GASTROINTEST ENDOSC, V49, P170, DOI 10.1016/S0016-5107(99)70482-7
   Falk GW, 1997, GASTROENTEROLOGY, V112, P1787, DOI 10.1053/gast.1997.v112.pm9178668
   FENNERTY MB, 1995, AM J GASTROENTEROL, V90, P1230
   Hvid-Jensen F, 2011, NEW ENGL J MED, V365, P1375, DOI 10.1056/NEJMoa1103042
   Johanson JF, 2011, DIGEST DIS SCI, V56, P767, DOI 10.1007/s10620-010-1497-6
   Kumaravel A, 2010, ENDOSCOPY, V42, P800, DOI 10.1055/s-0030-1255710
   LEVINE DS, 1993, GASTROENTEROLOGY, V105, P40, DOI 10.1016/0016-5085(93)90008-Z
   Pohl H, 2005, J NATL CANCER I, V97, P142, DOI 10.1093/jnci/dji024
   Sampliner RE, 2005, MED CLIN N AM, V89, P293, DOI 10.1016/j.mcna.2004.08.008
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Shaheen NJ, 2016, AM J GASTROENTEROL, V111, P30, DOI 10.1038/ajg.2015.322
   Shaheen NJ, 2009, NEW ENGL J MED, V360, P2277, DOI 10.1056/NEJMoa0808145
   Sharma P, 2004, ALIMENT PHARM THER, V20, P63, DOI 10.1111/j.1365-2036.2004.02136.x
   Sharma P., 2004, ALIMENT PHARM THER, V20, P95
   Sharma P, 2006, GASTROENTEROLOGY, V131, P1392, DOI 10.1053/j.gastro.2006.08.032
   Spechler SJ, 2002, NEW ENGL J MED, V346, P836, DOI 10.1056/NEJMcp012118
   Spechler SJ, 2011, GASTROENTEROLOGY, V140, P1084, DOI 10.1053/j.gastro.2011.01.030
   Vennalaganti PR, 2015, AM J GASTROENTEROL, V110, P1257, DOI 10.1038/ajg.2015.116
   Weinstein WM, 1996, GASTROINTEST ENDOSC, V44, P91, DOI 10.1016/S0016-5107(96)70239-0
NR 25
TC 59
Z9 62
U1 0
U2 6
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD FEB
PY 2018
VL 87
IS 2
BP 348
EP 355
DI 10.1016/j.gie.2017.07.039
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA FV2LO
UT WOS:000424398500003
PM 28757316
DA 2023-04-20
ER

PT J
AU Turan, M
   Almalioglu, Y
   Araujo, H
   Konukoglu, E
   Sitti, M
AF Turan, Mehmet
   Almalioglu, Yasin
   Araujo, Helder
   Konukoglu, Ender
   Sitti, Metin
TI Deep EndoVO: A recurrent convolutional neural network (RCNN) based
   visual odometry approach for endoscopic capsule robots
SO NEUROCOMPUTING
LA English
DT Article
DE Endoscopic capsule robot; Visual odometry; Sequential deep learning;
   RCNN; CNN; LSTM; Localization
ID LOCALIZATION; SYSTEMS
AB Ingestible wireless capsule endoscopy is an emerging minimally invasive diagnostic technology for inspection of the GI tract and diagnosis of a wide range of diseases and pathologies. Medical device companies and many research groups have recently made substantial progresses in converting passive capsule endoscopes to active capsule robots, enabling more accurate, precise, and intuitive detection of the location and size of the diseased areas. Since a reliable real time pose estimation functionality is crucial for actively controlled endoscopic capsule robots, in this study, we propose a monocular visual odometry (VO) method for endoscopic capsule robot operations. Our method lies on the application of the deep recurrent convolutional neural networks (RCNNs) for the visual odometry task, where convolutional neural networks (CNNs) and recurrent neural networks (RNNs) are used for the feature extraction and inference of dynamics across the frames, respectively. Detailed analyses and evaluations made on a real pig stomach dataset proves that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories. (C) 2017 The Author(s). Published by Elsevier B.V.
C1 [Turan, Mehmet; Sitti, Metin] Max Planck Inst Intelligent Syst, Phys Intelligence Dept, Stuttgart, Germany.
   [Almalioglu, Yasin] Bogazici Univ, Comp Engn Dept, Istanbul, Turkey.
   [Araujo, Helder] Univ Coimbra, Inst Syst & Robot, Coimbra, Portugal.
   [Turan, Mehmet; Konukoglu, Ender] ETH, Dept Informat Technol & Elect Engn, Comp Vis Lab, Zurich, Switzerland.
C3 Max Planck Society; Bogazici University; Universidade de Coimbra; Swiss
   Federal Institutes of Technology Domain; ETH Zurich
RP Turan, M (通讯作者)，Max Planck Inst Intelligent Syst, Phys Intelligence Dept, Stuttgart, Germany.
EM mturan@student.ethz.ch; yasin.almalioglu@boun.edu.tr; helder@isr.uc.pt;
   ender.konukoglu@vision.ee.ethz.ch; sitti@is.mpg.de
RI Turan, Mehmet/AGZ-7356-2022; Sitti, Metin/AGP-6288-2022; Araujo,
   Helder/B-3554-2008
OI Sitti, Metin/0000-0001-8249-3854; Araujo, Helder/0000-0002-9544-424X;
   Konukoglu, Ender/0000-0002-2542-3611; Almalioglu,
   Yasin/0000-0002-9251-7853
CR Carpi F, 2011, IEEE T BIO-MED ENG, V58, P231, DOI 10.1109/TBME.2010.2087332
   Donghoon Son, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1132, DOI 10.1109/ICRA.2017.7989135
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Fluckiger M, 2007, P ANN INT IEEE EMBS, P2867, DOI 10.1109/IEMBS.2007.4352927
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Goenka MK, 2014, WORLD J GASTROENTERO, V20, P10024, DOI 10.3748/wjg.v20.i29.10024
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Keller H, 2012, P IEEE RAS-EMBS INT, P859, DOI 10.1109/BioRob.2012.6290795
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kim K, 2008, ULTRASOUND MED BIOL, V34, P902, DOI 10.1016/j.ultrasmedbio.2007.11.020
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Liao ZA, 2010, GASTROINTEST ENDOSC, V71, P280, DOI 10.1016/j.gie.2009.09.031
   Mahoney AW, 2013, IEEE INT CONF ROBOT, P5366, DOI 10.1109/ICRA.2013.6631346
   Munoz F, 2014, ADV DRUG DELIVER REV, V71, P77, DOI 10.1016/j.addr.2013.12.007
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nakamura T, 2008, J GASTROENTEROL, V43, P93, DOI 10.1007/s00535-007-2153-6
   Pan GB, 2012, GASTROENT RES PRACT, V2012, DOI 10.1155/2012/841691
   Petruska AJ, 2013, IEEE INT CONF ROBOT, P822, DOI 10.1109/ICRA.2013.6630668
   Ping-Sing T., 1998, IMAGE VISION COMPUT, V12, P487
   Rubin JM, 2006, J ULTRAS MED, V25, P1179, DOI 10.7863/jum.2006.25.9.1179
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, CORR
   Sitti M, 2015, P IEEE, V103, P205, DOI 10.1109/JPROC.2014.2385105
   Son D, 2016, IEEE-ASME T MECH, V21, P708, DOI 10.1109/TMECH.2015.2488361
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Than TD, 2012, IEEE T BIO-MED ENG, V59, P2387, DOI 10.1109/TBME.2012.2201715
   Turan M., 2017, ARXIV170506196
   Turan M., 2017, ARXIV170809740
   Turan M., 2017, ARXIV170505435
   Turan M., 2017, ARXIV170506524
   Turan M., 2017, ARXIV170505444
   Walch Florian, 2016, ARXIV161107890
   Wang S, 2017, IEEE INT C ROB AUT I, DOI 10.1109/icra.2017.7989236
   Yim S, 2014, IEEE T BIO-MED ENG, V61, P513, DOI 10.1109/TBME.2013.2283369
   Yim S, 2013, IEEE T ROBOT, V29, P1139, DOI 10.1109/TRO.2013.2266754
NR 37
TC 62
Z9 67
U1 6
U2 48
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 31
PY 2018
VL 275
BP 1861
EP 1870
DI 10.1016/j.neucom.2017.10.014
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FQ5AI
UT WOS:000418370200173
OA hybrid, Green Submitted, Green Published
DA 2023-04-20
ER

PT J
AU Cooper, JA
   Parsons, N
   Stinton, C
   Mathews, C
   Smith, S
   Halloran, SP
   Moss, S
   Taylor-Phillips, S
AF Cooper, Jennifer Anne
   Parsons, Nick
   Stinton, Chris
   Mathews, Christopher
   Smith, Steve
   Halloran, Stephen P.
   Moss, Sue
   Taylor-Phillips, Sian
TI Risk-adjusted colorectal cancer screening using the FIT and routine
   screening data: development of a risk prediction model
SO BRITISH JOURNAL OF CANCER
LA English
DT Article
DE colorectal cancer screening; faecal immunochemical test; prediction
   model; test performance; risk-based screening
ID FECAL IMMUNOCHEMICAL TEST; ARTIFICIAL NEURAL-NETWORKS; OCCULT
   BLOOD-TESTS; HEMOGLOBIN CONCENTRATION; LOGISTIC-REGRESSION;
   DIAGNOSTIC-ACCURACY; STRATIFICATION; COMBINATION; FUTURE; AGE
AB Background: The faecal immunochemical test (FIT) is replacing the guaiac faecal occult blood test in colorectal cancer screening. Increased uptake and FIT positivity will challenge colonoscopy services. We developed a risk prediction model combining routine screening data with FIT concentration to improve the accuracy of screening referrals.
   Methods: Multivariate analysis used complete cases of those with a positive FIT (>= 20 mu g g(-1)) and diagnostic outcome (n = 1810; 549 cancers and advanced adenomas). Logistic regression was used to develop a risk prediction model using the FIT result and screening data: age, sex and previous screening history. The model was developed further using a feedforward neural network. Model performance was assessed by discrimination and calibration, and test accuracy was investigated using clinical sensitivity, specificity and receiver operating characteristic curves.
   Results: Discrimination improved from 0.628 with just FIT to 0.659 with the risk-adjusted model (P = 0.01). Calibration using the Hosmer-Lemeshow test was 0.90 for the risk-adjusted model. The sensitivity improved from 30.78% to 33.15% at similar specificity (FIT threshold of 160 mu g g(-1)). The neural network further improved model performance and test accuracy.
   Conclusions: Combining routinely available risk predictors with the FIT improves the clinical sensitivity of the FIT with an increase in the diagnostic yield of high-risk adenomas.
C1 [Cooper, Jennifer Anne; Parsons, Nick; Stinton, Chris; Taylor-Phillips, Sian] Univ Warwick, Warwick Med Sch, Div Hlth Sci, Gibbet Hill Rd, Coventry CV4 7AL, W Midlands, England.
   [Mathews, Christopher; Moss, Sue] Queen Mary Univ London, Wolfson Inst Prevent Med, Ctr Canc Prevent, London, England.
   [Smith, Steve] NHS Bowel Canc Screening Midlands & North West Pr, Rugby, England.
   [Halloran, Stephen P.] Publ Hlth England, London, England.
   [Halloran, Stephen P.] Univ Surrey, Guildford, Surrey, England.
C3 University of Warwick; University of London; Queen Mary University
   London; Public Health England; University of Surrey
RP Taylor-Phillips, S (通讯作者)，Univ Warwick, Warwick Med Sch, Div Hlth Sci, Gibbet Hill Rd, Coventry CV4 7AL, W Midlands, England.
EM s.taylor-phillips@warwick.ac.uk
RI Taylor-Phillips, Sian/AAW-8544-2021; Parsons, Nick/AAA-8713-2019
OI Parsons, Nick/0000-0001-9975-888X; Mathews, Chris/0000-0002-3653-1810;
   Taylor-Phillips, Sian/0000-0002-1841-4346
FU NIHR CLAHRC West Midlands initiative
FX Jennifer Cooper, Sian Taylor-Phillips and Chris Stinton are supported by
   the NIHR CLAHRC West Midlands initiative. This paper presents
   independent research and the views expressed are those of the author(s)
   and not necessarily those of the NHS, the NIHR or the Department of
   Health.
CR Allison JE, 2014, GUT LIVER, V8, P117, DOI 10.5009/gnl.2014.8.2.117
   Altman DG, 2006, BRIT MED J, V332, P1080, DOI 10.1136/bmj.332.7549.1080
   Aniwan S, 2015, GASTROINTEST ENDOSC, V81, P719, DOI 10.1016/j.gie.2014.11.035
   [Anonymous], 2019, R LANG ENV STAT COMP
   Auge JM, 2014, GASTROENTEROLOGY, V147, P628, DOI 10.1053/j.gastro.2014.06.008
   Bossuyt PM, 2003, CLIN CHEM, V49, P1, DOI 10.1373/49.1.1
   Brenner H, 2007, GUT, V56, P1585, DOI 10.1136/gut.2007.122739
   Cairns SR, 2010, GUT, V59, P666, DOI 10.1136/gut.2009.179804
   Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.7326/M14-0697, 10.1002/bjs.9736, 10.1016/j.eururo.2014.11.025, 10.1038/bjc.2014.639, 10.1016/j.jclinepi.2014.11.010, 10.1136/bmj.g7594, 10.1186/s12916-014-0241-z, 10.7326/M14-0698]
   Cooper JA, 2016, COLORECTAL DIS, V18, P650, DOI 10.1111/codi.13365
   Dayhoff JE, 2001, CANCER, V91, P1615, DOI 10.1002/1097-0142(20010415)91:8+<1615::AID-CNCR1175>3.0.CO;2-L
   de Groot JAH, 2011, BMJ-BRIT MED J, V343, DOI 10.1136/bmj.d4770
   Department for Communities and Local Government, 2011, ENGLISH INDICES DEPR
   Department of Health, 2014, SERV SPEC
   Digby J, 2017, J MED SCREEN, V24, P62, DOI 10.1177/0969141316653983
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Fraser CG, 2012, JNCI-J NATL CANCER I, V104, P810, DOI 10.1093/jnci/djs190
   Geraghty J, 2014, BRIT J CANCER, V111, P2156, DOI 10.1038/bjc.2014.480
   Launois Robert, 2014, Eur J Gastroenterol Hepatol, V26, P978, DOI 10.1097/MEG.0000000000000160
   Logan RFA, 2012, GUT, V61, P1439, DOI 10.1136/gutjnl-2011-300843
   McDonald PJ, 2012, CLIN CHEM LAB MED, V50, P935, DOI [10.1515/CCLM.2011.815, 10.1515/cclm.2011.815]
   Moss S, 2015, NHS BOWEL CANC SCREE
   Moss S, 2017, GUT, V66, P1631, DOI 10.1136/gutjnl-2015-310691
   Naaktgeboren CA, 2016, BMJ-BRIT MED J, V352, DOI 10.1136/bmj.i402
   NAGELKERKE NJD, 1991, BIOMETRIKA, V78, P691, DOI 10.1093/biomet/78.3.691
   Omata F, 2011, EUR J GASTROEN HEPAT, V23, P1036, DOI 10.1097/MEG.0b013e32834a2882
   Otero-Evez O, 2015, BRIT J CANCER
   Parkin DM, 2011, BRIT J CANCER, V105, pS77, DOI 10.1038/bjc.2011.489
   Ripley B.D., 2007, PATTERN RECOGN, DOI DOI 10.1016/J.PATCOG.2017.10.013
   Royston P, 2006, STAT MED, V25, P127, DOI 10.1002/sim.2331
   Rutter M., 2011, NHS BCSP PUBLICATION
   Sargent DJ, 2001, CANCER-AM CANCER SOC, V91, P1636, DOI 10.1002/1097-0142(20010415)91:8+<1636::AID-CNCR1176>3.0.CO;2-D
   Stegeman I, 2014, GUT, V63, P466, DOI 10.1136/gutjnl-2013-305013
   Steyerberg EW., 2009, CLIN PREDICTION MODE, DOI 10.1007/978-0-387-77244-8
   Tao S, 2012, BRIT J CANCER, V106, P1424, DOI 10.1038/bjc.2012.104
   Tu JV, 1996, J CLIN EPIDEMIOL, V49, P1225, DOI 10.1016/S0895-4356(96)00002-9
   van der Vlugt M, 2017, BRIT J CANCER, V116, P44, DOI 10.1038/bjc.2016.399
   van Rossum LG, 2008, GASTROENTEROLOGY, V135, P82, DOI 10.1053/j.gastro.2008.03.040
   Venables WN., 2002, MODERN APPL STAT S, VFourth, DOI DOI 10.1007/978-0-387-21706-2
   Watson J, 2013, J MED SCREEN, V20, P192, DOI 10.1177/0969141313511447
   Winawer Sidney J, 2002, Gastrointest Endosc Clin N Am, V12, P1, DOI 10.1016/S1052-5157(03)00053-9
   Yen AMF, 2014, INT J CANCER, V135, P1203, DOI 10.1002/ijc.28748
NR 43
TC 26
Z9 26
U1 0
U2 7
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 0007-0920
EI 1532-1827
J9 BRIT J CANCER
JI Br. J. Cancer
PD JAN 23
PY 2018
VL 118
IS 2
BP 285
EP 293
DI 10.1038/bjc.2017.375
PG 9
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA FT5HP
UT WOS:000423184900020
PM 29096402
OA hybrid, Green Published, Green Submitted
DA 2023-04-20
ER

PT J
AU Aksenov, SV
   Kostin, KA
   Ivanova, AV
   Liang, J
   Zamyatin, AV
AF Aksenov, S. V.
   Kostin, K. A.
   Ivanova, A. V.
   Liang, J.
   Zamyatin, A. V.
TI An Ensemble of Convolutional Neural Networks for the Use in Video
   Endoscopy
SO SOVREMENNYE TEHNOLOGII V MEDICINE
LA English
DT Article
DE deep learning; convolutional neural network; classifier of pathologies;
   medical diagnostics
ID COMPUTER-AIDED DETECTION; TUMOR-DETECTION; BRAIN-TUMOR; MRI; TECHNOLOGY
AB In this study, a technology for creating a classifier able to identify pathological formations in images obtained with video endoscopy using the methods of deep learning is proposed. For the training and testing of neural network models, images from the CVC-ColonDB open database and 20 colonoscopy video records from the University of Arizona (Phoenix, USA) were used. To improve the performance of the proposed classification model, noise effects inherent to video cameras were considered. In addition, a study on building the model using small data samples was conducted.
   In building the classifier, we utilized the results of recent studies on convolutional neural networks used in medical diagnostics, which allows us to apply the proposed approach to designing the architecture of a convolutional neural network adapted to a given task. By generalizing the features of the successful models, we developed an approach towards creating a non-excessive convolutional neural network. According to the proposed approach, the network architecture is divided into blocks, which alternate to enable composing the most efficient architecture.
   Using the proposed approach based on the recommended selection strategy and then ranking the most significant parameters, a second approach towards building an adaptive model of classifier has been proposed. It is based on the formation of an ensemble of classifiers such as the "convolutional neural network". To ensure the stability of the model and its insensitivity to changes in the input data as well as its applicability to different classification tasks, a set of networks with different major parameters are incorporated into the ensemble.
   Our experimental studies have shown that the proposed classifier can be improved by developing an ensemble of convolutional neural networks, which considers the functions proposed in the present approach. The results imply the prospective application of the developed approach for building classification models not only for medical diagnostics but also for general problems of machine vision based on small samples.
C1 [Aksenov, S. V.; Zamyatin, A. V.] Natl Res Tomsk State Univ, Dept Theoret Fdn Informat, 36 Lenin Ave, Tomsk 634050, Russia.
   [Aksenov, S. V.; Kostin, K. A.] Natl Res Tomsk Polytech Univ, Dept Informat Technol, 30 Lenin Ave, Tomsk 634050, Russia.
   [Aksenov, S. V.] Tomsk State Univ Control Syst & Radioelect, Dept Informat Proc Automat, 40 Lenin Ave, Tomsk 634050, Russia.
   [Kostin, K. A.; Ivanova, A. V.; Zamyatin, A. V.] Natl Res Tomsk State Univ, Sci & Educ Ctr Comp Sci & Technol, 36 Lenin Ave, Tomsk 634050, Russia.
   [Liang, J.] Arizona State Univ, Univ Ctr, Biodesign Ctr Biosignatures Discovery Automat, 411 N Cent Ave, Phoenix, AZ 85004 USA.
C3 Tomsk State University; Tomsk Polytechnic University; Tomsk State
   University of Control Systems & Radioelectronics; Tomsk State
   University; Arizona State University; Arizona State University-Downtown
   Phoenix
RP Zamyatin, AV (通讯作者)，Natl Res Tomsk State Univ, Dept Theoret Fdn Informat, 36 Lenin Ave, Tomsk 634050, Russia.; Zamyatin, AV (通讯作者)，Natl Res Tomsk State Univ, Sci & Educ Ctr Comp Sci & Technol, 36 Lenin Ave, Tomsk 634050, Russia.
EM avzamyatin@inbox.ru
RI Zamyatin, Alexander V./J-8755-2014
OI Zamyatin, Alexander V./0000-0002-1416-7472; Liang,
   Jianming/0000-0001-5486-1613
FU Russian Foundation for Basic Research [16-47-700289]
FX The research was conducted within the framework of the program for
   increasing the competitiveness of the National Research Tomsk State
   University and was supported by Russian Foundation for Basic Research
   (grant No. 16-47-700289).
CR Aksenov S. V., 2016, INFORM TEKHNOLOGII M, P75
   Axyonov S, 2016, DISTRIBUTED COMPUTER, P27
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Flach P., 2015, MASHINNOE OBUCHENIE
   Goel RM, 2014, BRIT J GEN PRACT, V64, P154, DOI 10.3399/bjgp14X677680
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Li B., 2009, INT C ROB BIOM ROBIO, DOI [10.1109/robio.2009.5420969, DOI 10.1109/ROBIO.2009.5420969]
   Li BP, 2009, IEEE ENG MED BIO, P3731, DOI 10.1109/IEMBS.2009.5334875
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Liu LZ, 2016, ACAD RADIOL, V23, P1024, DOI 10.1016/j.acra.2016.03.010
   Moon WK, 2013, IEEE T MED IMAGING, V32, P1191, DOI 10.1109/TMI.2012.2230403
   Nibali A, 2017, INT J COMPUT ASS RAD, V12, P1799, DOI 10.1007/s11548-017-1605-6
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Silva FB, 2011, GASTROINTEST ENDOSC, V73, P7, DOI 10.1016/j.gie.2010.09.023
   Song SE, 2015, CANCER IMAGING, V15, DOI 10.1186/s40644-015-0036-2
   State Scientific Center of Coloproctology of the Federal Health Service. Department of endoscopic surgery, HOW IS A COL
   Sudharani K, 2016, PROC TECH, V24, P1374, DOI 10.1016/j.protcy.2016.05.153
   Tajbakhsh N., 2015, IEEE 12 INT S BIOM I, DOI [10.1109/isbi.2015.7163821, DOI 10.1109/ISBI.2015.7163821]
   Tajbakhsh N, 2015, LECT NOTES COMPUT SC, V9350, P62, DOI 10.1007/978-3-319-24571-3_8
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Taylor FR, 2016, THESIS
   Uglov A. S., 2017, INFORM TEKHNOLOGII M, P126
   Varol G, 2015, EXPERT SYST APPL, V42, P8274, DOI 10.1016/j.eswa.2015.06.013
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Zhu R., 2015, 8 INT C IM SIGN PROC, DOI [10.1109/cisp.2015.7407907, DOI 10.1109/CISP.2015.7407907]
NR 28
TC 2
Z9 3
U1 0
U2 3
PU NIZHNIY NOVGOROD STATE MEDICAL ACAD
PI NIZHNIY NOVGOROD
PA MININ & POZHARSKY SQUARE, 10-1, NIZHNIY NOVGOROD, 603005, RUSSIA
SN 2076-4243
J9 SOVREM TEHNOL MED
JI Sovrem. Tehnol. Med.
PY 2018
VL 10
IS 2
BP 7
EP 17
DI 10.17691/stm2018.10.2.01
PG 11
WC Medicine, Research & Experimental
WE Emerging Sources Citation Index (ESCI)
SC Research & Experimental Medicine
GA GK7JP
UT WOS:000436377300001
OA Green Submitted, gold
DA 2023-04-20
ER

PT J
AU Ghosh, T
   Fattah, SA
   Wahid, KA
AF Ghosh, Tonmoy
   Fattah, Shaikh Anowarul
   Wahid, Khan A.
TI CHOBS: Color Histogram of Block Statistics for Automatic Bleeding
   Detection in Wireless Capsule Endoscopy Video
SO IEEE JOURNAL OF TRANSLATIONAL ENGINEERING IN HEALTH AND MEDICINE
LA English
DT Article
DE Bleeding detection; bleeding zone; color histogram; feature extraction;
   wireless capsule endoscopy
ID ENHANCEMENT
AB Wireless capsule endoscopy (WCE) is the most advanced technology to visualize whole gastrointestinal (GI) tract in a non-invasive way. But the major disadvantage here, it takes long reviewing time, which is very laborious as continuous manual intervention is necessary. In order to reduce the burden of the clinician, in this paper, an automatic bleeding detection method for WCE video is proposed based on the color histogram of block statistics, namely CHOBS. A single pixel in WCE image may be distorted due to the capsule motion in the GI tract. Instead of considering individual pixel values, a block surrounding to that individual pixel is chosen for extracting local statistical features. By combining local block features of three different color planes of RGB color space, an index value is defined. A color histogram, which is extracted from those index values, provides distinguishable color texture feature. A feature reduction technique utilizing color histogram pattern and principal component analysis is proposed, which can drastically reduce the feature dimension. For bleeding zone detection, blocks are classified using extracted local features that do not incorporate any computational burden for feature extraction. From extensive experimentation on several WCE videos and 2300 images, which are collected from a publicly available database, a very satisfactory bleeding frame and zone detection performance is achieved in comparison to that obtained by some of the existing methods. In the case of bleeding frame detection, the accuracy, sensitivity, and specificity obtained from proposed method are 97.85%, 99.47%, and 99.15%, respectively, and in the case of bleeding zone detection, 95.75% of precision is achieved. The proposed method offers not only low feature dimension but also highly satisfactory bleeding detection performance, which even can effectively detect bleeding frame and zone in a continuous WCE video data.
C1 Pabna Univ Sci & Technol, Dept Elect Elect Engn, Pabna 6600, Bangladesh.
   [Fattah, Shaikh Anowarul] Bangladesh Univ Engn & Technol, Dept Elect Elect Engn, Dhaka 1000, Bangladesh.
   Univ Saskatchewan, Dept ECE, Saskatoon, SK S7N 5A9, Canada.
C3 Bangladesh University of Engineering & Technology (BUET); University of
   Saskatchewan
RP Fattah, SA (通讯作者)，Bangladesh Univ Engn & Technol, Dept Elect Elect Engn, Dhaka 1000, Bangladesh.
EM fattah@eee.buet.ac.bd
RI Ghosh, Tonmoy/AAP-7360-2020
OI Ghosh, Tonmoy/0000-0003-1460-2267
CR Adler DG., 2003, HOSP PHYS, V39, P14
   ALTMAN DG, 1994, BRIT MED J, V308, P1552, DOI 10.1136/bmj.308.6943.1552
   [Anonymous], 2014, INT C INFORMATICS EL
   Conversano F, 2014, IEEE INT SYM MED MEA, P535
   Conversano F, 2011, ACAD RADIOL, V18, P461, DOI 10.1016/j.acra.2010.11.015
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ghosh T, 2014, IEEE INT SYMP SIGNAL, P256, DOI 10.1109/ISSPIT.2014.7300597
   Ghosh T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1293, DOI 10.1109/ICDSP.2015.7252090
   Ghosh T, 2014, IEEE ENG MED BIO, P4683, DOI 10.1109/EMBC.2014.6944669
   Ghosh T, 2014, INT CONF ELECTR ENG
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Imtiaz MS, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/607407
   Kobayashi Y, 2012, J DIGEST DIS, V13, P614, DOI 10.1111/j.1751-2980.2012.00641.x
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Liu JG, 2009, OPTIM ENG, V10, P289, DOI 10.1007/s11081-008-9066-y
   Mackiewicz M, 2008, PROC SPIE, V6914, DOI 10.1117/12.770510
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sainju S, 2013, CAN CON EL COMP EN, P539
   Sakai E, 2012, BMC GASTROENTEROL, V12, DOI 10.1186/1471-230X-12-83
   STRICKER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P704, DOI 10.1109/CVPR.1994.323774
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
NR 27
TC 32
Z9 32
U1 2
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2372
J9 IEEE J TRANSL ENG HE
JI IEEE J. Transl. Eng. Health Med.-JTEHM
PY 2018
VL 6
AR 1800112
DI 10.1109/JTEHM.2017.2756034
PG 12
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA FW4YC
UT WOS:000425321000001
PM 29468094
OA gold, Green Published
DA 2023-04-20
ER

PT J
AU Imler, TD
   Sherman, S
   Imperiale, TF
   Xu, HP
   Ouyang, FQ
   Beesley, C
   Hilton, C
   Cote, GA
AF Imler, Timothy D.
   Sherman, Stuart
   Imperiale, Thomas F.
   Xu, Huiping
   Ouyang, Fangqian
   Beesley, Christopher
   Hilton, Charity
   Cote, Gregory A.
TI Provider-specific quality measurement for ERCP using natural language
   processing
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID ENDOSCOPIC RETROGRADE CHOLANGIOPANCREATOGRAPHY; ADENOMA DETECTION RATES;
   COLONOSCOPY QUALITY; INDICATORS; VOLUME; CARE
AB Background and Aims: Natural language processing (NLP) is an information retrieval technique that has been shown to accurately identify quality measures for colonoscopy. There are no systematic methods by which to track adherence to quality measures for ERCP, the highest risk endoscopic procedure widely used in practice. Our aim was to demonstrate the feasibility of using NLP to measure adherence to ERCP quality indicators across individual providers.
   Methods: ERCPs performed by 6 providers at a single institution from 2006 to 2014 were identified. Quality measures were defined using society guidelines and from expert opinion, and then extracted using a combination of NLP and data mining (eg, ICD9-CM codes). Validation for each quality measure was performed by manual record review. Quality measures were grouped into preprocedure (5), intraprocedure (6), and postprocedure (2). NLP was evaluated using measures of precision and accuracy.
   Results: A total of 23,674 ERCPs were analyzed (average patient age, 52.9 +/- 17.8 years, 14,113 were women [59.6%]). Among 13 quality measures, precision of NLP ranged from 84% to 100% with intraprocedure measures having lower precision (84% for precut sphincterotomy). Accuracy of NLP ranged from 90% to 100% with intraprocedure measures having lower accuracy (90% for pancreatic stent placement).
   Conclusions: NLP in conjunction with data mining facilitates individualized tracking of ERCP providers for quality metrics without the need for manual medical record review. Incorporation of these tools across multiple centers may permit tracking of ERCP quality measures through national registries.
C1 [Imler, Timothy D.; Sherman, Stuart; Imperiale, Thomas F.; Cote, Gregory A.] Indiana Univ Sch Med, Div Gastroenterol & Hepatol, Indianapolis, IN 46202 USA.
   [Imler, Timothy D.; Sherman, Stuart; Imperiale, Thomas F.] Indiana Univ Sch Med, Dept Med, Indianapolis, IN 46202 USA.
   [Imler, Timothy D.; Beesley, Christopher; Hilton, Charity] Regenstrief Inst LLC, Dept Biomed Informat, Indianapolis, IN USA.
   [Imperiale, Thomas F.] Richard L Roudebush VA Med Ctr, Ctr Innovat Hlth Serv Res & Dev, Indianapolis, IN USA.
   [Imperiale, Thomas F.] Regenstrief Inst LLC, Hlth Serv Res, Indianapolis, IN USA.
   [Xu, Huiping; Ouyang, Fangqian] Indiana Univ Sch Med, Dept Biostat, Indianapolis, IN 46202 USA.
   [Cote, Gregory A.] Med Univ South Carolina, Div Gastroenterol & Hepatol, Charleston, SC USA.
C3 Indiana University System; Indiana University Bloomington; Indiana
   University System; Indiana University Bloomington; US Department of
   Veterans Affairs; Veterans Health Administration (VHA); Richard L.
   Roudebush VA Medical Center; Indiana University System; Indiana
   University Bloomington; Medical University of South Carolina
RP Imler, TD (通讯作者)，Div Gastroenterol & Hepatol, 702 Rotary Circle,Suite 225, Indianapolis, IN 46202 USA.; Imler, TD (通讯作者)，Regenstrief Inst Hlth Care, 702 Rotary Circle,Suite 225, Indianapolis, IN 46202 USA.
EM timler@iu.edu
OI Imperiale, Thomas/0000-0001-7586-1073; /0000-0003-2594-1993
FU American Society for Gastrointestinal Endoscopy Covidien Senior
   Investigator Mentoring Award (Imperiale); American Society for
   Gastrointestinal Endoscopy Career Development Award (Imler)
FX Dr Timothy Imler had full access to all of the data in the study and
   takes responsibility for the integrity of the data and accuracy of the
   data analysis. This work was performed at the Regenstrief Institute,
   Indianapolis, Indiana, and was supported in part by the American Society
   for Gastrointestinal Endoscopy Covidien Senior Investigator Mentoring
   Award (Imperiale) and the American Society for Gastrointestinal
   Endoscopy Career Development Award (Imler).
CR Adler DG, 2015, GASTROINTEST ENDOSC, V81, P54, DOI 10.1016/j.gie.2014.07.056
   Anderson MA, 2012, GASTROINTEST ENDOSC, V75, P467, DOI 10.1016/j.gie.2011.07.010
   Biondich Paul G, 2004, J Public Health Manag Pract, VSuppl, pS81
   Colton JB, 2009, GASTROINTEST ENDOSC, V70, P457, DOI 10.1016/j.gie.2008.11.022
   Corley DA, 2011, GASTROINTEST ENDOSC, V74, P656, DOI 10.1016/j.gie.2011.04.017
   Cote GA, 2013, MED CARE, V51, P1040, DOI 10.1097/MLR.0b013e3182a502dc
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Gawron AJ, 2014, AM J GASTROENTEROL, V109, P1844, DOI 10.1038/ajg.2014.147
   Harkema H, 2011, J AM MED INFORM ASSN, V18, pI150, DOI 10.1136/amiajnl-2011-000431
   Hewett DG, 2010, AM J GASTROENTEROL, V105, P1925, DOI 10.1038/ajg.2010.247
   Imler TD, 2015, AM J GASTROENTEROL, V110, P543, DOI 10.1038/ajg.2015.51
   Imler TD, 2013, CLIN GASTROENTEROL H, V11, P689, DOI 10.1016/j.cgh.2012.11.035
   Kahi CJ, 2013, GASTROINTEST ENDOSC, V77, P925, DOI 10.1016/j.gie.2013.01.012
   Kapral C, 2008, ENDOSCOPY, V40, P625, DOI 10.1055/s-2008-1077461
   McDonald CJ, 2005, HEALTH AFFAIR, V24, P1214, DOI 10.1377/hlthaff.24.5.1214
   Mehrotra A, 2012, GASTROINTEST ENDOSC, V75, P1233, DOI 10.1016/j.gie.2012.01.045
   Park WG, 2015, GASTROINTEST ENDOSC, V81, P17, DOI 10.1016/j.gie.2014.07.057
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Solad Y, 2015, AM J GASTROENTEROL, V110, P215, DOI 10.1038/ajg.2014.201
   Wani S, 2015, GASTROINTEST ENDOSC, P8167
NR 20
TC 9
Z9 10
U1 0
U2 2
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JAN
PY 2018
VL 87
IS 1
BP 164
EP +
DI 10.1016/j.gie.2017.04.030
PG 12
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA FP9IQ
UT WOS:000417961100022
PM 28476375
OA Green Submitted, Green Accepted
DA 2023-04-20
ER

PT J
AU Kundu, AK
   Fattah, SA
   Rizve, MN
AF Kundu, Amit Kumar
   Fattah, Shaikh Anowarul
   Rizve, Mamshad Nayeem
TI An Automatic Bleeding Frame and Region Detection Scheme for Wireless
   Capsule Endoscopy Videos Based on Interplane Intensity Variation Profile
   in Normalized RGB Color Space
SO JOURNAL OF HEALTHCARE ENGINEERING
LA English
DT Article
ID SUSPECTED BLOOD INDICATOR; IMAGE SEGMENTATION; SENSITIVITY
AB Wireless capsule endoscopy (WCE) is an effective video technology to diagnose gastrointestinal (GI) disease, such as bleeding. In order to avoid conventional tedious and risky manual review process of long duration WCE videos, automatic bleeding detection schemes are getting importance. In this paper, to investigate bleeding, the analysis of WCE images is carried out in normalized RGB color space as human perception of bleeding is associated with different shades of red. In the proposed method, at first, from the WCE image frame, an efficient region of interest (ROI) is extracted based on interplane intensity variation profile in normalized RGB space. Next, from the extracted ROI, the variation in the normalized green plane is presented with the help of histogram. Features are extracted from the proposed normalized green plane histograms. For classification purpose, the K-nearest neighbors classifier is employed. Moreover, bleeding zones in a bleeding image are extracted utilizing some morphological operations. For performance evaluation, 2300 WCE images obtained from 30 publicly available WCE videos are used in a tenfold cross-validation scheme and the proposed method outperforms the reported four existing methods having an accuracy of 97.86%, a sensitivity of 95.20%, and a specificity of 98.32%.
C1 [Kundu, Amit Kumar; Fattah, Shaikh Anowarul; Rizve, Mamshad Nayeem] Bangladesh Univ Engn & Technol, Dept Elect & Elect Engn, Dhaka, Bangladesh.
C3 Bangladesh University of Engineering & Technology (BUET)
RP Fattah, SA (通讯作者)，Bangladesh Univ Engn & Technol, Dept Elect & Elect Engn, Dhaka, Bangladesh.
EM fattah@eee.buet.ac.bd
CR Adler DG., 2003, HOSP PHYS, V39, P14
   ALTMAN DG, 1994, BRIT MED J, V308, P1552, DOI 10.1136/bmj.308.6943.1552
   ANDREADIS I, 1990, PATTERN RECOGN LETT, V11, P51, DOI 10.1016/0167-8655(90)90055-7
   Buscaglia JM, 2008, CLIN GASTROENTEROL H, V6, P298, DOI 10.1016/j.cgh.2007.12.029
   Chen Y., 2012, DIAGNOSTIC THERAPEUT, V2012
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Conversano F., 2014, P IEEE MED MEAS APPL, P1
   Conversano F, 2011, ACAD RADIOL, V18, P461, DOI 10.1016/j.acra.2010.11.015
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ghosh T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1293, DOI 10.1109/ICDSP.2015.7252090
   Ghosh T, 2014, IEEE ENG MED BIO, P4683, DOI 10.1109/EMBC.2014.6944669
   Ghosh T., 2015, TENCON IEEE REGION, P1, DOI [10.1109/TENCON.2015.7373186, DOI 10.1109/TENCON.2015.7373186]
   Gonzales R.C., 2008, DIGITAL IMAGE PROCES, V3rd
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Kundu AK, 2016, IEEE STUDENT TECHNOL, P245, DOI 10.1109/TechSym.2016.7872690
   Kundu AK, 2015, 2015 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (WIECON-ECE), P455, DOI 10.1109/WIECON-ECE.2015.7443966
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Mewes PW, 2011, LECT NOTES COMPUT SC, V6893, P141, DOI 10.1007/978-3-642-23626-6_18
   NEVATIA R, 1977, IEEE T SYST MAN CYB, V7, P820
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Park SC, 2012, WORLD J GASTROENTERO, V18, P4169, DOI 10.3748/wjg.v18.i31.4169
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sainju S, 2013, CAN CON EL COMP EN, P539
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Tkalcic M, 2003, IEEE REGION 8 EUROCON 2003, VOL A, PROCEEDINGS, P304
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
NR 26
TC 16
Z9 16
U1 1
U2 5
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2040-2295
EI 2040-2309
J9 J HEALTHC ENG
JI J. Healthc. Eng.
PY 2018
VL 2018
AR 9423062
DI 10.1155/2018/9423062
PG 12
WC Health Care Sciences & Services
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services
GA FY9ZE
UT WOS:000427225000001
PM 29682270
OA Green Published, Green Submitted
DA 2023-04-20
ER

PT S
AU Luo, XB
   Mori, K
   Peters, TM
AF Luo, Xiongbiao
   Mori, Kensaku
   Peters, Terry M.
BE Yamush, ML
TI Advanced Endoscopic Navigation: Surgical Big Data, Methodology, and
   Applications
SO ANNUAL REVIEW OF BIOMEDICAL ENGINEERING, VOL 20
SE Annual Review of Biomedical Engineering
LA English
DT Review; Book Chapter
DE endoscopy; big data; image-guided intervention; surgical robotics;
   surgical navigation; augmented reality; artificial intelligence; deep
   learning; endoscopic vision; image registration; 3D printing
ID OPTICAL COHERENCE TOMOGRAPHY; EMISSION COMPUTED-TOMOGRAPHY; AUGMENTED
   REALITY; VIDEO REGISTRATION; MOTION ESTIMATION; SURGERY; CT;
   LOCALIZATION; RESECTION; TRACKING
AB Interventional endoscopy (e.g., bronchoscopy, colonoscopy, laparoscopy, cystoscopy) is a widely performed procedure that involves either diagnosis of suspicious lesions or guidance for minimally invasive surgery in a variety of organs within the body cavity. Endoscopy may also be used to guide the introduction of certain items (e.g., stents) into the body. Endoscopic navigation systems seek to integrate big data with multimodal information (e.g., computed tomography, magnetic resonance images, endoscopic video sequences, ultrasound images, external trackers) relative to the patient's anatomy, control the movement of medical endoscopes and surgical tools, and guide the surgeon's actions during endoscopic interventions. Nevertheless, it remains challenging to realize the next generation of context-aware navigated endoscopy. This review presents a broad survey of various aspects of endoscopic navigation, particularly with respect to the development of endoscopic navigation techniques. First, we investigate big data with multimodal information involved in endoscopic navigation. Next, we focus on numerous methodologies used for endoscopic navigation. We then review different endoscopic procedures in clinical applications. Finally, we discuss novel techniques and promising directions for the development of endoscopic navigation.
C1 [Luo, Xiongbiao] Xiamen Univ, Fujian Key Lab Comp & Sensing Smart City, Dept Comp Sci, Xiamen 361005, Peoples R China.
   [Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Dept Intelligent Syst, Nagoya, Aichi 4648601, Japan.
   [Peters, Terry M.] Western Univ, Robarts Res Inst, London, ON N6A 3K7, Canada.
C3 Xiamen University; Nagoya University; Western University (University of
   Western Ontario)
RP Luo, XB (通讯作者)，Xiamen Univ, Fujian Key Lab Comp & Sensing Smart City, Dept Comp Sci, Xiamen 361005, Peoples R China.
EM xbluo@xmu.edu.cn; kensaku@is.nagoya-u.ac.jp; tpeters@robarts.ca
OI Mori, Kensaku/0000-0002-0100-4797
FU CIHR Funding Source: Medline
CR Antoniou SA, 2012, SURG ENDOSC, V26, P3650, DOI 10.1007/s00464-012-2389-y
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Bailey DL, 2013, J NUCL MED, V54, P83, DOI 10.2967/jnumed.112.111476
   Bankman IN, 2008, HDB MEDICAL IMAGE PR
   Bao GQ, 2015, IEEE SENS J, V15, P2669, DOI 10.1109/JSEN.2014.2367495
   Barsom EZ, 2016, SURG ENDOSC, V30, P4174, DOI 10.1007/s00464-016-4800-6
   Baum Z, 2017, P SOC PHOTO-OPT INS, V10135
   Bernhardt S, 2017, MED IMAGE ANAL, V37, P66, DOI 10.1016/j.media.2017.01.007
   Bhatt J, 2010, BJU INT, V106, P1425, DOI 10.1111/j.1464-410X.2010.09717.x
   Bruyant PP, 2002, J NUCL MED, V43, P1343
   Bush CM, 2013, OTOLARYNG CLIN N AM, V46, P41, DOI 10.1016/j.otc.2012.08.016
   Campbell IS, 2016, ANN INTERN MED, V165, P214, DOI 10.7326/M16-0025
   Chu YK, 2017, MED IMAGE ANAL, V42, P241, DOI 10.1016/j.media.2017.08.003
   Citardi MJ, 2016, INT FORUM ALLERGY RH, V6, P523, DOI 10.1002/alr.21702
   Cleary K, 2010, ANNU REV BIOMED ENG, V12, P119, DOI 10.1146/annurev-bioeng-070909-105249
   Collins JA, 2017, IEEE T MED IMAGING, V36, P1502, DOI 10.1109/TMI.2017.2668842
   Curtis W, 2013, INT J RADIAT ONCOL, V85, P700, DOI 10.1016/j.ijrobp.2012.05.044
   Cutsem E, 2014, ANN ONCOL, V25, piii1, DOI DOI 10.1093/ANN0NC/MDU260
   Daniilidis K, 1999, INT J ROBOT RES, V18, P286, DOI 10.1177/02783649922066213
   de Boer JF, 2017, BIOMED OPT EXPRESS, V8, P3248, DOI 10.1364/BOE.8.003248
   Dees-Ribbers HM, 2013, MED PHYS, V40, DOI 10.1118/1.4799842
   Deguchi D, 2012, INT J COMPUT ASS RAD, V7, P359, DOI 10.1007/s11548-011-0626-9
   Deguchi D, 2009, MED IMAGE ANAL, V13, P621, DOI 10.1016/j.media.2009.06.001
   Di Natali C, 2016, IEEE T ROBOT, V32, P327, DOI 10.1109/TRO.2016.2522433
   Drexler W., 2015, OPTICAL COHERENCE TO
   Ehlers JP, 2014, RETINA-J RET VIT DIS, V34, P213, DOI 10.1097/IAE.0b013e318297daf3
   Errico C, 2015, NATURE, V527, P499, DOI 10.1038/nature16066
   Fercher A F, 1996, J Biomed Opt, V1, P157, DOI 10.1117/12.231361
   Feuerstein M, 2009, IEEE T MED IMAGING, V28, P951, DOI 10.1109/TMI.2008.2008954
   Gerlach T, 2016, COGENT ENG, V3, DOI 10.1080/23311916.2016.1256563
   Ghani KR, 2016, EUR UROL, V70, P382, DOI 10.1016/j.eururo.2016.01.047
   Gill RR, 2015, J SURG ONCOL, V112, P18, DOI 10.1002/jso.23941
   Golby A. J., 2015, IMAGE GUIDED NEUROSU
   Greenwood JP, 2016, ANN INTERN MED, V165, P1, DOI 10.7326/M15-1801
   Hajnal J., 2001, MED IMAGE REGISTRATI
   Hansen TB, 2014, HAND CLIN, V30, P47, DOI 10.1016/j.hcl.2013.08.018
   Haouchine N, 2015, IEEE T VIS COMPUT GR, V21, P584, DOI 10.1109/TVCG.2014.2377772
   Haraldsen A, 2016, CLIN PHYSIOL FUNCT I, V36, P40, DOI 10.1111/cpf.12191
   Hartley R, 2007, IEEE T PATTERN ANAL, V29, P1309, DOI 10.1109/TPAMI.2007.1147
   Hayashi Y, 2016, INT J COMPUT ASS RAD, V11, P827, DOI 10.1007/s11548-015-1293-z
   Hekimian-Williams Cory, 2010, 2010 IEEE International Conference on RFID (IEEE RFID 2010), P89, DOI 10.1109/RFID.2010.5467268
   Heller J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3497, DOI 10.1109/CVPR.2011.5995629
   Heller J, 2016, IEEE T PATTERN ANAL, V38, P1027, DOI 10.1109/TPAMI.2015.2469299
   Holler K, 2009, LECT NOTES COMPUT SC, V5761, P459, DOI 10.1007/978-3-642-04268-3_57
   Hofstad EF, 2014, MED PHYS, V41, DOI 10.1118/1.4866884
   HORAUD R, 1995, INT J ROBOT RES, V14, P195, DOI 10.1177/027836499501400301
   Housden RJ, 2007, HYBRID SYSTEMS RECON
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Hughes-Hallett A, 2014, UROLOGY, V83, P266, DOI 10.1016/j.urology.2013.08.049
   Inoue M, 2015, MED PHYS, V42, P1904, DOI 10.1118/1.4915534
   Jia YL, 2014, OPHTHALMOLOGY, V121, P1435, DOI 10.1016/j.ophtha.2014.01.034
   JohansenBerg H, 2009, DIFFUSION MRI: FROM QUANTITATIVE MEASUREMENT TO IN VIVO NEUROANATOMY, P1
   Kallewaard JW, 2014, PAIN PRACT, V14, P365, DOI 10.1111/papr.12104
   Kang X, 2014, SURG ENDOSC, V28, P2227, DOI 10.1007/s00464-014-3433-x
   Kapila SD, 2014, CONE BEAM COMPUTED TOMOGRAPHY IN ORTHODONTICS: INDICATIONS, INSIGHTS, AND INNOVATIONS, P1, DOI 10.1002/9781118674888
   Karargyris A, 2015, IEEE T BIO-MED ENG, V62, P352, DOI 10.1109/TBME.2014.2352493
   Klayton T, 2012, INT J RADIAT ONCOL, V84, P130, DOI 10.1016/j.ijrobp.2011.11.041
   Klein BR, 2016, J CATARACT REFR SURG, V42, P537, DOI 10.1016/j.jcrs.2016.01.036
   Klein T, 2007, LECT NOTES COMPUT SC, V4791, P475
   KleinJan GH, 2014, EUR UROL, V66, P991, DOI 10.1016/j.eururo.2014.07.014
   Kobatake H., 2017, COMPUTATIONAL ANATOM
   Koizumi N, 2002, LECT NOTES COMPUT SC, V2488, P60
   Konda V.J.A., 2016, ENDOSCOPIC IMAGING T
   Kuhn AWB, 2015, SPORTS MED ARTHROSC, V23, pe31
   Leggett CL, 2016, GASTROINTEST ENDOSC, V83, P880, DOI 10.1016/j.gie.2015.08.050
   Li M, 2014, ENDOSCOPY, V46, DOI 10.1055/s-0034-1365813
   Li Y, 2004, IEEE T BIO-MED ENG, V51, P2040, DOI 10.1109/TBME.2004.834290
   Luo XB, 2017, IEEE T MED IMAGING, V36, P2021, DOI 10.1109/TMI.2017.2701861
   Luo XB, 2015, MED IMAGE ANAL, V24, P282, DOI 10.1016/j.media.2015.01.002
   Luo XB, 2015, MED PHYS, V42, P1808, DOI 10.1118/1.4915285
   Luo XB, 2014, LECT NOTES COMPUT SC, V8674, P340, DOI 10.1007/978-3-319-10470-6_43
   Luo XB, 2015, COMPUT METH PROG BIO, V118, P147, DOI 10.1016/j.cmpb.2014.11.008
   Luo XB, 2014, COMPUT MED IMAG GRAP, V38, P540, DOI 10.1016/j.compmedimag.2014.06.013
   Luo XB, 2014, MED PHYS, V41, DOI 10.1118/1.4876381
   Luo XB, 2014, IEEE T MED IMAGING, V33, P1248, DOI 10.1109/TMI.2014.2307052
   Luo XB, 2014, IEEE T BIO-MED ENG, V61, P85, DOI 10.1109/TBME.2013.2277609
   Luo XB, 2013, IEEE T MED IMAGING, V32, P1745, DOI 10.1109/TMI.2013.2263152
   Luo XB, 2012, INT J COMPUT ASS RAD, V7, P371, DOI 10.1007/s11548-011-0645-6
   Luo XB, 2012, MED IMAGE ANAL, V16, P577, DOI 10.1016/j.media.2010.11.001
   Mahara A, 2015, IEEE T MED IMAGING, V34, P1590, DOI 10.1109/TMI.2015.2407833
   Malik HH, 2015, J SURG RES, V199, P512, DOI 10.1016/j.jss.2015.06.051
   Marchetti G, 2015, CHEST, V147, P1008, DOI 10.1378/chest.14-0637
   Marcus HJ, 2015, NEUROSURG REV, V38, P367, DOI 10.1007/s10143-014-0602-2
   Mariappan P, 2017, UROLOGY, V109, P134, DOI 10.1016/j.urology.2017.08.007
   Marks JM, 2013, PRINCIPLES FLEXIBLE
   Mcgee MF, 2006, SURG INNOV, V13, P86, DOI 10.1177/1553350606290529
   McLeod AJ, 2014, PROC SPIE, V9036, DOI 10.1117/12.2043997
   Memon A, 2015, BRIT J CANCER, V105, P1850
   Merritt SA, 2013, IEEE T MED IMAGING, V32, P1376, DOI 10.1109/TMI.2013.2252361
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mirota DJ, 2013, IEEE T MED IMAGING, V32, P1215, DOI 10.1109/TMI.2013.2243464
   Moreland K, 2013, IEEE T VIS COMPUT GR, V19, P367, DOI 10.1109/TVCG.2012.133
   Morelli L, 2018, SURG ENDOSC, V32, P589, DOI 10.1007/s00464-017-5708-5
   Munsell BC, 2016, ELS MIC SOC BOOK SER, P455, DOI 10.1016/B978-0-12-804076-8.00016-5
   Nezhat C, 2011, NEZHATS HIST ENDOSCO
   Nielson GM, 2003, IEEE T VIS COMPUT GR, V9, P283, DOI 10.1109/TVCG.2003.1207437
   Oda M, 2017, INT J COMPUT ASS RAD, V12, P39, DOI 10.1007/s11548-016-1456-6
   Preim B, 2007, VISUALIZATION MED TH
   Pullens HJM, 2016, ENDOSCOPY, V48, P286, DOI 10.1055/s-0034-1392550
   Ramalingam S, 2017, IEEE T PATTERN ANAL, V39, P1309, DOI 10.1109/TPAMI.2016.2592904
   Reck M, 2013, LANCET, V382, P709, DOI 10.1016/S0140-6736(13)61502-0
   Reichl T, 2013, INT J COMPUT ASS RAD, V8, P955, DOI 10.1007/s11548-013-0835-5
   Roberts-Thomson IC, 2010, J GASTROEN HEPATOL, V25, P1051, DOI 10.1111/j.1440-1746.2010.06333.x
   Robu MR, 2017, INT J COMPUT ASS RAD, V12, P1079, DOI 10.1007/s11548-017-1584-7
   Rochitte CE, 2014, EUR HEART J, V35, P1120, DOI 10.1093/eurheartj/eht488
   Roth HR, 2014, PROC SPIE, V9036, DOI 10.1117/12.2042860
   Ruttkay T, 2015, INNOVATIONS, V10, P431, DOI 10.1097/IMI.0000000000000216
   Sadowski SM, 2016, J CLIN ONCOL, V34, P588, DOI 10.1200/JCO.2015.64.0987
   Davila JS, 2016, SURG ENDOSC, V30, P199, DOI 10.1007/s00464-015-4183-0
   Schneider A, 2014, LECT NOTES COMPUT SC, V8674, P357, DOI 10.1007/978-3-319-10470-6_45
   Schork NJ, 2015, NATURE, V520, P609, DOI 10.1038/520609a
   Semmler M, 2016, IEEE T MED IMAGING, V35, P1615, DOI 10.1109/TMI.2016.2521419
   Shaw C.C., 2014, CONE BEAM COMPUTED T
   Shen ML, 2015, INT J COMPUT ASS RAD, V10, P801, DOI 10.1007/s11548-015-1197-y
   Shi CY, 2017, IEEE T BIO-MED ENG, V64, P1665, DOI 10.1109/TBME.2016.2622361
   SHIU YC, 1989, IEEE T ROBOTIC AUTOM, V5, P16, DOI 10.1109/70.88014
   Simpson AL, 2014, IEEE T BIO-MED ENG, V61, P1833, DOI 10.1109/TBME.2014.2308299
   Smistad E, 2015, MED IMAGE ANAL, V20, P1, DOI 10.1016/j.media.2014.10.012
   Soper TD, 2010, IEEE T BIO-MED ENG, V57, P736, DOI 10.1109/TBME.2009.2034733
   Srinivasan VM, 2016, J NEUROINTERV SURG, V8, P69, DOI 10.1136/neurintsurg-2014-011422
   Sylvester PT, 2015, PITUITARY, V18, P72, DOI 10.1007/s11102-014-0560-2
   Szeliski R., 2011, COMPUTER VISION ALGO
   Tabrizi LB, 2015, J NEUROSURG, V123, P206, DOI 10.3171/2014.9.JNS141001
   Toney LK, 2014, J THORAC CARDIOV SUR, V148, P2345, DOI 10.1016/j.jtcvs.2014.04.036
   Than TD, 2012, IEEE T BIO-MED ENG, V59, P2387, DOI 10.1109/TBME.2012.2201715
   TSAI RY, 1989, IEEE T ROBOTIC AUTOM, V5, P345, DOI 10.1109/70.34770
   Vahrmeijer AL, 2013, NAT REV CLIN ONCOL, V10, P507, DOI 10.1038/nrclinonc.2013.123
   van der Stap N, 2014, LECT NOTES COMPUT SC, V8899, P77, DOI 10.1007/978-3-319-13410-9_8
   Vecchia RRD, 2017, OPER NEUROSURG, V2017
   Vemulapalli R, 2017, ELS MIC SOC BOOK SER, P381, DOI 10.1016/B978-0-12-810408-8.00022-5
   Viergever MA, 2016, MED IMAGE ANAL, V33, P140, DOI 10.1016/j.media.2016.06.030
   Wallerstedt A, 2015, EUR UROL, V67, P660, DOI 10.1016/j.eururo.2014.09.036
   Wedeen VJ, 2008, NEUROIMAGE, V41, P1267, DOI 10.1016/j.neuroimage.2008.03.036
   Wille A., 2011, 2011 IEEE International Conference on RFID (IEEE RFID 2011), P98, DOI 10.1109/RFID.2011.5764608
   Winchester DE, 2015, J NUCL CARDIOL, V22, P9, DOI 10.1007/s12350-014-9925-1
   Wognum S, 2014, MED PHYS, V41, DOI 10.1118/1.4883839
   Xuan Y, 2013, SURG ENDOSC, V27, P4364, DOI 10.1007/s00464-013-3042-0
   Yan CH, 2015, KNEE SURG SPORT TR A, V23, P3637, DOI 10.1007/s00167-014-3264-2
   Yelbuz TM, 2002, CIRCULATION, V106, P2771, DOI 10.1161/01.CIR.0000042672.51054.7B
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zaidi HA, 2016, NEUROSURG FOCUS, V40, DOI 10.3171/2016.1.FOCUS15515
   Zhang HP, 2017, WORLD NEUROSURG, V104, P802, DOI 10.1016/j.wneu.2017.04.056
   Zhang L, 2015, IEEE T MED IMAGING, V34, P2550, DOI 10.1109/TMI.2015.2444815
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 144
TC 30
Z9 32
U1 15
U2 67
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 1523-9829
EI 1545-4274
J9 ANNU REV BIOMED ENG
JI Annu. Rev. Biomed. Eng.
PY 2018
VL 20
BP 221
EP 251
DI 10.1146/annurev-bioeng-062117-120917
PG 31
WC Engineering, Biomedical
WE Book Citation Index– Science (BKCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA BK2ZZ
UT WOS:000434421400010
PM 29505729
DA 2023-04-20
ER

PT J
AU Munzer, B
   Schoeffmann, K
   Boszormenyi, L
AF Muenzer, Bernd
   Schoeffmann, Klaus
   Boeszoermenyi, Laszlo
TI Content-based processing and analysis of endoscopic images and videos: A
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging; Endoscopic videos; Content-based video analysis;
   Medical multimedia
ID MINIMALLY INVASIVE SURGERY; WIRELESS CAPSULE ENDOSCOPY; LAPAROSCOPIC
   PARTIAL NEPHRECTOMY; AUGMENTED REALITY VISUALIZATION; SURFACE
   RECONSTRUCTION; DISTORTION CORRECTION; SURGICAL-INSTRUMENTS; FRAME
   CLASSIFICATION; AUTOMATIC DETECTION; RETRIEVAL-SYSTEM
AB In recent years, digital endoscopy has established as key technology for medical screenings and minimally invasive surgery. Since then, various research communities with manifold backgrounds have picked up on the idea of processing and automatically analyzing the inherently available video signal that is produced by the endoscopic camera. Proposed works mainly include image processing techniques, pattern recognition, machine learning methods and Computer Vision algorithms. While most contributions deal with real-time assistance at procedure time, the post-procedural processing of recorded videos is still in its infancy. Many post-processing problems are based on typical Multimedia methods like indexing, retrieval, summarization and video interaction, but have only been sparsely addressed so far for this domain. The goals of this survey are (1) to introduce this research field to a broader audience in the Multimedia community to stimulate further research, (2) to describe domain-specific characteristics of endoscopic videos that need to be addressed in a pre-processing step, and (3) to systematically bring together the very diverse research results for the first time to provide a broader overview of related research that is currently not perceived as belonging together.
C1 [Muenzer, Bernd; Schoeffmann, Klaus; Boeszoermenyi, Laszlo] Klagenfurt Univ, Lakeside Labs, Inst Informat Technol, Univ Str 65-67, A-9020 Klagenfurt, Austria.
C3 University of Klagenfurt
RP Munzer, B (通讯作者)，Klagenfurt Univ, Lakeside Labs, Inst Informat Technol, Univ Str 65-67, A-9020 Klagenfurt, Austria.
EM bernd@itec.aau.at; ks@itec.aau.at; laszlo@itec.aau.at
FU University of Klagenfurt; Lakeside Labs GmbH, Klagenfurt, Austria;
   European Regional Development Fund; Carinthian Economic Promotion Fund
   (KWF) [KWF-20214 U. 3520/26336/38165]
FX Open access funding provided by University of Klagenfurt. This work was
   supported by Universitat Klagenfurt and Lakeside Labs GmbH, Klagenfurt,
   Austria and funding from the European Regional Development Fund and the
   Carinthian Economic Promotion Fund (KWF) under grant KWF-20214 U.
   3520/26336/38165.
CR Ackerman JD, 2002, PROC SPIE, V4661, P39, DOI 10.1117/12.460179
   Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8_8
   Ahmadi SA, 2006, LECT NOTES COMPUT SC, V4190, P420
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Allan M, 2013, IEEE T BIO-MED ENG, V60, P1050, DOI 10.1109/TBME.2012.2229278
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Amir-Khalili A, 2013, LECT NOTES COMPUT SC, V8198, P184, DOI 10.1007/978-3-642-41083-3_21
   Arnold M, 2010, EURASIP J IMAGE VIDE, DOI 10.1155/2010/814319
   Arnold M, 2009, 2009 13TH INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, P47, DOI 10.1109/IMVIP.2009.16
   Asari KV, 1999, IEEE T MED IMAGING, V18, P345, DOI 10.1109/42.768843
   Atasoy S, 2010, LECT NOTES COMPUT SC, V6362, P437
   Barreto J., 2009, 20 BRIT MACH VIS C B
   Barreto JP, 2007, 3DTV CONF, P354
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Baumhauer M, 2008, J ENDOUROL, V22, P751, DOI 10.1089/end.2007.9827
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beecks C, 2015, IEEE INTL SYMPOSIUM
   Behrens A, 2011, IEEE ENG MED BIO, P6635, DOI 10.1109/IEMBS.2011.6091636
   Bergen T, 2016, IEEE J BIOMED HEALTH, V20, P304, DOI 10.1109/JBHI.2014.2384134
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2014, LECT NOTES COMPUT SC, V8899, P1, DOI 10.1007/978-3-319-13410-9_1
   Bernhardt Sylvain, 2013, Medical Computer Vision. Recognition Techniques and Applications in Medical Imaging. Second International MICCAI Workshop, MCV 2012. Revised Selected Papers, P254, DOI 10.1007/978-3-642-36620-8_25
   Bichlmeier C, 2009, IEEE T MED IMAGING, V28, P1498, DOI 10.1109/TMI.2009.2018622
   Bilodeau GA, 2006, COMPUT MED IMAG GRAP, V30, P437, DOI 10.1016/j.compmedimag.2006.07.003
   Blum T, 2010, LECT NOTES COMPUT SC, V6363, P400
   Bouarfa L, 2012, MINIM INVASIV THER, V21, P129, DOI 10.3109/13645706.2011.580764
   Braga J., 2013, PROCEDIA TECHNOL, V9, P1123
   Braga J, 2014, ADV INTELL SYST, V275, P239, DOI 10.1007/978-3-319-05951-8_23
   Buck SD, 2001, LECT NOTES COMPUT SC, V2208, P691
   Burschka D, 2005, MED IMAGE ANAL, V9, P413, DOI 10.1016/j.media.2005.05.005
   Burschka D, 2005, ROBOT AUTON SYST, V52, P5, DOI 10.1016/j.robot.2005.03.013
   Calonder M., 2010, BRIEF BINARY ROBUST
   Cano AM, 2008, LECT NOTES COMPUT SC, V5104, P191, DOI 10.1007/978-3-540-70521-5_21
   Cao Y, 2004, LECT NOTES COMPUT SC, V3115, P160
   Cao Y, 2007, IEEE T BIO-MED ENG, V54, P1268, DOI 10.1109/TBME.2007.890734
   Carlisle J., 2015, P 2015 13 INT WORKSH, P1
   Casals A, 1996, IEEE INT CONF ROBOT, P895, DOI 10.1109/ROBOT.1996.503886
   Chattopadhyay T, 2008, TENCON 2008 2008 IEE, P1
   Chengyu Wu, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P388, DOI 10.1109/FSKD.2009.202
   Chhatkuli A, 2014, IEEE INT S BIOM IM I
   Chowdhury M, 2015, PERCEPTION AND MACHINE INTELLIGENCE, 2015, P64, DOI 10.1145/2708463.2709046
   Chu XQ, 2010, LECT NOTES COMPUT SC, V6362, P522
   Climent J, 2012, COMPUT BIOL MED, V42, P614, DOI 10.1016/j.compbiomed.2012.02.007
   Collins Toby, 2012, Information Processing in Computer-Assisted Interventions. Proceedings Third International Conference, IPCAI 2012, P11, DOI 10.1007/978-3-642-30618-1_2
   Collins T, 2011, MEDICAL IMAGE UNDERS
   Collins T, 2014, INT SYM MIX AUGMENT, P243, DOI 10.1109/ISMAR.2014.6948434
   Collins T, 2012, LECT NOTES COMPUT SC, V7511, P634, DOI 10.1007/978-3-642-33418-4_78
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Dahyot R, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/139429
   Deguchi D, 2009, MED IMAGE ANAL, V13, P621, DOI 10.1016/j.media.2009.06.001
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Dickens MM, 1998, 11TH IEEE SYMPOSIUM ON COMPUTER-BASED MEDICAL SYSTEMS, PROCEEDINGS, P246, DOI 10.1109/CBMS.1998.701364
   Dixon BJ, 2013, SURG ENDOSC, V27, P454, DOI 10.1007/s00464-012-2457-3
   Doignon C, 2007, LECT NOTES COMPUT SC, V4358, P314
   Doignon C, 2006, LECT NOTES COMPUT SC, V4190, P527
   Doignon C, 2008, LECT NOTES ELECTR EN, V8, P79
   Duda K, 2008, ICSES 2008 INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS, CONFERENCE PROCEEDINGS, P197, DOI 10.1109/ICSES.2008.4673391
   Duplaga M, 2008, LECT NOTES COMPUT SC, V5188, P227, DOI 10.1007/978-3-540-85891-1_25
   El Meslouhi O, 2011, OPEN COMPUT SCI, V1, P341, DOI 10.2478/s13537-011-0020-2
   Elter M, 2006, INT C PATT RECOG, P599
   Forestier G, 2012, J BIOMED INFORM, V45, P255, DOI 10.1016/j.jbi.2011.11.002
   Fuchs H, 1998, LECT NOTES COMPUT SC, V1496, P934, DOI 10.1007/BFb0056282
   Fukuda Norio, 2010, Proceedings of the 2nd International Conference on Software Engineering and Data Mining (SEDM 2010), P684
   Gambadauro P, 2012, SURG INNOV, V19, P76, DOI 10.1177/1553350611415424
   Gaviao W, 2012, MED IMAGE ANAL, V16, P160, DOI 10.1016/j.media.2011.06.008
   Geng JS, 2014, IEEE SENS J, V14, P945, DOI 10.1109/JSEN.2013.2294679
   Giannarou S, 2010, LECT NOTES COMPUT SC, V6326, P314
   Giannarou S, 2009, I S BIOMED IMAGING, P1059, DOI 10.1109/ISBI.2009.5193238
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Grasa Oscar G., 2011, IEEE International Conference on Robotics and Automation, P4816
   Grega M, 2010, ADV INTEL SOFT COMPU, V69, P535
   Groch A, 2011, SPIE SPIE C SERIES, V7964
   Groger M., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P53
   Groger M, 2005, BILDVERARBEITUNG MED, P242
   Gschwandtner M., 2010, 10 IEEE INT C INF TE, P1, DOI [10.1109/itab.2010.5687708, DOI 10.1109/ITAB.2010.5687708]
   Guggenberger M., 2014, P 1 ACM INT WORKSH H, P17
   Guthart G. S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P618, DOI 10.1109/ROBOT.2000.844121
   Hafner M, 2014, INT WORK CONTENT MUL
   Hafner M, 2013, COMP MED SY, P185, DOI 10.1109/CBMS.2013.6627786
   Haro BB, 2012, LECT NOTES COMPUT SC, V7510, P34, DOI 10.1007/978-3-642-33415-3_5
   Helferty JP, 2001, IEEE T MED IMAGING, V20, P605, DOI 10.1109/42.932745
   Hernandez-Mier Y, 2010, COMPUT MED IMAG GRAP, V34, P579, DOI 10.1016/j.compmedimag.2010.02.002
   Higgins WE, 2008, COMPUT MED IMAG GRAP, V32, P159, DOI 10.1016/j.compmedimag.2007.11.001
   Holler K, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P713
   Hu MX, 2012, MED IMAGE ANAL, V16, P597, DOI 10.1016/j.media.2010.11.002
   Hughes-Hallett A, 2014, UROLOGY, V83, P266, DOI 10.1016/j.urology.2013.08.049
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Hwang S, 2008, IEEE ENG MED BIO, P3004, DOI 10.1109/IEMBS.2008.4649835
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Ieiri S, 2012, PEDIATR SURG INT, V28, P341, DOI 10.1007/s00383-011-3034-x
   Jun SK, 2012, P IEEE RAS-EMBS INT, P25, DOI 10.1109/BioRob.2012.6290869
   Kallemeyn Nicole A, 2007, Iowa Orthop J, V27, P52
   Kanaya J, 2008, P 9 AS PAC IND ENG M, P2388
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Katic Darko, 2014, Information Processing in Computer-Assisted Interventions. 5th International Conference, IPCAI 2014. Proceedings: LNCS 8498, P158, DOI 10.1007/978-3-319-07521-1_17
   Katic D, 2013, COMPUT MED IMAG GRAP, V37, P174, DOI 10.1016/j.compmedimag.2013.03.003
   Kelley WE, 2008, JSLS-J SOC LAPAROEND, V12, P351
   Khatibi Toktam, 2014, J Med Signals Sens, V4, P53
   Klank U, 2008, INT J COMPUT ASS RAD, V3, P331, DOI 10.1007/s11548-008-0223-8
   Ko SY, 2010, INT J CONTROL AUTOM, V8, P782, DOI 10.1007/s12555-010-0410-6
   Kondo W, 2014, GYNECOL OBSTET, V04
   Koninckx PR, 2008, J MINIM INVAS GYN, V15, P248, DOI 10.1016/j.jmig.2007.12.001
   Koppel D, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P269
   Kranzfelder M, 2013, J SURG RES, V185, P704, DOI 10.1016/j.jss.2013.06.022
   Krupa A, 2003, IEEE T ROBOTIC AUTOM, V19, P842, DOI 10.1109/TRA.2003.817086
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Kumar Suren, 2013, 2013 IEEE International Conference on Automation Science and Engineering (CASE), P480, DOI 10.1109/CoASE.2013.6654037
   Kumar S, 2014, IEEE INT CONF ROBOT, P4887, DOI 10.1109/ICRA.2014.6907575
   Lahane A, 2011, P ACM SIGHIT INT HLH, V47, P114
   Lalys F, 2014, INT J COMPUT ASS RAD, V9, P495, DOI 10.1007/s11548-013-0940-5
   Lalys F, 2011, LECT NOTES COMPUT SC, V6533, P54, DOI 10.1007/978-3-642-18421-5_6
   Laranjo I., 2013, AISC, P317
   Lau WY, 1997, WORLD J SURG, V21, P444, DOI 10.1007/PL00012268
   Lee J, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1041
   Lee SL, 2010, COMPUT MED IMAG GRAP, V34, P33, DOI 10.1016/j.compmedimag.2009.07.007
   Leong JJH, 2006, LECT NOTES COMPUT SC, V4190, P752
   Leszczuk MI, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-110
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Liao H, 2009, MINIM INVASIV THER, V18, P332, DOI 10.3109/13645700903201217
   Liao R, 2013, IEEE T MULTIMEDIA, V15, P983, DOI 10.1109/TMM.2013.2244869
   Liedlgruber M., 2011, 17 INT C DIG SIGN PR, P1, DOI [10.1109/ICDSP.2011.6004900, DOI 10.1109/ICDSP.2011.6004900]
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lin Henry C, 2006, Comput Aided Surg, V11, P220, DOI 10.3109/10929080600989189
   Liu DY, 2007, P ANN INT IEEE EMBS, P3470, DOI 10.1109/IEMBS.2007.4353078
   Liu D, 2007, COMPUT METH PROG BIO, V88, P152, DOI 10.1016/j.cmpb.2007.07.011
   Lo B, 2008, LECT NOTES COMPUT SC, V5242, P104, DOI 10.1007/978-3-540-85990-1_13
   Lokoc Jakub, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P291, DOI 10.1007/978-3-319-14442-9_31
   Loukas C, 2015, INT J MED ROBOT COMP, V11, P80, DOI 10.1002/rcs.1578
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo XB, 2012, MED IMAGE ANAL, V16, P577, DOI 10.1016/j.media.2010.11.001
   LUX M, 2013, P 4 ACM MULT SYST C, P141
   Lux M, 2010, MULTIMED TOOLS APPL, V46, P521, DOI 10.1007/s11042-009-0353-1
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Maghsoudi O, 2014, JOURNAL OF ADVANCED
   Maier-Hein L, 2013, MED IMAGE ANAL, V17, P974, DOI 10.1016/j.media.2013.04.003
   Makary MA, 2013, JAMA-J AM MED ASSOC, V309, P1591, DOI 10.1001/jama.2013.595
   Malti A, 2014, INT J ADV COMPUTER S
   Malti A, 2014, IEEE T BIO-MED ENG, V61, P1684, DOI 10.1109/TBME.2014.2300237
   Marayong P, 2003, IEEE INT CONF ROBOT, P1954, DOI 10.1109/ROBOT.2003.1241880
   Markelj P, 2012, MED IMAGE ANAL, V16, P642, DOI 10.1016/j.media.2010.03.005
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Miranda-Luna R, 2008, IEEE T BIO-MED ENG, V55, P541, DOI 10.1109/TBME.2007.903520
   Mirota D, 2009, LECT NOTES COMPUT SC, V5761, P91, DOI 10.1007/978-3-642-04268-3_12
   Mirota DJ, 2011, ANNU REV BIOMED ENG, V13, P297, DOI 10.1146/annurev-bioeng-071910-124757
   Mirota DJ, 2011, SPIE C SERIES, V7964
   Moll M, 2009, IFMBE PROC, V22, P966
   Mountney P, 2010, MICCAI, V2010, P496
   Mountney P, RECOVERING TISSUE DE
   Mountney P, 2007, LECT NOTES COMPUT SC, V4792, P34
   Mountney P, 2012, MED IMAGE ANAL, V16, P550, DOI 10.1016/j.media.2011.02.010
   Mountney P, 2010, IEEE SIGNAL PROC MAG, V27, P14, DOI 10.1109/MSP.2010.936728
   Mountney P, 2009, IEEE ENG MED BIO, P1184, DOI 10.1109/IEMBS.2009.5333939
   Moustris GP, 2011, INT J MED ROBOT COMP, V7, P375, DOI 10.1002/rcs.408
   Munzer B, 2016, COMP MED SY, P312, DOI 10.1109/CBMS.2016.28
   Munzer B, 2013, COMP MED SY, P534, DOI 10.1109/CBMS.2013.6627865
   Munzer B, 2014, COMP MED SY, P153, DOI 10.1109/CBMS.2014.58
   Munzer B, 2013, IEEE INT SYM MULTIM, P84, DOI 10.1109/ISM.2013.22
   Muller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Munzer B., 2013, 2013 IEEE INT C MULT, P1
   Munzer B, 2011, THESIS
   Muthukudage J., 2014, ABDOMEN THORACIC IMA, P365, DOI [10.1007/978-1-4614-8498-1_14, DOI 10.1007/978-1-4614-8498-1_14]
   Muthukudage J, 2012, LNCS, V7087, P61
   Nageotte F, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2364, DOI 10.1109/IROS.2006.282647
   Neumuth T, 2011, INT J COMPUT ASS RAD, V6, P59, DOI 10.1007/s11548-010-0475-y
   Nicolau S, 2011, SURG ONCOL, V20, P189, DOI 10.1016/j.suronc.2011.07.002
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Oh J, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P724
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Okatani T, 1997, COMPUT VIS IMAGE UND, V66, P119, DOI 10.1006/cviu.1997.0613
   Oropesa I, 2013, SURG ENDOSC, V27, P1029, DOI 10.1007/s00464-012-2513-z
   Oropesa I, 2011, J SURG RES, V171, pE81, DOI 10.1016/j.jss.2011.06.034
   Padoy N., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5285, DOI 10.1109/ICRA.2011.5980250
   Padoy N, 2012, MED IMAGE ANAL, V16, P632, DOI 10.1016/j.media.2010.10.001
   Parchami M, 2014, P 7 INT C PERV TECHN, P25
   Park S., 2001, INT C MEDICAL IMAGE, P1419, DOI DOI 10.1007/3-540-45468-3_
   Parot V, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.7.076017
   Penne J, 2009, LECT NOTES COMPUT SC, V5761, P467, DOI 10.1007/978-3-642-04268-3_58
   Pezzementi Z, 2009, IEEE INT CONF ROBOT, P1225
   Prasath VBS, 2012, IEEE ENG MED BIO, P4014, DOI 10.1109/EMBC.2012.6346847
   Primus MJ, 2015, INT WORK CONTENT MUL
   Primus MJ, 2016, INT WORK CONTENT MUL
   Primus MJ, 2013, INT WORK CONTENT MUL, P223, DOI 10.1109/CBMI.2013.6576587
   Przelaskowski A, 2008, ADV INTEL SOFT COMPU, V47, P208
   Puerto GA, 2012, LECT NOTES COMPUT SC, V7511, P625, DOI 10.1007/978-3-642-33418-4_77
   Puerto-Souza GA, 2014, LECT NOTES COMPUT SC, V8333, P48, DOI 10.1007/978-3-642-53842-1_5
   Puerto-Souza GA, 2013, IEEE T MED IMAGING, V32, P1201, DOI 10.1109/TMI.2013.2239306
   Rangseekajee N, 2011, COMPUT CARDIOL CONF, V38, P549
   Reeff M, 2006, GI JAHRESTAGUNG, V1, P467
   Reiter A, 2014, INT J ROBOT RES, V33, P342, DOI 10.1177/0278364913507796
   Richa R, 2011, MED IMAGE ANAL, V15, P302, DOI 10.1016/j.media.2010.12.002
   Riegler M., 2016, P ACM MM, P968, DOI DOI 10.1145/2964284.2976760
   Rohl S, 2012, MED PHYS, V39, P1632, DOI 10.1118/1.3681017
   Rosen J, 2006, IEEE T BIO-MED ENG, V53, P399, DOI 10.1109/TBME.2005.869771
   Rosen J, 2001, IEEE T BIO-MED ENG, V48, P579, DOI 10.1109/10.918597
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rungseekajee N., 2009, 6 INT C ECTI CON 200, V02, P1076
   Rupp S, 2007, P ANN INT IEEE EMBS, P6566
   Sae Hwang, 2005, 13th Annual ACM International Conference on Multimedia, P912, DOI 10.1145/1101149.1101343
   Saint-Pierre CA, 2011, MACH VISION APPL, V22, P171, DOI 10.1007/s00138-007-0099-6
   Sauvee M, 2007, BIOMED SIGNAL PROCES, V2, P199, DOI 10.1016/j.bspc.2007.07.006
   Scharcanski J, 2006, IEEE IMAGE PROC, P129, DOI 10.1109/ICIP.2006.312376
   Schoeffmann K, 2015, MULTIMED TOOLS APPL, V74, P11187, DOI 10.1007/s11042-014-2224-7
   Selka F, 2015, COMPUT MED IMAG GRAP, V40, P49, DOI 10.1016/j.compmedimag.2014.11.012
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Sheraizin S, 2005, P ANN INT IEEE EMBS, P6551, DOI 10.1109/IEMBS.2005.1616001
   Shih TK, 2005, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P15
   Sielhorst T, 2008, J DISP TECHNOL, V4, P451, DOI 10.1109/JDT.2008.2001575
   Simpfendorfer T, 2011, J ENDOUROL, V25, P1841, DOI 10.1089/end.2010.0724
   Song KT, 2012, IEEE ASME INT C ADV, P39, DOI 10.1109/AIM.2012.6266023
   Soper TD, 2012, IEEE T BIO-MED ENG, V59, P1670, DOI 10.1109/TBME.2012.2191783
   Speidel S, 2009, SPIE C SERIES, V7261
   SPEIDEL S, 2008, SPIE SPIE C SERIES, V6918
   Spyrou E, 2013, 2013 8TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP 2013), P41, DOI 10.1109/SMAP.2013.21
   Srinivasan N, 2013, GASTROINTEST ENDOSC, V77
   Stanek SR, 2012, COMPUT METH PROG BIO, V108, P524, DOI 10.1016/j.cmpb.2011.04.003
   Stanek SR, 2008, SPIE C SERIES, V6919
   Staub C, 2010, P IEEE RAS-EMBS INT, P746, DOI 10.1109/BIOROB.2010.5628075
   Staub C, 2010, IEEE INT CONF ROBOT, P4585, DOI 10.1109/ROBOT.2010.5509601
   Stauder Ralf, 2014, Information Processing in Computer-Assisted Interventions. 5th International Conference, IPCAI 2014. Proceedings: LNCS 8498, P148, DOI 10.1007/978-3-319-07521-1_16
   Stehle T, 2006, ACTA POLYTECH, V46, P32
   Stehle Thomas., 2009, BILDVERARBEITUNG MED, P142, DOI [10.1007/978-3-540-93860-6_29, DOI 10.1007/978-3-540-93860-6_29]
   Stoyanov D, 2005, LECT NOTES COMPUT SC, V3750, P139, DOI 10.1007/11566489_18
   Stoyanov D, 2005, IEEE INT C IM PROC 2, V3
   Stoyanov D, 2010, LECT NOTES COMPUT SC, V6361, P275
   Su LM, 2009, UROLOGY, V73, P896, DOI 10.1016/j.urology.2008.11.040
   Sudra G, 2007, SPIE C SERIES, V6509
   Sugimoto M, 2010, J HEPATO-BIL-PAN SCI, V17, P629, DOI 10.1007/s00534-009-0199-y
   Sung GT, 2001, UROLOGY, V58, P893, DOI 10.1016/S0090-4295(01)01423-6
   Suwelack S, 2012, COMPUTATIONAL BIOMECHANICS FOR MEDICINE: DEFORMATION AND FLOW, P39, DOI 10.1007/978-1-4614-3172-5_6
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Taylor RH, 2003, IEEE T ROBOTIC AUTOM, V19, P765, DOI 10.1109/TRA.2003.817058
   Taylor RH, 2006, P IEEE, V94, P1652, DOI 10.1109/JPROC.2006.880669
   Teber D, 2009, EUR UROL, V56, P332, DOI 10.1016/j.eururo.2009.05.017
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Tokgozoglu H. N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6239241
   Tonet O, 2007, COMPUT AIDED SURG, V12, P35, DOI 10.1080/10929080701210782
   Totz J, 2012, INT J COMPUT ASS RAD, V7, P423, DOI 10.1007/s11548-011-0631-z
   Totz J, 2011, LECT NOTES COMPUT SC, V6891, P89, DOI 10.1007/978-3-642-23623-5_12
   Tsevas S, 2008, IEEE INT C BIOINF BI, P921
   Twinanda AP, 2014, LECT NOTES COMPUT SC, V8675, P409, DOI 10.1007/978-3-319-10443-0_52
   Twinanda AP, 2015, INT J COMPUT ASSIST, P1
   Ukimura O, 2008, J ENDOUROL, V22, P803, DOI 10.1089/end.2007.9823
   Vilarino F, 2006, INT C PATT RECOG, P719
   Visentini-Scarzanella M, 2009, LECT NOTES COMPUT SC, V5761, P353, DOI 10.1007/978-3-642-04268-3_44
   Vitiello Valentina, 2013, IEEE Rev Biomed Eng, V6, P111, DOI 10.1109/RBME.2012.2236311
   Vogt F, 2003, LECT NOTES COMPUT SC, V2879, P356
   Vogt F, 2002, IEEE IMAGE PROC, P637
   Vogt F, 2002, CGIV'2002: FIRST EUROPEAN CONFERENCE ON COLOUR IN GRAPHICS, IMAGING, AND VISION, CONFERENCE PROCEEDINGS, P352
   Voros S, 2007, INT J ROBOT RES, V26, P1173, DOI 10.1177/0278364907083395
   Voros S, 2010, IEEE-ASME T MECH, V15, P879, DOI 10.1109/TMECH.2010.2080683
   Voros S, 2008, P IEEE RAS-EMBS INT, P562, DOI 10.1109/BIOROB.2008.4762915
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Wang XW, 2010, IEEE T MED IMAGING, V29, P1213, DOI 10.1109/TMI.2009.2028341
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2013, IEEE J BIOMED HEALTH, V17, P143, DOI 10.1109/TITB.2012.2226595
   Wang Y, 2010, IEEE T BIO-MED ENG, V57, P685, DOI 10.1109/TBME.2009.2034466
   Weede O, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2012)
   Wei GQ, 1997, IEEE ENG MED BIOL, V16, P40, DOI 10.1109/51.566151
   Wengert C., 2006, BILDVERARBEITUNG F R, P419, DOI DOI 10.1007/3-540-32137-3_85
   Wieringa FP, 2014, J MED IMAGE, P1
   Winter C, 2006, IEEE T BIO-MED ENG, V53, P2035, DOI 10.1109/TBME.2006.877110
   Wolf R, 2011, LECT NOTES COMPUT SC, V6891, P203, DOI 10.1007/978-3-642-23623-5_26
   Wong WK, 2013, IEEE-ASME T MECH, V18, P1472, DOI 10.1109/TMECH.2012.2203919
   Wu CY, 2010, INT J COMPUT VISION, V86, P211, DOI 10.1007/s11263-009-0207-3
   Xia SR, 2005, P ANN INT IEEE EMBS, P1720
   Xia SR, 2003, P SOC PHOTO-OPT INS, V5286, P410, DOI 10.1117/12.538935
   Xiao-Ying T, 2009, INT J INF TECH DECIS, V8, P239, DOI 10.1142/S0219622009003363
   Yamaguchi Tetsuzo, 2004, Comput Aided Surg, V9, P203, DOI 10.1080/10929080500163505
   Yao R, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 4, P1, DOI 10.1109/ICACC.2010.5487088
   Yip MC, 2012, IEEE T MED IMAGING, V31, P2169, DOI 10.1109/TMI.2012.2212718
   Zappella L, 2013, MED IMAGE ANAL, V17, P732, DOI 10.1016/j.media.2013.04.007
   Zhang C, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICIP.2000.899441
   Zhang XL, 2002, J ROBOTIC SYST, V19, P315, DOI 10.1002/rob.10043
   Zheng MM, 2005, COMPUT BIOL MED, V35, P259, DOI 10.1016/j.compbiomed.2004.01.002
NR 279
TC 72
Z9 74
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1323
EP 1362
DI 10.1007/s11042-016-4219-z
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400055
OA hybrid
DA 2023-04-20
ER

PT J
AU Nakashima, H
   Kawahira, H
   Kawachi, H
   Sakaki, N
AF Nakashima, Hirotaka
   Kawahira, Hiroshi
   Kawachi, Hiroshi
   Sakaki, Nobuhiro
TI Artificial intelligence diagnosis of Helicobacter pylori infection using
   blue laser imaging-bright and linked color imaging: a single-center
   prospective study
SO ANNALS OF GASTROENTEROLOGY
LA English
DT Article
DE Endoscopic diagnosis; gastric carcinogenesis; Helicobacter pylori; deep
   convolutional neural network; image-enhanced endoscopy
ID CONVOLUTIONAL NEURAL-NETWORKS; GASTRIC-CANCER; MAGNIFYING ENDOSCOPY;
   STOMACH; ATROPHY; LESIONS; MUCOSA; SYSTEM; IMAGES
AB Background Deep learning is a type of artificial intelligence (AI) that imitates the neural network in the brain. We generated an AI to diagnose Helicobacter pylori (H. pylori) infection using blue laser imaging (BLI)-bright and linked color imaging (LCI). The aim of this pilot study was to establish an AI diagnosing system that predicts H. pylori infection status using endoscopic images to improve the accuracy and productivity of endoscopic examination.
   Methods A total of 222 enrolled subjects (105 H. pylori-positive) underwent esophagogastroduodenoscopy and a serum test for H. pylori IgG antibodies. During esophagogastroduodenoscopy, an endoscopist sequentially took 3 still images of the lesser curvature of the stomach using white light imaging (WLI), BLI-bright, and LCI. EG-L580NW endoscopic equipment (FUJIFILM Co., Japan) was used for the study. The specifications of the AI were as follows: operating system, Linux; neural network, GoogLeNet; framework, Caffe; graphic processor unit, Geforce GTX TITAN X (NVIDIA Co., USA).
   Results The area under the curve (AUC) on receiver operating characteristics analysis was 0.66 for WLI. In contrast, the AUCs of BLI-bright and LCI were 0.96 and 0.95, respectively. The AUCs obtained for BLI-bright and LCI were significantly larger than those for WLI (P<0.01).
   Conclusions The results demonstrate that the developed AI has an excellent ability to diagnose H. pylori infection using BLI-bright and LCI. AI technology with image-enhanced endoscopy is likely to become a useful image diagnostic tool.
C1 [Nakashima, Hirotaka; Sakaki, Nobuhiro] Fdn Detect Early Gastr Carcinoma, Tokyo, Japan.
   [Kawahira, Hiroshi] Chiba Univ, Ctr Frontier Med Engn, Tokyo, Japan.
   [Kawachi, Hiroshi] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Pathol, Tokyo, Japan.
C3 Chiba University; Japanese Foundation for Cancer Research
RP Nakashima, H (通讯作者)，Fdn Detect Early Gastr Carcinoma, Chuo Ku, 2-6-12 Nihombashikayabacho, Tokyo 1030025, Japan.
EM nakashima@soiken.or.jp
OI Nakashima, Hirotaka/0000-0002-2386-1933
CR Anagnostopoulos GK, 2007, ENDOSCOPY, V39, P202, DOI 10.1055/s-2006-945056
   Dohi O, 2016, ENDOSC INT OPEN, V4, pE800, DOI 10.1055/s-0042-109049
   International Agency for Research on Cancer, IARC WORK GROUP REP, V8
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kanda Y, 2013, BONE MARROW TRANSPL, V48, P452, DOI 10.1038/bmt.2012.244
   Kaneko K, 2014, ENDOSC INT OPEN, V2, pE212, DOI 10.1055/s-0034-1390707
   Kato T, 2013, DIGEST ENDOSC, V25, P508, DOI 10.1111/den.12031
   Kimura K, 1969, ENDOSCOPY, V1, P87, DOI [10.1055/s-0028-1098086, DOI 10.1055/S-0028-1098086]
   Kotachi T, 2017, DIGESTION, V95, P314, DOI 10.1159/000477239
   Kuramoto M, 2014, NBI BLI ATLAS NEW IM, P16
   Lee SY, 2014, WORLD J GASTROENTERO, V20, P1493, DOI 10.3748/wjg.v20.i6.1493
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Rugge M, 2012, ALIMENT PHARM THER, V35, P1460, DOI 10.1111/j.1365-2036.2012.05101.x
   SAKAKI N, 1995, EUR J GASTROEN HEPAT, V7, pS59
   Satoh K, 1996, AM J GASTROENTEROL, V91, P963
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sonoyama S., 2017, IEEE J BIOMED HEALTH, V21, P41
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tahara T, 2009, GASTROINTEST ENDOSC, V70, P246, DOI 10.1016/j.gie.2008.11.046
   Togashi K, 2016, THER ADV GASTROENTER, V9, P50, DOI 10.1177/1756283X15603614
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
   Xirouchakis E, 2013, DIGEST DIS SCI, V58, P1084, DOI 10.1007/s10620-012-2431-x
   Yagi K, 2002, J GASTROEN HEPATOL, V17, P39, DOI 10.1046/j.1440-1746.2002.02665.x
   Yagi K, 2002, ENDOSCOPY, V34, P376, DOI 10.1055/s-2002-25281
   Yagi K, 2014, HELICOBACTER, V19, P111, DOI 10.1111/hel.12104
NR 29
TC 77
Z9 80
U1 0
U2 8
PU HELLENIC SOC GASTROENTEROLOGY
PI ATHENS
PA DEMOKRATIAS AVE 67, ATHENS, 15451, GREECE
SN 1108-7471
EI 1792-7463
J9 ANN GASTROENTEROL
JI Ann. Gastroenterol.
PY 2018
VL 31
IS 4
BP 462
EP 468
DI 10.20524/aog.2018.0269
PG 7
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA GM2BK
UT WOS:000437882300009
PM 29991891
OA Green Submitted, gold, Green Published
DA 2023-04-20
ER

PT J
AU Renner, J
   Phlipsen, H
   Haller, B
   Navarro-Avila, F
   Saint-Hill-Febles, Y
   Mateus, D
   Ponchon, T
   Poszler, A
   Abdelhafez, M
   Schmid, RM
   von Delius, S
   Klare, P
AF Renner, Janis
   Phlipsen, Henrik
   Haller, Bernhard
   Navarro-Avila, Fernando
   Saint-Hill-Febles, Yadira
   Mateus, Diana
   Ponchon, Thierry
   Poszler, Alexander
   Abdelhafez, Mohamed
   Schmid, Roland M.
   von Delius, Stefan
   Klare, Peter
TI Optical classification of neoplastic colorectal polyps - a
   computer-assisted approach (the COACH study)
SO SCANDINAVIAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Adenoma; automatic; classification; optical; colonoscopy; colorectal;
   carcinoma; computer
ID DIAGNOSIS; SYSTEM; HISTOLOGY; LESIONS
AB Background and aims: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.Methods: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n=275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.Results: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p=.307 and p=1.000, respectively).Conclusions: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.
C1 [Renner, Janis; Phlipsen, Henrik; Poszler, Alexander; Abdelhafez, Mohamed; Schmid, Roland M.; Klare, Peter] Tech Univ Munich, Klinikum Rechts Isar, Med Klin 2, Munich, Germany.
   [Haller, Bernhard] Tech Univ Munich, Klinikum Rechts Isar, Inst Med Informat Stat & Epidemiol, Munich, Germany.
   [Navarro-Avila, Fernando; Saint-Hill-Febles, Yadira; Mateus, Diana] Tech Univ Munich, CAMP, Garching, Germany.
   [Ponchon, Thierry] Hop Edouard Herriot, Dept Endoscopy & Gastroenterol, Pavillon L, Lyon, France.
   [von Delius, Stefan] RoMed Klinikum Rosenheim, Med Klin 2, Rosenheim, Germany.
C3 Technical University of Munich; University of Hamburg; University
   Medical Center Hamburg-Eppendorf; University of Munich; Technical
   University of Munich; Technical University of Munich; CHU Lyon;
   University of Hamburg; University Medical Center Hamburg-Eppendorf
RP Klare, P (通讯作者)，Klinikum Rechts Der Isar, Klin & Poliklin Innere Med 2, Ismaninger Str 22, D-81675 Munich, Germany.
EM peter.klare@tum.de
RI Haller, Bernhard/I-1943-2019
OI Haller, Bernhard/0000-0002-9723-393X; Mateus, Diana/0000-0002-2252-8717
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   [Anonymous], 2014, P 31 INT C INT C MAC
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Klare P, 2016, ENDOSCOPY, V48, P909, DOI 10.1055/s-0042-110650
   Klare P, 2015, BMC MED EDUC, V15, DOI 10.1186/s12909-015-0312-7
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lieberman D, 2015, CLIN GASTROENTEROL H, V13, P1860, DOI 10.1016/j.cgh.2015.07.011
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Navarro F, 2017, SPIE MED IMAGING
   Pox C, 2013, Z GASTROENTEROL, V51, P753, DOI 10.1055/s-0033-1350264
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Sakata S, 2016, DIGEST ENDOSC, V28, P281, DOI 10.1111/den.12625
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   von Renteln D, 2017, CLIN TRANSL GASTROEN, V8, DOI 10.1038/ctg.2017.6
NR 18
TC 24
Z9 25
U1 0
U2 5
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0036-5521
EI 1502-7708
J9 SCAND J GASTROENTERO
JI Scand. J. Gastroenterol.
PY 2018
VL 53
IS 9
BP 1100
EP 1106
DI 10.1080/00365521.2018.1501092
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HA9OO
UT WOS:000450634000012
PM 30270677
DA 2023-04-20
ER

PT J
AU Sehgal, V
   Rosenfeld, A
   Graham, DG
   Lipman, G
   Bisschops, R
   Ragunath, K
   Rodriguez-Justo, M
   Novelli, M
   Banks, MR
   Haidry, RJ
   Lovat, LB
AF Sehgal, Vinay
   Rosenfeld, Avi
   Graham, David G.
   Lipman, Gideon
   Bisschops, Raf
   Ragunath, Krish
   Rodriguez-Justo, Manuel
   Novelli, Marco
   Banks, Matthew R.
   Haidry, Rehan J.
   Lovat, Laurence B.
TI Machine Learning Creates a Simple Endoscopic Classification System that
   Improves Dysplasia Detection in Barrett's Oesophagus amongst Non-expert
   Endoscopists
SO GASTROENTEROLOGY RESEARCH AND PRACTICE
LA English
DT Article
ID WHITE-LIGHT ENDOSCOPY; ACETIC-ACID; HIGH-DEFINITION; I-SCAN;
   MAGNIFICATION ENDOSCOPY; DIAGNOSIS; MANAGEMENT; CHROMOENDOSCOPY;
   ADENOCARCINOMA; SURVEILLANCE
AB Introduction. Barrett's oesophagus (BE) is a precursor to oesophageal adenocarcinoma (OAC). Endoscopic surveillance is performed to detect dysplasia arising in BE as it is likely to be amenable to curative treatment. At present, there are no guidelines on who should perform surveillance endoscopy in BE. Machine learning (ML) is a branch of artificial intelligence (AI) that generates simple rules, known as decision trees (DTs). We hypothesised that a DT generated from recognised expert endoscopists could be used to improve dysplasia detection in non-expert endoscopists. To our knowledge, ML has never been applied in this manner. Methods. Video recordings were collected from patients with non-dysplastic (ND-BE) and dysplastic Barrett's oesophagus (D-BE) undergoing high-definition endoscopy with i-Scan enhancement (PENTAX (R)). A strict protocol was used to record areas of interest after which a corresponding biopsy was taken to confirm the histological diagnosis. In a blinded manner, videos were shown to 3 experts who were asked to interpret them based on their mucosal and microvasculature patterns and presence of nodularity and ulceration as well as overall suspected diagnosis. Data generated were entered into the WEKA package to construct a DT for dysplasia prediction. Non-expert endoscopists (gastroenterology specialist registrars in training with variable experience and undergraduate medical students with no experience) were asked to score these same videos both before and after web-based training using the DT constructed from the expert opinion. Accuracy, sensitivity, and specificity values were calculated before and after training where p < 0 05 was statistically significant. Results. Videos from 40 patients were collected including 12 both before and after acetic acid (ACA) application. Experts' average accuracy for dysplasia prediction was 88%. When experts' answers were entered into a DT, the resultant decision model had a 92% accuracy with a mean sensitivity and specificity of 97% and 88%, respectively. Addition of ACA did not improve dysplasia detection. Untrained medical students tended to have a high sensitivity but poor specificity as they "overcalled" normal areas. Gastroenterology trainees did the opposite with overall low sensitivity but high specificity. Detection improved significantly and accuracy rose in both groups after formal web-based training although it did it reach the accuracy generated by experts. For trainees, sensitivity rose significantly from 71% to 83% with minimal loss of specificity. Specificity rose sharply in students from 31% to 49% with no loss of sensitivity. Conclusion. ML is able to define rules learnt from expert opinion. These generate a simple algorithm to accurately predict dysplasia. Once taught to non-experts, the algorithm significantly improves their rate of dysplasia detection. This opens the door to standardised training and assessment of competence for those who perform endoscopy in BE. It may shorten the learning curve and might also be used to compare competence of trainees with recognised experts as part of their accreditation process.
C1 [Sehgal, Vinay; Graham, David G.; Lipman, Gideon; Banks, Matthew R.; Haidry, Rehan J.; Lovat, Laurence B.] Univ Coll London Hosp NHS Fdn Trust, Dept Gastroenterol, London, England.
   [Sehgal, Vinay; Graham, David G.; Lovat, Laurence B.] UCL, Div Surg & Intervent Sci, Res Dept Tissue & Energy, London, England.
   [Rosenfeld, Avi] Jerusalem Coll Technol, Dept Ind Engn, Jerusalem, Israel.
   [Bisschops, Raf] Univ Hosp Leuven, Dept Gastroenterol, Leuven, Belgium.
   [Ragunath, Krish] Queens Med Ctr, Dept Gastroenterol, Nottingham, England.
   [Rodriguez-Justo, Manuel; Novelli, Marco] Univ Coll London Hosp NHS Fdn Trust, Dept Histopathol, London, England.
C3 University College London Hospitals NHS Foundation Trust; University of
   London; University College London; University of London; University
   College London; KU Leuven; University Hospital Leuven; University of
   Nottingham; University College London Hospitals NHS Foundation Trust;
   University of London; University College London
RP Sehgal, V (通讯作者)，Univ Coll London Hosp NHS Fdn Trust, Dept Gastroenterol, London, England.; Sehgal, V (通讯作者)，UCL, Div Surg & Intervent Sci, Res Dept Tissue & Energy, London, England.
EM v.sehgal@ucl.ac.uk
RI Lovat, Laurence/C-1986-2009; Banks, Matthew/I-2951-2019;
   Rodriguez-Justo, Manuel/C-6204-2009; Ragunath, Krish/ACQ-0721-2022
OI Lovat, Laurence/0000-0003-4542-3915; Banks, Matthew/0000-0002-9137-2779;
   Rodriguez-Justo, Manuel/0000-0001-5007-1761; Ragunath,
   Krish/0000-0001-6571-5435; Bisschops, Raf/0000-0002-9994-8226
FU Department of Health's NIHR Biomedical Research Centres; CRUK UCL Early
   Cancer Medicine Centre
FX This work was undertaken at UCLH/UCL, which received a proportion of
   funding from the Department of Health's NIHR Biomedical Research Centres
   funding scheme. The work was also supported by the CRUK UCL Early Cancer
   Medicine Centre.
CR Anagnostopoulos GK, 2007, ALIMENT PHARM THER, V26, P501, DOI 10.1111/j.1365-2036.2007.03374.x
   Banks MR, 2011, WORLD J GASTROENTERO, V17, P4308, DOI 10.3748/wjg.v17.i38.4308
   Bellazzi R, 2008, INT J MED INFORM, V77, P81, DOI 10.1016/j.ijmedinf.2006.11.006
   Bennett C, 2012, GASTROENTEROLOGY, V143, P336, DOI 10.1053/j.gastro.2012.04.032
   Bergman J, 2017, GASTROINTEST ENDOSC, V85, pAB48, DOI 10.1016/j.gie.2017.03.040
   Bisschops R, 2002, GUT, V50, P724, DOI 10.1136/gut.50.5.724
   Broadhurst DI, 2006, METABOLOMICS, V2, P171, DOI 10.1007/s11306-006-0037-z
   Cancer Research UK, 2014, CANC STAT
   Chedgy FJQ, 2017, ENDOSCOPY, V49, P121, DOI 10.1055/s-0042-120179
   Espino A, 2014, CLIN ENDOSC, V47, P47, DOI 10.5946/ce.2014.47.1.47
   Fitzgerald RC, 2014, GUT, V63, P7, DOI 10.1136/gutjnl-2013-305372
   Giudici P., 2003, APPL DATA MINING STA
   Herrero LA, 2009, EUR J GASTROEN HEPAT, V21, P1068, DOI 10.1097/MEG.0b013e3283271e87
   Hoffman A, 2010, ENDOSCOPY, V42, P827, DOI 10.1055/s-0030-1255713
   James PD, 2016, BEST PRACT RES CL GA, V30, P421, DOI 10.1016/j.bpg.2016.05.003
   Kara MA, 2006, GASTROINTEST ENDOSC, V64, P155, DOI 10.1016/j.gie.2005.11.049
   KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993
   Kuo WJ, 2001, BREAST CANCER RES TR, V66, P51, DOI 10.1023/A:1010676701382
   Lipman G, 2017, ENDOSCOPY, V49, P1219, DOI 10.1055/s-0043-113441
   Palaniappan S, 2008, INT J COMPUT SCI NET, V8, P343
   Pigo F, 2013, INT J COLORECTAL DIS, V28, P399, DOI 10.1007/s00384-012-1583-7
   Pohl J, 2007, ENDOSCOPY, V39, P594, DOI 10.1055/s-2007-966649
   Richards RA, 2002, LECT NOTES COMPUT SC, V2363, P473
   Rokach L., 2007, SERIES MACHINE PERCE, V69
   Sami SS, 2015, DIS ESOPHAGUS, V28, P742, DOI 10.1111/dote.12283
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Sehgal V., 2014, UNITED EUROPEAN G S1, V2
   Sharma P, 2004, GASTROENTEROLOGY, V127, P310, DOI 10.1053/j.gastro.2004.04.010
   Sharma P, 2006, GASTROINTEST ENDOSC, V64, P167, DOI 10.1016/j.gie.2005.10.044
   Sharma P, 2016, GASTROENTEROLOGY, V150, P591, DOI 10.1053/j.gastro.2015.11.037
   Sharma P, 2012, GASTROINTEST ENDOSC, V76, P252, DOI 10.1016/j.gie.2012.05.007
   Sierra B, 1998, ARTIF INTELL MED, V14, P215, DOI 10.1016/S0933-3657(98)00024-4
   Singh M, 2011, ENDOSCOPY, V43, P745, DOI 10.1055/s-0030-1256631
   Tholoor S, 2014, GASTROINTEST ENDOSC, V80, P417, DOI 10.1016/j.gie.2014.01.041
   Vlahou A., 2003, J BIOMEDICINE BIOTEC, V2003
   Wang KK, 2008, AM J GASTROENTEROL, V103, P788, DOI 10.1111/j.1572-0241.2008.01835.x
   Wegwarth O, 2009, MED EDUC, V43, P721, DOI 10.1111/j.1365-2923.2009.03359.x
   Witten I. H., 2005, MORGAN KAUFMANN SERI
   Yeh DY, 2011, EXPERT SYST APPL, V38, P8970, DOI 10.1016/j.eswa.2011.01.114
NR 39
TC 13
Z9 13
U1 3
U2 7
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-6121
EI 1687-630X
J9 GASTROENT RES PRACT
JI Gastroenterol. Res. Pract.
PY 2018
VL 2018
AR 1872437
DI 10.1155/2018/1872437
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA GT0WX
UT WOS:000444173000001
PM 30245711
OA Green Published, Green Submitted, gold
DA 2023-04-20
ER

PT J
AU Shin, Y
   Qadir, HA
   Aabakken, L
   Bergsland, J
   Balasingham, I
AF Shin, Younghak
   Qadir, Hemin Ali
   Aabakken, Lars
   Bergsland, Jacob
   Balasingham, Ilangko
TI Automatic Colon Polyp Detection Using Region Based Deep CNN and Post
   Learning Approaches
SO IEEE ACCESS
LA English
DT Article
DE Colonoscopy; convolutional neural network; image augmentation; polyp
   detection; region proposal network; transfer learning
ID CONVOLUTIONAL NEURAL-NETWORKS; VALIDATION
AB Automatic image detection of colonic polyps is still an unsolved problem due to the large variation of polyps in terms of shape, texture, size, and color, and the existence of various polyp-like mimics during colonoscopy. In this paper, we apply a recent region-based convolutional neural network (CNN) approach for the automatic detection of polyps in the images and videos obtained from colonoscopy examinations. We use a deep-CNN model (Inception Resnet) as a transfer learning scheme in the detection system. To overcome the polyp detection obstacles and the small number of polyp images, we examine image augmentation strategies for training deep networks. We further propose two efficient post-learning methods, such as automatic false positive learning and offline learning, both of which can be incorporated with the region-based detection system for reliable polyp detection. Using the large size of colonoscopy databases, experimental results demonstrate that the suggested detection systems show better performance than other systems in the literature. Furthermore, we show improved detection performance using the proposed post-learning schemes for colonoscopy videos.
C1 [Shin, Younghak; Balasingham, Ilangko] Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.
   [Shin, Younghak; Qadir, Hemin Ali; Aabakken, Lars; Bergsland, Jacob; Balasingham, Ilangko] Oslo Univ Hosp, Intervent Ctr, N-0027 Oslo, Norway.
   [Qadir, Hemin Ali] Univ Oslo, Dept Informat, N-0315 Oslo, Norway.
   [Aabakken, Lars] Univ Oslo, Dept Transplantat, Fac Med, N-0315 Oslo, Norway.
C3 Norwegian University of Science & Technology (NTNU); University of Oslo;
   University of Oslo; University of Oslo
RP Shin, Y (通讯作者)，Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.; Shin, Y (通讯作者)，Oslo Univ Hosp, Intervent Ctr, N-0027 Oslo, Norway.
EM shinyh0919@gmail.com
RI Balasingham, Ilangko/AGU-7268-2022; Bergsland, Jacob/H-3966-2016
FU European Research Consortium for Informatics and Mathematics Alain
   Bensoussan Fellowship Programme; Research Council of Norway through
   MELODY Project [225885/O70]; Research Council of Norway through
   Industrial Ph.D. Project [271542/O30]
FX This work was supported in part by the European Research Consortium for
   Informatics and Mathematics Alain Bensoussan Fellowship Programme, in
   part by the Research Council of Norway through the MELODY Project under
   Contract 225885/O70, and in part by the Research Council of Norway
   through the Industrial Ph.D. Project under Contract 271542/O30.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Chen, 2017, ARXIV170202138
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Girshick R., 2013, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   He K., 2017, P IEEE INT C COMP VI, P2961, DOI 10.1109/ICCV.2017.322
   He YX, 2023, TRANSPORTMETRICA A, V19, DOI [10.1109/CVPR.2016.90, 10.1080/23249935.2022.2033348]
   Huang J., 2017, CVPR
   Hundertmark S., 2015, 2015 42nd IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2015.7180004
   Jiang H., 2016, FACE DETECTION FASTE
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Park S., 2015, TECH REP
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P1186, DOI 10.1016/S0002-9270(03)00183-7
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Szegedy, 2013, ARXIV13126199, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhao XD, 2016, ACSR ADV COMPUT, V56, P1
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 41
TC 104
Z9 107
U1 1
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2018
VL 6
BP 40950
EP 40962
DI 10.1109/ACCESS.2018.2856402
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA GQ6WJ
UT WOS:000441868800053
OA Green Submitted, gold
DA 2023-04-20
ER

PT J
AU Shin, Y
   Qadir, HA
   Balasingham, I
AF Shin, Younghak
   Qadir, Hemin Ali
   Balasingham, Ilangko
TI Abnormal Colon Polyp Image Synthesis Using Conditional Adversarial
   Networks for Improved Detection Performance
SO IEEE ACCESS
LA English
DT Article
DE Colonoscopy; convolutional neural network; dilated convolution;
   generative adversarial networks; polyp detection
ID VALIDATION
AB One of the major obstacles in automatic polyp detection during colonoscopy is the lack of labeled polyp training images. In this paper, we propose a framework of conditional adversarial networks to increase the number of training samples by generating synthetic polyp images. Using a normal binary form of polyp mask which represents only the polyp position as an input conditioned image, realistic polyp image generation is a difficult task in a generative adversarial networks approach. We propose an edge filtering-based combined input conditioned image to train our proposed networks. This enables realistic polyp image generations while maintaining the original structures of the colonoscopy image frames. More importantly, our proposed framework generates synthetic polyp images from normal colonoscopy images which have the advantage of being relatively easy to obtain. The network architecture is based on the use of multiple dilated convolutions in each encoding part of our generator network to consider large receptive fields and avoid much contractions of a feature map size. An image resizing with convolution for upsampling in the decoding layers is considered to prevent artifacts on generated images. We show that the generated polyp images are not only qualitatively realistic, but also help to improve polyp detection performance.
C1 [Shin, Younghak; Balasingham, Ilangko] Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.
   [Shin, Younghak; Qadir, Hemin Ali; Balasingham, Ilangko] Oslo Univ Hosp, Intervent Ctr, N-0315 Oslo, Norway.
   [Qadir, Hemin Ali] Univ Oslo, Dept Informat, N-0315 Oslo, Norway.
C3 Norwegian University of Science & Technology (NTNU); University of Oslo;
   University of Oslo
RP Shin, Y (通讯作者)，Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.; Shin, Y (通讯作者)，Oslo Univ Hosp, Intervent Ctr, N-0315 Oslo, Norway.
EM shinyh0919@gmail.com
RI Balasingham, Ilangko/AGU-7268-2022
FU Research Council of Norway through the MELODY Project [225885/O70];
   Research Council of Norway [271542/O30]
FX This work was supported in part by the Research Council of Norway
   through the MELODY Project under Contract 225885/O70 and in part by the
   Research Council of Norway through the Industrial Ph.D. Project under
   Contract 271542/O30.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen L. - C., 2017, DEEPLAB SEMANTIC IMA
   Clevert D., 2015, ARXIV151107289
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Gauthier J., 2015, TECH REP
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Huang J., 2017, CVPR
   Isola P., 2017, PROC 30 IEEE C COMPU, P1125, DOI DOI 10.1109/CVPR.2017.632
   Jansson Andreas, 2017, P INT SOC MUS INF RE, DOI DOI 10.5281/ZENODO.1414934
   Jung A., IMAGE AUGMENTATION M
   Kingma Diederik P, 2014, ADAM METHOD STOCHAST
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mahmood F., 2017, UNSUPERVISED REVERSE
   Odena A., 2016, DISTILL, DOI [DOI 10.23915/DISTILL.00003, 10.23915/distill.00003.-URL]
   Park S., 2015, POLYP DETECTION COLO
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Radford A., 2015, COMPUTER SCI
   Reed S, 2016, PR MACH LEARN RES, V48
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sajjadi M. S., 2017, IEEE INT C COMP VIS, DOI DOI 10.1109/CVPR.2019.00817
   Shi Q, 2018, IEEE ACCESS, V6, P25486, DOI 10.1109/ACCESS.2017.2773142
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Yu F, 2016, PROC INT C LEARN REP
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhu JY, 2017, ADV NEUR IN, V30
NR 39
TC 39
Z9 40
U1 2
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2018
VL 6
BP 56007
EP 56017
DI 10.1109/ACCESS.2018.2872717
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA GY1OJ
UT WOS:000448300700001
OA Green Submitted, Green Published, gold
DA 2023-04-20
ER

PT J
AU Vasilakakis, MD
   Iakovidis, DK
   Spyrou, E
   Koulaouzidis, A
AF Vasilakakis, Michael D.
   Iakovidis, Dimitris K.
   Spyrou, Evaggelos
   Koulaouzidis, Anastasios
TI DINOSARC: Color Features Based on Selective Aggregation of Chromatic
   Image Components for Wireless Capsule Endoscopy
SO COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE
LA English
DT Article
AB Wireless Capsule Endoscopy (WCE) is a noninvasive diagnostic technique enabling the inspection of the whole gastrointestinal (GI) tract by capturing and wirelessly transmitting thousands of color images. Proprietary software "stitches" the images into videos for examination by accredited readers. However, the videos produced are of large length and consequently the reading task becomes harder and more prone to human errors. Automating the WCE reading process could contribute in both the reduction of the examination time and the improvement of its diagnostic accuracy. In this paper, we present a novel feature extraction methodology for automated WCE image analysis. It aims at discriminating various kinds of abnormalities from the normal contents of WCE images, in a machine learning-based classification framework. The extraction of the proposed features involves an unsupervised color-based saliency detection scheme which, unlike current approaches, combines both point and region-level saliency information and the estimation of local and global image color descriptors. The salient point detection process involves estimation of DIstaNces On Selective Aggregation of chRomatic image Components (DINOSARC). The descriptors are extracted from superpixels by coevaluating both point and region-level information. The main conclusions of the experiments performed on a publicly available dataset of WCE images are (a) the proposed salient point detection scheme results in significantly less and more relevant salient points; (b) the proposed descriptors are more discriminative than relevant state-of-the-art descriptors, promising a wider adoption of the proposed approach for computer-aided diagnosis in WCE.
C1 [Vasilakakis, Michael D.; Iakovidis, Dimitris K.; Spyrou, Evaggelos] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
   [Spyrou, Evaggelos] Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Athens, Greece.
   [Koulaouzidis, Anastasios] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh, Midlothian, Scotland.
C3 National Centre of Scientific Research "Demokritos"; Royal Infirmary of
   Edinburgh; University of Edinburgh
RP Iakovidis, DK (通讯作者)，Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
EM dimitris.iakovidis@ieee.org
RI Koulaouzidis, Anastasios/G-9060-2014
OI Koulaouzidis, Anastasios/0000-0002-2248-489X; Iakovidis,
   Dimitris/0000-0002-5027-5323
FU project "Klearchos Koulaouzidis," Special Account of Research Grants of
   the University of Thessaly, Greece [5151]
FX This project was supported in part by the project "Klearchos
   Koulaouzidis," Grant no. 5151, Special Account of Research Grants of the
   University of Thessaly, Greece.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Csurka G., 2004, WORKSH STAT LEARN CO, V44, P1, DOI DOI 10.1234/12345678
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Figueiredo IN, 2018, BIOMED SIGNAL PROCES, V39, P486, DOI 10.1016/j.bspc.2017.08.019
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Iakovidis D. K., 2014, P IEEE INT C IM SYST
   Iakovidis DK, 2015, IEEE ENG MED BIO, P731, DOI 10.1109/EMBC.2015.7318466
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Koulaouzidis A, 2015, WORLD J GASTROENTERO, V21, P5119, DOI 10.3748/wjg.v21.i17.5119
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Riphaus A, 2009, Z GASTROENTEROL, V47, P273, DOI 10.1055/s-2008-1027822
   Shi W., 2016, P 8 INT C BIOM ENG I, P73
   Vasilakakis M., 2017, LECT NOTES COMPUTER, P1
   Wyszecki G., 1982, COLOR SCI, V8
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
NR 25
TC 4
Z9 4
U1 0
U2 0
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1748-670X
EI 1748-6718
J9 COMPUT MATH METHOD M
JI Comput. Math. Method Med.
PY 2018
VL 2018
AR 2026962
DI 10.1155/2018/2026962
PG 11
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA GU0JW
UT WOS:000444936800001
PM 30250496
OA gold, Green Published, Green Submitted
DA 2023-04-20
ER

PT J
AU Wang, CL
   Luo, Z
   Liu, XQ
   Bai, JY
   Liao, GB
AF Wang, Chengliang
   Luo, Zhuo
   Liu, Xiaoqi
   Bai, Jianying
   Liao, Guobin
TI Organic Boundary Location Based on Color-Texture of Visual Perception in
   Wireless Capsule Endoscopy Video
SO JOURNAL OF HEALTHCARE ENGINEERING
LA English
DT Article
AB This paper addresses the problem of automatically locating the boundary between the stomach and the small intestine (the pylorus) in wireless capsule endoscopy (WCE) video. For efficient image segmentation, the color-saliency region detection (CSD) method is developed for obtaining the potentially valid region of the frame (VROF). To improve the accuracy of locating the pylorus, we design the Monitor-Judge model. On the one hand, the color-texture fusion feature of visual perception (CTVP) is constructed by grey level cooccurrence matrix (GLCM) feature from the maximum moments of the phase congruency covariance and hue-saturation histogram feature in HSI color space. On the other hand, support vector machine (SVM) classifier with the CTVP feature is utilized to locate the pylorus. The experimental results on 30 real WCE videos demonstrate that the proposed location method outperforms the related valuable techniques.
C1 [Wang, Chengliang; Luo, Zhuo; Liu, Xiaoqi] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Bai, Jianying; Liao, Guobin] Third Mil Med Univ, Affiliated Hosp 2, Dept Gastroenterol, Chongqing, Peoples R China.
C3 Chongqing University; Army Medical University
RP Wang, CL (通讯作者)，Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM wangcl55@gmail.com
OI Luo, Zhuo/0000-0002-5432-3441; Wang, Chengliang/0000-0003-0877-1064
FU National Natural Science Foundation of China [61672115]; Chongqing
   Social Undertakings and Livelihood Security Science and Technology
   Innovation Project Special Program [cstc2015jcyjBX0124,
   cstc2017shmsA30003]
FX The authors are grateful to the clinicians from Xinqiao Hospital, China,
   for their helpful discussion and suggestions. This work is supported by
   the National Natural Science Foundation of China under Grant no.
   61672115 and Chongqing Social Undertakings and Livelihood Security
   Science and Technology Innovation Project Special Program (no.
   cstc2015jcyjBX0124 and no. cstc2017shmsA30003).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Appleyard M, 2000, GASTROENTEROLOGY, V119, P1431, DOI 10.1053/gast.2000.20844
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iobagiu S, 2008, J GASTROINTEST LIVER, V17, P347
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Kovesi P, 2003, PHASE CONGRUENCY DET
   Li B., 2011, 2011 IEEE INT C INF
   Li B., 2011, 2011 IEEE INT C AUT
   Li J., COMP VIS ACCV 2014 W, V2014
   Lin O., 2005, P 4 INT C CAPS END M, pAB87
   Marr D., 1982, VISION COMPUTATIONAL
   Ran Zhou, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P825, DOI 10.1109/ROBIO.2012.6491070
   Sharma G, 1997, IEEE T IMAGE PROCESS, V6, P901, DOI 10.1109/83.597268
   WELCH E, 1991, IEEE PROCEEDINGS OF THE SOUTHEASTCON 91, VOLS 1 AND 2, P722, DOI 10.1109/SECON.1991.147852
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Zhou S., 2017, BIOMEDICAL ENG, V62
NR 19
TC 1
Z9 1
U1 0
U2 3
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2040-2295
EI 2040-2309
J9 J HEALTHC ENG
JI J. Healthc. Eng.
PY 2018
VL 2018
AR 3090341
DI 10.1155/2018/3090341
PG 11
WC Health Care Sciences & Services
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services
GA FT3SY
UT WOS:000423069000001
PM 29599946
OA Green Submitted, gold, Green Published
DA 2023-04-20
ER

PT J
AU Xie, XL
   Xing, J
   Kong, N
   Li, C
   Li, JL
   Zhang, ST
AF Xie, Xiaolei
   Xing, Jie
   Kong, Nan
   Li, Chong
   Li, Jinlin
   Zhang, Shutian
TI Improving Colorectal Polyp Classification Based on Physical Examination
   Data-An Ensemble Learning Approach
SO IEEE ROBOTICS AND AUTOMATION LETTERS
LA English
DT Article
DE Colorectal polyp; ensemble learning; health care management; incidence
   prediction; physical examination; random forests; risk assessment;
   screening colonoscopy
ID LIFE-STYLE FACTORS; RISK; CANCER; IMPACT; COLONOSCOPY
AB Colorectal canceris a common type of cancer. Due to the alarming incidence and mortality rate, it has received increasing attention on early detection and treatment. Colorectal polyps form and grow at initial stages of most colorectal cancer cases. Due to rather stringent medical resource availability and low screening compliance rate, it is more desirable in China than industrialized countries to characterize the relations between colorectalpolyp occurrence and various potential determinants, including basic health information, comorbidities, and lifestyle conditions. Subsequently, one can better predict polyp incidence for each individual. In this letter, we report a data-driven modeling study to improve binary classification of colorectal polyp occurrence. We apply several machine-learning methods, particularly random forests, for physical examination and screening colonoscopy results of a Chinese cohort, to build the classifiers. Our results suggest improved prediction performance with the random forests model. Our study also provides evidence to support the general speculation that emotional status may be an influential risk factor to early colorectal cancer growth in China.
C1 [Xie, Xiaolei] Tsinghua Univ, Dept Ind Engn, Beijing 100084, Peoples R China.
   [Xing, Jie; Zhang, Shutian] Capital Med Univ, Beijing Friendship Hosp, Dept Gastroenterol, Beijing 100050, Peoples R China.
   [Kong, Nan] Purdue Univ, Weldon Sch Biomed Engn, W Lafayette, IN 47907 USA.
   [Li, Chong; Li, Jinlin] Beijing Inst Technol, Sch Management & Econ, Beijing 100081, Peoples R China.
C3 Tsinghua University; Capital Medical University; Purdue University
   System; Purdue University; Purdue University West Lafayette Campus;
   Beijing Institute of Technology
RP Li, JL (通讯作者)，Beijing Inst Technol, Sch Management & Econ, Beijing 100081, Peoples R China.
EM xxie@tsinghua.edu.cn; xingjie0315@126.com; nkong@purdue.edu;
   lichongbit@163.com; jinlinli@bit.edu.cn
FU National Natural Science Foundation of China [71432002, 71672006,
   71501109]; NIH/NCI National [106511]; Center for Data-Centric Management
   in the Department of Industrial Engineering, Tsinghua University; U.S.
   National Cancer Institute [106511]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 71432002, 71672006, and 71501109, in
   part by the NIH/NCI National under Grant 106511, in part by the Center
   for Data-Centric Management in the Department of Industrial Engineering,
   Tsinghua University, and in part by the U.S. National Cancer Institute
   under Grant 106511.
CR Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 1984, CLASSIFICATION REGRE, DOI [10.1002/widm.8, DOI 10.1002/WIDM.8]
   Brenner H, 2011, ANN INTERN MED, V154, P22, DOI 10.7326/0003-4819-154-1-201101040-00004
   Chen W, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00068
   Colditz GA, 2000, CANCER CAUSE CONTROL, V11, P477, DOI 10.1023/A:1008984432272
   Cottet V, 2012, GUT, V61, P1180, DOI 10.1136/gutjnl-2011-300295
   Freedman AN, 2009, J CLIN ONCOL, V27, P686, DOI 10.1200/JCO.2008.17.4797
   Freedman DA, 2009, TECHNOMETRICS
   Fu ZM, 2012, AM J EPIDEMIOL, V176, P766, DOI 10.1093/aje/kws157
   Gromping U, 2009, AM STAT, V63, P308, DOI 10.1198/tast.2009.08199
   Hassan C, 2010, DIS COLON RECTUM, V53, P1328, DOI 10.1007/DCR.0b013e3181e10daa
   Huxley RR, 2009, INT J CANCER, V125, P171, DOI 10.1002/ijc.24343
   Imperiale TF, 2003, ANN INTERN MED, V139, P959, DOI 10.7326/0003-4819-139-12-200312160-00005
   ISBISTER WH, 1986, AUST NZ J SURG, V56, P717, DOI 10.1111/j.1445-2197.1986.tb02379.x
   LOTFI AM, 1986, MAYO CLIN PROC, V61, P337, DOI 10.1016/S0025-6196(12)61950-8
   Martinez ME, 2009, GASTROENTEROLOGY, V136, P832, DOI 10.1053/j.gastro.2008.12.007
   Miles J, 2005, ENCY STAT BEHAV SCI
   Miller F. P., 2010, COLORECTAL POLYP
   MURAKAMI R, 1990, INT J CANCER, V46, P159, DOI 10.1002/ijc.2910460203
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Schoen RE, 2003, AM J GASTROENTEROL, V98, P1237, DOI 10.1016/S0002-9270(03)00271-5
   Shin A, 2008, CANCER EPIDEM BIOMAR, V17, P320, DOI 10.1158/1055-9965.EPI-07-0615
   Shrubsole MJ, 2008, AM J EPIDEMIOL, V167, P1050, DOI 10.1093/aje/kwm400
   Sterne Jonathan A C, 2009, BMJ, V338, pb2393, DOI 10.1136/bmj.b2393
   Usher-Smith JA, 2016, CANCER PREV RES, V9, P13, DOI 10.1158/1940-6207.CAPR-15-0274
   Wei EK, 2009, AM J EPIDEMIOL, V170, P863, DOI 10.1093/aje/kwp210
   Weitz J, 2005, LANCET, V365, P153, DOI 10.1016/S0140-6736(05)17706-X
   Williams TGS, 2016, BMC GASTROENTEROL, V16, DOI 10.1186/s12876-016-0475-7
   Win A. K., 2014, CANCER EPIDEMIOL, V21, P398
   Zhan T., 2016, INT J COLORECTAL DIS, V28, P1
   Zheng S., 2016, J PRACTICAL ONCOL, V31, P2
NR 32
TC 4
Z9 4
U1 3
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2377-3766
J9 IEEE ROBOT AUTOM LET
JI IEEE Robot. Autom. Lett.
PD JAN
PY 2018
VL 3
IS 1
BP 434
EP 441
DI 10.1109/LRA.2017.2746918
PG 8
WC Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Robotics
GA FM1DN
UT WOS:000414713800001
DA 2023-04-20
ER

PT J
AU Rahmatallah, Y
   Khaidakov, M
   Lai, KK
   Goyne, HE
   Lamps, LW
   Hagedorn, CH
   Glazko, G
AF Rahmatallah, Yasir
   Khaidakov, Magomed
   Lai, Keith K.
   Goyne, Hannah E.
   Lamps, Laura W.
   Hagedorn, Curt H.
   Glazko, Galina
TI Platform-independent gene expression signature differentiates sessile
   serrated adenomas/polyps and hyperplastic polyps of the colon
SO BMC MEDICAL GENOMICS
LA English
DT Article
DE Sessile serrated adenoma/polys; Hyperplastic polyps; Molecular
   signature; RNA-seq; Microarrays; Formalin-fixed paraffin-embedded;
   Shrunken centroid classifier; Summary metric; Feature selection;
   Cantelli's inequality
ID EPITHELIAL-MESENCHYMAL TRANSITION; COLORECTAL-CANCER; POOR-PROGNOSIS;
   RNA-SEQ; DOWN-REGULATION; BREAST-CANCER; PEPTIDE YY; MICROARRAY;
   COLONOSCOPY; PREVALENCE
AB Background: Sessile serrated adenomas/polyps are distinguished from hyperplastic colonic polyps subjectively by their endoscopic appearance and histological morphology. However, hyperplastic and sessile serrated polyps can have overlapping morphological features resulting in sessile serrated polyps diagnosed as hyperplastic. While sessile serrated polyps can progress into colon cancer, hyperplastic polyps have virtually no risk for colon cancer. Objective measures, differentiating these types of polyps would improve cancer prevention and treatment outcome.
   Methods: RNA-seq training data set and Affimetrix, Illumina testing data sets were obtained from Gene Expression Omnibus (GEO). RNA-seq single-end reads were filtered with FastX toolkit. Read mapping to the human genome, gene abundance estimation, and differential expression analysis were performed with Tophat-Cufflinks pipeline. Background correction, normalization, and probe summarization steps for Affimetrix arrays were performed using the robust multi-array method (RMA). For Illumina arrays, log(2)-scale expression data was obtained from GEO. Pathway analysis was implemented using Bioconductor package GSAR. To build a platform-independent molecular classifier that accurately differentiates sessile serrated and hyperplastic polyps we developed a new feature selection step. We also developed a simple procedure to classify new samples as either sessile serrated or hyperplastic with a class probability assigned to the decision, estimated using Cantelli's inequality.
   Results: The classifier trained on RNA-seq data and tested on two independent microarray data sets resulted in zero and three errors. The classifier was further tested using quantitative real-time PCR expression levels of 45 blinded independent formalin-fixed paraffin-embedded specimens and was highly accurate. Pathway analyses have shown that sessile serrated polyps are distinguished from hyperplastic polyps and normal controls by: up-regulation of pathways implicated in proliferation, inflammation, cell-cell adhesion and down-regulation of serine threonine kinase signaling pathway; differential co-expression of pathways regulating cell division, protein trafficking and kinase activities.
   Conclusions: Most of the differentially expressed pathways are known as hallmarks of cancer and likely to explain why sessile serrated polyps are more prone to neoplastic transformation than hyperplastic. The new molecular classifier includes 13 genes and may facilitate objective differentiation between two polyps.
C1 [Rahmatallah, Yasir; Glazko, Galina] Univ Arkansas Med Sci, Dept Biomed Informat, Little Rock, AR 72205 USA.
   [Khaidakov, Magomed; Hagedorn, Curt H.] Cent Arkansas Vet Healthcare Syst, Little Rock, AR 72205 USA.
   [Khaidakov, Magomed; Hagedorn, Curt H.] Univ Arkansas Med Sci, Div Gastroenterol & Hepatol, Dept Med, Little Rock, AR 72205 USA.
   [Goyne, Hannah E.; Lamps, Laura W.] Univ Arkansas Med Sci, Dept Pathol, Little Rock, AR 72205 USA.
   [Lai, Keith K.] Cleveland Clin, Dept Anat Pathol, Cleveland, OH 44195 USA.
C3 University of Arkansas System; University of Arkansas Medical Sciences;
   US Department of Veterans Affairs; Veterans Health Administration (VHA);
   Central Arkansas Veterans Healthcare System; University of Arkansas
   System; University of Arkansas Medical Sciences; University of Arkansas
   System; University of Arkansas Medical Sciences; Cleveland Clinic
   Foundation
RP Glazko, G (通讯作者)，Univ Arkansas Med Sci, Dept Biomed Informat, Little Rock, AR 72205 USA.
EM gvglazko@uams.edu
RI Lai, Keith/AAX-3945-2021
OI Lai, Keith/0000-0002-5727-6900; Khaidakov, Magomed/0000-0003-4834-1077;
   Rahmatallah, Yasir/0000-0002-8176-6328
FU Arkansas Biosciences Institute [UL1TR000039]; NIH [CA148068, CA176130];
   NIH IDeA Networks of Biomedical Research Excellence (INBRE) grant
   [P20GM103429]; Center for Translational Pediatric Research (CTPR) NIH
   Center of Biomedical Research Excellence award [P20GM121293]; National
   Science Foundation [CRI CNS-0855248, EPS-0701890, MRI CNS-0619069,
   OISE-0729792]
FX Support has been provided in part by the Arkansas Biosciences Institute
   under grant UL1TR000039, NIH CA148068, NIH CA176130, the NIH IDeA
   Networks of Biomedical Research Excellence (INBRE) grant P20GM103429,
   and by Center for Translational Pediatric Research (CTPR) NIH Center of
   Biomedical Research Excellence award P20GM121293. This work employed the
   High Performance Computing (HPC) resources at the UALR Computational
   Research Center that is supported by the following grants: National
   Science Foundation grants CRI CNS-0855248, EPS-0701890, MRI CNS-0619069,
   and OISE-0729792. None of the funding bodies had a role in the design of
   the study and collection, analysis, and interpretation of data and in
   writing the manuscript.
CR Abdeljawad K, 2015, GASTROINTEST ENDOSC, V81, P517, DOI 10.1016/j.gie.2014.04.064
   Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501
   Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699
   Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556
   Ball HJ, 2009, INT J BIOCHEM CELL B, V41, P467, DOI 10.1016/j.biocel.2008.01.005
   Bao J, 2014, GASTROENT RES PRACT, V2014, DOI DOI 10.1155/2014/913106
   Baron KD, 2015, BBA-MOL CELL RES, V1853, P1683, DOI 10.1016/j.bbamcr.2015.04.003
   Bartley AN, 2010, MODERN PATHOL, V23, P169, DOI 10.1038/modpathol.2009.155
   Beggs AD, 2013, PLOS GENET, V9, DOI 10.1371/journal.pgen.1003488
   Bettington M, 2013, HISTOPATHOLOGY, V62, P367, DOI 10.1111/his.12055
   Byrne JA, 2014, TUMOR BIOL, V35, P7369, DOI 10.1007/s13277-014-2006-x
   Carrega P, 2016, IMMUNOL LETT, V179, P29, DOI 10.1016/j.imlet.2016.06.003
   Caruso M, 2009, VIRCHOWS ARCH, V454, P291, DOI 10.1007/s00428-009-0731-0
   Castaldi PJ, 2011, BRIEF BIOINFORM, V12, P189, DOI 10.1093/bib/bbq073
   Chang CQ, 2015, GENET MED, V17, P431, DOI 10.1038/gim.2014.133
   Chen J, 2015, CANCER RES, V75, P4198, DOI 10.1158/0008-5472.CAN-15-1062
   Chibon F, 2013, EUR J CANCER, V49, P2000, DOI 10.1016/j.ejca.2013.02.021
   Cleven AHG, 2014, CLIN CANCER RES, V20, P3261, DOI 10.1158/1078-0432.CCR-12-3734
   Dave SS, 2004, NEW ENGL J MED, V351, P2159, DOI 10.1056/NEJMoa041869
   De Sousa E Melo F, 2013, NAT MED, V19, P614, DOI 10.1038/nm.3174
   de Veer MJ, 2001, J LEUKOCYTE BIOL, V69, P912
   Delker DA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088367
   El-Salhy M, 2013, INT J MOL MED, V31, P275, DOI 10.3892/ijmm.2012.1222
   Erichsen R, 2016, GASTROENTEROLOGY, V150, P895, DOI 10.1053/j.gastro.2015.11.046
   Fallarino F, 2003, ADV EXP MED BIOL, V527, P183
   Fang YJ, 2009, INT J COLORECTAL DIS, V24, P875, DOI 10.1007/s00384-009-0725-z
   Fumagalli D, 2014, BMC GENOMICS, V15, DOI 10.1186/1471-2164-15-1008
   Galamb O, 2008, CANCER EPIDEM BIOMAR, V17, P2835, DOI 10.1158/1055-9965.EPI-08-0231
   Gibson JA, 2011, AM J SURG PATHOL, V35, P742, DOI 10.1097/PAS.0b013e31821537a2
   Glebov OK, 2003, CANCER EPIDEM BIOMAR, V12, P755
   Gonzalo DH, 2013, J PATHOL, V230, P420, DOI 10.1002/path.4200
   Gray RG, 2011, J CLIN ONCOL, V29, P4611, DOI 10.1200/JCO.2010.32.8732
   Hamada S, 2012, FRONT PHYSIOL, V3, DOI 10.3389/fphys.2012.00254
   Hanahan D, 2011, CELL, V144, P646, DOI 10.1016/j.cell.2011.02.013
   Hendrix A, 2010, JNCI-J NATL CANCER I, V102, P866, DOI 10.1093/jnci/djq153
   Hewish M, 2010, NAT REV CLIN ONCOL, V7, P197, DOI 10.1038/nrclinonc.2010.18
   Higuchi T, 2004, J CLIN PATHOL, V57, P682, DOI 10.1136/jcp.2003.015230
   Iansante V, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8882
   IJspeert Joep Evert Godfried, 2015, Gastrointest Endosc Clin N Am, V25, P169, DOI 10.1016/j.giec.2014.11.004
   Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249
   Ishigooka S, 2012, WORLD J GASTROENTERO, V18, P4308, DOI 10.3748/wjg.v18.i32.4308
   Kahi CJ, 2012, GASTROINTEST ENDOSC, V75, P515, DOI 10.1016/j.gie.2011.08.021
   Kahi CJ, 2011, CLIN GASTROENTEROL H, V9, P42, DOI 10.1016/j.cgh.2010.09.013
   Kanth P, 2016, CANCER PREV RES, V9, P456, DOI 10.1158/1940-6207.CAPR-15-0363
   Kim JU, 2016, J NANOMATER, V2016, DOI 10.1155/2016/7602395
   Lagal V, 2014, J CELL SCI, V127, P328, DOI 10.1242/jcs.130161
   Langmead B, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-3-r25
   Lascorz J, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018867
   Lash RH, 2010, J CLIN PATHOL, V63, P681, DOI 10.1136/jcp.2010.075507
   Levin B, 2008, CA-CANCER J CLIN, V58, P130, DOI 10.3322/CA.2007.0018
   Li HJ, 2011, DIABETES OBES METAB, V13, P5, DOI 10.1111/j.1463-1326.2011.01438.x
   Li J, 2013, MOL BIOL CELL, V24, P3569, DOI 10.1091/mbc.E13-05-0273
   Liberzon A, 2011, BIOINFORMATICS, V27, P1739, DOI 10.1093/bioinformatics/btr260
   Lieberman DA, 2000, NEW ENGL J MED, V343, P162, DOI 10.1056/NEJM200007203430301
   Limketkai BN, 2013, GASTROINTEST ENDOSC, V77, P360, DOI 10.1016/j.gie.2012.11.013
   Manning S, 2014, ANNU REV PHYSIOL, V76, P585, DOI 10.1146/annurev-physiol-021113-170404
   Marioni JC, 2008, GENOME RES, V18, P1509, DOI 10.1101/gr.079558.108
   McVey M, 2008, TRENDS GENET, V24, P529, DOI 10.1016/j.tig.2008.08.007
   Mestdagh P, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-6-r64
   Opitz CA, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019823
   Oshimori N, 2006, NAT CELL BIOL, V8, P1095, DOI 10.1038/ncb1474
   Owens SR, 2008, MODERN PATHOL, V21, P660, DOI 10.1038/modpathol.2008.55
   Pavelitz T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108483
   Payne SR, 2014, CLIN GASTROENTEROL H, V12, P1119, DOI 10.1016/j.cgh.2013.11.034
   Pope JL, 2014, MOL CANCER, V13, DOI 10.1186/1476-4598-13-167
   Prendergast GC, 2014, CANCER IMMUNOL IMMUN, V63, P721, DOI 10.1007/s00262-014-1549-4
   Prendergast GC, 2010, AM J PATHOL, V176, P2082, DOI 10.2353/ajpath.2010.091173
   Quintero E, 2012, NEW ENGL J MED, V366, P697, DOI 10.1056/NEJMx150040
   Rahmatallah Y, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1482-6
   Rahmatallah Y, 2014, BIOINFORMATICS, V30, P360, DOI 10.1093/bioinformatics/btt687
   Rex DK, 2012, AM J GASTROENTEROL, V107, P1315, DOI 10.1038/ajg.2012.161
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Salazar R, 2011, J CLIN ONCOL, V29, P17, DOI 10.1200/JCO.2010.30.1077
   Samarajiwa SA, 2009, NUCLEIC ACIDS RES, V37, pD852, DOI 10.1093/nar/gkn732
   SAVAGE R, 1961, J RES NBS B MATH SCI, V65, P211, DOI 10.6028/jres.065B.020
   Scolnick DM, 2000, NATURE, V406, P430, DOI 10.1038/35019108
   Shan ZZ, 2015, AM J CANCER RES, V5, P344
   Shi W, 2010, PHARMACOGENOMICS J, V10, P310, DOI 10.1038/tpj.2010.35
   Shon WJ, 2015, SCI REP-UK, V5, DOI 10.1038/srep17305
   Simon R, 2005, J CLIN ONCOL, V23, P7332, DOI 10.1200/JCO.2005.02.8712
   Starodub AN, 2015, CLIN CANCER RES, V21, P3870, DOI 10.1158/1078-0432.CCR-14-3321
   Su ZQ, 2014, GENOME BIOL, V15, DOI 10.1186/s13059-014-0523-y
   Tarca AL, 2013, BIOINFORMATICS, V29, P2892, DOI 10.1093/bioinformatics/btt492
   Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299
   Tinmouth J, 2014, AM J GASTROENTEROL, V109, P1698, DOI 10.1038/ajg.2014.78
   Torlakovic E, 1996, GASTROENTEROLOGY, V110, P748, DOI 10.1053/gast.1996.v110.pm8608884
   Torlakovic E, 2003, AM J SURG PATHOL, V27, P65, DOI 10.1097/00000478-200301000-00008
   Torlakovic EE, 2008, AM J SURG PATHOL, V32, P21, DOI 10.1097/PAS.0b013e318157f002
   Trapnell C, 2013, NAT BIOTECHNOL, V31, P46, DOI 10.1038/nbt.2450
   Trapnell C, 2012, NAT PROTOC, V7, P562, DOI 10.1038/nprot.2012.016
   Uyttenhove C, 2003, NAT MED, V9, P1269, DOI 10.1038/nm934
   Walpole R E., 2016, PROBABILITY STAT ENG
   Wang C, 2014, NAT BIOTECHNOL, V32, P926, DOI 10.1038/nbt.3001
   Wang GH, 2014, MOL CANCER THER, V13, P1837, DOI 10.1158/1535-7163.MCT-14-0049
   Wang XW, 2012, NUCLEIC ACIDS RES, V40, pD1144, DOI 10.1093/nar/gkr1013
   Weiss A, 2013, WIRES DEV BIOL, V2, P47, DOI 10.1002/wdev.86
   Wu D, 2010, BIOINFORMATICS, V26, P2176, DOI 10.1093/bioinformatics/btq401
   Xiong SB, 2014, P NATL ACAD SCI USA, V111, P11145, DOI 10.1073/pnas.1404139111
   Yamanami H, 2007, CANCER SCI, V98, P299, DOI 10.1111/j.1349-7006.2007.00403.x
   Yu XC, 2005, NAT GENET, V37, P401, DOI 10.1038/ng1538
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang JX, 2012, J TRANSL MED, V10, DOI 10.1186/1479-5876-10-242
   Zhao P, 2015, MOL MED REP, V12, P4364, DOI 10.3892/mmr.2015.3900
NR 103
TC 11
Z9 11
U1 0
U2 12
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 1755-8794
J9 BMC MED GENOMICS
JI BMC Med. Genomics
PD DEC 28
PY 2017
VL 10
AR 81
DI 10.1186/s12920-017-0317-7
PG 18
WC Genetics & Heredity
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Genetics & Heredity
GA FR6LJ
UT WOS:000419177200001
PM 29284484
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Ahmad, J
   Muhammad, K
   Lee, MY
   Baik, SW
AF Ahmad, Jamil
   Muhammad, Khan
   Lee, Mi Young
   Baik, Sung Wook
TI Endoscopic Image Classification and Retrieval using Clustered
   Convolutional Features
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Image retrieval; Features extraction; Convolution; Classification;
   Spatial pooling; Endoscopy
ID COLOR; TEXTURE
AB With the growing use of minimally invasive surgical procedures, endoscopic video archives are growing at a rapid pace. Efficient access to relevant content in such huge multimedia archives require compact and discriminative visual features for indexing and matching. In this paper, we present an effective method to represent images using salient convolutional features. Convolutional kernels from the first layer of a pre-trained convolutional neural network (CNN) are analyzed and clustered into multiple distinct groups, based on their sensitivity to colors and textures. Dominant features detected by each cluster are collected into a single, layout-preserving feature map using a spatial maximal activator pooling (SMAP) approach. A moving window based structured pooling method then captures spatial layout features and global shape information from the aggregated feature map to populate feature histograms. Finally, individual histograms for each cluster are combined into a single comprehensive feature histogram. Clustering convolutional feature space allow extraction of color and texture features of varying strengths. Further, the SMAP approach enable us to select dominant discriminative features. The proposed features are compact and capable of conveniently outperforming several existing features extraction approaches in retrieval and classification tasks on endoscopy images dataset.
C1 [Ahmad, Jamil; Muhammad, Khan; Lee, Mi Young; Baik, Sung Wook] Sejong Univ, Digital Contents Res Inst, Seoul, South Korea.
C3 Sejong University
RP Baik, SW (通讯作者)，Sejong Univ, Digital Contents Res Inst, Seoul, South Korea.
EM sbaik@sejong.ac.kr
RI Ahmad, Jamil/G-6931-2015; Baik, Sung Wook/AAR-8236-2020; Muhammad,
   Khan/L-9059-2016; Ahmad, Jamil/H-6264-2019
OI Ahmad, Jamil/0000-0001-8407-5971; Muhammad, Khan/0000-0003-4055-7412;
   Ahmad, Jamil/0000-0001-8407-5971; Baik, Sung Wook/0000-0002-6678-7788
FU National Research Foundation of Korea (NRF) - Korea Government (MSIP)
   [2016R1A2B4011712]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea Government (MSIP) (No.
   2016R1A2B4011712).
CR Ahmad J, 2016, J REAL-TIME IMAGE PR, P1
   Ahmad J, 2017, COMPUT ELECTR ENG, V61, P297, DOI 10.1016/j.compeleceng.2017.05.033
   Ahmad J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181707
   Ahmad J, 2017, J VIS COMMUN IMAGE R, V45, P62, DOI 10.1016/j.jvcir.2017.02.010
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Haas S., 2011, MICCAI INT WORKSH ME, P58, DOI DOI 10.1007/978-3-642-28460-1_6
   Krizhevsky A., 2011, P EUR S ART NEUR NET, P489
   Li CR, 2017, PATTERN RECOGN, V64, P118, DOI 10.1016/j.patcog.2016.10.030
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu SY, 2017, COMPUT METH PROG BIO, V141, P1, DOI 10.1016/j.cmpb.2017.01.014
   Messing DS, 2001, IEEE IMAGE PROC, P670, DOI 10.1109/ICIP.2001.959134
   Murala S, 2012, J MED SYST, V36, P2865, DOI 10.1007/s10916-011-9764-4
   Nowakova J, 2017, J MED SYST, V41, DOI 10.1007/s10916-016-0659-2
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pons J, 2017, INT CONF ACOUST SPEE, P2472, DOI 10.1109/ICASSP.2017.7952601
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Vishnuvarthanan A, 2017, APPL SOFT COMPUT, V57, P399, DOI 10.1016/j.asoc.2017.04.023
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Wang SH, 2017, CNS NEUROL DISORD-DR, V16, P11, DOI 10.2174/1871527315666161111123024
   Wang SH, 2016, PEERJ, V4, DOI 10.7717/peerj.2207
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Yang J., 2007, PROC INT WORKSHOP WO, P197, DOI DOI 10.1145/1290082.1290111
   Yu LH, 2016, IEEE ACCESS, V4, P6204, DOI 10.1109/ACCESS.2016.2607841
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang YS, 2018, MULTIDIM SYST SIGN P, V29, P999, DOI 10.1007/s11045-017-0482-z
NR 36
TC 26
Z9 27
U1 1
U2 42
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD DEC
PY 2017
VL 41
IS 12
AR 196
DI 10.1007/s10916-017-0836-y
PG 12
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA FL5YE
UT WOS:000414321600001
PM 29086034
DA 2023-04-20
ER

PT J
AU Cabras, P
   Nageotte, F
   Zanne, P
   Doignon, C
AF Cabras, Paolo
   Nageotte, Florent
   Zanne, Philippe
   Doignon, Christophe
TI An adaptive and fully automatic method for estimating the 3D position of
   bendable instruments using endoscopic images
SO INTERNATIONAL JOURNAL OF MEDICAL ROBOTICS AND COMPUTER ASSISTED SURGERY
LA English
DT Article
DE bendable instruments; flexible endoscopy; in vivo image segmentation;
   pose estimation; surgical robotics
ID SURGERY; SYSTEM
AB Background Flexible bendable instruments are key tools for performing surgical endoscopy. Being able to measure the 3D position of such instruments can be useful for various tasks, such as controlling automatically robotized instruments and analyzing motions.
   Methods An automatic method is proposed to infer the 3D pose of a single bending section instrument, using only the images provided by a monocular camera embedded at the tip of the endoscope. The proposed method relies on colored markers attached onto the bending section. The image of the instrument is segmented using a graph-based method and the corners of the markers are extracted by detecting the color transitions along Bezier curves fitted on edge points. These features are accurately located and then used to estimate the 3D pose of the instrument using an adaptive model that takes into account the mechanical play between the instrument and its housing channel.
   Results The feature extraction method provides good localization of marker corners with images of the in vivo environment despite sensor saturation due to strong lighting. The RMS error on estimation of the tip position of the instrument for laboratory experiments was 2.1, 1.96, and 3.18 mm in the x, y and z directions, respectively. Qualitative analysis in the case of in vivo images shows the ability to correctly estimate the 3D position of the instrument tip during real motions.
   Conclusions The proposed method provides an automatic and accurate estimation of the 3D position of the tip of a bendable instrument in realistic conditions, where standard approaches fail.
C1 [Cabras, Paolo; Nageotte, Florent; Zanne, Philippe; Doignon, Christophe] Univ Strasbourg, CNRS, ICube Lab, 300 Bd Sebastian Brant,CS 10413, F-67412 Illkirch Graffenstaden, France.
C3 Centre National de la Recherche Scientifique (CNRS); UDICE-French
   Research Universities; Universites de Strasbourg Etablissements
   Associes; Universite de Strasbourg
RP Cabras, P (通讯作者)，1 Pl Hop, F-67000 Strasbourg, France.
EM cabras@unistra.fr
OI Cabras, Paolo/0000-0002-6153-5928
FU Agence Nationale de la Recherche [ANR-11-LABX- 0004]
FX Agence Nationale de la Recherche, Grant/Award Number: ANR-11-LABX- 0004
CR Agrawal V, 2010, IEEE T ROBOT, V26, P914, DOI 10.1109/TRO.2010.2064014
   Bardou B, 2010, IEEE INT C INT ROBOT, P2345, DOI 10.1109/IROS.2010.5649221
   BEATON AE, 1974, TECHNOMETRICS, V16, P147, DOI 10.2307/1267936
   Bouguet J.-Y, 2013, CAMERA CALIBRATION T
   Cabras P., 2016, THESIS
   Cabras P, 2014, IEEE INT C INT ROBOT, P3522, DOI 10.1109/IROS.2014.6943054
   Camarillo DB, 2008, IEEE T ROBOT, V24, P1262, DOI 10.1109/TRO.2008.2002311
   De Donno A, 2013, IEEE INT CONF ROBOT, P1213, DOI 10.1109/ICRA.2013.6630726
   Dogangil G, 2010, P I MECH ENG H, V224, P653, DOI 10.1243/09544119JEIM591
   Jagersand M., 2001, P VISION INTERFACE O, P100
   KESNER SB, 2010, ROB AUT ICRA 2010 IE, P1059
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   Marchand T, 2002, COMPUT GRAPH FORUM, V21, P289, DOI 10.1111/1467-8659.t01-1-00588
   Reichl T, 2013, IEEE T MED IMAGING, V32, P1526, DOI 10.1109/TMI.2013.2259636
   Reilink R, 2013, INT J COMPUT ASS RAD, V8, P407, DOI 10.1007/s11548-012-0795-1
   Reiter A., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P2390, DOI 10.1109/IROS.2011.6048634
   Reiter A, 2012, P IEEE RAS-EMBS INT, P829, DOI 10.1109/BioRob.2012.6290702
   Roesthuis RJ, 2013, IEEE INT C INT ROBOT, P2545, DOI 10.1109/IROS.2013.6696715
   Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802
   Webster RJ, 2010, INT J ROBOT RES  JUN
   Wei GQ, 1997, IEEE ENG MED BIOL, V16, P40, DOI 10.1109/51.566151
   XU K, 2009, IEEE RSJ INT C INT R, P5546
   Yeung BPM, 2012, INT J SURG, V10, P345, DOI 10.1016/j.ijsu.2012.05.009
NR 23
TC 15
Z9 15
U1 2
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1478-5951
EI 1478-596X
J9 INT J MED ROBOT COMP
JI Int. J. Med. Robot. Comput. Assist. Surg.
PD DEC
PY 2017
VL 13
IS 4
AR e1812
DI 10.1002/rcs.1812
PG 14
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA FO6ES
UT WOS:000416955800016
PM 28387448
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Pogorelov, K
   Riegler, M
   Eskeland, SL
   de Lange, T
   Johansen, D
   Griwodz, C
   Schmidt, PT
   Halvorsen, P
AF Pogorelov, Konstantin
   Riegler, Michael
   Eskeland, Sigrun Losada
   de lange, Thomas
   Johansen, Dag
   Griwodz, Carsten
   Schmidt, Peter Thelin
   Halvorsen, Pal
TI Efficient disease detection in gastrointestinal videos - global features
   versus neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical; Automatic disease detection; Algorithmic screening; Global and
   local image features; Deep learning neural networks; Information
   retrieval; Performance evaluation
ID TEXTURAL FEATURES; POLYP DETECTION; DEEP
AB Analysis of medical videos from the human gastrointestinal (GI) tract for detection and localization of abnormalities like lesions and diseases requires both high precision and recall. Additionally, it is important to support efficient, real-time processing for live feedback during (i) standard colonoscopies and (ii) scalability for massive population-based screening, which we conjecture can be done using a wireless video capsule endoscope (camera-pill). Existing related work in this field does neither provide the necessary combination of accuracy and performance for detecting multiple classes of abnormalities simultaneously nor for particular disease localization tasks. In this paper, a complete end-to-end multimedia system is presented where the aim is to tackle automatic analysis of GI tract videos. The system includes an entire pipeline ranging from data collection, processing and analysis, to visualization. The system combines deep learning neural networks, information retrieval, and analysis of global and local image features in order to implement multi-class classification, detection and localization. Furthermore, it is built in a modular way, so that it can be easily extended to deal with other types of abnormalities. Simultaneously, the system is developed for efficient processing in order to provide real-time feedback to the doctors and for scalability reasons when potentially applied for massive population-based algorithmic screenings in the future. Initial experiments show that our system has multi-class detection accuracy and polyp localization precision at least as good as state-of-the-art systems, and provides additional novelty in terms of real-time performance, low resource consumption and ability to extend with support for new classes of diseases.
C1 [Pogorelov, Konstantin; Riegler, Michael; Griwodz, Carsten; Halvorsen, Pal] Simula Res Lab, POB 134, N-1325 Lysaker, Norway.
   [Eskeland, Sigrun Losada; de lange, Thomas] Baerum Hosp, Lysaker, Norway.
   [Johansen, Dag] UiT Arctic Univ Norway, Lysaker, Norway.
   [Schmidt, Peter Thelin] Karolinska Inst, Solna, Sweden.
C3 UiT The Arctic University of Tromso; Karolinska Institutet
RP Pogorelov, K (通讯作者)，Simula Res Lab, POB 134, N-1325 Lysaker, Norway.
EM konstantin@simula.no; michael@simula.no; sigesk@vestreviken.no;
   t.d.lange@medisin.uio.no; dag.johansen@uit.no; griff@simula.no;
   peter.thelin-schmidt@karolinska.se; paalh@ifi.uio.no
RI de Lange, Thomas/Q-9063-2016; Riegler, Michael A/E-5443-2015
OI de Lange, Thomas/0000-0003-3989-7487; Riegler, Michael
   A/0000-0002-3153-2064; Halvorsen, Pal/0000-0003-2073-7029
FU FRINATEK project "EONS" [231687]
FX This work is founded by the FRINATEK project "EONS" #231687.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Albisser Z, 2015, P MMSYS, P73
   Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Chaabouni S, 2016, IEEE IMAGE PROC, P1604, DOI 10.1109/ICIP.2016.7532629
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Cheng DC, 2008, LECT NOTES ARTIF INT, V5108, P62, DOI 10.1007/978-3-540-70715-8_6
   Chin C, 2000, J RES SCI TEACH, V37, P109, DOI 10.1002/(SICI)1098-2736(200002)37:2<109::AID-TEA3>3.3.CO;2-Z
   Darknet Redmon J, OPEN SOURCE NEURAL N
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2014, PR MACH LEARN RES, V32
   Fitzgibbon AW, 1996, BUYERS XGUIDE CONIC
   Hall M., 2009, ACM SPECIAL INTEREST, V11, P10
   Holme O, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD009259.pub2
   Hwang S., 2007, P 2007 IEEE INT C IM, DOI [DOI 10.1109/ICIP.2007.4379193, 10.1109/ICIP.2007.4379193]
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kang J, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1469
   Khaleghi A, 2015, IEEE ENG MED BIO, P4081, DOI 10.1109/EMBC.2015.7319291
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Lux M, 2013, SYNT LECT INFORM CON, V5, P1, DOI DOI 10.2200/S00468ED1V01Y201301ICR025
   Mallery S, 2000, MED CLIN N AM, V84, P1059, DOI 10.1016/S0025-7125(05)70276-5
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Ngiam J, 2011, P 28 INT C MACH LEAR, P265
   Nguyen A. M., 2014, P IEEE C COMP VIS PA
   O'Connell JB, 2004, JNCI-J NATL CANCER I, V96, P1420, DOI 10.1093/jnci/djh275
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P170, DOI 10.1145/3083187.3083216
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pogorelov K, 2016, COMP MED SY, P185, DOI 10.1109/CBMS.2016.63
   Redmon J, 2015, PROC CVPR IEEE, P779, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Riegler M., 2016, P ACM MM, P968, DOI DOI 10.1145/2964284.2976760
   Riegler M, 2016, P MMSYS, P29
   Riegler M., 2016, 2016 14 INT WORKSHOP, P1, DOI [10.1109/CBMI.2016.7500257, DOI 10.1109/CBMI.2016.7500257]
   Riegler M, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3079765
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Stewart R, 2015, END TO END PEOPLE DE
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tanimoto TT, 1958, LEMENTARY MATH THEOR
   Tieleman T, 2012, NEURAL NETWORKS MACH, V4
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   von Karsa L, 2012, ENDOSCOPY, V44, pSE1, DOI 10.1055/s-0032-1309822
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Zagoris Konstantinos, 2010, Proceedings of the 14th Panhellenic Conference on Informatics (PCI 2010), P143, DOI 10.1109/PCI.2010.38
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
NR 51
TC 31
Z9 31
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22493
EP 22525
DI 10.1007/s11042-017-4989-y
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200032
OA Green Published, hybrid, Green Accepted
DA 2023-04-20
ER

PT J
AU Shichijo, S
   Nomura, S
   Aoyama, K
   Nishikawa, Y
   Miura, M
   Shinagawa, T
   Takiyama, H
   Tanimoto, T
   Ishihara, S
   Matsuo, K
   Tada, T
AF Shichijo, Satoki
   Nomura, Shuhei
   Aoyama, Kazuharu
   Nishikawa, Yoshitaka
   Miura, Motoi
   Shinagawa, Takahide
   Takiyama, Hirotoshi
   Tanimoto, Tetsuya
   Ishihara, Soichiro
   Matsuo, Keigo
   Tada, Tomohiro
TI Application of Convolutional Neural Networks in the Diagnosis of
   Helicobacter pylori Infection Based on Endoscopic Images
SO EBIOMEDICINE
LA English
DT Article
DE Helicobacter pylori; Endoscopy; Artificial intelligence; Convolutional
   neural networks
ID GASTRIC-CANCER; ERADICATION; RESECTION; ANTIBODY
AB Background and aims: The role of artificial intelligence in the diagnosis of Helicobacter pylori gastritis based on endoscopic images has not been evaluated. We constructed a convolutional neural network (CNN), and evaluated its ability to diagnose H. pylori infection.
   Methods: A 22-layer, deep CNN was pre-trained and fine-tuned on a dataset of 32,208 images either positive or negative for H. pylori (first CNN). Another CNN was trained using images classified according to 8 anatomical locations (secondary CNN). A separate test data set (11,481 images from 397 patients) was evaluated by the CNN, and 23 endoscopists, independently.
   Results: The sensitivity, specificity, accuracy, and diagnostic time were 81.9%, 83.4%, 83.1%, and 198 s, respectively, for the first CNN, and 88.9%, 87.4%, 87.7%, and 194 s, respectively, for the secondary CNN. These values for the 23 endoscopists were 79.0%, 83.2%, 82.4%, and 230 +/- 65 min (85.2%, 89.3%, 88.6%, and 253 +/- 92 min by 6 board-certified endoscopists), respectively. The secondary CNN had a significantly higher accuracy than endoscopists (by 5.3%; 95% CI, 0.3-10.2).
   Conclusion: H. pylori gastritis could be diagnosed based on endoscopic images using CNN with higher accuracy and in a considerably shorter time compared to manual diagnosis by endoscopists. (C) 2017 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license.
C1 [Shichijo, Satoki; Miura, Motoi; Shinagawa, Takahide; Takiyama, Hirotoshi; Ishihara, Soichiro; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
   [Shichijo, Satoki] Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Osaka, Japan.
   [Nomura, Shuhei] Univ Tokyo, Grad Sch Med, Dept Global Hlth Policy, Tokyo, Japan.
   [Nomura, Shuhei] Imperial Coll London, Sch Publ Hlth, Dept Epidemiol & Biostat, London, England.
   [Aoyama, Kazuharu] Idee Inc, Tokyo, Japan.
   [Nishikawa, Yoshitaka] Kyoto Univ, Sch Publ Hlth, Dept Hlth Informat, Kyoto, Japan.
   [Miura, Motoi] Teikyo Univ, Grad Sch Publ Hlth, Tokyo, Japan.
   [Shinagawa, Takahide; Takiyama, Hirotoshi; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Tanimoto, Tetsuya] Med Governance Res Inst, Tokyo, Japan.
   [Tanimoto, Tetsuya] Jyoban Hosp, Tokiwa Fdn, Iwaki, Fukushima, Japan.
   [Ishihara, Soichiro] Int Univ Hlth & Welf, Sanno Hosp, Dept Surg, Tokyo, Japan.
   [Matsuo, Keigo] Tokatsu Tsujinaka Hosp, Abiko, Chiba, Japan.
C3 University of Tokyo; Imperial College London; Kyoto University; Teikyo
   University; University of Tokyo; International University of Health &
   Welfare
RP Shichijo, S (通讯作者)，Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Chuo Ku, 3-1-69 Otemae, Osaka 5418567, Japan.
EM shichijiyou-tky@umin.ac.jp
RI Nomura, Shuhei/HCH-5356-2022; Nishikawa, Yoshitaka/GLV-3579-2022;
   Ishihara, Soichiro/AFK-1375-2022
OI Nomura, Shuhei/0000-0002-2963-7297; Nishikawa,
   Yoshitaka/0000-0003-3313-1990; Shichijo, Satoki/0000-0002-5750-0976;
   Miura, Motoi/0000-0001-8032-7086
CR Almadi MA, 2015, CAN J GASTROENTEROL, V29, P304, DOI 10.1155/2015/789038
   Anagnostopoulos GK, 2007, ENDOSCOPY, V39, P202, DOI 10.1055/s-2006-945056
   [Anonymous], 2016, HELICOBACTER PYLORI, DOI DOI 10.1007/978-4-431-55705-0_10
   Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   CORREA P, 1995, AM J SURG PATHOL, V19, pS37
   Correa P, 2007, GASTROENTEROLOGY, V133, P659, DOI 10.1053/j.gastro.2007.06.026
   Dohi O, 2016, ENDOSC INT OPEN, V4, pE800, DOI 10.1055/s-0042-109049
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ferwana M, 2015, WORLD J GASTROENTERO, V21, P1305, DOI 10.3748/wjg.v21.i4.1305
   Ford Alexander C, 2014, BMJ, V348, pg3174, DOI 10.1136/bmj.g3174
   Fukase K, 2008, LANCET, V372, P392, DOI 10.1016/S0140-6736(08)61159-9
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Kanzaki H, 2012, HELICOBACTER, V17, P224, DOI 10.1111/j.1523-5378.2012.00938.x
   Kato M, 2000, HELICOBACTER, V5, P109, DOI 10.1046/j.1523-5378.2000.00017.x
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Murakami K, 2011, CLIN LAB, V57, P481
   O'Connor A, 2017, NAT REV GASTRO HEPAT, V14, P230, DOI 10.1038/nrgastro.2016.195
   Ogura K, 2008, J CLIN GASTROENTEROL, V42, P279, DOI 10.1097/01.mcg.0000248006.80699.7f
   Sato M, 2012, J GASTROEN HEPATOL, V27, P23, DOI 10.1111/j.1440-1746.2012.07066.x
   Shichijo S, 2015, J GASTROEN HEPATOL, V30, P1260, DOI 10.1111/jgh.12946
   Sugano K, 2015, GUT, V64, P1353, DOI 10.1136/gutjnl-2015-309252
   Take S, 2015, J GASTROENTEROL, V50, P638, DOI 10.1007/s00535-014-1004-5
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
   Yagi K, 2014, HELICOBACTER, V19, P111, DOI 10.1111/hel.12104
   Yoon SB, 2014, HELICOBACTER, V19, P243, DOI 10.1111/hel.12146
NR 25
TC 159
Z9 173
U1 4
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2352-3964
J9 EBIOMEDICINE
JI EBioMedicine
PD NOV
PY 2017
VL 25
BP 106
EP 111
DI 10.1016/j.ebiom.2017.10.014
PG 6
WC Medicine, General & Internal; Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine; Research & Experimental Medicine
GA FP2IK
UT WOS:000417440500021
PM 29056541
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Swager, AF
   van der Sommen, F
   Klomp, SR
   Zinger, S
   Meijer, SL
   Schoon, EJ
   Bergman, JJGHM
   de With, PH
   Curvers, WL
AF Swager, Anne-Fre
   van der Sommen, Fons
   Klomp, Sander R.
   Zinger, Sveta
   Meijer, Sybren L.
   Schoon, Erik J.
   Bergman, Jacques J. G. H. M.
   de With, Peter H.
   Curvers, Wouter L.
TI Computer-aided detection of early Barrett's neoplasia using volumetric
   laser endomicroscopy
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID ESOPHAGUS; MICROSCOPY; DYSPLASIA; EXPERTS
AB Background and Aims: Volumetric laser endomicroscopy (VLE) is an advanced imaging system that provides a near-microscopic resolution scan of the esophageal wall layers up to 3-mm deep. VLE has the potential to improve detection of early neoplasia in Barrett's esophagus (BE). However, interpretation of VLE images is complex because of the large amount of data that need to be interpreted in real time. The aim of this study was to investigate the feasibility of a computer algorithm to identify early BE neoplasia on ex vivo VLE images.
   Methods: We used 60 VLE images from a database of high-quality ex vivo VLE-histology correlations, obtained from BE patients +/- neoplasia (30 nondysplastic BE [NDBE] and 30 high-grade dysplasia/early adenocarcinoma images). VLE features from a recently developed clinical VLE prediction score for BE neoplasia served as input for the algorithm: (1) higher VLE surface than subsurface signal and (2) lack of layering. With this input, novel clinically inspired algorithm features were developed, based on signal intensity statistics and grayscale correlations. For comparison, generic image analysis methods were examined for their performance to detect neoplasia. For classification of the images in the NDBE or neoplastic group, several machine learning methods were evaluated. Leave-1-out cross-validation was used for algorithm validation.
   Results: Three novel clinically inspired algorithm features were developed. The feature "layering and signal decay statistics" showed the optimal performance compared with the other clinically features ("layering" and "signal intensity distribution") and generic image analyses methods, with an area under the receiver operating characteristic curve (AUC) of.95. Corresponding sensitivity and specificity were 90% and 93%, respectively. In addition, the algorithm showed a better performance than the clinical VLE prediction score (AUC.81).
   Conclusions: This is the first study in which a computer algorithm for BE neoplasia was developed based on VLE images with direct histologic correlates. The algorithm showed good performance to detect BE neoplasia in ex vivo VLE images compared with the performance of a recently developed clinical VLE prediction score. This study suggests that an automatic detection algorithm has the potential to assist endoscopists in detecting early neoplasia on VLE. Future studies on in vivo VLE scans are needed to further validate the algorithm.
C1 [Swager, Anne-Fre; Bergman, Jacques J. G. H. M.] Acad Med Ctr, Dept Gastroenterol & Hepatol, Amsterdam, Netherlands.
   [Meijer, Sybren L.] Acad Med Ctr, Dept Pathol, Amsterdam, Netherlands.
   [van der Sommen, Fons; Klomp, Sander R.; Zinger, Sveta; de With, Peter H.] Eindhoven Univ Technol, Dept Elect Engn, Eindhoven, Netherlands.
   [Schoon, Erik J.; Curvers, Wouter L.] Catharina Hosp, Dept Gastroenterol & Hepatol, Eindhoven, Netherlands.
C3 University of Amsterdam; Academic Medical Center Amsterdam; University
   of Amsterdam; Academic Medical Center Amsterdam; Eindhoven University of
   Technology; Catharina Hospital
RP Curvers, WL (通讯作者)，Catharina Hosp, Dept Gastroenterol & Hepatol, NL-5623 EJ Eindhoven, Netherlands.
RI Bergman, Jacques/AAS-2500-2021
OI Bergman, Jacques/0000-0001-7548-6955; Klomp, Sander/0000-0002-0874-4720;
   van der Sommen, Fons/0000-0002-3593-2356; Meijer,
   Sybren/0000-0002-6953-2406
FU Ninepoint Medical; Olympus Endoscopy; Erbe; Fujifilm; NinePoint Medical
   Inc.
FX The following author disclosed financial relationships relevant to this
   publication: J. J. Bergman: Research support recipient from Ninepoint
   Medical, Olympus Endoscopy, Erbe, and Fujifilm; consultant for Olympus
   Endoscopy and Fujifilm. All other authors disclosed no financial
   relationships relevant to this publication. Research support for this
   study was provided by an unrestricted grant from NinePoint Medical Inc.
CR Curvers WL, 2016, GASTROINTEST ENDOSC, V83, P115, DOI 10.1016/j.gie.2015.08.057
   Fitzgerald RC, 2014, GUT, V63, P7, DOI 10.1136/gutjnl-2013-305372
   Klomp S., 2017, P SOC PHOTO-OPT INS, V10134
   Leggett CL, 2016, GASTROINTEST ENDOSC, V83, P880, DOI 10.1016/j.gie.2015.08.050
   Park WG, 2015, AM J GASTROENTEROL, V110, P60, DOI 10.1038/ajg.2014.384
   Pohl H, 2010, CANCER EPIDEM BIOMAR, V19, P1468, DOI 10.1158/1055-9965.EPI-10-0012
   Qi X, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2337314
   Qi X, 2010, BIOMED OPT EXPRESS, V1, P825, DOI 10.1364/BOE.1.000825
   Rodriguez-Diaz E, 2015, GASTROENTEROLOGY, V148, pS91
   Suter MJ, 2008, GASTROINTEST ENDOSC, V68, P745, DOI 10.1016/j.gie.2008.05.014
   Suter MJ, 2014, GASTROINTEST ENDOSC, V79, P886, DOI 10.1016/j.gie.2013.11.016
   Swager A, 2016, DIS ESOPHAGUS, V29, P505, DOI 10.1111/dote.12371
   Swager AF, 2017, GASTROINTEST ENDOSC, V85, P918, DOI 10.1016/j.gie.2016.09.012
   Swager AF, 2016, GASTROINTEST ENDOSC, V83, pAB573, DOI 10.1016/j.gie.2016.03.1180
   Swager AF, 2016, GASTROENTEROLOGY, V150, pS628, DOI 10.1016/S0016-5085(16)32158-8
   Trindade AJ, 2016, GASTROINTES IN PRESS
   Trindade AJ, 2016, ENDOSC INT OPEN, V4, pE318, DOI 10.1055/s-0042-101409
   Vakoc BJ, 2007, GASTROINTEST ENDOSC, V65, P898, DOI 10.1016/j.gie.2006.08.009
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Wolfsen HC, 2015, GASTROINTEST ENDOSC, V3, P1
   Yun SH, 2006, NAT MED, V12, P1429, DOI 10.1038/nm1450
   Yun SH, 2003, OPT EXPRESS, V11, P2953, DOI 10.1364/OE.11.002953
NR 22
TC 53
Z9 55
U1 0
U2 5
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD NOV
PY 2017
VL 86
IS 5
BP 839
EP 846
DI 10.1016/j.gie.2017.03.011
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA FK2IJ
UT WOS:000413305600009
PM 28322771
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Dimas, G
   Spyrou, E
   Iakovidis, DK
   Koulaouzidis, A
AF Dimas, George
   Spyrou, Evaggelos
   Iakovidis, Dimitris K.
   Koulaouzidis, Anastasios
TI Intelligent visual localization of wireless capsule endoscopes enhanced
   by color information
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Wireless capsule endoscopy; Capsule endoscope localization
ID CALIBRATION; VISION
AB Wireless capsule endoscopy (WCE) is performed with a miniature swallowable endoscope enabling the visualization of the whole gastrointestinal (GI) tract. One of the most challenging problems in WCE is the localization of the capsule endoscope (CE) within the GI lumen. Contemporary, radiation-free localization approaches are mainly based on the use of external sensors and transit time estimation techniques, with practically low localization accuracy. Latest advances for the solution of this problem include localization approaches based solely on visual information from the CE camera. In this paper we present a novel visual localization approach based on an intelligent, artificial neural network, architecture which implements a generic visual odometry (VO) framework capable of estimating the motion of the CE in physical units. Unlike the conventional, geometric, VO approaches, the proposed one is adaptive to the geometric model of the CE used; therefore, it does not require any prior knowledge about and its intrinsic parameters. Furthermore, it exploits color as a cue to increase localization accuracy and robustness. Experiments were performed using a robotic-assisted setup providing ground truth information about the actual location of the CE. The lowest average localization error achieved is 2.70 +/- 1.62 cm, which is significantly lower than the error obtained with the geometric approach. This result constitutes a promising step towards the in-vivo application of VO, which will open new horizons for accurate local treatment, including drug infusion and surgical interventions.
C1 [Dimas, George; Spyrou, Evaggelos; Iakovidis, Dimitris K.] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
   [Spyrou, Evaggelos] Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Athens, Greece.
   [Koulaouzidis, Anastasios] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh, Midlothian, Scotland.
C3 National Centre of Scientific Research "Demokritos"; Royal Infirmary of
   Edinburgh; University of Edinburgh
RP Spyrou, E (通讯作者)，Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Patriarchou Grigoriou E & 27 Neapoleos St, Aghia Paraskevi 15341, Greece.
EM espyrou@iit.demokritos.gr
RI Koulaouzidis, Anastasios/G-9060-2014
OI Koulaouzidis, Anastasios/0000-0002-2248-489X
CR Ahmed M. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P463, DOI 10.1109/ICCV.1999.791257
   [Anonymous], 2004, NEURAL NETWORKS, DOI DOI 10.5555/541500
   Bao GQ, 2014, IEEE ENG MED BIO, P5615, DOI 10.1109/EMBC.2014.6944900
   Besdok E, 2009, SENSORS-BASEL, V9, P4572, DOI 10.3390/s90604572
   Fischler M.A., COMMUN ACM, V24
   G.I. Corporation, 2013, PILLCAM CAPS END RAP
   Geng YS, 2016, IEEE T MOBILE COMPUT, V15, P1951, DOI 10.1109/TMC.2015.2483492
   Hartley R., 2004, MULTIPLE VIEW GEOMET
   Hornik K., NEURAL NETW, V3
   Hu C, 2004, IEEE INT CONF ROBOT, P4718
   Iakovidis D.K., 2013, BIOINF BIOENG BIBE 2, P1
   Iakovidis D.K., 2014, IEEE INT C IM SYST T, P95
   Iakovidis DK, 2016, IEEE CONF IMAGING SY, P83, DOI 10.1109/IST.2016.7738202
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   J-Y Bouguet, 2004, CAMERA CALIBRATION T
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153
   Khan UI, 2011, IEEE ENG MED BIO, P5602, DOI 10.1109/IEMBS.2011.6091356
   Konda Kishore, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P486
   Koulaouzidis A, 2015, WORLD J GASTROENTERO, V21, P5119, DOI 10.3748/wjg.v21.i17.5119
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Memon Q, 2001, INT J SYST SCI, V32, P1155, DOI 10.1080/00207720010024276
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Mi L., 2014, SPIE MED IMAGING
   Pourhomayoun M., 2014, IEEE T BIOMED ENG, V61
   Pourhomayoun M, 2012, IEEE ENG MED BIO, P5757, DOI 10.1109/EMBC.2012.6347302
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Slawinski Piotr R., 2015, Journal of Medical Engineering & Technology, V39, P54, DOI 10.3109/03091902.2014.973619
   Sliker LJ, 2014, EXPERT REV MED DEVIC, V11, P649, DOI 10.1586/17434440.2014.941809
   Spyrou E, 2015, COMPUT BIOL MED, V65, P297, DOI 10.1016/j.compbiomed.2015.05.013
   Spyrou E, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/1/015002
   Tomasi C., 1991, CMUCS91132
   Than TD, 2014, IEEE T ROBOT, V30, P1174, DOI 10.1109/TRO.2014.2333111
   Than TD, 2012, IEEE T BIO-MED ENG, V59, P2387, DOI 10.1109/TBME.2012.2201715
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wyszecki G., 1982, COLOR SCI, V8
   Ye YX, 2011, 2011 IEEE 22ND INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P2173, DOI 10.1109/PIMRC.2011.6139900
   Zheng YP, 2012, AM J GASTROENTEROL, V107, P554, DOI 10.1038/ajg.2011.461
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
NR 39
TC 22
Z9 25
U1 1
U2 26
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD OCT 1
PY 2017
VL 89
BP 429
EP 440
DI 10.1016/j.compbiomed.2017.08.029
PG 12
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA FK3HQ
UT WOS:000413376600042
PM 28886480
DA 2023-04-20
ER

PT J
AU Hornbrook, MC
   Goshen, R
   Choman, E
   O'Keeffe-Rosetti, M
   Kinar, Y
   Liles, EG
   Rust, KC
AF Hornbrook, Mark C.
   Goshen, Ran
   Choman, Eran
   O'Keeffe-Rosetti, Maureen
   Kinar, Yaron
   Liles, Elizabeth G.
   Rust, Kristal C.
TI Early Colorectal Cancer Detected by Machine Learning Model Using Gender,
   Age, and Complete Blood Count Data
SO DIGESTIVE DISEASES AND SCIENCES
LA English
DT Article
DE Colorectal neoplasms; Colonoscopy; Medical informatics computing; Blood
   cell count; Hemoglobin; Area under receiver operating characteristics
   curve
ID FECAL IMMUNOCHEMICAL TEST; AMERICAN-COLLEGE; COLONOSCOPY; CARCINOMA;
   DIAGNOSIS; COLON; SURVEILLANCE; POPULATION; STRATEGIES; ADHERENCE
AB Machine learning tools identify patients with blood counts indicating greater likelihood of colorectal cancer and warranting colonoscopy referral.
   To validate a machine learning colorectal cancer detection model on a US community-based insured adult population.
   Eligible colorectal cancer cases (439 females, 461 males) with complete blood counts before diagnosis were identified from Kaiser Permanente Northwest Region's Tumor Registry. Control patients (n = 9108) were randomly selected from KPNW's population who had no cancers, received at ae<yen>1 blood count, had continuous enrollment from 180 days prior to the blood count through 24 months after the count, and were aged 40-89. For each control, one blood count was randomly selected as the pseudo-colorectal cancer diagnosis date for matching to cases, and assigned a "calendar year" based on the count date. For each calendar year, 18 controls were randomly selected to match the general enrollment's 10-year age groups and lengths of continuous enrollment. Prediction performance was evaluated by area under the curve, specificity, and odds ratios.
   Area under the receiver operating characteristics curve for detecting colorectal cancer was 0.80 +/- 0.01. At 99% specificity, the odds ratio for association of a high-risk detection score with colorectal cancer was 34.7 (95% CI 28.9-40.4). The detection model had the highest accuracy in identifying right-sided colorectal cancers.
   ColonFlag(A (R)) identifies individuals with tenfold higher risk of undiagnosed colorectal cancer at curable stages (0/I/II), flags colorectal tumors 180-360 days prior to usual clinical diagnosis, and is more accurate at identifying right-sided (compared to left-sided) colorectal cancers.
C1 [Hornbrook, Mark C.; O'Keeffe-Rosetti, Maureen; Liles, Elizabeth G.; Rust, Kristal C.] Kaiser Permanente, Ctr Hlth Res, 3800 North Interstate Ave, Portland, OR 97227 USA.
   [Goshen, Ran; Choman, Eran; Kinar, Yaron] Medial EarlySign Inc, 11 HaZait St, Kfar Malal, Israel.
   [Kinar, Yaron] Medial Res Inc, 11 HaZait St, Kfar Malal, Israel.
   [Rust, Kristal C.] Kaiser Sunnyside Med Ctr, LL Nursing Adm, 10180 SE Sunnyside Rd, Clackamas, OR 97015 USA.
C3 Kaiser Permanente; Kaiser Permanente
RP Hornbrook, MC (通讯作者)，Kaiser Permanente, Ctr Hlth Res, 3800 North Interstate Ave, Portland, OR 97227 USA.
EM mark.c.hornbrook@gmail.com; ran@earlysign.com; eran@earlysign.com;
   maureen.rosetti@kpchr.org; yaron@medial-research.com;
   Elizabeth.G.Liles@kp.org; kristal.c.rust@kp.org
OI HORNBROOK, MARK/0000-0001-6087-0698
FU Medial Early Sign Inc., Kfar Malal, Israel
FX This research was funded by a contract to the Kaiser Foundation Research
   Institute, Oakland, CA, from Medial Early Sign Inc., Kfar Malal, Israel.
   The contents of this work are solely the responsibility of the authors
   and do not necessarily represent the official views of Kaiser Permanente
   or Medial Early Sign, Inc.
CR Acher P L, 2003, Colorectal Dis, V5, P145, DOI 10.1046/j.1463-1318.2003.00415.x
   American Cancer Society, 2016, CANC FACTS FIG
   Bafandeh Y, 2008, WORLD J GASTROENTERO, V14, P1534, DOI 10.3748/wjg.14.1534
   BARILLARI P, 1989, EUR J SURG ONCOL, V15, P441
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Blak Betina T, 2011, Inform Prim Care, V19, P251
   Castro I, 2015, DIGEST DIS SCI, V60, P1424, DOI 10.1007/s10620-014-3434-6
   CDC, 2010, BEH RISK FACT SURV S
   Committee ACNCCGR, 2005, CLIN PRACT GUID PREV
   Davis M, 2017, EUR J CANCER CARE, V26, DOI 10.1111/ecc.12582
   Dominguez-Ayala M, 2012, REV ESP ENFERM DIG, V104, P343, DOI 10.4321/s1130-01082012000700002
   Doubeni CA, 2016, GUT, DOI [10.1136/gutjnl-2016-312712, DOI 10.1136/GUTJNL-2016-312712(EPUBAHEADOFPRINT).]
   Driver JA, 2007, AM J MED, V120, P257, DOI 10.1016/j.amjmed.2006.05.055
   Goldshtein I, 2010, EUR J CANCER PREV, V19, P342, DOI 10.1097/CEJ.0b013e32833c1be0
   GOODMAN D, 1993, BRIT J SURG, V80, P1327, DOI 10.1002/bjs.1800801037
   Goodwin JS, 2011, ARCH INTERN MED, V171, P1335, DOI 10.1001/archinternmed.2011.212
   Hafstrm L, 2012, PATIENT SAF SURG, V6, DOI 10.1186/1754-9493-6-13
   Hippisley-Cox J, 2012, BRIT J GEN PRACT, V62, DOI 10.3399/bjgp12X616346
   Inadomi JM, 2012, ARCH INTERN MED, V172, P575, DOI 10.1001/archinternmed.2012.332
   Joseph DA, 2016, CANCER-AM CANCER SOC, V122, P2479, DOI 10.1002/cncr.30070
   Kinar Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171759
   Kinar Y, 2016, J AM MED INFORM ASSN, V23, P879, DOI 10.1093/jamia/ocv195
   Klabunde Carrie N., 2012, Morbidity and Mortality Weekly Report, V61, P41
   Kruse GR, 2015, J GEN INTERN MED, V30, P277, DOI 10.1007/s11606-014-3015-6
   Levin B, 2008, GASTROENTEROLOGY, V134, P1570, DOI 10.1053/j.gastro.2008.02.002
   Liles EG, 2015, IMPLEMENT SCI, V10, DOI 10.1186/s13012-015-0227-z
   Lin JS, 2016, JAMA-J AM MED ASSOC, V315, P2576, DOI 10.1001/jama.2016.3332
   Power E, 2009, FUTURE ONCOL, V5, P1371, DOI 10.2217/fon.09.134
   Qaseem A, 2012, ANN INTERN MED, V156, P378, DOI 10.7326/0003-4819-156-5-201203060-00010
   Rai S, 2005, COLORECTAL DIS, V7, P588, DOI 10.1111/j.1463-1318.2005.00880.x
   Segnan N, 2010, EUROPEAN GUIDELINES
   Shahidi NC, 2013, AM J CLIN ONCOL-CANC, V36, P381, DOI 10.1097/COC.0b013e318248da66
   Shapiro JA, 2012, CANCER EPIDEM BIOMAR, V21, P895, DOI 10.1158/1055-9965.EPI-12-0192
   Spell DW, 2004, CANCER DETECT PREV, V28, P37, DOI 10.1016/j.cdp.2003.10.002
   van der Vlugt M, 2017, BRIT J CANCER, V116, P44, DOI 10.1038/bjc.2016.399
NR 36
TC 51
Z9 55
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0163-2116
EI 1573-2568
J9 DIGEST DIS SCI
JI Dig. Dis. Sci.
PD OCT
PY 2017
VL 62
IS 10
BP 2719
EP 2727
DI 10.1007/s10620-017-4722-8
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA FI3PH
UT WOS:000411876900016
PM 28836087
OA hybrid
DA 2023-04-20
ER

PT J
AU Soares, F
   Becker, K
   Anzanello, MJ
AF Soares, Felipe
   Becker, Karin
   Anzanello, Michel J.
TI A hierarchical classifier based on human blood plasma fluorescence for
   non-invasive colorectal cancer screening
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Colorectal cancer; Hierarchical classification; Fluorescence
   spectroscopy; Support vector machine; Human blood plasma; SVM-RFE
ID FEATURE-SELECTION; SUPPORT; SPECTROSCOPY; DIAGNOSIS; CHEMOMETRICS;
   COLONOSCOPY; POPULATION; SPECTRA; TIMP-1; TESTS
AB Colorectal cancer (CRC) a leading cause of death by cancer, and screening programs for its early identification are at the heart of the increasing survival rates. To motivate population participation, non-invasive, accurate, scalable and cost-effective diagnosis methods are required. Blood fluorescence spectroscopy provides rich information that can be used for cancer identification. The main challenges in analyzing blood fluorescence data for CRC classification are related to its high dimensionality and inherent variability, especially when analyzing a small number of samples. In this paper, we present a hierarchical classification method based on plasma fluorescence to identify not only CRC, but also adenomas and other non-malignant colorectal findings that may require further medical investigation. A feature selection algorithm is proposed to deal with the high dimensionality and select discriminant fluorescence wavelengths. These are used to train a binary support vector machine (SVM) in the first level to identify the CRC samples. The remaining samples are then presented to a one-class SVM trained on healthy subjects to detect deviant samples, and thus non-malignant findings. This hierarchical design, together with the one class-SVM, aims to reduce the effects of small samples and high variability. Using a.dataset analyzed in previous studies comprised of 12,341 wavelengths, we achieved much superior results. Sensitivity and specificity are 0.87 and 0.95 for CRC detection, and 0.60 and 0.79 for non-malignant findings, respectively. Compared to related work, the proposed method presented a better accuracy, required fewer features, and provides a unified approach that expands CRC detection to non-malignant findings. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Soares, Felipe; Becker, Karin] Univ Fed Rio Grande do Sul, Inst Informat, Ave Ben Goncalves,9500, Porto Alegre, RS, Brazil.
   [Anzanello, Michel J.] Univ Fed Rio Grande do Sul, Dept Ind Engn, Ave Osvaldo Aranha,99-5 Andar, Porto Alegre, RS, Brazil.
C3 Universidade Federal do Rio Grande do Sul; Universidade Federal do Rio
   Grande do Sul
RP Soares, F (通讯作者)，Univ Fed Rio Grande do Sul, Inst Informat, Ave Ben Goncalves,9500, Porto Alegre, RS, Brazil.
EM felipe.soares@inf.ufrgs.br; karin.becker@inf.ufrgs.br;
   anzanello@producao.ufrgs.br
RI Becker, Karin/E-8963-2013; Soares, Felipe/HOI-0057-2023; Anzanello,
   Michel J/L-8361-2017; Soares, Felipe/HCI-4579-2022
OI Becker, Karin/0000-0003-4967-1027; Soares, Felipe/0000-0002-2837-1853;
   Anzanello, Michel/0000-0002-4421-7004
CR Adler A, 2014, BMC GASTROENTEROL, V14, DOI 10.1186/1471-230X-14-183
   Al-Salhi M, 2011, J FLUORESC, V21, P637, DOI 10.1007/s10895-010-0751-9
   Amer M., 2013, P ACM SIGKDD WORKSHO, P8
   Bro R, 2013, METABOLOMICS, V9, P3, DOI 10.1007/s11306-012-0446-0
   Cios KJ, 2002, ARTIF INTELL MED, V26, P1, DOI 10.1016/S0933-3657(02)00049-0
   de Carvalho AO, 2014, ARTIF INTELL MED, V60, P165, DOI 10.1016/j.artmed.2013.11.002
   Dickinson BT, 2015, GUT, V64, P1485, DOI 10.1136/gutjnl-2014-308075
   Dimitrakopoulos C, 2016, ARTIF INTELL MED, V71, P62, DOI 10.1016/j.artmed.2016.05.006
   Ebenezar J, 2010, PHOTOCHEM PHOTOBIOL, V86, P77, DOI 10.1111/j.1751-1097.2009.00628.x
   Garcia-Torres M, 2016, INFORM SCIENCES, V326, P102, DOI 10.1016/j.ins.2015.07.041
   Gheyas IA, 2010, PATTERN RECOGN, V43, P5, DOI 10.1016/j.patcog.2009.06.009
   Guyon, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hegenbart S, 2015, COMPUT BIOL MED, V65, P348, DOI 10.1016/j.compbiomed.2015.02.007
   Itzkowitz SH, 2007, CLIN GASTROENTEROL H, V5, P111, DOI 10.1016/j.cgh.2006.10.006
   Lakowicz J-R., 2013, PRINCIPLES FLUORESCE, P1
   Lawaetz AJ, 2012, METABOLOMICS, V8, pS111, DOI 10.1007/s11306-011-0310-7
   Lillhonga T, 2005, ANAL CHIM ACTA, V544, P177, DOI 10.1016/j.aca.2005.01.057
   Lin HY, 2013, KNOWL-BASED SYST, V37, P94, DOI 10.1016/j.knosys.2012.07.018
   Lin WM, 2004, J BIOMED OPT, V9, P180, DOI 10.1117/1.1628244
   Lualdi M, 2007, TUMORI, V93, P567
   MACGREGOR JF, 1995, CONTROL ENG PRACT, V3, P403, DOI 10.1016/0967-0661(95)00014-L
   Majumder SK, 2005, J BIOMED OPT, V10, DOI 10.1117/1.1897396
   Masilamani V, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.9.098001
   Nielsen HJ, 2011, SCAND J GASTROENTERO, V46, P1283, DOI 10.3109/00365521.2011.610002
   Nielsen HJ, 2011, SCAND J GASTROENTERO, V46, P60, DOI 10.3109/00365521.2010.513060
   Nielsen HJ, 2008, SCAND J GASTROENTERO, V43, P242, DOI 10.1080/00365520701523439
   NORGAARD L, 1995, TALANTA, V42, P1305, DOI 10.1016/0039-9140(95)01586-Z
   Norgaard L, 2007, J CHEMOMETR, V21, P451, DOI 10.1002/cem.1042
   Palmer GM, 2003, IEEE T BIO-MED ENG, V50, P1233, DOI 10.1109/TBME.2003.818488
   Quintero E, 2012, NEW ENGL J MED, V366, P697, DOI 10.1056/NEJMx150040
   Ramanujam N, 2000, NEOPLASIA, V2, P89, DOI 10.1038/sj.neo.7900077
   Rathore S, 2015, COMPUT BIOL MED, V65, P279, DOI 10.1016/j.compbiomed.2015.03.004
   Sadanandam A, 2013, NAT MED, V19, P619, DOI 10.1038/nm.3175
   Sadecka J, 2007, CZECH J FOOD SCI, V25, P159, DOI 10.17221/687-CJFS
   Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P1
   Schreuders E. H., 2015, GUT, P1
   Senore C, 2014, NEW ENGL J MED, V371, P185, DOI [10.1056/NEJMc1405215, 10.1056/NEJMoa1311194]
   Sonoda H, 2011, GUT, V60, P814, DOI 10.1136/gut.2010.218305
   Thiele H, 2012, NEW ENGL J MED, V367, P1287, DOI 10.1056/NEJMoa1208410
   Thissen U, 2004, CHEMOMETR INTELL LAB, V73, P169, DOI 10.1016/j.chemolab.2004.01.002
   Torre LA, 2015, CA-CANCER J CLIN, V65, P87, DOI 10.3322/caac.21262
   Tzikopoulos SD, 2011, COMPUT METH PROG BIO, V102, P47, DOI 10.1016/j.cmpb.2010.11.016
   Utzinger U, 1999, IEEE T BIO-MED ENG, V46, P1293, DOI 10.1109/10.797989
   Van Ballegooijen M, 2009, PREVENTIVE SERVICES, V149, P659
   Widjaja E, 2008, INT J ONCOL, V32, P653
NR 46
TC 12
Z9 12
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD OCT
PY 2017
VL 82
BP 1
EP 10
DI 10.1016/j.artmed.2017.09.004
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA FN1WH
UT WOS:000415781400001
PM 28939302
DA 2023-04-20
ER

PT J
AU Suman, S
   Hussin, FA
   Malik, AS
   Ho, SH
   Hilmi, I
   Leow, AHR
   Goh, KL
AF Suman, Shipra
   Hussin, Fawnizu Azmadi
   Malik, Aamir Saeed
   Ho, Shiaw Hooi
   Hilmi, Ida
   Leow, Alex Hwong-Ruey
   Goh, Khean-Lee
TI Feature Selection and Classification of Ulcerated Lesions Using
   Statistical Analysis for WCE Images
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE wireless capsule endoscopy; feature selection; color space selection;
   statistical analysis; support vector machine; grid search; overlapping
   area; classification
ID CAPSULE ENDOSCOPY
AB Wireless capsule endoscopy (WCE) is a technology developed to inspect the whole gastrointestinal tract (especially the small bowel area that is unreachable using the traditional endoscopy procedure) for various abnormalities in a non-invasive manner. However, visualization of a massive number of images is a very time-consuming and tedious task for physicians (prone to human error). Thus, an automatic scheme for lesion detection in WCE videos is a potential solution to alleviate this problem. In this work, a novel statistical approach was chosen for differentiating ulcer and non-ulcer pixels using various color spaces (or more specifically using relevant color bands). The chosen feature vector was used to compute the performance metrics using SVM with grid search method for maximum efficiency. The experimental results and analysis showed that the proposed algorithm was robust in detecting ulcers. The performance in terms of accuracy, sensitivity, and specificity are 97.89%, 96.22%, and 95.09%, respectively, which is promising.
C1 [Suman, Shipra; Hussin, Fawnizu Azmadi; Malik, Aamir Saeed] Univ Teknol PETRONAS, Ctr Intelligent Signal & Imaging Res, Seri Iskandar 32610, Malaysia.
   [Ho, Shiaw Hooi; Hilmi, Ida; Leow, Alex Hwong-Ruey; Goh, Khean-Lee] Univ Malaya, Med Ctr, Dept Med, Kuala Lumpur 50603, Malaysia.
C3 Universiti Teknologi Petronas; Universiti Malaya
RP Suman, S (通讯作者)，Univ Teknol PETRONAS, Ctr Intelligent Signal & Imaging Res, Seri Iskandar 32610, Malaysia.
EM suman.shipra@ieee.org; fawnizu@utp.edu.my; aamir_saeed@utp.edu.my;
   shooiho@yahoo.com; i_hilmi@um.edu.my; alexleow@gmail.com;
   klgoh56@gmail.com
RI suman, shipra/AAE-8903-2020; suman, shipra/GQP-7224-2022; Malik, Aamir
   S/C-6904-2009; Goh, Khean-Lee/B-6404-2009; Hussin, Fawnizu
   Azmadi/G-9067-2011; Ho, Shiaw-Hooi/B-1606-2017; Hilmi, Ida/AAN-7129-2020
OI suman, shipra/0000-0002-1689-1704; Malik, Aamir S/0000-0003-1085-3157;
   Goh, Khean-Lee/0000-0002-9965-1561; Hussin, Fawnizu
   Azmadi/0000-0002-1419-9300; Ho, Shiaw-Hooi/0000-0003-4992-7627; 
FU Centre for Intelligent Signal and Imaging Research (CISIR); Graduate
   Assistantship (GA) scheme, Universiti Teknologi PETRONAS, Perak,
   Malaysia
FX This research work is supported by the Centre for Intelligent Signal and
   Imaging Research (CISIR) and the Graduate Assistantship (GA) scheme,
   Universiti Teknologi PETRONAS, Perak, Malaysia.
CR Ahmed A., 2012, P WSEAS INT C REC AD
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   Colantoni P., COLOR SPACE TRANSFOR
   Colombel JF, 2017, GASTROENTEROLOGY, V152, P309, DOI 10.1053/j.gastro.2016.12.004
   Deeba F., 2016, CMBES P, V39, P1
   Deeba F, 2016, IEEE ENG MED BIO, P3871, DOI 10.1109/EMBC.2016.7591573
   Figueiredo IN, 2013, COMP M BIO BIO E-IV, V1, P198, DOI 10.1080/21681163.2013.796164
   Figueiredo P.N., 2011, DIAGN THER ENDOSC, V2011
   Ghoshal U.C., 2013, ENDOSCOPY GI TRACT
   Hsu C. W., 2003, PRACTICAL GUIDE SUPP
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Ibraheem N. A., 2012, ARPN J SCI TECHNOLOG, V2, P265
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Kaplan GG, 2017, GASTROENTEROLOGY, V152, P313, DOI 10.1053/j.gastro.2016.10.020
   Kaplan GG, 2016, GASTROENTEROLOGY, V150, P24, DOI 10.1053/j.gastro.2015.11.029
   Koshy NE, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1725, DOI 10.1109/ECS.2015.7124881
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Mohapatra Saurav, 2016, 2016 Power Systems Computation Conference (PSCC), P1, DOI 10.1109/PSCC.2016.7540904
   Pascale D., 2003, BABEL COLOR, V18, P136
   Saevarsson BB, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, P318
   Suman S., 2016, INT C SIGN INF PROC, P1
   Suman S, 2016, ADV SCI LETT, V22, P2764, DOI 10.1166/asl.2016.7099
   Suman S, 2015, LECT NOTES COMPUT SC, V9489, P373, DOI 10.1007/978-3-319-26532-2_41
   Suman S, 2014, LECT NOTES COMPUT SC, V8836, P276, DOI 10.1007/978-3-319-12643-2_34
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Wiggins RH, 2001, RADIOGRAPHICS, V21, P789, DOI 10.1148/radiographics.21.3.g01ma25789
   Xiaoying Liu, 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P737, DOI 10.1109/BHI.2012.6211688
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
NR 31
TC 21
Z9 21
U1 2
U2 9
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD OCT
PY 2017
VL 7
IS 10
AR 1097
DI 10.3390/app7101097
PG 12
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA FL7VB
UT WOS:000414457800135
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Ali, H
   Sharif, M
   Yasmin, M
   Rehmani, MH
AF Ali, Hussam
   Sharif, Muhammad
   Yasmin, Mussarat
   Rehmani, Mubashir Husain
TI Computer-based classification of chromoendoscopy images using
   homogeneous texture descriptors
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Classification; Endoscopy; Feature extraction; Gastrointestinal; Gastric
   cancer; Local binary patterns; Homogeneous texture; Chromoendoscopy;
   Genetic algorithm
ID CAPSULE ENDOSCOPY; GASTRIC-CANCER; DIAGNOSIS; FEATURES; LESIONS
AB Computer-aided analysis of clinical pathologies is a challenging task in the field of medical imaging. Specifically, the detection of abnormal regions in the frames collected during an endoscopic session is difficult. The variations in the conditions of image acquisition, such as field of view or illumination modification, make it more demanding. Therefore, the design of a computer-assisted diagnostic system for the recognition of gastric abnormalities requires features that are robust to scale, rotation, and illumination variations of the images. Therefore, this study focuses on designing a set of texture descriptors based on the Gabor wavelets that will cope with certain image dynamics. The proposed features are extracted from the images and utilized for the classification of the chromoendoscopy (CH) frames into normal and abnormal categories. Moreover, to attain a higher accuracy, an optimized subset of descriptors is selected through the genetic algorithm. The results obtained using the proposed features are compared with other existing texture descriptors (e.g., local binary pattern and homogeneous texture descriptors). Furthermore, the selected features are used to train the support vector machine (SVM), naive Bayes (NB) algorithm, k-nearest neighbor algorithm, linear discriminant analysis, and ensemble tree classifier. The performance of these state-of-the-art classifiers for different texture descriptors is compared based on the accuracy, sensitivity, specificity, and area under the curve (AUC) derived by using the CH images. The classification results reveal that the SVM classifier achieves 90.0% average accuracy and 0.93 AUC when it is employed with an optimized set of features obtained by using a genetic algorithm.
C1 [Ali, Hussam; Sharif, Muhammad; Yasmin, Mussarat] COMSATS Inst Informat Technol, Dept Comp Sci, Wah Cantt, Pakistan.
   [Rehmani, Mubashir Husain] COMSATS Inst Informat Technol, Dept Elect Engn, Wah Cantt, Pakistan.
C3 COMSATS University Islamabad (CUI); COMSATS University Islamabad (CUI)
RP Ali, H (通讯作者)，COMSATS Inst Informat Technol, Dept Comp Sci, Wah Cantt, Pakistan.
EM hussamalics@gmail.com; muhammadsharifmalik@yahoo.com;
   mussaratabdullah@gmail.com; mshrehmani@gmail.com
RI Sharif, Muhammad/ACD-2598-2022; Ali, Hussam/I-4217-2016; Sharif,
   Muhammad/AAB-8376-2022; Rehmani, Mubashir Husain/E-8059-2014; Yasmin,
   Mussarat/HPC-9476-2023
OI Sharif, Muhammad/0000-0002-7258-8400; Ali, Hussam/0000-0002-9520-5185;
   Rehmani, Mubashir Husain/0000-0002-3565-7390; Sharif,
   Muhammad/0000-0002-1355-2168
CR Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Constantinescu A. F., 2015, Applied Medical Informatics, V36, P31
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Hafner M, 2010, IEEE T INF TECHNOL B, V14, P958, DOI 10.1109/TITB.2010.2044184
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Kiesslich R, 2007, GASTROINTEST ENDOSC, V66, P150, DOI 10.1016/j.gie.2006.12.031
   Koshy NE, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1725, DOI 10.1109/ECS.2015.7124881
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Lee TC, 2013, IEEE ENG MED BIO, P4430, DOI 10.1109/EMBC.2013.6610529
   Li BP, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P766, DOI 10.1109/ICInfA.2015.7279387
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Ma Y., 1995, P IEEE INT C IM PROC, V2, P256, DOI DOI 10.1109/ICIP.1995.537463
   Magoulas GD, 2004, APPL SOFT COMPUT, V4, P369, DOI 10.1016/j.asoc.2004.01.005
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   McGill S, 2009, CAN J GASTROENTEROL, V23, P741, DOI 10.1155/2009/143949
   Miyahara R, 2007, J GASTROEN HEPATOL, V22, P1435, DOI 10.1111/j.1440-1746.2007.04991.x
   Nagahama T, 2011, GASTROINTEST ENDOSC, V74, P1259, DOI 10.1016/j.gie.2011.09.005
   Pennazio M, 2006, DIGEST LIVER DIS, V38, P867, DOI 10.1016/j.dld.2006.09.007
   Qi X, 2008, COMPUTER AIDED DIAGN
   Riaz F, 2017, IEEE J BIOMED HEALTH, V21, P162, DOI 10.1109/JBHI.2015.2492464
   Riaz F, 2013, IEEE T BIO-MED ENG, V60, P1191, DOI 10.1109/TBME.2012.2230174
   Riaz F, 2012, IEEE T BIO-MED ENG, V59, P2893, DOI 10.1109/TBME.2012.2212440
   Siegel RL, 2015, CA-CANCER J CLIN, V65, P5, DOI 10.3322/caac.21254
   Sousa A, 2009, IEEE IMAGE PROC, P681, DOI 10.1109/ICIP.2009.5414082
   Swannell R., 2010, WORLD CANC REPORT 20, P6
   Vecsei A, 2009, COMPUT METH PROG BIO, V95, pS68, DOI 10.1016/j.cmpb.2009.02.017
   Wallace MB, 2010, GASTROENTEROLOGY, V138, P2140, DOI 10.1053/j.gastro.2009.12.067
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
NR 33
TC 22
Z9 22
U1 0
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD SEP 1
PY 2017
VL 88
BP 84
EP 92
DI 10.1016/j.compbiomed.2017.07.002
PG 9
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA FG3DF
UT WOS:000410016300009
PM 28700903
DA 2023-04-20
ER

PT J
AU Dimas, G
   Iakovidis, DK
   Karargyris, A
   Ciuti, G
   Koulaouzidis, A
AF Dimas, George
   Iakovidis, Dimitris K.
   Karargyris, Alexandros
   Ciuti, Gastone
   Koulaouzidis, Anastasios
TI An artificial neural network architecture for non-parametric visual
   odometry in wireless capsule endoscopy
SO MEASUREMENT SCIENCE AND TECHNOLOGY
LA English
DT Article
DE visual odometry; capsule endoscope localization; neural networks;
   medical imaging
ID DIAGNOSIS; MODEL
AB Wireless capsule endoscopy is a non-invasive screening procedure of the gastrointestinal (GI) tract performed with an ingestible capsule endoscope (CE) of the size of a large vitamin pill. Such endoscopes are equipped with a usually low-frame-rate color camera which enables the visualization of the GI lumen and the detection of pathologies. The localization of the commercially available CEs is performed in the 3D abdominal space using radio-frequency (RF) triangulation from external sensor arrays, in combination with transit time estimation. State-of-the-art approaches, such as magnetic localization, which have been experimentally proved more accurate than the RF approach, are still at an early stage. Recently, we have demonstrated that CE localization is feasible using solely visual cues and geometric models. However, such approaches depend on camera parameters, many of which are unknown. In this paper the authors propose a novel non-parametric visual odometry (VO) approach to CE localization based on a feed-forward neural network architecture. The effectiveness of this approach in comparison to state-of-the-art geometric VO approaches is validated using a robotic-assisted in vitro experimental setup.
C1 [Dimas, George; Iakovidis, Dimitris K.] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
   [Karargyris, Alexandros] IBM Res, San Jose, CA USA.
   [Ciuti, Gastone] St Anna Sch Adv Studies, BioRobot Inst, Pisa, Italy.
   [Koulaouzidis, Anastasios] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh, Midlothian, Scotland.
C3 International Business Machines (IBM); Scuola Superiore Sant'Anna; Royal
   Infirmary of Edinburgh; University of Edinburgh
RP Iakovidis, DK (通讯作者)，Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
EM dimitris.iakovidis@ieee.org
RI Ciuti, Gastone/T-6377-2018; Koulaouzidis, Anastasios/G-9060-2014
OI Ciuti, Gastone/0000-0002-0855-7976; Koulaouzidis,
   Anastasios/0000-0002-2248-489X
CR Ahmed M. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P463, DOI 10.1109/ICCV.1999.791257
   Bao G, 2013, IEEE INT C ELECTRO I, P1, DOI [10.1109/EIT.2013.6632652, DOI 10.1109/EIT.2013.6632652]
   Baptista Veronica, 2014, World J Gastrointest Pathophysiol, V5, P523, DOI 10.4291/wjgp.v5.i4.523
   Besdok E, 2009, SENSORS-BASEL, V9, P4572, DOI 10.3390/s90604572
   Corporation G I, 2013, PILLCAM CAPSULE ENDO
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   HORNIK K, 1990, NEURAL NETWORKS, V3, P551, DOI 10.1016/0893-6080(90)90005-6
   Hu C, 2004, IEEE INT CONF ROBOT, P4718
   Iakovidis D K, 2013, 2013 IEEE 13 INT C B
   Iakovidis DK, 2016, IEEE CONF IMAGING SY, P83, DOI 10.1109/IST.2016.7738202
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   J-Y Bouguet, 2004, CAMERA CALIBRATION T
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153
   Kita H, 2006, BEST PRACT RES CL GA, V20, P179, DOI 10.1016/j.bpg.2005.09.004
   Konda Kishore, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P486
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Looney CG, 1997, PATTERN RECOGNITION
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lucas BD., ITERATIVE IMAGE REGI, P674
   Memon Q, 2001, INT J SYST SCI, V32, P1155, DOI 10.1080/00207720010024276
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Mi L, 2014, PROC SPIE, V9036, DOI 10.1117/12.2043963
   Nister D, 2004, PROC CVPR IEEE, P652
   Poynton C., 1996, MAGNITUDE NONCONSTAN
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sliker LJ, 2014, EXPERT REV MED DEVIC, V11, P649, DOI 10.1586/17434440.2014.941809
   Spyrou E, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/1/015002
   Tomasi C., 1991, CMUCS91132
   Than TD, 2014, IEEE T ROBOT, V30, P1174, DOI 10.1109/TRO.2014.2333111
   Than TD, 2012, IEEE T BIO-MED ENG, V59, P2387, DOI 10.1109/TBME.2012.2201715
   Ye YX, 2014, INT J WIREL INF NETW, V21, P208, DOI 10.1007/s10776-014-0247-7
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
NR 34
TC 11
Z9 11
U1 0
U2 24
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0957-0233
EI 1361-6501
J9 MEAS SCI TECHNOL
JI Meas. Sci. Technol.
PD SEP
PY 2017
VL 28
IS 9
AR 094005
DI 10.1088/1361-6501/aa7ebf
PG 10
WC Engineering, Multidisciplinary; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA FE4AA
UT WOS:000408155600003
DA 2023-04-20
ER

PT J
AU Hashimoto, S
   Ogihara, H
   Suenaga, M
   Fujita, Y
   Terai, S
   Hamamoto, Y
   Sakaida, I
AF Hashimoto, Shinichi
   Ogihara, Hiroyuki
   Suenaga, Masato
   Fujita, Yusuke
   Terai, Shuji
   Hamamoto, Yoshihiko
   Sakaida, Isao
TI An Automated Self-Learning Quantification System to Identify Visible
   Areas in Capsule Endoscopy Images
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Capsule endoscopy; Visible area; Supervised learning; Self-learning
ID BLEEDING DETECTION; BOWEL PREPARATION; VIDEOS; QUALITY
AB Visibility in capsule endoscopic images is presently evaluated through intermittent analysis of frames selected by a physician. It is thus subjective and not quantitative. A method to automatically quantify the visibility on capsule endoscopic images has not been reported. Generally, when designing automated image recognition programs, physicians must provide a training image; this process is called supervised learning. We aimed to develop a novel automated self-learning quantification system to identify visible areas on capsule endoscopic images. The technique was developed using 200 capsule endoscopic images retrospectively selected from each of three patients. The rate of detection of visible areas on capsule endoscopic images between a supervised learning program, using training images labeled by a physician, and our novel automated self-learning program, using unlabeled training images without intervention by a physician, was compared. The rate of detection of visible areas was equivalent for the supervised learning program and for our automatic self-learning program. The visible areas automatically identified by self-learning program correlated to the areas identified by an experienced physician. We developed a novel self-learning automated program to identify visible areas in capsule endoscopic images.
C1 [Hashimoto, Shinichi; Sakaida, Isao] Yamaguchi Univ, Dept Gastroenterol & Hepatol, Grad Sch Med, 1-1-1 Minami Kogushi, Ube, Yamaguchi 7558505, Japan.
   [Ogihara, Hiroyuki; Suenaga, Masato] Yamaguchi Univ, Dept Biomol Engn Appl Mol Biosci, Grad Sch Med, 2-16-1 Tokiwadai, Ube, Yamaguchi 7558611, Japan.
   [Fujita, Yusuke; Hamamoto, Yoshihiko] Yamaguchi Univ, Div Elect Elect & Informat Engn, Grad Sch Sci & Technol Innovat, 2-16-1 Tokiwadai, Ube, Yamaguchi 7558611, Japan.
   [Terai, Shuji] Niigata Univ, Div Gastroenterol & Hepatol, Grad Sch Med & Dent Sci, Chuo Ku, 757 Ichibancho, Niigata, Niigata 9518510, Japan.
C3 Yamaguchi University; Yamaguchi University; Yamaguchi University;
   Niigata University
RP Hashimoto, S (通讯作者)，Yamaguchi Univ, Dept Gastroenterol & Hepatol, Grad Sch Med, 1-1-1 Minami Kogushi, Ube, Yamaguchi 7558505, Japan.
EM has-333@yamaguchi-u.ac.jp
CR Duda RO, 2001, PATTERN CLASSIFICATI, P20
   Endo H, 2008, DIGEST DIS SCI, V53, P3201, DOI 10.1007/s10620-008-0292-0
   Ghosh T, 2014, IEEE ENG MED BIO, P4683, DOI 10.1109/EMBC.2014.6944669
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Lau PY, 2007, P ANN INT IEEE EMBS, P5601, DOI 10.1109/IEMBS.2007.4353616
   Lv GL, 2011, IEEE ENG MED BIO, P6643, DOI 10.1109/IEMBS.2011.6091638
   Niv Y, 2005, ALIMENT PHARM THER, V22, P957, DOI 10.1111/j.1365-2036.2005.02647.x
   Rokkas T, 2009, AM J GASTROENTEROL, V104, P219, DOI 10.1038/ajg.2008.63
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Van Weyenberg SJB, 2011, ENDOSCOPY, V43, P406, DOI 10.1055/s-0030-1256228
NR 14
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD AUG
PY 2017
VL 41
IS 8
AR 119
DI 10.1007/s10916-017-0769-5
PG 9
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA FA6CV
UT WOS:000405531800007
PM 28685305
DA 2023-04-20
ER

PT J
AU Leja, M
   Camargo, MC
   Polaka, I
   Isajevs, S
   Liepniece-Karele, I
   Janciauskas, D
   Rudzite, D
   Kikuste, I
   Vanags, A
   Kojalo, I
   Folkmanis, V
   Kirsners, A
   Tolmanis, I
   Rabkin, CS
AF Leja, Marcis
   Camargo, M. Constanza
   Polaka, Inese
   Isajevs, Sergejs
   Liepniece-Karele, Inta
   Janciauskas, Dainius
   Rudzite, Dace
   Kikuste, Ilze
   Vanags, Aigars
   Kojalo, Ilona
   Folkmanis, Valdis
   Kirsners, Arnis
   Tolmanis, Ivars
   Rabkin, Charles S.
TI Detection of gastric atrophy by circulating pepsinogens: A comparison of
   three assays
SO HELICOBACTER
LA English
DT Article
DE atrophy; gastric cancer; pepsinogen; risk stratification; stomach
ID SERUM PEPSINOGEN; CANCER
AB Background: Circulating levels of pepsinogens have been used in high gastric cancer-risk Asian and European populations to triage endoscopic evaluation for more severe pathology. There are different analytic methods with uncertain correlations. We therefore compared diagnostic performance of three commonly used pepsinogen assays to detect histologically confirmed gastric atrophy.
   Methods: We tested plasma samples from adult patients with (n = 50) and without (n = 755) moderate or severe gastric corpus atrophy, as determined histologically by consensus of three expert pathologists. A single laboratory measured pepsinogens I (PgI) and II (PgII) using commercially available assays: two ELISA assays produced by Biohit (Finland) and Vector Best (Russia), and a latex agglutination assay from Eiken (Japan). Quantitative correlations were assessed by Spearman statistics. Receiver operating characteristic (ROC) curves vs histological diagnosis were calculated using both the manufacturers' and optimized cutoffs.
   Results: Pepsinogen levels were highly correlated among the assays (pairwise Rhos: PgI >= 0.84, PgII >= 0.87; all P-values<.01). Based on manufacturers' cutoffs, sensitivities, specificities and areas under the ROC curve for detecting moderate to severe histological corpus atrophy by PgI/PgII were 44%/91%/0.70, 56%/84%/0.76, and 52%/90%/0.77 for Biohit, Vector Best and Eiken, respectively. Cutoffs optimized by ROC or data mining analyses did not substantially improve test performance.
   Conclusions: Commercial assays for pepsinogen have good relative agreement but are imperfect tests for clinical diagnosis of gastric atrophy. Impact: Pepsinogen testing alone does not provide sufficient information for gastric cancer risk stratification. Future investigations should focus on other potential markers, in combination with pepsinogens.
C1 [Leja, Marcis; Polaka, Inese; Isajevs, Sergejs; Liepniece-Karele, Inta; Rudzite, Dace; Kikuste, Ilze; Kojalo, Ilona; Folkmanis, Valdis; Kirsners, Arnis] Univ Latvia, Inst Clin & Prevent Med, Riga, Latvia.
   [Leja, Marcis; Polaka, Inese; Isajevs, Sergejs; Liepniece-Karele, Inta; Rudzite, Dace; Kikuste, Ilze; Kojalo, Ilona; Folkmanis, Valdis; Kirsners, Arnis] Univ Latvia, Fac Med, Riga, Latvia.
   [Leja, Marcis; Isajevs, Sergejs; Liepniece-Karele, Inta; Rudzite, Dace; Kojalo, Ilona; Kirsners, Arnis] Riga East Univ Hosp, Dept Res, Riga, Latvia.
   [Leja, Marcis; Kikuste, Ilze; Vanags, Aigars; Tolmanis, Ivars] Digest Dis Ctr GASTRO, Riga, Latvia.
   [Camargo, M. Constanza; Rabkin, Charles S.] NCI, Div Canc Epidemiol & Genet, Bethesda, MD 20892 USA.
   [Polaka, Inese; Kirsners, Arnis] Riga Tech Univ, Fac Comp Sci & Informat Technol, Riga, Latvia.
   [Isajevs, Sergejs; Liepniece-Karele, Inta] Acad Histol Lab, Riga, Latvia.
   [Janciauskas, Dainius] Lithuanian Univ Healthcare, Kaunas, Lithuania.
C3 University of Latvia; University of Latvia; Riga East University
   Hospital; National Institutes of Health (NIH) - USA; NIH National Cancer
   Institute (NCI); Riga Technical University
RP Leja, M (通讯作者)，Univ Latvia, Inst Clin & Prevent Med, Riga, Latvia.
EM cei@latnet.lv
RI Polaka, Inese/H-4565-2016; Camargo, M. Constanza/R-9891-2016
OI Polaka, Inese/0000-0002-9892-7765; Camargo, M.
   Constanza/0000-0002-1065-2198; TOLMANIS, IVARS/0000-0003-0783-6460;
   Kirsners, Arnis/0000-0002-1252-0623; Isajevs,
   Sergejs/0000-0001-7159-0464
FU State Program in Research of Latvia - BIOMEDICINE; University of Latvia
FX This study was supported in part from the Project No. 4, State Program
   in Research of Latvia - BIOMEDICINE 2014-2017 and Project from
   University of Latvia: "Actual clinical and fundamental research in
   biomedicine and farmacy"
CR Agreus L, 2012, SCAND J GASTROENTERO, V47, P136, DOI 10.3109/00365521.2011.645501
   [Anonymous], 2015, INT J CANCER
   Bornschein J, 2014, FRONT BIOSCI-LANDMRK, V19, P312, DOI 10.2741/4210
   Brenner H, 2007, INT J CANCER, V121, P2782, DOI 10.1002/ijc.22992
   Checchi S, 2007, J CLIN ENDOCR METAB, V92, P4346, DOI 10.1210/jc.2007-0988
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Di Mario F, 2006, DIGEST DIS SCI, V51, P1791, DOI 10.1007/s10620-006-9206-1
   Dinis-Ribeiro M, 2004, J MED SCREEN, V11, P141, DOI 10.1258/0969141041732184
   Fock KM, 2009, J GASTROEN HEPATOL, V24, P1587, DOI 10.1111/j.1440-1746.2009.05982.x
   Hall M., 2009, ACM SPECIAL INTEREST, V11, P10
   Huang YK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142080
   Huang ZG, 2014, BMC GASTROENTEROL, V14, DOI 10.1186/1471-230X-14-74
   Iijima K, 2005, J GASTROENTEROL, V40, P938, DOI 10.1007/s00535-005-1677-x
   Kim N, 2010, GUT LIVER, V4, P307, DOI 10.5009/gnl.2010.4.3.307
   Lomba-Viana R, 2012, EUR J GASTROEN HEPAT, V24, P37, DOI 10.1097/MEG.0b013e32834d0a0a
   Malfertheiner P, 2017, GUT, V66, P6, DOI 10.1136/gutjnl-2016-312288
   Miki Kazumasa, 2006, Gastric Cancer, V9, P245, DOI 10.1007/s10120-006-0397-0
   Miki K, 2011, P JPN ACAD B-PHYS, V87, P405, DOI 10.2183/pjab.87.405
   Miki K, 2009, DIGEST ENDOSC, V21, P134, DOI 10.1111/j.1443-1661.2009.00845.x
   NOMURA AMY, 1980, ANN INTERN MED, V93, P537, DOI 10.7326/0003-4819-93-4-537
   Ross Quinlan J., 1993, MACH LEARN, V16, P235, DOI DOI 10.1007/BF00993309
   SAMLOFF IM, 1971, GASTROENTEROLOGY, V60, P586
   SAMLOFF IM, 1974, GASTROENTEROLOGY, V66, P494
   Terasawa T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109783
   Zayakin P, 2013, INT J CANCER, V132, P137, DOI 10.1002/ijc.27667
NR 25
TC 28
Z9 31
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1083-4389
EI 1523-5378
J9 HELICOBACTER
JI Helicobacter
PD AUG
PY 2017
VL 22
IS 4
AR e12393
DI 10.1111/hel.12393
PG 6
WC Gastroenterology & Hepatology; Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Microbiology
GA EZ8GA
UT WOS:000404961600013
PM 28557128
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Takeda, K
   Kudo, S
   Mori, Y
   Misawa, M
   Kudo, T
   Wakamura, K
   Katagiri, A
   Baba, T
   Hidaka, E
   Ishida, F
   Inoue, H
   Oda, M
   Mori, K
AF Takeda, Kenichi
   Kudo, Shin-ei
   Mori, Yuichi
   Misawa, Masashi
   Kudo, Toyoki
   Wakamura, Kunihiko
   Katagiri, Atsushi
   Baba, Toshiyuki
   Hidaka, Eiji
   Ishida, Fumio
   Inoue, Haruhiro
   Oda, Masahiro
   Mori, Kensaku
TI Accuracy of diagnosing invasive colorectal cancer using computer-aided
   endocytoscopy
SO ENDOSCOPY
LA English
DT Article
ID POLYP HISTOLOGY; LESIONS; ENDOSCOPY; SYSTEM; CLASSIFICATION; SOCIETY
AB Background and study aims Invasive cancer carries the risk of metastasis, and therefore, the ability to distinguish between invasive cancerous lesions and less-aggressive lesions is important. We evaluated a computer-aided diagnosis system that uses ultra-high (approximately x 400) magnification endocytoscopy (EC-CAD).
   Patients and methods We generated an image database from a consecutive series of 5843 endocytoscopy images of 375 lesions. For construction of a diagnostic algorithm, 5543 endocytoscopy images from 238 lesions were randomly extracted from the database for machine learning. We applied the obtained algorithm to 200 endocytoscopy images and calculated test characteristics for the diagnosis of invasive cancer. We defined a high-confidence diagnosis as having a >= 90% probability of being correct.
   Results Of the 200 test images, 188 (94.0%) were assessable with the EC-CADsystem. Sensitivity, specificity, accuracy, positive predictive value (PPV), and negative predictive value (NPV) were 89.4%, 98.9%, 94.1%, 98.8%, and 90.1 %, respectively. High-confidence diagnosis had a sensitivity, specificity, accuracy, PPV, and NPV of 98.1%, 100%, 99.3%, 100 %, and 98.8%, respectively.
   Conclusion: EC-CADmay be a useful tool in diagnosing invasive colorectal cancer.
C1 [Takeda, Kenichi; Kudo, Shin-ei; Mori, Yuichi; Misawa, Masashi; Kudo, Toyoki; Wakamura, Kunihiko; Katagiri, Atsushi; Baba, Toshiyuki; Hidaka, Eiji; Ishida, Fumio] Showa Univ, Northern Yokohama Hosp, Ctr Digest Dis, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
   [Inoue, Haruhiro] Showa Univ, Koto Toyosu Hosp, Ctr Digest Dis, Tokyo, Japan.
   [Oda, Masahiro] Nagoya Univ, Grad Sch Informat Sci, Nagoya, Aichi, Japan.
   [Mori, Kensaku] Nagoya Univ, Informat & Commun, Nagoya, Aichi, Japan.
C3 Showa University; Showa University; Nagoya University; Nagoya University
RP Kudo, S (通讯作者)，Showa Univ, Northern Yokohama Hosp, Ctr Digest Dis, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
EM kudos@med-showa-u.ac.jp
RI Misawa, Masashi/H-9004-2019; Mori, Yuichi/AAU-5406-2020
OI Misawa, Masashi/0000-0002-8520-2036; Mori, Kensaku/0000-0002-0100-4797;
   Mori, Yuichi/0000-0003-2262-0334; Oda, Masahiro/0000-0001-7714-422X
FU Japan Society for the Promotion of Science [25860564, 15K19351];
   Grants-in-Aid for Scientific Research [15K19351, 17H05305, 25860564,
   17K15971] Funding Source: KAKEN
FX We thank Cybernet Systems (Tokyo, Japan) for their cooperation in
   developing the EC-CADsystem. This study was supported by Grants-in-Aid
   for Scientific Research (Number 25860564 and 15K19351) from the Japan
   Society for the Promotion of Science.
CR Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Kiesslich R, 2004, GASTROENTEROLOGY, V127, P706, DOI 10.1053/j.gastro.2004.06.050
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2001, ENDOSCOPY, V33, P367
   Kudo SE, 2011, ENDOSCOPY, V43, P869, DOI 10.1055/s-0030-1256663
   Kudo SE, 2015, GASTROINTEST ENDOSC, V82, P912, DOI 10.1016/j.gie.2015.04.039
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Takeda K, 2016, ENDOSC INT OPEN, V4, pE397, DOI 10.1055/s-0042-101753
   Wanders LK, 2013, LANCET ONCOL, V14, P1337, DOI 10.1016/S1470-2045(13)70509-6
   Watanabe T, 2015, INT J CLIN ONCOL, V20, P207, DOI 10.1007/s10147-015-0801-z
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 15
TC 70
Z9 73
U1 1
U2 8
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD AUG
PY 2017
VL 49
IS 8
BP 798
EP 802
DI 10.1055/s-0043-105486
PG 5
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA FB6ZV
UT WOS:000406291800017
PM 28472832
DA 2023-04-20
ER

PT J
AU Croner, LJ
   Dillon, R
   Kao, A
   Kairs, SN
   Benz, R
   Christensen, IJ
   Nielsen, HJ
   Blume, JE
   Wilcox, B
AF Croner, Lisa J.
   Dillon, Roslyn
   Kao, Athit
   Kairs, Stefanie N.
   Benz, Ryan
   Christensen, Ib J.
   Nielsen, Hans J.
   Blume, John E.
   Wilcox, Bruce
TI Discovery and validation of a colorectal cancer classifier in a new
   blood test with improved performance for high-risk subjects
SO CLINICAL PROTEOMICS
LA English
DT Article
DE Blood tests; Clinical markers; Colorectal neoplasms; Tumor biomarkers;
   Proteomics
ID DIAGNOSTIC WORK-UP; MASS-SPECTROMETRY; AMERICAN-COLLEGE; PRIMARY-CARE;
   MORTALITY; BIOMARKERS; DISEASE; CURVES
AB Background: The aim was to improve upon an existing blood-based colorectal cancer (CRC) test directed to high-risk symptomatic patients, by developing a new CRC classifier to be used with a new test embodiment. The new test uses a robust assay format-electrochemiluminescence immunoassays-to quantify protein concentrations. The aim was achieved by building and validating a CRC classifier using concentration measures from a large sample set representing a true intent-to-test (ITT) symptomatic population.
   Methods: 4435 patient samples were drawn from the Endoscopy II sample set. Samples were collected at seven hospitals across Denmark between 2010 and 2012 from subjects with symptoms of colorectal neoplasia. Colonoscopies revealed the presence or absence of CRC. 27 blood plasma proteins were selected as candidate biomarkers based on previous studies. Multiplexed electrochemiluminescence assays were used to measure the concentrations of these 27 proteins in all 4435 samples. 3066 patients were randomly assigned to the Discovery set, in which machine learning was used to build candidate classifiers. Some classifiers were refined by allowing up to a 25% indeterminate score range. The classifier with the best Discovery set performance was successfully validated in the separate Validation set, consisting of 1336 samples.
   Results: The final classifier was a logistic regression using ten predictors: eight proteins (A1AG, CEA, CO9, DPPIV, MIF, PKM2, SAA, TFRC), age, and gender. In validation, the indeterminate rate of the new panel was 23.2%, sensitivity/specificity was 0.80/0.83, PPV was 36.5%, and NPV was 97.1%.
   Conclusions: The validated classifier serves as the basis of a new blood-based CRC test for symptomatic patients. The improved performance, resulting from robust concentration measures across a large sample set mirroring the ITT population, renders the new test the best available for this population. Results from a test using this classifier can help assess symptomatic patients' CRC risk, increase their colonoscopy compliance, and manage next steps in their care.
C1 [Croner, Lisa J.; Dillon, Roslyn; Kao, Athit; Kairs, Stefanie N.; Benz, Ryan; Blume, John E.; Wilcox, Bruce] Appl Prote Inc, 3545 John Hopkins Court,Suite 150, San Diego, CA 92121 USA.
   [Christensen, Ib J.; Nielsen, Hans J.] Univ Copenhagen, Hvidovre Hosp, Dept Surg Gastroenterol 360, DK-2650 Hvidovre, Denmark.
C3 University of Copenhagen
RP Croner, LJ (通讯作者)，Appl Prote Inc, 3545 John Hopkins Court,Suite 150, San Diego, CA 92121 USA.
EM lisa@appliedproteomics.com
OI Nielsen, Hans Jorgen/0000-0003-2619-4379; Kairs,
   Stefanie/0000-0003-4957-6636; Blume, John/0000-0003-3026-953X; Benz,
   Ryan/0000-0002-8924-6116
CR Alves JC, 2016, FRONT IMMUNOL, V7, DOI 10.3389/fimmu.2016.00145
   Anderson L, 2014, J PROTEOMICS, V107, P24, DOI 10.1016/j.jprot.2014.03.005
   Blume JE, 2016, J APPL LAB MED, V1, P181, DOI 10.1373/jalm.2016.020271
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bretthauer M, 2016, JAMA INTERN MED, V176, P894, DOI 10.1001/jamainternmed.2016.0960
   Brierley JD, 2017, TNM CLASSIFICATION M, Veighth, DOI DOI 10.1002/9780471420194.TNMC26.PUB3
   Clarke N, 2014, BMC GASTROENTEROL, V14, DOI 10.1186/1471-230X-14-92
   da Silva RB, 2015, NAT IMMUNOL, V16, P850, DOI 10.1038/ni.3201
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Elias SG, 2016, BMC MED, V14, DOI 10.1186/s12916-016-0684-5
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Fisher RA, 1922, J R STAT SOC, V85, P87, DOI 10.2307/2340521
   Fraser CG, 2016, BMC MED, V14, DOI 10.1186/s12916-016-0694-3
   Jones JJ, 2016, CLIN COLORECTAL CANC, V15, P186, DOI 10.1016/j.clcc.2016.02.004
   Kruse N, 2012, METHODS, V56, P514, DOI 10.1016/j.ymeth.2012.03.016
   Levin B, 2008, CA-CANCER J CLIN, V58, P130, DOI 10.3322/CA.2007.0018
   Lindebjerg J, 2014, DAN MED J, V61
   McShane LM, 2005, BRIT J CANCER, V93, P387, DOI 10.1038/sj.bjc.6602678
   Meyer D., 2015, E1071 MISC FUNCTIONS, P6
   Morito K, 2015, INT J ONCOL, V46, P563, DOI 10.3892/ijo.2014.2755
   Plevy S, 2013, INFLAMM BOWEL DIS, V19, P1139, DOI 10.1097/MIB.0b013e318280b19e
   Qaseem A, 2012, ANN INTERN MED, V156, P378, DOI 10.7326/0003-4819-156-5-201203060-00010
   R Core Team, 2016, R FDN STAT COMP
   Robin X, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-77
   Romanski P., 2016, **DATA OBJECT**
   Rus H, 2005, IMMUNOL RES, V33, P103, DOI 10.1385/IR:33:2:103
   Schliep K., 2016, KKNN WEIGHTED K NEAR
   SCHULTZ DR, 1990, SEMIN ARTHRITIS RHEU, V20, P129, DOI 10.1016/0049-0172(90)90055-K
   Senore C, 2014, NEW ENGL J MED, V371, P185, DOI [10.1056/NEJMc1405215, 10.1056/NEJMoa1311194]
   Simon N, 2011, J STAT SOFTW, V39, P1
   Sing T, 2005, BIOINFORM, V12, P7881
   Song LL, 2016, WORLD J GASTRO ONCOL, V8, P793, DOI 10.4251/wjgo.v8.i11.793
   Surinova S, 2011, J PROTEOME RES, V10, P5, DOI 10.1021/pr1008515
   Thorsen SB, 2013, J TRANSL MED, V11, DOI 10.1186/1479-5876-11-253
   Wheelhouse NM, 2006, INT J MOL MED, V18, P957
   Wilcox BE, 2016, GASTROENTEROLOGY, V150, pS185, DOI 10.1016/S0016-5085(16)30705-3
   Wilhelmsen M, 2017, INT J CANCER, V140, P1436, DOI 10.1002/ijc.30558
   Zauber AG, 2015, DIGEST DIS SCI, V60, P681, DOI 10.1007/s10620-015-3600-5
NR 38
TC 9
Z9 9
U1 4
U2 7
PU BIOMED CENTRAL LTD
PI LONDON
PA 236 GRAYS INN RD, FLOOR 6, LONDON WC1X 8HL, ENGLAND
SN 1542-6416
EI 1559-0275
J9 CLIN PROTEOM
JI Clin. Proteom.
PD JUL 25
PY 2017
VL 14
AR 28
DI 10.1186/s12014-017-9163-z
PG 12
WC Biochemical Research Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology
GA FC1XG
UT WOS:000406630700001
PM 28769740
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Liu, XQ
   Wang, CL
   Bai, JY
   Liao, GB
   Zhao, YJ
AF Liu, Xiaoqi
   Wang, Chengliang
   Bai, Jianying
   Liao, Guobin
   Zhao, Yanjun
TI Hue-texture-embedded region-based model for magnifying endoscopy with
   narrow-band imaging image segmentation based on visual features
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE ME-NBI; Precancerous lesions; Early gastric cancer; Segmentation;
   Hue-texture-embedded region-based active contour model
ID ACTIVE CONTOURS; CANCER; CHINA
AB Background and objective: Magnification endoscopy with narrow-band imaging (ME-NBI) has become a feasible tool for detecting diseases within the human gastrointestinal tract, and is more applied by physicians to search for pathological abnormalities with gastric cancer such as precancerous lesions, early gastric cancer and advanced cancer. In order to improve the reliability of diseases detection, there is a need for applying or proposing computer-assisted methodologies to efficiently analyze and process ME-NBI images. However, traditional computer vision methodologies, mainly segmentation, do not express well to the specific visual characteristics of NBI scenario.
   Methods: In this paper, two energy functional items based on specific visual characteristics of ME-NBI images have been integrated in the framework of Chan-Vese model to construct the Hue-texture-embedded model. On the one hand, a global hue energy functional was proposed representing a global color information extracted in H channel (HSI color space). On the other hand, a texture energy was put forward presenting local microvascular textures extracted by the PIF of adaptive threshold in S channel.
   Results: The results of our model have been compared with Chan-Vese model and manual annotations marked by physicians using F-measure and false positive rate. The value of average F-measure and FPR was 0.61 and 0.16 achieved through the Hue-texture-embedded region-based model. And the C-V model achieved the average F-measure and FPR value of 0.52 and 0.32, respectively. Experiments showed that the Hue-texture-embedded region-based outperforms Chan-Vese model in terms of efficiency, universality and lesion detection.
   Conclusions: Better segmentation results are acquired by the Hue-texture-embedded region-based model compared with the traditional region-based active contour in these five cases: chronic gastritis, intestinal metaplasia and atrophy, low grade neoplasia, high grade neoplasia and early gastric cancer. In the future, we are planning to expand the universality of our proposed methodology to segment other lesions such as intramucosal cancer etc. As long as these issues are solved, we can proceed with the classification of clinically relevant diseases in ME-NBI images to implement a fully automatic computer-assisted diagnosis system. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Liu, Xiaoqi; Wang, Chengliang] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Wang, Chengliang] Chongqing Univ, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing, Peoples R China.
   [Bai, Jianying; Liao, Guobin] Third Mil Med Univ, Affiliated Hosp 2, Dept Gastroenterol, Chongqing, Peoples R China.
   [Zhao, Yanjun] Troy Univ, Comp Sci Dept, Troy, AL USA.
C3 Chongqing University; Chongqing University; Army Medical University;
   Troy University System; Troy University
RP Liu, XQ (通讯作者)，Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM 252146521@qq.com
OI Liao, Guobin/0000-0002-9861-8161
FU MIIT, China; National Natural Science Foundation, China [61672115];
   basic science and frontier technology research, Chongqing
   [cstc2015shmszx120010]; social undertakings and livelihood security
   technology innovation funds, Chongqing [cstc2015jcyjBX0124]
FX This work is supported by the project of the research on the real time
   image recognition technology and capsule endoscopy intelligent
   diagnostics industrialization project, 2013 special development funds
   for internet of things project of the MIIT, China; software defined
   smart and its application in elderly care, National Natural Science
   Foundation, China (No. 61672115); 2015 basic science and frontier
   technology research, Chongqing (No. cstc2015shmszx120010) and 2015
   social undertakings and livelihood security technology innovation funds,
   Chongqing (No. cstc2015jcyjBX0124).
CR American Cancer Society, 2015, GLOB CANC FACTS FIG
   Catalano V, 2009, CRIT REV ONCOL HEMAT, V71, P127, DOI 10.1016/j.critrevonc.2009.01.004
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Chen WQ, 2015, CHINESE J CANCER RES, V27, P2, DOI 10.3978/j.issn.1000-9604.2015.01.06
   Coimbra M, 2010, IEEE ENG MED BIO, P4744, DOI 10.1109/IEMBS.2010.5626622
   Dingley J, 2009, CASS SER POLIT VIOLE, P1
   Hayashi T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100857
   Hirota T., 1993, GASTRIC CANCER, V66-87
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Li HY, 2012, DIAGN THER ENDOSC, V2012, DOI [10.1155/2012/271914, DOI 10.1155/2012/271914]
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Riaz F, 2011, I S BIOMED IMAGING, P117, DOI 10.1109/ISBI.2011.5872368
   Riaz F, 2013, IEEE T BIO-MED ENG, V60, P1191, DOI 10.1109/TBME.2012.2230174
   Savelonas MA, 2008, PATTERN RECOGN LETT, V29, P1404, DOI 10.1016/j.patrec.2008.02.013
   Sousa A, 2009, IEEE IMAGE PROC, P681, DOI 10.1109/ICIP.2009.5414082
   Sousa A.M.C.D., 2014, FEUPSDIRIFEUP
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Yao K., 2014, ZOOM GASTROSCOPY
   Yao K, 2013, ANN GASTROENTEROL, V26, P11
NR 20
TC 4
Z9 4
U1 0
U2 18
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD JUL
PY 2017
VL 145
BP 53
EP 66
DI 10.1016/j.cmpb.2017.04.010
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA EW4HY
UT WOS:000402463800007
PM 28552126
DA 2023-04-20
ER

PT J
AU Bernal, J
   Tajkbaksh, N
   Sanchez, FJ
   Matuszewski, BJ
   Chen, H
   Yu, LQ
   Angermann, Q
   Romain, O
   Rustad, B
   Balasingham, I
   Pogorelov, K
   Choi, S
   Debard, Q
   Maier-Hein, L
   Speidel, S
   Stoyanov, D
   Brandao, P
   Cordova, H
   Sanchez-Montes, C
   Gurudu, SR
   Fernandez-Esparrach, G
   Dray, X
   Liang, JM
   Histace, A
AF Bernal, Jorge
   Tajkbaksh, Nima
   Sanchez, Francisco Javier
   Matuszewski, Bogdan J.
   Chen, Hao
   Yu, Lequan
   Angermann, Quentin
   Romain, Olivier
   Rustad, Bjorn
   Balasingham, Ilangko
   Pogorelov, Konstantin
   Choi, Sungbin
   Debard, Quentin
   Maier-Hein, Lena
   Speidel, Stefanie
   Stoyanov, Danail
   Brandao, Patrick
   Cordova, Henry
   Sanchez-Montes, Cristina
   Gurudu, Suryakanth R.
   Fernandez-Esparrach, Gloria
   Dray, Xavier
   Liang, Jianming
   Histace, Aymeric
TI Comparative Validation of Polyp Detection Methods in Video Colonoscopy:
   Results From the MICCAI 2015 Endoscopic Vision Challenge
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Endoscopic vision; polyp detection; handcrafted features; machine
   learning; validation framework
ID CT COLONOGRAPHY; MISS RATE; DIAGNOSIS; ADENOMAS; ACCURACY; SYSTEM;
   IMPACT
AB Colonoscopy is the gold standard for colon cancer screening though some polyps are still missed, thus preventing early disease detection and treatment. Several computational systems have been proposed to assist polyp detection during colonoscopy but so far without consistent evaluation. The lack of publicly available annotated databases has made it difficult to compare methods and to assess if they achieve performance levels acceptable for clinical use. The Automatic Polyp Detection subchallenge, conducted as part of the Endoscopic Vision Challenge (https://hfbicc3c649c5357d4053h995u9bvnqn966605fiac.eds.tju.edu.cn) at the international conference onMedical Image Computing and Computer Assisted Intervention (MICCAI) in 2015, was an effort to address this need. In this paper, we report the results of this comparative evaluation of polyp detection methods, as well as describe additional experiments to further explore differences between methods. We define performance metrics and provide evaluation databases that allow comparison of multiple methodologies. Results show that convolutional neural networks are the state of the art. Nevertheless, it is also demonstrated that combining different methodologies can lead to an improved overall performance.
C1 [Bernal, Jorge; Sanchez, Francisco Javier] Univ Autonoma Barcelona, Dept Comp Sci, Bellaterra 08193, Spain.
   [Bernal, Jorge; Sanchez, Francisco Javier] Univ Autonoma Barcelona, Comp Vis Ctr, Bellaterra 08193, Spain.
   [Tajkbaksh, Nima; Liang, Jianming] Arizona State Univ, Tempe, AZ 85281 USA.
   [Matuszewski, Bogdan J.] Univ Cent Lancashire, Sch Engn, Preston PR1 2HE, Lancs, England.
   [Chen, Hao; Yu, Lequan] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Angermann, Quentin; Romain, Olivier; Dray, Xavier; Histace, Aymeric] Univ Cergy Pontoise, ENSEA, ETIS, CNRS, F-95000 Cergy C, France.
   [Rustad, Bjorn; Balasingham, Ilangko] Oslo Univ Hosp, N-0379 Oslo, Norway.
   [Rustad, Bjorn] Univ Oslo, OmniVis, N-0313 Oslo, Norway.
   [Pogorelov, Konstantin] Simula Res Lab, Media Performance Grp, N-0313 Oslo, Norway.
   [Pogorelov, Konstantin] Univ Oslo, N-0313 Oslo, Norway.
   [Choi, Sungbin] Seoul Natl Univ, Seoul 08826, South Korea.
   [Debard, Quentin] Univ Nice Sophia Antipolis, F-06000 Nice, France.
   [Maier-Hein, Lena] German Canc Res Ctr, Jr Grp Comp Assisted Intervent, D-69120 Heidelberg, Germany.
   [Speidel, Stefanie] Karlsruhe Inst Technol, Inst Anthropomat, D-76021 Karlsruhe, Germany.
   [Stoyanov, Danail; Brandao, Patrick] UCL, Ctr Med Image Comp, London WC1E 6BT, England.
   [Stoyanov, Danail; Brandao, Patrick] UCL, Dept Comp Sci, London WC1E 6BT, England.
   [Cordova, Henry; Sanchez-Montes, Cristina; Fernandez-Esparrach, Gloria] Univ Barcelona, CIBEREHD, IDIBAPS, Endoscopy Unit,Gastroenterol Dept,Hosp Clin, Barcelona, Spain.
   [Gurudu, Suryakanth R.] Mayo Clin, Div Gastroenterol & Hepatol, Scottsdale, AZ 85259 USA.
   [Dray, Xavier] Lariboisiere Hosp, APHP, F-75000 Paris, France.
C3 Autonomous University of Barcelona; Autonomous University of Barcelona;
   Centre de Visio per Computador (CVC); Arizona State University; Arizona
   State University-Tempe; University of Central Lancashire; Chinese
   University of Hong Kong; Centre National de la Recherche Scientifique
   (CNRS); CY Cergy Paris Universite; University of Oslo; University of
   Oslo; University of Oslo; Seoul National University (SNU); UDICE-French
   Research Universities; Universite Cote d'Azur; Helmholtz Association;
   German Cancer Research Center (DKFZ); Helmholtz Association; Karlsruhe
   Institute of Technology; University of London; University College
   London; University of London; University College London; CIBER - Centro
   de Investigacion Biomedica en Red; CIBEREHD; University of Barcelona;
   Hospital Clinic de Barcelona; IDIBAPS; Mayo Clinic; Mayo Clinic Phoenix;
   Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire
   Ambroise-Pare - APHP; UDICE-French Research Universities; Universite
   Paris Cite; Hopital Universitaire Lariboisiere-Fernand-Widal - APHP
RP Histace, A (通讯作者)，Univ Cergy Pontoise, ENSEA, ETIS, CNRS, F-95000 Cergy C, France.
RI Bernal, Jorge/H-4647-2015; romain, olivier/AAF-1985-2019; Stoyanov,
   Danail/V-1043-2019; Speidel, Stefanie/K-1959-2017; Chen,
   Hao/V-4299-2019; Balasingham, Ilangko/AGU-7268-2022; Yu,
   Lequan/U-5377-2019; Córdova, Henry/HJG-5764-2022; Sanchez, F.
   Javier/H-5591-2015; Cordova Guevara, Henry Nelson/D-7844-2019
OI Bernal, Jorge/0000-0001-8493-9514; romain, olivier/0000-0002-2172-1865;
   Stoyanov, Danail/0000-0002-0980-3227; Speidel,
   Stefanie/0000-0002-4590-1908; Chen, Hao/0000-0002-8400-3780; Yu,
   Lequan/0000-0002-9315-6527; Sanchez, F. Javier/0000-0002-9364-3122;
   Liang, Jianming/0000-0001-5486-1613; Cordova Guevara, Henry
   Nelson/0000-0002-6636-6764; Fernandez-Esparrach/0000-0002-3378-3940;
   Liang, Jianming/0000-0002-3029-341X
FU ASU-Mayo Clinic partnerships; Spanish Government [DPI2015-65286-R];
   FSEED; Secretaria d'Universitats i Recerca de la Generalitat de
   Catalunya [2014-SGR-1470, 2014-SGR-135]; par SATT IdFInnov (France)
   through the Project Smart Videocolonoscopy [186]; European Union through
   the ERC [ERC-2015-StG-37960]; EPSRC [EP/P012841/1, EP/N022750/1,
   EP/M020533/1] Funding Source: UKRI; Engineering and Physical Sciences
   Research Council [EP/P012841/1, EP/M020533/1, EP/N022750/1, 1091178]
   Funding Source: researchfish
FX This work was supported in part by ASU-Mayo Clinic partnerships, in part
   by the Spanish Government through the Funded Project iVENDIS under
   Project DPI2015-65286-R, in part by FSEED, in part by the Secretaria
   d'Universitats i Recerca de la Generalitat de Catalunya under Grant
   2014-SGR-1470 and Grant 2014-SGR-135, in part by par SATT IdFInnov
   (France) through the Project Smart Videocolonoscopy under Grant 186, and
   in part by the European Union through the ERC starting grant COMBIOSCOPY
   under the New Horizon Framework Programme under Grant
   ERC-2015-StG-37960. (Jorge Bernal and Nima Tajbaksh share first
   co-authorship. Aymeric Histace and Jianming Liang share last
   co-authorship) Asterisk indicates corresponding author.
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Angermann Q, 2016, PROCEDIA COMPUT SCI, V90, P182, DOI 10.1016/j.procs.2016.07.017
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   [Anonymous], 2014, DEEPLY SUPERVISED NE
   Armin MA, 2015, LECT NOTES COMPUT SC, V9349, P396, DOI 10.1007/978-3-319-24553-9_49
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bruno MJ, 2003, GUT, V52, P7
   Burling D, 2010, CLIN RADIOL, V65, P474, DOI 10.1016/j.crad.2009.12.003
   CHEN H, 2016, DCAN DEEP CONTOUR AW
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Coriat R, 2008, GASTROEN CLIN BIOL, V32, P363, DOI 10.1016/j.gcb.2007.11.013
   Farnbacher MJ, 2014, SCAND J GASTROENTERO, V49, P339, DOI 10.3109/00365521.2013.865784
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P494, DOI 10.1016/j.gie.2011.08.002
   Hassan C, 2013, ENDOSCOPY, V45, P842, DOI 10.1055/s-0033-1344548
   Heimann T, 2009, IEEE T MED IMAGING, V28, P1251, DOI 10.1109/TMI.2009.2013851
   Hoffman A, 2010, ENDOSCOPY, V42, P827, DOI 10.1055/s-0030-1255713
   Hongbin Zhu, 2010, Virtual Colonoscopy and Abdominal Imaging. Computational Challenges and Clinical Opportunities. Second International Workshop Held in Conjunction with MICCAI 2010. Revised Selected Papers, P9, DOI 10.1007/978-3-642-25719-3_2
   HWANG S, 2007, P IEEE INT C IM PROC, V0002, P00465
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Iwahori Y., 2013, MVA, P21
   Jemal A, 2008, CA-CANCER J CLIN, V58, P71, DOI 10.3322/CA.2007.0010
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996
   Kang J, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1469
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lebwohl B, 2011, GASTROINTEST ENDOSC, V73, P1207, DOI 10.1016/j.gie.2011.01.051
   Lee SH, 2008, GASTROINTEST ENDOSC, V67, P683, DOI 10.1016/j.gie.2007.10.018
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Maier-Hein L, 2014, IEEE T MED IMAGING, V33, P1913, DOI 10.1109/TMI.2014.2325607
   Park S.Y., 2016, P SPIE, V9785
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Riegler M, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P397, DOI 10.1145/2647868.2654894
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sevo I, 2016, COMPUT BIOL MED, V72, P138, DOI 10.1016/j.compbiomed.2016.03.017
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Zhou Z., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 52
TC 205
Z9 214
U1 3
U2 31
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD JUN
PY 2017
VL 36
IS 6
BP 1231
EP 1249
DI 10.1109/TMI.2017.2664042
PG 19
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA EW7UM
UT WOS:000402722500003
PM 28182555
OA Green Accepted, Green Submitted
DA 2023-04-20
ER

PT J
AU Zhou, T
   Han, GQ
   Li, BN
   Lin, ZZ
   Ciaccio, EJ
   Green, PH
   Qin, J
AF Zhou, Teng
   Han, Guoqiang
   Li, Bing Nan
   Lin, Zhizhe
   Ciaccio, Edward J.
   Green, Peter H.
   Qin, Jing
TI Quantitative analysis of patients with celiac disease by video capsule
   endoscopy: A deep learning method
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Celiac disease; Videocapsule endoscopy; Deep learning; GoogLeNet;
   Quantitative analysis
ID DUODENAL BIOPSY; VILLOUS ATROPHY; DIAGNOSIS
AB Background. Celiac disease is one of the most common diseases in the world. Capsule endoscopy is an alternative way to visualize the entire small intestine without invasiveness to the patient. It is useful to characterize celiac disease, but hours are need to manually analyze the retrospective data of a single patient. Computer-aided quantitative analysis by a deep learning method helps in alleviating the workload during analysis of the retrospective videos.
   Method. Capsule endoscopy clips from 6 celiac disease patients and 5 controls were preprocessed for training. The frames with a large field of opaque extraluminal fluid or air bubbles were removed automatically by using a pre-selection algorithm. Then the frames were cropped and the intensity was corrected prior to frame rotation in the proposed new method. The GoogLeNet is trained with these frames. Then, the clips of capsule endoscopy from 5 additional celiac disease patients and 5 additional control patients are used for testing. The trained GoogLeNet was able to distinguish the frames from capsule endoscopy clips of celiac disease patients vs controls. Quantitative measurement with evaluation of the confidence was developed to assess the severity level of pathology in the subjects.
   Results. Relying on the evaluation confidence, the GoogLeNet achieved 100% sensitivity and specificity for the testing set. The t-test confirmed the evaluation confidence is significant to distinguish celiac disease patients from controls. Furthermore, it is found that the evaluation confidence may also relate to the severity level of small bowel mucosal lesions.
   Conclusions. A deep convolutional neural network was established for quantitative measurement of the existence and degree of pathology throughout the small intestine, which may improve computer-aided clinical techniques to assess mucosal atrophy and other etiologies in real-time with videocapsule endoscopy.
C1 [Zhou, Teng; Han, Guoqiang] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Li, Bing Nan] Hefei Univ Technol, Dept Biomed Engn, Hefei 230009, Peoples R China.
   [Lin, Zhizhe] Sun Yat Sen Univ, Shantou Cent Hosp, Affiliated Shantou Hosp, Shantou 515000, Peoples R China.
   [Qin, Jing] Hong Kong Polytech Univ, Sch Nursing, Ctr Smart Hlth, Hong Kong, Hong Kong, Peoples R China.
   [Ciaccio, Edward J.; Green, Peter H.] Columbia Univ, Dept Med, Celiac Dis Ctr, New York, NY USA.
C3 South China University of Technology; Hefei University of Technology;
   Sun Yat Sen University; Hong Kong Polytechnic University; Columbia
   University
RP Li, BN (通讯作者)，Hefei Univ Technol, Dept Biomed Engn, Hefei 230009, Peoples R China.
EM bingoon@ieee.org
RI Qin, Jing/J-9807-2016; Zhou, Teng/AAG-7091-2020; Zhou, Teng/K-2023-2019
OI Qin, Jing/0000-0002-7059-0929; Zhou, Teng/0000-0003-1920-8891; 
FU National Natural Science Foundation of China [61571176, 61511140099];
   Anhui Provincial Natural Science Foundation [1608085J04]; International
   Science and Technology Cooperation Plan of Anhui Province [1503062015]
FX This work was supported partially by the National Natural Science
   Foundation of China under Grants 61571176 and 61511140099, in part by
   Anhui Provincial Natural Science Foundation under Grant 1608085J04, and
   in part by the International Science and Technology Cooperation Plan of
   Anhui Province under Grant 1503062015.
CR Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cheng G, 2016, PROC CVPR IEEE, P2884, DOI 10.1109/CVPR.2016.315
   Ciaccio EJ, 2016, COMPUT BIOL MED, V78, P97, DOI 10.1016/j.compbiomed.2016.09.009
   Ciaccio EJ, 2015, COMPUT BIOL MED, V65, P364, DOI 10.1016/j.compbiomed.2015.04.019
   Ciaccio EJ, 2013, WORLD J GASTRO ENDOS, V5, P313, DOI 10.4253/wjge.v5.i7.313
   Ciaccio EJ, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-44
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   El-Matary W, 2009, J LAPAROENDOSC ADV S, V19, P815, DOI 10.1089/lap.2008.0380
   Fasano A, 2012, NEW ENGL J MED, V367, P2419, DOI 10.1056/NEJMcp1113994
   Hopper AD, 2007, DIGEST LIVER DIS, V39, P140, DOI 10.1016/j.dld.2006.07.017
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia Y., ARXIV14085093
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li BN, 2016, IEEE T CYBERNETICS, V46, P2543, DOI 10.1109/TCYB.2015.2479645
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Pais WP, 2008, GASTROINTEST ENDOSC, V67, P1082, DOI 10.1016/j.gie.2007.10.015
   Petroniene R, 2005, AM J GASTROENTEROL, V100, P685, DOI 10.1111/j.1572-0241.2005.41069.x
   Rokkas T, 2012, EUR J GASTROEN HEPAT, V24, P303, DOI 10.1097/MEG.0b013e32834fa914
   Rondonotti E, 2007, AM J GASTROENTEROL, V102, P1624, DOI 10.1111/j.1572-0241.2007.01238.x
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., 2016, 2016 IEEE C COMP VIS, DOI 10.1109/CVPR.2016.308
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Van de Bruaene C, 2015, WORLD J GASTRO ENDOS, V7, P13, DOI 10.4253/wjge.v7.i1.13
   Wang Y, 2016, IEEE T MED IMAGING, V35, P589, DOI 10.1109/TMI.2015.2485299
   Zheng Y., 2008, SINGLE IMAGE VIGNETT, V31, P1
NR 26
TC 94
Z9 102
U1 3
U2 34
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD JUN 1
PY 2017
VL 85
BP 1
EP 6
DI 10.1016/j.compbiomed.2017.03.031
PG 6
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA EX8OX
UT WOS:000403511200001
PM 28412572
DA 2023-04-20
ER

PT J
AU Mossotto, E
   Ashton, JJ
   Coelho, T
   Beattie, RM
   MacArthur, BD
   Ennis, S
AF Mossotto, E.
   Ashton, J. J.
   Coelho, T.
   Beattie, R. M.
   MacArthur, B. D.
   Ennis, S.
TI Classification of Paediatric Inflammatory Bowel Disease using Machine
   Learning
SO SCIENTIFIC REPORTS
LA English
DT Article
ID ULCERATIVE-COLITIS; RISING INCIDENCE; CROHNS-DISEASE; PREDICTION;
   DIAGNOSIS; EXTENT
AB Paediatric inflammatory bowel disease (PIBD), comprising Crohn's disease (CD), ulcerative colitis (UC) and inflammatory bowel disease unclassified (IBDU) is a complex and multifactorial condition with increasing incidence. An accurate diagnosis of PIBD is necessary for a prompt and effective treatment. This study utilises machine learning (ML) to classify disease using endoscopic and histological data for 287 children diagnosed with PIBD. Data were used to develop, train, test and validate a ML model to classify disease subtype. Unsupervised models revealed overlap of CD/UC with broad clustering but no clear subtype delineation, whereas hierarchical clustering identified four novel subgroups characterised by differing colonic involvement. Three supervised ML models were developed utilising endoscopic data only, histological only and combined endoscopic/histological data yielding classification accuracy of 71.0%, 76.9% and 82.7% respectively. The optimal combined model was tested on a statistically independent cohort of 48 PIBD patients from the same clinic, accurately classifying 83.3% of patients. This study employs mathematical modelling of endoscopic and histological data to aid diagnostic accuracy. While unsupervised modelling categorises patients into four subgroups, supervised approaches confirm the need of both endoscopic and histological evidence for an accurate diagnosis. Overall, this paper provides a blueprint for ML use with clinical data.
C1 [Mossotto, E.; Ashton, J. J.; Coelho, T.; Ennis, S.] Univ Southampton, Human Genet & Genom Med, Southampton, Hants, England.
   [Mossotto, E.; MacArthur, B. D.] Univ Southampton, Inst Life Sci, Southampton, Hants, England.
   [Ashton, J. J.; Coelho, T.; Beattie, R. M.] Southampton Childrens Hosp, Dept Pediat Gastroenterol, Southampton, Hants, England.
C3 University of Southampton; University of Southampton
RP Ennis, S (通讯作者)，Univ Southampton, Human Genet & Genom Med, Southampton, Hants, England.
EM s.ennis@southampton.ac.uk
RI Coelho, Tracy/AAE-1472-2019
OI MacArthur, Ben/0000-0002-5396-9750; Ashton, James/0000-0003-0348-8198;
   Beattie, Robert Mark/0000-0003-4721-0577
FU Hilary Marsden IfLS Scholarship; University of Southampton NIHR academic
   clinical fellowship; Crohn's in Childhood Research Association; Action
   Medical Research [2560] Funding Source: researchfish; National Institute
   for Health Research [ACF-2014-26-006] Funding Source: researchfish
FX The authors would like to thank Rachel Haggarty for assistance with
   management of the genetics of PIBD study database. We also would like to
   thank: the Hilary Marsden IfLS Scholarship; the University of
   Southampton NIHR academic clinical fellowship and; the Crohn's in
   Childhood Research Association.
CR Ashton JJ, 2014, ARCH DIS CHILD, V99, P659, DOI 10.1136/archdischild-2013-305419
   Ashton JJ, 2016, J PEDIATR GASTR NUTR, V62, P246, DOI 10.1097/MPG.0000000000001032
   Capriotti E, 2011, GENOMICS, V98, P310, DOI 10.1016/j.ygeno.2011.06.010
   Criminisi A, 2016, MED IMAGE ANAL, V33, P91, DOI 10.1016/j.media.2016.06.002
   de Bie CI, 2013, INFLAMM BOWEL DIS, V19, P378, DOI 10.1002/ibd.23008
   Documentation, 2012, DOCUMENTATION M MATL, DOI [10.1201/9781420034950, DOI 10.1201/9781420034950]
   Fernandes MA, 2016, J PEDIATR GASTR NUTR, V62, P242, DOI 10.1097/MPG.0000000000000967
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Henderson P, 2012, INFLAMM BOWEL DIS, V18, P999, DOI 10.1002/ibd.21797
   Hu XH, 2013, NAT REV UROL, V10, P174, DOI 10.1038/nrurol.2013.9
   Kannel W. B., 1975, CIRCULATION, V51
   Levine A, 2013, J PEDIAT GASTROENTER, P1, DOI 10.1097/MPG. 0 0 0 0 0 0 0 0 0 0 0 0 0239
   Levine A, 2011, INFLAMM BOWEL DIS, V17, P1314, DOI 10.1002/ibd.21493
   Li J, 2016, BRIEF BIOINFORM, V17, P2, DOI 10.1093/bib/bbv020
   Lima AN, 2016, EXPERT OPIN DRUG DIS, V11, P225, DOI 10.1517/17460441.2016.1146250
   Lutz M, 2007, ICARUS, V78
   Mathe C, 2002, NUCLEIC ACIDS RES, V30, P4103, DOI 10.1093/nar/gkf543
   Moum B, 1999, AM J GASTROENTEROL, V94, P1564
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Oliphant TE, 2007, COMPUT SCI ENG, V9, P10, DOI 10.1109/MCSE.2007.58
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Plevy S, 2013, INFLAMM BOWEL DIS, V19, P1139, DOI 10.1097/MIB.0b013e318280b19e
   PODOLSKY DK, 1991, NEW ENGL J MED, V325, P1008, DOI 10.1056/NEJM199110033251406
   SANKEY EA, 1993, GUT, V34, P375, DOI 10.1136/gut.34.3.375
   SOKAL ROBERT R., 1958, UNIV KANSAS SCI BULL, V38, P1409
   Turner D, 2016, J PEDIATR GASTR NUTR, V62, P191, DOI 10.1097/MPG.0000000000001049
   Upstill-Goddard R, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068606
   Wei Z, 2013, AM J HUM GENET, V92, P1008, DOI 10.1016/j.ajhg.2013.05.002
   Weiser M, 2018, GUT, V67, P36, DOI 10.1136/gutjnl-2016-312518
   Woodruff PG, 2009, AM J RESP CRIT CARE, V180, P388, DOI 10.1164/rccm.200903-0392OC
NR 32
TC 72
Z9 72
U1 4
U2 11
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAY 25
PY 2017
VL 7
AR 2427
DI 10.1038/s41598-017-02606-2
PG 10
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA EV7NC
UT WOS:000401962500031
PM 28546534
OA Green Published, gold, Green Accepted
DA 2023-04-20
ER

PT J
AU Loftus, TJ
   Brakenridge, SC
   Croft, CA
   Smith, RS
   Efron, PA
   Moore, FA
   Mohr, AM
   Jordan, JR
AF Loftus, Tyler J.
   Brakenridge, Scott C.
   Croft, Chasen A.
   Smith, Robert Stephen
   Efron, Philip A.
   Moore, Frederick A.
   Mohr, Alicia M.
   Jordan, Janeen R.
TI Neural network prediction of severe lower intestinal bleeding and the
   need for surgical intervention
SO JOURNAL OF SURGICAL RESEARCH
LA English
DT Article
DE Gastrointestinal bleeding; Severe bleeding; Surgery; Transfusion;
   Strate; Neural network
ID LOWER-GASTROINTESTINAL HEMORRHAGE; VALIDATION; OUTCOMES
AB Background: The prognosis for patients with severe acute lower intestinal bleeding (ALIB) may be assessed by complex artificial neural networks (ANNs) or user-friendly regression-based models. Comparisons between these modalities are limited, and predicting the need for surgical intervention remains elusive. We hypothesized that ANNs would outperform the Strate rule to predict severe bleeding and would also predict the need for surgical intervention.
   Methods: We performed a 4-y retrospective analysis of 147 adult patients who underwent endoscopy, angiography, or surgery for ALIB. Baseline characteristics, Strate risk factors, management parameters, and outcomes were analyzed. The primary outcomes were severe bleeding and surgical intervention. ANNs were created in SPSS. Models were compared by area under the receiver operating characteristic curve (AUROC) with 95% confidence intervals.
   Results: The number of Strate risk factors for each patient correlated significantly with the outcome of severe bleeding (r = 0.29, P < 0.001). However, the Strate model was less accurate than an ANN (AUROC 0.66 [0.57-0.75] versus 0.98 [0.95-1.00], respectively) which incorporated six variables present on admission: hemoglobin, systolic blood pressure, outpatient prescription for Aspirin 325 mg daily, Charlson comorbidity index, base deficit >= 5 mEq/L, and international normalized ratio >= 1.5. A similar ANN including hemoglobin nadir and the occurrence of a 20% decrease in hematocrit was effective in predicting the need for surgery (AUROC 0.95 [0.90-1.00]).
   Conclusions: The Strate prediction rule effectively stratified risk for severe ALIB, but was less accurate than an ANN. A separate ANN accurately predicted the need for surgery by combining risk factors for severe bleeding with parameters quantifying blood loss. Optimal prognostication may be achieved by integrating pragmatic regression-based calculators for quick decisions at the bedside and highly accurate ANNs when time and resources permit. Published by Elsevier Inc.
C1 [Loftus, Tyler J.; Brakenridge, Scott C.; Croft, Chasen A.; Smith, Robert Stephen; Efron, Philip A.; Moore, Frederick A.; Mohr, Alicia M.; Jordan, Janeen R.] Univ Florida Hlth, Dept Surg, 1600 SW Archer Rd Room M-602, Gainesville, FL 32610 USA.
   [Loftus, Tyler J.; Brakenridge, Scott C.; Efron, Philip A.; Moore, Frederick A.; Mohr, Alicia M.] Univ Florida Hlth, Dept Sepsis & Crit Illness Res Ctr Gainesville, Gainesville, FL USA.
C3 State University System of Florida; University of Florida; State
   University System of Florida; University of Florida
RP Jordan, JR (通讯作者)，Univ Florida Hlth, Dept Surg, 1600 SW Archer Rd Room M-602, Gainesville, FL 32610 USA.
EM Janeen.Jordan@surgery.ufl.edu
RI Loftus, Tyler/J-7761-2016; Brakenridge, Scott/AAD-6691-2019
OI Loftus, Tyler/0000-0001-5354-443X; Brakenridge,
   Scott/0000-0002-7327-3718; Mohr, Alicia/0000-0003-1732-1313; Smith,
   Robert/0000-0002-0455-6415
FU National Institute of General Medical Sciences (NIGMS) [R01
   GM105893-01A1, R01 GM113945-01, P50 GM111152e01]; postgraduate training
   grant [T32 GM-08721]; National Institute of General Medical Sciences;
   National Center for Advancing Translational Sciences [UL1TR001427]
FX This work has never been published elsewhere and is not under
   consideration at any other journals. The authors were supported in part
   by R01 GM105893-01A1 (A.M.M.), R01 GM113945-01 (P.A.E.), and P50
   GM111152e01 (S.C.B., F.A.M., A.M.M., P.A.E.) awarded by the National
   Institute of General Medical Sciences (NIGMS). T.J.L. was supported by a
   postgraduate training grant (T32 GM-08721) in burns, trauma and
   perioperative injury by National Institute of General Medical Sciences.
   Research reported in this publication was supported by the National
   Center for Advancing Translational Sciences under Award Number
   UL1TR001427. The content is solely the responsibility of the authors and
   does not necessarily represent the official views of the National
   Institutes of Health.
CR Ayaru L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132485
   Baharifar H, 2016, NANOMED-NANOTECHNOL, V12, P171, DOI 10.1016/j.nano.2015.09.002
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   Belliveau T, 2016, ARCH PHYS MED REHAB, V97, P1663, DOI 10.1016/j.apmr.2016.04.014
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Das A, 2007, EUR J GASTROEN HEPAT, V19, P1064, DOI 10.1097/MEG.0b013e3282f198f7
   Farrell AJ, 2001, GASTROENTEROL CLIN N, V30, P377, DOI 10.1016/S0889-8553(05)70187-4
   Kollef MH, 1997, CRIT CARE MED, V25, P1125, DOI 10.1097/00003246-199707000-00011
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J, 2009, SCAND J SURG, V98, P135, DOI 10.1177/145749690909800302
   Marion Y, 2014, J VISC SURG, V151, P191, DOI 10.1016/j.jviscsurg.2014.03.008
   MCGUIRE HH, 1994, ANN SURG, V220, P653, DOI 10.1097/00000658-199411000-00008
   Morris AH, 2000, ANN INTERN MED, V132, P373, DOI 10.7326/0003-4819-132-5-200003070-00007
   Sheikhtaheri A, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0110-5
   Siriyasatien P, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1034-5
   Soriano MC, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00068
   Strate LL, 2008, CLIN GASTROENTEROL H, V6, P1004, DOI 10.1016/j.cgh.2008.03.021
   Strate LL, 2005, AM J GASTROENTEROL, V100, P1821, DOI 10.1111/j.1572-0241.2005.41755.x
   Velayos FS, 2004, CLIN GASTROENTEROL H, V2, P485, DOI 10.1016/S1542-3565(04)00167-3
   Vernava AM, 1997, DIS COLON RECTUM, V40, P846, DOI 10.1007/BF02055445
   World Health Organization, 1968, WHO TECH REP SER, V405, P5
NR 21
TC 17
Z9 18
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0022-4804
EI 1095-8673
J9 J SURG RES
JI J. Surg. Res.
PD MAY 15
PY 2017
VL 212
BP 42
EP 47
DI 10.1016/j.jss.2016.12.032
PG 6
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA FA3RS
UT WOS:000405362700006
PM 28550920
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Sengupta, N
   Tapper, EB
AF Sengupta, Neil
   Tapper, Elliot B.
TI Derivation and Internal Validation of a Clinical Prediction Tool for
   30-Day Mortality in Lower Gastrointestinal Bleeding
SO AMERICAN JOURNAL OF MEDICINE
LA English
DT Article
DE Lower gastrointestinal bleeding; Mortality
ID RESOURCE UTILIZATION; ADVERSE OUTCOMES; SCORING SYSTEMS; RISK-FACTORS;
   HEMORRHAGE; COLONOSCOPY; TRIAL; INTERVENTION; EPIDEMIOLOGY; MANAGEMENT
AB BACKGROUND: There are limited data to predict which patients with lower gastrointestinal bleeding are at risk for adverse outcomes. We aimed to develop a clinical tool based on admission variables to predict 30-day mortality in lower gastrointestinal bleeding.
   METHODS: We used a validated machine learning algorithm to identify adult patients hospitalized with lower gastrointestinal bleeding at an academic medical center between 2008 and 2015. The cohort was split randomly into derivation and validation cohorts. In the derivation cohort, we used multiple logistic regression on all candidate admission variables to create a prediction model for 30-day mortality, using area under the receiving operator characteristic curve and misclassification rate to estimate prediction accuracy. Regression coefficients were used to derive an integer score, and mortality risk associated with point totals was assessed.
   RESULTS: In the derivation cohort (n = 4044), 8 variables were most associated with 30-day mortality: age, dementia, metastatic cancer, chronic kidney disease, chronic pulmonary disease, anticoagulant use, admission hematocrit, and albumin. The model yielded a misclassification rate of 0.06 and area under the curve of 0.81. The integer score ranged from -10 to 26 in the derivation cohort, with a misclassification rate of 0.11 and area under the curve of 0.74. In the validation cohort (n = 2060), the score had an area under the curve of 0.72 with a misclassification rate of 0.12. After dividing the score into 4 quartiles of risk, 30-day mortality in the derivation and validation sets was 3.6% and 4.4% in quartile 1, 4.9% and 7.3% in quartile 2, 9.9% and 9.1% in quartile 3, and 24% and 26% in quartile 4, respectively.
   CONCLUSIONS: A clinical tool can be used to predict 30-day mortality in patients hospitalized with lower gastrointestinal bleeding. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Sengupta, Neil] Univ Chicago, Med Ctr, Dept Med, Sect Gastroenterol Hepatol & Nutr, 5841 S Maryland Ave,MC 4076, Chicago, IL 60637 USA.
   [Tapper, Elliot B.] Univ Michigan Hlth Syst, Dept Internal Med, Div Gastroenterol, Ann Arbor, MI USA.
C3 University of Chicago; University of Chicago Medical Center; University
   of Michigan System; University of Michigan
RP Sengupta, N (通讯作者)，Univ Chicago, Med Ctr, Dept Med, Sect Gastroenterol Hepatol & Nutr, 5841 S Maryland Ave,MC 4076, Chicago, IL 60637 USA.
EM nsengupta@medicine.bsd.uchicago.edu
CR Aoki T, 2016, CLIN GASTROENTEROL H, V14, P1562, DOI 10.1016/j.cgh.2016.05.042
   Comay D, 2002, CAN J GASTROENTEROL, V16, P677, DOI 10.1155/2002/156592
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Green BT, 2005, AM J GASTROENTEROL, V100, P2395, DOI 10.1111/j.1572-0241.2005.00306.x
   Kazi DS, 2015, J AM COLL CARDIOL, V65, P1411, DOI 10.1016/j.jacc.2015.01.047
   Kollef MH, 1997, CRIT CARE MED, V25, P1125, DOI 10.1097/00003246-199707000-00011
   Laine L, 2016, NEW ENGL J MED, V374, P2367, DOI 10.1056/NEJMcp1514257
   Laine L, 2010, AM J GASTROENTEROL, V105, P2636, DOI 10.1038/ajg.2010.277
   Lanas A, 2009, AM J GASTROENTEROL, V104, P1633, DOI 10.1038/ajg.2009.164
   Longstreth GF, 1997, AM J GASTROENTEROL, V92, P419
   Nagata N, 2016, CLIN GASTROENTEROL H, V14, P558, DOI 10.1016/j.cgh.2015.10.011
   Nagata N, 2014, GASTROINTEST ENDOSC, V80, P1124, DOI 10.1016/j.gie.2014.06.039
   Newman J, 2012, COLORECTAL DIS, V14, P1020, DOI 10.1111/j.1463-1318.2011.02824.x
   Nikolsky E, 2009, J AM COLL CARDIOL, V54, P1293, DOI 10.1016/j.jacc.2009.07.019
   Qureshi W, 2014, AM J CARDIOL, V113, P662, DOI 10.1016/j.amjcard.2013.10.044
   Robertson M, 2016, GASTROINTEST ENDOSC, V83, P1151, DOI 10.1016/j.gie.2015.10.021
   Sengupta N, 2015, AM J GASTROENTEROL, V110, P328, DOI 10.1038/ajg.2014.398
   Sengupta N, 2015, MAYO CLIN PROC, V90, P1021, DOI 10.1016/j.mayocp.2015.04.024
   Siddique J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138987
   Staerk L, 2015, BMJ-BRIT MED J, V351, DOI 10.1136/bmj.h5876
   Stanley AJ, 2012, WORLD J GASTROENTERO, V18, P2739, DOI 10.3748/wjg.v18.i22.2739
   Strate LL, 2008, CLIN GASTROENTEROL H, V6, P1004, DOI 10.1016/j.cgh.2008.03.021
   Strate LL, 2016, AM J GASTROENTEROL, V111, P755, DOI 10.1038/ajg.2016.155
   Strate LL, 2005, GASTROENTEROL CLIN N, V34, P643, DOI 10.1016/j.gtc.2005.08.007
   Strate LL, 2005, AM J GASTROENTEROL, V100, P1821, DOI 10.1111/j.1572-0241.2005.41755.x
   Strate LL, 2003, ARCH INTERN MED, V163, P838, DOI 10.1001/archinte.163.7.838
   Sullivan LM, 2004, STAT MED, V23, P1631, DOI 10.1002/sim.1742
   Velayos FS, 2004, CLIN GASTROENTEROL H, V2, P485, DOI 10.1016/S1542-3565(04)00167-3
   Whelan CT, 2010, J HOSP MED, V5, P141, DOI 10.1002/jhm.606
   Witt DM, 2012, ARCH INTERN MED, V172, P1484, DOI 10.1001/archinternmed.2012.4261
NR 30
TC 33
Z9 33
U1 0
U2 3
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0002-9343
EI 1555-7162
J9 AM J MED
JI Am. J. Med.
PD MAY
PY 2017
VL 130
IS 5
AR 601.e1
DI 10.1016/j.amjmed.2016.12.009
PG 8
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA EV7ZZ
UT WOS:000402001400046
PM 28065767
OA Bronze
DA 2023-04-20
ER

PT J
AU Wang, S
   Cong, Y
   Fan, HJ
   Fan, BJ
   Liu, LQ
   Yang, YS
   Tang, YD
   Zhao, H
   Yu, H
AF Wang, Shuai
   Cong, Yang
   Fan, Huijie
   Fan, Baojie
   Liu, Lianqing
   Yang, Yunsheng
   Tang, Yandong
   Zhao, Huaici
   Yu, Haibin
TI Multi-Class Latent Concept Pooling for Computer-Aided Endoscopy
   Diagnosis
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Computer-aided diagnosis; multi-class; sparse dictionary learning;
   latent concept pooling; endoscopy
ID IMAGE CLASSIFICATION; DESCRIPTORS; FEATURES; RECOGNITION
AB Successful computer-aided diagnosis systems typically rely on training datasets containing sufficient and richly annotated images. However, detailed image annotation is often time consuming and subjective, especially for medical images, which becomes the bottleneck for the collection of large datasets and then building computer-aided diagnosis systems. In this article, we design a novel computer-aided endoscopy diagnosis system to deal with the multi-classification problem of electronic endoscopy medical records (EEMRs) containing sets of frames, while labels of EEMRs can be mined from the corresponding text records using an automatic text-matching strategy without human special labeling. With unambiguous EEMR labels and ambiguous frame labels, we propose a simple but effective pooling scheme called Multi-class Latent Concept Pooling, which learns a codebook from EEMRs with different classes step by step and encodes EEMRs based on a soft weighting strategy. In our method, a computer-aided diagnosis system can be extended to new unseen classes with ease and applied to the standard single-instance classification problem even though detailed annotated images are unavailable. In order to validate our system, we collect 1,889 EEMRs with more than 59K frames and successfully mine labels for 348 of them. The experimental results show that our proposed system significantly outperforms the state-of-the-art methods. Moreover, we apply the learned latent concept codebook to detect the abnormalities in endoscopy images and compare it with a supervised learning classifier, and the evaluation shows that our codebook learning method can effectively extract the true prototypes related to different classes from the ambiguous data.
C1 [Wang, Shuai; Cong, Yang; Fan, Huijie; Liu, Lianqing; Tang, Yandong; Zhao, Huaici; Yu, Haibin] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang, Peoples R China.
   [Wang, Shuai] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Fan, Baojie] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210003, Jiangsu, Peoples R China.
   [Yang, Yunsheng] Chinese Peoples Liberat Army Gen Hosp, Beijing 100853, Peoples R China.
   [Wang, Shuai; Cong, Yang; Fan, Huijie; Liu, Lianqing; Tang, Yandong; Zhao, Huaici; Yu, Haibin] Chinese Acad Sci, Shenyang Inst Automat, Shenyang 110016, Peoples R China.
C3 Chinese Academy of Sciences; Shenyang Institute of Automation, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Nanjing University of Posts & Telecommunications; Chinese People's
   Liberation Army General Hospital; Chinese Academy of Sciences; Shenyang
   Institute of Automation, CAS
RP Cong, Y (通讯作者)，Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang, Peoples R China.; Cong, Y (通讯作者)，Chinese Acad Sci, Shenyang Inst Automat, Shenyang 110016, Peoples R China.
EM shuaiwang@sia.cn; congyang81@gmail.com; fanhuijie@sia.cn;
   jobfbj@gmail.com; lianqingliu@sia.cn; sunny301ddc@126.com; ytang@sia.cn;
   hczhao@sia.cn; yhb@sia.cn
OI Wang, Shuai/0000-0003-3730-6401
FU NSFC [61375014, 61533015, U1613214, 61333019, 61401455]
FX This work was supported by NSFC (61375014, 61533015, U1613214, 61333019,
   and 61401455).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146
   Baker ZK, 2005, IEEE T VLSI SYST, V13, P1179, DOI 10.1109/TVLSI.2005.859472
   Bashar MK, 2008, LECT NOTES COMPUT SC, V5242, P603, DOI 10.1007/978-3-540-85990-1_72
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Buchner AM, 2010, GASTROENTEROLOGY, V138, P834, DOI 10.1053/j.gastro.2009.10.053
   Chu XQ, 2010, LECT NOTES COMPUT SC, V6362, P522
   Codella N, 2014, LECT NOTES COMPUT SC, V8674, P487, DOI 10.1007/978-3-319-10470-6_61
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   He H., 2015, IEEE T INTELL TRANSP, V16, P1
   He HS, 2016, IEEE J BIOMED HEALTH, V20, P848, DOI 10.1109/JBHI.2015.2419251
   Huang CR, 2008, IEEE T INF TECHNOL B, V12, P523, DOI 10.1109/TITB.2007.913128
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Lee Honglak, 2007, NIPS, P801
   Li BP, 2015, MED PHYS, V42, P645, DOI 10.1118/1.4905164
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mehmood I., 2014, J MED SYST, V38, P1
   Mozafari AS, 2016, PATTERN RECOGN, V56, P142, DOI 10.1016/j.patcog.2016.03.009
   Muto M, 2011, J GASTROENTEROL, V46, P998, DOI 10.1007/s00535-011-0419-5
   Pasolli E, 2014, IEEE T GEOSCI REMOTE, V52, P2217, DOI 10.1109/TGRS.2013.2258676
   Perronnin F., 2010, ECCV, P119
   Riaz F., 2015, LEUKEMIA, V27, pe90
   Riaz F, 2012, IEEE T BIO-MED ENG, V59, P2893, DOI 10.1109/TBME.2012.2212440
   Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shahidi R, 2002, IEEE T MED IMAGING, V21, P1524, DOI 10.1109/TMI.2002.806597
   Shao ZZ, 2014, IEEE INT CONF ROBOT, P1290, DOI 10.1109/ICRA.2014.6907019
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Shenghua Gao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2809, DOI 10.1109/CVPR.2011.5995454
   Wang S, 2016, IEEE T BIO-MED ENG, V63, P2347, DOI 10.1109/TBME.2016.2530141
   Wu CH, 2007, IEEE T BIO-MED ENG, V54, P1199, DOI 10.1109/TBME.2006.889767
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yang JC, 2010, LECT NOTES COMPUT SC, V6315, P113, DOI 10.1007/978-3-642-15555-0_9
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yu XY, 2015, IEEE T CYBERNETICS, V45, P444, DOI 10.1109/TCYB.2014.2327246
   Yuan Y., 2015, IEEE T NEUR NET LEAR, V34, P1
   Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484
NR 52
TC 1
Z9 1
U1 0
U2 8
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD MAY
PY 2017
VL 13
IS 2
AR 15
DI 10.1145/3051481
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EV1VK
UT WOS:000401537300003
DA 2023-04-20
ER

PT J
AU Yuan, YX
   Meng, MQH
AF Yuan, Yixuan
   Meng, Max Q. -H.
TI Deep learning for polyp recognition in wireless capsule endoscopy images
SO MEDICAL PHYSICS
LA English
DT Article
DE image manifold information; polyp recognition; stacked sparse
   autoencoder with image manifold (SSAEIM); wireless capsule endoscopy
   images
AB Purpose: Wireless capsule endoscopy (WCE) enables physicians to examine the digestive tract without any surgical operations, at the cost of a large volume of images to be analyzed. In the computer-aided diagnosis of WCE images, the main challenge arises from the difficulty of robust characterization of images. This study aims to provide discriminative description of WCE images and assist physicians to recognize polyp images automatically.
   Methods: We propose a novel deep feature learning method, named stacked sparse autoencoder with image manifold constraint (SSAEIM), to recognize polyps in the WCE images. Our SSAEIM differs from the traditional sparse autoencoder (SAE) by introducing an image manifold constraint, which is constructed by a nearest neighbor graph and represents intrinsic structures of images. The image manifold constraint enforces that images within the same category share similar learned features and images in different categories should be kept far away. Thus, the learned features preserve large intervariances and small intravariances among images.
   Results: The average overall recognition accuracy (ORA) of our method for WCE images is 98.00%. The accuracies for polyps, bubbles, turbid images, and clear images are 98.00%, 99.50%, 99.00%, and 95.50%, respectively. Moreover, the comparison results show that our SSAEIM outperforms existing polyp recognition methods with relative higher ORA.
   Conclusion: The comprehensive results have demonstrated that the proposed SSAEIM can provide descriptive characterization for WCE images and recognize polyps in a WCE video accurately. This method could be further utilized in the clinical trials to help physicians from the tedious image reading work. (C) 2017 American Association of Physicists in Medicine
C1 [Yuan, Yixuan; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Yuan, YX (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM yxyuan@ee.cuhk.edu.hk
RI Meng, Max Q.-H./C-8078-2009; meng, meng/GWZ-7461-2022; Meng,
   Q./GSI-6185-2022
OI Yuan, Yixuan/0000-0002-0853-6948
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Anthimopoulos MM, 2014, IEEE J BIOMED HEALTH, V18, P1261, DOI 10.1109/JBHI.2014.2308928
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Barbosa DC, 2012, BIOMED ENG ONLINE, V11, DOI 10.1186/1475-925X-11-3
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   El Khatib A, 2015, IEEE ENG MED BIO, P2669, DOI 10.1109/EMBC.2015.7318941
   Gueye L, 2015, IEEE IMAGE PROC, P1061, DOI 10.1109/ICIP.2015.7350962
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hosseini-Asl E, 2016, IEEE T NEUR NET LEAR, V27, P2486, DOI 10.1109/TNNLS.2015.2479223
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Karargyris A, 2012, INT J ARTIF INTELL T, V21, DOI 10.1142/S0218213012400210
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee NM, 2010, EXPERT REV GASTROENT, V4, P503, DOI 10.1586/EGH.10.44
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Li C, 2014, NEUROCOMPUTING, V123, P398, DOI 10.1016/j.neucom.2013.08.002
   Ma L, 2015, IEEE T GEOSCI REMOTE, V53, P2832, DOI 10.1109/TGRS.2014.2365676
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sae Hwang, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P320, DOI 10.1007/978-3-642-24031-7_32
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Silva J, 2013, IEEE ENG MED BIO, P5711, DOI 10.1109/EMBC.2013.6610847
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wilson DR, 2003, NEURAL NETWORKS, V16, P1429, DOI 10.1016/S0893-6080(03)00138-2
   Wu SS, 2014, IEEE IMAGE PROC, P1897, DOI 10.1109/ICIP.2014.7025380
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
   Zhao Q, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P948, DOI 10.1109/WCICA.2011.5970656
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 41
TC 100
Z9 114
U1 2
U2 25
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD APR
PY 2017
VL 44
IS 4
BP 1379
EP 1389
DI 10.1002/mp.12147
PG 11
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA ET8SZ
UT WOS:000400572700017
PM 28160514
DA 2023-04-20
ER

PT J
AU Chen, HH
   Wu, X
   Tao, G
   Peng, Q
AF Chen, Honghan
   Wu, Xiao
   Tao, Gan
   Peng, Qiang
TI Automatic content understanding with cascaded spatial-temporal deep
   framework for capsule endoscopy videos
SO NEUROCOMPUTING
LA English
DT Article
DE Wireless capsule endoscopy; Convolutional neural network; Topographic
   segmentation; Content understanding; Hidden Markov model
ID SEGMENTATION; FEATURES; TEXTURE
AB Capsule endoscopy (CE) is the first-line diagnostic tool for inspecting gastrointestinal (GI) tract diseases. It is a tremendous task on examining and managing the CE videos by endoscopists. Therefore, a computer-aided diagnosis system is desired and urgent. In this paper, a general cascaded spatial temporal deep framework is proposed to understand the most commonly seen contents of whole GI tract videos. First, the noisy contents such as feces, bile, bubble, and low power images are detected and removed by a Convolutional Neural Network (CNN) model. The clear images are then classified into entrance, stomach, small intestine, and colon by the second CNN. Finally, the topographic segmentation of the whole video is performed with a global temporal integration strategy by Hidden Markov Model (HMM). Compared to existing methods, the proposed framework performs noise content detection and topographic segmentation at the same time, which significantly reduces the number of images to be checked by endoscopists and segments images of different organs more accurately. Experiments on a dataset with 630K images from 14 patients demonstrate that the proposed approach achieves a promising performance in terms of effectiveness and efficiency.
C1 [Chen, Honghan; Wu, Xiao; Peng, Qiang] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Peoples R China.
   [Tao, Gan] Sichuan Univ, West China Hosp, Endoscopy Ctr, Chengdu, Peoples R China.
C3 Southwest Jiaotong University; Sichuan University
RP Wu, X (通讯作者)，Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Peoples R China.
EM honghanchen@hotmail.com; wuxiaohk@home.swjtu.edu.cn; gantao-1@163.com;
   qpeng@home.swjtu.edu.cn
OI Wu, Xiao/0000-0002-8322-8558
FU National Natural Science Foundation of China [61373121, 61036008,
   61272290]; Program for Sichuan Provincial Science Fund for Distinguished
   Young Scholars [13QNJJ0149]; Program for Sichuan Provincial Key
   Technology Research and Development [2012FZ0004]; NVIDIA Corporation
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos. 61373121, 61036008 and 61272290), Program for
   Sichuan Provincial Science Fund for Distinguished Young Scholars (No.
   13QNJJ0149), and Program for Sichuan Provincial Key Technology Research
   and Development (No. 2012FZ0004). We would like to thank the editors and
   reviewers for their valuable comments to improve the quality of this
   paper. We also gratefully acknowledge the support of NVIDIA Corporation
   with the donation of the K40 GPU used for this research.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bastan M, 2010, IEEE MULTIMEDIA, V17, P62, DOI 10.1109/MMUL.2010.5692184
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Chawla NV, 2003, LECT NOTES ARTIF INT, V2838, P107, DOI 10.1007/978-3-540-39804-2_12
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fergus R., 2015, 2 BAG OF WORDS CLASS
   Fireman Z, 2010, WORLD J GASTRO ENDOS, V2, P305, DOI 10.4253/wjge.v2.i9.305
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Guo YR, 2016, IEEE T MED IMAGING, V35, P1077, DOI 10.1109/TMI.2015.2508280
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia Y., 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Kevin M., 2015, HIDDEN MARKOV MODEL
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Seshamani S, 2011, IEEE T MED IMAGING, V30, P1468, DOI 10.1109/TMI.2011.2119326
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Shi J, 2016, NEUROCOMPUTING, V194, P87, DOI 10.1016/j.neucom.2016.01.074
   Simonyan K, 2015, Arxiv
   Suk HI, 2015, LECT NOTES COMPUT SC, V9349, P573, DOI 10.1007/978-3-319-24553-9_70
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao Q, 2015, COMPUT MED IMAG GRAP, V41, P108, DOI 10.1016/j.compmedimag.2014.05.011
NR 47
TC 22
Z9 24
U1 1
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD MAR 15
PY 2017
VL 229
SI SI
BP 77
EP 87
DI 10.1016/j.neucom.2016.06.077
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EK1YZ
UT WOS:000393725000009
DA 2023-04-20
ER

PT J
AU Zhou, SB
   Yang, H
   Siddique, MA
   Xu, J
   Zhou, P
AF Zhou, Shangbo
   Yang, Han
   Siddique, Muhammad Abubakar
   Xu, Jie
   Zhou, Ping
TI A novel method for automatically locating the pylorus in the wireless
   capsule endoscopy
SO BIOMEDICAL ENGINEERING-BIOMEDIZINISCHE TECHNIK
LA English
DT Article
DE capsule endoscopy; pylorus location; short-term color change; Weber
   local descriptor (WLD)
AB Wireless capsule endoscopy (WCE) is a non-invasive technique used to examine the interiors of digestive tracts. Generally, the digestive tract can be divided into four segments: the entrance; stomach; small intestine; and large intestine. The stomach and the small intestine have a higher risk of infections than the other segments. In order to locate the diseased organ, an appropriate classification of the WCE images is necessary. In this article, a novel method is proposed for automatically locating the pylorus in WCE. The location of the pylorus is determined on two levels: rough-level and refined-level. In the roughlevel, a short-term color change at the boundary between stomach and intestine can help us to find approximately 70-150 positions. In the refined-level, an improved Weber local descriptor (WLD) feature extraction method is designed for gray-scale images. Compared to the original WLD calculation method, the method for calculating the differential excitation is improved to give a higher level of robustness. A K-nearest neighbor (KNN) classifier is incorporated to segment these images around the approximate position into different regions. The proposed algorithm locates three most probable positions of the pylorus that were marked by the clinician. The experimental results indicate that the proposed method is effective.
C1 [Zhou, Shangbo; Yang, Han] Chongqing Univ, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400030, Peoples R China.
   [Zhou, Shangbo; Yang, Han] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
   [Siddique, Muhammad Abubakar] COMSATS Inst Informat Technol, Dept Comp Sci, Vehari, Pakistan.
   [Xu, Jie; Zhou, Ping] Chongqing Jinshan Sci & Technol Co Ltd, Chongqing 401120, Peoples R China.
C3 Chongqing University; Chongqing University; COMSATS University Islamabad
   (CUI)
RP Zhou, SB (通讯作者)，Chongqing Univ, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400030, Peoples R China.; Zhou, SB (通讯作者)，Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
EM shbzhou@cqu.edu.cn
RI Siddique, Muhammad Abubakar/AAO-9279-2021
OI Siddique, Muhammad Abubakar/0000-0001-9721-3034
FU Fundamental Research Funds for the Central Universities
   [106112014CDJZR188801]; Frontier and Application Foundation Research
   Program of CQ CSTC [cstc2014jcyjA40037]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities No. 106112014CDJZR188801, and Frontier and
   Application Foundation Research Program of CQ CSTC (No.
   cstc2014jcyjA40037).
CR Baopu Li, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P373, DOI 10.1109/ICINFA.2011.5949020
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   Berens J, 2004, ENDOSCOPY S1, V36, pA76
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   Haji-Maghsoudi Omid, 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P116, DOI 10.1109/AISP.2012.6313729
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Igual L, 2009, IFMBE PROC, V22, P1536
   Jain A, 1989, FUNDAMENTALS DIGITAL
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Lin O., 2005, P 4 INT C CAPS END M
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma T, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P582, DOI 10.1109/ChinaSIP.2014.6889310
   Mackiewicz M, 2006, AC SPEECH SIGN PROC, V2, pII
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Maieron A, 2004, ENDOSCOPY, V36, P864, DOI 10.1055/s-2004-825852
   Ran Zhou, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P825, DOI 10.1109/ROBIO.2012.6491070
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Suh S. C., 2012, PRACTICAL APPL DATA
   Zhou R, 2013, IEEE INT C INT ROBOT, P3096, DOI 10.1109/IROS.2013.6696795
NR 21
TC 5
Z9 5
U1 1
U2 12
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 0013-5585
EI 1862-278X
J9 BIOMED ENG-BIOMED TE
JI Biomed. Eng.-Biomed. Tech.
PD FEB
PY 2017
VL 62
IS 1
BP 1
EP 12
DI 10.1515/bmt-2015-0080
PG 12
WC Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Medical Informatics
GA EP2LA
UT WOS:000397213400001
PM 27107827
DA 2023-04-20
ER

PT J
AU Komeda, Y
   Handa, H
   Watanabe, T
   Nomura, T
   Kitahashi, M
   Sakurai, T
   Okamoto, A
   Minami, T
   Kono, M
   Arizumi, T
   Takenaka, M
   Hagiwara, S
   Matsui, S
   Nishida, N
   Kashida, H
   Kudo, M
AF Komeda, Yoriaki
   Handa, Hisashi
   Watanabe, Tomohiro
   Nomura, Takanobu
   Kitahashi, Misaki
   Sakurai, Toshiharu
   Okamoto, Ayana
   Minami, Tomohiro
   Kono, Masashi
   Arizumi, Tadaaki
   Takenaka, Mamoru
   Hagiwara, Satoru
   Matsui, Shigenaga
   Nishida, Naoshi
   Kashida, Hiroshi
   Kudo, Masatoshi
TI Computer-Aided Diagnosis Based on Convolutional Neural Network System
   for Colorectal Polyp Classification: Preliminary Experience
SO ONCOLOGY
LA English
DT Article; Proceedings Paper
CT 1st Kindai International Symposium on Gastrointestinal Cancer (KISGIC)
CY JUL 08, 2017
CL Osaka, JAPAN
DE Computer-aided diagnosis; Convolutional neural network; Artificial
   intelligence; Colon polyp classification; Deep learning
ID LESIONS; HISTOLOGY; CANCER; PREVENTION; PATTERNS
AB Background and Aim: Computer-aided diagnosis (CAD) is becoming a next-generation tool for the diagnosis of human disease. CAD for colon polyps has been suggested as a particularly useful tool for trainee colonoscopists, as the use of a CAD system avoids the complications associated with endoscopic resections. In addition to conventional CAD, a convolutional neural network (CNN) system utilizing artificial intelligence (AI) has been developing rapidly over the past 5 years. We attempted to generate a unique CNN-CAD system with an AI function that studied endoscopic images extracted from movies obtained with colonoscopes used in routine examinations. Here, we report our preliminary results of this novel CNN-CAD system for the diagnosis of colon polyps. Methods: A total of 1,200 images from cases of colonoscopy performed between January 2010 and December 2016 at Kindai University Hospital were used. These images were extracted from the video of actual endoscopic examinations. Additional video images from 10 cases of unlearned processes were retrospectively assessed in a pilot study. They were simply diagnosed as either an adenomatous or nonadenomatous polyp. Results: The number of images used by AI to learn to distinguish adenomatous from nonadenomatous was 1,200: 600. These images were extracted from the videos of actual endoscopic examinations. The size of each image was adjusted to 256 x 256 pixels. A 10-hold cross-validation was carried out. The accuracy of the 10-hold cross-validation is 0.751, where the accuracy is the ratio of the number of correct answers over the number of all the answers produced by the CNN. The decisions by the CNN were correct in 7 of 10 cases. Conclusion: A CNN-CAD system using routine colonoscopy might be useful for the rapid diagnosis of colorectal polyp classification. Further prospective studies in an in vivo setting are required to confirm the effectiveness of a CNN-CAD system in routine colonoscopy. (C) 2017 S. Karger AG, Basel
C1 [Komeda, Yoriaki; Watanabe, Tomohiro; Sakurai, Toshiharu; Okamoto, Ayana; Minami, Tomohiro; Kono, Masashi; Arizumi, Tadaaki; Takenaka, Mamoru; Hagiwara, Satoru; Matsui, Shigenaga; Nishida, Naoshi; Kashida, Hiroshi; Kudo, Masatoshi] Kindai Univ, Fac Med, Dept Gastroenterol & Hepatol, 377-2 Ohno Higashi, Osakasayama, Osaka 5898511, Japan.
   [Handa, Hisashi] Kindai Univ, Fac Sci & Engn, Osakasayama, Japan.
   [Nomura, Takanobu; Kitahashi, Misaki] Kindai Univ, Grad Sch Sci & Engn Res, Osakasayama, Japan.
RP Komeda, Y (通讯作者)，Kindai Univ, Fac Med, Dept Gastroenterol & Hepatol, 377-2 Ohno Higashi, Osakasayama, Osaka 5898511, Japan.
EM y-komme@mvb.biglobe.ne.jp
RI Watanabe, Tomohiro/ABA-4712-2021; Komeda, Yoriaki/AAF-6652-2020; Kudo,
   Masatoshi/AAA-9744-2019
OI Kudo, Masatoshi/0000-0002-4102-3474; Kashida,
   Hiroshi/0000-0002-9774-9485
CR Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Philpotts LE, 2009, RADIOLOGY, V253, P17, DOI 10.1148/radiol.2531090689
   Pohl J, 2008, AM J GASTROENTEROL, V103, P562, DOI 10.1111/j.1572-0241.2007.01670.x
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 17
TC 116
Z9 120
U1 1
U2 19
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0030-2414
EI 1423-0232
J9 ONCOLOGY-BASEL
JI Oncology
PY 2017
VL 93
SU 1
BP 30
EP 34
DI 10.1159/000481227
PG 5
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Oncology
GA FQ8VC
UT WOS:000418640300006
PM 29258081
OA Bronze
DA 2023-04-20
ER

PT J
AU Nadeem, S
   Marino, J
   Gu, XF
   Kaufman, A
AF Nadeem, Saad
   Marino, Joseph
   Gu, Xianfeng
   Kaufman, Arie
TI Corresponding Supine and Prone Colon Visualization Using Eigenfunction
   Analysis and Fold Modeling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE VIS Conference
CY OCT 23-28, 2016
CL Baltimore, MD
SP IEEE
DE Medical visualization; colon registration; geometry-based techniques;
   mathematical foundations for visualization
ID REGISTRATION; POLYPS
AB We present a method for registration and visualization of corresponding supine and prone virtual colonoscopy scans based on eigenfunction analysis and fold modeling. In virtual colonoscopy, CT scans are acquired with the patient in two positions, and their registration is desirable so that physicians can corroborate findings between scans. Our algorithm performs this registration efficiently through the use of Fiedler vector representation (the second eigenfunction of the Laplace-Beltrami operator). This representation is employed to first perform global registration of the two colon positions. The registration is then locally refined using the haustral folds, which are automatically segmented using the 3D level sets of the Fiedler vector. The use of Fiedler vectors and the segmented folds presents a precise way of visualizing corresponding regions across datasets and visual modalities. We present multiple methods of visualizing the results, including 2D flattened rendering and the corresponding 3D endoluminal views. The precise fold modeling is used to automatically find a suitable cut for the 2D flattening, which provides a less distorted visualization. Our approach is robust, and we demonstrate its efficiency and efficacy by showing matched views on both the 2D flattened colons and in the 3D endoluminal view. We analytically evaluate the results by measuring the distance between features on the registered colons, and we also assess our fold segmentation against 20 manually labeled datasets. We have compared our results analytically to previous methods, and have found our method to achieve superior results. We also prove the hot spots conjecture for modeling cylindrical topology using Fiedler vector representation, which allows our approach to be used for general cylindrical geometry modeling and feature extraction.
C1 [Nadeem, Saad; Marino, Joseph; Gu, Xianfeng; Kaufman, Arie] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Nadeem, S (通讯作者)，SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM sanadeem@cs.stonybrook.edu; jmarino@cs.stonybrook.edu;
   gu@cs.stonybrook.edu; ari@cs.stonybrook.edu
OI Gu, Xianfeng David/0000-0001-8226-5851
FU NSF [DMS-1418255, CNS-0959979, IIP-1069147, CNS-1302246]; Marcus
   Foundation; Direct For Computer & Info Scie & Enginr; Division Of
   Computer and Network Systems [1302246] Funding Source: National Science
   Foundation
FX The datasets are courtesy of Stony Brook University Hospital (SBUH) and
   Dr. Richard Choi, Walter Reed Army Medical Center. We would like to
   thank Dr. Kevin Baker of SBUH for his help in this project. This work
   has been partially supported by NSF grants DMS-1418255, CNS-0959979,
   IIP-1069147, CNS-1302246, and the Marcus Foundation.
CR Acar B, 2001, P ANN INT IEEE EMBS, V23, P2433, DOI 10.1109/IEMBS.2001.1017269
   Acar B, 2001, RADIOLOGY, V221, P332
   Bartroli AV, 2001, IEEE VISUAL, P411, DOI 10.1109/VISUAL.2001.964540
   Boscaini D, 2015, COMPUT GRAPH FORUM, V34, P265, DOI 10.1111/cgf.12558
   Chowdhury AS, 2010, PATTERN RECOGN LETT, V31, P876, DOI 10.1016/j.patrec.2010.01.012
   Chung MK, 2011, LECT NOTES COMPUT SC, V7009, P225, DOI 10.1007/978-3-642-24319-6_28
   de Vries AH, 2006, BRIT J RADIOL, V79, P740, DOI 10.1259/bjr/55953054
   Gebal K, 2009, COMPUT GRAPH FORUM, V28, P1405, DOI 10.1111/j.1467-8659.2009.01517.x
   Gibson SFF, 1998, LECT NOTES COMPUT SC, V1496, P888, DOI 10.1007/BFb0056277
   Gurijala KC, 2013, IEEE T VIS COMPUT GR, V19, P2848, DOI 10.1109/TVCG.2013.139
   Haker S, 2000, IEEE T VIS COMPUT GR, V6, P181, DOI 10.1109/2945.856998
   Hong W, 2006, IEEE T VIS COMPUT GR, V12, P861, DOI 10.1109/TVCG.2006.112
   Huang A, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P279
   Kovnatsky A, 2013, COMPUT GRAPH FORUM, V32, P439, DOI 10.1111/cgf.12064
   Lai ZQ, 2010, LECT NOTES COMPUT SC, V6361, P332
   Lichan Hong, 1997, Computer Graphics Proceedings, SIGGRAPH 97, P27, DOI 10.1145/258734.258750
   Liu LG, 2008, COMPUT GRAPH FORUM, V27, P1495, DOI 10.1111/j.1467-8659.2008.01290.x
   Liu R, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P298
   Marino J, 2016, IEEE T VIS COMPUT GR, V22, P906, DOI 10.1109/TVCG.2015.2467413
   Marino J, 2011, IEEE T VIS COMPUT GR, V17, P1997, DOI 10.1109/TVCG.2011.182
   Meyer M., 2002, VISUALIZATION MATH, V3, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Nadeem S, 2016, IEEE T VIS COMPUT GR, V99, P1
   Nain D., 2002, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2002. 5th International Conference. Proceedings, Part II (Lecture Notes in Computer Science Vol.2489), P573
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Ping L, 2004, MED PHYS, V31, P2912, DOI 10.1118/1.1796171
   Plishker W., 2008, P MICCAI WORKSH VIRT, P116
   SCHWARTZ EL, 1986, IEEE COMPUT GRAPH, V6, P36, DOI 10.1109/MCG.1986.276630
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Suh JW, 2009, J COMPUT ASSIST TOMO, V33, P902, DOI 10.1097/RCT.0b013e3181a7e2c1
   Umemoto Y, 2008, PROC SPIE, V6916, DOI 10.1117/12.773105
   Wang SJ, 2009, MED PHYS, V36, P5595, DOI 10.1118/1.3259727
   Wang ZG, 2006, IEEE T BIO-MED ENG, V53, P1635, DOI 10.1109/TBME.2006.877793
   Yao JH, 2007, I S BIOMED IMAGING, P900, DOI 10.1109/ISBI.2007.356998
   Zeng W, 2010, IEEE T VIS COMPUT GR, V16, P1348, DOI 10.1109/TVCG.2010.200
   Zhao LX, 2006, IEEE T VIS COMPUT GR, V12, P885, DOI 10.1109/TVCG.2006.158
   Zhu HJ, 2011, LECT N MANAG SCI, V1, P1
   Zhu HB, 2013, IEEE T BIO-MED ENG, V60, P321, DOI 10.1109/TBME.2012.2226242
   Zhuoshi Wei, 2010, Virtual Colonoscopy and Abdominal Imaging. Computational Challenges and Clinical Opportunities. Second International Workshop Held in Conjunction with MICCAI 2010. Revised Selected Papers, P98, DOI 10.1007/978-3-642-25719-3_14
NR 38
TC 11
Z9 12
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2017
VL 23
IS 1
BP 751
EP 760
DI 10.1109/TVCG.2016.2598791
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EM8CA
UT WOS:000395537600078
PM 27875189
OA Green Submitted, Green Accepted
DA 2023-04-20
ER

PT J
AU Vazquez, D
   Bernal, J
   Sanchez, FJ
   Fernandez-Esparrach, G
   Lopez, AM
   Romero, A
   Drozdzal, M
   Courville, A
AF Vazquez, David
   Bernal, Jorge
   Javier Sanchez, F.
   Fernandez-Esparrach, Gloria
   Lopez, Antonio M.
   Romero, Adriana
   Drozdzal, Michal
   Courville, Aaron
TI A Benchmark for Endoluminal Scene Segmentation of Colonoscopy Images
SO JOURNAL OF HEALTHCARE ENGINEERING
LA English
DT Article
ID NETWORKS; VALIDATION; DIAGNOSIS; POLYPS
AB Colorectal cancer (CRC) is the third cause of cancer death worldwide. Currently, the standard approach to reduce CRC-related mortality is to perform regular screening in search for polyps and colonoscopy is the screening tool of choice. The main limitations of this screening procedure are polyp miss rate and the inability to perform visual assessment of polyp malignancy. These drawbacks can be reduced by designing decision support systems (DSS) aiming to help clinicians in the different stages of the procedure by providing endoluminal scene segmentation. Thus, in this paper, we introduce an extended benchmark of colonoscopy image segmentation, with the hope of establishing a new strong benchmark for colonoscopy image analysis research. The proposed dataset consists of 4 relevant classes to inspect the endoluminal scene, targeting different clinical needs. Together with the dataset and taking advantage of advances in semantic segmentation literature, we provide new baselines by training standard fully convolutional networks (FCNs). We perform a comparative study to show that FCNs significantly outperform, without any further postprocessing, prior results in endoluminal scene segmentation, especially with respect to polyp segmentation and localization.
C1 [Vazquez, David; Bernal, Jorge; Javier Sanchez, F.; Lopez, Antonio M.] Univ Autonoma Barcelona, Comp Sci Dept, Comp Vis Ctr, Barcelona, Spain.
   [Vazquez, David; Lopez, Antonio M.; Romero, Adriana; Courville, Aaron] Univ Montreal, Montreal Inst Learning Algorithms, Montreal, PQ, Canada.
   [Fernandez-Esparrach, Gloria] Univ Barcelona, Hosp Clin, IDIBAPS, Endoscopy Unit,Gastroenterol Serv,CIBERHED, Barcelona, Spain.
   [Drozdzal, Michal] Ecole Polytech, Montreal, PQ, Canada.
   [Drozdzal, Michal] Imagia Inc, Montreal, PQ, Canada.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Universite de Montreal; University of Barcelona; Hospital Clinic
   de Barcelona; IDIBAPS; Universite de Montreal; Polytechnique Montreal
RP Vazquez, D (通讯作者)，Univ Autonoma Barcelona, Comp Sci Dept, Comp Vis Ctr, Barcelona, Spain.; Vazquez, D (通讯作者)，Univ Montreal, Montreal Inst Learning Algorithms, Montreal, PQ, Canada.
EM dvazquez@cvc.uab.es
RI Vázquez, David/P-3306-2019; Bernal, Jorge/H-4647-2015; López, Antonio
   M/L-5303-2014
OI Vázquez, David/0000-0002-2845-8158; Bernal, Jorge/0000-0001-8493-9514;
   López, Antonio M/0000-0002-6979-5783;
   Fernandez-Esparrach/0000-0002-3378-3940
FU Imagia Inc.; Spanish government [AC/DC TRA2014-57088-C2-1-R]; iVENDIS
   [DPI2015-65286-R]; SGR [2014-SGR-1506, 2014-SGR-1470, 2014-SGR-135];
   CERCA Programme/Generalitat de Catalunya; TECNIOspring-ACCI grant;
   NVIDIA Corporation; FSEED
FX The authors would like to thank the developers of Theano [37] and Keras
   [38]. The authors acknowledge the support of the following agencies for
   research funding and computing support: Imagia Inc.; Spanish government
   through funded Project AC/DC TRA2014-57088-C2-1-R and iVENDIS
   (DPI2015-65286-R); SGR Projects 2014-SGR-1506, 2014-SGR-1470, and
   2014-SGR-135; CERCA Programme/Generalitat de Catalunya; and
   TECNIOspring-FP7-ACCI grant, FSEED, and NVIDIA Corporation for the
   generous support in the form of different GPU hardware units.
CR Arganda-Carreras I, 2015, FRONT NEUROANAT, V9, DOI 10.3389/fnana.2015.00142
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2014, LECT NOTES COMPUT SC, V8899, P1, DOI 10.1007/978-3-319-13410-9_1
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821
   Bruno M. J., 2003, Gut, V52, piv7, DOI 10.1136/gut.52.suppl_4.iv7
   Cha KH, 2016, MED PHYS, V43, P1882, DOI 10.1118/1.4944498
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Chollet F., 2015, TECH REP
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Eigen D., 2014, PREDICTING DEPTH SUR
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gross S., 2009, INT SOC OPTICS PHOTO
   Havaei M., 2015, BRAIN TUMOR SEGMENTA
   Huang G., 2017, 2017 P IEEE C COMP V, P4700, DOI DOI 10.1109/CVPR.2017.243
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Menze Bjoern H, 2015, IEEE Trans Med Imaging, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nunez JM, 2014, LECT NOTES COMPUT SC, V8899, P22, DOI 10.1007/978-3-319-13410-9_3
   Park S., 2016, SPIE MED IMAGING
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Romero Adriana, 2015, INT C LEARN REPR
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy HK, 2011, GASTROENTEROLOGY, V140, P1863, DOI 10.1053/j.gastro.2011.04.027
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Society A. C, 2016, COLORECTAL CANC
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Styner M., 2008, MIDAS J, V2008, P1, DOI [DOI 10.54294/LMKQVM, 10.54294/lmkqvm]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Theano Development Team, 2016, ABS160502688 ARXIV
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26
NR 38
TC 143
Z9 143
U1 3
U2 12
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2040-2295
EI 2040-2309
J9 J HEALTHC ENG
JI J. Healthc. Eng.
PY 2017
VL 2017
AR 4037190
DI 10.1155/2017/4037190
PG 9
WC Health Care Sciences & Services
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services
GA FD1GJ
UT WOS:000407285100001
PM 29065595
OA Green Published, Green Submitted, gold, Green Accepted
DA 2023-04-20
ER

PT J
AU Yu, LQ
   Chen, H
   Dou, Q
   Qin, J
   Heng, PA
AF Yu, Lequan
   Chen, Hao
   Dou, Qi
   Qin, Jing
   Heng, Pheng Ann
TI Integrating Online and Offline Three-Dimensional Deep Learning for
   Automated Polyp Detection in Colonoscopy Videos
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Automated polyp detection; colonoscopy video; computer-aided diagnosis;
   convolutional neural networks (CNNs); deep learning
ID CONVOLUTIONAL NEURAL-NETWORKS; IMAGES; SEGMENTATION; CANCER
AB Automated polyp detection in colonoscopy videos has been demonstrated to be a promising way for colorectal cancer prevention and diagnosis. Traditional manual screening is time consuming, operator dependent, and error prone; hence, automated detection approach is highly demanded in clinical practice. However, automated polyp detection is very challenging due to high intraclass variations in polyp size, color, shape, and texture, and low interclass variations between polyps and hard mimics. In this paper, we propose a novel offline and online three-dimensional (3-D) deep learning integration framework by leveraging the 3-D fully convolutional network (3D-FCN) to tackle this challenging problem. Compared with the previous methods employing hand-crafted features or 2-D convolutional neural network, the 3D-FCN is capable of learning more representative spatio-temporal features from colonoscopy videos, and hence has more powerful discrimination capability. More importantly, we propose a novel online learning scheme to deal with the problem of limited training data by harnessing the specific information of an input video in the learning process. We integrate offline and online learning to effectively reduce the number of false positives generated by the offline network and further improve the detection performance. Extensive experiments on the dataset of MICCAI 2015 Challenge on Polyp Detection demonstrated the better performance of our method when compared with other competitors.
C1 [Yu, Lequan; Chen, Hao; Dou, Qi; Heng, Pheng Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Qin, Jing] Hong Kong Polytech Univ, Sch Nursing, Ctr Smart Hlth, Hong Kong, Hong Kong, Peoples R China.
   [Heng, Pheng Ann] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Virtual Real & Human Interact Te, Shenzhen 518055, Peoples R China.
C3 Chinese University of Hong Kong; Hong Kong Polytechnic University;
   Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS
RP Yu, LQ (通讯作者)，Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
EM lqyu@cse.cuhk.edu.hk; hchen@cse.cuhk.edu.hk; qdou@cse.cuhk.edu.hk;
   harry.qin@polyu.edu.hk; pheng@cse.cuhk.edu.hk
RI Yu, Lequan/U-5377-2019; Dou, Qi/I-8175-2019; Chen, Hao/V-4299-2019; Qin,
   Jing/J-9807-2016
OI Yu, Lequan/0000-0002-9315-6527; Dou, Qi/0000-0002-3416-9950; Chen,
   Hao/0000-0002-8400-3780; Qin, Jing/0000-0002-7059-0929; Heng, Pheng
   Ann/0000-0003-3055-5034
FU Research Grants Council of the Hong Kong Special Administrative Region
   [CUHK 14202514, CUHK 14203115]; National Natural Science Foundation of
   China [61233012]; Shenzhen Science and Technology Program
   [JCYJ20160429190300857]
FX This work was supported in part by the grants from the Research Grants
   Council of the Hong Kong Special Administrative Region under Project
   CUHK 14202514 and Project CUHK 14203115, in part by the National Natural
   Science Foundation of China under Project 61233012, and in part by the
   Shenzhen Science and Technology Program (JCYJ20160429190300857). (Lequan
   Yu and Hao Chen contributed equally to this work.)
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   [Anonymous], 2016, ARXIV160305959
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Bengio Y., 2014, ARXIV14126550
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821
   Chen H, 2016, AAAI CONF ARTIF INTE, P1160
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen H, 2015, LECT NOTES COMPUT SC, V9349, P507, DOI 10.1007/978-3-319-24553-9_62
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   He YX, 2023, TRANSPORTMETRICA A, V19, DOI [10.1109/CVPR.2016.90, 10.1080/23249935.2022.2033348]
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li RJ, 2014, LECT NOTES COMPUT SC, V8675, P305, DOI 10.1007/978-3-319-10443-0_39
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Nie D, 2016, I S BIOMED IMAGING, P1342, DOI 10.1109/ISBI.2016.7493515
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P471, DOI 10.1016/S0002-9270(02)05928-2
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2014, LECT NOTES COMPUT SC, V8673, P520, DOI 10.1007/978-3-319-10404-1_65
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21654, 10.3322/caac.21387, 10.3322/caac.21708]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
NR 46
TC 130
Z9 139
U1 2
U2 45
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD JAN
PY 2017
VL 21
IS 1
BP 65
EP 75
DI 10.1109/JBHI.2016.2637004
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA EM8CJ
UT WOS:000395538500008
PM 28114049
DA 2023-04-20
ER

PT J
AU Yuan, YX
   Li, BP
   Meng, MQH
AF Yuan, Yixuan
   Li, Baopu
   Meng, Max Q. -H.
TI WCE Abnormality Detection Based on Saliency and Adaptive
   Locality-Constrained Linear Coding
SO IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING
LA English
DT Article
DE Adaptive coding bases; patch saliency; saliency and adaptive
   locality-constrained linear coding (SALLC) algorithm; wireless capsule
   endoscopy (WCE) image classification
ID CAPSULE ENDOSCOPY; IMAGE CLASSIFICATION; FEATURES; RECOGNITION; BAG
AB Wireless capsule endoscopy (WCE) has become a widely used diagnostic technique for the digestive tract, at the price of a large volume of data that needs to be analyzed. To tackle this problem, a new computer-aided system using novel features is proposed in this paper to classify WCE images automatically. In the feature learning stage, to obtain the representative visual words, we first calculate the color scale invariant feature transform from the bleeding, polyp, ulcer, and normal WCE image samples separately and then apply K-means clustering on these features to obtain visual words. These four types of visual words are combined together to composite the representative visual words for classifying the WCE images. In the feature coding stage, we propose a novel saliency and adaptive locality-constrained linear coding (SALLC) algorithm to encode the images. The SALLC encodes patch features based on adaptive coding bases, which are calculated by the distance differences among the features and the visual words. Moreover, it imposes the patch saliency constraint on the feature coding process to emphasize the important information in the images. The experimental results exhibit a promising overall recognition accuracy of 88.61%, validating the effectiveness of the proposed method.
   Note to Practitioners-Because of approximately 50 000 wireless capsule endoscopy (WCE) images for one patient, a clinician usually has to spend about 2 h to view these images and make a diagnostic decision on possible gastrointestinal diseases. Therefore, it is crucial to design an automatic computer-aided system to assist clinicians to classify images with abnormal structures. However, most WCE abnormality detection methods consider only one specific abnormality and the existing multiabnormality classification results are far from satisfactory. Thus, we propose a novel automatic multiabnormality WCE image detection scheme, namely, saliency and adaptive locality-constrained linear coding algorithm, by considering the local coding bases adaptively and the saliency information about the images. Results from comprehensive comparison experiments suggest that the proposed computer-aided classification system achieves improved accuracy.
C1 [Yuan, Yixuan; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
   [Li, Baopu] Shenzhen Univ, Dept Biomed Engn, Shenzhen 518060, Peoples R China.
C3 Chinese University of Hong Kong; Shenzhen University
RP Meng, MQH (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM yxyuan@ee.cuhk.edu.hk; bpli@szu.edu.cn; max@ee.cuhk.edu.hk
RI Meng, Max Q.-H./C-8078-2009; Meng, Q./GSI-6185-2022; meng,
   meng/GWZ-7461-2022
OI Yuan, Yixuan/0000-0002-0853-6948
FU RGC GRF [415613]; National Natural Science Foundation of China
   [61305099]; Natural Science Foundation of Guangdong Province
   [2015A030313547]; Scientific and Technical Innovation Council of
   Shenzhen Government [000047]
FX The work of M.Q.-H. Meng was supported in part by RGC GRF under Grant
   415613, in part by the National Natural Science Foundation of China
   under Grant 61305099, in part by the Natural Science Foundation of
   Guangdong Province under Grant 2015A030313547, and in part by the Seed
   Funding from Scientific and Technical Innovation Council of Shenzhen
   Government under Grant 000047.
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   [Anonymous], 2010, [No title captured], DOI DOI 10.1109/CVPR.2010.5540018
   Anthimopoulos MM, 2014, IEEE J BIOMED HEALTH, V18, P1261, DOI 10.1109/JBHI.2014.2308928
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen SH, 2015, PATTERN RECOGN LETT, V51, P44, DOI 10.1016/j.patrec.2014.08.008
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Csurka G., 2004, WORKSH STAT LEARN CO, V44, P1, DOI DOI 10.1234/12345678
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Huang YZ, 2011, PROC CVPR IEEE, P1753, DOI 10.1109/CVPR.2011.5995682
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Lazebnik S., 2006, P IEEE INT C COMP VI, V2, P2169, DOI DOI 10.1109/CVPR.2006.68
   Lee NM, 2010, EXPERT REV GASTROENT, V4, P503, DOI 10.1586/EGH.10.44
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manno M., 2012, ILEOSCOPY, P79
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Quan Fang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P260, DOI 10.1109/ICME.2012.164
   Sae Hwang, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P320, DOI 10.1007/978-3-642-24031-7_32
   Siddiqui AJ, 2016, IEEE T INTELL TRANSP, V17, P3205, DOI 10.1109/TITS.2016.2545640
   Toennies JL, 2010, P I MECH ENG C-J MEC, V224, P1397, DOI 10.1243/09544062JMES1879
   Upchurch BR, 2008, REV GASTROENTEROL DI, V8, P169
   van der Maaten L., 2011, P INT C MACH LEARN, P217
   van Grinsven MJJP, 2013, I S BIOMED IMAGING, P1444
   Wang J, 2010, APPL MECH MATER, V36, P96, DOI [10.4028/www.scientific.net/AMM.36.96, 10.1109/ICICTA.2010.35]
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Wu ZF, 2012, INT C PATT RECOG, P1505
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Yu K, 2009, ADV NEURAL INFORM PR, V22, P2223
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Zare MR, 2013, IET COMPUT VIS, V7, P105, DOI 10.1049/iet-cvi.2012.0291
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhou JD, 2011, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.2011.6116405
NR 44
TC 52
Z9 58
U1 0
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-5955
EI 1558-3783
J9 IEEE T AUTOM SCI ENG
JI IEEE Trans. Autom. Sci. Eng.
PD JAN
PY 2017
VL 14
IS 1
BP 149
EP 159
DI 10.1109/TASE.2016.2610579
PG 11
WC Automation & Control Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems
GA EG9MJ
UT WOS:000391382700014
DA 2023-04-20
ER

PT J
AU Zhang, RK
   Zheng, YL
   Mak, TWC
   Yu, RX
   Wong, SH
   Lau, JYW
   Poon, CCY
AF Zhang, Ruikai
   Zheng, Yali
   Mak, Tony Wing Chung
   Yu, Ruoxi
   Wong, Sunny H.
   Lau, James Y. W.
   Poon, Carmen C. Y.
TI Automatic Detection and Classification of Colorectal Polyps by
   Transferring Low-Level CNN Features From Nonmedical Domain
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Colorectal cancer; deep learning; health informatics; polyp diagnosis
ID CONVOLUTIONAL NEURAL-NETWORKS; DIFFERENTIAL-DIAGNOSIS; MUCOSAL; LESIONS
AB Colorectal cancer (CRC) is a leading cause of cancer deaths worldwide. Although polypectomy at early stage reduces CRC incidence, 90% of the polyps are small and diminutive, where removal of them poses risks to patients that may outweigh the benefits. Correctly detecting and predicting polyp type during colonoscopy allows endoscopists to resect and discard the tissue without submitting it for histology, saving time, and costs. Nevertheless, human visual observation of early stage polyps varies. Therefore, this paper aims at developing a fully automatic algorithm to detect and classify hyperplastic and adenomatous colorectal polyps. Adenomatous polyps should be removed, whereas distal diminutive hyperplastic polyps are considered clinically insignificant and may be left in situ. A novel transfer learning application is proposed utilizing features learned from big nonmedical datasets with 1.4-2.5 million images using deep convolutional neural network. The endoscopic images we collected for experiment were taken under random lighting conditions, zooming and optical magnification, including 1104 endoscopic nonpolyp images taken under both white-light and narrowband imaging (NBI) endoscopy and 826 NBI endoscopic polyp images, of which 263 images were hyperplasia and 563 were adenoma as confirmed by histology. The proposed method identified polyp images from nonpolyp images in the beginning followed by predicting the polyp histology. When compared with visual inspection by endoscopists, the results of this study show that the proposed method has similar precision (87.3% versus 86.4%) but a higher recall rate (87.6% versus 77.0%) and a higher accuracy (85.9% versus 74.3%). In conclusion, automatic algorithms can assist endoscopists in identifying polyps that are adenomatous but have been incorrectly judged as hyperplasia and, therefore, enable timely resection of these polyps at an early stage before they develop into invasive cancer.
C1 [Zhang, Ruikai; Zheng, Yali; Mak, Tony Wing Chung; Yu, Ruoxi; Lau, James Y. W.; Poon, Carmen C. Y.] Chinese Univ Hong Kong, Dept Surg, Shatin, Hong Kong, Peoples R China.
   [Wong, Sunny H.] Chinese Univ Hong Kong, Li Ka Shing Inst Hlth Sci, Inst Digest Dis, Dept Med & Therapeut,State Key Lab Digest Dis, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong; Chinese University of Hong Kong
RP Zhang, RK (通讯作者)，Chinese Univ Hong Kong, Dept Surg, Shatin, Hong Kong, Peoples R China.
EM rzhang@surgery.cuhk.edu.hk; ylzheng@surgery.cuhk.edu.hk;
   tonymak@surgery.cuhk.edu.hk; yuruoxi@surgery.cuhk.edu.hk;
   wonghei@cuhk.edu.hk; laujyw@surgery.cuhk.edu.hk;
   cpoon@surgery.cuhk.edu.hk
RI Zhang, Ruikai/W-9847-2019; Mak, Tony W. C./M-1310-2018; Wong, Sunny
   H/N-3754-2015; Lau, James Y. W./O-2612-2016; Zhang, Ruikai/W-9848-2019;
   Poon, Carmen C. Y./B-4616-2011
OI Mak, Tony W. C./0000-0002-4516-3124; Wong, Sunny H/0000-0002-3354-9310;
   Lau, James Y. W./0000-0003-0122-4068; Zhang, Ruikai/0000-0001-8929-628X;
   Poon, Carmen C. Y./0000-0001-7717-4752; Zheng, Yali/0000-0002-6215-1694
FU Hong Kong Innovation and Technology Fund; Shaw Endoscopy Center; Chow
   Yuk Ho Technology Centre for Innovative Medicine
FX This work was supported by the Hong Kong Innovation and Technology Fund,
   Shaw Endoscopy Center and the Chow Yuk Ho Technology Centre for
   Innovative Medicine.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bar Y, 2015, PROC SPIE, V9414, DOI 10.1117/12.2083124
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Oba S, 2010, SCAND J GASTROENTERO, V45, P1084, DOI 10.3109/00365521003734166
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Rastogi A, 2009, GASTROINTEST ENDOSC, V69, P716, DOI 10.1016/j.gie.2008.09.058
   Rex DK, 2009, LANCET ONCOL, V10, P1135, DOI 10.1016/S1470-2045(09)70342-0
   Roth HR, 2015, I S BIOMED IMAGING, P101, DOI 10.1109/ISBI.2015.7163826
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sano Y, 2009, GASTROINTEST ENDOSC, V69, P278, DOI 10.1016/j.gie.2008.04.066
   Shie C.-K., 2015, P 37 ANN INT C IEEE
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Stehle T, 2009, PROC SPIE, V7260, DOI 10.1117/12.808103
   Su MY, 2006, AM J GASTROENTEROL, V101, P2711, DOI 10.1111/j.1572-0241.2006.00932.x
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tanaka S, 2011, DIGEST ENDOSC, V23, P131, DOI 10.1111/j.1443-1661.2011.01106.x
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Yosinski J., 2014, NIPS
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhou Bolei, 2014, ADV NEURAL INFORM PR, DOI DOI 10.1162/153244303322533223
NR 31
TC 199
Z9 213
U1 7
U2 72
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD JAN
PY 2017
VL 21
IS 1
BP 41
EP 47
DI 10.1109/JBHI.2016.2635662
PG 7
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA EM8CJ
UT WOS:000395538500005
PM 28114040
DA 2023-04-20
ER

PT J
AU Cho, YJ
   Bae, SH
   Yoon, KJ
AF Cho, Yeong-Jun
   Bae, Seung-Hwan
   Yoon, Kuk-Jin
TI Multi-Classifier-Based Automatic Polyp Detection in Endoscopic Images
SO JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING
LA English
DT Article
DE Medical imaging; Medical engineering; Automatic polyp detection;
   Multi-classifier learning; Contour intensity difference measure
ID COLONOSCOPY; ENSEMBLE
AB Automatic polyp detection in endoscopy (or colonoscopy) images is challenging because the types of polyp and their appearances are diverse, and the colors and textures of polyps are quite similar to those of normal tissues in many cases. It is thus often very difficult to distinguish polyps from normal tissues using conventional methodology. To effectively resolve these challenges, we propose a framework based on multi-classifier learning and a contour intensity difference (CID) measure. To detect polyps of diverse appearances, we first classify polyps into K types according to their shape via unsupervised learning. We then train K classifiers to detect the K types of polyp. This multi-classifier learning improves the polyp detection rate. However, false positives also increase because colon structures look similar to polyps. To reduce false positives while preserving the high detection rate, we propose a CID measure. Experimental results using public and our own datasets show that the proposed methods are promising for detecting polyps with diverse appearances.
C1 [Cho, Yeong-Jun; Yoon, Kuk-Jin] Gwangju Inst Sci & Technol, 123 Cheom Dan Gwagi Ro, Gwangju 500712, South Korea.
   [Bae, Seung-Hwan] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Electronics &
   Telecommunications Research Institute - Korea (ETRI)
RP Yoon, KJ (通讯作者)，Gwangju Inst Sci & Technol, 123 Cheom Dan Gwagi Ro, Gwangju 500712, South Korea.
EM kjyoon@gist.ac.kr
RI Yoon, Kuk-Jin/F-4329-2018; CHO, Yeong-Jun/HSF-4060-2023
CR Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   [Anonymous], 2014, WORLD CANC REPORT
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bieniek A, 2000, PATTERN RECOGN, V33, P907, DOI 10.1016/S0031-3203(99)00154-5
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   COOPE ID, 1993, J OPTIMIZ THEORY APP, V76, P381, DOI 10.1007/BF00939613
   Dalal N., 2005, COMPUTER VISION PATT, V1, P693
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Dollar P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Everingham M, 2006, LECT NOTES ARTIF INT, V3944, P117
   HWANG S, 2007, P IEEE INT C IM PROC, V0002, P00465
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Li BP, 2012, J MED SYST, V36, P2463, DOI 10.1007/s10916-011-9713-2
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li P, 2005, PROC CVPR IEEE, P670
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Viola P., 2005, ADV NEURAL INFORM PR, P1417
NR 24
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1609-0985
EI 2199-4757
J9 J MED BIOL ENG
JI J. Med. Biol. Eng.
PD DEC
PY 2016
VL 36
IS 6
SI SI
BP 871
EP 882
DI 10.1007/s40846-016-0190-4
PG 12
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA EH9IN
UT WOS:000392085100012
DA 2023-04-20
ER

PT J
AU Segui, S
   Drozdzal, M
   Pascual, G
   Radeva, P
   Malagelada, C
   Azpiroz, F
   Vitria, J
AF Segui, Santi
   Drozdzal, Michal
   Pascual, Guillem
   Radeva, Petia
   Malagelada, Carolina
   Azpiroz, Fernando
   Vitria, Jordi
TI Generic feature learning for wireless capsule endoscopy analysis
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Wireless capsule endoscopy; Deep learning; Feature learning; Motility
   analysis
ID INCREASED DIAGNOSTIC YIELD; SMALL-BOWEL TUMORS; FRAMES
AB The interpretation and analysis of wireless capsule endoscopy (WCE) recordings is a complex task which requires sophisticated computer aided decision (CAD) systems to help physicians with video screening and, finally, with the diagnosis. Most CAD systems used in capsule endoscopy share a common system design, but use very different image and video representations. As a result, each time a new clinical application of WCE appears, a new CAD system has to be designed from the scratch. This makes the design of new CAD systems very time consuming. Therefore, in this paper we introduce a system for small intestine motility characterization, based on Deep Convolutional Neural Networks, which circumvents the laborious step of designing specific features for individual motility events. Experimental results show the superiority of the learned features over alternative classifiers constructed using state-of-the-art handcrafted features. In particular, it reaches a mean classification accuracy of 96% for six intestinal motility events, outperforming the other classifiers by a large margin (a 14% relative performance increase).
C1 [Segui, Santi; Pascual, Guillem; Radeva, Petia; Vitria, Jordi] Univ Barcelona, Dept Matemat & Informat, Barcelona, Spain.
   [Segui, Santi; Radeva, Petia; Vitria, Jordi] CVC, Barcelona, Spain.
   [Drozdzal, Michal] Medtron GI, Yoqneam, Israel.
   [Malagelada, Carolina; Azpiroz, Fernando] Hosp Valle De Hebron, Digest Syst Res Unit, Barcelona, Spain.
C3 University of Barcelona; Centre de Visio per Computador (CVC); Hospital
   Universitari Vall d'Hebron
RP Segui, S (通讯作者)，Univ Barcelona, Dept Matemat & Informat, Barcelona, Spain.
EM santi.segui@ub.edu
RI Vitrià, Jordi/AAF-9668-2020; Malagelada, Carolina/F-3743-2016; Segui,
   Santi/E-4860-2010
OI Vitrià, Jordi/0000-0003-1484-539X; Malagelada,
   Carolina/0000-0001-7097-1492; Segui, Santi/0000-0002-8603-138X; Azpiroz,
   Fernando/0000-0002-7327-960X
FU Given Imaging Ltd., Yoqneam, Israel; Spanish MINECO/EU
   [TIN2012-38187-C03]; EU under REA [607652];  [SGR 1219]
FX This work was supported in part by a research grant from Given Imaging
   Ltd., Yoqneam, Israel, as well as by both the Spanish MINECO/EU Grant
   TIN2012-38187-C03 and the SGR 1219. MD received funding from the People
   Programme of the EU's 7th Framework Programme under REA grant agreement
   no. 607652 (ITN NeuroGut). We gratefully acknowledge the support of
   NVIDIA Corporation through the donation of the Tesla K40 GPU used for
   this research.
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Belle Ashwin, 2013, ScientificWorldJournal, V2013, P769639, DOI 10.1155/2013/769639
   Candes E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chen HH, 2013, INT CONF BIOMED, P116, DOI 10.1109/BMEI.2013.6746918
   Chen Y.-J., 2009, P SPIE, V7260
   Chu XQ, 2010, LECT NOTES COMPUT SC, V6362, P522
   Ciaccio EJ, 2013, WORLD J GASTRO ENDOS, V5, P313, DOI 10.4253/wjge.v5.i7.313
   Ciaccio EJ, 2010, COMPUT METH PROG BIO, V100, P39, DOI 10.1016/j.cmpb.2010.02.005
   Cobrin GM, 2006, CANCER-AM CANCER SOC, V107, P22, DOI 10.1002/cncr.21975
   Drozdzal M, 2015, COMPUT BIOL MED, V65, P320, DOI 10.1016/j.compbiomed.2015.04.006
   Drozdzal M, 2013, COMPUT MED IMAG GRAP, V37, P72, DOI 10.1016/j.compmedimag.2012.09.002
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Eliakim R, 2004, WORLD J GASTROENTERO, V10, P1238
   Figueiredo I. N., 2013, COMPUTER METHODS BIO, V1, P1
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Iakovidis D.K., 2013, BIOINF BIOENG BIBE 2, P1
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia Yangqing, 2013, CAFFE OPEN SOURCE CO
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lowe D., 1999, P 7 IEEE INT C COMPU, P1150
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Maghsoudi Omid Haji, 2014, J ADV COMPUTING, V3, P12, DOI DOI 10.7726/jac.2014.1002a
   Malagelada C, 2012, NEUROGASTROENT MOTIL, V24, P223, DOI 10.1111/j.1365-2982.2011.01823.x
   Malagelada C., AM J PHYSL GASTROINT
   Mamonov A. V., CORR
   Mustafa BF, 2013, EXPERT REV GASTROENT, V7, P323, DOI [10.1586/egh.13.20, 10.1586/EGH.13.20]
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Segui S., 2014, DETECTION WRINKLE FR
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K., CORR
   Suenaga Masato, 2014, Modern Advances in Applied Intelligence. 27th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2014. Proceedings: LNCS 8482, P228, DOI 10.1007/978-3-319-07467-2_24
   Sun Z, 2012, IEEE INT C AUTOMAT L, P294, DOI 10.1109/ICAL.2012.6308214
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   Urgesi R, 2012, TUMORI, V98, P357, DOI 10.1700/1125.12405
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Yang LP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087396
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zhao Q, 2015, COMPUT MED IMAG GRAP, V41, P108, DOI 10.1016/j.compmedimag.2014.05.011
   Zheng YP, 2012, AM J GASTROENTEROL, V107, P554, DOI 10.1038/ajg.2011.461
NR 47
TC 59
Z9 60
U1 0
U2 22
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD DEC 1
PY 2016
VL 79
BP 163
EP 172
DI 10.1016/j.compbiomed.2016.10.011
PG 10
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA EE0UP
UT WOS:000389294700017
PM 27810622
OA Green Submitted, Green Accepted
DA 2023-04-20
ER

PT J
AU Oliva, JT
   Lee, HD
   Spolaor, N
   Coy, CSR
   Wu, FC
AF Oliva, Jefferson Tales
   Lee, Huei Diana
   Spolaor, Newton
   Coy, Claudio Saddy Rodrigues
   Wu, Feng Chung
TI Prototype system for feature extraction, classification and study of
   medical images
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Image analysis; Texture; Machine learning; Prototyping; Artificial
   intelligence; Medical information systems
ID COMPUTER-AIDED DETECTION; TEXTURAL FEATURES; FALSE POSITIVES; POLYPS;
   REDUCTION; SCALE
AB Colonoscopy exam images are useful to identify diseases, such as the colorectal cancer, which is one of the most common cancers worldwide. Computational image analysis and machine learning techniques can assist experts to identify abnormalities in these images. In this work, we present and evaluate MIAS 3.0, which aims to help experts to study and analyze colon tissue images. To do so, the system initially extracts features from these images. Currently, Amadasum, Haralick and Laws texture descriptors are supported. Then, the described images are classified into normal or abnormal images. In this version, J48, nearest neighbor, backpropagation based on multilayer perceptron, naive Bayes, and support vector machine classification algorithms are implemented. MIAS was developed with open source technologies using a software engineering approach to improve flexibility and maintainability. In this work, MIAS was quantitatively assessed by its application in a set of 134 tissue image fragments. The classifiers built from this set were compared according to the cross-validation and contingency table strategies. Also, the system was qualitatively evaluated using 12 heuristics by twelve volunteers from Health and Exact Sciences. The issues found were categorized according to Rolf Molich's severity scale. As a result, the J48 classifier achieved the highest sensitivity (85.07%) and reasonable average error (18.68%). In the qualitative evaluation, 61.26% of the issues found were not considered serious. These assessments suggest that MIAS can be useful to assist domain experts with minimum knowledge in informatics to conduct more complete studies of medical images, by identifying patterns regarding different abnormalities. (C) 2016 Published by Elsevier Ltd.
C1 [Oliva, Jefferson Tales] Univ Sao Paulo, Bioinspired Comp Lab, Trabalhador Sao Carlense Ave, BR-13560970 Sao Paulo, Brazil.
   [Oliva, Jefferson Tales; Lee, Huei Diana; Spolaor, Newton; Wu, Feng Chung] Western Parana State Univ, Lab Bioinformat, Presidente Tancredo Neves Ave 6731, BR-85867900 Foz Do Iguacu, Parana, Brazil.
   [Coy, Claudio Saddy Rodrigues; Wu, Feng Chung] Univ Estadual Campinas, Serv Coloproctol, Tessalia Vieira de Camargo St 126, BR-13083887 Sao Paulo, Brazil.
C3 Universidade de Sao Paulo; Centro Universitario La Salle; Universidade
   Estadual de Campinas
RP Lee, HD (通讯作者)，Western Parana State Univ, Lab Bioinformat, Presidente Tancredo Neves Ave 6731, BR-85867900 Foz Do Iguacu, Parana, Brazil.
EM jeffersontalesoliva@gmail.com; huei.lee@unioeste.br;
   newtonspolaor@gmail.com; claudiocoy@gmail.com; wufengchung@gmail.com
RI Coy, Claudio/AAD-7599-2019; Chung, Wu Feng/AAB-1319-2021; Lee, Huei
   Diana/D-8219-2015
OI OLIVA, JEFFERSON/0000-0003-1574-1293; Lee, Huei
   Diana/0000-0002-2189-1047
FU Higher Education Personnel (CAPES); Graduate Program in Electrical
   Engineering and Computer Science (PGEEC); Western Parana State
   University (Unioeste
FX The authors would like to thank the Coordination for the Improvement of
   Higher Education Personnel (CAPES) and the Graduate Program in
   Electrical Engineering and Computer Science (PGEEC) at the Western
   Parana State University (Unioeste) for the financial support.
CR Aizerman M. A., 1964, AUTOMAT REM CONTR, V25, P821, DOI DOI 10.1234/12345678
   Alpaydin E, 2014, ADAPT COMPUT MACH LE, P115
   AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   American Cancer Society, 2014, COL CANC FACTS FIG 2
   Beura S, 2015, NEUROCOMPUTING, V154, P1, DOI 10.1016/j.neucom.2014.12.032
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dasgupta S, 2003, RANDOM STRUCT ALGOR, V22, P60, DOI 10.1002/rsa.10073
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Ferrero C. A., 2009, BRAZILIAN J COLOPROC, V29, P23
   Ferrero C. A., 2008, P WORKSH EPHAM APR, P1
   Fredman D., 1988, STATISTICS
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Fu JJC, 2014, COMPUT MED IMAG GRAP, V38, P267, DOI 10.1016/j.compmedimag.2013.12.009
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hall M., 2009, WEKA 3 DATA MINING S
   Han J, 2012, MOR KAUF D, P1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Haykin S, 2009, NEURAL NETWORKS LEAR
   Hyvarinen A, 2013, PHILOS T R SOC A, V371, DOI 10.1098/rsta.2011.0534
   Karahaliou AN, 2008, IEEE T INF TECHNOL B, V12, P731, DOI 10.1109/TITB.2008.920634
   Karkanis S., 1999, P WORKSH MACH LEARN, P63
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Laws K, 1980, THESIS U SO CALIFORN
   Laws KI, 1979, P IM UND WORKSH, P47, DOI DOI 10.111141600-0846.2009.00354.X
   Lee H. D., 2013, P BRAZ C COL
   Li WQ, 2015, MED IMAGE ANAL, V26, P57, DOI 10.1016/j.media.2015.08.002
   Lilholt PH, 2015, INT J MED INFORM, V84, P319, DOI 10.1016/j.ijmedinf.2015.01.012
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu Z, 2011, LECT NOTES COMPUT SC, V6893, P124, DOI 10.1007/978-3-642-23626-6_16
   Lowe D., 1999, P 7 IEEE INT C COMPU, P1150
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mack R. L, 1994, USABILITY INSPECTION
   Mahapatra D, 2013, J DIGIT IMAGING, V26, P920, DOI 10.1007/s10278-013-9576-9
   Molich R., 2008, USABLE WEB DESIGN
   Molina JFG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093600
   Nanni L, 2013, EXPERT SYST APPL, V40, P7457, DOI 10.1016/j.eswa.2013.07.047
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   National Cancer Institute of Brazil, 2014, EST 2014 CANC INC BR
   NetBeans I., 2015, NETB IDE FEAT
   Nielsen, 1995, 10 USABILITY HEURIST
   Niu LL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076880
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva J. T., 2012, P BRAZ C HLTH INF, P1
   Oracle, 2015, JAV ADV IM
   Pedrini H., 2008, DIGITAL IMAGE ANAL P
   Pressman R., 2010, SOFTWARE ENG PROFESS
   Quilici F., 2000, COLONOSCOPY
   Quinlan J. R., 2014, C4 5 PROGRAMS MACHIN
   Rezende S. O, 2003, INTELLIGENT SYSTEMS
   Shan J, 2012, ULTRASOUND MED BIOL, V38, P262, DOI 10.1016/j.ultrasmedbio.2011.10.022
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Spolaor N., 2010, P BRAZ C HLTH INF, P1
   Suzuki K, 2006, MED PHYS, V33, P3814, DOI 10.1118/1.2349839
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Witten I., 2011, MACHINE LEARNING PRA
   Wong W. K., 2013, INT J ENHANCED RES S, V2, P1
   Zhang X., 2006, P ANN INT C ENG MED, P867
NR 61
TC 12
Z9 14
U1 1
U2 80
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 30
PY 2016
VL 63
BP 267
EP 283
DI 10.1016/j.eswa.2016.07.008
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA DU5TH
UT WOS:000382273700022
DA 2023-04-20
ER

PT J
AU Awaysheh, A
   Wilcke, J
   Elvinger, F
   Rees, L
   Fan, WG
   Zimmerman, KL
AF Awaysheh, Abdullah
   Wilcke, Jeffrey
   Elvinger, Francois
   Rees, Loren
   Fan, Weiguo
   Zimmerman, Kurt L.
TI Evaluation of supervised machine-learning algorithms to distinguish
   between inflammatory bowel disease and alimentary lymphoma in cats
SO JOURNAL OF VETERINARY DIAGNOSTIC INVESTIGATION
LA English
DT Article
DE Cats; diagnosis; inflammatory bowel disease; lymphoma; machine learning
ID ENDOSCOPIC BIOPSY; GASTROINTESTINAL INFLAMMATION; DIAGNOSIS; DOGS;
   SELECTION; SAMPLES; TRACT
AB Inflammatory bowel disease (IBD) and alimentary lymphoma (ALA) are common gastrointestinal diseases in cats. The very similar clinical signs and histopathologic features of these diseases make the distinction between them diagnostically challenging. We tested the use of supervised machine-learning algorithms to differentiate between the 2 diseases using data generated from noninvasive diagnostic tests. Three prediction models were developed using 3 machine-learning algorithms: naive Bayes, decision trees, and artificial neural networks. The models were trained and tested on data from complete blood count (CBC) and serum chemistry (SC) results for the following 3 groups of client-owned cats: normal, inflammatory bowel disease (IBD), or alimentary lymphoma (ALA). Naive Bayes and artificial neural networks achieved higher classification accuracy (sensitivities of 70.8% and 69.2%, respectively) than the decision tree algorithm (63%, p < 0.0001). The areas under the receiver-operating characteristic curve for classifying cases into the 3 categories was 83% by naive Bayes, 79% by decision tree, and 82% by artificial neural networks. Prediction models using machine learning provided a method for distinguishing between ALA-IBD, ALA-normal, and IBD-normal. The naive Bayes and artificial neural networks classifiers used 10 and 4 of the CBC and SC variables, respectively, to outperform the C4.5 decision tree, which used 5 CBC and SC variables in classifying cats into the 3 classes. These models can provide another noninvasive diagnostic tool to assist clinicians with differentiating between IBD and ALA, and between diseased and nondiseased cats.
C1 [Awaysheh, Abdullah; Wilcke, Jeffrey; Zimmerman, Kurt L.] Virginia Tech, Dept Biomed Sci & Pathobiol, Blacksburg, VA USA.
   [Elvinger, Francois] Virginia Tech, Dept Populat Hlth Sci, Blacksburg, VA USA.
   [Rees, Loren] Virginia Tech, Dept Business Informat Technol, Blacksburg, VA USA.
   [Fan, Weiguo] Virginia Tech, Dept Accounting & Informat Syst, Blacksburg, VA USA.
C3 Virginia Polytechnic Institute & State University; Virginia Polytechnic
   Institute & State University; Virginia Polytechnic Institute & State
   University; Virginia Polytechnic Institute & State University
RP Zimmerman, KL (通讯作者)，Virginia Tech, Coll Vet Med, Dept Biomed Sci & Pathobiol, Blacksburg, VA 24061 USA.
EM kzimmerm@vt.edu
RI Fan, Weiguo/E-6343-2012
OI Fan, Weiguo/0000-0003-1272-5538
CR Abbass HA, 2002, ARTIF INTELL MED, V25, P265, DOI 10.1016/S0933-3657(02)00028-3
   Abbod MF, 2007, J UROLOGY, V178, P1150, DOI 10.1016/j.juro.2007.05.122
   Al-Omari FA, 2011, J CLIN PATHOL, V64, P330, DOI 10.1136/jcp.2010.088252
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Briscoe KA, 2011, J COMP PATHOL, V145, P187, DOI 10.1016/j.jcpa.2010.12.011
   Burke KF, 2013, VET J, V196, P189, DOI 10.1016/j.tvjl.2012.09.019
   Carreras JK, 2003, J VET INTERN MED, V17, P326, DOI 10.1892/0891-6640(2003)017&lt;0326:FEIMLC&gt;2.3.CO;2
   Day MJ, 2008, J COMP PATHOL, V138, pS1, DOI 10.1016/j.jcpa.2008.01.001
   DENNIS JS, 1992, J AM VET MED ASSOC, V200, P1712
   Evans SE, 2006, JAVMA-J AM VET MED A, V229, P1447, DOI 10.2460/javma.229.9.1447
   Gabor LJ, 2000, AUST VET J, V78, P456, DOI 10.1111/j.1751-0813.2000.tb11856.x
   Gabriels W, 2007, AQUAT ECOL, V41, P427, DOI 10.1007/s10452-007-9081-7
   Gevrey M, 2003, ECOL MODEL, V160, P249, DOI 10.1016/S0304-3800(02)00257-0
   GOLDEN DL, 1993, SEMIN VET MED SURG, V8, P239
   Jaffe ES., 2009, HEMATOL AM SOC HEMAT, V2009, P523, DOI 10.1182/asheducation-2009.1.523
   Jergens AE, 2010, J VET INTERN MED, V24, P1027, DOI 10.1111/j.1939-1676.2010.0549.x
   JERGENS AE, 1992, J AM VET MED ASSOC, V201, P1603
   Lalor S, 2014, J VET INTERN MED, V28, P351, DOI 10.1111/jvim.12294
   Leib MS, 1999, J VET INTERN MED, V13, P191, DOI 10.1892/0891-6640(1999)013&lt;0191:EAOICI&gt;2.3.CO;2
   Marsilio S, 2014, J COMP PATHOL, V150, P416, DOI 10.1016/j.jcpa.2014.01.002
   McDonald JM, 1998, ARCH PATHOL LAB MED, V122, P409
   Moore PF, 2005, VET IMMUNOL IMMUNOP, V106, P167, DOI 10.1016/j.vetimm.2005.02.014
   Palaniappan S, 2008, I C COMP SYST APPLIC, P108, DOI 10.1109/AICCSA.2008.4493524
   Ragaini L, 2003, VET RES COMMUN, V27, P791, DOI 10.1023/B:VERC.0000014273.80853.c1
   Rassnick KM, 2009, J VET INTERN MED, V23, P317, DOI 10.1111/j.1939-1676.2008.0270.x
   ROTH L, 1990, J AM VET MED ASSOC, V196, P635
   Russell KJ, 2012, J FELINE MED SURG, V14, P910, DOI 10.1177/1098612X12454861
   Schnabel LV, 2006, J VET INTERN MED, V20, P204, DOI 10.1892/0891-6640(2006)20[204:PALWMT]2.0.CO;2
   Smith AL, 2011, VET SURG, V40, P849, DOI 10.1111/j.1532-950X.2011.00863.x
   Swanson CM, 2012, J FELINE MED SURG, V14, P741, DOI 10.1177/1098612X12451404
   Taylor SS, 2013, J FELINE MED SURG, V15, P142, DOI 10.1177/1098612X12463928
   Taylor SS, 2010, J FELINE MED SURG, V12, P643, DOI 10.1016/j.jfms.2010.03.018
   Washabau RJ, 2010, J VET INTERN MED, V24, P10, DOI 10.1111/j.1939-1676.2009.0443.x
   WASMER ML, 1995, J AM ANIM HOSP ASSOC, V31, P463, DOI 10.5326/15473317-31-6-463
   WILCOCK B, 1992, SEMIN VET MED SURG, V7, P162
   Willard MD, 2008, J VET INTERN MED, V22, P1084, DOI 10.1111/j.1939-1676.2008.0149.x
   Willard M D, 1999, J Feline Med Surg, V1, P155, DOI 10.1016/S1098-612X(99)90204-8
   Willard MD, 2002, J AM VET MED ASSOC, V220, P1177, DOI 10.2460/javma.2002.220.1177
   Xhemali D., 2009, INT J COMPUT SCI ISS, V4, P16
   Zelic I, 1997, J MED SYST, V21, P429, DOI 10.1023/A:1022880431298
   Zhang XW, 2014, COMPUT METH PROG BIO, V113, P781, DOI 10.1016/j.cmpb.2013.12.023
NR 41
TC 7
Z9 7
U1 0
U2 16
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1040-6387
EI 1943-4936
J9 J VET DIAGN INVEST
JI J. Vet. Diagn. Invest.
PD NOV
PY 2016
VL 28
IS 6
BP 679
EP 687
DI 10.1177/1040638716657377
PG 9
WC Veterinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Veterinary Sciences
GA DZ4CM
UT WOS:000385805400010
PM 27698168
DA 2023-04-20
ER

PT J
AU Dunaeva, O
   Edelsbrunner, H
   Lukyanov, A
   Machin, M
   Malkova, D
   Kuvaev, R
   Kashin, S
AF Dunaeva, Olga
   Edelsbrunner, Herbert
   Lukyanov, Anton
   Machin, Michael
   Malkova, Daria
   Kuvaev, Roman
   Kashin, Sergey
TI The classification of endoscopy images with persistent homology
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Endoscopy; Automated diagnostics; Image processing; Computational
   topology; Persistent homology; Machine learning
ID SYSTEM
AB Aiming at the automatic diagnosis of tumors using narrow band imaging (NBI) magnifying endoscopic (ME) images of the stomach, we combine methods from image processing, topology, geometry, and machine learning to classify patterns into three classes: oval, tubular and irregular. Training the algorithm on a small number of images of each type, we achieve a high rate of correct classifications. The analysis of the learning algorithm reveals that a handful of geometric and topological features are responsible for the overwhelming majority of decisions. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Dunaeva, Olga; Lukyanov, Anton] PG Demidov Yaroslavl State Univ, Dept Comp Sci, Yaroslavl, Yaroslavl Regio, Russia.
   [Machin, Michael; Malkova, Daria] PG Demidov Yaroslavl State Univ, Delone Lab Discrete & Computat Geometry, Yaroslavl, Yaroslavl Regio, Russia.
   [Edelsbrunner, Herbert] IST Austria Inst Sci & Technol Austria, Dept Comp Sci, Klosterneuburg, Lower Austria, Austria.
   [Kuvaev, Roman; Kashin, Sergey] Yaroslavl Reg Canc Hosp, Endoscopy Dept, Yaroslavl, Yaroslavl Regio, Russia.
C3 Yaroslavl State University; Yaroslavl State University; Institute of
   Science & Technology - Austria
RP Malkova, D (通讯作者)，PG Demidov Yaroslavl State Univ, Delone Lab Discrete & Computat Geometry, Yaroslavl, Yaroslavl Regio, Russia.
EM dasha.m91@gmail.com
RI Dunaeva, Olga/P-1541-2015; Kuvaev, Roman O/L-8399-2016
OI Dunaeva, Olga/0000-0001-8078-4447; Kashin, Sergey V./0000-0001-6098-7677
FU Russian Government [11.G34.31.0053]; P.G. Demidov Yaroslavl State
   University within State Assignment for Research [477]
FX This research is partially supported by the Russian Government under the
   Mega Project 11.G34.31.0053. This research is partially supported by the
   project no. 477 of P.G. Demidov Yaroslavl State University within State
   Assignment for Research.
CR [Anonymous], 2022, COMPUTATIONAL TOPOLO
   Edelsbrunner H., 2012, Proceedings of the 2012 Ninth International Symposium on Voronoi Diagrams in Science and Engineering (ISVD 2012), P41, DOI 10.1109/ISVD.2012.11
   Felzenszwalb P.F., 2012, THEORY COMPUT, V8, P415, DOI DOI 10.4086/TOC.2012.V008A019
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Hafner M., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2724, DOI 10.1109/ICPR.2010.667
   Hafner M., 2009, P 9 INT C INF TECHN, P1
   Har-peled S., 2011, MATH SURVEYS MONOGRA, DOI DOI 10.1090/SURV/173
   Kwitt R, 2012, MED IMAGE ANAL, V16, P1415, DOI 10.1016/j.media.2012.04.010
   Kwitt R, 2010, P IEEE COMP SOC C CO, P103, DOI [10.1109/CVPRW.2010.5543146, DOI 10.1109/CVPRW.2010.5543146]
   Munkres James R., 1984, ELEMENTS ALGEBRAIC T
   Nakayoshi T, 2004, ENDOSCOPY, V36, P1080, DOI 10.1055/s-2004-825961
   Saito S, 2011, INT J SURG ONCOL, V2011, DOI 10.1155/2011/242608
   Shapiro L. G., 2002, COMPUTER VISION
   Song LMWK, 2008, GASTROINTEST ENDOSC, V67, P581, DOI 10.1016/j.gie.2008.01.013
   Sonka M., 2014, IMAGE PROCESSING ANA, V4th
   Stehle T., 2009, MED IMAGING 2009 COM, V7260
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tarjan R. E., 1983, DATA STRUCTURES NETW
   Yao K, 2008, NEW CHALLENGES IN GASTROINTESTINAL ENDOSCOPY, P169, DOI 10.1007/978-4-431-78889-8_16
NR 19
TC 12
Z9 12
U1 1
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD NOV 1
PY 2016
VL 83
BP 13
EP 22
DI 10.1016/j.patrec.2015.12.012
PN 1
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EA8HA
UT WOS:000386874700003
DA 2023-04-20
ER

PT J
AU Wang, S
   Cong, Y
   Fan, HJ
   Liu, LQ
   Li, XQ
   Yang, YS
   Tang, YD
   Zhao, HC
   Yu, HB
AF Wang, Shuai
   Cong, Yang
   Fan, Huijie
   Liu, Lianqing
   Li, Xiaoqiu
   Yang, Yunsheng
   Tang, Yandong
   Zhao, Huaici
   Yu, Haibin
TI Computer-Aided Endoscopic Diagnosis Without Human-Specific Labeling
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Computer-aided endoscopic diagnosis; multiple instance learning (MIL);
   online metric learning; weakly labeled data
ID HELICOBACTER-PYLORI; FEATURE-SELECTION; MULTIPLE; CLASSIFICATION;
   TEXTURE; IMAGES
AB Goal: Most state-of-the-art computer-aided endoscopic diagnosis methods require pixelwise labeled data to train various supervised machine learning models. However, it is a tedious and time-consuming work to collect sufficient precisely labeled image data. Fortunately, we can easily obtain huge endoscopic medical reports including the diagnostic text and images, which can be considered as weakly labeled data. Methods: In this paper, ourmotivation is to design a new computer-aided endoscopic diagnosis system without human specific labeling; in comparison with most state of the arts, ours only depends on the endoscopic images with weak labels mined from the diagnostic text. To achieve this, we first cast the endoscopic image folder and included images as bag and instances and represent each instance based on the global bag-of-words model. We then adopt a feature mapping scheme to represent each bag by mining the most suspicious lesion instance from each positive bag automatically. In order to achieve self-online updating from sequential new coming data, an online metric learning method is used to optimize the bag-level classification. Results: Our computer-aided endoscopic diagnosis system achieves an AUC of 0.93 on a new endoscopic image dataset captured from424 volunteers with more than 12k images. Conclusion: The system performance outperforms other state of the arts when we mine the most positive instances from positive bags and adopt the online phase to mine more information from the unseen bags. Significance: We present the first weakly labeled endoscopic image dataset for computer-aided endoscopic diagnosis and a novel system that is suitable for use in clinical settings.
C1 [Wang, Shuai; Cong, Yang; Fan, Huijie; Liu, Lianqing; Tang, Yandong; Zhao, Huaici; Yu, Haibin] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang 110016, Peoples R China.
   [Wang, Shuai] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Li, Xiaoqiu] Gen Hosp Shenyang Mil Reg, Dept Neurol, Shenyang, Peoples R China.
   [Yang, Yunsheng] Chinese Peoples Liberat Army Gen Hosp, Hosp 301, Dept Gastroenterol & Hepatol, Beijing, Peoples R China.
   [Yang, Yunsheng] Chinese Peoples Liberat Army Gen Hosp, Hosp 301, Inst Digest Dis, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Shenyang Institute of Automation, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese People's Liberation Army General Hospital; Chinese People's
   Liberation Army General Hospital
RP Cong, Y (通讯作者)，Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang 110016, Peoples R China.
EM congyang@sia.cn
OI Wang, Shuai/0000-0003-3730-6401
FU National Science and Technology Support Program [2012BAI14B03]; National
   Natural Science Foundation of China [61375014, 61533015, 61333019];
   Foundation of Chinese Scholarship Council
FX This work was supported by the National Science and Technology Support
   Program under Contract 2012BAI14B03, the National Natural Science
   Foundation of China under Grant 61375014, Grant 61533015, and Grant
   61333019, and the Foundation of Chinese Scholarship Council. Asterisk
   indicates corresponding author.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Andrews S., 2002, P ADV NEUR INF PROC, P561
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Baker ZK, 2005, IEEE T VLSI SYST, V13, P1179, DOI 10.1109/TVLSI.2005.859472
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Bashar MK, 2008, LECT NOTES COMPUT SC, V5242, P603, DOI 10.1007/978-3-540-85990-1_72
   Bau TC, 2010, IEEE T GEOSCI REMOTE, V48, P3457, DOI 10.1109/TGRS.2010.2046494
   Bell CS, 2013, ARTIF INTELL MED, V59, P185, DOI 10.1016/j.artmed.2013.09.002
   Cabral R, 2015, IEEE T PATTERN ANAL, V37, P121, DOI 10.1109/TPAMI.2014.2343234
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Cheplygina V, 2015, PATTERN RECOGN, V48, P264, DOI 10.1016/j.patcog.2014.07.022
   Chu A, 2008, ARTIF INTELL MED, V42, P247, DOI 10.1016/j.artmed.2007.10.003
   Chu XQ, 2010, LECT NOTES COMPUT SC, V6362, P522
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Cong Y, 2013, IEEE T IMAGE PROCESS, V22, P3179, DOI 10.1109/TIP.2013.2260168
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Dundar MM, 2008, IEEE T BIO-MED ENG, V55, P1015, DOI 10.1109/TBME.2007.909544
   Er M. J., 2004, INTELLIGENT SENSORY
   Figueiredo I. N., 2013, COMPUTER METHODS BIO, V1, P1
   Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7
   Hafner M., 2013, MED COMPUTER VISION, P205
   Huang CR, 2008, IEEE T INF TECHNOL B, V12, P523, DOI 10.1109/TITB.2007.913128
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   I. CVX Research, 2014, CVX MATLAB SOFTWARE
   John RI, 2005, IEEE T SYST MAN CY B, V35, P1340, DOI 10.1109/TSMCB.2005.855588
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karargyris A, 2011, IEEE T MED IMAGING, V30, P957, DOI 10.1109/TMI.2010.2098882
   Karlik B, 2009, MATH COMPUT APPL, V14, P241, DOI 10.3390/mca14030241
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li WJ, 2010, IEEE T KNOWL DATA EN, V22, P76, DOI 10.1109/TKDE.2009.58
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lin BX, 2015, IEEE T BIO-MED ENG, V62, P1141, DOI 10.1109/TBME.2014.2373273
   Lin Q., 2013, FUNCT MOL MED IMAG, V2, P195
   Mackiewicz M, 2008, PROC SPIE, V6914, DOI 10.1117/12.770510
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Maron O, 1998, ADV NEUR IN, V10, P570
   Melendez J, 2015, IEEE T MED IMAGING, V34, P179, DOI 10.1109/TMI.2014.2350539
   Munzenmayer C, 2009, METHOD INFORM MED, V48, P324, DOI 10.3414/ME9230
   Murray J. F., 2005, J MACH LEARN RES, V6
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Quellec G, 2012, MED IMAGE ANAL, V16, P1228, DOI 10.1016/j.media.2012.06.003
   Song XF, 2013, SIGNAL PROCESS, V93, P1, DOI 10.1016/j.sigpro.2012.07.029
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Tan T, 2013, IEEE T MED IMAGING, V32, P1698, DOI 10.1109/TMI.2013.2263389
   Tao QP, 2008, IEEE T PATTERN ANAL, V30, P2084, DOI 10.1109/TPAMI.2007.70846
   Torheim T, 2014, IEEE T MED IMAGING, V33, P1648, DOI 10.1109/TMI.2014.2321024
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang D, 2006, LECT NOTES COMPUT SC, V4212, P473
   Wang J., 2000, P 17 INT C MACH LEAR, P1119
   Wang J. Y., 2013, BMC BIOINFORMATICS, V14, P339
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang S, 2015, IEEE IMAGE PROC, P3072, DOI 10.1109/ICIP.2015.7351368
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Yang J., 2008, MILL MULTIPLE INSTAN
   Zhang D, 2010, PATTERN RECOGN, V43, P478, DOI 10.1016/j.patcog.2009.03.002
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang Q, 2002, ADV NEUR IN, V14, P1073
NR 61
TC 19
Z9 19
U1 1
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD NOV
PY 2016
VL 63
IS 11
BP 2347
EP 2358
DI 10.1109/TBME.2016.2530141
PG 12
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA DZ9ZL
UT WOS:000386242300014
PM 26890528
DA 2023-04-20
ER

PT J
AU Charisis, VS
   Hadjileontiadis, LJ
AF Charisis, Vasileios S.
   Hadjileontiadis, Leontios J.
TI Potential of hybrid adaptive filtering in inflammatory lesion detection
   from capsule endoscopy images
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Capsule endoscopy; Curvelet; Ulcer; Genetic algorithms; Crohn's disease
ID LACUNARITY ANALYSIS; TEXTURE; SYSTEM; ULCER
AB A new feature extraction technique for the detection of lesions created from mucosal inflammations in Crohn's disease, based on wireless capsule endoscopy (WCE) images processing is presented here. More specifically, a novel filtering process, namely Hybrid Adaptive Filtering (HAF), was developed for efficient extraction of lesion-related structural/textural characteristics from WCE images, by employing Genetic Algorithms to the Curvelet-based representation of images. Additionally, Differential Lacunarity (DLac) analysis was applied for feature extraction from the HAF-filtered images. The resulted scheme, namely HAF-DLac, incorporates support vector machines for robust lesion recognition performance. For the training and testing of HAFDLac, an 800-image database was used, acquired from 13 patients who undertook WCE examinations, where the abnormal cases were grouped into mild and severe, according to the severity of the depicted lesion, for a more extensive evaluation of the performance. Experimental results, along with comparison with other related efforts, have shown that the HAF-DLac approach evidently outperforms them in the field of WCE image analysis for automated lesion detection, providing higher classification results, up to 93.8% (accuracy), 95.2% (sensitivity), 92.4% (specificity) and 92.6% (precision). The promising performance of HAF-DLac paves the way for a complete computer-aided diagnosis system that could support physicians' clinical practice.
C1 [Charisis, Vasileios S.; Hadjileontiadis, Leontios J.] Aristotle Univ Thessaloniki, Dept Elect & Comp Engn, GR-54124 Thessaloniki, Greece.
   [Hadjileontiadis, Leontios J.] Khalifa Univ, Dept Elect & Comp Engn, POB 127788, Abu Dhabi, U Arab Emirates.
C3 Aristotle University of Thessaloniki; Khalifa University of Science &
   Technology
RP Hadjileontiadis, LJ (通讯作者)，Aristotle Univ Thessaloniki, Dept Elect & Comp Engn, SPBTU, Univ Campus,Bldg D,6th Floor, GR-54124 Thessaloniki, Greece.
EM leontios@auth.gr
RI Hadjileontiadis, Leontios/AAF-3448-2020
CR Candes E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Chen Y, 2012, P 20 ACM INT C MULT, P1181, DOI DOI 10.1145/2393347.2396413
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Cristianini N., 2000, INTRO SUPPORT VECTOR, DOI [DOI 10.1017/CBO9780511801389, 10.1017/CBO9780511801389]
   Dong P, 2000, INT J REMOTE SENS, V21, P3369, DOI 10.1080/014311600750019985
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Gevers T, 2007, IMAGE PROCESS SER, P203
   Girgis HZ, 2010, I S BIOMED IMAGING, P1373, DOI 10.1109/ISBI.2010.5490253
   Given Imaging, 2014, GIV IM
   Goldberg D.E., 1989, GENETIC ALGORITHMS S
   Hadjileontiadis LJ, 2009, IEEE T BIO-MED ENG, V56, P718, DOI 10.1109/TBME.2008.2011747
   Haneishi H, 2000, APPL OPTICS, V39, P6621, DOI 10.1364/AO.39.006621
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jebarani WSL, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P303, DOI 10.1109/ICSIPR.2013.6497945
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karargyris A, 2009, I S BIOMED IMAGING, P554, DOI 10.1109/ISBI.2009.5193107
   Koulaouzidis A., KID KOULAOUZIDIS IAK
   Krystallis C, 2011, DIGEST LIVER DIS, V43, P953, DOI 10.1016/j.dld.2011.07.018
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Kyriakos N, 2012, EUR J GASTROEN HEPAT, V24, P1276, DOI 10.1097/MEG.0b013e32835718d2
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Maieron A, 2004, ENDOSCOPY, V36, P864, DOI 10.1055/s-2004-825852
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Plotnick RE, 1996, PHYS REV E, V53, P5461, DOI 10.1103/PhysRevE.53.5461
   PLOTNICK RE, 1993, LANDSCAPE ECOL, V8, P201, DOI 10.1007/BF00125351
   Rondonotti E, 2010, EUR J GASTROEN HEPAT, V22, P1380, DOI 10.1097/MEG.0b013e3283352ced
   Sae Hwang, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P320, DOI 10.1007/978-3-642-24031-7_32
   Signorelli C, 2005, ENDOSCOPY, V37, P1170, DOI 10.1055/s-2005-870410
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Szczypinski PM, 2009, COMPUT METH PROG BIO, V94, P66, DOI 10.1016/j.cmpb.2008.08.005
   Tasic J. F., 2003, EUR 2003, V1, P1, DOI DOI 10.1109/EURC0N.2003.1248032]
   Yu LC, 2012, INT C PATT RECOG, P45
   Zaia A, 2006, IEEE T INF TECHNOL B, V10, P484, DOI 10.1109/TITB.2006.872078
NR 43
TC 22
Z9 23
U1 0
U2 9
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD OCT 21
PY 2016
VL 22
IS 39
BP 8641
EP 8657
DI 10.3748/wjg.v22.i39.8641
PG 17
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA EA4QD
UT WOS:000386597500001
PM 27818583
OA Green Submitted, hybrid, Green Published
DA 2023-04-20
ER

PT J
AU Mesejo, P
   Pizarro, D
   Abergel, A
   Rouquette, O
   Beorchia, S
   Poincloux, L
   Bartoli, A
AF Mesejo, Pablo
   Pizarro, Daniel
   Abergel, Armand
   Rouquette, Olivier
   Beorchia, Sylvain
   Poincloux, Laurent
   Bartoli, Adrien
TI Computer-Aided Classification of Gastrointestinal Lesions in Regular
   Colonoscopy
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Colonoscopy; colorectal cancer; computer-aided decision support system;
   ensemble classifiers; structure-from-motion; tissue classification;
   virtual biopsy
ID SESSILE SERRATED ADENOMAS; RANDOM SUBSPACE METHOD; COLORECTAL-CANCER; CT
   COLONOGRAPHY; POLYP DETECTION; I-SCAN; ENDOSCOPY; TEXTURE; SYSTEM;
   CHROMOENDOSCOPY
AB We have developed a technique to study how good computers can be at diagnosing gastrointestinal lesions from regular (white light and narrow banded) colonoscopic videos compared to two levels of clinical knowledge (expert and beginner). Our technique includes a novel tissue classification approach which may save clinician's time by avoiding chromoendoscopy, a time-consuming staining procedure using indigo carmine. Our technique also discriminates the severity of individual lesions in patients with many polyps, so that the gastroenterologist can directly focus on those requiring polypectomy. Technically, we have designed and developed a framework combining machine learning and computer vision algorithms, which performs a virtual biopsy of hyperplastic lesions, serrated adenomas and adenomas. Serrated adenomas are very difficult to classify due to their mixed/hybrid nature and recent studies indicate that they can lead to colorectal cancer through the alternate serrated pathway. Our approach is the first step to avoid systematic biopsy for suspected hyperplastic tissues. We also propose a database of colonoscopic videos showing gastrointestinal lesions with ground truth collected from both expert image inspection and histology. We not only compare our system with the expert predictions, but we also study if the use of 3D shape features improves classification accuracy, and compare our technique's performance with three competitor methods.
C1 [Mesejo, Pablo; Pizarro, Daniel; Bartoli, Adrien] Univ Auvergne, CNRS, ISIT UMR 6284, F-63000 Clermont Ferrand, France.
   [Mesejo, Pablo] INRIA Grenoble Rhone Alpes, LJK, F-38330 Grenoble, France.
   [Pizarro, Daniel] Univ Alcala de Henares, Dept Elect, E-28871 Alcala De Henares, Spain.
   [Abergel, Armand; Rouquette, Olivier; Poincloux, Laurent] CHU Estaing, Dept Gastroenterol, F-63100 Clermont Ferrand, France.
   [Beorchia, Sylvain] Clin Sauvegarde, F-69009 Lyon, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Clermont
   Auvergne (UCA); Universidad de Alcala; CHU Clermont Ferrand
RP Mesejo, P (通讯作者)，Univ Auvergne, CNRS, ISIT UMR 6284, F-63000 Clermont Ferrand, France.
EM pablomesejo@gmail.com
RI Mesejo, Pablo/K-4589-2014
OI Mesejo, Pablo/0000-0001-9955-2101; Pizarro, Daniel/0000-0003-0622-4884
FU French National Research Agency through the Syseo Project
   [ANR-10-TECS-0005]
FX This work has been supported by the French National Research Agency
   through the Syseo Project (ANR-10-TECS-0005). Asterisk indicates
   corresponding author.
CR Alcantarilla PF, 2013, IEEE ENG MED BIO, P7346, DOI 10.1109/EMBC.2013.6611255
   Allwein E. L., 2001, Journal of Machine Learning Research, V1, P113, DOI 10.1162/15324430152733133
   Aman Javed M., 2010, Virtual Colonoscopy and Abdominal Imaging. Computational Challenges and Clinical Opportunities. Second International Workshop Held in Conjunction with MICCAI 2010. Revised Selected Papers, P15, DOI 10.1007/978-3-642-25719-3_3
   [Anonymous], 2012, EST CANC INC MORT PR
   Arnold Mirko, 2010, J IMAGE VIDEO PROCES, V2010
   Artusi A, 2011, COMPUT GRAPH FORUM, V30, P2208, DOI 10.1111/j.1467-8659.2011.01971.x
   Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169
   Bauer Valerie P, 2008, Clin Colon Rectal Surg, V21, P273, DOI 10.1055/s-0028-1089942
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Bertoni A, 2005, NEUROCOMPUTING, V63, P535, DOI 10.1016/j.neucom.2004.07.007
   Bianconi F, 2014, PATTERN RECOGN LETT, V48, P34, DOI 10.1016/j.patrec.2014.04.006
   Bishop C. M., 2006, PATTERN RECOGNITION
   Blake A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P394, DOI 10.1109/CCV.1988.590016
   Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717
   Bosman FT, 2010, WHO CLASSIFICATION T
   Bouguet J.-Y., CAMERA CALIBRATION T
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burnett-Hartman AN, 2013, AM J EPIDEMIOL, V177, P625, DOI 10.1093/aje/kws282
   Chadebecq F, 2013, I S BIOMED IMAGING, P354
   Chowdhury TA, 2006, COMPUT MED IMAG GRAP, V30, P427, DOI 10.1016/j.compmedimag.2006.06.004
   Cignoni P., 2008, ERCIM NEWS, V73, p[45, 6], DOI DOI 10.2312/L0CALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPC0NF2008/129-136
   Coimbra M., 2005, 2nd European Workshop on the Integration of Knowledge, Semantics and Digital Media Technology (EWIMT 2005), P105, DOI 10.1049/ic.2005.0718
   Einspahr JG, 1997, CANCER EPIDEM BIOMAR, V6, P37
   Engelhardt S., 2010, BILDVERARBEITUNG MED, V574, P350
   Farris AB, 2008, AM J SURG PATHOL, V32, P30, DOI 10.1097/PAS.0b013e318093e40a
   Fleming RW, 2004, J VISION, V4, P798, DOI 10.1167/4.9.10
   Friedewald SM, 2014, JAMA-J AM MED ASSOC, V311, P2499, DOI 10.1001/jama.2014.6095
   Gross SA, 2006, AM J GASTROENTEROL, V101, P2717, DOI 10.1111/j.1572-0241.2006.00923.x
   Hafner M, 2012, COMPUT METH PROG BIO, V107, P565, DOI 10.1016/j.cmpb.2011.12.012
   HAFNER M, 2012, P INT S COMP BAS MED, P1, DOI DOI 10.1109/CBMS.2012.6266355
   Hart AR, 1998, GUT, V43, P229, DOI 10.1136/gut.43.2.229
   Hartley R., 2004, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hasegawa S, 2011, ONCOL LETT, V2, P785, DOI 10.3892/ol.2011.341
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hoffman A, 2010, ENDOSCOPY, V42, P827, DOI 10.1055/s-0030-1255713
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Khan R, 2013, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR.2013.369
   Kodashima S, 2010, WORLD J GASTROENTERO, V16, P1043, DOI 10.3748/wjg.v16.i9.1043
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Kuncheva L. I., 2004, COMBINING PATTERN CL
   Kuncheva LI, 2003, PATTERN ANAL APPL, V6, P22, DOI 10.1007/s10044-002-0173-7
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Kuncheva LI, 2010, MAGN RESON IMAGING, V28, P583, DOI 10.1016/j.mri.2009.12.021
   Lai C, 2006, PATTERN RECOGN LETT, V27, P1067, DOI 10.1016/j.patrec.2005.12.018
   Lambert R, 2009, GASTROINTEST ENDOSC, V70, P1182, DOI 10.1016/j.gie.2009.09.015
   Lee JG, 2011, COMPUT BIOL MED, V41, P790, DOI 10.1016/j.compbiomed.2011.06.015
   Li WQ, 2015, MED IMAGE ANAL, V26, P57, DOI 10.1016/j.media.2015.08.002
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Maenpaa T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   Manivannan S, 2013, I S BIOMED IMAGING, P644
   Meseguer P, 2012, PROG ARTIF INTELL, V1, P25, DOI 10.1007/s13748-011-0006-2
   MUTO T, 1975, CANCER, V36, P2251, DOI 10.1002/cncr.2820360944
   Nanda N.C, 2013, COMPREHENSIVE TXB EC, V1
   Nanda N.C., 2013, COMPREHENSIVE TXB EC, V2
   Nava R., 2011, CORR
   Oka K, 2014, WORLD J GASTROENTERO, V20, P4050, DOI 10.3748/wjg.v20.i14.4050
   Parot V, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.7.076017
   Parra-Blanco A, 2009, WORLD J GASTROENTERO, V15, P5266, DOI 10.3748/wjg.15.5266
   Pittayanon R, 2012, WORLD J GASTRO ENDOS, V4, P472, DOI 10.4253/wjge.v4.i10.472
   Rees J, 2008, MED IMAGE UNDERSTAND
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Riaz F, 2012, IEEE T BIO-MED ENG, V59, P2893, DOI 10.1109/TBME.2012.2212440
   Riaz F, 2011, LECT NOTES COMPUT SC, V6669, P709
   Rustamov R. M., 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Segnan N, 2010, EUROPEAN GUIDELINES
   Shi R, 2006, RADIOLOGY, V239, P768, DOI 10.1148/radiol.2393050418
   Shuttleworth JK, 2002, IEEE CCEC 2002: CANADIAN CONFERENCE ON ELECTRCIAL AND COMPUTER ENGINEERING, VOLS 1-3, CONFERENCE PROCEEDINGS, P1134, DOI 10.1109/CCECE.2002.1013107
   Snavely N., BUNDLER STRUCTURE MO
   Soetikno RM, 2008, JAMA-J AM MED ASSOC, V299, P1027, DOI 10.1001/jama.299.9.1027
   Sonnenberg A, 2008, GASTROINTEST ENDOSC, V67, P489, DOI 10.1016/j.gie.2007.08.041
   Spring KJ, 2006, GASTROENTEROLOGY, V131, P1400, DOI 10.1053/j.gastro.2006.08.038
   Stefanou S, 2012, LECT NOTES COMPUT SC, V7431, P220, DOI 10.1007/978-3-642-33179-4_22
   Stock C, 2010, ENDOSCOPY, V42, P546, DOI 10.1055/s-0029-1244127
   Summers RM, 2010, RADIOLOGY, V255, P707, DOI 10.1148/radiol.10090877
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Takai K, 2011, J NEUROSURG-SPINE, V15, P654, DOI 10.3171/2011.8.SPINE11155
   Tamaki T, 2011, LECT NOTES COMPUT SC, V6493, P452
   Torlakovic EE, 2008, AM J SURG PATHOL, V32, P21, DOI 10.1097/PAS.0b013e318157f002
   Ugolotti R, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074481
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wehrmann K, 2002, ENDOSCOPY, V34, P905, DOI 10.1055/s-2002-35302
   Yao JH, 2009, PATTERN RECOGN, V42, P1029, DOI 10.1016/j.patcog.2008.09.034
   Young J, 2007, GUT, V56, P1453, DOI 10.1136/gut.2007.126870
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   ZISSERMAN A, 1989, IMAGE VISION COMPUT, V7, P38, DOI 10.1016/0262-8856(89)90018-8
NR 93
TC 96
Z9 102
U1 3
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD SEP
PY 2016
VL 35
IS 9
BP 2051
EP 2063
DI 10.1109/TMI.2016.2547947
PG 13
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA DY6VK
UT WOS:000385266800006
PM 28005009
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Facciorusso, A
   Di Maso, M
   Serviddio, G
   Vendemiale, G
   Spada, C
   Costamagna, G
   Muscatiello, N
AF Facciorusso, Antonio
   Di Maso, Marianna
   Serviddio, Gaetano
   Vendemiale, Gianluigi
   Spada, Cristiano
   Costamagna, Guido
   Muscatiello, Nicola
TI Factors Associated With Recurrence of Advanced Colorectal Adenoma After
   Endoscopic Resection
SO CLINICAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE ACA; Machine Learning; CRC; Colon Cancer
ID COLONOSCOPIC POLYPECTOMY; RISK STRATIFICATION; CANCER; SURVEILLANCE;
   COLON; INJECTION
AB BACKGROUND & AIMS: Studies have identified risk factors for recurrence of advanced colorectal adenoma (ACA) after polypectomy, but the relative importance and interaction of these risk factors, and their potential impact on surveillance recommendations, are unclear. We aimed to develop a model to identify ACA features associated with risk of recurrence after polypectomy.
   METHODS: In a retrospective study, we collected data from 3360 patients who underwent colonoscopy with polypectomy at University of Foggia from 2004 through 2008 and identified 746 patients with 1017 ACAs. We performed recursive partitioning analysis to identify factors associated with recurrence of ACA within 3 years after polypectomy.
   RESULTS: Median ACA size was 16 mm (range, 8-34 mm) and median number was 1.5 (range, 1-2). Pedunculated, sessile, and nonpolypoid lesions accounted for 41.3%, 39.4%, and 19.3% of ACAs detected, respectively. Factors independently associated with local recurrence of ACA and metachronous distant polyps within 3 years after polypectomy included size and number of ACAs and grade of dysplasia. The recurrence rate was 4.2% in patients with a single ACA <= 15 mm without high-grade dysplasia (HGD), 21.3% in patients with HGD <= 15 mm, ACA without HGD >15 mm, or multiple ACAs without HGD <= 15 mm, and 57.9% in patients with HGD >15 mm.
   CONCLUSIONS: In this retrospective analysis of 746 patients with ACA who underwent polypectomy and surveillance colonoscopy within 3 years, the recurrence rate was highest in those with HGD >= 15 mm. These patients might benefit from more intensive surveillance, whereas patients with a single ACA without HGD <= 15 mm are at lower risk for and could be considered for longer follow-up intervals.
C1 [Facciorusso, Antonio; Di Maso, Marianna; Muscatiello, Nicola] Univ Foggia, Dept Med Sci, Gastroenterol Unit, Foggia, Italy.
   [Serviddio, Gaetano; Vendemiale, Gianluigi] Univ Foggia, Internal Med Unit, Foggia, Italy.
   [Spada, Cristiano; Costamagna, Guido] Catholic Univ, Digest Endoscop Unit, Rome, Italy.
C3 University of Foggia; University of Foggia; Catholic University of the
   Sacred Heart; IRCCS Policlinico Gemelli
RP Facciorusso, A (通讯作者)，Univ Foggia, Gastroenterol Unit, Dept Med Sci, AOU Osped Riuniti, Viale Pinto 1, I-71100 Foggia, Italy.
EM antonio.facciorusso@virgilio.it
RI Facciorusso, Antonio/AAA-5966-2019; Spada, Cristiano/AAO-8852-2020;
   serviddio, gaetano/C-7629-2011
OI Spada, Cristiano/0000-0002-5692-0960; serviddio,
   gaetano/0000-0002-6424-7841
CR ATKIN WS, 1992, NEW ENGL J MED, V326, P658, DOI 10.1056/NEJM199203053261002
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 1984, CLASSIFICATION REGRE, DOI [10.1002/widm.8, DOI 10.1002/WIDM.8]
   Buchner AM, 2012, GASTROINTEST ENDOSC, V76, P255, DOI 10.1016/j.gie.2012.02.060
   Chung SJ, 2011, GUT, V60, P1537, DOI 10.1136/gut.2010.232876
   Dobrowolski S, 2004, SURG ENDOSC, V18, P990, DOI 10.1007/s00464-003-9214-6
   Ell C, 2008, AM J GASTROENTEROL, V103, P883, DOI 10.1111/j.1572-0241.2007.01708.x
   Facciorusso A, 2015, GASTROINTEST ENDOSC, V82, P350, DOI 10.1016/j.gie.2015.01.003
   Facciorusso A, 2015, WORLD J GASTROENTERO, V21, P5149, DOI 10.3748/wjg.v21.i17.5149
   Levin B, 2008, GASTROENTEROLOGY, V134, P1570, DOI 10.1053/j.gastro.2008.02.002
   Lieberman DA, 2007, GASTROENTEROLOGY, V133, P1077, DOI 10.1053/j.gastro.2007.07.006
   Martinez ME, 2009, GASTROENTEROLOGY, V136, P832, DOI 10.1053/j.gastro.2008.12.007
   Martinez ME, 2001, GASTROENTEROLOGY, V120, P1077, DOI 10.1053/gast.2001.23247
   MUTO T, 1975, CANCER, V36, P2251, DOI 10.1002/cncr.2820360944
   Seo JY, 2015, GASTROINTEST ENDOSC, V81, P655, DOI 10.1016/j.gie.2014.09.064
   WINAWER SJ, 1993, NEW ENGL J MED, V328, P901, DOI 10.1056/NEJM199304013281301
   Yang G, 1998, J NATL CANCER I, V90, P1661, DOI 10.1093/jnci/90.21.1661
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 18
TC 38
Z9 41
U1 0
U2 4
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1542-3565
EI 1542-7714
J9 CLIN GASTROENTEROL H
JI Clin. Gastroenterol. Hepatol.
PD AUG
PY 2016
VL 14
IS 8
BP 1148
EP +
DI 10.1016/j.cgh.2016.03.017
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA DT8BY
UT WOS:000381714900019
PM 27005802
DA 2023-04-20
ER

PT J
AU Liu, DY
   Gan, T
   Rao, NN
   Xing, YW
   Zheng, J
   Li, S
   Luo, CS
   Zhou, ZJ
   Wan, YL
AF Liu, Ding-Yun
   Gan, Tao
   Rao, Ni-Ni
   Xing, Yao-Wen
   Zheng, Jie
   Li, Sang
   Luo, Cheng-Si
   Zhou, Zhong-Jun
   Wan, Yong-Li
TI Identification of lesion images from gastrointestinal endoscope based on
   feature extraction of combinational methods with and without learning
   process
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Gastrointestinal endoscopic image; Joint diagonalisation; Principal
   component analysis; Lesion identification
ID CLASSIFICATION
AB The gastrointestinal endoscopy in this study refers to conventional gastroscopy and wireless capsule endoscopy (WCE). Both of these techniques produce a large number of images in each diagnosis. The lesion detection done by hand from the images above is time consuming and inaccurate. This study designed a new computer-aided method to detect lesion images. We initially designed an algorithm named joint diagonalisation principal component analysis (JDPCA), in which there are no approximation, iteration or inverting procedures. Thus, JDPCA has a low computational complexity and is suitable for dimension reduction of the gastrointestinal endoscopic images. Then, a novel image feature extraction method was established through combining the algorithm of machine learning based on JDPCA and conventional feature extraction algorithm without learning. Finally, a new computer-aided method is proposed to identify the gastrointestinal endoscopic images containing lesions. The clinical data of gastroscopic images and WCE images containing the lesions of early upper digestive tract cancer and small intestinal bleeding, which consist of 1330 images from 291 patients totally, were used to confirm the validation of the proposed method. The experimental results shows that, for the detection of early oesophageal cancer images, early gastric cancer images and small intestinal bleeding images, the mean values of accuracy of the proposed method were 90.75%, 90.75% and 94.34%, with the standard deviations (SDs) of 0.0426, 0.0334 and 0.0235, respectively. The areas under the curves (ADCs) were 0.9471, 0.9532 and 0.9776, with the SDs of 0.0296, 0.0285 and 0.0172, respectively. Compared with the traditional related methods, our method showed a better performance. It may therefore provide worthwhile guidance for improving the efficiency and accuracy of gastrointestinal disease diagnosis and is a good prospect for clinical application. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Liu, Ding-Yun; Rao, Ni-Ni; Xing, Yao-Wen; Zheng, Jie; Li, Sang; Luo, Cheng-Si; Zhou, Zhong-Jun; Wan, Yong-Li] Univ Elect Sci & Technol China, Key Lab Neuroinformat, Minist Educ, Chengdu, Peoples R China.
   [Liu, Ding-Yun; Rao, Ni-Ni; Xing, Yao-Wen; Zheng, Jie; Li, Sang; Luo, Cheng-Si; Zhou, Zhong-Jun; Wan, Yong-Li] Univ Elect Sci & Technol China, Ctr Informat BioMed, Chengdu, Peoples R China.
   [Liu, Ding-Yun; Rao, Ni-Ni; Xing, Yao-Wen; Zheng, Jie; Li, Sang; Luo, Cheng-Si; Zhou, Zhong-Jun; Wan, Yong-Li] Univ Elect Sci & Technol China, Dept Biomed Engn, Chengdu, Peoples R China.
   [Gan, Tao] Sichuan Univ, Digest Endoscop Ctr, West China Hosp, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; University of Electronic
   Science & Technology of China; Sichuan University
RP Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Key Lab Neuroinformat, Minist Educ, Chengdu, Peoples R China.; Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Ctr Informat BioMed, Chengdu, Peoples R China.; Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Dept Biomed Engn, Chengdu, Peoples R China.
EM raonn@uestc.edu.cn
FU NSFC (National Natural Science Foundation of China) [81171411]; Sichuan
   Science and Technology Support Program [2015SZ0191]
FX This work was supported by NSFC (National Natural Science Foundation of
   China, Grant No. 81171411) and Sichuan Science and Technology Support
   Program (Grant No. 2015SZ0191).
CR Ammar M, 2013, 2013 8TH INTERNATIONAL WORKSHOP ON SYSTEMS, SIGNAL PROCESSING AND THEIR APPLICATIONS (WOSSPA), P50, DOI 10.1109/WoSSPA.2013.6602335
   Chang C., 2007, LIBSVM LIB SUPPORT V
   Chen Y., 2012, DIAGN THER ENDOSC
   Fisher M., 2013, COLOR MED IMAGE ANAL, P129
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hegenbart S, 2013, MED IMAGE ANAL, V17, P458, DOI 10.1016/j.media.2013.02.001
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Jiang XD, 2011, IEEE SIGNAL PROC MAG, V28, P16, DOI 10.1109/MSP.2010.939041
   Jiang XD, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 1, P1, DOI 10.1109/ICCSIT.2009.5235014
   Jiang XD, 2009, IEEE T PATTERN ANAL, V31, P931, DOI 10.1109/TPAMI.2008.258
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Liu DY, 2015, J MED IMAG HEALTH IN, V5, P296, DOI 10.1166/jmihi.2015.1390
   Munzenmayer C, 2009, METHOD INFORM MED, V48, P324, DOI 10.3414/ME9230
   Pass G., 1997, P 4 ACM INT C MULT, P65, DOI DOI 10.1145/244130.244148
   Rui Yao, 2010, 2010 International Conference of Medical Image Analysis and Clinical Application (MIACA), P38, DOI 10.1109/MIACA.2010.5528397
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sommen F.V.D., 2013, SPIE MED IMAGING
   Sun Kai, 2011, 2011 IEEE INT WORKSH, P1
   Tao Xin-min, 2011, Control and Decision, V26, P1535
   Tong Z., 2011, THESIS
   Tsai W-J, 2014, J SOFTW ENG APPL, DOI [10.4236/jsea.2014.75039, DOI 10.4236/JSEA.2014.75039]
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Zhang S, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P2374, DOI 10.1109/ICMLC.2009.5212217
   Zhang W., 2011, THESIS
NR 29
TC 49
Z9 52
U1 1
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD AUG
PY 2016
VL 32
BP 281
EP 294
DI 10.1016/j.media.2016.04.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA DQ1OC
UT WOS:000378969300020
PM 27236223
DA 2023-04-20
ER

PT J
AU Shrestha, R
   Mohammed, SK
   Hasan, MM
   Zhang, XC
   Wahid, KA
AF Shrestha, Ravi
   Mohammed, Shahed K.
   Hasan, Md. Mehedi
   Zhang, Xuechao
   Wahid, Khan A.
TI Automated Adaptive Brightness in Wireless Capsule Endoscopy Using Image
   Segmentation and Sigmoid Function
SO IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS
LA English
DT Article; Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 24-27, 2015
CL Lisbon, PORTUGAL
SP IEEE
DE Adaptive illumination; automatic brightness control; pulse width
   modulation; sigmoid function; wireless capsule endoscopy
AB Wireless capsule endoscopy (WCE) plays an important role in the diagnosis of gastrointestinal (GI) diseases by capturing images of human small intestine. Accurate diagnosis of endoscopic images depends heavily on the quality of captured images. Along with image and frame rate, brightness of the image is an important parameter that influences the image quality which leads to the design of an efficient illumination system. Such design involves the choice and placement of proper light source and its ability to illuminate GI surface with proper brightness. Light emitting diodes (LEDs) are normally used as sources where modulated pulses are used to control LED's brightness. In practice, instances like under-and over-illumination are very common in WCE, where the former provides dark images and the later provides bright images with high power consumption. In this paper, we propose a low-power and efficient illumination system that is based on an automated brightness algorithm. The scheme is adaptive in nature, i.e., the brightness level is controlled automatically in real-time while the images are being captured. The captured images are segmented into four equal regions and the brightness level of each region is calculated. Then an adaptive sigmoid function is used to find the optimized brightness level and accordingly a new value of duty cycle of the modulated pulse is generated to capture future images. The algorithm is fully implemented in a capsule prototype and tested with endoscopic images. Commercial capsules like Pillcam and Mirocam were also used in the experiment. The results show that the proposed algorithm works well in controlling the brightness level accordingly to the environmental condition, and as a result, good quality images are captured with an average of 40% brightness level that saves power consumption of the capsule.
C1 [Shrestha, Ravi; Mohammed, Shahed K.; Hasan, Md. Mehedi; Zhang, Xuechao; Wahid, Khan A.] Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK S7N 5A9, Canada.
C3 University of Saskatchewan
RP Wahid, KA (通讯作者)，Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK S7N 5A9, Canada.
EM khan.wahid@usask.ca
OI Shrestha, Ravi/0000-0003-2324-7658
CR [Anonymous], 2015, ATLAS GASTROINTESTIN
   [Anonymous], 2015, TECHNICAL UPDATE VID
   [Anonymous], 2015, PENTAX MED I SCAN MI
   Filip Dobromir, 2011, INT J INFORM TECHNOL, V5, P3
   Imtiaz MS, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/607407
   Imtiaz MS, 2014, IEEE ENG MED BIO, P3905, DOI 10.1109/EMBC.2014.6944477
   Khan T. H., 2014, SENSOR ACTUAT A-PHYS, V221, P77
   Lee CH, 2012, LECT NOTES ENG COMP, P746
   Mang OY, 2007, P SOC PHOTO-OPT INS, V6430, pV4300, DOI 10.1117/12.699763
   Pan GB, 2012, GASTROENT RES PRACT, V2012, DOI 10.1155/2012/841691
   Roh Y. J., 2012, P SOC PHOTO-OPT INS, V4902, P463
   유지현, 2012, [Journal of Internet Computing and Services, 인터넷정보학회논문지], V13, P61, DOI 10.7472/jksii.2012.13.3.61
   Shen C, 2006, INT EL DEVICES MEET, P69
   Shrestha R, 2015, IEEE INT SYMP CIRC S, P778, DOI 10.1109/ISCAS.2015.7168749
   Sousa R. M., P SPIE, V9481
   Turcza P, 2013, IEEE J BIOMED HEALTH, V17, P1046, DOI 10.1109/JBHI.2013.2266101
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Xu X, 2011, SENSORS-BASEL, V11, P8281, DOI 10.3390/s110908281
NR 18
TC 8
Z9 8
U1 0
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1932-4545
EI 1940-9990
J9 IEEE T BIOMED CIRC S
JI IEEE Trans. Biomed. Circuits Syst.
PD AUG
PY 2016
VL 10
IS 4
SI SI
BP 884
EP 892
DI 10.1109/TBCAS.2016.2546838
PG 9
WC Engineering, Biomedical; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA DT4IA
UT WOS:000381442200010
PM 27333609
DA 2023-04-20
ER

PT J
AU Serej, ND
   Ahmadian, A
   Kasaei, S
   Sadrehosseini, SM
   Farnia, P
AF Serej, Nasim Dadashi
   Ahmadian, Alireza
   Kasaei, Shohreh
   Sadrehosseini, Seyed Musa
   Farnia, Parastoo
TI A robust keypoint extraction and matching algorithm based on wavelet
   transform and information theory for point-based registration in
   endoscopic sinus cavity data
SO SIGNAL IMAGE AND VIDEO PROCESSING
LA English
DT Article
DE Endoscopic sinus images; Repeatable and reproducible keypoints; DTCWT;
   NMI; Modified ICP; Gaussian weighted function
AB Feature extraction is one of the most important steps in processing endoscopic data. The extracted features should be invariant to image scale and rotation to provide a robust matching across a substantial range of affine distortions and changes in 3D space. In this study, a method is proposed on the basis of the dual-tree complex wavelet transform. First, a map is estimated for each scale, and then a Gaussian weighted additive function (GWAF) is determined. Keypoints are selected from local peaks of GWAF. The matching and registration are performed by applying normalized mutual information and our modified iterative closest point. Results are reported in terms of robustness to rotation, noise, color, brightness, number of keypoints, index of matching and execution time for the building, standard clinical and phantom sinus datasets. Although the results are comparable to that of the speeded up robust features, scale invariant feature transform, and the Harris method, they are more robust to the variations in rotation, brightness, color, and noise than those obtained from other methods. Registration errors obtained for consequent frames for building, clinical and phantom datasets are 0.97, 1.46 and 1.1 mm, respectively.
C1 [Serej, Nasim Dadashi; Ahmadian, Alireza; Farnia, Parastoo] Univ Tehran Med Sci, Sch Med, Med Phys & Biomed Engn Dept, Tehran, Iran.
   [Serej, Nasim Dadashi; Ahmadian, Alireza; Farnia, Parastoo] Univ Tehran Med Sci, Res Ctr Biomed Technol & Robot RCBTR, Tehran, Iran.
   [Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
   [Sadrehosseini, Seyed Musa] Univ Tehran Med Sci, Skull Base Ctr, Imam Khomeini Hosp Complex, Tehran, Iran.
C3 Tehran University of Medical Sciences; Tehran University of Medical
   Sciences; Sharif University of Technology; Tehran University of Medical
   Sciences
RP Ahmadian, A (通讯作者)，Univ Tehran Med Sci, Sch Med, Med Phys & Biomed Engn Dept, Tehran, Iran.; Ahmadian, A (通讯作者)，Univ Tehran Med Sci, Res Ctr Biomed Technol & Robot RCBTR, Tehran, Iran.
EM dadashi@razi.tums.ac.ir; ahmadian@sina.tums.ac.ir; skasaei@sharif.edu;
   sadrehosseini@gmail.com; parastoo.farnia@razi.tums.ac.ir
RI Kasaei, Shohreh/AAD-5618-2019; Farnia, Parastoo/L-4094-2018; Serej,
   Nassim Dadashi/N-6508-2018
OI Kasaei, Shohreh/0000-0002-3831-0878; Serej, Nassim
   Dadashi/0000-0002-2898-1926; Farnia, Parastoo/0000-0002-7554-5545
FU Tehran University of Medical Sciences & health Services grant
   [90-04-30-15836]; Research Center for Biomedical Technology & Robotics,
   RCBTR
FX This research has been supported by Tehran University of Medical
   Sciences & health Services grant 90-04-30-15836. Also, the authors would
   like to thank Research Center for Biomedical Technology & Robotics,
   RCBTR for supporting and providing an environment to carry on this
   project.
CR Abretske D., 2009, WORKSH APPL COMP VIS, P1
   Ahmadian A, 2013, INT J IMAG SYST TECH, V23, P294, DOI 10.1002/ima.22064
   [Anonymous], 3 D DIGITAL IMAGING
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bendale P., 2010, P BRIT MACH VIS C
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Estevez PA, 2009, IEEE T NEURAL NETWOR, V20, P189, DOI 10.1109/TNN.2008.2005601
   Fauqueur J., 2006, INT C IM PROC
   Harris C, 1988, P 4 ALV VIS C, V15, P10
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Loupias E., 2000, IEEE INT C IM PROC
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mirota DJ, 2013, IEEE T MED IMAGING, V32, P1215, DOI 10.1109/TMI.2013.2243464
   Mirota DJ, 2011, PROC SPIE, V7964, DOI 10.1117/12.877803
   Nabatchian A, 2011, PATTERN RECOGN, V44, P2576, DOI 10.1016/j.patcog.2011.03.012
   Nazem F, 2014, INT J COMPUT ASS RAD, V9, P39, DOI 10.1007/s11548-013-0907-6
   Neumann J, 2005, INT J WAVELETS MULTI, V3, P43, DOI 10.1142/S0219691305000749
   Papademetris X, 2004, LECT NOTES COMPUT SC, V3216, P763
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Serej ND, 2015, INT J COMPUT ASS RAD, V10, P541, DOI 10.1007/s11548-014-1075-z
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Thormahlen T, 2002, FALK SYMP, V124, P199
   Wells W M 3rd, 1996, Med Image Anal, V1, P35
NR 25
TC 4
Z9 4
U1 1
U2 25
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1863-1703
EI 1863-1711
J9 SIGNAL IMAGE VIDEO P
JI Signal Image Video Process.
PD JUL
PY 2016
VL 10
IS 5
BP 983
EP 991
DI 10.1007/s11760-015-0849-2
PG 9
WC Engineering, Electrical & Electronic; Imaging Science & Photographic
   Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Imaging Science & Photographic Technology
GA DO7AP
UT WOS:000377934900024
DA 2023-04-20
ER

PT J
AU van der Sommen, F
   Zinger, S
   Curvers, WL
   Bisschops, R
   Pech, O
   Weusten, BLAM
   Bergman, JJGHM
   de With, PHN
   Schoon, EJ
AF van der Sommen, Fons
   Zinger, Svitlana
   Curvers, Wouter L.
   Bisschops, Raf
   Pech, Oliver
   Weusten, Bas L. A. M.
   Bergman, Jacques J. G. H. M.
   de With, Peter H. N.
   Schoon, Erik J.
TI Computer-aided detection of early neoplastic lesions in Barrett's
   esophagus
SO ENDOSCOPY
LA English
DT Article
ID ADENOCARCINOMA; CLASSIFICATION; VIDEO
AB Background and study aims: Early neoplasia in Barrett's esophagus is difficult to detect and often overlooked during Barrett's surveillance. An automatic detection system could be beneficial, by assisting endoscopists with detection of early neoplastic lesions. The aim of this study was to assess the feasibility of a computer system to detect early neoplasia in Barrett's esophagus.
   Patients and methods: Based on 100 images from 44 patients with Barrett's esophagus, a computer algorithm, which employed specific texture, color filters, and machine learning, was developed for the detection of early neoplastic lesions in Barrett's esophagus. The evaluation by one endoscopist, who extensively imaged and endoscopically removed all early neoplastic lesions and was not blinded to the histological outcome, was considered the gold standard. For external validation, four international experts in Barrett's neoplasia, who were blinded to the pathology results, reviewed all images.
   Results: The system identified early neoplastic lesions on a per-image analysis with a sensitivity and specificity of 0.83. At the patient level, the system achieved a sensitivity and specificity of 0.86 and 0.87, respectively. A trade-off between the two performance metrics could be made by varying the percentage of training samples that showed neoplastic tissue.
   Conclusion: The automated computer algorithm developed in this study was able to identify early neoplastic lesions with reasonable accuracy, suggesting that automated detection of early neoplasia in Barrett's esophagus is feasible. Further research is required to improve the accuracy of the system and prepare it for real-time operation, before it can be applied in clinical practice.
C1 [van der Sommen, Fons; Zinger, Svitlana; de With, Peter H. N.] Eindhoven Univ Technol, Dept Elect Engn, POB 513, NL-5600 MB Eindhoven, Netherlands.
   [Curvers, Wouter L.; Schoon, Erik J.] Catharina Hosp, Dept Gastroenterol, Eindhoven, Netherlands.
   [Bisschops, Raf] Katholieke Univ Leuven, Dept Gastroenterol, Univ Hosp Leuven, Leuven, Belgium.
   [Pech, Oliver] St John God Hosp, Gastroenterol & Intervent Endoscopy, Regensburg, Germany.
   [Weusten, Bas L. A. M.] St Antonius Hosp, Dept Gastroenterol, Nieuwegein, Netherlands.
   [Bergman, Jacques J. G. H. M.] Amsterdam Med Ctr, Dept Gastroenterol, Amsterdam, Netherlands.
C3 Eindhoven University of Technology; Catharina Hospital; KU Leuven;
   University Hospital Leuven; St. Antonius Hospital Utrecht; University of
   Amsterdam; Academic Medical Center Amsterdam
RP van der Sommen, F (通讯作者)，Eindhoven Univ Technol, Dept Elect Engn, POB 513, NL-5600 MB Eindhoven, Netherlands.
EM f.v.d.sommen@tue.nl
RI Bergman, Jacques/AAS-2500-2021
OI Weusten, Bas/0000-0001-9468-4578; Bisschops, Raf/0000-0002-9994-8226;
   van der Sommen, Fons/0000-0002-3593-2356; Bergman,
   Jacques/0000-0001-7548-6955
CR Barbosa DJC, 2011, DISCRETE WAVELET TRA, P155
   Behrens A, 2011, DTSCH ARZTEBL INT, V108, P313, DOI 10.3238/arztebl.2011.0313
   Dent J, 2011, J GASTROEN HEPATOL, V26, P11, DOI 10.1111/j.1440-1746.2010.06535.x
   Kara MA, 2010, TECH GASTROINTEST EN, V12, P82, DOI 10.1016/j.tgie.2010.01.010
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Lagergren J, 2010, BMJ-BRIT MED J, V341, DOI 10.1136/bmj.c6280
   Lepage C, 2008, AM J GASTROENTEROL, V103, P2694, DOI 10.1111/j.1572-0241.2008.02191.x
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Phoa KN, 2016, GUT, V65, P555, DOI 10.1136/gutjnl-2015-309298
   Reid BJ, 2000, AM J GASTROENTEROL, V95, P3089, DOI 10.1111/j.1572-0241.2000.03182.x
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Setio A. A., 2013, PROC VISAPP, V1, P238
   van der Sommen F, 2014, NEUROCOMPUTING, V144, P92, DOI 10.1016/j.neucom.2014.02.066
   van Vilsteren FGI, 2011, ENDOSCOPY, V43, P282, DOI 10.1055/s-0030-1256309
NR 17
TC 97
Z9 98
U1 1
U2 6
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD JUL
PY 2016
VL 48
IS 7
BP 617
EP 624
DI 10.1055/s-0042-105284
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA DQ0UD
UT WOS:000378915600004
PM 27100718
DA 2023-04-20
ER

PT J
AU Wimmer, G
   Tamaki, T
   Tischendorf, JJW
   Hafner, M
   Yoshida, S
   Tanaka, S
   Uhl, A
AF Wimmer, Georg
   Tamaki, Toru
   Tischendorf, J. J. W.
   Haefner, Michael
   Yoshida, Shigeto
   Tanaka, Shinji
   Uhl, Andreas
TI Directional wavelet based features for colonic polyp classification
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Polyp classification; Wavelet; Curvelet; Contourlet; Shearlet
ID TEXTURE CLASSIFICATION; FEATURE-EXTRACTION; IMAGE; ENDOSCOPY; RETRIEVAL;
   DENSITY
AB In this work, various wavelet based methods like the discrete wavelet transform, the dual-tree complex wavelet transform, the Gabor wavelet transform, curvelets, contourlets and shearlets are applied for the automated classification of colonic polyps. The methods are tested on 8 HD-endoscopic image databases, where each database is acquired using different imaging modalities (Pentax's i-Scan technology combined with or without staining the mucosa), 2 NBI high-magnification databases and one database with chromoscopy high-magnification images.
   To evaluate the suitability of the wavelet based methods with respect to the classification of colonic polyps, the classification performances of 3 wavelet transforms and the more recent curvelets, contourlets and shearlets are compared using a common framework. Wavelet transforms were already often and successfully applied to the classification of colonic polyps, whereas curvelets, contourlets and shearlets have not been used for this purpose so far.
   We apply different feature extraction techniques to extract the information of the subbands of the wavelet based methods. Most of the in total 25 approaches were already published in different texture classification contexts. Thus, the aim is also to assess and compare their classification performance using a common framework. Three of the 25 approaches are novel. These three approaches extract Weibull features from the subbands of curvelets, contourlets and shearlets. Additionally, 5 state-of-the-art non wavelet based methods are applied to our databases so that we can compare their results with those of the wavelet based methods.
   It turned out that extracting Weibull distribution parameters from the subband coefficients generally leads to high classification results, especially for the dual-tree complex wavelet transform, the Gabor wavelet transform and the Shearlet transform. These three wavelet based transforms in combination with Weibull features even outperform the state-of-the-art methods on most of the databases. We will also show that the Weibull distribution is better suited to model the subband coefficient distribution than other commonly used probability distributions like the Gaussian distribution and the generalized Gaussian distribution.
   So this work gives a reasonable summary of wavelet based methods for colonic polyp classification and the huge amount of endoscopic polyp databases used for our experiments assures a high significance of the achieved results. (C) 2016 The Authors. Published by Elsevier B.V.
C1 [Wimmer, Georg; Uhl, Andreas] Salzburg Univ, Dept Comp Sci, Jakob Haringerstr 2, A-5020 Salzburg, Austria.
   [Haefner, Michael] St Elizabeth Hosp, Landstrasser Hauptstr 4a, A-1030 Vienna, Austria.
   [Tamaki, Toru] Hiroshima Univ, Dept Informat Engn, Grad Sch Engn, 1-4-1 Kagamiyama, Hiroshima 7398527, Japan.
   [Yoshida, Shigeto; Tanaka, Shinji] Hiroshima Univ Hosp, Dept Endoscopy, Minami Ku, 1-2-3 Kasumi, Hiroshima 7348551, Japan.
   [Tischendorf, J. J. W.] RWTH Aachen Univ Hosp, Med Dept Gastroenterol Hepatol & Metab Dis 3, Paulwelsstr 30, D-52072 Aachen, Germany.
C3 Salzburg University; Hiroshima University; Hiroshima University; RWTH
   Aachen University; RWTH Aachen University Hospital
RP Wimmer, G (通讯作者)，Salzburg Univ, Dept Comp Sci, Jakob Haringerstr 2, A-5020 Salzburg, Austria.
EM gwimmer@cosy.sbg.ac.at; uhl@cosy.sbg.ac.at
RI Tamaki, Toru/D-7091-2011
OI Tamaki, Toru/0000-0001-9712-7777
FU Austrian Science Fund, TRP Project [206]
FX This work is supported by the Austrian Science Fund, TRP Project 206.
CR Andre B, 2012, IEEE T MED IMAGING, V31, P1276, DOI 10.1109/TMI.2012.2188301
   Andre B, 2011, MED IMAGE ANAL, V15, P460, DOI 10.1016/j.media.2011.02.003
   [Anonymous], 1992, 10 LECT WAVELETS
   Barbosa DJC, 2009, IEEE ENG MED BIO, P6683, DOI 10.1109/IEMBS.2009.5334013
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Candes EJ, 2002, COMMUN PUR APPL MATH, P219
   Candes E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chakravarti I.M.R.G.L.J.R, 1967, HDB METHODS APPL STA, Vi
   Chowdhury TA, 2008, IEEE T BIO-MED ENG, V55, P888, DOI 10.1109/TBME.2007.909506
   Do M. N., 2001, TECHNICAL REPORT
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Dong YS, 2015, IEEE T CYBERNETICS, V45, P358, DOI 10.1109/TCYB.2014.2326059
   Dong YS, 2013, NEUROCOMPUTING, V116, P157, DOI 10.1016/j.neucom.2011.12.059
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Evans M., 2000, WILEY SERIES PROBABI
   Gomez F, 2011, PATTERN RECOGN LETT, V32, P2178, DOI 10.1016/j.patrec.2011.09.029
   Gono K, 2003, OPT REV, V10, P211, DOI 10.1007/s10043-003-0211-8
   Gross S., 2012, AUTOMATED CLASSIFICA
   Hafner M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P365, DOI 10.1007/978-3-662-46224-9_63
   Hafner M, 2012, COMPUT METH PROG BIO, V107, P565, DOI 10.1016/j.cmpb.2011.12.012
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hafner M, 2009, PATTERN ANAL APPL, V12, P407, DOI 10.1007/s10044-008-0136-8
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hafner Michael, 2014, Medical Computer Vision Large Data in Medical Imaging. Third International MICCAI Workshop, MCV 2013. Revised Selected Papers. LNCS: 8331, P205, DOI 10.1007/978-3-319-05530-5_20
   Hafner M., 2014, P 22 INT C PATT REC, P2734
   Hafner M., 2010, 10 IEEE INT C INF TE, P1
   Hafner M., 2009, P 9 INT C INF TECHN
   He JP, 2013, IEEE SIGNAL PROC LET, V20, P905, DOI 10.1109/LSP.2013.2267730
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Jabbour JM, 2012, ANN BIOMED ENG, V40, P378, DOI 10.1007/s10439-011-0426-y
   Kato S, 2006, WORLD J GASTROENTERO, V12, P1416, DOI 10.3748/wjg.v12.i9.1416
   Kiesslich R., 2009, EUR GASTROENTEROL HE, V5, P22
   Kingsbury N. G., 1998, P 8 IEEE DSP WORKSH, P9
   Kodashima S, 2010, WORLD J GASTROENTERO, V16, P1043, DOI 10.3748/wjg.v16.i9.1043
   Kovesi P., 1999, Videre, V1
   Kovesi P. D., 2000, MATLAB OCTAVE FUNCTI
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   Kwitt Roland, 2007, 2007 11th IEEE International Conference on Computer Vision, P1, DOI 10.1109/ICCV.2007.4409170
   Kwitt R, 2010, IEEE T IMAGE PROCESS, V19, P241, DOI 10.1109/TIP.2009.2032313
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Liao S., 2007, P 2007 INT C ADV BIO, P828
   Long ZL, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P31
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Martins MM, 2010, IEEE ENG MED BIO, P5557, DOI 10.1109/IEMBS.2010.5626780
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Niola V., 2006, METHOD MOMENTS ESTIM, P382
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Romain O., 2013, IEEE 13 INT C BIOINF, P1
   Schwartz WR, 2011, IEEE IMAGE PROC, P1033, DOI 10.1109/ICIP.2011.6115600
   STEHLE T, 2009, MED IMAGING 2009 COM
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Uhl A, 2014, IEEE IMAGE PROC, P2299, DOI 10.1109/ICIP.2014.7025466
   Varma M., 2007, P IEEE INT C COMP VI, P1, DOI DOI 10.1109/ICCV.2007.4408875
   Vedaldi A., 2008, VLFEAT OPEN PORTABLE
   VETTERLI M, 1984, SIGNAL PROCESS, V6, P97, DOI 10.1016/0165-1684(84)90012-4
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Yuce MR, 2012, IEEE MICROW MAG, V13, P90, DOI 10.1109/MMM.2012.2205833
   Zuiderveld K., 1994, GRAPHICS GEMS
NR 64
TC 53
Z9 56
U1 5
U2 30
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD JUL
PY 2016
VL 31
BP 16
EP 36
DI 10.1016/j.media.2016.02.001
PG 21
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA DK0TS
UT WOS:000374625700002
PM 26948110
OA hybrid
DA 2023-04-20
ER

PT J
AU Hu, EZ
   Sakanashi, H
   Nosato, H
   Takahashi, E
   Suzuki, Y
   Takeuchi, K
   Aoki, H
   Murakawa, M
AF Hu, Erzhong
   Sakanashi, Hidenori
   Nosato, Hirokazu
   Takahashi, Eiichi
   Suzuki, Yasuo
   Takeuchi, Ken
   Aoki, Hiroshi
   Murakawa, Masahiro
TI Bleeding and Tumor Detection for Capsule Endoscopy Images Using Improved
   Geometric Feature
SO JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING
LA English
DT Article
DE Capsule endoscopy; Anomaly detection; Local-contrast-enhanced
   higher-order local auto-correlation (LCE-HLAC); Non-linear conversion of
   HSV color space; Support vector machine (SVM)
ID SMALL-BOWEL; ANOMALY DETECTION; TEXTURE; DIAGNOSIS; SYSTEM
AB This paper presents a method for detecting bleeding and tumors within capsule endoscopy (CE) images. Because CE can be used for visual, non-invasive examinations of the small bowel, it has recently become widely used. However, as a capsule progresses along the gastrointestinal tract, it collects vast quantities of images that make diagnosis a very time-consuming task. To address this problem, many computational approaches for anomaly detection have been proposed. Common to most approaches is the belief that color, texture, and shape are the most promising features for detecting anomalies within CE images. However, given that the requirements for each type of feature vary according to the anomaly, generally, it is essential to apply a complicated combination of techniques for multiple-feature extraction. In this study, in order to realize a scheme that covers the features of color, texture, and shape and can be applied to lesion areas of various sizes, a geometric image feature called local-contrast-enhanced higher-order local auto-correlation (LCE-HLAC) is proposed. Moreover, although the HSV color space is generally regarded as being appropriate for the analysis of CE images, imbalances in the distributions of utilized hue components limit discriminatory performance for normal and anomalous images. Accordingly, an image pre-processing method that uses a non-linear conversion model for the HSV color space is also proposed. Anomaly detection is implemented using a support vector machine classifier. The results of experiments, conducted with normal, bleeding, and tumor images obtained from 28 patients, demonstrate both the feasibility and superiority of the proposed method for both bleeding and tumor detection tasks.
C1 [Hu, Erzhong] Univ Tsukuba, Dept Intelligent Interact Technol, Tsukuba, Ibaraki 3058573, Japan.
   [Sakanashi, Hidenori; Nosato, Hirokazu; Takahashi, Eiichi; Murakawa, Masahiro] Natl Inst Adv Ind Sci & Technol, Artificial Intelligence Res Ctr, Tsukuba, Ibaraki 3058568, Japan.
   [Suzuki, Yasuo; Takeuchi, Ken; Aoki, Hiroshi] Toho Univ, Sakura Med Ctr, Dept Gastroenterol, Sakura 2858741, Japan.
C3 University of Tsukuba; National Institute of Advanced Industrial Science
   & Technology (AIST); Toho University
RP Hu, EZ (通讯作者)，Univ Tsukuba, Dept Intelligent Interact Technol, Tsukuba, Ibaraki 3058573, Japan.
EM ajon-fu@aist.go.jp
RI Nosato, Hirokazu/AAP-8171-2020; Aoki, Hiroshi/M-3255-2018; Nosato,
   Hirokazu/A-6344-2017; Sakanashi, Hidenori/B-1613-2017; Takahashi,
   Eiichi/A-8135-2013; Murakawa, Masahiro/B-1144-2017
OI Nosato, Hirokazu/0000-0003-0332-7028; Aoki, Hiroshi/0000-0002-0975-2116;
   Nosato, Hirokazu/0000-0003-0332-7028; Sakanashi,
   Hidenori/0000-0001-8987-908X; Takahashi, Eiichi/0000-0003-4088-6072;
   Murakawa, Masahiro/0000-0002-8406-7426
CR Al-Rahayfeh A. A., 2010, INT J MULTIMEDIA APP, V2, P1
   Barbosa DJC, 2008, IEEE ENG MED BIO, P3012, DOI 10.1109/IEMBS.2008.4649837
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Delvaux M, 2008, BEST PRACT RES CL GA, V22, P813, DOI 10.1016/j.bpg.2008.06.003
   Doherty GA, 2011, GASTROINTEST ENDOSC, V74, P167, DOI 10.1016/j.gie.2011.01.067
   Gan T, 2008, WORLD J GASTROENTERO, V14, P6929, DOI 10.3748/wjg.14.6929
   Hara AK, 2006, RADIOLOGY, V238, P128, DOI 10.1148/radiol.2381050296
   Hu EZ, 2013, IEEE ENG MED BIO, P5477, DOI 10.1109/EMBC.2013.6610789
   Hu EZ, 2012, IEEE SYS MAN CYBERN, P2289, DOI 10.1109/ICSMC.2012.6378082
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   KOBAYASHI T, 2008, P ECSIS S BIOINSP LE, P40, DOI DOI 10.1109/BLISS.2008.21
   Lau PY, 2007, P ANN INT IEEE EMBS, P5601, DOI 10.1109/IEMBS.2007.4353616
   Lee J, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1041
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Li CH, 2000, IEEE T MED IMAGING, V19, P1150, DOI 10.1109/42.896791
   Mete M., 2008, DELINEATION MALIGNAN, P28
   MIMURA S, 2008, P BIOINSP LEARN INT, P56, DOI DOI 10.1109/BLISS.2008.31
   Nosato Hirokazu, 2011, IPSJ Transactions on Computer Vision and Applications, V3, P211, DOI 10.2197/ipsjtcva.3.211
   Onoda T., 2001, OPER RES, P225
   Otsu N., 1988, Proceedings of IAPR Workshop on Computer Vision: Special Hardware and Industrial Applications, P431
   Penna B., 2009, P EUR SIGN PROC C, P1865
   Press W. H., 2007, NUMERICAL RECIPES AR, P889
   Qu J, 2012, INT CONF SIGN PROCES, P1198, DOI 10.1109/ICoSP.2012.6491791
   Rey JF, 2004, ENDOSCOPY, V36, P656, DOI 10.1055/s-2004-814557
   Signorelli C, 2005, ENDOSCOPY, V37, P1170, DOI 10.1055/s-2005-870410
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Szczypinski PM, 2009, COMPUT METH PROG BIO, V94, P66, DOI 10.1016/j.cmpb.2008.08.005
   University of Rochester Medical Center, DIG DIAGN PROC
   Vapnik V, 1998, STAT LEARNING THEORY
   Xynopoulos D, 2002, ANN GASTROENTEROLOGY, V15, P18
   Yagi Y., 2007, Inflammopharmacology, V15, P78, DOI 10.1007/s10787-006-0010-5
NR 35
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1609-0985
EI 2199-4757
J9 J MED BIOL ENG
JI J. Med. Biol. Eng.
PD JUN
PY 2016
VL 36
IS 3
BP 344
EP 356
DI 10.1007/s40846-016-0138-8
PG 13
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA DQ9CC
UT WOS:000379507000006
DA 2023-04-20
ER

PT J
AU Hu, YF
   Liang, ZR
   Song, BW
   Han, H
   Pickhardt, PJ
   Zhu, W
   Duan, CJ
   Zhang, H
   Barish, MA
   Lascarides, CE
AF Hu, Yifan
   Liang, Zhengrong
   Song, Bowen
   Han, Hao
   Pickhardt, Perry J.
   Zhu, Wei
   Duan, Chaijie
   Zhang, Hao
   Barish, Matthew A.
   Lascarides, Chris E.
TI Texture Feature Extraction and Analysis for Polyp Differentiation via
   Computed Tomography Colonography
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Colorectal polyps; computed tomography colonography; polyp subtype
   classification; texture feature
ID AMERICAN-CANCER-SOCIETY; CT COLONOGRAPHY; COLORECTAL-CANCER; VIRTUAL
   COLONOSCOPY; PREVALENCE; SIZE; LESIONS; COLON; SURVEILLANCE; NEOPLASIA
AB Image textures in computed tomography colonography (CTC) have great potential for differentiating non-neoplastic from neoplastic polyps and thus can advance the current CTC detection-only paradigm to a new level with diagnostic capability. However, image textures are frequently compromised, particularly in low-dose CT imaging. Furthermore, texture feature extraction may vary, depending on the polyp spatial orientation variation, resulting in variable results. To address these issues, this study proposes an adaptive approach to extract and analyze the texture features for polyp differentiation. Firstly, derivative (e.g. gradient and curvature) operations are performed on the CT intensity image to amplify the textures with adequate noise control. Then Haralick co-occurrence matrix (CM) is used to calculate texture measures along each of the 13 directions (defined by the first and second order image voxel neighbors) through the polyp volume in the intensity, gradient and curvature images. Instead of taking the mean and range of each CM measure over the 13 directions as the so-called Haralick texture features, Karhunen-Loeve transform is performed to map the 13 directions into an orthogonal coordinate system so that the resulted texture features are less dependent on the polyp orientation variation. These simple ideas for amplifying textures and stabilizing spatial variation demonstrated a significant impact for the differentiating task by experiments using 384 polyp datasets, of which 52 are non-neoplastic polyps and the rest are neoplastic polyps. By the merit of area under the curve of receiver operating characteristic, the innovative ideas achieved differentiation capability of 0.8016, indicating the CTC diagnostic feasibility.
C1 [Hu, Yifan; Liang, Zhengrong; Song, Bowen; Han, Hao; Zhu, Wei; Zhang, Hao; Barish, Matthew A.] SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
   [Hu, Yifan; Song, Bowen; Zhu, Wei] SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA.
   [Liang, Zhengrong; Han, Hao; Zhang, Hao; Barish, Matthew A.] SUNY Stony Brook, Dept Biomed Engn, Stony Brook, NY 11794 USA.
   [Pickhardt, Perry J.] Univ Wisconsin, Sch Med, Dept Radiol, Madison, WI 53792 USA.
   [Duan, Chaijie] Tsinghua Univ, Sch Biomed Engn, Shenzhen 518055, Guangdong, Peoples R China.
   [Lascarides, Chris E.] SUNY Stony Brook, Dept Med, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook; State University of New York
   (SUNY) System; State University of New York (SUNY) Stony Brook;
   University of Wisconsin System; University of Wisconsin Madison;
   Tsinghua University; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook
RP Liang, ZR (通讯作者)，SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.; Liang, ZR (通讯作者)，SUNY Stony Brook, Dept Biomed Engn, Stony Brook, NY 11794 USA.
EM yifanhu@mil.sunysb.edu; jerome.liang@sunysb.edu; bowen@mil.sunysb.edu;
   haohan@mil.sunysb.edu; ppickhardt2@uwhealth.org; weizhu2000@gmail.com;
   duan.chaijie@sz.tsinghua.edu; zhanghao@mil.sunysb.edu;
   matthew.barish@stonybrookmedicine.edu;
   chris.lascarides@stonybrookmedicine.edu
RI han, hao/HNS-0623-2023; , Hao/D-5618-2015
OI , Hao/0000-0002-9387-7279; Barish, Matthew/0000-0002-7521-8878
FU NIH/NCI [CA082402, CA143111]; NSF of China [81230035]
FX This work was partly supported by the NIH/NCI under grants CA082402 and
   CA143111. C. Duan was supported in part by the NSF of China under grant
   81230035. Asterisk indicates corresponding author.
CR American Cancer Society, 2014, CANC FACTS FIG 2015
   American College of Radiology, 2005, ACR PRACT GUID, V29, P295
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Byers T, 1997, CA-CANCER J CLIN, V47, P154, DOI 10.3322/canjclin.47.3.154
   Castellano G, 2004, CLIN RADIOL, V59, P1061, DOI 10.1016/j.crad.2004.07.008
   Do C, 2012, CANCER PREV RES, V5, P675, DOI 10.1158/1940-6207.CAPR-11-0408
   Engel K, 2006, REAL TIME VOLUME GRA
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   GELFAND DW, 1988, AM J ROENTGENOL, V150, P727
   Han FF, 2015, J DIGIT IMAGING, V28, P99, DOI 10.1007/s10278-014-9718-8
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996
   JOHNSON DA, 1990, AM J GASTROENTEROL, V85, P969
   Kumar V, 2014, ROBBINS COTRAN PATHO
   Levin B, 2008, GASTROENTEROLOGY, V134, P1570, DOI 10.1053/j.gastro.2008.02.002
   Liang Z, 2010, EXPERT OPIN MED DIAG, V4, P149
   Lieberman DA, 2005, CLIN GASTROENTEROL H, V3, P798, DOI 10.1016/S1542-3565(05)00405-2
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Liu Y., 2014, THESIS
   Luboldt W, 2004, EUR RADIOL, V14, P2228, DOI 10.1007/s00330-004-2467-1
   Ma M., 2014, IEEE NSS MIC
   Monga O., 1991, COMPUTER VISION IMAG, P171
   Ng F, 2013, RADIOLOGY, V266, P177, DOI 10.1148/radiol.12120254
   Oto A, 2003, EUR RADIOL, V13, P1657, DOI 10.1007/s00330-002-1770-y
   Philips C, 2008, INT C BIOC BIOINF BI
   Pickhardt PJ, 2008, JAMA-J AM MED ASSOC, V299, P2743, DOI 10.1001/jama.299.23.2743-a
   Pickhardt PJ, 2007, CANCER, V109, P2213, DOI 10.1002/cncr.22668
   Pickhardt PJ, 2013, LANCET ONCOL, V14, P711, DOI 10.1016/S1470-2045(13)70216-X
   Pickhardt PJ, 2010, CLIN GASTROENTEROL H, V8, P610, DOI 10.1016/j.cgh.2010.03.007
   Pickhardt PJ, 2009, AM J ROENTGENOL, V193, P40, DOI 10.2214/AJR.08.1709
   Pickhardt PJ, 2004, RADIOLOGY, V232, P784, DOI 10.1148/radiol.2323031614
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   POTTER JD, 1993, EPIDEMIOL REV, V15, P499, DOI 10.1093/oxfordjournals.epirev.a036132
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Schaeffer B, 2014, ACAD RADIOL, V21, P1567, DOI 10.1016/j.acra.2014.07.019
   Showalter C, 2006, OSTEOPOROSIS INT, V17, P259, DOI 10.1007/s00198-005-1994-1
   Song B., 2012, 26 INT C EXH COMP AS, V7, pS273
   Song BW, 2014, INT J COMPUT ASS RAD, V9, P1021, DOI 10.1007/s11548-014-0991-2
   Song BW, 2014, INT J COMPUT ASS RAD, V9, P79, DOI 10.1007/s11548-013-0913-8
   STRYKER SJ, 1987, GASTROENTEROLOGY, V93, P1009, DOI 10.1016/0016-5085(87)90563-4
   Summers R., 2004, ACAD RADIOL, V13, P1490
   Summers RM, 2005, GASTROENTEROLOGY, V129, P1832, DOI 10.1053/j.gastro.2005.08.054
   Tesar L, 2008, COMPUT MED IMAG GRAP, V32, P513, DOI 10.1016/j.compmedimag.2008.05.005
   Wang S, 2008, MED PHYS, V35, P5787, DOI 10.1118/1.3013591
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Yao JH, 2011, ACAD RADIOL, V18, P306, DOI 10.1016/j.acra.2010.11.013
   Zhang G, 2012, INT J CARS S, V7, pS274
   Zhu HB, 2011, ACAD RADIOL, V18, P1024, DOI 10.1016/j.acra.2011.03.012
NR 48
TC 58
Z9 60
U1 0
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD JUN
PY 2016
VL 35
IS 6
BP 1522
EP 1531
DI 10.1109/TMI.2016.2518958
PG 10
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA DR5GA
UT WOS:000379930300014
PM 26800530
OA Green Accepted
DA 2023-04-20
ER

PT J
AU DiMagno, EP
   DiMagno, MJ
AF DiMagno, Eugene P.
   DiMagno, Matthew J.
TI Chronic Pancreatitis Landmark Papers, Management Decisions, and Future
SO PANCREAS
LA English
DT Review
DE chronic pancreatitis; endoscopic ultrasonography; exocrine pancreatic
   insufficiency; pancreatic cancer; natural history
ID CYSTIC-FIBROSIS GENE; IDIOPATHIC CHRONIC-PANCREATITIS; RECURRENT
   ACUTE-PANCREATITIS; TRANSMEMBRANE CONDUCTANCE REGULATOR; ALCOHOLIC
   CHRONIC-PANCREATITIS; CONFOCAL LASER ENDOMICROSCOPY; NEURAL-NETWORK
   ANALYSIS; SENSING-RECEPTOR GENE; HIGH-FAT DIETS; HEREDITARY PANCREATITIS
AB On May 16, 2015 at the invitation of the American Gastroen-terological Association Institute Council E.P.D. presented a state-of-the-art lecture at Digestive Disease Week 2015. The aims were to discuss a selection of landmark papers in chronic pancreatitis (CP) that influence modern management and to conclude by suggesting some future directions. This is based on that presentation. We will specifically review the following: duct anatomy and pancreas divisum, description of chronic relapsing pancreatitis and its differentiation from recurrent acute pancreatitis and established CP (ECP), natural histories and gene discoveries of alcoholic, idiopathic and hereditary pancreatitis, development of pancreatic cancer in CP, exocrine pancreatic insufficiency and calculation of dose and delivery of enzymes, endoscopic ultrasonography, and autoimmune pancreatitis. With some exceptions, we exclude basic science and surgery.
C1 [DiMagno, Eugene P.] Mayo Clin, Mayo Med Sch, Dept Internal Med, Div Gastroenterol & Hepatol, 200 1st St SW, Rochester, MN 55905 USA.
   [DiMagno, Matthew J.] Univ Michigan, Sch Med, Dept Internal Med, Div Gastroenterol & Hepatol, Ann Arbor, MI 48109 USA.
C3 Mayo Clinic; University of Michigan System; University of Michigan
RP DiMagno, EP (通讯作者)，Mayo Clin, Mayo Med Sch, Dept Internal Med, Div Gastroenterol & Hepatol, 200 1st St SW, Rochester, MN 55905 USA.
EM dimagno.eugene@mayo.edu
FU NIH/NIAAA [R21AA017271]; Michigan Translational Research and
   Commercialization for Life Sciences Program; Cystic Fibrosis Foundation:
   Developing Innovative Gastroenterology Specialty Training or DIGEST
   Program; British Medical Journal Publishing Group Limited; American
   College of Physicians (Philadelphia, Pa) for coauthoring 2 chapters in
   the gastroenterology and hepatology section of MKSAP 17
FX M.J.D. received the following research support in the past 3 years:
   NIH/NIAAA (R21AA017271); Michigan Translational Research and
   Commercialization for Life Sciences Program; and the Cystic Fibrosis
   Foundation: Developing Innovative Gastroenterology Specialty Training or
   DIGEST Program.; M.J.D. received honoraria from the British Medical
   Journal Publishing Group Limited (for articles published in British
   Medical Journal Point-of-Care), The American Gastroenterological
   Association (for contributing to a web-based Patient Brochure -
   Pancreatitis) and Oakstone Publishing (for Podcasts on Pancreatic
   Disorders, Best of Digestive Disease Week 2013-2015). M.J.D. also
   received a consulting fee from the American College of Physicians
   (Philadelphia, Pa) for coauthoring 2 chapters in the gastroenterology
   and hepatology section of MKSAP 17, entitled "Diseases of the Pancreas"
   and "Gastrointestinal Bleeding."
CR AMMANN RW, 1984, GASTROENTEROLOGY, V86, P820
   Ammann RW, 1999, GASTROENTEROLOGY, V116, P1132, DOI 10.1016/S0016-5085(99)70016-8
   [Anonymous], 2011, Med Lett Drugs Ther, V53, P12
   Aoun E, 2010, AM J GASTROENTEROL, V105, P446, DOI 10.1038/ajg.2009.630
   BEGER HG, 1989, ANN SURG, V209, P273, DOI 10.1097/00000658-198903000-00004
   Bernard C, 1985, MONOGR PHYSL SOC, V42, P1
   Bernard C, 1856, LECONS PHYSL EXPT PA, V11, P180
   Bertin C, 2012, AM J GASTROENTEROL, V107, P311, DOI 10.1038/ajg.2011.424
   Bishop MD, 2005, HUM GENET, V118, P372, DOI 10.1007/s00439-005-0059-z
   Buxton JL, 1980, AM I ULTR MED ANN M
   Cahen DL, 2007, NEW ENGL J MED, V356, P676, DOI 10.1056/NEJMoa060610
   Cahen DL, 2011, GASTROENTEROLOGY, V141, P1690, DOI 10.1053/j.gastro.2011.07.049
   Chari ST, 2006, CLIN GASTROENTEROL H, V4, P1010, DOI 10.1016/j.cgh.2006.05.017
   Chari ST, 2010, PANCREAS, V39, P549, DOI 10.1097/MPA.0b013e3181e4d9e5
   Choudari CP, 2004, AM J GASTROENTEROL, V99, P1358, DOI 10.1111/j.1572-0241.2004.30655.x
   Chung JP, 2000, GASTROENTEROLOGY, V118, pA418, DOI 10.1016/S0016-5085(00)83785-3
   Cohn JA, 1998, NEW ENGL J MED, V339, P653, DOI 10.1056/NEJM199809033391002
   COMFORT MW, 1952, GASTROENTEROLOGY, V21, P54
   COMFORT MW, 1946, GASTROENTEROLOGY, V6, P239
   COMFORT MW, 1946, GASTROENTEROLOGY, V6, P376
   Conwell DL, 2003, GASTROINTEST ENDOSC, V57, P37, DOI 10.1067/mge.2003.14
   COTTON PB, 1980, GUT, V21, P105, DOI 10.1136/gut.21.2.105
   DIMAGNO EP, 1973, NEW ENGL J MED, V288, P813, DOI 10.1056/NEJM197304192881603
   DIMAGNO EP, 1980, LANCET, V1, P629
   DIMAGNO EP, 1982, GASTROENTEROLOGY, V83, P824
   DIMAGNO EP, 1979, CLIN RES, V27, pA682
   DiMagno EP, 2001, GASTROENTEROLOGY, V121, P1508, DOI 10.1053/gast.2001.29980
   DIMAGNO EP, 1980, GASTROENTEROLOGY, V78, P1157
   DIMAGNO EP, 1977, NEW ENGL J MED, V296, P1318, DOI 10.1056/NEJM197706092962304
   DiMagno EP, 1980, 4 EUR C GASTR END JU, P51
   DIMAGNO EP, 1981, GASTROENTEROLOGY, V80, P1136
   DiMagno EP, 1981, MIDW GUT CLUB M MARC
   DiMagno EP, 2016, DIGEST DIS SCI, V61, P342, DOI 10.1007/s10620-015-3999-8
   DiMagno MJ, 2013, CURR OPIN GASTROEN, V29, P531, DOI 10.1097/MOG.0b013e3283639370
   DiMagno MJ, 2012, AM J GASTROENTEROL, V107, P318, DOI 10.1038/ajg.2011.430
   DiMagno MJ, 2007, PANCREAS, V34, P21
   Dray X, 2007, PANCREAS, V35, P90, DOI 10.1097/MPA.0b013e318054771f
   Egberts JH, 2000, GASTROENTEROLOGY, V118, pA420, DOI 10.1016/S0016-5085(00)83793-2
   Felderbauer P, 2003, BMC GASTROENTEROL, V3, DOI 10.1186/1471-230X-3-34
   Flati G, 2002, PANCREATOLOGY, V2, P4, DOI 10.1159/000049441
   Gamgee A, 1893, TXB PHYSL CHEM ANIMA, VII
   Garg PK, 2009, J CLIN GASTROENTEROL, V43, P848, DOI 10.1097/MCG.0b013e3181a4e772
   Gelrud A, 2004, AM J GASTROENTEROL, V99, P1557, DOI 10.1111/j.1572-0241.2004.30834.x
   GREGG JA, 1977, AM J SURG, V134, P539, DOI 10.1016/0002-9610(77)90429-9
   Groman JD, 2002, NEW ENGL J MED, V347, P401, DOI 10.1056/NEJMoa011899
   Hamano H, 2001, NEW ENGL J MED, V344, P732, DOI 10.1056/NEJM200103083441005
   HEISS FW, 1978, AM J GASTROENTEROL, V70, P158
   Holtmann G, 1997, AM J PHYSIOL-GASTR L, V273, pG553, DOI 10.1152/ajpgi.1997.273.2.G553
   Howard JM, 1998, J AM COLL SURGEONS, V187, P201, DOI 10.1016/S1072-7515(98)00136-7
   HOWARD JM, 2002, HISTORY
   Hyrtl J, 1865, K AKAD WISSENSCHA MN, V52, P275
   Inman T, 1860, AM J MED SCI, VXL, P450
   Karstensen JG, 2015, PANCREAS, V44, P833, DOI 10.1097/MPA.0000000000000345
   Kisiel JB, 2015, CLIN CANCER RES, V21, P4473, DOI 10.1158/1078-0432.CCR-14-2469
   Kleinerman R, 2014, CLIN ANAT, V27, P545, DOI 10.1002/ca.22294
   Knowles MR, 2002, NEW ENGL J MED, V347, P439, DOI 10.1056/NEJMe020070
   Ko SBH, 2010, GASTROENTEROLOGY, V138, P1988, DOI 10.1053/j.gastro.2010.01.001
   Konda VJA, 2011, GASTROINTEST ENDOSC, V74, P1049, DOI 10.1016/j.gie.2011.07.018
   LaRusch J, 2015, CLIN TRANSL GASTROEN, V6, DOI 10.1038/ctg.2014.13
   LAYER P, 1994, GASTROENTEROLOGY, V107, P1481, DOI 10.1016/0016-5085(94)90553-3
   LAYER P, 1986, AM J PHYSIOL, V251, pG475, DOI 10.1152/ajpgi.1986.251.4.G475
   Lowenfels AB, 1997, J NATL CANCER I, V89, P442, DOI 10.1093/jnci/89.6.442
   LOWENFELS AB, 1993, NEW ENGL J MED, V328, P1433, DOI 10.1056/NEJM199305203282001
   Lowenfels AB, 2001, JAMA-J AM MED ASSOC, V286, P169, DOI 10.1001/jama.286.2.169
   LUTZ H, 1976, ENDOSCOPY, V8, P203, DOI 10.1055/s-0028-1098414
   Maleth J, 2015, GASTROENTEROLOGY, V148, P427, DOI 10.1053/j.gastro.2014.11.002
   Masamune A, 2011, J GASTROEN HEPATOL, V26, P974, DOI 10.1111/j.1440-1746.2011.06691.x
   Masson E, 2008, HUM GENET, V123, P83, DOI 10.1007/s00439-007-0459-3
   Meckel JF, 1812, HDB PATHOLOGISCHEN A
   Midha S, 2010, GUT, V59, P800, DOI 10.1136/gut.2009.191239
   Muddana V, 2008, WORLD J GASTROENTERO, V14, P4486, DOI 10.3748/wjg.14.4486
   Nakai Y, 2012, J PHYSIOL PHARMACOL, V63, P577
   Nakai Y, 2015, GASTROINTEST ENDOSC, V81, P1204, DOI 10.1016/j.gie.2014.10.025
   Noone PG, 2001, GASTROENTEROLOGY, V121, P1310, DOI 10.1053/gast.2001.29673
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644
   Olesen SS, 2011, GASTROENTEROLOGY, V141, P536, DOI 10.1053/j.gastro.2011.04.003
   Opie EL., 1903, DIS PANCREAS ITS CAU
   Pezzilli R, 2003, PANCREAS, V27, P332, DOI 10.1097/00006676-200311000-00011
   Pungpapong S, 2007, PANCREATOLOGY, V7, P491, DOI 10.1159/000108966
   RAIMONDO M, 1994, GASTROENTEROLOGY, V107, P231, DOI 10.1016/0016-5085(94)90081-7
   Raimondo M, 2003, CLIN GASTROENTEROL H, V1, P397, DOI 10.1053/S1542-3565(03)00182-4
   Rajagopalan B, 1980, ACOUSTICAL IMAGING V, P555
   Reddy N, 2016, PANCREAS IN PRESS
   REGAN PT, 1977, NEW ENGL J MED, V297, P854, DOI 10.1056/NEJM197710202971603
   ROSCH W, 1976, GASTROINTEST ENDOSC, V22, P206, DOI 10.1016/S0016-5107(76)73755-6
   Rosendahl J, 2008, NAT GENET, V40, P78, DOI 10.1038/ng.2007.44
   Saftoiu A, 2008, GASTROINTEST ENDOSC, V68, P1086, DOI 10.1016/j.gie.2008.04.031
   SARLES H, 1961, AM J DIG DIS, V6, P688, DOI 10.1007/BF02232341
   Sharer N, 1998, NEW ENGL J MED, V339, P645, DOI 10.1056/NEJM199809033391001
   STERN CD, 1986, GUT, V27, P203, DOI 10.1136/gut.27.2.203
   STROHM WD, 1980, ENDOSCOPY, V12, P241, DOI 10.1055/s-2007-1021752
   Sutherland DER, 2012, J AM COLL SURGEONS, V214, P409, DOI 10.1016/j.jamcollsurg.2011.12.040
   Suzuki A, 1999, GASTROENTEROLOGY, V116, P431, DOI 10.1016/S0016-5085(99)70141-1
   Suzuki A, 1997, GASTROENTEROLOGY, V112, P2048, DOI 10.1053/gast.1997.v112.pm9178698
   Tileston W, 1911, T ASSOC AM PHYSICIAN, V26, P511
   Versalius Andreas, 1543, HUMANI CORPORIS FABR
   Wang J, 2014, J CANCER, V5, P696, DOI 10.7150/jca.10094
   Wharton T., 1656, ADENOGRAPHIA SIVE GL
   Whitcomb DC, 2012, NAT GENET, V44, P1349, DOI 10.1038/ng.2466
   Whitcomb DC, 1996, GASTROENTEROLOGY, V110, P1975, DOI 10.1053/gast.1996.v110.pm8964426
   Whitcomb DC, 1996, NAT GENET, V14, P141, DOI 10.1038/ng1096-141
   Witt H, 2000, NAT GENET, V25, P213, DOI 10.1038/76088
   Witt H, 2013, NAT GENET, V45, P1216, DOI 10.1038/ng.2730
   WOLLAEGER EE, 1947, GASTROENTEROLOGY, V9, P272
   Xu WM, 2011, CELL BIOL INT, V35, P463, DOI 10.1042/CBI20100664
   YOSHIDA K, 1995, DIGEST DIS SCI, V40, P1561, DOI 10.1007/BF02285209
NR 106
TC 21
Z9 21
U1 0
U2 16
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0885-3177
EI 1536-4828
J9 PANCREAS
JI Pancreas
PD MAY-JUN
PY 2016
VL 45
IS 5
BP 641
EP 650
DI 10.1097/MPA.0000000000000599
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA DJ5QU
UT WOS:000374265700003
PM 27077713
DA 2023-04-20
ER

PT J
AU Hoogendoorn, M
   Szolovits, P
   Moons, LMG
   Numans, ME
AF Hoogendoorn, Mark
   Szolovits, Peter
   Moons, Leon M. G.
   Numans, Mattijs E.
TI Utilizing uncoded consultation notes from electronic medical records for
   predictive modeling of colorectal cancer
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Natural language processing; Predictive modeling; Uncoded consultation
   notes; Colorectal cancer
ID UMLS; TEXT
AB Objective: Machine learning techniques can be used to extract predictive models for diseases from electronic medical records (EMRs). However, the nature of EMRs makes it difficult to apply off-the-shelf machine learning techniques while still exploiting the rich content of the EMRs. In this paper, we explore the usage of a range of natural language processing (NLP) techniques to extract valuable predictors from uncoded consultation notes and study whether they can help to improve predictive performance.
   Methods: We study a number of existing techniques for the extraction of predictors from the consultation notes, namely a bag of words based approach and topic modeling. In addition, we develop a dedicated technique to match the uncoded consultation notes with a medical ontology. We apply these techniques as an extension to an existing pipeline to extract predictors from EMRs. We evaluate them in the context of predictive modeling for colorectal cancer (CRC), a disease known to be difficult to diagnose before performing an endoscopy.
   Results: Our results show that we are able to extract useful information from the consultation notes. The predictive performance of the ontology-based extraction method moves significantly beyond the benchmark of age and gender alone (area under the receiver operating characteristic curve (AUC) of 0.870 versus 0.831). We also observe more accurate predictive models by adding features derived from processing the consultation notes compared to solely using coded data (AUC of 0.896 versus 0.882) although the difference is not significant. The extracted features from the notes are shown be equally predictive (i.e. there is no significant difference in performance) compared to the coded data of the consultations.
   Conclusion: It is possible to extract useful predictors from uncoded consultation notes that improve predictive performance. Techniques linking text to concepts in medical ontologies to derive these predictors are shown to perform best for predicting CRC in our EMR dataset. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Hoogendoorn, Mark] Vrije Univ Amsterdam, Dept Comp Sci, De Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
   [Hoogendoorn, Mark; Szolovits, Peter] MIT, Comp Sci & Artificial Intelligence Lab, 32 Vassar St, Cambridge, MA 02139 USA.
   [Moons, Leon M. G.] Univ Utrecht, Med Ctr, Dept Gastroenterol & Hepatol, Heidelberglaan 100, NL-3584 CX Utrecht, Netherlands.
   [Numans, Mattijs E.] Leiden Univ, Med Ctr, Dept Publ Hlth & Primary Care, Hippocratespad 21, NL-2333 ZD Leiden, Netherlands.
C3 Vrije Universiteit Amsterdam; Massachusetts Institute of Technology
   (MIT); Utrecht University; Leiden University; Leiden University Medical
   Center (LUMC); Leiden University - Excl LUMC
RP Hoogendoorn, M (通讯作者)，Vrije Univ Amsterdam, Dept Comp Sci, De Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
EM m.hoogendoorn@vu.nl; psz@mit.edu; l.m.g.moons@umcutrecht.nl;
   m.e.numans@lumc.nl
FU NIH [R01-EB017205, 154HG007963]
FX We thank the GPs from the Julius General Practitioners Network (JHN) in
   the Netherlands, who were willing to share their anonymized routine
   general practice care EMR datasets for the purpose of this study. Prof.
   Szolovits' work is supported by NIH grants R01-EB017205 and 154HG007963.
   In addition, we would like to thank Reinier Kop for providing support
   with the integration of the developed text modules in the software
   accompanying the pre-processing pipeline and Tristan Naumann for the
   fruitful discussions.
CR Aronson AR, 2001, J AM MED INFORM ASSN, P17
   Batal I, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508044
   Bentsen B G, 1986, Scand J Prim Health Care, V4, P43, DOI 10.3109/02813438609013970
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061
   Ghassemi M, 2012, ICML MACH LEARN CLIN, P1
   Hippisley-Cox J, 2012, BRIT J GEN PRACT, V62, DOI 10.3399/bjgp12X616346
   Jaccard P., 1912, NEW PHYTOL, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Kop R, 2015, P 15 C ART INT MED A
   Kop R, 2015, IMPROVED PREDI UNPUB
   Lehman Li-wei, 2012, AMIA Annu Symp Proc, V2012, P505
   Levenshtein V.I., 1966, SOV PHYS DOKL, V10, P707
   Liao KP, 2010, ARTHRIT CARE RES, V62, P1120, DOI 10.1002/acr.20184
   Luo Y, 2014, J AM MED INFORM ASSN, V21, P824, DOI 10.1136/amiajnl-2013-002443
   Marshall T, 2011, GUT, V60, P1242, DOI 10.1136/gut.2010.225987
   Organization WH, 1996, GUID ATC CLASS DDD A
   Savova GK, 2010, J AM MED INFORM ASSN, V17, P507, DOI 10.1136/jamia.2009.001560
   Stearns MQ, 2001, J AM MED INFORM ASSN, P662
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Tremblay MC, 2009, INFORM TECHNOL MANAG, V10, P253, DOI 10.1007/s10799-009-0061-6
   Zeng Qing T, 2006, BMC Med Inform Decis Mak, V6, P30, DOI 10.1186/1472-6947-6-30
   Zipf G.K., 1949, HUMAN BEHAV PRINCIPL
NR 22
TC 28
Z9 29
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD MAY
PY 2016
VL 69
BP 53
EP 61
DI 10.1016/j.artmed.2016.03.003
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA DO4BX
UT WOS:000377727900006
PM 27085847
OA Green Accepted, Green Published
DA 2023-04-20
ER

PT J
AU Sevo, I
   Avramovic, A
   Balasingham, I
   Elle, OJ
   Bergsland, J
   Aabakken, L
AF Sevo, I.
   Avramovic, A.
   Balasingham, I.
   Elle, O. J.
   Bergsland, J.
   Aabakken, L.
TI Edge density based automatic detection of inflammation in colonoscopy
   videos
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Colonoscopy; Inflammation; Texture; Automatic detection
ID CAPSULE ENDOSCOPY; COLORECTAL POLYPS; TEXTURE FEATURES; DIAGNOSIS
AB Colon cancer is one of the deadliest diseases where early detection can prolong life and can increase the survival rates. The early stage disease is typically associated with polyps and mucosa inflammation. The often used diagnostic tools rely on high quality videos obtained from colonoscopy or capsule endoscope. The state-of-the-art image processing techniques of video analysis for automatic detection of anomalies use statistical and neural network methods. In this paper, we investigated a simple alternative model based approach using texture analysis. The method can easily be implemented in parallel processing mode for real-time applications. A characteristic texture of inflamed tissue is used to distinguish between inflammatory and healthy tissues, where an appropriate filter kernel was proposed and implemented to efficiently detect this specific texture. The basic method is further improved to eliminate the effect of blood vessels present in the lower part of the descending colon. Both approaches of the proposed method were described in detail and tested in two different computer experiments. Our results show that the inflammatory region can be detected in real-time with an accuracy of over 84%. Furthermore, the experimental study showed that it is possible to detect certain segments of video frames containing inflammations with the detection accuracy above 90%. (C) 2016 Elsevier Ltd. All rights reserved.
C1 [Sevo, I.; Avramovic, A.] Univ Banja Luka, Fac Elect Engn, Patre 5, Banja Luka 78000, Bosnia & Herceg.
   [Avramovic, A.] Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11000, Serbia.
   [Balasingham, I.; Elle, O. J.; Bergsland, J.] Oslo Univ Hosp, Intervent Ctr, N-0027 Oslo, Norway.
   [Balasingham, I.] Norwegian Univ Sci & Technol, Dept Elect & Telecommun, N-7491 Trondheim, Norway.
   [Elle, O. J.] Univ Oslo, Dept Informat, N-0316 Oslo, Norway.
   [Aabakken, L.] Univ Hosp, Rikshosp, N-0027 Oslo, Norway.
C3 University of Banja Luka (UNIBL); University of Belgrade; University of
   Oslo; Norwegian University of Science & Technology (NTNU); University of
   Oslo; University of Oslo; National Hospital Norway
RP Avramovic, A (通讯作者)，Univ Banja Luka, Fac Elect Engn, Patre 5, Banja Luka 78000, Bosnia & Herceg.
EM igor.sevo@etfbl.net; aleksej@etfbl.net; ilangko.balasingham@iet.ntnu.no;
   oelle@ous-hf.no; jacob.bergsland@ous-hf.no; lars.aabakken@medisin.uio.no
RI Bergsland, Jacob/H-3966-2016; Balasingham, Ilangko/AGU-7268-2022
FU NORBOTECH (NORwayBOsnia TECHnology Transfer) project for Programme in
   Higher Education, Research and Development by Norwegian Ministry of
   Foreign Affairs; Ministry of Science and Technology of the Republic of
   Srpska [19/6-020/961-187/14]; Bilateral Collaboration Project of
   Slovenian Research Agency (ARRS); Ministry of Civil Affairs of Bosnia
   and Herzegovina [BI-BA/10-11-026, BI-BA/14-15-035]
FX Authors would like to thank the Lars Aabakken's gastro lab for providing
   the colonoscopy videos that were used in this research. The research was
   supported by NORBOTECH (NORwayBOsnia TECHnology Transfer) project for
   Programme in Higher Education, Research and Development by Norwegian
   Ministry of Foreign Affairs, and by the Ministry of Science and
   Technology of the Republic of Srpska under Contract 19/6-020/961-187/14,
   and by Bilateral Collaboration Project of Slovenian Research Agency
   (ARRS) and Ministry of Civil Affairs of Bosnia and Herzegovina, under
   Grants BI-BA/10-11-026 and BI-BA/14-15-035.
CR ACS, 2015, CANC FACTS FIG 2015
   Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Bashar MK, 2008, LECT NOTES COMPUT SC, V5242, P603, DOI 10.1007/978-3-540-85990-1_72
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P498, DOI 10.1109/IROS.2009.5354726
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Lu L, 2009, INT J PSYCHOL, V44, P274, DOI 10.1080/00207590802079369
   MULLER AD, 1995, ANN INTERN MED, V123, P904, DOI 10.7326/0003-4819-123-12-199512150-00002
   Thiis-Evensen E, 2000, GASTROINTEST ENDOSC, V52, P606, DOI 10.1067/mge.2000.109804
   Tu Z., 2006, CVPR, P1544
   Vilarino F, 2009, BILDVERARBEITUNG MED, V22, P346
   Vilarino F, 2006, PATTERN RECOGN LETT, V27, P875, DOI 10.1016/j.patrec.2005.10.011
   Wang Z, 2004, PROC SPIE, V5370, P972, DOI 10.1117/12.535664
NR 18
TC 14
Z9 15
U1 0
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD MAY 1
PY 2016
VL 72
BP 138
EP 150
DI 10.1016/j.compbiomed.2016.03.017
PG 13
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA DL7HT
UT WOS:000375812500013
PM 27043856
DA 2023-04-20
ER

PT J
AU Huang, CR
   Chen, YT
   Chen, WY
   Cheng, HC
   Sheu, BS
AF Huang, Chun-Rong
   Chen, Yan-Ting
   Chen, Wei-Ying
   Cheng, Hsiu-Chi
   Sheu, Bor-Shyang
TI Gastroesophageal Reflux Disease Diagnosis Using Hierarchical
   Heterogeneous Descriptor Fusion Support Vector Machine
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Computer-aided diagnosis; feature extraction; gastroenterology;
   gastroesophageal reflux disease; support vector machines
ID WIRELESS CAPSULE ENDOSCOPY; HELICOBACTER-PYLORI; ESOPHAGITIS; FEATURES;
   COLOR; CLASSIFICATION; MANAGEMENT; IMPEDANCE; SYSTEM; SPACE
AB A new computer-aided diagnosis method is proposed to diagnose the gastroesophageal reflux disease (GERD) from endoscopic images of the esophageal-gastric junction. To avoid the interferences of different endoscope devices and automatic camera white balance adjustment, heterogeneous descriptors computed from heterogeneous color models are used to represent endoscopic images. Instead of concatenating these descriptors to a super vector, a hierarchical heterogeneous descriptor fusion support vector machine (HHDF-SVM) framework is proposed to simultaneously apply heterogeneous descriptors for GERD diagnosis and overcome the curse of dimensionality problem. During validation, heterogeneous descriptors are extracted from test endoscopic images at first. The classification result is obtained by using HHDF-SVM with heterogeneous descriptors. As shown in the experiments, our method can automatically diagnose GERD without any manual selection of region of interest and achieve better accuracy compared to states-of-the-art methods.
C1 [Huang, Chun-Rong] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
   [Chen, Yan-Ting] Natl Chung Hsing Univ, Inst Networking & Multimedia, Taichung 402, Taiwan.
   [Chen, Wei-Ying; Cheng, Hsiu-Chi; Sheu, Bor-Shyang] Natl Cheng Kung Univ, Inst Clin Med, Taichung 701, Taiwan.
   [Chen, Wei-Ying; Cheng, Hsiu-Chi; Sheu, Bor-Shyang] Natl Chung Hsing Univ, Natl Cheng Kung Univ Hosp, Dept Internal Med, Taichung 701, Taiwan.
C3 National Chung Hsing University; National Chung Hsing University;
   National Cheng Kung University; National Cheng Kung University; National
   Cheng Kung University Hospital; National Chung Hsing University
RP Huang, CR (通讯作者)，Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
EM crhuang@nchu.edu.tw; g100083002@mail.nchu.edu.tw;
   chen036543@yahoo.com.tw; teishuki@mail.ncku.edu.tw;
   sheubs@mail.ncku.edu.tw
OI Schirmer, Claire/0000-0002-7994-1190
FU Ministry of Science and Technology, Taiwan [MOST104-2221-E-005-027-MY3,
   MOST101-2221-E-005-086-MY3]; National Cheng Kung University Hospital,
   Taiwan [NCKUH-10002006]
FX This work was supported in part by MOST104-2221-E-005-027-MY3 and
   MOST101-2221-E-005-086-MY3 from the Ministry of Science and Technology,
   Taiwan, and NCKUH-10002006 from the National Cheng Kung University
   Hospital, Taiwan.
CR Armstrong D, 1996, GASTROENTEROLOGY, V111, P85, DOI 10.1053/gast.1996.v111.pm8698230
   Ativanichayaphong T, 2010, IEEE MTT S INT MICR, P608, DOI 10.1109/MWSYM.2010.5517628
   BARRIENTOS M, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P1174, DOI 10.1109/IEMBS.1994.415379
   Bratkova M, 2009, IEEE COMPUT GRAPH, V29, P42, DOI 10.1109/MCG.2009.13
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cao H, 2012, IEEE T BIO-MED ENG, V59, P3131, DOI 10.1109/TBME.2012.2214773
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen WY, 2010, AM J GASTROENTEROL, V105, P1046, DOI 10.1038/ajg.2009.632
   Chen YT, 2007, PATTERN RECOGN, V40, P2706, DOI 10.1016/j.patcog.2006.11.023
   Cheng H, 2011, SURG ENDOSC, V25, P2478, DOI 10.1007/s00464-010-1569-x
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dawson B, 2001, BASIC CLIN BIOSTATIS
   De Falco I, 2014, IEEE T BIO-MED ENG, V61, P794, DOI 10.1109/TBME.2013.2290018
   Dent J, 1999, GUT, V44, pS1, DOI 10.1136/gut.44.2008.S1
   Dent J, 2005, GUT, V54, P710, DOI 10.1136/gut.2004.051821
   DeVault KR, 2005, AM J GASTROENTEROL, V100, P190, DOI 10.1111/j.1572-0241.2005.41217.x
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Gloger O, 2015, IEEE T BIO-MED ENG, V62, P795, DOI 10.1109/TBME.2014.2364862
   Gonzalez-Guillaumin JL, 2007, IEEE T BIO-MED ENG, V54, P2231, DOI 10.1109/TBME.2007.908332
   Hammond PA, 2005, IEEE T BIO-MED ENG, V52, P687, DOI 10.1109/TBME.2005.844041
   Holloway RH, 1996, GUT, V38, P649, DOI 10.1136/gut.38.5.649
   Huang CR, 2008, IEEE T INF TECHNOL B, V12, P523, DOI 10.1109/TITB.2007.913128
   Huang CR, 2008, PATTERN RECOGN, V41, P3071, DOI 10.1016/j.patcog.2008.03.013
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Kahrilas PJ, 1996, GASTROENTEROLOGY, V110, P1982, DOI 10.1053/gast.1996.1101982
   Karargyris A, 2015, IEEE T BIO-MED ENG, V62, P352, DOI 10.1109/TBME.2014.2352493
   KUBELKA P, 1948, J OPT SOC AM, V38, P448, DOI 10.1364/JOSA.38.000448
   Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2
   Lee YC, 2006, J GASTROEN HEPATOL, V21, P798, DOI 10.1111/j.1440-1746.2005.04034.x
   Liang HL, 2005, IEEE T BIO-MED ENG, V52, P1692, DOI 10.1109/TBME.2005.855719
   Lichtenstein DR, 2007, GASTROINTEST ENDOSC, V66, P219, DOI 10.1016/j.gie.2007.05.027
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Locke GR, 1997, GASTROENTEROLOGY, V112, P1448, DOI 10.1016/S0016-5085(97)70025-8
   Locke GR, 1999, AM J MED, V106, P642, DOI 10.1016/S0002-9343(99)00121-7
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lundell LR, 1999, GUT, V45, P172, DOI 10.1136/gut.45.2.172
   Luo XB, 2014, IEEE T BIO-MED ENG, V61, P85, DOI 10.1109/TBME.2013.2277609
   Moayyedi P, 2006, LANCET, V367, P2086, DOI 10.1016/S0140-6736(06)68932-0
   Munzenmayer C, 2009, METHOD INFORM MED, V48, P324, DOI 10.3414/ME9230
   Najmabadi M, 2007, 2007 IEEE BIOMEDICAL CIRCUITS AND SYSTEMS CONFERENCE, P207, DOI 10.1109/BIOCAS.2007.4463345
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Radovanovic M, 2010, J MACH LEARN RES, V11, P2487
   Rath HC, 2004, GASTROINTEST ENDOSC, V60, P44, DOI 10.1016/S0016-5107(04)01289-1
   Richter JE, 2003, AM J MED SCI, V326, P300, DOI 10.1097/00000441-200311000-00006
   Starner T, 2004, EIGHTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P194, DOI 10.1109/ISWC.2004.9
   TSUJI S, 1988, GASTROINTEST ENDOSC, V34, P332, DOI 10.1016/S0016-5107(88)71368-1
   Vakil N, 2006, AM J GASTROENTEROL, V101, P1900, DOI 10.1111/j.1572-0241.2006.00630.x
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yacob Y. M., 2009, P IEEE REG 10 C, P1
   Yang HB, 2009, AM J GASTROENTEROL, V104, P1642, DOI 10.1038/ajg.2009.172
   Yao K, 2005, ENDOSCOPY, V37, P479, DOI 10.1055/s-2005-861285
NR 54
TC 15
Z9 17
U1 1
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD MAR
PY 2016
VL 63
IS 3
BP 588
EP 599
DI 10.1109/TBME.2015.2466460
PG 12
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA DG2XJ
UT WOS:000371933800014
PM 26276981
DA 2023-04-20
ER

PT J
AU Ozkan, M
   Cakiroglu, M
   Kocaman, O
   Kurt, M
   Yilmaz, B
   Can, G
   Korkmaz, U
   Dandil, E
   Eksi, Z
AF Ozkan, Murat
   Cakiroglu, Murat
   Kocaman, Orhan
   Kurt, Mevlut
   Yilmaz, Bulent
   Can, Guray
   Korkmaz, Ugur
   Dandil, Emre
   Eksi, Ziya
TI Age-based computer-aided diagnosis approach for pancreatic cancer on
   endoscopic ultrasound images
SO ENDOSCOPIC ULTRASOUND
LA English
DT Article
DE Computer-aided diagnosis (CAD); endoscopic ultrasound (EUS) images;
   pancreatic cancer
ID EUS; STATISTICS
AB Aim: The aim was to develop a high-performance computer-aided diagnosis (CAD) system with image processing and pattern recognition in diagnosing pancreatic cancer by using endosonography images. Materials and Methods: On the images, regions of interest (ROI) of three groups of patients (<40, 40-60 and >60) were extracted by experts; features were obtained from images using three different techniques and were trained separately for each age group with an Artificial Neural Network (ANN) to diagnose cancer. The study was conducted on endosonography images of 202 patients with pancreatic cancer and 130 noncancer patients. Results: 122 features were identified from the 332 endosonography images obtained in the study, and the 20 most appropriate features were selected by using the relief method. Images classified under three age groups (in years; <40, 40-60 and >60) were tested via 200 random tests and the following ratios were obtained in the classification: accuracy: 92%, 88.5%, and 91.7%, respectively; sensitivity: 87.5%, 85.7%, and 93.3%, respectively; and specificity: 94.1%, 91.7%, and 88.9%, respectively. When all the age groups were assessed together, the following values were obtained: accuracy: 87.5%, sensitivity: 83.3%, and specificity: 93.3%. Conclusions: It was observed that the CAD system developed in the study performed better in diagnosing pancreatic cancer images based on classification by patient age compared to diagnosis without classification. Therefore, it is imperative to take patient age into consideration to ensure higher performance.
C1 [Ozkan, Murat] Bolu Vocat Sch, Dept Elect, Bolu, Turkey.
   [Ozkan, Murat] Bolu Vocat Sch, Dept Energy, Bolu, Turkey.
   [Kurt, Mevlut; Yilmaz, Bulent; Can, Guray; Korkmaz, Ugur] Abant Izzet Baysal Univ, Dept Gastroenterol, Bolu, Turkey.
   [Ozkan, Murat; Dandil, Emre] Sakarya Univ, Dept Comp & Informat Engn, Sakarya, Turkey.
   [Cakiroglu, Murat] Sakarya Univ, Dept Mechatron Engn, Sakarya, Turkey.
   [Eksi, Ziya] Sakarya Univ, Dept Elect & Comp Educ, Sakarya, Turkey.
   [Kocaman, Orhan] Bezmialem Vakif Univ, Dept Gastroenterol, Istanbul, Turkey.
   [Dandil, Emre] Bilecik Seyh Edebali Univ, Dept Comp Engn, Bilecik, Turkey.
C3 Ministry of National Education - Turkey; Ministry of Energy & Natural
   Resources - Turkey; Ministry of National Education - Turkey; Abant Izzet
   Baysal University; Sakarya University; Sakarya University; Sakarya
   University; Bezmialem Vakif University; Bilecik Seyh Edebali University
RP Kurt, M (通讯作者)，Abant Izzet Baysal Univ, Fac Med, Dept Gastroenterol, TR-14280 Golkoy, Bolu, Turkey.
EM dr.mevlutkurt@gmail.com
RI Kurt, Mevlut/Q-2093-2015; CAN, GÜRAY/AAA-3274-2020; Dandil,
   Emre/AAC-5860-2019
OI Kurt, Mevlut/0000-0003-3726-5945; Dandil, Emre/0000-0001-6559-1399; Can,
   Guray/0000-0002-6054-9244
FU Abant Izzet Baysal University BAP [2014.08.30.786]
FX This work was funded by Abant Izzet Baysal University BAP (No:
   2014.08.30.786).
CR AKILANDESWARI U, 2012, EUR J SCI RES, V71, P265
   Aslantas A, 2015, J CANC RES IN PRESS
   Cevik K.K., 2012, INT J INFORM TECHNOL, V5, P19
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036
   DIMAGNO EP, 1977, NEW ENGL J MED, V297, P737, DOI 10.1056/NEJM197710062971401
   FREENY PC, 1988, RADIOLOGY, V166, P125, DOI 10.1148/radiology.166.1.2827228
   Fritscher-Ravens A, 2002, AM J GASTROENTEROL, V97, P2768
   GUDJONSSON B, 1987, CANCER, V60, P2284, DOI 10.1002/1097-0142(19871101)60:9<2284::AID-CNCR2820600930>3.0.CO;2-V
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hidalgo M, 2010, NEW ENGL J MED, V362, P1605, DOI 10.1056/NEJMra0901557
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Rajan E, 2005, GASTROINTEST ENDOSC, V61, P401, DOI 10.1016/S0016-5107(04)02758-0
   Siegel R, 2014, CA-CANCER J CLIN, V64, P9, DOI 10.3322/caac.21208
   Tahir F, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/791246
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Zhang MM, 2010, GASTROINTEST ENDOSC, V72, P978, DOI 10.1016/j.gie.2010.06.042
   Zhu ML, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063820
NR 18
TC 43
Z9 44
U1 2
U2 7
PU WOLTERS KLUWER MEDKNOW PUBLICATIONS
PI MUMBAI
PA WOLTERS KLUWER INDIA PVT LTD , A-202, 2ND FLR, QUBE, C T S  NO 1498A-2
   VILLAGE MAROL, ANDHERI EAST, MUMBAI, 400059, INDIA
SN 2303-9027
EI 2226-7190
J9 ENDOSC ULTRASOUND
JI Endosc. Ultrasound
PD MAR-APR
PY 2016
VL 5
IS 2
BP 101
EP 107
DI 10.4103/2303-9027.180473
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA DK5KX
UT WOS:000374959900006
PM 27080608
OA Green Published
DA 2023-04-20
ER

PT J
AU Yuan, YX
   Li, BP
   Meng, MQH
AF Yuan, Yixuan
   Li, Baopu
   Meng, Max Q. -H.
TI Bleeding Frame and Region Detection in the Wireless Capsule Endoscopy
   Video
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Bleeding classification and region detection; words-based color
   histograms; wireless capsule endoscopy (WCE)
AB Wireless capsule endoscopy (WCE) enables noninvasive and painless direct visual inspection of a patient's whole digestive tract, but at the price of long time reviewing large amount of images by clinicians. Thus, an automatic computer-aided technique to reduce the burden of physicians is highly demanded. In this paper, we propose a novel color feature extraction method to discriminate the bleeding frames from the normal ones, with further localization of the bleeding regions. Our proposal is based on a twofold system. First, we make full use of the color information of WCE images and utilize K-means clustering method on the pixel represented images to obtain the cluster centers, with which we characterize WCE images as words-based color histograms. Then, we judge the status of a WCE frame by applying the support vector machine (SVM) and K-nearest neighbor methods. Comprehensive experimental results reveal that the best classification performance is obtained with YCbCr color space, cluster number 80 and the SVM. The achieved classification performance reaches 95.75% in accuracy, 0.9771 for AUC, validating that the proposed scheme provides an exciting performance for bleeding classification. Second, we propose a two-stage saliency map extraction method to highlight bleeding regions, where the first-stage saliency map is created by means of different color channels mixer and the second-stage saliency map is obtained from the visual contrast. Followed by an appropriate fusion strategy and threshold, we localize the bleeding areas. Quantitative as well as qualitative results show that our methods could differentiate the bleeding areas from neighborhoods correctly.
C1 [Yuan, Yixuan; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
   [Li, Baopu] Shenzhen Univ, Dept Biomed Engn, Shenzhen 518060, Peoples R China.
C3 Chinese University of Hong Kong; Shenzhen University
RP Meng, MQH (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.; Li, BP (通讯作者)，Shenzhen Univ, Dept Biomed Engn, Shenzhen 518060, Peoples R China.
EM bpli@szu.edu.cn; max@ee.cuhk.edu.hk
RI Meng, Max Q.-H./C-8078-2009; meng, meng/GWZ-7461-2022; Meng,
   Q./GSI-6185-2022
OI Yuan, Yixuan/0000-0002-0853-6948
FU RGC GRF [CUHK415613]; National Natural Science Foundation of China
   [61305099]
FX This project is partially supported by RGC GRF #CUHK415613 and National
   Natural Science Foundation of China (61305099).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   [Anonymous], 2010, [No title captured], DOI DOI 10.1109/CVPR.2010.5540018
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Conversano F, 2014, IEEE INT SYM MED MEA, P535
   Conversano F, 2011, ACAD RADIOL, V18, P461, DOI 10.1016/j.acra.2010.11.015
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Csurka G., 2004, WORKSH STAT LEARN CO, V44, P1, DOI DOI 10.1234/12345678
   Dudani S. A., 1976, IEEE Transactions on Systems, Man and Cybernetics, VSMC-6, P325, DOI 10.1109/TSMC.1976.5408784
   Faigel D. O., 2008, CAPSULE ENDOSCOPY SA
   Francis R., 2004, 3 INT C CAPS END MIA
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Gay G, 2004, ENDOSCOPY, V36, P913, DOI 10.1055/s-2004-825868
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hwang S, 2006, PROC SPIE, V6144, DOI 10.1117/12.654109
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Lee NM, 2010, EXPERT REV GASTROENT, V4, P503, DOI 10.1586/EGH.10.44
   Lei Cui, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P1746, DOI 10.1109/ICINFA.2010.5512218
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li Q, 2006, MED PHYS, V33, P868, DOI 10.1118/1.2179750
   Lv GL, 2011, IEEE ENG MED BIO, P6643, DOI 10.1109/IEMBS.2011.6091638
   Otsu N., 1975, AUTOMATICA, V11, P23, DOI [10.1109/TSMC.1979.4310076, DOI 10.1109/TSMC.1979.4310076]
   Pennazio M, 2006, DIGEST LIVER DIS, V38, P867, DOI 10.1016/j.dld.2006.09.007
   Schanda J, 2007, COLORIMETRY: UNDERSTANDING THE CIE SYSTEM, P1, DOI 10.1002/9780470175637
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Sharma G, 1997, IEEE T IMAGE PROCESS, V6, P901, DOI 10.1109/83.597268
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yonghui Zhao, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2725, DOI 10.1109/ICIP.2011.6116232
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
NR 30
TC 92
Z9 96
U1 1
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD MAR
PY 2016
VL 20
IS 2
BP 624
EP 630
DI 10.1109/JBHI.2015.2399502
PG 7
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA DH2QP
UT WOS:000372631500020
PM 25675468
DA 2023-04-20
ER

PT J
AU Tajbakhsh, N
   Gurudu, SR
   Liang, JM
AF Tajbakhsh, Nima
   Gurudu, Suryakanth R.
   Liang, Jianming
TI Automated Polyp Detection in Colonoscopy Videos Using Shape and Context
   Information
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Optical colonoscopy; polyp detection; boundary classification; edge
   voting; detection latency
ID COMPUTER-AIDED DETECTION; CT COLONOGRAPHY; MISS RATE; COLORECTAL-CANCER;
   TEXTURE FEATURES; CLASSIFICATION; CURVATURE
AB This paper presents the culmination of our research in designing a system for computer-aided detection (CAD) of polyps in colonoscopy videos. Our system is based on a hybrid context-shape approach, which utilizes context information to remove non-polyp structures and shape information to reliably localize polyps. Specifically, given a colonoscopy image, we first obtain a crude edge map. Second, we remove non-polyp edges from the edge map using our unique feature extraction and edge classification scheme. Third, we localize polyp candidates with probabilistic confidence scores in the refined edge maps using our novel voting scheme. The suggested CAD system has been tested using two public polyp databases, CVC-ColonDB, containing 300 colonoscopy images with a total of 300 polyp instances from 15 unique polyps, and ASU-Mayo database, which is our collection of colonoscopy videos containing 19,400 frames and a total of 5,200 polyp instances from 10 unique polyps. We have evaluated our system using free-response receiver operating characteristic (FROC) analysis. At 0.1 false positives per frame, our system achieves a sensitivity of 88.0% for CVC-ColonDB and a sensitivity of 48% for the ASU-Mayo database. In addition, we have evaluated our system using a new detection latency analysis where latency is defined as the time from the first appearance of a polyp in the colonoscopy video to the time of its first detection by our system. At 0.05 false positives per frame, our system yields a polyp detection latency of 0.3 seconds.
C1 [Tajbakhsh, Nima; Liang, Jianming] Arizona State Univ, Dept Biomed Informat, Scottsdale, AZ 85259 USA.
   [Gurudu, Suryakanth R.] Mayo Clin, Div Gastroenterol & Hepatol, Scottsdale, AZ 85259 USA.
C3 Arizona State University; Mayo Clinic; Mayo Clinic Phoenix
RP Tajbakhsh, N (通讯作者)，Arizona State Univ, Dept Biomed Informat, Scottsdale, AZ 85259 USA.
EM nima.tajbakhsh@asu.edu; gurudu.suryakanth@mayo.edu;
   jianming.liang@asu.edu
RI Tajbakhsh, Nima/AAC-1354-2019
OI Liang, Jianming/0000-0001-5486-1613; Liang, Jianming/0000-0002-3029-341X
FU Arizona State University; Mayo Clinic
FX This work was supported by the seed grant awarded by Arizona State
   University and Mayo Clinic.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Atherton T., 1993, IEE C HOUGH TRANSF, P5
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Cheng DC, 2011, BIOMED ENG-APP BAS C, V23, P357, DOI 10.4015/S1016237211002761
   Criminisi A., 2013, DECISION FORESTS COM
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Figueiredo IN, 2014, COMPUTATIONAL VISION AND MEDICAL IMAGE PROCESSING IV, P229
   Gross S., 2012, AUTOMATED CLASSIFICA, V83
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kim DH, 2007, NEW ENGL J MED, V357, P1403, DOI 10.1056/NEJMoa070543
   Kwitt R, 2011, LECT NOTES COMPUT SC, V6893, P280, DOI 10.1007/978-3-642-23626-6_35
   Lee JG, 2011, COMPUT BIOL MED, V41, P790, DOI 10.1016/j.compbiomed.2011.06.015
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Lieberman D, 2005, GASTROINTEST ENDOSC, V61, P392, DOI 10.1016/S0016-5107(05)00133-1
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468
   Mordohai P., 2007, SYNTHESIS LECT IMAGE
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ong JL, 2011, IEEE T IMAGE PROCESS, V20, P1000, DOI 10.1109/TIP.2010.2076295
   Pabby A, 2005, GASTROINTEST ENDOSC, V61, P385, DOI 10.1016/S0016-5107(04)02765-8
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P471, DOI 10.1016/S0002-9270(02)05928-2
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Siegel RL, 2015, CA-CANCER J CLIN, V65, P5, DOI 10.3322/caac.21254
   Silva J., 2013, INT J COMPUT ASSIST, P1
   Suzuki K, 2010, IEEE T MED IMAGING, V29, P1907, DOI 10.1109/TMI.2010.2053213
   Tajbakhsh N., 2014, LECT NOTES COMPUT SC
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Tajbakhsh N, 2014, I S BIOMED IMAGING, P97, DOI 10.1109/ISBI.2014.6867818
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   van Ravesteijn VF, 2010, IEEE T MED IMAGING, V29, P120, DOI 10.1109/TMI.2009.2028576
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   van Wijk C, 2010, IEEE T MED IMAGING, V29, P688, DOI 10.1109/TMI.2009.2031323
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Zhao LX, 2006, IEEE T VIS COMPUT GR, V12, P885, DOI 10.1109/TVCG.2006.158
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
   Zhu H., 2011, VIRTUAL COLONOSCOPY, V6668, P9
NR 50
TC 242
Z9 256
U1 7
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD FEB
PY 2016
VL 35
IS 2
BP 630
EP 644
DI 10.1109/TMI.2015.2487997
PG 15
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA DE6LQ
UT WOS:000370745600024
PM 26462083
DA 2023-04-20
ER

PT J
AU Ben Ismail, MM
   Bchir, O
AF Ben Ismail, Mohamed Maher
   Bchir, Ouiem
TI Endoscopy video summarisation using novel relational motion histogram
   descriptor and semi-supervised clustering
SO JOURNAL OF EXPERIMENTAL & THEORETICAL ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE capsule endoscopy; semi-supervised clustering; relational clustering;
   motion descriptor
ID OPTICAL-FLOW; C-MEANS; CAPSULE
AB In this paper, we propose a novel system for capsule endoscopy (CE) summarisation that has two main components. The first component consists of the Semi-Supervised Clustering and Local Scale Learning (SS-LSL) algorithm. This algorithm is used to group video frames into prototypical clusters that summarise the CE video. The constraints consist of pairs of frames that should not be included in the same cluster. These constraints are deduced from the training frames to help in guiding the clustering process. The second component of the system consists of a novel relational motion histogram descriptor that is designed to represent the local motion distribution between two contiguous frames. The main idea is to identify "highlight" frames which contain typical variations within the frame collection. These variations are due to different pathologies, small tumours and other subtle abnormalities of the small intestine and so on. SS-LSL algorithm is assessed using synthetic data sets, and proved to outperform similar clustering algorithms because of its ability to discover clusters of different sizes and densities. The proposed video summarisation system is trained, field-tested, evaluated and compared using a large-scale cross-validation experiment that uses videos from Video Surveillance Online Repository, and four CE videos acquired from four patients. This collection includes more than 150k video frames.
C1 [Ben Ismail, Mohamed Maher; Bchir, Ouiem] King Saud Univ, Coll Comp & Informat Sci, POB 51178, Riyadh 11541, Saudi Arabia.
C3 King Saud University
RP Ben Ismail, MM (通讯作者)，King Saud Univ, Coll Comp & Informat Sci, POB 51178, Riyadh 11541, Saudi Arabia.
EM mbenismail@ksu.edu.sa; obchir@ksu.edu.sa
FU Research Center of the College of Computer and Information Sciences,
   King Saud University
FX This work was supported by the Research Center of the College of
   Computer and Information Sciences, King Saud University. The authors are
   grateful for this support.
CR [Anonymous], 2004, PROC 21 INT C MACH L
   [Anonymous], CLUSTER ANAL
   Baopu Li, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P373, DOI 10.1109/ICINFA.2011.5949020
   Baopu Li, 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P454, DOI 10.1109/ROBIO.2010.5723369
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Basu S., 2002, P 19 INT C MACH LEAR, P19
   BATTITI R, 1991, INT J COMPUT VISION, V6, P133, DOI 10.1007/BF00128153
   Bchir Ouiem, 2010, Proceedings of the 2010 IEEE International Workshop on Machine Learning for Signal Processing (MLSP), P289, DOI 10.1109/MLSP.2010.5589234
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   BEZDEK JC, 1981, SIAM J APPL MATH, V40, P339, DOI 10.1137/0140029
   Chang H., 2005, BRIT MACH VIS C BMVC
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Frigui H, 2007, PATTERN RECOGN, V40, P3053, DOI 10.1016/j.patcog.2007.02.019
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Handoko D, 2000, 2000 SYMPOSIUM ON VLSI CIRCUITS, DIGEST OF TECHNICAL PAPERS, P28, DOI 10.1109/VLSIC.2000.852842
   HATHAWAY RJ, 1994, PATTERN RECOGN, V27, P429, DOI 10.1016/0031-3203(94)90119-8
   HATHAWAY RJ, 1989, PATTERN RECOGN, V22, P205, DOI 10.1016/0031-3203(89)90066-6
   Hoi S. C. H., 2008, C COMP VIS PATT REC
   Iakovidis D. K., 2008, P 4 INT IEEE C, P3
   Iakovidis D.K., 2013, BIOINF BIOENG BIBE 2, P1
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Kodogiannis Vassilis S., 2008, WORLD ACAD SCI ENG T, V21, P620
   Kumar N., 2005, INT C DAT MIN ICDM T
   Lim S, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P925, DOI 10.1109/ICIP.2001.958646
   Liu XQ, 2001, P SOC PHOTO-OPT INS, V4306, P450, DOI 10.1117/12.426983
   Mackiewicz M., 2011, NEW TECHNIQUES GASTR, DOI [10.5772/23145, DOI 10.5772/23145]
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   MacQueen J., 1967, P 5 BERKELEY S MATH, V1, P281
   Mannjunath B. S., 2002, INTRO MPEG 7 MULTIME
   Mewes P. W., 2012, MED IMAGING COMPUTER, V8315, P1
   Miaou SG, 2009, J MED BIOL ENG, V29, P114
   Okun O, 2007, SIGNAL PROCESS, V87, P2260, DOI 10.1016/j.sigpro.2007.02.006
   Qian Zhao, 2010, 2010 IEEE International Conference on Automation and Logistics (ICAL), P565, DOI 10.1109/ICAL.2010.5585347
   Riccioni ME, 2012, WORLD J GASTRO ENDOS, V4, P99, DOI 10.4253/wjge.v4.i4.99
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Stevanovic N., 2000, 2000 IEEE International Solid-State Circuits Conference. Digest of Technical Papers (Cat. No.00CH37056), P104, DOI 10.1109/ISSCC.2000.839710
   Stiller C, 1999, IEEE SIGNAL PROC MAG, V16, P70, DOI 10.1109/79.774934
   Sun Z, 2012, IEEE INT C AUTOMAT L, P294, DOI 10.1109/ICAL.2012.6308214
   Tsevas S, 2008, IEEE INT C BIOINF BI, P921
   Xing E.P., 2003, P ADV NEURAL INFORM, P521
   Yang DXD, 1999, IEEE J SOLID-ST CIRC, V34, P1821, DOI 10.1109/4.808907
   Zeitoun JD, 2007, WORLD J GASTROENTERO, V13, P1451, DOI 10.3748/wjg.v13.i9.1451
   Zhou R, 2013, IEEE INT C INT ROBOT, P3096, DOI 10.1109/IROS.2013.6696795
NR 45
TC 3
Z9 3
U1 0
U2 6
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0952-813X
EI 1362-3079
J9 J EXP THEOR ARTIF IN
JI J. Exp. Theor. Artif. Intell.
PY 2016
VL 28
IS 4
BP 629
EP 653
DI 10.1080/0952813X.2015.1020623
PG 25
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DU6MR
UT WOS:000382329700002
DA 2023-04-20
ER

PT J
AU Constantinescu, AF
   Ionescu, M
   Iovanescu, VF
   Ciurea, ME
   Ionescu, AG
   Streba, CT
   Bunescu, MG
   Rogoveanu, I
   Vere, CC
AF Constantinescu, Adriana Florentina
   Ionescu, Mihaela
   Iovanescu, Vlad-Florin
   Ciurea, Marius Eugen
   Ionescu, Alin Gabriel
   Streba, Costin Teodor
   Bunescu, Marius-Gabriel
   Rogoveanu, Ion
   Vere, Cristin Constantin
TI A computer-aided diagnostic system for intestinal polyps identified by
   wireless capsule endoscopy
SO ROMANIAN JOURNAL OF MORPHOLOGY AND EMBRYOLOGY
LA English
DT Article
DE small bowel polyps; morphological features; artificial neural network;
   computer-aided diagnosis system
ID LESION DETECTION; MANAGEMENT
AB Small bowel polyps present in images acquired by wireless capsule endoscopy are more difficult to detect using computer-aided diagnostic (CAD) systems. We aimed to identify the optimum morphological characteristics that best describe a polyp and convert them into feature vectors used for automatic detection of polyps present in images acquired by wireless capsule endoscopy (WCE). We prospectively induded 54 patients with clinical indications for WCE. Initially, physicians analyzed all images acquired, identifying the frames that contained small bowel polyps. Subsequently, all images were analyzed using an automated computer-aided diagnostic system designed and implemented to convert physical characteristics into vectors of numeric values. The data set was completed with texture and color information, and then analyzed by a feed forward back propagation artificial neural network (ANN) trained to identify the presence of polyps in WCE frames. Overall, the neural network had 93.75% sensitivity, 91.38% specificity, 85.71% positive predictive value (PPV) and 96.36% negative predictive value (NPV). In comparison, physicians' diagnosis indicated 94.79% sensitivity, 93.68% specificity, 89.22% PPV and 97.02% NPV, thus showing that ANN diagnosis was similar to that of human interpretation. Computer-aided diagnostic of small bowel polyps, based on morphological features detection methods, emulation and neural networks classification, seems efficient, fast and reliable for physicians.
C1 [Constantinescu, Adriana Florentina] Univ Med & Pharm Craiova, Dept Internal Med, Craiova, Romania.
   [Ionescu, Mihaela] Univ Med & Pharm Craiova, Dept Bioinformat & Biostat, 2 Petru Rares St, Craiova 200349, Romania.
   [Iovanescu, Vlad-Florin; Ionescu, Alin Gabriel; Streba, Costin Teodor; Rogoveanu, Ion; Vere, Cristin Constantin] Univ Med & Pharm Craiova, Res Ctr Gastroenterol & Hepatol, Craiova, Romania.
   [Ciurea, Marius Eugen] Univ Med & Pharm Craiova, Dept Plast Surg & Reconstruct Microsurg, Craiova, Romania.
   [Bunescu, Marius-Gabriel] Univ Med & Pharm Craiova, Dept Labor Med, Craiova, Romania.
C3 University of Medicine & Pharmacy of Craiova; University of Medicine &
   Pharmacy of Craiova; University of Medicine & Pharmacy of Craiova;
   University of Medicine & Pharmacy of Craiova; University of Medicine &
   Pharmacy of Craiova
RP Ionescu, M (通讯作者)，Univ Med & Pharm Craiova, Dept Bioinformat & Biostat, 2 Petru Rares St, Craiova 200349, Romania.
EM miki.iones@yahoo.com
RI Bunescu, Marius/AAQ-1568-2021; Ciurea, Marius/ABS-6302-2022; Ionescu,
   Mihaela/AAO-6869-2021; Streba, Costin Teodor/C-4196-2011
OI Ciurea, Marius/0000-0001-8242-5333; Bunescu, Marius/0000-0003-4504-4691;
   Streba, Costin Teodor/0000-0001-9590-3197
FU National Research Council (CNCS), Romania [209/2014]
FX This work was supported from one research grant funded by the National
   Research Council (CNCS), Romania, entitled "Intelligent Imagistic
   Diagnosis Support Infrastructure (INDISIO)", contract number 209/2014.
   The handers had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.
CR Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Cardoso H, 2015, ACTA MEDICA PORT, V28, P448, DOI 10.20344/amp.6479
   Cheung DY, 2016, CLIN ENDOSC, V49, P21, DOI 10.5946/ce.2016.49.1.21
   Devi K. G., 2013, WORLD J MED SCI, V9, P273
   Fiori M, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414600143
   Ginsberg GG, 2002, GASTROINTEST ENDOSC, V56, P621, DOI 10.1016/S0016-5107(02)70106-5
   Gunther U, 2010, INT J COLORECTAL DIS, V25, P1377, DOI 10.1007/s00384-010-0982-x
   Hadithi M, 2006, AM J GASTROENTEROL, V101, P52, DOI 10.1111/j.1572-0241.2005.00346.x
   Hagel AF, 2014, CAN J GASTROENTEROL, V28, P77, DOI 10.1155/2014/691785
   Iakovidis D.K., 2013, P 13 IEEE INT C BIOI, P1
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Min YW, 2016, CLIN ENDOSC, V49, P16, DOI 10.5946/ce.2016.49.1.16
   Pan SY, 2011, WORLD J GASTRO ONCOL, V3, P33, DOI 10.4251/wjgo.v3.i3.33
   Pandey V, 2016, INTEST RES, V14, P69, DOI 10.5217/ir.2016.14.1.69
   Rondonotti E, 2015, DIGEST DIS, V33, P244, DOI 10.1159/000369510
   Rosa B, 2015, ACTA MEDICA PORT, V28, P632, DOI 10.20344/amp.6128
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Scapa E, 2002, AM J GASTROENTEROL, V97, P2776, DOI 10.1111/j.1572-0241.2002.07021.x
   Singeap AM, 2016, WORLD J GASTROENTERO, V22, P369, DOI 10.3748/wjg.v22.i1.369
   Swain P, 2004, GUT, V53, P1866, DOI 10.1136/gut.2003.035576
   Szczypinski PM, 2009, MED IMAGE ANAL, V13, P312, DOI 10.1016/j.media.2008.12.002
   Vere CC, 2009, INTRO ENDOSCOPIA DIG, P205
   Vere CC, 2010, TEHNICI MODERNE DIAG, P43
   Wang HF, 2015, PHYS MED BIOL, V60, P7207, DOI 10.1088/0031-9155/60/18/7207
   Yang DH, 2016, GASTROENT RES PRACT, V2016, DOI 10.1155/2016/8236367
   Zhou MD, 2014, IEEE ENG MED BIO, P5591, DOI 10.1109/EMBC.2014.6944894
NR 29
TC 10
Z9 10
U1 0
U2 6
PU EDITURA ACAD ROMANE
PI BUCURESTI
PA CALEA 13 SEPTEMBRIE NR 13, SECTOR 5, BUCURESTI 050711, ROMANIA
SN 1220-0522
J9 ROM J MORPHOL EMBRYO
JI Rom. J. Morphol. Embryol.
PY 2016
VL 57
IS 3
BP 979
EP 984
PG 6
WC Developmental Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Developmental Biology
GA EG5LJ
UT WOS:000391085000009
PM 28002513
DA 2023-04-20
ER

PT J
AU Khachidze, M
   Tsintsadze, M
   Archuadze, M
AF Khachidze, Manana
   Tsintsadze, Magda
   Archuadze, Maia
TI Natural Language Processing Based Instrument for Classification of Free
   Text Medical Records
SO BIOMED RESEARCH INTERNATIONAL
LA English
DT Article
ID CLASSIFIERS; SELECTION
AB According to the Ministry of Labor, Health and Social Affairs of Georgia a new health management system has to be introduced in the nearest future. In this context arises the problem of structuring and classifying documents containing all the history of medical services provided. The present work introduces the instrument for classification of medical records based on the Georgian language. It is the first attempt of such classification of the Georgian language based medical records. On the whole 24.855 examination records have been studied. The documents were classified into three main groups (ultrasonography, endoscopy, and X-ray) and 13 subgroups using two well-known methods: Support Vector Machine (SVM) and K-Nearest Neighbor (KNN). The results obtained demonstrated that both machine learning methods performed successfully, with a little supremacy of SVM. In the process of classification a "shrink" method, based on features selection, was introduced and applied. At the first stage of classification the results of the "shrink" case were better; however, on the second stage of classification into subclasses 23% of all documents could not be linked to only one definite individual subclass (liver or binary system) due to common features characterizing these subclasses. The overall results of the study were successful.
C1 [Khachidze, Manana; Tsintsadze, Magda; Archuadze, Maia] Ivane Javakhishvili Tbilisi State Univ, Univ St 3, GE-0179 Tbilisi, Georgia.
C3 Ivane Javakhishvili Tbilisi State University
RP Tsintsadze, M (通讯作者)，Ivane Javakhishvili Tbilisi State Univ, Univ St 3, GE-0179 Tbilisi, Georgia.
EM magda.tsintsadze@tsu.ge
RI archuadze, maia/H-3505-2016; Tsintsadze, Magda/AGN-4188-2022
OI archuadze, maia/0000-0002-9484-1016; Tsintsadze,
   Magda/0000-0001-9316-3295
CR [Anonymous], 2012, INT J INTELLIGENCE A, DOI DOI 10.5121/IJAIA.2012.3208
   Aronson AR, 2001, J AM MED INFORM ASSN, P17
   Aronson Howard., 1990, GEORGIAN READING GRA
   Baruch Jordon J., 1965, COMPUTERS BIOMEDICAL, P291
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Demner-Fushman D, 2009, J BIOMED INFORM, V42, P760, DOI 10.1016/j.jbi.2009.08.007
   Farkas R, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S3-S10
   Friedman C., 2013, BIOMEDICAL INFORM, P255
   Gao HY, 2015, J BIOMED INFORM, V54, P77, DOI 10.1016/j.jbi.2015.01.010
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Heaps H. S., 1978, INFORM RETRIEVAL COM
   Hull D. A., 1996, DETAILED ANAL ENGLIS
   Khachidze M., 2015, P 4 ANN C EX NAT SCI
   Khachidze M, 2015, BALT J MOD COMPUT, V3, P307
   Kotfila C, 2015, J BIOMED INFORM, V58, pS92, DOI 10.1016/j.jbi.2015.07.016
   LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281, DOI 10.1055/s-0038-1634945
   Luo G., 2012, P 2 ACM SIGHIT INT H
   Manning C., 2008, INTRO IINFORMATION R
   Marafino B, 2014, J AM MED INFORM ASSN, V21, P871, DOI 10.1136/amiajnl-2014-002694
   Morris F., 2015, HIST MED INFORM US
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Pedersen J. O, 1997, P ICML
   Pollettini JT, 2012, J MED SYST, V36, P3861, DOI 10.1007/s10916-012-9859-6
   Porter M. F., 2004, STEMMING ALGORITHMS
   Revathy N., 2011, INT J COMPUT APPL, V14, P19
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sarker A, 2015, J BIOMED INFORM, V53, P196, DOI 10.1016/j.jbi.2014.11.002
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Sonel A. F., 2006, USE REMIND ARTIFICIA
   Tanushi H., 2013, P 19 NORD C COMP LIN
   杨云峰, 1999, [西安公路交通大学学报, Journal of Xian Highway University], P67
NR 33
TC 13
Z9 14
U1 0
U2 5
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2314-6133
EI 2314-6141
J9 BIOMED RES INT
JI Biomed Res. Int.
PY 2016
VL 2016
AR 8313454
DI 10.1155/2016/8313454
PG 10
WC Biotechnology & Applied Microbiology; Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Biotechnology & Applied Microbiology; Research & Experimental Medicine
GA DW2ZK
UT WOS:000383511200001
PM 27668260
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Patel, V
   Armstrong, D
   Ganguli, M
   Roopra, S
   Kantipudi, N
   Albashir, S
   Kamath, MV
AF Patel, Vivek
   Armstrong, David
   Ganguli, Malika
   Roopra, Sandeep
   Kantipudi, Neha
   Albashir, Siwar
   Kamath, Markad V.
TI Deep Learning in Gastrointestinal Endoscopy
SO CRITICAL REVIEWS IN BIOMEDICAL ENGINEERING
LA English
DT Article
AB Gastrointestinal (GI) endoscopy is used to inspect the lumen or interior of the GI tract for several purposes, including, (1) making a clinical diagnosis, in real time, based on the visual appearances; (2) taking targeted tissue samples for subsequent histopathological examination; and (3) in some cases, performing therapeutic interventions targeted at specific lesions. GI endoscopy is therefore predicated on the assumption that the operator-the endoscopist-is able to identify and characterize abnormalities or lesions accurately and reproducibly. However, as in other areas of clinical medicine, such as histopathology and radiology, many studies have documented marked interobserver and intraobserver variability in lesion recognition. Thus, there is a clear need and opportunity for techniques or methodologies that will enhance the quality of lesion recognition and diagnosis and improve the outcomes of GI endoscopy.
   Deep learning models provide a basis to make better clinical decisions in medical image analysis. Biomedical image segmentation, classification, and registration can be improved with deep learning. Recent evidence suggests that the application of deep learning methods to medical image analysis can contribute significantly to computer-aided diagnosis. Deep learning models are usually considered to be more flexible and provide reliable solutions for image analysis problems compared to conventional computer vision models. The use of fast computers offers the possibility of real-time support that is important for endoscopic diagnosis, which has to be made in real time. Advanced graphics processing units and cloud computing have also favored the use of machine learning, and more particularly, deep learning for patient care. This paper reviews the rapidly evolving literature on the feasibility of applying deep learning algorithms to endoscopic imaging.
C1 [Patel, Vivek; Armstrong, David; Ganguli, Malika; Roopra, Sandeep; Kantipudi, Neha; Albashir, Siwar; Kamath, Markad V.] McMaster Univ, Dept Med, Hamilton, ON, Canada.
C3 McMaster University
RP Patel, V (通讯作者)，Dept Med, 3H2,1280 Main St West, Hamilton, ON L8S 4L8, Canada.
EM vivekpatel36@gmail.com
OI Armstrong, David/0000-0003-2487-1479
CR Alex K., 2017, ADV NEURAL INF PROCE, V60, P84, DOI [10.1145/3065386, DOI 10.1145/3065386]
   Annese V, 2013, J CROHNS COLITIS, V7, P982, DOI 10.1016/j.crohns.2013.09.016
   [Anonymous], GUIDANCE INDICATIONS
   [Anonymous], I SEE I THINK I DRIV
   Assadsangabi A, 2015, J GASTROEN HEPATOL, V30, P984, DOI 10.1111/jgh.12891
   Barkin Jodie A, 2017, Gastrointest Endosc Clin N Am, V27, P15, DOI 10.1016/j.giec.2016.08.002
   Belsey J, 2012, CURR MED RES OPIN, V28, P1883, DOI 10.1185/03007995.2012.747953
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bughin J, ARTIFICIAL INTELLIGE
   Churchland M. M., 2012, NATURE, V487, P51, DOI DOI 10.1038/nature11129
   Cobrin GM, 2006, CANCER-AM CANCER SOC, V107, P22, DOI 10.1002/cncr.21975
   Culliford A, 2005, GASTROINTEST ENDOSC, V62, P55, DOI 10.1016/S0016-5107(05)01566-X
   Enns RA, 2017, GASTROENTEROLOGY, V152, P497, DOI 10.1053/j.gastro.2016.12.032
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Jensen MD, 2017, ANN GASTROENTEROL, V30, P168, DOI 10.20524/aog.2016.0119
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Ketkar N., 2017, DEEP LEARNING PYTHON, DOI [10.1007/978-1-4842-2766-4, DOI 10.1007/978-1-4842-2766-4]
   Kevin M, 2012, MACHINE LEARNING PRO
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee HS, 2016, GASTROENT RES PRACT, V2016, DOI 10.1155/2016/9804783
   Loffeld RJLF, 2015, INT J COLORECTAL DIS, V30, P927, DOI 10.1007/s00384-015-2181-2
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Pu W, 2017, 2017 WORLD C GASTR
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Rokkas T, 2010, GASTROINTEST ENDOSC, V71, P792, DOI 10.1016/j.gie.2009.10.050
   Schramm C, 2017, UNITED EUR GASTROENT, V5, P742, DOI 10.1177/2050640616675220
   Shahid MW, 2012, AM J GASTROENTEROL, V107, P231, DOI 10.1038/ajg.2011.376
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Taha Bilal, 2017, Proceedings of the IASTED International Conference on Biomedical Engineering (BioMed 2017), P233, DOI 10.2316/P.2017.852-031
   Wu LC, 2011, SCAND J GASTROENTERO, V46, P227, DOI 10.3109/00365521.2010.525714
   Yu JS, 2015 IEEE INT C ROB
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang YZ, 2014, WORLD J GASTROENTERO, V20, P91, DOI 10.3748/wjg.v20.i1.91
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 38
TC 4
Z9 5
U1 2
U2 13
PU BEGELL HOUSE INC
PI DANBURY
PA 50 NORTH ST, DANBURY, CT 06810 USA
SN 0278-940X
EI 1943-619X
J9 CRIT REV BIOMED ENG
JI Crit. Rev. Biomed. Eng.
PY 2016
VL 44
IS 6
BP 493
EP 504
DI 10.1615/CritRevBiomedEng.2017025035
PG 12
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA VC1HR
UT WOS:000428955600006
PM 29431094
DA 2023-04-20
ER

PT J
AU Ribeiro, E
   Uhl, A
   Wimmer, G
   Hafner, M
AF Ribeiro, Eduardo
   Uhl, Andreas
   Wimmer, Georg
   Haefner, Michael
TI Exploring Deep Learning and Transfer Learning for Colonic Polyp
   Classification
SO COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE
LA English
DT Article
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Recently, Deep Learning, especially through Convolutional Neural Networks (CNNs) has been widely used to enable the extraction of highly representative features. This is done among the network layers by filtering, selecting, and using these features in the last fully connected layers for pattern classification. However, CNN training for automated endoscopic image classification still provides a challenge due to the lack of large and publicly available annotated databases. In this work we explore Deep Learning for the automated classification of colonic polyps using different configurations for training CNNs from scratch (or full training) and distinct architectures of pretrained CNNs tested on 8-HD-endoscopic image databases acquired using different modalities. We compare our results with some commonly used features for colonic polyp classification and the good results suggest that features learned by CNNs trained from scratch and the "off-the-shelf" CNNs features can be highly relevant for automated classification of colonic polyps. Moreover, we also show that the combination of classical features and "off-the-shelf" CNNs features can be a good approach to further improve the results.
C1 [Ribeiro, Eduardo; Uhl, Andreas; Wimmer, Georg] Salzburg Univ, Dept Comp Sci, Salzburg, Austria.
   [Ribeiro, Eduardo] Fed Univ Tocantins, Dept Comp Sci, Palmas, TO, Brazil.
   [Haefner, Michael] St Elizabeth Hosp, Vienna, Austria.
C3 Salzburg University; Universidade Federal do Tocantins (UFT)
RP Ribeiro, E (通讯作者)，Salzburg Univ, Dept Comp Sci, Salzburg, Austria.
EM ufg.eduardo@gmail.com
FU CNPq, Brazil [00736/2014-0]
FX This research was partially supported by CNPq, Brazil, for Eduardo
   Ribeiro under Grant no. 00736/2014-0.
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, 10.1007/978-3-540-93860-6_70]
   Arevalo J, 2015, IEEE ENG MED BIO, P797, DOI 10.1109/EMBC.2015.7318482
   Bar Y, 2015, I S BIOMED IMAGING, P294, DOI 10.1109/ISBI.2015.7163871
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Chatfield K., 2014, P 25 BRIT MACH VIS C
   Ciompi F, 2015, MED IMAGE ANAL, V26, P195, DOI 10.1016/j.media.2015.08.001
   Ciresan D., 2012, ADV NEURAL INF PROCE, V25, P2843
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Coates Adam, 2011, P 14 INT C ART INT S
   Dong YS, 2015, IEEE T CYBERNETICS, V45, P358, DOI 10.1109/TCYB.2014.2326059
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gross S., 2012, AUTOMATED CLASSIFICA
   Guo J., DEEP CNN ENSEMBLE DA
   Hafner M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P365, DOI 10.1007/978-3-662-46224-9_63
   Hafner M, 2012, COMPUT METH PROG BIO, V107, P565, DOI 10.1016/j.cmpb.2011.12.012
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hafner M, 2009, PATTERN ANAL APPL, V12, P407, DOI 10.1007/s10044-008-0136-8
   Hafner Michael, 2014, Medical Computer Vision Large Data in Medical Imaging. Third International MICCAI Workshop, MCV 2013. Revised Selected Papers. LNCS: 8331, P205, DOI 10.1007/978-3-319-05530-5_20
   Hafner M., 2010, 10 IEEE INT C INF TE, P1
   HAFNER M, 2012, P INT S COMP BAS MED, P1, DOI DOI 10.1109/CBMS.2012.6266355
   Hafner M., 2009, P 9 INT C INF TECHN, P1
   Hatipoglu N, 2014, 4 INT C IM PROC THEO, P1, DOI DOI 10.1109/IPTA.2014.7001976
   Kato S, 2006, WORLD J GASTROENTERO, V12, P1416, DOI 10.3748/wjg.v12.i9.1416
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   LeCun Y., 2001, INTELLIGENT SIGNAL P, P306
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Roth H., 2014, CORR
   Roth H. R., 2014, NEW 2 5D REPRESENTAT
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Sermanet P., 2013, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1312.6229
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K., 2014, ARXIV PREPRINT ARXIV
   Stehle T., 2009, P SPIE, V7260
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, LECT NOTES COMPUT SC, V9350, P62, DOI 10.1007/978-3-319-24571-3_8
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Vedaldi A., 2014, CORR
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 57
TC 95
Z9 95
U1 3
U2 18
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1748-670X
EI 1748-6718
J9 COMPUT MATH METHOD M
JI Comput. Math. Method Med.
PY 2016
VL 2016
AR 6584725
DI 10.1155/2016/6584725
PG 16
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA EB5BD
UT WOS:000387387100001
OA Green Submitted, Green Published, gold
HC Y
HP N
DA 2023-04-20
ER

PT J
AU Dolati, P
   Golby, A
   Eichberg, D
   Abolfotoh, M
   Dunn, IF
   Mukundan, S
   Hulou, MM
   Al-Mefty, O
AF Dolati, Parviz
   Golby, Alexandra
   Eichberg, Daniel
   Abolfotoh, Mohamad
   Dunn, Ian F.
   Mukundan, Srinivasan
   Hulou, Mohamed M.
   Al-Mefty, Ossama
TI Pre-operative image-based segmentation of the cranial nerves and blood
   vessels in microvascular decompression: Can we prevent unnecessary
   explorations?
SO CLINICAL NEUROLOGY AND NEUROSURGERY
LA English
DT Article
DE Trigeminal neuralgia; Hemifacial spasm; Cranial nerve segmentation;
   Endoscopic and microscopic view
ID ENDOSCOPIC VASCULAR DECOMPRESSION; DIGITAL-SUBTRACTION-ANGIOGRAPHY;
   PARTIAL SENSORY RHIZOTOMY; TRIGEMINAL NEURALGIA; NEUROVASCULAR
   COMPRESSION; CEREBRAL-ANGIOGRAPHY; COMPLICATIONS; VISUALIZATION;
   SIMULATION; EXPERIENCE
AB Objectives: This study was conducted to validate the accuracy of image-based pre-operative segmentation using the gold standard endoscopic and microscopic findings for localization and pre-operative diagnosis of the offensive vessel.
   Patients and methods: Fourteen TN and 6 HS cases were randomly selected. All patients had 3T MRI, which included thin-sectioned 3D space T2, 3D Time of Flight and MPRAGE Sequences. Imaging sequences were loaded in BrainLab iPlanNet and fused. Individual segmentation of the affected cranial nerves and the compressing vascular structure was performed by a neurosurgeon, and the results were compared with the microscopic and endoscopic findings by two blinded neurosurgeons. For each case, at least three neurovascular landmarks were targeted. Each segmented neurovascular element was validated by manual placement of the navigation probe over each target, and errors of localization were measured in mm.
   Results: All patients underwent retro-sigmoid craniotomy and MVD using both microscope and endoscope. Based on image segmentation, the compressing vessel was identified in all cases except one, which was also negative intraoperatively. Perfect correspondence was found between image-based segmentation and endoscopic and microscopic images and videos (Dice coefficient of 1). Measurement accuracy was 0.45 +/- 0.21 mm (mean SD).
   Conclusion: Image-based segmentation is a promising method for pre-operative identification and localization of offending blood vessels causing HFS and TN. Using this method may prevent some unnecessary explorations on especially atypical cases with no vascular contacts. However, negative pre-operative image segmentation may not preclude one from exploration in classic cases of TN or HFS. A multicenter study with larger number of cases is recommended. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Dolati, Parviz; Golby, Alexandra; Eichberg, Daniel; Abolfotoh, Mohamad; Dunn, Ian F.; Hulou, Mohamed M.; Al-Mefty, Ossama] Harvard Univ, Brigham & Womens Hosp, Sch Med, Dept Neurosurg, Boston, MA 02215 USA.
   [Mukundan, Srinivasan] Harvard Univ, Brigham & Womens Hosp, Sch Med, Dept Neuroradiol, Boston, MA 02215 USA.
C3 Harvard University; Brigham & Women's Hospital; Harvard Medical School;
   Harvard University; Brigham & Women's Hospital; Harvard Medical School
RP Dolati, P (通讯作者)，Harvard Univ, Brigham & Womens Hosp, Sch Med, Dept Neurosurg, 75 Francis St, Boston, MA 02215 USA.
EM neuro81ward@yahoo.com
CR Abolfotoh M, 2013, NEUROSURGERY, V73, P16, DOI 10.1227/NEU.0b013e31827fc87b
   ADAMS CBT, 1982, J NEUROL NEUROSUR PS, V45, P1020, DOI 10.1136/jnnp.45.11.1020
   Anderson VC, 2006, NEUROSURGERY, V58, P666, DOI 10.1227/01.NEU.0000197117.34888.DE
   Anxionnat R, 2001, RADIOLOGY, V218, P799, DOI 10.1148/radiology.218.3.r01mr09799
   Apfelbaum R I, 1983, Clin Neurosurg, V31, P351
   Artz GJ, 2008, OTOL NEUROTOL, V29, P995, DOI 10.1097/MAO.0b013e318184601a
   Badr-El-Dine M, 2002, OTOL NEUROTOL, V23, P122, DOI 10.1097/00129492-200203000-00002
   Broggi M, 2013, ACTA NEUROCHIR, V155, P1709, DOI 10.1007/s00701-013-1824-8
   Cheng WY, 2008, SURG NEUROL, V70, P40, DOI 10.1016/j.surneu.2008.02.024
   DION JE, 1987, STROKE, V18, P997, DOI 10.1161/01.STR.18.6.997
   EARNEST F, 1984, AM J ROENTGENOL, V142, P247, DOI 10.2214/ajr.142.2.247
   El Refaee E, 2013, NEUROSURGERY, V73, P58, DOI 10.1227/01.neu.0000429838.38342.e2
   GABRIELSEN TO, 1994, AM J NEURORADIOL, V15, P1408
   GOLFINOS JG, 1995, J NEUROSURG, V83, P197, DOI 10.3171/jns.1995.83.2.0197
   Gumprecht HK, 1999, NEUROSURGERY, V44, P97, DOI 10.1097/00006123-199901000-00056
   Halpern CH, 2013, MINIM INVASIVE SURG, V2013, DOI 10.1155/2013/739432
   HEISERMAN JE, 1994, AM J NEURORADIOL, V15, P1401
   Kabil MS, 2005, MINIM INVAS NEUROSUR, V48, P207, DOI 10.1055/s-2005-870928
   Kaufmann TJ, 2007, RADIOLOGY, V243, P812, DOI 10.1148/radiol.2433060536
   KLUN B, 1992, NEUROSURGERY, V30, P49, DOI 10.1227/00006123-199201000-00009
   Kurtsoy A, 2004, NEUROSURG REV, V27, P267, DOI 10.1007/s10143-004-0322-0
   Leal PRL, 2010, ACTA NEUROCHIR, V152, P817, DOI 10.1007/s00701-009-0588-7
   Lang SS, 2012, ORL J OTO-RHINO-LARY, V74, P293, DOI 10.1159/000342795
   Lee A, 2014, J NEUROSURG, V120, P1048, DOI 10.3171/2014.1.JNS131410
   Linda W, 2015, J NEUROSURG, V123, P1, DOI 10.3171/2014.10.JNS141055
   Little A.S., 2014, WORLD NEUROSURG
   Maciunas R J, 1996, Clin Neurosurg, V43, P353
   MAGNAN J, 1994, AM J OTOL, V15, P366
   McLaughlin MR, 1999, J NEUROSURG, V90, P1, DOI 10.3171/jns.1999.90.1.0001
   Miller J, 2008, J NEUROSURG, V108, P477, DOI 10.3171/JNS/2008/108/3/0477
   Miyazaki H, 2005, LARYNGOSCOPE, V115, P1612, DOI 10.1097/01.mlg.0000172038.22929.63
   ODONOGHUE GM, 1993, AM J OTOL, V14, P122
   Oishi M, 2012, J NEUROSURG, V117, P555, DOI 10.3171/2012.5.JNS112334
   Rak R, 2004, NEUROSURGERY, V54, P876, DOI 10.1227/01.NEU.0000115151.52925.37
   Satoh T, 2007, J NEUROSURG, V106, P82, DOI 10.3171/jns.2007.106.1.82
   Satoh T, 2007, NEUROSURGERY, V60, P104, DOI 10.1227/01.NEU.0000249213.34838.C9
   Setty P, 2014, WORLD NEUROSURG, V81, P603, DOI 10.1016/j.wneu.2013.10.036
   Shimanskii V N, 2011, Zh Vopr Neirokhir Im N N Burdenko, V75, P70
   Shimanskii V.N., 2011, ZH VOPR NEIROKHIR IM, V75, P74
   Sipos EP, 1996, NEUROSURGERY, V39, P194, DOI 10.1097/00006123-199607000-00048
   Stidd DA, 2014, J NEUROSURG, V121, P745, DOI 10.3171/2014.6.JNS132386
   Stieglitz LH, 2013, NEUROSURGERY, V72, P796, DOI 10.1227/NEU.0b013e318287072d
   Takao T., 2008, NEUROSURGERY S1
   Takao T., 2008, NEUROSURGERY S1, V63
   Takemura Y., 2014, WORLD NEUROSURG
   Teo C., 2006, NEUROSURGERY, V59, P489
   Teo C, 2014, WORLD NEUROSURG, V81, P499, DOI 10.1016/j.wneu.2013.11.002
   Ugwuanyi UCPC, 2010, BRIT J NEUROSURG, V24, P26, DOI 10.3109/02688690903507489
   WATANABE E, 1987, SURG NEUROL, V27, P543, DOI 10.1016/0090-3019(87)90152-2
   WAUGH JR, 1992, RADIOLOGY, V182, P243, DOI 10.1148/radiology.182.1.1727290
   ZORMAN G, 1984, NEUROLOGY, V34, P1362, DOI 10.1212/WNL.34.10.1362
NR 51
TC 20
Z9 22
U1 1
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0303-8467
EI 1872-6968
J9 CLIN NEUROL NEUROSUR
JI Clin. Neurol. Neurosurg.
PD DEC
PY 2015
VL 139
BP 159
EP 165
DI 10.1016/j.clineuro.2015.10.006
PG 7
WC Clinical Neurology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Surgery
GA CY2FG
UT WOS:000366223600029
PM 26476700
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Hussein, AMA
   Mahfouz, H
   Abd Elazeem, K
   Fakhry, M
   Abd Elrazek, E
   Foad, M
   Alboraie, M
   Ragab, A
   Baghdady, S
   Bilasy, SE
   Salama, K
   Masseih, RA
   Amer, MO
   Hassaneen, S
   Bhagavathula, AS
   Elnour, AA
   Al Nuaimi, SK
   Shehab, A
AF Hussein, Abd Elrazek M. Ali
   Mahfouz, Hamdy
   Abd Elazeem, Khaled
   Fakhry, Mohamed
   Abd Elrazek, Emad
   Foad, Mahmoud
   Alboraie, Mohamed
   Ragab, Aly
   Baghdady, Shazly
   Bilasy, Shymaa E.
   Salama, Khaled
   Masseih, Ramy Abdel
   Amer, Mohamed Omar
   Hassaneen, Sayed
   Bhagavathula, Akshaya Srikanth
   Elnour, Asim Ahmed
   Al Nuaimi, Saif K.
   Shehab, Abdulla
TI The Value of U/S to Determine Priority for Upper Gastrointestinal
   Endoscopy in Emergency Room
SO MEDICINE
LA English
DT Article
ID HEPATITIS-C VIRUS; GASTROESOPHAGEAL-REFLUX; ABDOMINAL ULTRASOUND;
   DIAGNOSTIC-ACCURACY; ESOPHAGEAL-VARICES; INFECTION; PROGRESSION;
   PREVALENCE; MANAGEMENT; FIBROSIS
AB In countries endemic for liver and GIT diseases, frequent emergency department (ED) patients contribute to a disproportionate number of visits consuming substantial amount of medical resources. One of the most frequent ED visits is patients who present with hypovolemic shock, abdominal pain, or confusion with or without signs of upper gastrointestinal bleeding (UGIB). The use of conventional two-dimensional ultrasound (2D-U/S) may provide immediate and useful information on the presence of esophageal varices, gastrointestinal tumors, and other GIT abnormalities.The current study investigated the feasibility of using (2D-U/S) to predict the source of UGIB in ED and to determine patients' priority for UGE.Between February 2003 and March 2013, we retrospectively reviewed the profiles of 38,551 Egyptian patients, aged 2 to 75 years old, who presented with a history of GI/liver diseases and no alcohol consumption. We assessed the value of 2D-U/S technology in predicting the source of UGIB.Of 38,551 patients presenting to ED, 900 patients (2.3%), 534 male (59.3%) and 366 female (40.7%) developed UGIB. Analyzing results obtained from U/S examinations by data mining for emergent UGE were patients with liver cirrhosis (LC), splenomegaly, and ascites (42.6% incidence of UGIB), followed by LC and splenomegaly (14.6%), LC only (9.4%), and was only 0.5% who had no morbidity finding by 2D-U/S.Ultrasonographic instrumentation increases the feasibility of predictive emergency medicine. The area has recently not only gained a fresh impulse, but also a new set of complex problems that needs to be addressed in the emergency medicine setting according to each priority.
C1 [Hussein, Abd Elrazek M. Ali] Dept Hepatol & GIT, Div Liver Transplantat & Data Min Res, Cairo, Egypt.
   [Hussein, Abd Elrazek M. Ali] Al Azhar & Aswan Univ, Cairo, Egypt.
   [Hussein, Abd Elrazek M. Ali] Al Azhar & Aswan Univ, Asuit, Egypt.
   [Hussein, Abd Elrazek M. Ali] Al Azhar & Aswan Univ, Aswan, Egypt.
   [Abd Elazeem, Khaled] Al Azhar Univ Asuit, Dept Trop GI & Hepatol, Al Azhar Sch Med, Asuit Branch, Cairo, Egypt.
   Al Azhar Univ Asuit, Dept Gynecol & Obstet, Al Azhar Sch Med, Asuit Branch, Cairo, Egypt.
   [Alboraie, Mohamed] Al Azhar Univ, Dept Internal Med, Al Azhar Sch Med, Cairo, Egypt.
   [Ragab, Aly] Al Azhar Sch Med, Dept Gen & Laparoscop Surg, Cairo, Egypt.
   [Baghdady, Shazly] Aswan Univ, Aswan Sch Med, Chest & Resp Intens Care Unit, Aswan, Egypt.
   [Bilasy, Shymaa E.] Suez Canal Univ, Dept Biochem, Fac Pharm, Ismailia, Egypt.
   [Masseih, Ramy Abdel] Univ Calif Los Angeles, Dept Hepatol, Los Angeles, CA 90024 USA.
   [Amer, Mohamed Omar] Menoufia Univ, Dept Hepatol, Natl Liver Inst, Menoufia, Egypt.
   [Hassaneen, Sayed] Asuit Fac Med, Dept Radiol, Asuit, Egypt.
   [Bhagavathula, Akshaya Srikanth] Univ Gondar, Coll Med & Hlth Sci, Dept Clin Pharm, Gondar, Ethiopia.
   [Elnour, Asim Ahmed; Al Nuaimi, Saif K.; Shehab, Abdulla] Univ Arab Emirates, Dept Clin Pharmacol, Coll Med & Hlth Sci, Abu Dhabi, U Arab Emirates.
   [Elnour, Asim Ahmed; Al Nuaimi, Saif K.; Shehab, Abdulla] Univ Arab Emirates, Dept Med, Coll Med & Hlth Sci, Abu Dhabi, U Arab Emirates.
   [Elnour, Asim Ahmed; Al Nuaimi, Saif K.; Shehab, Abdulla] Univ Arab Emirates, Dept Cardiovasc Dis, Coll Med & Hlth Sci, Abu Dhabi, U Arab Emirates.
   [Elnour, Asim Ahmed; Al Nuaimi, Saif K.; Shehab, Abdulla] UAE Emirates, Abu Dhabi, U Arab Emirates.
C3 Egyptian Knowledge Bank (EKB); Al Azhar University; Aswan University;
   Egyptian Knowledge Bank (EKB); Al Azhar University; Aswan University;
   Egyptian Knowledge Bank (EKB); Al Azhar University; Aswan University;
   Egyptian Knowledge Bank (EKB); Al Azhar University; Egyptian Knowledge
   Bank (EKB); Al Azhar University; Egyptian Knowledge Bank (EKB); Al Azhar
   University; Egyptian Knowledge Bank (EKB); Al Azhar University; Egyptian
   Knowledge Bank (EKB); Aswan University; Egyptian Knowledge Bank (EKB);
   Suez Canal University; University of California System; University of
   California Los Angeles; Egyptian Knowledge Bank (EKB); Menofia
   University; Egyptian Knowledge Bank (EKB); Assiut University; University
   of Gondar
RP Shehab, A (通讯作者)，UAE Univ, Cardiovasc Med Clin Pharmacol & Med Educ, POB 17666, Abu Dhabi, U Arab Emirates.
EM a.shehab@uaeu.ac.ae
RI Elnour, Asim/AAE-4405-2019; Bhagavathula, Akshaya Srikanth/G-6649-2015;
   Elnour, Asim/ABI-6308-2020; Bhagavathula, Akshaya/GQH-1302-2022; salama,
   khaled Nabil/K-3689-2019; Alboraie, Mohamed/F-5688-2011; Abd Elrazek,
   Abd Elrazek/A-6240-2014
OI Elnour, Asim/0000-0002-4143-7810; Bhagavathula, Akshaya
   Srikanth/0000-0002-0581-7808; salama, khaled Nabil/0000-0001-7742-1282;
   Alboraie, Mohamed/0000-0002-8490-9822; Abd Elrazek, Abd
   Elrazek/0000-0001-5381-994X
CR Abd Elrazek AEMA, 2015, EUR J GASTROEN HEPAT, V27, P106, DOI 10.1097/MEG.0000000000000210
   Abd Elrazek AEMA, 2015, EUR J GASTROEN HEPAT, V27, P8, DOI 10.1097/MEG.0000000000000196
   Abd Elrazek AEM, 2014, EUR J GASTROEN HEPAT, V26, P187, DOI 10.1097/MEG.0b013e328365c3b0
   Abd Elrazek AEMA, 2014, MEDICINE, V93, DOI 10.1097/MD.0000000000000204
   Abd Elrazek AMA, 2013, WORLD J GASTRO ENDOS, V5, P417, DOI 10.4253/wjge.v5.i8.417
   Abd Elrazek E.M.A., 2013, GLOBAL J COMPUT SCI, V13, P1
   Abdel-Rahman M, 2013, WORLD J GASTROENTERO, V19, P2691, DOI 10.3748/wjg.v19.i17.2691
   Ali AEM, 2014, AM J MED SCI, V347, P28, DOI 10.1097/MAJ.0b013e3182750ce8
   Balderas V, 2011, AM J MED, V124, P970, DOI 10.1016/j.amjmed.2011.04.032
   Barkun AN, 2010, ANN INTERN MED, V152, P101, DOI 10.7326/0003-4819-152-2-201001190-00009
   Bellazzi R, 2008, INT J MED INFORM, V77, P81, DOI 10.1016/j.ijmedinf.2006.11.006
   Cappell MS, 2008, MED CLIN N AM, V92, P491, DOI 10.1016/j.mcna.2008.01.005
   Crooks C, 2011, GASTROENTEROLOGY, V141, P62, DOI 10.1053/j.gastro.2011.03.048
   Fass R, 2005, ALIMENT PHARM THER, V22, P79, DOI 10.1111/j.1365-2036.2005.02531.x
   Fornari F, 2010, EUR J GASTROEN HEPAT, V22, P404, DOI 10.1097/MEG.0b013e328332f7b8
   Guerra J, 2012, J VIRAL HEPATITIS, V19, P560, DOI 10.1111/j.1365-2893.2011.01576.x
   Habib M, 2001, HEPATOLOGY, V33, P248, DOI 10.1053/jhep.2001.20797
   Hankis JS, 2014, MEDICINE, V93
   Hayashida K, 2010, MICROBIOL IMMUNOL, V54, P684, DOI 10.1111/j.1348-0421.2010.00268.x
   Hearnshaw SA, 2011, GUT, V60, P1327, DOI 10.1136/gut.2010.228437
   Hopper Andrew D, 2011, Practitioner, V255, P15
   Hussein E, 2014, TRANSFUS APHER SCI, V50, P63, DOI 10.1016/j.transci.2013.11.005
   Lofdahl HE, 2011, EUR J GASTROEN HEPAT, V23, P128, DOI 10.1097/MEG.0b013e3283424e25
   Mohamed MK, 2004, AFRO ARAB LIVER J, V13, P41
   Mohamoud YA, 2013, BMC INFECT DIS, V13, DOI 10.1186/1471-2334-13-288
   Murakami Y, 2013, MICROBES INFECT, V15, P45, DOI 10.1016/j.micinf.2012.10.003
   North M., 2008, DATA MINING MASSES
   Poynard T, 2001, J HEPATOL, V34, P730, DOI 10.1016/S0168-8278(00)00097-0
   Rockey Don C, MAJOR CAUSES UPPER G
   Shimizu I, 2003, LIVER INT, V23, P63, DOI 10.1034/j.1600-0676.2003.00811.x
   Sort P, 2014, EUR J GASTROEN HEPAT, V26, P1335, DOI 10.1097/MEG.0000000000000174
   Tang SD, 2014, EUR J CLIN MICROBIOL, V33, P999, DOI 10.1007/s10096-013-2038-y
NR 32
TC 3
Z9 3
U1 0
U2 1
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0025-7974
EI 1536-5964
J9 MEDICINE
JI Medicine (Baltimore)
PD DEC
PY 2015
VL 94
IS 49
AR e2241
DI 10.1097/MD.0000000000002241
PG 7
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA DC9KX
UT WOS:000369541600048
PM 26656368
OA Green Published, gold
DA 2023-04-20
ER

PT J
AU Altomare, DF
   Di Lena, M
   Porcelli, F
   Travaglio, E
   Longobardi, F
   Tutino, M
   Depalma, N
   Tedesco, G
   Sardaro, A
   Memeo, R
   de Gennaro, G
AF Altomare, Donato F.
   Di Lena, Maria
   Porcelli, Francesca
   Travaglio, Elisabetta
   Longobardi, Francesco
   Tutino, Maria
   Depalma, Norma
   Tedesco, Giuseppina
   Sardaro, Annamaria
   Memeo, Riccardo
   de Gennaro, Gianluigi
TI Effects of Curative Colorectal Cancer Surgery on Exhaled Volatile
   Organic Compounds and Potential Implications in Clinical Follow-up
SO ANNALS OF SURGERY
LA English
DT Article
DE breath analysis; colorectal cancer; follow-up; metabolomics; screening;
   volatile organic compounds
ID METABOLOMIC ANALYSIS; STOOL SAMPLES; BREATH; DIAGNOSIS; LUNG;
   COLONOSCOPY; EXPRESSION; BIOMARKERS; MICRORNAS; MARKERS
AB Objective:The aim of this study was to determine whether the volatile organic compounds (VOCs) pattern in colorectal cancer (CRC) patients is modified by curative surgery for a potential application in the oncologic follow-up.Background:CRC has been proved to induce metabolic derangements detectable by high through-output techniques in exhaled breath showing a specific pattern of VOCs.Methods:Forty-eight CRC patients and 55 healthy controls (HC) entered the study. Thirty-two patients (M/F: 1.4; mean age 63 years) attended the oncologic follow-up (mean 24 months) and were found disease-free. Breath samples were collected under similar environmental conditions into a Tedlar bags and processed offline by thermal-desorption gas chromatography-mass spectrometry (TD-GC-MS). VOCs were selected by U test to build a Probabilistic Neural Network (PNN) model to set-up a training phase, which was cross-validated using the leave-one out method.Results:A total of 11 VOCs were finally selected for their excellent discriminant performance in identifying disease-free patients in follow-up from CRC patients before surgery, (sensitivity 100%, specificity 97.92%, accuracy 98.75%, and AUC: 1). The same VOCs pattern discriminated follow-up patients from HC, with a sensitivity of 100%, specificity of 90.91%, accuracy of 94.25%, and AUC 0.959.Conclusions:Exhaled VOCs pattern from CRC patients is modified by cancer removal confirming the tight relationship between tumor metabolism and exhaled VOCs. PNN analysis provides a high discriminatory tool to identify patients disease-free after curative surgery suggesting potential implications in CRC screening and secondary prevention.
C1 [Altomare, Donato F.; Di Lena, Maria; Travaglio, Elisabetta; Depalma, Norma; Memeo, Riccardo] Azienda Osped Univ, Dept Emergency & Organ Transplantat, I-70124 Bari, Italy.
   [Porcelli, Francesca; Longobardi, Francesco; Tutino, Maria; Tedesco, Giuseppina; Sardaro, Annamaria; de Gennaro, Gianluigi] Univ Aldo Moro Bari, Dept Chem, Bari, Italy.
C3 Universita degli Studi di Bari Aldo Moro; Universita degli Studi di Bari
   Aldo Moro
RP Altomare, DF (通讯作者)，Azienda Osped Univ, Dept Emergency & Organ Transplantat, Policlin Bari, Piazza G Cesare 11, I-70124 Bari, Italy.
EM donatofrancesco.altomare@uniba.it
OI Travaglio, Elisabetta/0000-0001-6952-1259; Altomare, Donato
   Francesco/0000-0001-8980-2752
CR Altomare DF, 2013, BRIT J SURG, V100, P144, DOI 10.1002/bjs.8942
   Arasaradnam RP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108750
   Battaglia P, 2014, TUMORI J, V100, P122, DOI 10.1700/1491.16391
   Bonfrate L, 2013, J GASTROINTEST LIVER, V22, P311
   Broza YY, 2013, NANOMED-NANOTECHNOL, V9, P15, DOI 10.1016/j.nano.2012.07.009
   Carrera A, 2012, COLORECTAL DIS, V14, P943, DOI 10.1111/j.1463-1318.2011.02849.x
   Castro G, 2013, CANCER-AM CANCER SOC, V119, P2849, DOI 10.1002/cncr.28159
   Chen JL, 2010, WORLD J GASTROENTERO, V16, P5874, DOI 10.3748/wjg.v16.i46.5874
   de Boer NKH, 2014, CLIN GASTROENTEROL H, V12, P1085, DOI 10.1016/j.cgh.2014.05.005
   de Gennaro G, 2010, ANAL BIOANAL CHEM, V398, P3043, DOI 10.1007/s00216-010-4238-y
   Di Lena M, 2013, WORLD J GASTROENTERO, V19, P1855, DOI 10.3748/wjg.v19.i12.1855
   Du ML, 2014, CARCINOGENESIS, V35, P2723, DOI 10.1093/carcin/bgu189
   Dweik RA, 2008, J BREATH RES, V2, DOI 10.1088/1752-7163/2/3/030301
   Frixione E, 2013, J HIST MED ALL SCI, V68, P505, DOI 10.1093/jhmas/jrs033
   Ghanbari R, 2015, CANCER BIOMARK, V15, P189, DOI 10.3233/CBM-140453
   Guo Q, 2013, MED ONCOL, V30, DOI 10.1007/s12032-013-0695-4
   HAMILTON SR, 1992, J CELL BIOCHEM, P41
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.20115, 10.3322/caac.20107, 10.3322/caac.21590]
   Kearns M, 1999, NEURAL COMPUT, V11, P1427, DOI 10.1162/089976699300016304
   Kwak J, 2014, METABOLITES, V4, P879, DOI 10.3390/metabo4040879
   Kwak J, 2013, J CHROMATOGR B, V931, P90, DOI 10.1016/j.jchromb.2013.05.007
   Liu R, 2013, INT J MOL SCI, V14, P8899, DOI 10.3390/ijms14058899
   Mangler M, 2012, GINEKOL POL, V83, P730
   Markar SR, 2015, J CLIN GASTROENTEROL, V49, P1, DOI 10.1097/MCG.0000000000000247
   Patel N, 2014, ALIMENT PHARM THER, V40, P498, DOI 10.1111/apt.12861
   Peng G, 2010, BRIT J CANCER, V103, P542, DOI 10.1038/sj.bjc.6605810
   Poli D, 2005, RESP RES, V6, DOI 10.1186/1465-9921-6-71
   Poli Diana, 2008, Acta Biomed, V79 Suppl 1, P64
   Qin T, 2010, CANCER EPIDEM BIOMAR, V19, P2247, DOI 10.1158/1055-9965.EPI-10-0302
   Roberts MJ, 2011, KOREAN J UROL, V52, P79, DOI 10.4111/kju.2011.52.2.79
   Samara MA, 2013, J AM COLL CARDIOL, V61, P1463, DOI 10.1016/j.jacc.2012.12.033
   Smolinska A, 2014, J BREATH RES, V8, DOI 10.1088/1752-7155/8/2/027105
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Wang CS, 2014, ANAL BIOANAL CHEM, V406, P4757, DOI 10.1007/s00216-014-7865-x
   Wang CS, 2014, CANCER BIOL THER, V15, P200, DOI 10.4161/cbt.26723
   Wu XD, 2014, MED ONCOL, V31, DOI 10.1007/s12032-014-0894-7
   Yang H, 2013, CAN J GASTROENTEROL, V27, P467, DOI 10.1155/2013/258030
   Yang XY, 2015, TUMOR BIOL, V36, P2675, DOI 10.1007/s13277-014-2890-0
   Zhang H, 2014, WORLD J GASTROENTERO, V20, P6329, DOI 10.3748/wjg.v20.i20.6329
NR 39
TC 31
Z9 31
U1 3
U2 19
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0003-4932
EI 1528-1140
J9 ANN SURG
JI Ann. Surg.
PD NOV
PY 2015
VL 262
IS 5
BP 862
EP 867
DI 10.1097/SLA.0000000000001471
PG 6
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA DA7VD
UT WOS:000368011900023
PM 26583677
DA 2023-04-20
ER

PT J
AU Bae, SH
   Yoon, KJ
AF Bae, Seung-Hwan
   Yoon, Kuk-Jin
TI Polyp Detection via Imbalanced Learning and Discriminative Feature
   Learning
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Endoscopy; colonoscopy; computer aided detection (CAD); polyp detection;
   imbalanced learning; feature learning; partial least square analysis;
   medical imaging system
ID PARTIAL LEAST-SQUARES; CLASSIFICATION; HISTOGRAMS
AB Recent achievement of the learning-based classification leads to the noticeable performance improvement in automatic polyp detection. Here, building large good datasets is very crucial for learning a reliable detector. However, it is practically challenging due to the diversity of polyp types, expensive inspection, and labor-intensive labeling tasks. For this reason, the polyp datasets usually tend to be imbalanced, i.e., the number of non-polyp samples is much larger than that of polyp samples, and learning with those imbalanced datasets results in a detector biased toward a non-polyp class. In this paper, we propose a data sampling-based boosting framework to learn an unbiased polyp detector from the imbalanced datasets. In our learning scheme, we learn multiple weak classifiers with the datasets rebalanced by up/down sampling, and generate a polyp detector by combining them. In addition, for enhancing discriminability between polyps and non-polyps that have similar appearances, we propose an effective feature learning method using partial least square analysis, and use it for learning compact and discriminative features. Experimental results using challenging datasets show obvious performance improvement over other detectors. We further prove effectiveness and usefulness of the proposed methods with extensive evaluation.
C1 [Bae, Seung-Hwan; Yoon, Kuk-Jin] Gwangju Inst Sci & Technol, Sch Informat & Commun, Gwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Yoon, KJ (通讯作者)，Gwangju Inst Sci & Technol, Sch Informat & Commun, Gwangju 500712, South Korea.
EM bshwan@gist.ac.kr; kjyoon@gist.ac.kr
RI Yoon, Kuk-Jin/F-4329-2018
FU Ministry of Science, ICT & Future Planning, Republic of Korea
   [GIST-12-03] Funding Source: Korea Institute of Science & Technology
   Information (KISTI), National Science & Technology Information Service
   (NTIS)
CR Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chung DJ, 2010, STAT APPL GENET MOL, V9, DOI 10.2202/1544-6115.1492
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dalai N., 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Dollar P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Fan W, 1999, MACHINE LEARNING, PROCEEDINGS, P97
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   GUO H, 2004, SIGKDD EXPLORATIONS, V6
   Hoens T.R., 2013, IMBALANCED DATASETS
   Hu S., INT WORKSH COMP SCI
   Jiang XD, 2009, IEEE T PATTERN ANAL, V31, P931, DOI 10.1109/TPAMI.2008.258
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kubat M., 1997, P 14 INT C MACH LEAR, V97, P179
   Marin J, 2010, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2010.5540218
   Masnadi-Shirazi H, 2011, IEEE T PATTERN ANAL, V33, P294, DOI 10.1109/TPAMI.2010.71
   Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217
   Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Qu HN, 2010, PATTERN RECOGN, V43, P3448, DOI 10.1016/j.patcog.2010.05.002
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Rosipal R, 2002, J MACH LEARN RES, V2, P97, DOI 10.1162/15324430260185556
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009
   Ting K.M., 2000, P 17 INT C MACHINE L
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Vedaldi A., VLFEAT OPEN PORTABLE
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P4454, DOI 10.1109/TIP.2012.2205700
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   You MY, 2011, INT J DATA MIN BIOIN, V5, P383, DOI 10.1504/IJDMB.2011.041555
NR 40
TC 60
Z9 62
U1 0
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD NOV
PY 2015
VL 34
IS 11
BP 2379
EP 2393
DI 10.1109/TMI.2015.2434398
PG 15
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA CV7NP
UT WOS:000364461000015
PM 26011864
DA 2023-04-20
ER

PT J
AU Hubenthal, M
   Hemmrich-Stanisak, G
   Degenhardt, F
   Szymczak, S
   Du, ZP
   Elsharawy, A
   Keller, A
   Schreiber, S
   Franke, A
AF Huebenthal, Matthias
   Hemmrich-Stanisak, Georg
   Degenhardt, Frauke
   Szymczak, Silke
   Du, Zhipei
   Elsharawy, Abdou
   Keller, Andreas
   Schreiber, Stefan
   Franke, Andre
TI Sparse Modeling Reveals miRNA Signatures for Diagnostics of Inflammatory
   Bowel Disease
SO PLOS ONE
LA English
DT Article
ID ULCERATIVE-COLITIS; EXPRESSION PROFILES; CROHNS-DISEASE; INCREASED
   SUSCEPTIBILITY; NEOPLASTIC PROGRESSION; CIRCULATING MICRORNA;
   MULTIPLE-SCLEROSIS; PERIPHERAL-BLOOD; MURINE MODEL; GENE
AB The diagnosis of inflammatory bowel disease (IBD) still remains a clinical challenge and the most accurate diagnostic procedure is a combination of clinical tests including invasive endoscopy. In this study we evaluated whether systematic miRNA expression profiling, in conjunction with machine learning techniques, is suitable as a non-invasive test for the major IBD phenotypes (Crohn's disease (CD) and ulcerative colitis (UC)). Based on microarray technology, expression levels of 863 miRNAs were determined for whole blood samples from 40 CD and 36 UC patients and compared to data from 38 healthy controls (HC). To further discriminate between disease-specific and general inflammation we included miRNA expression data from other inflammatory diseases (inflammation controls (IC): 24 chronic obstructive pulmonary disease (COPD), 23 multiple sclerosis, 38 pancreatitis and 45 sarcoidosis cases) as well as 70 healthy controls from previous studies. Classification problems considering 2, 3 or 4 groups were solved using different types of penalized support vector machines (SVMs). The resulting models were assessed regarding sparsity and performance and a subset was selected for further investigation. Measured by the area under the ROC curve (AUC) the corresponding median holdout-validated accuracy was estimated as ranging from 0.75 to 1.00 (including IC) and 0.89 to 0.98 (excluding IC), respectively. In combination, the corresponding models provide tools for the distinction of CD and UC as well as CD, UC and HC with expected classification error rates of 3.1 and 3.3%, respectively. These results were obtained by incorporating not more than 16 distinct miRNAs. Validated target genes of these miRNAs have been previously described as being related to IBD. For others we observed significant enrichment for IBD susceptibility loci identified in earlier GWAS. These results suggest that the proposed miRNA signature is of relevance for the etiology of IBD. Its diagnostic value, however, should be further evaluated in large, independent, clinically well characterized cohorts.
C1 [Huebenthal, Matthias; Hemmrich-Stanisak, Georg; Degenhardt, Frauke; Szymczak, Silke; Du, Zhipei; Elsharawy, Abdou; Schreiber, Stefan; Franke, Andre] Univ Kiel, Inst Clin Mol Biol, Kiel, Germany.
   [Elsharawy, Abdou] Damietta Univ, Div Biochem, Dept Chem, Fac Sci, New Damietta, Egypt.
   [Keller, Andreas] Univ Saarland, Chair Clin Bioinformat, D-66123 Saarbrucken, Germany.
   [Schreiber, Stefan] Univ Hosp Schleswig Holstein, Dept Internal Med 1, Kiel, Germany.
C3 University of Kiel; Egyptian Knowledge Bank (EKB); Damietta University;
   Saarland University; University of Kiel; Schleswig Holstein University
   Hospital
RP Hemmrich-Stanisak, G (通讯作者)，Univ Kiel, Inst Clin Mol Biol, Kiel, Germany.
EM g.hemmrich-stanisak@ikmb.uni-kiel.de
RI Szymczak, Silke/C-6625-2013; Hübenthal, Matthias/M-8149-2015; Keller,
   Andreas/ABB-6412-2021; Franke, Andre/B-2151-2010; Szymczak,
   Silke/HGT-8202-2022
OI Hübenthal, Matthias/0000-0002-5956-3006; Keller,
   Andreas/0000-0002-5361-0895; Franke, Andre/0000-0003-1530-5811;
   Szymczak, Silke/0000-0002-8897-9035; Degenhardt,
   Frauke/0000-0001-7516-3179; Elsharawy, Abdou/0000-0002-5089-9435
FU German Ministry of Education and Research (BMBF) program e:Med
   sysINFLAME [01ZX1306A]
FX This study was supported by the German Ministry of Education and
   Research (BMBF) program e:Med sysINFLAME
   (https://hfbic188b109a51ff4e3dh995u9bvnqn966605fiac.eds.tju.edu.cn/de/5111.php, no.: 01ZX1306A)
   and received infrastructure support from the Deutsche
   Forschungsgemeinschaft (DFG) Cluster of Excellence 'Inflammation at
   Interfaces' (https://hfbic04cbbb50cd724ecah995u9bvnqn966605fiac.eds.tju.edu.cn, no.: XC306/2).
   Andre Franke receives an endowment professorship (Peter Hans
   Hofschneider Professorship) of the "Stiftung Experimentelle Biomedizin"
   located in Zuerich, Switzerland.
CR Abu-Halima M, 2014, FERTIL STERIL, V102, P989, DOI 10.1016/j.fertnstert.2014.07.001
   Andoh A, 2001, INFLAMM BOWEL DIS, V7, P210, DOI 10.1097/00054725-200108000-00005
   Balzola F, 2012, INFLAMM BOWEL DIS, P126
   Barrett JC, 2009, NAT GENET, V41, P1330, DOI 10.1038/ng.483
   Becker N, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-138
   Becker N, 2009, BIOINFORMATICS, V25, P1711, DOI 10.1093/bioinformatics/btp286
   Bhonde MR, 2008, AM J PHYSIOL-GASTR L, V295, pG1237, DOI 10.1152/ajpgi.90537.2008
   Bian Z, 2011, J PATHOL, V225, P544, DOI 10.1002/path.2907
   Blunt MD, 2012, CURR OPIN PHARMACOL, V12, P444, DOI 10.1016/j.coph.2012.02.015
   Bouzid D, 2012, HUM IMMUNOL, V73, P732, DOI 10.1016/j.humimm.2012.04.018
   Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P82
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brest P, 2011, NAT GENET, V43, P242, DOI 10.1038/ng.762
   Chen Wei-Xu, 2014, World J Gastrointest Pathophysiol, V5, P63, DOI 10.4291/wjgp.v5.i2.63
   Chen Y, 2013, CELL DEATH DIS, V4, DOI 10.1038/cddis.2013.22
   Chen Y, 2013, BIOCHEM BIOPH RES CO, V438, P133, DOI 10.1016/j.bbrc.2013.07.040
   Chuang AY, 2014, INFLAMM BOWEL DIS, V20, P126, DOI 10.1097/01.MIB.0000436954.70596.9b
   Clark PM, 2012, INFLAMM BOWEL DIS, V18, P2315, DOI 10.1002/ibd.22958
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dahan S, 2011, GASTROENTEROLOGY, V140, P550, DOI 10.1053/j.gastro.2010.10.057
   Deng H, 2012, GENE SELECTION GUIDE
   Diegelmann J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077773
   Dotan I, 2006, GASTROENTEROLOGY, V131, P366, DOI 10.1053/j.gastro.2006.04.030
   Duttagupta R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031241
   Fasseu M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013160
   Feng X, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0052782
   Franke A, 2010, NAT GENET, V42, P1118, DOI 10.1038/ng.717
   Frey MR, 2014, PEDIATR RES, V75, P127, DOI 10.1038/pr.2013.210
   FRIEDMAN J, 1996, ANOTHER APPROACH POL
   Gerlach K, 2014, NAT IMMUNOL, V15, P676, DOI 10.1038/ni.2920
   Ghorpade DS, 2013, J BIOL CHEM, V288, P33037, DOI 10.1074/jbc.M113.492496
   Gologan S, 2013, J CROHNS COLITIS, V7, P622, DOI 10.1016/j.crohns.2012.08.015
   Granlund AV, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056818
   Guimil R, 2003, NUCLEOS NUCLEOT NUCL, V22, P1721, DOI 10.1081/NCN-120023122
   Nguyen HTT, 2014, GASTROENTEROLOGY, V146, P508, DOI 10.1053/j.gastro.2013.10.021
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Hsu SD, 2014, NUCLEIC ACIDS RES, V42, pD78, DOI 10.1093/nar/gkt1266
   HUBER W, 2003, STAT APPL GENET MOL, V2, DOI DOI 10.2202/1544-6115.1008
   Iborra M, 2013, CLIN EXP IMMUNOL, V173, P250, DOI 10.1111/cei.12104
   Iskandar HN, 2012, TRANSL RES, V159, P313, DOI 10.1016/j.trsl.2012.01.001
   Jakobsdottir J, 2009, PLOS GENET, V5, DOI 10.1371/journal.pgen.1000337
   Jostins L, 2012, NATURE, V491, P119, DOI 10.1038/nature11582
   Jostins L, 2011, HUM MOL GENET, V20, pR182, DOI 10.1093/hmg/ddr378
   Kanaan Z, 2012, HUM MUTAT, V33, P551, DOI 10.1002/humu.22021
   Keller A, 2014, MULT SCLER J, V20, P295, DOI 10.1177/1352458513496343
   Keller A, 2011, MOL BIOSYST, V7, P3187, DOI 10.1039/c1mb05353a
   Keller A, 2011, NAT METHODS, V8, P841, DOI [10.1038/NMETH.1682, 10.1038/nmeth.1682]
   Keller A, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007440
   Keutgen XM, 2012, CLIN CANCER RES, V18, P2032, DOI 10.1158/1078-0432.CCR-11-2487
   Khor TO, 2006, CANCER RES, V66, P11580, DOI 10.1158/0008-5472.CAN-06-3562
   Koukos G, 2013, GASTROENTEROLOGY, V145, P842, DOI 10.1053/j.gastro.2013.07.001
   Lajer CB, 2011, BRIT J CANCER, V104, P830, DOI 10.1038/bjc.2011.29
   Lewis JD, 2011, GASTROENTEROLOGY, V140, P1817, DOI 10.1053/j.gastro.2010.11.058
   Li ZX, 2011, J IMMUNOL, V186, P6182, DOI 10.4049/jimmunol.1000917
   Liu JZ, 2014, BEST PRACT RES CL GA, V28, P373, DOI 10.1016/j.bpg.2014.04.009
   Ludwig K, 2013, VIRCHOWS ARCH, V462, P57, DOI 10.1007/s00428-012-1345-5
   Marcil V, 2012, GENES IMMUN, V13, P556, DOI 10.1038/gene.2012.37
   Miotto P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080149
   Montero-Melendez T, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076235
   Moum B, 1997, GUT, V40, P328, DOI 10.1136/gut.40.3.328
   Olaru AV, 2013, INFLAMM BOWEL DIS, V19, P471, DOI 10.1097/MIB.0b013e31827e78eb
   Olaru AV, 2011, INFLAMM BOWEL DIS, V17, P221, DOI 10.1002/ibd.21359
   Paraskevi A, 2012, J CROHNS COLITIS, V6, P900, DOI 10.1016/j.crohns.2012.02.006
   Patnaik SK, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046045
   Schulmann K, 2005, GASTROENTEROLOGY, V129, P74, DOI 10.1053/j.gastro.2005.04.011
   Shi CZ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066814
   Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623
   Sipos F, 2008, SCAND J GASTROENTERO, V43, P289, DOI 10.1080/00365520701714434
   Sobajima J, 1997, CLIN EXP IMMUNOL, V107, P135, DOI 10.1046/j.1365-2249.1997.d01-907.x
   Strobl C, 2009, PSYCHOL METHODS, V14, P323, DOI 10.1037/a0016973
   Szymczak S, R2VIM NEW VARI UNPUB
   van Lierop PPE, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079549
   Vorwerk S, 2008, NEW BIOTECHNOL, V25, P142, DOI 10.1016/j.nbt.2008.08.005
   Wu F, 2008, GASTROENTEROLOGY, V135, P1624, DOI 10.1053/j.gastro.2008.07.068
   Wu F, 2011, INFLAMM BOWEL DIS, V17, P241, DOI 10.1002/ibd.21450
   Wu F, 2010, INFLAMM BOWEL DIS, V16, P1729, DOI 10.1002/ibd.21267
   Yang YZ, 2013, BIOCHEM BIOPH RES CO, V434, P746, DOI 10.1016/j.bbrc.2013.03.122
   Ying L, 2005, CANCER RES, V65, P9132, DOI 10.1158/0008-5472.CAN-05-1358
   Zahm AM, 2014, J CROHNS COLITIS, V8, P1108, DOI 10.1016/j.crohns.2014.02.012
   Zahm AM, 2011, J PEDIATR GASTR NUTR, V53, P26, DOI 10.1097/MPG.0b013e31822200cc
   Zhai Z, 2013, INFLAMM BOWEL DIS, V19, P2295, DOI 10.1097/MIB.0b013e31829e71cf
   Zhang HH, 2006, BIOINFORMATICS, V22, P88, DOI 10.1093/bioinformatics/bti736
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 83
TC 28
Z9 28
U1 0
U2 10
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD OCT 14
PY 2015
VL 10
IS 10
AR e0140155
DI 10.1371/journal.pone.0140155
PG 20
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA CU0CK
UT WOS:000363183100082
PM 26466382
OA gold, Green Submitted, Green Published
DA 2023-04-20
ER

PT J
AU Keuchel, M
   Kurniawan, N
   Baltes, P
   Bandorski, D
   Koulaouzidis, A
AF Keuchel, M.
   Kurniawan, N.
   Baltes, P.
   Bandorski, D.
   Koulaouzidis, A.
TI Quantitative measurements in capsule endoscopy
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Video capsule endoscopy; Automated detection; Scores; Wireless motility
   capsule; pH; Pressure; Image analysis
ID SUSPECTED BLOOD INDICATOR; SMALL-BOWEL; TRANSIT-TIME; MOTILITY CAPSULE;
   COLON CAPSULE; VIDEO CAPSULE; VIDEOCAPSULE ENDOSCOPY;
   GASTROINTESTINAL-TRACT; RADIOPAQUE MARKERS; FECAL CALPROTECTIN
AB This review summarizes several approaches for quantitative measurement in capsule endoscopy. Video capsule endoscopy (VCE) typically provides wireless imaging of small bowel. Currently, a variety of quantitative measurements are implemented in commercially available hardware/software. The majority is proprietary and hence undisclosed algorithms. Measurement of amount of luminal contamination allows calculating scores from whole VCE studies. Other scores express the severity of small bowel lesions in Crohn's disease or the degree of villous atrophy in celiac disease. Image processing with numerous algorithms of textural and color feature extraction is further in the research focuses for automated image analysis. These tools aim to select single images with relevant lesions as blood, ulcers, polyps and tumors or to omit images showing only luminal contamination. Analysis of motility pattern, size measurement and determination of capsule localization are additional topics.
   Non-visual wireless capsules transmitting data acquired with specific sensors from the gastrointestinal (GI) tract are available for clinical routine. This includes pH measurement in the esophagus for the diagnosis of acid gastro-esophageal reflux. A wireless motility capsule provides GI motility analysis on the basis of pH, pressure, and temperature measurement. Electromagnetically tracking of another motility capsule allows visualization of motility. However, measurement of substances by GI capsules is of great interest but still at an early stage of development. (C) 2015 Elsevier Ltd. All rights reserved.
C1 [Keuchel, M.; Kurniawan, N.; Baltes, P.] Bethesda Krankenhaus Bergedolf, Clin Internal Med, Glindersweg 80, D-21029 Hamburg, Germany.
   [Bandorski, D.] Max Planck Inst Physiol & Clin Res, Kerckhoff Klin, Bad Nauheim, Germany.
   [Koulaouzidis, A.] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh, Midlothian, Scotland.
C3 Kerckhoff Clinic; Max Planck Society; Royal Infirmary of Edinburgh;
   University of Edinburgh
RP Keuchel, M (通讯作者)，Bethesda Krankenhaus Bergedolf, Clin Internal Med, Glindersweg 80, D-21029 Hamburg, Germany.
EM keuchel@bkb.info
RI Baltes, Peter/ABI-5554-2020; Koulaouzidis, Anastasios/G-9060-2014;
   Bandorski, Dirk/GSO-2966-2022
OI Koulaouzidis, Anastasios/0000-0002-2248-489X; Bandorski,
   Dirk/0000-0001-5341-5195; Baltes, Peter/0000-0001-6318-6015
FU GivenImaging/Covidien; Intromedic and Olympus; Given Imaging and
   Intromedic; Olympus; GivenImaging; Capsovision; SynMed UK
FX M.K. received speakers' fees from GivenImaging/Covidien, Intromedic and
   Olympus, study support from Given Imaging and Intromedic; N.K. received
   speakers' fees from GivenImaging/Covidien; P. B. received speakers' fees
   from GivenImaging/Covidien and Olympus and study support and travel
   reimbursement from GivenImaging and Capsovision; AK. received Research
   support from Given Imaging and SynMed UK, speakers' fees from Dr Falk UK
   and travel support from Abbott, Dr. Falk, Almirall, Ferring, MSD; D.B.
   has no disclosures.
CR Adler S, 2012, GASTROINTEST ENDOSC, V76, P1170, DOI 10.1016/j.gie.2012.07.034
   Ayazi S, 2011, SURG ENDOSC, V25, P2219, DOI 10.1007/s00464-010-1529-5
   Barbosa DJC, 2008, IEEE ENG MED BIO, P3012, DOI 10.1109/IEMBS.2008.4649837
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Bashar MK, 2008, LECT NOTES COMPUT SC, V5242, P603, DOI 10.1007/978-3-540-85990-1_72
   Boillat CS, 2010, AM J VET RES, V71, P903, DOI 10.2460/ajvr.71.8.903
   Boscan P, 2014, VET ANAESTH ANALG, V41, P73, DOI 10.1111/vaa.12093
   Brotz C, 2009, GASTROINTEST ENDOSC, V69, P262, DOI 10.1016/j.gie.2008.04.016
   Brun M, 2011, GASTROENTEROLOGY, V140, pS865
   Buscaglia JM, 2008, CLIN GASTROENTEROL H, V6, P298, DOI 10.1016/j.cgh.2007.12.029
   Camilleri M, 2010, NEUROGASTROENT MOTIL, V22, P874, DOI 10.1111/j.1365-2982.2010.01517.x
   Charisis V, 2010, IEEE ENG MED BIO, P3674, DOI 10.1109/IEMBS.2010.5627648
   Chen Y, 2012, P 20 ACM INT C MULT, P1181, DOI DOI 10.1145/2393347.2396413
   Chu XQ, 2010, LECT NOTES COMPUT SC, V6362, P522
   Ciaccio EJ, 2012, DIGEST DIS SCI, V57, P2936, DOI 10.1007/s10620-012-2225-1
   Ciaccio EJ, 2012, COMPUT METH PROG BIO, V108, P28, DOI 10.1016/j.cmpb.2011.12.008
   Ciaccio EJ, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-78
   Ciaccio EJ, 2011, DIGEST DIS SCI, V56, P805, DOI 10.1007/s10620-010-1371-6
   Ciaccio EJ, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-44
   Ciaccio EJ, 2010, COMPUT METH PROG BIO, V100, P39, DOI 10.1016/j.cmpb.2010.02.005
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   David E., 2013, INTERNALIZED OPPRESS, P1
   De Iorio F, 2009, NEUROGASTROENT MOTIL, V21, DOI 10.1111/j.1365-2982.2009.01363.x
   DuPont AW, 2014, DIGESTION, V89, P119, DOI 10.1159/000356314
   Fan YC, 2011, IEEE ENG MED BIO, P4864, DOI 10.1109/IEMBS.2011.6091205
   Figueiredo Pedro N, 2011, Diagn Ther Endosc, V2011, P182435, DOI 10.1155/2011/182435
   Fireman Z, 2007, DIGEST DIS SCI, V52, P2884, DOI 10.1007/s10620-007-9789-1
   Fischer Doron, 2004, Gastrointest Endosc Clin N Am, V14, P25, DOI 10.1016/j.giec.2003.10.020
   Gal E, 2008, DIGEST DIS SCI, V53, P1933, DOI 10.1007/s10620-007-0084-y
   Gan T, 2008, WORLD J GASTROENTERO, V14, P6929, DOI 10.3748/wjg.14.6929
   Gelfond D, 2013, DIGEST DIS SCI, V58, P2275, DOI 10.1007/s10620-012-2209-1
   Girelli CM, 2011, GASTROINTEST ENDOSC, V74, P1067, DOI 10.1016/j.gie.2011.07.022
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Graepler F, 2008, GASTROINTEST ENDOSC, V67, P924, DOI 10.1016/j.gie.2007.10.060
   Gralnev IM, 2008, ALIMENT PHARM THERAP, V27, P146, DOI 10.1111/j.1365-2036.2007.03556.x
   Hedsund C, 2013, CLIN EXP GASTROENTER, V6, P201, DOI 10.2147/CEG.S51402
   Hoog CM, 2014, SCAND J GASTROENTERO, V49, P1084, DOI 10.3109/00365521.2014.920915
   Hwang S., 2011, BAG OF VISUAL WORDS, P320
   Iakovidis D, 2014, GLOB J GASTROENTEROL, V2, P11, DOI DOI 10.12970/2308-6483.2014.02.01.3
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iida H, 2012, HEPATO-GASTROENTEROL, V59, P413, DOI 10.5754/hge11394
   JAMIESON JR, 1992, AM J GASTROENTEROL, V87, P1102
   Johannessen EA, 2004, IEEE T BIO-MED ENG, V51, P525, DOI 10.1109/TBME.2003.820370
   Johannessen EA, 2006, IEEE T BIO-MED ENG, V53, P2333, DOI 10.1109/TBME.2006.883698
   Karargyris A, 2015, IEEE T BIO-MED ENG, V62, P352, DOI 10.1109/TBME.2014.2352493
   Karargyris A, 2013, WORLD J GASTROENTERO, V19, P5943, DOI 10.3748/wjg.v19.i35.5943
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Keuchel M, 2007, GASTROINTEST ENDOSC, V65, pAB172, DOI 10.1016/j.gie.2007.03.290
   Kloetzer L, 2010, NEUROGASTROENT MOTIL, V22, P527, DOI 10.1111/j.1365-2982.2010.01468.x
   Kopylov U, 2015, INFLAMM BOWEL DIS, V21, P93, DOI 10.1097/MIB.0000000000000255
   Korman LY, 2005, ENDOSCOPY, V37, P951, DOI 10.1055/s-2005-870329
   Koulaouzidis A., 2015, ANN GASTROENTEROL, V28, P1
   Koulaouzidis A, 2015, WORLD J GASTROENTERO, V21, P5119, DOI 10.3748/wjg.v21.i17.5119
   Koulaouzidis A, 2013, DIGEST LIVER DIS, V45, P909, DOI 10.1016/j.dld.2013.05.013
   Koulaouzidis A, 2013, WORLD J GASTROENTERO, V19, P3726, DOI 10.3748/wjg.v19.i24.3726
   Koulaouzidis A, 2012, DIGEST DIS SCI, V57, P987, DOI 10.1007/s10620-011-1956-8
   Koulaouzidis A, 2012, WORLD J GASTRO ENDOS, V4, P33, DOI 10.4253/wjge.v4.i2.33
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Kuo B, 2011, DIGEST DIS SCI, V56, P2928, DOI 10.1007/s10620-011-1751-6
   Lalezari D, 2012, ANN GASTROENTEROL, V25, P333
   Lee A, 2012, NEUROGASTROENT MOTIL, V24, DOI 10.1111/j.1365-2982.2012.01905.x
   Lee YY, 2014, J NEUROGASTROENTEROL, V20, P265, DOI [10.5056/jnm.20.2.265, 10.5056/jnm.2014.20.2.265]
   Leighton JA, 2011, ENDOSCOPY, V43, P123, DOI 10.1055/s-0030-1255916
   Li BP, 2009, IEEE ENG MED BIO, P3731, DOI 10.1109/IEMBS.2009.5334875
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Lima CS, 2008, IEEE ENG MED BIO, P1242, DOI 10.1109/IEMBS.2008.4649388
   Liu HY, 2014, BIO-MED MATER ENG, V24, P519, DOI 10.3233/BME-130838
   Malagelada C, 2012, NEUROGASTROENT MOTIL, V24, P223, DOI 10.1111/j.1365-2982.2011.01823.x
   Malagelada C, 2008, GASTROENTEROLOGY, V135, P1155, DOI 10.1053/j.gastro.2008.06.084
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Marques N, 2011, IEEE ENG MED BIO, P6631, DOI 10.1109/IEMBS.2011.6091635
   Marya N, 2014, GASTROINTEST ENDOSC, V79, P669, DOI 10.1016/j.gie.2013.11.022
   Michalek W, 2011, DIGEST DIS SCI, V56, P1735, DOI 10.1007/s10620-010-1479-8
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Niv Y, 2012, ENDOSCOPY, V44, P21, DOI 10.1055/s-0031-1291385
   Park SC, 2012, WORLD J GASTROENTERO, V18, P4169, DOI 10.3748/wjg.v18.i31.4169
   Postgate A, 2008, ENDOSCOPY, V40, P496, DOI 10.1055/s-2007-995590
   Racz I, 2007, ENDOSCOPY, V39, pE41, DOI 10.1055/s-2006-945063
   Rao SSC, 2012, ARCH GERONTOL GERIAT, V55, P289, DOI 10.1016/j.archger.2012.04.003
   Rauch S, 2012, J CRIT CARE, V27, DOI 10.1016/j.jcrc.2011.12.002
   Roland BC, 2014, DIGEST DIS SCI, V59, P1269, DOI 10.1007/s10620-014-3166-7
   Roland BC, 2013, J CLIN GASTROENTEROL, V47, P888, DOI 10.1097/MCG.0b013e31829006bb
   Romain O., 2013, IEEE 13 INT C BIOINF, P1
   Rondonotti E, 2014, GASTROINTEST ENDOSC, V80, P642, DOI 10.1016/j.gie.2014.04.057
   Saad Richard J, 2011, Gastroenterol Hepatol (N Y), V7, P795
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Sarosiek I, 2010, ALIMENT PHARM THER, V31, P313, DOI 10.1111/j.1365-2036.2009.04162.x
   Saurin JC, 2012, DIGEST LIVER DIS, V44, P477, DOI 10.1016/j.dld.2011.12.021
   Segui S, 2014, IEEE J BIOMED HEALTH, V18, P1831, DOI 10.1109/JBHI.2014.2304179
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Seshamani S, 2010, LECT NOTES COMPUT SC, V6362, P454
   Seshamani S, 2009, LECT NOTES COMPUT SC, V5761, P582, DOI 10.1007/978-3-642-04268-3_72
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Subramanian V, 2012, DIGEST DIS SCI, V57, P1624, DOI 10.1007/s10620-012-2074-y
   Szczypinski PM, 2009, MED IMAGE ANAL, V13, P312, DOI 10.1016/j.media.2008.12.002
   Tal AO, 2014, SCAND J GASTROENTERO, V49, P1131, DOI 10.3109/00365521.2014.923503
   Terry BS, 2012, J MECH BEHAV BIOMED, V15, P24, DOI 10.1016/j.jmbbm.2012.06.018
   Terry BS, 2012, IEEE T BIO-MED ENG, V59, P1971, DOI 10.1109/TBME.2012.2195179
   Timm D, 2011, BRIT J NUTR, V105, P1337, DOI 10.1017/S0007114510004988
   Tukey M, 2009, AM J GASTROENTEROL, V104, P2734, DOI 10.1038/ajg.2009.404
   Van Weyenberg S.J., 2014, GASTROINTEST ENDOSC, V79, pAB584
   Van Weyenberg SJB, 2011, ENDOSCOPY, V43, P406, DOI 10.1055/s-0030-1256228
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Vu H, 2007, LECT NOTES COMPUT SC, V4791, P775
   Vu H, 2009, COMPUT BIOL MED, V39, P16, DOI 10.1016/j.compbiomed.2008.10.005
   Wang X, 2010, P I MECH ENG H, V224, P107, DOI 10.1243/09544119JEIM540
   Worsoe J, 2011, BMC GASTROENTEROL, V11, DOI 10.1186/1471-230X-11-145
   Yagi Y., 2007, Inflammopharmacology, V15, P78, DOI 10.1007/s10787-006-0010-5
   Yu LC, 2012, INT C PATT RECOG, P45
   Yuan Y., 2015, IEEE T MED IMAGING
   Zarate N, 2010, AM J PHYSIOL-GASTR L, V299, pG1276, DOI 10.1152/ajpgi.00127.2010
   Zhang H, 2008, GASTROINTEST ENDOSC, V68, P520, DOI 10.1016/j.gie.2008.02.023
   Zhao Qian, 2012, Stud Health Technol Inform, V173, P559
NR 118
TC 8
Z9 8
U1 1
U2 17
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD OCT 1
PY 2015
VL 65
BP 333
EP 347
DI 10.1016/j.compbiomed.2015.07.016
PG 15
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA CT5OW
UT WOS:000362860700038
PM 26299419
DA 2023-04-20
ER

PT J
AU Sandberg, TH
   Nilsson, M
   Poulsen, JL
   Gram, M
   Frokjaer, JB
   Ostergaard, LR
   Drewes, AM
AF Sandberg, Thomas Holm
   Nilsson, Matias
   Poulsen, Jakob Lykke
   Gram, Mikkel
   Frokjaer, Jens Brondum
   Ostergaard, Lasse Riis
   Drewes, Asbjorn Mohr
TI A novel semi-automatic segmentation method for volumetric assessment of
   the colon based on magnetic resonance imaging
SO ABDOMINAL IMAGING
LA English
DT Article
DE Colon; Magnetic resonance imaging; Machine learning; Artificial
   intelligence; Computer-assisted image processing; Constipation
ID VIRTUAL COLONOSCOPY; CT COLONOGRAPHY; INTENSITY NONUNIFORMITY; MRI;
   ALGORITHM; EFFICIENT; IMAGES; MODEL
AB To develop a novel semi-automatic segmentation method for quantification of the colon from magnetic resonance imaging (MRI).
   Fourteen abdominal T2-weighted and dual-echo Dixon-type water-only MRI scans were obtained from four healthy subjects. Regions of interest containing the colon were outlined manually on the T2-weighted images. Segmentation of the colon and feces was obtained using k-means clustering and image registration. Regional colonic and fecal volumes were obtained. Inter-observer agreement between two observers was assessed using the Dice similarity coefficient as measure of overlap.
   Colonic segmentations showed wide variation in volume and morphology between subjects. Colon volumes of the four healthy subjects for both observers were (median [interquartile range]) ascending colon 200 mL [169.5-260], transverse 200.5 mL [113.5-242.5], descending 148 mL [121.5-178.5], sigmoid-rectum 277 mL [192-345], and total 819 mL [687-898.5]. Overlap agreement for the total colon segmentation between the two observers was high with a Dice similarity coefficient of 0.91 [0.84-0.94]. The colon volume to feces volume ratio was on average 0.7.
   Regional colon volumes were comparable to previous findings using fully manual segmentation. The method showed good agreement between observers and may be used in future studies of gastrointestinal disorders to assess colon and fecal volume and colon morphology. Novel insight into morphology and quantitative assessment of the colon using this method may provide new biomarkers for constipation and abdominal pain compared to radiography which suffers from poor reliability.
C1 [Sandberg, Thomas Holm; Nilsson, Matias; Poulsen, Jakob Lykke; Gram, Mikkel; Drewes, Asbjorn Mohr] Aalborg Univ Hosp, Mech Sense, Dept Gastroenterol & Hepatol, DK-9000 Aalborg, Denmark.
   [Frokjaer, Jens Brondum] Aalborg Univ Hosp, Mech Sense, Dept Radiol, DK-9000 Aalborg, Denmark.
   [Ostergaard, Lasse Riis] Aalborg Univ, Dept Hlth Sci & Technol, Aalborg, Denmark.
   [Frokjaer, Jens Brondum; Drewes, Asbjorn Mohr] Aalborg Univ, Dept Clin Med, Aalborg, Denmark.
C3 Aalborg University; Aalborg University Hospital; Aalborg University;
   Aalborg University Hospital; Aalborg University; Aalborg University
RP Drewes, AM (通讯作者)，Aalborg Univ Hosp, Mech Sense, Dept Gastroenterol & Hepatol, Molleparkvej 4, DK-9000 Aalborg, Denmark.
EM amd@rn.dk
RI Ostergaard, Lars/AAA-3020-2020; Frøkjær, Jens Brøndum/F-5938-2017;
   Drewes, Asbjørn/AAR-7479-2021
OI Ostergaard, Lars/0000-0003-2459-0511; Frøkjær, Jens
   Brøndum/0000-0001-8722-0070; Drewes, Asbjørn/0000-0001-7465-964X;
   stergaard, Lasse Riis/0000-0002-0524-6347; Poulsen, Jakob
   Lykke/0000-0002-0251-6049; Ostergaard, Lars/0000-0002-7619-605X
FU Innovation Fund Denmark
FX This study was supported by funding from Innovation Fund Denmark.
CR Arnold JB, 2001, NEUROIMAGE, V13, P931, DOI 10.1006/nimg.2001.0756
   BARTKO JJ, 1991, SCHIZOPHRENIA BULL, V17, P483, DOI 10.1093/schbul/17.3.483
   Bert A, 2009, COMPUT MED IMAG GRAP, V33, P325, DOI 10.1016/j.compmedimag.2009.02.004
   Bidgoli JH, 2005, P ANN INT IEEE EMBS, P3429, DOI 10.1109/IEMBS.2005.1617215
   Bielen D, 2007, ABDOM IMAGING, V32, P571, DOI 10.1007/s00261-007-9293-2
   Chen DQ, 2000, IEEE T MED IMAGING, V19, P1220, DOI 10.1109/42.897814
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dinning PG, 2010, NEUROGASTROENT MOTIL, V22, P633, DOI 10.1111/j.1365-2982.2010.01480.x
   Franaszek M, 2006, IEEE T MED IMAGING, V25, P358, DOI 10.1109/TMI.2005.863836
   Haas S, 2014, NEUROGASTROENT MOTIL, V26, P862, DOI 10.1111/nmo.12341
   Jiang GX, 2005, P ANN INT IEEE EMBS, P5149
   Khashab MA, 2009, ENDOSCOPY, V41, P674, DOI 10.1055/s-0029-1214899
   Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616
   Losnegard A, 2010, PHYS MED BIOL, V55, P5569, DOI 10.1088/0031-9155/55/18/020
   Lu L, 2013, COMPUT METH PROG BIO, V109, P1, DOI 10.1016/j.cmpb.2012.08.012
   Ma JF, 2004, MAGN RESON MED, V52, P415, DOI 10.1002/mrm.20146
   Major G, 2014, GUT, V63, pA35, DOI 10.1136/gutjnl-2014-307263.70
   Marciani L, 2014, NEUROGASTROENT MOTIL, V26, P1426, DOI 10.1111/nmo.12403
   Moylan S, 2010, J UROLOGY, V184, P1692, DOI 10.1016/j.juro.2010.05.054
   Murray K, 2014, AM J GASTROENTEROL, V109, P110, DOI 10.1038/ajg.2013.386
   Pritchard SE, 2015, NEUROGASTROENT MOTIL, V27, P542, DOI 10.1111/nmo.12529
   Pritchard SE, 2014, NEUROGASTROENT MOTIL, V26, P124, DOI 10.1111/nmo.12243
   Rao SSC, 2004, AM J GASTROENTEROL, V99, P2405, DOI 10.1111/j.1572-0241.2004.40453.x
   Shamonin D.P., 2013, FRONT NEUROINFORM, V7, P1
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Steele Scott R, 2007, Clin Colon Rectal Surg, V20, P110, DOI 10.1055/s-2007-977489
   Tielbeek JAW, 2012, ABDOM IMAGING, V37, P967, DOI 10.1007/s00261-011-9822-x
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wyatt CL, 2006, COMPUT MED IMAG GRAP, V30, P17, DOI 10.1016/j.compmedimag.2005.07.003
   Wyatt CL, 2000, COMPUT MED IMAG GRAP, V24, P1, DOI 10.1016/S0895-6111(99)00039-7
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 31
TC 28
Z9 28
U1 0
U2 9
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0942-8925
EI 1432-0509
J9 ABDOM IMAGING
JI Abdom. Imaging
PD OCT
PY 2015
VL 40
IS 7
BP 2232
EP 2241
DI 10.1007/s00261-015-0475-z
PG 10
WC Gastroenterology & Hepatology; Radiology, Nuclear Medicine & Medical
   Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Radiology, Nuclear Medicine & Medical
   Imaging
GA CS1OJ
UT WOS:000361835700016
PM 26054979
DA 2023-04-20
ER

PT J
AU Spyrou, E
   Iakovidis, DK
   Niafas, S
   Koulaouzidis, A
AF Spyrou, Evaggelos
   Iakovidis, Dimitris K.
   Niafas, Stavros
   Koulaouzidis, Anastasios
TI Comparative assessment of feature extraction methods for visual odometry
   in wireless capsule endoscopy
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Wireless capsule endoscopy; Localization; Visual odometry; Feature
   extraction; Algorithm; Small bowel; Gastrointestinal tract
ID LOCALIZATION
AB Wireless capsule endoscopy (WCE) enables the non-invasive examination of the gastrointestinal (GI) tract by a swallowable device equipped with a miniature camera. Accurate localization of the capsule in the GI tract enables accurate localization of abnormalities for medical interventions such as biopsy and polyp resection; therefore, the optimization of the localization outcome is important. Current approaches to endoscopic capsule localization are mainly based on external sensors and transit time estimations. Recently, we demonstrated the feasibility of capsule localization based entirely on visual features, without the use of external sensors. This technique relies on a motion estimation algorithm that enables measurements of the distance and the rotation of the capsule from the acquired video frames. Towards the determination of an optimal visual feature extraction technique for capsule motion estimation, an extensive comparative assessment of several state-of-the-art techniques, using a publicly available dataset, is presented. The results show that the minimization of the localization error is possible at the cost of computational efficiency. A localization error of approximately one order of magnitude higher than the minimal one can be considered as compromise for the use of current computationally efficient feature extraction techniques. Crown Copyright (C) 2015 Published by Elsevier Ltd. All rights reserved.
C1 [Spyrou, Evaggelos; Iakovidis, Dimitris K.; Niafas, Stavros] Technol Educ Inst Cent Greece, Dept Comp Engn, Lamia 35100, Greece.
   [Spyrou, Evaggelos] Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, CIL, Athens 60037, Greece.
   [Koulaouzidis, Anastasios] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh EH16 4SA, Midlothian, Scotland.
C3 National Centre of Scientific Research "Demokritos"; Royal Infirmary of
   Edinburgh; University of Edinburgh
RP Spyrou, E (通讯作者)，Technol Educ Inst Cent Greece, Dept Comp Engn, 3rd Km Old Natl Rd Lamia Athens, Lamia 35100, Greece.
RI Koulaouzidis, Anastasios/G-9060-2014
OI Koulaouzidis, Anastasios/0000-0002-2248-489X
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2010, MATLAB VERS 7 10 0 R
   Bao G., 2012, P INT C MOD SIM VIS
   Bao G., 2013, P 14 INT C BIOINF CO
   Baptista Veronica, 2014, World J Gastrointest Pathophysiol, V5, P523, DOI 10.4291/wjgp.v5.i4.523
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beppu T., 2014, ENDOSCOPY DIAGNOSIS, P25
   Ciuti Gastone, 2011, IEEE Rev Biomed Eng, V4, P59, DOI 10.1109/RBME.2011.2171182
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gay G, 2006, ENDOSCOPY, V38, P49, DOI 10.1055/s-2005-921176
   Hai Vu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2468, DOI 10.1109/ICPR.2010.604
   Harris C. G., 1988, P ALVEY VISION C 198, P147
   Hartley R., 2004, MULTIPLE VIEW GEOMET
   Iakovidis D.K., 2013, P 13 IEEE INT C BIOI, P1
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Karargyris A., 2014, ODOCAPSULE NEXT GENE, DOI [10.1109/TBME.2014.2352493, DOI 10.1109/TBME.2014.2352493]
   Karargyris A, 2013, WORLD J GASTROENTERO, V19, P5943, DOI 10.3748/wjg.v19.i35.5943
   Koulaouzidis A, 2014, GUT, V63, pA44, DOI 10.1136/gutjnl-2014-307263.90
   Koulaouzidis A, 2013, WORLD J GASTROENTERO, V19, P3726, DOI 10.3748/wjg.v19.i24.3726
   Li X, 2009, ENDOSCOPY, V41, P762, DOI 10.1055/s-0029-1215009
   Liu L, 2009, IEEE ENG MED BIO, P3711, DOI 10.1109/IEMBS.2009.5334803
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Marya N, 2014, GASTROINTEST ENDOSC, V79, P669, DOI 10.1016/j.gie.2013.11.022
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Miksik O, 2012, INT C PATT RECOG, P2681
   Moglia A, 2009, NAT REV GASTRO HEPAT, V6, P353, DOI 10.1038/nrgastro.2009.69
   Nister D., 2004, COMP VIS PATT REC 20, V1, pI, DOI [10.1109/CVPR.2004.1315094, DOI 10.1109/CVPR.2004.1315094]
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Spyrou E., 2012, Proceedings of the 2012 IEEE International Conference on Imaging Systems and Techniques (IST), P101, DOI 10.1109/IST.2012.6295583
   Spyrou E, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/1/015002
   Szczypinski PM, 2009, MED IMAGE ANAL, V13, P312, DOI 10.1016/j.media.2008.12.002
   Tomasi C., 1991, DETECTION TRACKING P
   Than TD, 2012, IEEE T BIO-MED ENG, V59, P2387, DOI 10.1109/TBME.2012.2201715
   Vedaldi A., 2008, VLFEAT OPEN PORTABLE
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Xiaona Wang, 2011, International Journal of Mechatronics and Automation, V1, P38, DOI 10.1504/IJMA.2011.039154
   Zhou MD, 2014, IEEE ENG MED BIO, P5591, DOI 10.1109/EMBC.2014.6944894
   Zhou R, 2013, IEEE INT C INT ROBOT, P3096, DOI 10.1109/IROS.2013.6696795
NR 44
TC 11
Z9 12
U1 4
U2 19
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD OCT 1
PY 2015
VL 65
BP 297
EP 307
DI 10.1016/j.compbiomed.2015.05.013
PG 11
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA CT5OW
UT WOS:000362860700033
PM 26073184
DA 2023-04-20
ER

PT J
AU Yuan, YX
   Wang, JL
   Li, BP
   Meng, MQH
AF Yuan, Yixuan
   Wang, Jiaole
   Li, Baopu
   Meng, Max Q. -H.
TI Saliency Based Ulcer Detection for Wireless Capsule Endoscopy Diagnosis
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Locality; constrained linear coding (LLC); multi-level superpixel
   representation; saliency; saliency-based max-pooling method
ID FEATURES; ROTATION; SCALE
AB Ulcer is one of the most common symptoms of many serious diseases in the human digestive tract. Especially for the ulcers in the small bowel where other procedures cannot adequately visualize, wireless capsule endoscopy (WCE) is increasingly being used in the diagnosis and clinical management. Because WCE generates large amount of images from the whole process of inspection, computer-aided detection of ulcer is considered an indispensable relief to clinicians. In this paper, a two-staged fully automated computer-aided detection system is proposed to detect ulcer from WCE images. In the first stage, we propose an effective saliency detection method based on multi-level superpixel representation to outline the ulcer candidates. To find the perceptually and semantically meaningful salient regions, we first segment the image into multi-level superpixel segmentations. Each level corresponds to different initial region sizes of the superpixels. Then we evaluate the corresponding saliency according to the color and texture features in superpixel region of each level. In the end, we fuse the saliency maps from all levels together to obtain the final saliency map. In the second stage, we apply the obtained saliency map to better encode the image features for the ulcer image recognition tasks. Because the ulcer mainly corresponds to the saliency region, we propose a saliency max-pooling method integrated with the Locality-constrained Linear Coding (LLC) method to characterize the images. Experiment results achieve promising 92.65% accuracy and 94.12% sensitivity, validating the effectiveness of the proposed method. Moreover, the comparison results show that our detection system outperforms the state-of-the-art methods on the ulcer classification task.
C1 [Yuan, Yixuan; Wang, Jiaole] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
   [Li, Baopu] Shenzhen Univ, Dept Biomed Engn, Shenzhen 518005, Peoples R China.
   [Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong; Shenzhen University; Chinese University
   of Hong Kong
RP Li, BP (通讯作者)，Shenzhen Univ, Dept Biomed Engn, Shenzhen 518005, Peoples R China.
EM yxyuan@ee.cuhk.edu.hk; jlwang@ee.cuhk.edu.hk; bpli@szu.edu.cn;
   max@ee.cuhk.edu.hk
RI meng, meng/GWZ-7461-2022; Meng, Max Q.-H./C-8078-2009; Meng,
   Q./GSI-6185-2022
OI Yuan, Yixuan/0000-0002-0853-6948
FU RGC [GRF 415613]; National Natural Science Foundation of China
   [61305099]
FX This work is supported by RGC GRF 415613 awarded to Max Q.-H. Meng and
   partially by National Natural Science Foundation of China (61305099)
   awarded to Baopu Li. Asterisk indicates corresponding author.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2010, [No title captured], DOI DOI 10.1109/CVPR.2010.5540018
   Appleyard M, 2000, GASTROENTEROLOGY, V119, P1431, DOI 10.1053/gast.2000.20844
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Charisis V., 2012, NEW ADV BASIC CLIN G, P185
   Charisis V. S., 2012, 2012 25 IEEE INT S C, P1
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dalai N., 2005, PROC CVPR IEEE, P886, DOI DOI 10.1109/CVPR.2005.177
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J., 2006, P ADV NEUR INF PROC, DOI DOI 10.7551/MITPRESS/7503.003.0073
   Ho HT, 2012, IEEE IMAGE PROC, P153, DOI 10.1109/ICIP.2012.6466818
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Lazebnik S., 2006, P IEEE INT C COMP VI, V2, P2169, DOI DOI 10.1109/CVPR.2006.68
   Lee NM, 2010, EXPERT REV GASTROENT, V4, P503, DOI 10.1586/EGH.10.44
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma T, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P582, DOI 10.1109/ChinaSIP.2014.6889310
   Manno M., 2012, ILEOSCOPY, P79
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Moore AP, 2008, PROC CVPR IEEE, P998
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Safdari M., 2013, P SPIE MED IMAG
   Upchurch BR, 2008, REV GASTROENTEROL DI, V8, P169
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Wang J, 2010, APPL MECH MATER, V36, P96, DOI [10.4028/www.scientific.net/AMM.36.96, 10.1109/ICICTA.2010.35]
   Wang JY, 2011, IEEE T MED IMAGING, V30, P1996, DOI 10.1109/TMI.2011.2161673
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yu LC, 2012, INT C PATT RECOG, P45
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhu L, 2013, IEEE IMAGE PROC, P176, DOI 10.1109/ICIP.2013.6738037
NR 41
TC 87
Z9 88
U1 2
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD OCT
PY 2015
VL 34
IS 10
BP 2046
EP 2057
DI 10.1109/TMI.2015.2418534
PG 12
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA CS8SF
UT WOS:000362358000004
PM 25850085
DA 2023-04-20
ER

PT J
AU Malagelada, C
   Drozdzal, M
   Segui, S
   Mendez, S
   Vitria, J
   Radeva, P
   Santos, J
   Accarino, A
   Malagelada, JR
   Azpiroz, F
AF Malagelada, Carolina
   Drozdzal, Michal
   Segui, Santi
   Mendez, Sara
   Vitria, Jordi
   Radeva, Petia
   Santos, Javier
   Accarino, Anna
   Malagelada, Juan-R
   Azpiroz, Fernando
TI Classification of functional bowel disorders by objective physiological
   criteria based on endoluminal image analysis
SO AMERICAN JOURNAL OF PHYSIOLOGY-GASTROINTESTINAL AND LIVER PHYSIOLOGY
LA English
DT Article
DE functional bowel disorders; capsule endoscopy; intestinal motility;
   computer vision analysis; machine learning
ID GASTROINTESTINAL DISORDERS; INTESTINAL CONTRACTIONS; CAPSULE ENDOSCOPY;
   DYSMOTILITY; OBSTRUCTION; MANOMETRY; MOTILITY; MACHINE; FRAMES
AB We have previously developed an original method to evaluate small bowel motor function based on computer vision analysis of endoluminal images obtained by capsule endoscopy. Our aim was to demonstrate intestinal motor abnormalities in patients with functional bowel disorders by endoluminal vision analysis. Patients with functional bowel disorders (n = 205) and healthy subjects (n = 136) ingested the endoscopic capsule (Pillcam-SB2, Given-Imaging) after overnight fast and 45 min after gastric exit of the capsule a liquid meal (300 ml, 1 kcal/ml) was administered. Endoluminal image analysis was performed by computer vision and machine learning techniques to define the normal range and to identify clusters of abnormal function. After training the algorithm, we used 196 patients and 48 healthy subjects, completely naive, as test set. In the test set, 51 patients (26%) were detected outside the normal range (P < 0.001 vs. 3 healthy subjects) and clustered into hypo-and hyperdynamic subgroups compared with healthy subjects. Patients with hypodynamic behavior (n = 38) exhibited less luminal closure sequences (41 +/- 2% of the recording time vs. 61 +/- 2%; P < 0.001) and more static sequences (38 +/- 3 vs. 20 +/- 2%; P < 0.001); in contrast, patients with hyperdynamic behavior (n = 13) had an increased proportion of luminal closure sequences (73 +/- 4 vs. 61 +/- 2%; P = 0.029) and more high-motion sequences (3 +/- 1 vs. 0.5 +/- 0.1%; P < 0.001). Applying an original methodology, we have developed a novel classification of functional gut disorders based on objective, physiological criteria of small bowel function.
C1 [Malagelada, Carolina; Mendez, Sara; Santos, Javier; Accarino, Anna; Malagelada, Juan-R; Azpiroz, Fernando] Hosp Gen Valle Hebron, Digest Syst Res Unit, Barcelona 08035, Spain.
   [Malagelada, Carolina; Mendez, Sara; Santos, Javier; Accarino, Anna; Malagelada, Juan-R; Azpiroz, Fernando] Ctr Invest Biomed Red Enfermedades Hepat & Digest, Barcelona, Spain.
   [Malagelada, Carolina; Mendez, Sara; Santos, Javier; Accarino, Anna; Malagelada, Juan-R; Azpiroz, Fernando] Univ Autonoma Barcelona, Dept Med, E-08193 Barcelona, Spain.
   [Drozdzal, Michal; Segui, Santi; Vitria, Jordi; Radeva, Petia] Comp Vis Ctr, Bellaterra, Spain.
   [Segui, Santi; Vitria, Jordi; Radeva, Petia] Univ Barcelona, Appl Math & Anal Dept, Barcelona, Spain.
C3 Hospital Universitari Vall d'Hebron; CIBER - Centro de Investigacion
   Biomedica en Red; CIBEREHD; Autonomous University of Barcelona; Centre
   de Visio per Computador (CVC); University of Barcelona
RP Azpiroz, F (通讯作者)，Hosp Gen Valle Hebron, Digest Syst Res Unit, Barcelona 08035, Spain.
EM azpiroz.fernando@gmail.com
RI Vitrià, Jordi/AAF-9668-2020; Garaventa, Anna Accarino/Q-8658-2017;
   Segui, Santi/E-4860-2010; Santos, Javier/O-1501-2014; Radeva,
   Petia/I-3385-2015; Malagelada, Carolina/F-3743-2016
OI Vitrià, Jordi/0000-0003-1484-539X; Segui, Santi/0000-0002-8603-138X;
   Santos, Javier/0000-0002-4798-5033; Radeva, Petia/0000-0003-0047-5172;
   Malagelada, Carolina/0000-0001-7097-1492; Azpiroz,
   Fernando/0000-0002-7327-960X
FU Given Imaging; Spanish Ministry of Economy and Competitiveness
   (Direccion General de Investigacion Cientifica y Tecnica) [SAF
   2013-43677-R]; Instituto de Salud Carlos III
FX This work was supported in part by Given Imaging and the Spanish
   Ministry of Economy and Competitiveness (Direccion General de
   Investigacion Cientifica y Tecnica, SAF 2013-43677-R). CIBERehd is
   funded by the Instituto de Salud Carlos III.
CR ACCARINO AM, 1993, J GASTROINTEST MOTIL, V5, P23
   Bifet A, 2007, P 2007 SIAM INT C DA
   Camci F, 2008, PATTERN RECOGN, V41, P3021, DOI 10.1016/j.patcog.2008.04.001
   CAMILLERI M, 1989, GUT, V30, P468, DOI 10.1136/gut.30.4.468
   Camilleri M, 2015, AM J PHYSIOL-GASTR L, V309, pG411, DOI 10.1152/ajpgi.00265.2015
   Cogliandro RF, 2011, NEUROGASTROENT MOTIL, V23, P1084, DOI 10.1111/j.1365-2982.2011.01783.x
   De Iorio F, 2009, NEUROGASTROENT MOTIL, V21, DOI 10.1111/j.1365-2982.2009.01363.x
   Drozdzal M, 2011, LECT NOTES COMPUT SC, V6669, P143
   FRANK JW, 1994, AM J GASTROENTEROL, V89, P339
   Lloyd S., 1982, IEEE T INFORMATION T, V28, P129, DOI DOI 10.1109/TIT.1982.1056489
   Longstreth GF, 2006, GASTROENTEROLOGY, V130, P1480, DOI 10.1053/j.gastro.2005.11.061
   Malagelada C, 2012, NEUROGASTROENT MOTIL, V24, P223, DOI 10.1111/j.1365-2982.2011.01823.x
   Malagelada C, 2008, GASTROENTEROLOGY, V135, P1155, DOI 10.1053/j.gastro.2008.06.084
   Marciani L, 2010, GASTROENTEROLOGY, V138, P469, DOI 10.1053/j.gastro.2009.10.055
   Ohkubo H, 2013, AM J GASTROENTEROL, V108, P1130, DOI 10.1038/ajg.2013.57
   Quigley EMM, 2015, J NEUROGASTROENTEROL, V21, P330, DOI 10.5056/jnm15094
   Quigley Eamonn M M, 2010, Gastroenterology, V139, P346, DOI 10.1053/j.gastro.2010.05.031
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   RUSS JC, 2007, IMAGE PROCESSING HDB
   Segui S, 2008, LECT NOTES COMPUT SC, V5008, P251
   Segui S, 2014, IEEE J BIOMED HEALTH, V18, P1831, DOI 10.1109/JBHI.2014.2304179
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Waljee AK, 2010, AM J GASTROENTEROL, V105, P1224, DOI 10.1038/ajg.2010.173
NR 25
TC 25
Z9 25
U1 0
U2 6
PU AMER PHYSIOLOGICAL SOC
PI BETHESDA
PA 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA
SN 0193-1857
EI 1522-1547
J9 AM J PHYSIOL-GASTR L
JI Am. J. Physiol.-Gastroint. Liver Physiol.
PD SEP 15
PY 2015
VL 309
IS 6
BP G413
EP G419
DI 10.1152/ajpgi.00193.2015
PG 7
WC Gastroenterology & Hepatology; Physiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Physiology
GA CS1IO
UT WOS:000361817700002
PM 26251472
OA Bronze
DA 2023-04-20
ER

PT J
AU Ayaru, L
   Ypsilantis, PP
   Nanapragasam, A
   Choi, RCH
   Thillanathan, A
   Min-Ho, L
   Montana, G
AF Ayaru, Lakshmana
   Ypsilantis, Petros-Pavlos
   Nanapragasam, Abigail
   Choi, Ryan Chang-Ho
   Thillanathan, Anish
   Min-Ho, Lee
   Montana, Giovanni
TI Prediction of Outcome in Acute Lower Gastrointestinal Bleeding Using
   Gradient Boosting
SO PLOS ONE
LA English
DT Article
ID MANAGEMENT; MORTALITY; VALIDATION; HEMORRHAGE; IMPACT; RISK
AB Background
   There are no widely used models in clinical care to predict outcome in acute lower gastrointestinal bleeding (ALGIB). If available these could help triage patients at presentation to appropriate levels of care/intervention and improve medical resource utilisation. We aimed to apply a state-of-the-art machine learning classifier, gradient boosting (GB), to predict outcome in ALGIB using non-endoscopic measurements as predictors.
   Methods
   Non-endoscopic variables from patients with ALGIB attending the emergency departments of two teaching hospitals were analysed retrospectively for training/internal validation (n=170) and external validation (n=130) of the GB model. The performance of the GB algorithm in predicting recurrent bleeding, clinical intervention and severe bleeding was compared to a multiple logic regression (MLR) model and two published MLR-based prediction algorithms (BLEED and Strate prediction rule).
   Results
   The GB algorithm had the best negative predictive values for the chosen outcomes (>88%). On internal validation the accuracy of the GB algorithm for predicting recurrent bleeding, therapeutic intervention and severe bleeding were (88%, 88% and 78% respectively) and superior to the BLEED classification (64%, 68% and 63%), Strate prediction rule (78%, 78%, 67%) and conventional MLR (74%, 74% 62%). On external validation the accuracy was similar to conventional MLR for recurrent bleeding (88% vs. 83%) and therapeutic intervention (91% vs. 87%) but superior for severe bleeding (83% vs. 71%).
   Conclusion
   The gradient boosting algorithm accurately predicts outcome in patients with acute lower gastrointestinal bleeding and outperforms multiple logistic regression based models. These may be useful for risk stratification of patients on presentation to the emergency department.
C1 [Ayaru, Lakshmana; Nanapragasam, Abigail; Choi, Ryan Chang-Ho; Thillanathan, Anish; Min-Ho, Lee] Imperial Coll Healthcare NHS Trust, Charing Cross Hosp, Dept Gastroenterol, London, England.
   [Ayaru, Lakshmana; Nanapragasam, Abigail; Choi, Ryan Chang-Ho; Thillanathan, Anish; Min-Ho, Lee] Imperial Coll Healthcare NHS Trust, Hammersmith Hosp, London, England.
   [Ypsilantis, Petros-Pavlos; Montana, Giovanni] Kings Coll London, Dept Biomed Engn, London, England.
C3 Imperial College London; Imperial College London; University of London;
   King's College London
RP Ayaru, L (通讯作者)，Imperial Coll Healthcare NHS Trust, Charing Cross Hosp, Dept Gastroenterol, London, England.
EM Lakshmana.ayaru@imperial.nhs.uk; giovanni.montana@kcl.ac.uk
CR Aoki T, 2015, CLIN GASTROENTEROL H, V13, P488, DOI 10.1016/j.cgh.2014.06.023
   Austin PC, 2012, BIOMETRICAL J, V54, P657, DOI 10.1002/bimj.201100251
   Barnert J, 2009, NAT REV GASTRO HEPAT, V6, P637, DOI 10.1038/nrgastro.2009.167
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726
   Breiman L., 1984, CLASSIFICATION REGRE, DOI [10.1002/widm.8, DOI 10.1002/WIDM.8]
   Casanova R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098587
   Chen HY, 2007, NEW ENGL J MED, V356, P11, DOI 10.1056/NEJMoa060096
   Chen YF, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/873595
   Chu A, 2008, ARTIF INTELL MED, V42, P247, DOI 10.1016/j.artmed.2007.10.003
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Dodd S, 2014, J AFFECT DISORDERS, V168, P284, DOI 10.1016/j.jad.2014.05.014
   Dworzynski K, 2012, BRIT MED J, V344, DOI 10.1136/bmj.e3412
   Farrell JJ, 2005, ALIMENT PHARM THER, V21, P1281, DOI 10.1111/j.1365-2036.2005.02485.x
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gurm HS, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096385
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Jianjun Xie, 2010, Statistical Analysis and Data Mining, V3, P253, DOI 10.1002/sam.10079
   Kalai A., 2003, P ANN ACM S THEORY C, P195, DOI [10.1145/780542.780573, DOI 10.1145/780542.780573]
   Kollef MH, 1997, CRIT CARE MED, V25, P1125, DOI 10.1097/00003246-199707000-00011
   Lanas A, 2009, AM J GASTROENTEROL, V104, P1633, DOI 10.1038/ajg.2009.164
   Maroco Joao, 2011, BMC Res Notes, V4, P299, DOI 10.1186/1756-0500-4-299
   Martin R, 2006, PHARMACOGENOMICS, V7, P1003, DOI 10.2217/14622416.7.7.1003
   Parker Donna R, 2011, J Med Econ, V14, P279, DOI 10.3111/13696998.2011.571328
   Peng SY, 2010, EUR J NEUROL, V17, P945, DOI 10.1111/j.1468-1331.2010.02955.x
   Strate LL, 2008, CLIN GASTROENTEROL H, V6, P1004, DOI 10.1016/j.cgh.2008.03.021
   Strate LL, 2010, CLIN GASTROENTEROL H, V8, P333, DOI 10.1016/j.cgh.2009.12.017
   Strate LL, 2005, AM J GASTROENTEROL, V100, P1821, DOI 10.1111/j.1572-0241.2005.41755.x
   Strate LL, 2003, ARCH INTERN MED, V163, P838, DOI 10.1001/archinte.163.7.838
   Velayos FS, 2004, CLIN GASTROENTEROL H, V2, P485, DOI 10.1016/S1542-3565(04)00167-3
   Venkatesh PGK, 2014, INT J COLORECTAL DIS, V29, P953, DOI 10.1007/s00384-014-1915-x
   Weiss JC, 2012, P INN APPL ART INT C
NR 32
TC 36
Z9 38
U1 0
U2 4
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JUL 14
PY 2015
VL 10
IS 7
AR e0132485
DI 10.1371/journal.pone.0132485
PG 14
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA CN1QN
UT WOS:000358194900054
PM 26172121
OA gold, Green Published, Green Submitted
DA 2023-04-20
ER

PT J
AU Saftoiu, A
   Vilmann, P
   Dietrich, CF
   Iglesias-Garcia, J
   Hocke, M
   Seicean, A
   Ignee, A
   Hassan, H
   Streba, CT
   Ioncica, AM
   Gheonea, DI
   Ciurea, T
AF Saftoiu, Adrian
   Vilmann, Peter
   Dietrich, Christoph F.
   Iglesias-Garcia, Julio
   Hocke, Michael
   Seicean, Andrada
   Ignee, Andre
   Hassan, Hazem
   Streba, Costin Teodor
   Ioncica, Ana Maria
   Gheonea, Dan Ionut
   Ciurea, Tudorel
TI Quantitative contrast-enhanced harmonic EUS in differential diagnosis of
   focal pancreatic masses (with videos)
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID LOW MECHANICAL INDEX; ENDOSCOPIC ULTRASOUND; TRANSABDOMINAL ULTRASOUND;
   CONVENTIONAL ULTRASOUND; ULTRASONOGRAPHY; CANCER; TUMORS; LESIONS;
   QUANTIFICATION; PERFUSION
AB Background: The role of EUS with contrast agents can be expanded through the use of time-intensity curve (TIC) analysis and computer-aided interpretation.
   Objective: To validate the use of parameters derived from TIC analysis in an artificial neural network (ANN) classification model designed to diagnose pancreatic carcinoma (PC) and chronic pancreatitis (CP).
   Setting: Prospective, multicenter, observational trialdendoscopy units from Romania, Denmark, Germany, and Spain.
   Patients: A total of 167 consecutive patients with PC or CP.
   Interventions: Contrast-enhanced harmonic EUS (CEH-EUS) and EUS-guided FNA (EUS-FNA), TIC analysis, and ANN processing.
   Main Outcome Measurements: Sensitivity, specificity, positive and negative predictive values (PPV, NPV) for EUS-FNA, CEH-EUS, and the ANN.
   Results: After excluding all of the recordings that did not meet the technical and procedural criteria, 112 cases of PC and 55 cases of CP were included. EUS-FNA was performed in 129 patients, and the diagnosis was confirmed by surgery (n Z 15) or follow-up (n = 23) in the remaining cases. Its sensitivity and specificity were 84.82% and 100%, respectively, whereas the PPV and NPV were 100% and 76.63%, respectively. The sensitivity of realtime quantitative assessment of CEH-EUS was 87.5%, specificity 92.72%, PPV 96.07%, and NPV 78.46%. Peak enhancement, wash-in area under the curve, wash-in rate, and the wash-in perfusion index were significantly different between the groups. No significant differences were found between rise time, mean transit time, and time to peak. For the ANN, sensitivity was 94.64%, specificity 94.44%, PPV 97.24%, and NPV 89.47%.
   Limitations: Only PC and CP lesions were included.
   Conclusion: Parameters obtained through TIC analysis can differentiate between PC and CP cases and can be used in an automated computer-aided diagnostic system with good diagnostic results.
C1 [Saftoiu, Adrian; Streba, Costin Teodor; Ioncica, Ana Maria; Gheonea, Dan Ionut; Ciurea, Tudorel] Univ Med & Pharm, Res Ctr Gastroenterol & Hepatol Craiova, Craiova, Romania.
   [Saftoiu, Adrian; Vilmann, Peter; Hassan, Hazem] Copenhagen Univ Hosp, Endoscopy Dept, Herlev, Denmark.
   [Dietrich, Christoph F.] Zhengzhou Univ, Affiliated Hosp 1, Sino German Res Ctr Ultrasound Med, Zhengzhou 450052, Peoples R China.
   [Dietrich, Christoph F.; Ignee, Andre] Caritas Krankenhaus Bad, Med D 2, Mergentheim, Germany.
   [Iglesias-Garcia, Julio] Univ Hosp Santiago de Compostela, Dept Gastroenterol, Coruna, Spain.
   [Hocke, Michael] Hosp Meiningen, Internal Med 2, Meiningen, Germany.
   [Seicean, Andrada] Univ Med & Pharm Iuliu Hatieganu, Reg Inst Gastroenterol & Hepatol, Cluj Napoca, Romania.
C3 University of Medicine & Pharmacy of Craiova; University of Copenhagen;
   Zhengzhou University; Caritas Hospital Bad Mergentheim; Complexo
   Hospitalario Universitario de Santiago de Compostela; Iuliu Hatieganu
   University of Medicine & Pharmacy; Regional Institute of
   Gastroenterology & Hepatology
RP Streba, CT (通讯作者)，Res Ctr Gastroenterol & Hepatol, Craiova, Romania.
RI Ignee, André/G-7729-2019; Saftoiu, Adrian/C-2792-2011; Gheonea, Dan
   Ionut/C-3578-2012; Streba, Costin Teodor T/C-4196-2011; Dietrich,
   Christoph/AAB-7514-2020; Vilmann, Peter/AAJ-8401-2020; Vilmann,
   Peter/AAP-2730-2021; Ciurea, Tudorel/G-3226-2016; Ignee,
   André/AAH-3333-2019
OI Saftoiu, Adrian/0000-0001-7993-8269; Streba, Costin Teodor
   T/0000-0001-9590-3197; Ignee, André/0000-0002-2388-2945; Ciurea,
   Tudorel/0009-0009-9860-0795
FU Bracco Suisse SA (Geneva, Switzerland) [CEH-EUS-001]; National Research
   Council-UEFISCDI [PN-II-ID-PCE-2011-3-0589]; research grant Minimal
   Invasive Assessment of Angiogenesis in Pancreatic Cancer Based on
   Imaging Methods and Molecular Techniques (Angio-PAC), Ideas Programme
   [164/2011]
FX The study Contrast Enhanced Harmonic Endoscopic Ultrasound (CEH-EUS) in
   Focal Pancreatic Masses was supported by Bracco Suisse SA (CEH-EUS-001;
   Geneva, Switzerland), who provided a trial version of the VueBox
   quantification software after reviewing the study protocol. The study
   was partially supported by the research grant Minimal Invasive
   Assessment of Angiogenesis in Pancreatic Cancer Based on Imaging Methods
   and Molecular Techniques (Angio-PAC), Ideas Programme, 164/2011,
   National Research Council-UEFISCDI, PN-II-ID-PCE-2011-3-0589. All other
   authors disclosed no financial relationships relevant to this article.
CR Sanchez MVA, 2009, GASTROINTEST ENDOSC, V69, pS71, DOI 10.1016/j.gie.2008.12.004
   Catalano MF, 2009, GASTROINTEST ENDOSC, V69, P1251, DOI 10.1016/j.gie.2008.07.043
   Claudon M, 2008, ULTRASCHALL MED, V29, P28, DOI 10.1055/s-2007-963785
   D'Onofrio M, 2007, ABDOM IMAGING, V32, P171, DOI 10.1007/s00261-006-9010-6
   D'Onofrio M, 2004, ABDOM IMAGING, V29, P246, DOI 10.1007/s00261-003-0097-8
   D'Onofrio M, 2012, EUR J RADIOL, V81, P630, DOI 10.1016/j.ejrad.2011.01.053
   Dietrich CF, 2008, J CANCER RES CLIN, V134, P635, DOI 10.1007/s00432-007-0326-6
   Dietrich CF, 2012, ULTRASCHALL MED, V33, P344, DOI 10.1055/s-0032-1313026
   Dietrich CF, 2009, ENDOSCOPY, V41, pE43, DOI 10.1055/s-0028-1119491
   Dietrich CF, 2005, Z GASTROENTEROL, V43, P1219, DOI 10.1055/s-2005-858662
   Dietrich CF, 2008, CLIN GASTROENTEROL H, V6, P590, DOI 10.1016/j.cgh.2008.02.030
   Fan ZH, 2013, EUR J RADIOL, V82, P1385, DOI 10.1016/j.ejrad.2013.04.016
   Fritscher-Ravens A, 2002, AM J GASTROENTEROL, V97, P2768
   Fusaroli P, 2010, CLIN GASTROENTEROL H, V8, P629, DOI 10.1016/j.cgh.2010.04.012
   Thomas PG, 2011, ULTRASONICS, V51, P102, DOI 10.1016/j.ultras.2010.06.004
   Gheonea DI, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-2
   Gincul R, 2014, ENDOSCOPY
   Goertz RS, 2010, EUR J RADIOL, V75, pE22, DOI 10.1016/j.ejrad.2009.11.004
   Gong TT, 2012, GASTROINTEST ENDOSC, V76, P301, DOI 10.1016/j.gie.2012.02.051
   Grossi E, 2007, DIGEST LIVER DIS, V39
   Grossjohann HS, 2010, SCAND J GASTROENTERO, V45, P917, DOI 10.3109/00365521003702718
   Guo DM, 2009, COMPUT MED IMAG GRAP, V33, P588, DOI 10.1016/j.compmedimag.2009.04.005
   Hocke M, 2006, WORLD J GASTROENTERO, V12, P246, DOI 10.3748/wjg.v12.i2.246
   Ignee A, 2010, EUR J RADIOL, V73, P153, DOI 10.1016/j.ejrad.2008.10.016
   Jiang J, 2010, COMPUT MED IMAG GRAP, V34, P617, DOI 10.1016/j.compmedimag.2010.07.003
   Kalmin B, 2011, CAN J GASTROENTEROL, V25, P261, DOI 10.1155/2011/302382
   Karlson BM, 1999, RADIOLOGY, V213, P107, DOI 10.1148/radiology.213.1.r99oc25107
   Kersting S, 2011, PANCREATOLOGY, V11, P20, DOI 10.1159/000323480
   Kersting S, 2009, GASTROENTEROLOGY, V137, P1903, DOI 10.1053/j.gastro.2009.08.049
   Kida Mitsuhiro, 2011, J Interv Gastroenterol, V1, P102
   Kitano M, 2008, GASTROINTEST ENDOSC, V67, P141, DOI 10.1016/j.gie.2007.07.045
   Klapman JB, 2005, AM J GASTROENTEROL, V100, P2658, DOI 10.1111/j.1572-0241.2005.00315.x
   Krishna NB, 2009, GASTROINTEST ENDOSC, V70, P70, DOI 10.1016/j.gie.2008.10.030
   Matsubara H, 2011, PANCREAS, V40, P1073, DOI 10.1097/MPA.0b013e31821f57b7
   Miura Fumihiko, 2006, HPB (Oxford), V8, P337, DOI 10.1080/13651820500540949
   Napoleon B, 2010, ENDOSCOPY, V42, P564, DOI 10.1055/s-0030-1255537
   Peronneau P, 2010, ULTRASCHALL MED, V31, P370, DOI 10.1055/s-0029-1245450
   Piscaglia F, 2012, ULTRASCHALL MED, V33, P33, DOI 10.1055/s-0031-1281676
   Rickes S, 2004, J GASTROEN HEPATOL, V19, P761, DOI 10.1111/j.1440-1746.2004.03406.x
   Rickes S, 2002, SCAND J GASTROENTERO, V37, P1313, DOI 10.1080/003655202761020605
   Rickes S, 2006, J PANCREAS, V7, P584
   Rognin NG, 2008, ULTRASON, P1690, DOI 10.1109/ULTSYM.2008.0413
   Saftoiu A, 2012, CLIN GASTROENTEROL H, V10, P84, DOI 10.1016/j.cgh.2011.09.014
   Saftoiu A, 2010, GASTROINTEST ENDOSC, V72, P739, DOI 10.1016/j.gie.2010.02.056
   Saftoiu A, 2009, J CLIN ULTRASOUND, V37, P1, DOI 10.1002/jcu.20534
   Seicean A, 2010, ULTRASCHALL MED, V31, P571, DOI 10.1055/s-0029-1245833
   Seicean A, 2010, WORLD J GASTROENTERO, V16, P4253, DOI 10.3748/wjg.v16.i34.4253
   Seicean A, 2010, J GASTROINTEST LIVER, V19, P99
   Streba CT, 2012, GASTROENTEROLOGY, V142, pS1004
   Streba CT, 2012, WORLD J GASTROENTERO, V18, P4427, DOI 10.3748/wjg.v18.i32.4427
   Turner BG, 2010, GASTROINTEST ENDOSC, V71, P91, DOI 10.1016/j.gie.2009.06.017
   Varadarajulu S, 2005, GASTROINTEST ENDOSC, V62, P728, DOI 10.1016/j.gie.2005.06.051
   Vasile TA, 2012, J GASTROINTEST LIVER, V21, P285
   Zhang XJ, 2009, RADIOL PHYS TECHNOL, V2, P175, DOI 10.1007/s12194-009-0062-5
NR 54
TC 92
Z9 95
U1 1
U2 12
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JUL
PY 2015
VL 82
IS 1
BP 59
EP 69
DI 10.1016/j.gie.2014.11.040
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA CK4GR
UT WOS:000356182600009
PM 25792386
DA 2023-04-20
ER

PT J
AU Robinson, HF
   Dennick, R
AF Robinson, H. Fiona
   Dennick, Reg
TI Teaching laryngeal endoscopy skills to speech and language therapists:
   applying learning theory to optimize practical skills mastery
SO CURRENT OPINION IN OTOLARYNGOLOGY & HEAD AND NECK SURGERY
LA English
DT Review
DE education; endoscopy; experiential; learning theory; voice
ID EDUCATIONAL-THEORY; CLINICAL SKILLS; PERFORMANCE
AB Purpose of review
   This review was carried out to highlight relevant learning theory and its application to the teaching of endoscopic skills to speech and language therapists (SLTs). This article explains the most relevant models from Constructivist, Experiential and Humanistic Learning Theory, a combination that has been described as Constructive Experience, and describes the relevance and the benefits of applying educational frameworks in course design. This approach has been formally used to design and deliver practical skills teaching in medicine.
   Recent findings
   SLTs carry out endoscopic evaluation of the larynx (EEL) to provide information for evaluation and rehabilitation of voice and swallowing disorders. These are essential procedures in ear, nose and throat, voice and swallowing specialist centres. Training in endoscopy skills for SLTs working in the ear, nose and throat specialist centres in the United Kingdom has traditionally been provided external to the local clinic environment as 1 or 2-day courses. In one survey in the United Kingdom, 79% of SLTs reported that they did not acquire the depth of skill required to carry out EEL autonomously after attending such courses. Course development to teach practical skills should be underpinned by educational theory.
   Summary
   One EEL course in the United Kingdom is described, wherein sessions are interactive and experiential, promoting deep learning, constructive feedback and reflection, enriched by the completion of logs and portfolios. From course evaluations, all the learners met the learning objectives, developing and applying skills to become confident endoscopists in autonomous clinical practice.
C1 [Robinson, H. Fiona; Dennick, Reg] Univ Hosp NHS Trust, Dept Ear Nose & Throat, Nottingham NG7 2UH, England.
C3 Nottingham University Hospital NHS Trust; University of Nottingham
RP Robinson, HF (通讯作者)，Univ Hosp NHS Trust, Dept Ear Nose & Throat, Derby Rd, Nottingham NG7 2UH, England.
EM Fiona.Robinson@nuh.nhs.uk
CR Ausubel D.P., 1968, ED PSYCHOL COGNITIVE
   Bandura A., 1971, SOCIAL LEARNING THEO
   Carding PN, 2008, ROYAL COLL SPEECH LA
   Chowdhury RR, 2004, OBSTET GYNAECOL, V6, P243, DOI [10.1576/toag.6.4.243.27023, DOI 10.1576/TOAG.6.4.243.27023]
   Dennick R, 2008, INTRO STUDY ED
   Dennick R, 2012, MED TEACH, V34, P618, DOI 10.3109/0142159X.2012.668244
   Dewey J., 1963, EXPERIENCE ED, P69
   Dewey J., 1938, LOGIC THEORY ENQUIRY
   Entwistle N., 1988, STYLES LEARNING TEAC
   Ericsson KA, 2004, ACAD MED, V79, pS70, DOI 10.1097/00001888-200410001-00022
   Festinger L., 1964, CONFLICT DECISION DI
   George JH, 2001, FAM MED, V33, P577
   Gibbs G., 1988, LEARNING DOING GUIDE
   Harden RM, 2007, MED TEACH, V29, P678, DOI 10.1080/01421590701729955
   Kolb D., 2015, EXPERIENTIAL LEARNIN, V2nd
   Marton F., 2005, EXPERIENCE LEARNING, P39
   Maslow A. H., 1968, PSYCHOL BEING, V2nd ed.
   Mezirow J, 1991, TRANSFORMATIVE DIMEN
   MILLER GE, 1990, ACAD MED, V65, pS63, DOI 10.1097/00001888-199009000-00045
   Rogers C.R.(, 1983, FREEDOM LEARN 80S
   Sadideen H, 2012, AM J SURG, V204, P396, DOI 10.1016/j.amjsurg.2011.12.020
   Sch?n D., 1991, REFLECTIVE PRACTITIO
   Slade S., 2009, P BRIT AC C OT LIV
   Wertsch J., 1985, VYGOTSKY SOCIAL FORM
   Wiliam D., 1998, ASSESS EDUC, V5, P7, DOI DOI 10.1080/0969595980050102
NR 25
TC 2
Z9 2
U1 2
U2 11
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 1068-9508
EI 1531-6998
J9 CURR OPIN OTOLARYNGO
JI Curr. Opin. Otolaryngol. Head Neck Surg.
PD JUN
PY 2015
VL 23
IS 3
BP 197
EP 201
DI 10.1097/MOO.0000000000000163
PG 5
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology
GA CH9UY
UT WOS:000354383100004
PM 25943959
DA 2023-04-20
ER

PT J
AU Liu, DY
   Gan, T
   Rao, NN
   Xu, GG
   Zeng, B
   Li, HL
AF Liu, D. Y.
   Gan, T.
   Rao, N. N.
   Xu, G. G.
   Zeng, B.
   Li, H. L.
TI Automatic Detection of Early Gastrointestinal Cancer Lesions Based on
   Optimal Feature Extraction from Gastroscopic Images
SO JOURNAL OF MEDICAL IMAGING AND HEALTH INFORMATICS
LA English
DT Article
DE Gastroscopic Images; Early Gatestroinstinal Cancer; Lesion Region;
   Feature; Detection
ID GASTRIC-CANCER; TUMOR; ENDOSCOPY
AB The conventional upper gastrointestinal endoscopy, the most commonly used method of diagnosing early gastrointestinal cancers, mainly depends on the experience of digestive endoscopists to detect the suspicious lesion. This study developed a computer-aided automatic method to detect lesion regions of early gastrointestinal cancer in gastroscopic images. First, we developed a technique to eliminate the useless regions from a gastroscopic image for enhancing the accuracy of suspicious lesion detection. Then Canny-dilation algorithm was applied to segment the image into smaller regions according to different image features. Next, we combined multiple kinds of features (including color histogram, color moment and rotation invariant local binary patterns) to describe each partitioned region. Therefore the optimal features can be selected according to the respective classification accuracy of each feature between lesions and normal regions. Finally, we detected the early gastrointestinal cancer lesions based on the optimal features in a region and used the clinical data of 407 gastroscopic images to testify the validation of the proposed method. The experimental results indicated the proposed method has the sensitivity, specificity, accuracy and G-mean of 0.93, 0.83, 0.85 and 0.88 in stomach and those of 0.83, 0.88, 0.87 and 0.86 in esophagus, and has low computation complexity. The performance of the proposed method is better than co-occurrence matrix algorithm and color wavelet covariance method treating the same data set. This pilot study shows that our established method has high sensitivity and specificity in the detection of the early gastric cancers and can provide worthy guidance to the further clinical trials.
C1 [Liu, D. Y.; Rao, N. N.; Xu, G. G.] Univ Elect Sci & Technol China, Sch Life Sci & Technol, Ctr Informat BioMed, Chengdu 610054, Peoples R China.
   [Gan, T.] Sichuan Univ, West China Hosp, Digest Endoscop Ctr, Chengdu 610041, Peoples R China.
   [Zeng, B.; Li, H. L.] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China; Sichuan
   University; University of Electronic Science & Technology of China
RP Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Sch Life Sci & Technol, Ctr Informat BioMed, Chengdu 610054, Peoples R China.
FU National Natural Science Foundation [81171411]; Key Technology Research
   and Development Program of Sichuan Province [2011FZ0034]
FX The authors would like to propose a vote of thanks to Digestive
   Endoscopy Center of the West China Hospital Sichuan, China, for the
   provision of the endoscopic images used in our study. This work was
   supported by grants from National Natural Science Foundation (Grant No.
   81171411) and Key Technology Research and Development Program of Sichuan
   Province (Grant No. 2011FZ0034).
CR Alvarenga AV, 2007, MED PHYS, V34, P379, DOI 10.1118/1.2401039
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   El Abiad R, 2012, SURG ONCOL CLIN N AM, V21, P1, DOI 10.1016/j.soc.2011.09.002
   Fu Y., 2011, 2011 IEEE 54 INT MID
   Han H., 2005, INT C INT COMP, P878, DOI DOI 10.1007/11538059_91
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   He X., 2009, 2009 JOINT C PERV CO
   Iakovidis D. K., 2005, 2005 18 IEEE S CBMS
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kim KB, 2006, IEICE T FUND ELECTR, VE89A, P2662, DOI 10.1093/ietfec/e89-a.10.2662
   Kobara H, 2012, ONCOL REP, V28, P841, DOI 10.3892/or.2012.1889
   Lecleire S, 2011, DIS ESOPHAGUS, V24, P418, DOI 10.1111/j.1442-2050.2010.01164.x
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Morgagni P., 2012, SURG MULTIMODAL MANA, P81
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sun K, 2011, IEEE INT WORKS MACH
   Tang YY, 2000, IEEE T SYST MAN CY B, V30, P93, DOI 10.1109/3477.826950
   Tao Xin-min, 2011, Control and Decision, V26, P1535
   Trahanias PE, 1996, IEEE T SYST MAN CY B, V26, P135, DOI 10.1109/3477.484445
NR 19
TC 8
Z9 8
U1 1
U2 19
PU AMER SCIENTIFIC PUBLISHERS
PI VALENCIA
PA 26650 THE OLD RD, STE 208, VALENCIA, CA 91381-0751 USA
SN 2156-7018
EI 2156-7026
J9 J MED IMAG HEALTH IN
JI J. Med. Imaging Health Inform.
PD APR
PY 2015
VL 5
IS 2
BP 296
EP 302
DI 10.1166/jmihi.2015.1390
PG 7
WC Mathematical & Computational Biology; Radiology, Nuclear Medicine &
   Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology; Radiology, Nuclear Medicine &
   Medical Imaging
GA CF4PC
UT WOS:000352531300017
DA 2023-04-20
ER

PT J
AU Asakawa, Y
   Ohtaka, M
   Maekawa, S
   Fukasawa, M
   Nakayama, Y
   Yamaguchi, T
   Inoue, T
   Uetake, T
   Sakamoto, M
   Sato, T
   Kawaguchi, Y
   Fujii, H
   Mochizuki, K
   Hada, M
   Oyama, T
   Yasumura, T
   Omata, K
   Nishiyama, A
   Naito, K
   Hata, H
   Haba, Y
   Miyata, K
   Saitoh, H
   Yamadera, Y
   Miura, K
   Kawaoi, A
   Abe, T
   Tsunoda, H
   Honda, Y
   Kurosaki, M
   Enomoto, N
AF Asakawa, Yukiko
   Ohtaka, Masahiko
   Maekawa, Shinya
   Fukasawa, Mitsuharu
   Nakayama, Yasuhiro
   Yamaguchi, Tatsuya
   Inoue, Taisuke
   Uetake, Tomoyoshi
   Sakamoto, Minoru
   Sato, Tadashi
   Kawaguchi, Yoshihiko
   Fujii, Hideki
   Mochizuki, Kunio
   Hada, Masao
   Oyama, Toshio
   Yasumura, Tomotaka
   Omata, Kosaku
   Nishiyama, Atsushi
   Naito, Keiichi
   Hata, Hideo
   Haba, Yoshiaki
   Miyata, Kazuyuki
   Saitoh, Haruhisa
   Yamadera, Yoichi
   Miura, Kazuo
   Kawaoi, Akira
   Abe, Tohru
   Tsunoda, Hajime
   Honda, Yuji
   Kurosaki, Masayuki
   Enomoto, Nobuyuki
TI Stratifying the risk of lymph node metastasis in undifferentiated-type
   early gastric cancer
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Undifferentiated-type early gastric cancer; Lymph node metastasis;
   Lymphatic involvement; Data-mining analysis; Stratification
ID ENDOSCOPIC SUBMUCOSAL DISSECTION; PREDICTIVE FACTORS; CARCINOMA;
   CLASSIFICATION; RESECTION; FEASIBILITY; INVASION; IMPACT
AB AIM: To study how lymph node metastasis (LNM) risk is stratified in undifferentiated-type early gastric cancer (undiff-EGC) dependent on combinations of risk factors.
   METHODS: Five hundred and sixty-seven cases with undiff-EGC undergoing gastrectomy with lymphadenectomy were examined retrospectively. Using clinicopathological factors of patient age, location, size, an endoscopic macroscopic tumor form, ulceration, depth, histology, lymphatic involvement (LI) and venous involvement (VI), LNM risk was examined and stratified by conventional statistical analysis and data-mining analysis.
   RESULTS: LNM was positive in 44 of 567 cases (7.8%). Univariate analysis revealed > 2 cm, protrusion, submucosal (sm), mixed type, LI and VI as significant prognostic factors and > 2 cm and LI-positive were independent factors by multivariate analysis. In preoper-atively evaluable factors excluding LVI, sm and > 2 cm were independent factors. According to the depth and size, cases were categorized into the low-risk group [m and <= 2 cm, 0% (LNM incidence)], the moderaterisk group (m and > 2 cm, 5.6%; and sm and <= 2 cm, 6.0%), and the high-risk group (sm and > 2 cm, 19.3%). On the other hand, LNM occurred in 1.4% in all LI-negative cases, greatly lower than 28.2% in all LI-positive cases, and LNM incidence was low in LI-negative cases even in the moderate-and high-risk groups.
   CONCLUSION: LNM-related factors in undiff-EGC were depth and size preoperatively while those were LI and size postoperatively. Among these factors, LI was the most significantly correlated factor.
C1 [Asakawa, Yukiko; Ohtaka, Masahiko; Maekawa, Shinya; Fukasawa, Mitsuharu; Nakayama, Yasuhiro; Yamaguchi, Tatsuya; Inoue, Taisuke; Uetake, Tomoyoshi; Sakamoto, Minoru; Sato, Tadashi; Enomoto, Nobuyuki] Univ Yamanashi, Fac Med, Dept Internal Med 1, Yamanashi 4093898, Japan.
   [Kawaguchi, Yoshihiko; Fujii, Hideki] Univ Yamanashi, Fac Med, Dept Surg 1, Yamanashi 4093898, Japan.
   [Mochizuki, Kunio] Univ Yamanashi, Fac Med, Dept Pathol, Yamanashi 4093898, Japan.
   [Hada, Masao] Yamanashi Prefectural Cent Hosp, Dept Surg, Yamanashi 4008506, Japan.
   [Oyama, Toshio] Yamanashi Prefectural Cent Hosp, Dept Pathol, Yamanashi 4008506, Japan.
   [Yasumura, Tomotaka] Social Insurance Yamanashi Hosp, Dept Surg, Yamanashi 4000025, Japan.
   [Omata, Kosaku] Social Insurance Yamanashi Hosp, Dept Pathol, Yamanashi 4000025, Japan.
   [Nishiyama, Atsushi; Naito, Keiichi] Kofu Kyoritsu Hosp, Dept Gen Surg, Yamanashi 4000034, Japan.
   [Hata, Hideo; Miyata, Kazuyuki] Kofu Kyoritsu Hosp, Dept Pathol, Yamanashi 4000034, Japan.
   [Haba, Yoshiaki; Saitoh, Haruhisa; Yamadera, Yoichi] Kofu Kyoritsu Hosp, Dept Surg, Yamanashi 4000034, Japan.
   [Miura, Kazuo] Kanoiwa Gen Hosp, Dept Surg, Yamanashi 4050018, Japan.
   [Kawaoi, Akira] Kanoiwa Gen Hosp, Dept Pathol, Yamanashi 4050018, Japan.
   [Abe, Tohru] Social Insurance Kajikazawa Hosp, Dept Surg, Yamanashi 4000601, Japan.
   [Tsunoda, Hajime] Kofu Natl Hosp, Dept Surg, Yamanashi 4000006, Japan.
   [Honda, Yuji] Fujiyoshida Municipal Med Ctr, Dept Surg, Yamanashi 4030005, Japan.
   [Kurosaki, Masayuki] Musashino Red Cross Hosp, Div Gastroenterol & Hepatol, Tokyo 1800023, Japan.
C3 University of Yamanashi; University of Yamanashi; University of
   Yamanashi
RP Ohtaka, M (通讯作者)，Univ Yamanashi, Fac Med, Dept Internal Med 1, 1110 Shimokato Chuo, Yamanashi 4093898, Japan.
EM motaka@yamanashi.ac.jp
RI Maekawa, Shinya/AAF-1349-2019
CR Abe N, 2012, GASTRIC CANCER, V15, P70, DOI 10.1007/s10120-011-0067-8
   AKAMATSU T, 1990, HISTOCHEM J, V22, P416, DOI 10.1007/BF01003461
   Bando E, 2004, BRIT J SURG, V91, P1197, DOI 10.1002/bjs.4541
   Gotoda Takuji, 2000, Gastric Cancer, V3, P219, DOI 10.1007/PL00011720
   Ha TK, 2008, ANN SURG ONCOL, V15, P508, DOI 10.1245/s10434-007-9660-9
   Hanaoka N, 2009, ENDOSCOPY, V41, P427, DOI 10.1055/s-0029-1214495
   Hirasawa T, 2010, GASTRIC CANCER, V13, P267, DOI 10.1007/s10120-010-0577-9
   Hirasawa T, 2009, GASTRIC CANCER, V12, P148, DOI 10.1007/s10120-009-0515-x
   Japanese Gastric Canc Assoc, 2011, GASTRIC CANCER, V14, P101, DOI 10.1007/s10120-011-0041-5
   Japanese Gastric Canc Assoc, 2011, GASTRIC CANCER, V14, P113, DOI 10.1007/s10120-011-0042-4
   Jeon SR, 2012, WORLD J GASTROENTERO, V18, P4578, DOI 10.3748/wjg.v18.i33.4578
   Kim KJ, 2011, TURK J GASTROENTEROL, V22, P139, DOI 10.4318/tjg.2011.0182
   Kunisaki C, 2009, ENDOSCOPY, V41, P498, DOI 10.1055/s-0029-1214758
   Kurosaki M, 2010, HEPATOL RES, V40, P251, DOI 10.1111/j.1872-034X.2009.00607.x
   Lee JH, 2012, BRIT J SURG, V99, P1688, DOI 10.1002/bjs.8934
   Li C, 2008, ANN SURG ONCOL, V15, P764, DOI 10.1245/s10434-007-9707-y
   Li H, 2008, WORLD J GASTROENTERO, V14, P4222, DOI 10.3748/wjg.14.4222
   Lo-Ciganic Weihsuan, 2011, J Diabetes Sci Technol, V5, P486
   Mandai K, 2012, GASTROENT RES PRACT, V2012, DOI 10.1155/2012/245390
   Nakata K, 2012, HEPATO-GASTROENTEROL, V59, P1855, DOI 10.5754/hge10130
   Saragoni L, 2013, GASTRIC CANCER, V16, P549, DOI 10.1007/s10120-013-0233-2
   Shimizu H, 2012, J SURG ONCOL, V105, P800, DOI 10.1002/jso.23010
   Statistics and Information Department, ABR LIF TABL JAP 201
   Takizawa K, 2013, GASTRIC CANCER, V16, P531, DOI 10.1007/s10120-012-0220-z
   World Medical Association, 2009, J INDIAN MED ASSOC, V107, P403
   Yamao T, 1996, CANCER, V77, P602, DOI 10.1002/(SICI)1097-0142(19960215)77:4<602::AID-CNCR3>3.0.CO;2-I
   Ye BD, 2008, J GASTROEN HEPATOL, V23, P46, DOI 10.1111/j.1440-1746.2006.04791.x
   Yonemura Y, 2006, HUM PATHOL, V37, P1193, DOI 10.1016/j.humpath.2006.04.014
NR 28
TC 20
Z9 23
U1 0
U2 8
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 8226 REGENCY DR, PLEASANTON, CA 94588 USA
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD MAR 7
PY 2015
VL 21
IS 9
BP 2683
EP 2692
DI 10.3748/wjg.v21.i9.2683
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA CC9KJ
UT WOS:000350688400014
PM 25759537
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Cong, Y
   Wang, S
   Liu, J
   Cao, J
   Yang, YS
   Luo, JB
AF Cong, Yang
   Wang, Shuai
   Liu, Ji
   Cao, Jun
   Yang, Yunsheng
   Luo, Jiebo
TI Deep sparse feature selection for computer aided endoscopy diagnosis
SO PATTERN RECOGNITION
LA English
DT Article
DE Deep sparse; Group sparsity; Feature selection; Computer aided
   diagnosis; Endoscopy; Image representation
ID WIRELESS CAPSULE ENDOSCOPY; TEXTURE CLASSIFICATION; IMAGE
   CLASSIFICATION; HELICOBACTER-PYLORI; FRAMES; SCALE; COLOR
AB In this paper, we develop a computer aided diagnosis algorithm to detect and classify the abnormalities in vision-based endoscopic examination. We focus on analyzing the traditional gastroscope data and help the medical experts improve the accuracy of medical diagnosis with our analysis tool. To achieve this, we first segment the image into superpixels, then extract various color and texture features from them and combine the features into one feature vector to represent the images. This approach is more flexible and accurate than the traditional patch-based image representation. Then we design a novel feature selection model with group sparsity, Deep Sparse SVM (DSSVM) that not only can assign a suitable weight to the feature dimensions like the other traditional feature selection models, but also directly exclude useless features from the feature pool. Thus, our DSSVM model can maintain the accuracy while reducing the computation complexity. Moreover, the image quality is also pre-assessed. For the experiments, we build a new gastroscope dataset with a total of about 3800 images from 1284 volunteers, and conducted various experiments and comparisons with other algorithms to justify the effectiveness and efficiency of our algorithm. (C) 2014 Elsevier Ltd. All rights reserved.
C1 [Cong, Yang; Wang, Shuai] Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Beijing 100864, Peoples R China.
   [Cong, Yang; Liu, Ji; Luo, Jiebo] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
   [Cao, Jun] Arizona State Univ, Dept Comp Sci, Tempe, AZ 85287 USA.
   [Yang, Yunsheng] Chinese Peoples Liberat Army Gen Hosp, Beijing, Peoples R China.
   [Wang, Shuai] Univ Chinese Acad Sci, Hefei, Peoples R China.
C3 Chinese Academy of Sciences; Shenyang Institute of Automation, CAS;
   University of Rochester; Arizona State University; Arizona State
   University-Tempe; Chinese People's Liberation Army General Hospital;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Cong, Y (通讯作者)，Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Beijing 100864, Peoples R China.
EM congyang81@gmail.com; shuaiwang@sia.cn; jliu@cs.rochester.edu;
   jun.cao.1@asu.edu; sunny301ddc@126.com; jiebo.luo@cs.rochester.edu
RI Luo, Jiebo/AAI-7549-2020
OI Wang, Shuai/0000-0003-3730-6401; Luo, Jiebo/0000-0002-4516-9729
FU National Science and Technology Support Program [2012BAI14B03]; NSFC
   [61105013, 61375014]; foundation of Chinese Scholarship Council
FX This work is supported by National Science and Technology Support
   Program (2012BAI14B03), NSFC (61105013, 61375014) and also the
   foundation of Chinese Scholarship Council.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Atasoy S, 2012, IEEE T MED IMAGING, V31, P637, DOI 10.1109/TMI.2011.2174252
   Atasoy S, 2010, LECT NOTES COMPUT SC, V6362, P437
   Bashar MK, 2008, LECT NOTES COMPUT SC, V5242, P603, DOI 10.1007/978-3-540-85990-1_72
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Brown G, 2012, J MACH LEARN RES, V13, P27
   Cai Deng, 2010, P 16 ACM SIGKDD INT, P333, DOI DOI 10.1145/1835804.1835848
   Cheng H., ETRI J, V33
   Chu XQ, 2010, LECT NOTES COMPUT SC, V6362, P522
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Fernando B, 2012, PROC CVPR IEEE, P3434, DOI 10.1109/CVPR.2012.6248084
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Hafner M, 2010, IEEE T INF TECHNOL B, V14, P958, DOI 10.1109/TITB.2010.2044184
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hand D.J., 1981, WILEY SERIES PROBABI, P1
   Huang CR, 2008, IEEE T INF TECHNOL B, V12, P523, DOI 10.1109/TITB.2007.913128
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Karargyris A., IEEE T MED IMAGING, P1
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Liu S, 2012, PATTERN RECOGN LETT, V33, P744, DOI 10.1016/j.patrec.2011.12.008
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Moore A. P., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587471
   Munzenmayer C, 2009, METHOD INFORM MED, V48, P324, DOI 10.3414/ME9230
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Reyes-Aldasoro CC, 2006, PATTERN RECOGN, V39, P812, DOI 10.1016/j.patcog.2005.12.003
   Riaz F, 2012, IEEE T BIO-MED ENG, V59, P2893, DOI 10.1109/TBME.2012.2212440
   Scharwachter T, 2013, LECT NOTES COMPUT SC, V8142, P435, DOI 10.1007/978-3-642-40602-7_46
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Seshamani S, 2010, LECT NOTES COMPUT SC, V6362, P454
   Seshamani S, 2011, IEEE T MED IMAGING, V30, P1468, DOI 10.1109/TMI.2011.2119326
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Sousa A, 2009, IEEE IMAGE PROC, P681, DOI 10.1109/ICIP.2009.5414082
   Tan M, 2010, P 27 INT C MACH LEAR, V2010, P1047
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Wang Y, 2010, IEEE T BIO-MED ENG, V57, P685, DOI 10.1109/TBME.2009.2034466
   Weibel T, 2012, PATTERN RECOGN, V45, P4138, DOI 10.1016/j.patcog.2012.05.023
   Weston J, 2001, ADV NEUR IN, V13, P668
   Young T.Y, 1994, HDB PATTERN RECOGNIT, V2
NR 52
TC 44
Z9 47
U1 1
U2 73
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD MAR
PY 2015
VL 48
IS 3
BP 907
EP 917
DI 10.1016/j.patcog.2014.09.010
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AY7NP
UT WOS:000347747000024
DA 2023-04-20
ER

PT J
AU Loukas, C
   Georgiou, E
AF Loukas, Constantinos
   Georgiou, Evangelos
TI Smoke detection in endoscopic surgery videos: a first step towards
   retrieval of semantic events
SO INTERNATIONAL JOURNAL OF MEDICAL ROBOTICS AND COMPUTER ASSISTED SURGERY
LA English
DT Article
DE smoke detection; event retrieval; event detection; one-class support
   vector machine (OCSVM)
ID MOTION ANALYSIS; CLASSIFICATION; TASKS
AB BackgroundEvent-based annotation of surgical operations has not received much attention, mainly due to diversity of the visual content. As a first attempt at retrieval of surgical events, we address the problem of detecting the smoke produced by electrosurgery tasks.
   MethodsAfter video decomposition into shots, a grid of particles is placed over the initial frame. The grid is advected with the space-time optical flow and a number of ad hoc kinematic features are extracted. After feature selection, a one-class support vector machine is employed for classification. A vision-based fire surveillance method is used for comparison.
   ResultsExperimental evaluation is performed on individual shots and laparoscopic cholecystectomy videos. In the first set-up, average specificity and sensitivity were 86% and 83%, respectively. In video-based assessment the recognition accuracy was80% for two of the three videos tested. The fire surveillance method had a maximum accuracy of 63%.
   ConclusionsThe irregular movement of smoke was captured robustly by the proposed features, which could also be employed for interpretation of other semantic occurrences in surgical videos. Copyright (c) 2014 John Wiley & Sons, Ltd.
C1 [Loukas, Constantinos; Georgiou, Evangelos] Univ Athens, Sch Med, Simulat Ctr, Med Phys Lab, GR-11527 Athens, Greece.
C3 Athens Medical School; National & Kapodistrian University of Athens
RP Loukas, C (通讯作者)，Univ Athens, Sch Med, Simulat Ctr, Med Phys Lab, Mikras Asias 75 Str, GR-11527 Athens, Greece.
EM cloukas@med.uoa.gr
RI Loukas, Constantinos/M-8890-2018
OI Loukas, Constantinos/0000-0001-7879-7329
CR Ahmadi SA, 2006, LECT NOTES COMPUT SC, V4190, P420
   Avgerinakiss K, 2012, INT WORKSH MULT SYST
   Bashir FI, 2006, MULTIMEDIA SYST, V12, P45, DOI 10.1007/s00530-006-0024-2
   Blum T, 2010, LECT NOTES COMPUT SC, V6363, P400
   Bouarfa L, 2011, J BIOMED INFORM, V44, P455, DOI 10.1016/j.jbi.2010.01.004
   Calderara S, 2011, MACH VISION APPL, V22, P705, DOI 10.1007/s00138-010-0272-1
   Chens T-H, 2004, INT C IM PROC ICIP S
   Droueche Z, 2012, IEEE ENG MED BIO, P4962, DOI 10.1109/EMBC.2012.6347106
   Gomez-Rodriguez F, 2003, P SOC PHOTO-OPT INS, V5094, P404, DOI 10.1117/12.487050
   Gubbis J, 2009, FIRE SAFETY J, V44, P1443
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   James A, 2007, LECT NOTES COMPUT SC, V4792, P110
   Ke Y, 2007, IEEE I CONF COMP VIS, P1424
   Kopilovic I, 2000, INT C PATT RECOG, P714, DOI 10.1109/ICPR.2000.903017
   Lalys F, 2013, INT J COMPUT ASS RAD, V8, P39, DOI 10.1007/s11548-012-0685-6
   Lees CY, 2012, INT J INNOV COMPUT I, V7, P4749
   Lo BPL, 2003, LECT NOTES COMPUT SC, V2878, P230
   Loukas C, 2013, COMPUT AIDED SURG, V18, P47, DOI 10.3109/10929088.2012.762944
   Lux M, 2010, MULTIMED TOOLS APPL, V46, P521, DOI 10.1007/s11042-009-0353-1
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Miyawaki F, 2005, IEEE T IND ELECTRON, V52, P1227, DOI 10.1109/TIE.2005.855692
   Neumuth T, 2007, INT J COMPUT ASS RAD, V2, pS436
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Padoy N, 2007, LECT NOTES COMPUT SC, V4791, P102
   Padoy N, 2008, PROC NATL CONF ARTIF
   Padoy N, 2012, MED IMAGE ANAL, V16, P632, DOI 10.1016/j.media.2010.10.001
   Perperis T, 2011, EXPERT SYST APPL, V38, P14102, DOI 10.1016/j.eswa.2011.04.219
   Quellec G, 2011, IEEE ENG MED BIO, P4465, DOI 10.1109/IEMBS.2011.6091107
   Rapantzikos K, 2011, COGN COMPUT, V3, P167, DOI 10.1007/s12559-011-9097-0
   Reiley CE, 2011, SURG ENDOSC, V25, P356, DOI 10.1007/s00464-010-1190-z
   Reiley CE, 2008, STUD HEALTH TECHNOL, V132, P396
   Sarker SJ, 2013, SURG INNOV, V20, P530, DOI 10.1177/1553350612468960
   Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Tax DMJ, 2003, LECT NOTES COMPUT SC, V2714, P342
   Toreyins B, 2005, 13 EUR SIGN PROC C E
   Wolf L, 2005, J MACH LEARN RES, V6, P1855
   Xu ZG, 2007, CIS WORKSHOPS 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY WORKSHOPS, P316, DOI 10.1109/CIS.Workshops.2007.5
   Zappella L, 2013, MED IMAGE ANAL, V17, P732, DOI 10.1016/j.media.2013.04.007
NR 41
TC 17
Z9 17
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1478-5951
EI 1478-596X
J9 INT J MED ROBOT COMP
JI Int. J. Med. Robot. Comput. Assist. Surg.
PD MAR
PY 2015
VL 11
IS 1
BP 80
EP 94
DI 10.1002/rcs.1578
PG 15
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA CC8TJ
UT WOS:000350640800011
PM 24615868
DA 2023-04-20
ER

PT J
AU Li, C
   Shi, C
   Zhang, H
   Hui, C
   Lam, KM
   Zhang, S
AF Li, Chao
   Shi, Cen
   Zhang, Huan
   Hui, Chun
   Lam, Kin Man
   Zhang, Su
TI Computer-Aided Diagnosis for Preoperative Invasion Depth of Gastric
   Cancer with Dual-Energy Spectral CT Imaging
SO ACADEMIC RADIOLOGY
LA English
DT Article
DE Computer-aided diagnosis; preoperative invasion depth; gastric cancer;
   dual-energy spectral CT; machine-learning algorithms
ID ENDOSCOPIC ULTRASONOGRAPHY; TUMOR INVASION; CARCINOMA; MRI; TOMOGRAPHY;
   ULTRASOUND; PREDICTION
AB Rationale and Objectives: This study evaluates the accuracy of dual-energy spectral computed tomography (DEsCT) imaging with the aid of computer-aided diagnosis (CAD) system in assessing serosal invasion in patients with gastric cancer.
   Materials and Methods: Thirty patients with gastric cancer were enrolled in this study. Two types of features (information) were collected with the use of DEsCT imaging: conventional features including patient's clinical information (eg, age, gender) and descriptive characteristics on the CT images (eg, location of the lesion, wall thickness at the gastric cardia) and additional spectral CT features extracted from monochromatic images (eg, 60 keV) and material-decomposition images (eg, iodine- and water-density images). The classification results of the CAD system were compared to pathologic findings. Important features can be found out using support vector machine classification method in combination with feature-selection technique thereby helping the radiologists diagnose better.
   Results: Statistical analysis showed that for the collected cases, the feature "long axis" was significantly different between group A (serosa negative) and group B (serosa positive) (P <.05). By adding quantitative spectral features from several regions of interest (ROls), the total classification accuracy was improved from 83.33% to 90.00%. Two feature ranking algorithms were used in the CAD scheme to derive the top-ranked features. The results demonstrated that low single-energy (approximately 60 key) CT values, tumor size (long axis and short axis), iodine (water) density, and Effective-Z values of ROls were important for classification. These findings concurred with the experience of the radiologist.
   Conclusions: The CAD system designed using machine-learning algorithms may be used to improve the identification accuracy in the assessment of serosal invasion in patients of gastric cancer with DEsCT imaging and provide some indicators which may be useful in predicting prognosis.
C1 [Li, Chao; Hui, Chun; Zhang, Su] Shanghai Jiao Tong Univ, Med X Res Inst, Dept Biomed Engn, Shanghai 200030, Peoples R China.
   [Shi, Cen; Zhang, Huan] Shanghai Jiao Tong Univ, Dept Radiol, Ruijin Hosp, Sch Med, Shanghai 200030, Peoples R China.
   [Lam, Kin Man] Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Hong Kong
   Polytechnic University
RP Zhang, S (通讯作者)，Shanghai Jiao Tong Univ, Med X Res Inst, Dept Biomed Engn, Room 123,1954 Huashan Rd, Shanghai 200030, Peoples R China.
EM suzhang@sjtu.edu.cn
OI Li, Chao/0000-0001-6340-9960
FU National Basic Research Program of China (973 Program) [2010CB732506];
   National Natural Science Foundation of China [81201145, 60972110]
FX This work was supported by the National Basic Research Program of China
   (973 Program, grant number 2010CB732506) and the National Natural
   Science Foundation of China (grant numbers 81201145 and 60972110).
CR [Anonymous], 2000, PATTERN CLASSIFICATI
   Arocena MG, 2006, REV ESP ENFERM DIG, V98, P582
   Chan HP, 2008, ACAD RADIOL, V15, P535, DOI 10.1016/j.acra.2008.01.014
   Chandra N, 2011, MED RADIOL DIAGN IMA, P35, DOI 10.1007/174_2010_35
   Choi J, 2010, ENDOSCOPY, V42, P705, DOI 10.1055/s-0030-1255617
   Choi J, 2011, GASTROINTEST ENDOSC, V73, P917, DOI 10.1016/j.gie.2010.11.053
   Department of Health GoSA, 2010, S AUSTR UPP GASTR CA, P140
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Edge SB, 2010, ANN SURG ONCOL, V17, P1471, DOI 10.1245/s10434-010-0985-4
   Ferro A, 2014, EUR J CANCER, V50, P1330, DOI 10.1016/j.ejca.2014.01.029
   Fujita H, 2008, COMPUT METH PROG BIO, V92, P238, DOI 10.1016/j.cmpb.2008.04.003
   Furukawa K, 2011, AM J ROENTGENOL, V197, P867, DOI 10.2214/AJR.10.5872
   Hallinan JTPD, 2013, CANCER IMAGING, V13, P212, DOI 10.1102/1470-7330.2013.0023
   Halvorsen RA, 1996, SEMIN ONCOL, V23, P325
   Han J., 2012, PROC C UAI
   He J, 2013, ACAD RADIOL
   He X, 2005, NIPS, V186, P189
   Hwang SW, 2010, J GASTROEN HEPATOL, V25, P512, DOI 10.1111/j.1440-1746.2009.06106.x
   Jemal A, 2013, CANC FACTS FIGURES
   Joo I, 2014, J MAGN REASON IMAGIN
   Joshi M, 2010, P SOC PHOTO-OPT INS, V7622
   Kwee RM, 2007, J CLIN ONCOL, V25, P2107, DOI 10.1200/JCO.2006.09.5224
   Langan D, 2008, GEMSTONE SPECTRAL IM
   Lei C, 2013, MOL CLIN ONCOL, V1, P699, DOI 10.3892/mco.2013.103
   Li B., 2013, OMICS J RADIOL
   Lim JS, 2006, RADIOGRAPHICS, V26, P143, DOI 10.1148/rg.261055078
   Lin XZ, 2011, J COMPUT ASSIST TOMO, V35, P294, DOI 10.1097/RCT.0b013e3182058d5c
   Lv PJ, 2012, KOREAN J RADIOL, V13, P434, DOI 10.3348/kjr.2012.13.4.434
   Lv PJ, 2011, RADIOLOGY, V259, P720, DOI 10.1148/radiol.11101425
   Matsumoto K, 2011, RADIOLOGY, V259, P257, DOI 10.1148/radiol.11100978
   MINAMI M, 1992, RADIOLOGY, V185, P173, DOI 10.1148/radiology.185.1.1523303
   Moschetta M, 2011, ROLE COMPUTED TOMOGR
   Motohara T, 2002, ABDOM IMAGING, V27, P376, DOI 10.1007/s00261-001-0118-4
   Pan ZL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053651
   Puli SR, 2008, WORLD J GASTROENTERO, V14, P4011, DOI 10.3748/wjg.14.4011
   Seevaratnam R, 2012, GASTRIC CANCER, V15, pS3, DOI 10.1007/s10120-011-0069-6
   Takahashi Tsunehiro, 2013, Cancers (Basel), V5, P48, DOI 10.3390/cancers5010048
   Tsuzuki T, 2011, ACTA MED OKAYAMA, V65, P105
   Yamada Y, 2012, INVEST RADIOL, V47, P292, DOI 10.1097/RLI.0b013e318240a874
   Yan C, 2009, J SURG ONCOL, V100, P205, DOI 10.1002/jso.21316
   Yu LF, 2012, AM J ROENTGENOL, V199, pS9, DOI 10.2214/AJR.12.9121
   Zhang XF, 2013, ACAD RADIOL, V20, P947, DOI 10.1016/j.acra.2013.02.011
   Zurleni T, 2013, WORLD J GASTRO SURG, V5, P287, DOI 10.4240/wjgs.v5.i11.287
NR 43
TC 7
Z9 11
U1 3
U2 31
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1076-6332
EI 1878-4046
J9 ACAD RADIOL
JI Acad. Radiol.
PD FEB
PY 2015
VL 22
IS 2
BP 149
EP 157
DI 10.1016/j.acra.2014.08.006
PG 9
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA AZ1MK
UT WOS:000348002900003
PM 25249448
DA 2023-04-20
ER

PT J
AU Unger, J
   Lohscheller, J
   Reiter, M
   Eder, K
   Betz, CS
   Schuster, M
AF Unger, Jakob
   Lohscheller, Joerg
   Reiter, Maximilian
   Eder, Katharina
   Betz, Christian S.
   Schuster, Maria
TI A Noninvasive Procedure for Early-Stage Discrimination of Malignant and
   Precancerous Vocal Fold Lesions Based on Laryngeal Dynamics Analysis
SO CANCER RESEARCH
LA English
DT Article
ID OPTICAL COHERENCE TOMOGRAPHY; VIBRATIONS; CANCER; PHONOVIBROGRAMS;
   GLOTTOGRAPHY
AB About two thirds of laryngeal cancers originate at the vocal cords. Early-stage detection of malignant vocal fold alterations, including a discrimination of premalignant lesions, represents a major challenge in laryngology as precancerous vocal fold lesions and small carcinomas are difficult to distinguish by means of regular endoscopy only. We report a procedure to discriminate between malignant and precancerous lesions by measuring the characteristics of vocal fold dynamics by means of a computerized analysis of laryngeal high-speed videos. Ten patients with squamous cell T1a carcinoma, ten with precancerous lesions with hyperkeratosis, and ten subjects without laryngeal disease underwent high-speed laryngoscopy yielding 4,000 images per second. By means of wavelet-based phonovibrographic analysis, a set of three clinically meaningful vibratory measures was extracted from the videos comprising a total number of 15,000 video frames. Statistical analysis (ANOVA with post hoc two-sided t tests, P < 0.05) revealed that vocal fold dynamics is significantly affected in the presence of precancerous lesions and T1a carcinoma. On the basis of the three measures, a discriminating pattern was extracted using a support vector machine-learning algorithm performing an individual classification in respect to the different clinical groups. By applying a leave-one-out cross-validation strategy, we could show that the proposed measures discriminate with a very high performance between precancerous lesions and T1a carcinoma (sensitivity, 100%; specificity, 100%). Although a large-scale study will be necessary to confirm clinical significance, the set of vibratory measures derived in this study may be applicable to improve the accuracy and reliability of noninvasive diagnostics of vocal fold lesions. (C)2014 AACR.
C1 [Unger, Jakob; Lohscheller, Joerg] Trier Univ Appl Sci, Dept Comp Sci, D-54293 Trier, Germany.
   [Reiter, Maximilian; Eder, Katharina; Betz, Christian S.; Schuster, Maria] Univ Munich, Dept Otorhinolaryngol Head & Neck Surg, Munich, Germany.
C3 University of Munich
RP Unger, J (通讯作者)，Trier Univ Appl Sci, D-54293 Trier, Germany.
EM unger@hochschule-trier.de
RI Betz, Christian Stephan/B-3996-2013
OI Betz, Christian Stephan/0000-0003-3188-1026; Reiter,
   Maximilian/0000-0003-3100-6838
FU German Research Foundation (DFG) [LO-1413/2-2]
FX The German Research Foundation (DFG) supports this work. Grant no.
   LO-1413/2-2.
CR Bahannan AA, 2014, HEAD NECK-J SCI SPEC, V36, P763, DOI 10.1002/hed.23368
   Betz CS, 2002, INT J CANCER, V97, P245, DOI 10.1002/ijc.1596
   Bonilha HS, 2012, AM J SPEECH-LANG PAT, V21, P3, DOI 10.1044/1058-0360(2011/09-0086)
   Burns JA, 2012, CURR OPIN OTOLARYNGO, V20, P477, DOI 10.1097/MOO.0b013e3283582d7d
   Dejonckere P H, 1998, Rev Laryngol Otol Rhinol (Bord), V119, P259
   Dejonckere PH, 2001, EUR ARCH OTO-RHINO-L, V258, P77, DOI 10.1007/s004050000299
   Doellinger M, 2009, J VOICE, V23, P175, DOI 10.1016/j.jvoice.2007.09.008
   Eysholdt U, 2003, EUR ARCH OTO-RHINO-L, V260, P412, DOI 10.1007/s00405-003-0606-y
   Ferlay J, 2010, INT J CANCER, V127, P2893, DOI 10.1002/ijc.25516
   Fiorella R, 1997, ACTA OTO-LARYNGOL, P77
   Golden D, 2001, ANN OTO RHINOL LARYN, V110, P293, DOI 10.1177/000348940111000401
   HIRANO M, 1974, FOLIA PHONIATR, V26, P89, DOI 10.1159/000263771
   Isenberg JS, 2008, ANN OTO RHINOL LARYN, V117, P74, DOI 10.1177/000348940811700114
   Kraft M, 2011, HEAD NECK-J SCI SPEC, V33, P941, DOI 10.1002/hed.21565
   Krausert CR, 2012, AM J OTOLARYNG, V33, P641, DOI 10.1016/j.amjoto.2012.01.002
   Lohscheller J, 2008, LARYNGOSCOPE, V118, P753, DOI 10.1097/MLG.0b013e318161f9e1
   Lohscheller J, 2008, IEEE T MED IMAGING, V27, P300, DOI 10.1109/TMI.2007.903690
   Lohscheller J, 2007, MED IMAGE ANAL, V11, P400, DOI 10.1016/j.media.2007.04.005
   Mehta DD, 2008, CURR OPIN OTOLARYNGO, V16, P211, DOI 10.1097/MOO.0b013e3282fe96ce
   Neubauer J, 2001, J ACOUST SOC AM, V110, P3179, DOI 10.1121/1.1406498
   Nguyen FT, 2009, CANCER RES, V69, P8790, DOI 10.1158/0008-5472.CAN-08-4340
   Ni XG, 2011, J LARYNGOL OTOL, V125, P288, DOI 10.1017/S0022215110002033
   Olthoff A, 2007, LARYNGOSCOPE, V117, P1123, DOI 10.1097/MLG.0b013e318041f70c
   Peeters AJGE, 2004, EUR ARCH OTO-RHINO-L, V261, P534, DOI 10.1007/s00405-003-0697-5
   Rohde M, 2012, DAN MED J, V59
   Schultz P, 2011, EUR ANN OTORHINOLARY, V128, P301, DOI 10.1016/j.anorl.2011.04.004
   Svec JG, 2007, ANN OTO RHINOL LARYN, V116, P172, DOI 10.1177/000348940711600303
   TANAKA S, 1990, ARCH OTOLARYNGOL, V116, P721
   Unger J, 2014, IEEE T BIO-MED ENG, V61, P2422, DOI 10.1109/TBME.2014.2318774
   Unger J, 2013, IEEE ENG MED BIO, P7360, DOI 10.1109/EMBC.2013.6611258
   VANDENBERG J, 1958, J SPEECH HEAR RES, V1, P227, DOI 10.1044/jshr.0103.227
   Voigt D, 2010, COMPUT METH PROG BIO, V99, P275, DOI 10.1016/j.cmpb.2010.01.004
   Voigt D, 2010, ARTIF INTELL MED, V49, P51, DOI 10.1016/j.artmed.2010.01.001
   Volgger V, 2013, CURR OPIN OTOLARYNGO, V21, P164, DOI 10.1097/MOO.0b013e32835df135
   Wittenberg T, 1995, MACH VISION APPL, V8, P399, DOI 10.1007/BF01213501
   Wurzbacher T, 2008, J ACOUST SOC AM, V123, P2324, DOI 10.1121/1.2835435
   Yan YL, 2005, J VOICE, V19, P161, DOI 10.1016/j.jvoice.2004.04.006
NR 37
TC 31
Z9 34
U1 0
U2 5
PU AMER ASSOC CANCER RESEARCH
PI PHILADELPHIA
PA 615 CHESTNUT ST, 17TH FLOOR, PHILADELPHIA, PA 19106-4404 USA
SN 0008-5472
EI 1538-7445
J9 CANCER RES
JI Cancer Res.
PD JAN 1
PY 2015
VL 75
IS 1
BP 31
EP 39
DI 10.1158/0008-5472.CAN-14-1458
PG 9
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA AY1XN
UT WOS:000347383000006
PM 25371410
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Ben Ismail, MM
   Bchir, O
   Emam, AZ
AF Ben Ismail, Mohamed Maher
   Bchir, Ouiem
   Emam, Ahmed Z.
TI ENDOSCOPY VIDEO SUMMARIZATION BASED ON MULTI-MODAL DESCRIPTORS AND
   POSSIBILISTIC UNSUPERVISED LEARNING AND FEATURE SUBSET WEIGHTING
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Capsule Endoscopy; Video Summarization; Unsupervised Learning; Feature
   Weighting; Possibilistic Approach
ID CAPSULE ENDOSCOPY; FUZZY
AB The spread of capsule endoscopy systems has proved to be inherently constrained by the tedious diagnosis process when the physician has to review thousands of endoscopy video frames in order to detect pathology symptoms. In this paper, we propose a novel endoscopy video summarization approach based on possibilistic clustering and feature weighting algorithm. The algorithm generates possibilistic membership that represents the degree of typicality of the video frames, and that is used to identify and discard noise frames. The robustness to irrelevant features is achieved by learning optimal relevance weight for each feature subset within each cluster. We extend the proposed algorithm to find the optimal number of clusters in an unsupervised and efficient way by exploiting some properties of the possibilistic membership function. The system demonstrated promising performance in extensive testing on real-world datasets associated with the difficult problem of endoscopy video summarization. The endoscopy video collection was acquired on four patients at different geographic locations. It includes more than 90k video frames.
C1 [Ben Ismail, Mohamed Maher; Bchir, Ouiem; Emam, Ahmed Z.] King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 King Saud University
RP Ben Ismail, MM (通讯作者)，King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM mbenismail@KSU.EDU.SA
RI Emam, Ahmed Z/E-6029-2013
OI Emam, ahmed/0000-0003-0662-1097
FU Research Center of College of Computer and Information Sciences, King
   Saud University [RC121258]
FX This work was supported by the Research Center of College of Computer
   and Information Sciences, King Saud University (Project RC121258). The
   authors are grateful for this support.
CR ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547
   [Anonymous], CLUSTER ANAL
   Baopu Li M. Q.-H., 2010, P 2010 IEEE INT C RO
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   BEZDEK JC, 1981, SIAM J APPL MATH, V40, P339, DOI 10.1137/0140029
   Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624
   Chen C., 2000, P 16 IFIP WORLD COMP
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Datta R., 2006, IMAGE RETRIEVAL IDEA
   Dave RN, 1997, IEEE T FUZZY SYST, V5, P270, DOI 10.1109/91.580801
   Frigui H, 2004, PATTERN RECOGN, V37, P567, DOI 10.1016/j.patcog.2003.08.002
   FRIGUI H, 1995, P 1 INT C NEUR PAR S, V1, P163
   Frigui H., 2007, ADV FUZZY CLUSTERING
   Frigui H., 2005, P IEEE C FUZZ SYST, P158
   Frigui H, 2007, PATTERN RECOGN, V40, P3053, DOI 10.1016/j.patcog.2007.02.019
   Gerber J, 2007, GASTROINTEST ENDOSC, V66, P1188, DOI 10.1016/j.gie.2007.06.003
   Guyon, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hampel F.R., 2011, ROBUST STAT APPROACH
   HATHAWAY RJ, 1989, PATTERN RECOGN, V22, P205, DOI 10.1016/0031-3203(89)90066-6
   Iakovidis D. K., 2008, 4 INT IEEE C INT SYS
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   KIRA K, 1992, MACHINE LEARNING /, P249
   Kodogiannis Vassilis S., 2008, WORLD ACAD SCI ENG T, V21, P620
   KRISHNAPURAM R, 1992, IEEE T NEURAL NETWOR, V3, P663, DOI 10.1109/72.159056
   KRISHNAPURAM R, 1992, PATTERN RECOGN, V25, P385, DOI 10.1016/0031-3203(92)90087-Y
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   KRISHNAPURAM R, 1995, IEEE T FUZZY SYST, V3, P29, DOI 10.1109/91.366564
   Mackiewicz M., 2011, NEW TECHNIQUES GASTR
   MacQueen J., 1967, P 5 BERKELEY S MATH, V1, P281
   Maher Ben Ismail M., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P573, DOI 10.1109/ICPR.2010.145
   Manjunath B. S., 2002, INTRO MPEG 7 MULTIME
   McLachlan G, 2000, WILEY SER PROB STAT
   Mewes P. W., 2012, P SPIE MED IMAGING C
   Miaou SG, 2009, J MED BIOL ENG, V29, P114
   Nakamura T, 2008, J GASTROENTEROL, V43, P93, DOI 10.1007/s00535-007-2153-6
   Okun O, 2007, SIGNAL PROCESS, V87, P2260, DOI 10.1016/j.sigpro.2007.02.006
   Raju G, 2008, 2008 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING, P489, DOI 10.1109/ICACTE.2008.199
   Riccioni ME, 2012, WORLD J GASTRO ENDOS, V4, P99, DOI 10.4253/wjge.v4.i4.99
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256
   Yang MS, 2006, PATTERN RECOGN, V39, P5, DOI 10.1016/j.patcog.2005.07.005
   Zeitoun JD, 2007, WORLD J GASTROENTERO, V13, P1451, DOI 10.3748/wjg.v13.i9.1451
   Zhao Qian, 2010, IEEE INT C AUT LOG I
NR 45
TC 0
Z9 0
U1 0
U2 5
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PD SEP
PY 2014
VL 20
IS 3
BP 381
EP 402
DI 10.1080/10798587.2014.890320
PG 22
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA AM8NL
UT WOS:000340132500006
DA 2023-04-20
ER

PT J
AU Hou, JK
   Imler, TD
   Imperiale, TF
AF Hou, Jason K.
   Imler, Timothy D.
   Imperiale, Thomas F.
TI Current and Future Applications of Natural Language Processing in the
   Field of Digestive Diseases
SO CLINICAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE Natural Language Processing; Colonoscopy; Adenoma Detection Rate;
   Inflammatory Bowel Disease; Clinical Decision Support; Performance
   Measures; Quality Improvement
ID ELECTRONIC MEDICAL-RECORDS; COLORECTAL-CANCER; SURVEILLANCE COLONOSCOPY;
   IDENTIFICATION; QUALITY
AB Natural language processing (NLP) is a technology that uses computer-based linguistics and artificial intelligence to identify and extract information from free-text data sources such as progress notes, procedure and pathology reports, and laboratory and radiologic test results. With the creation of large databases and the trajectory of health care reform, NLP holds the promise of enhancing the availability, quality, and utility of clinical information with the goal of improving documentation, quality, and efficiency of health care in the United States. To date, NLP has shown promise in automatically determining appropriate colonoscopy intervals and identifying cases of inflammatory bowel disease from electronic health records. The objectives of this review are to provide background on NLP and its associated terminology, to describe how NLP has been used thus far in the field of digestive diseases, and to identify its potential future uses.
C1 [Hou, Jason K.] Michael E DeBakey VA Med Ctr, Ctr Innovat Qual Effectiveness & Safety, Houston, TX USA.
   [Hou, Jason K.] Baylor Coll Med, Dept Med, Houston, TX 77030 USA.
   [Imler, Timothy D.; Imperiale, Thomas F.] Indiana Univ Sch Med, Div Gastroenterol & Hepatol, Indianapolis, IN 46202 USA.
   [Imler, Timothy D.; Imperiale, Thomas F.] Indiana Univ Sch Med, Dept Med, Indianapolis, IN 46202 USA.
   [Hou, Jason K.] Regenstrief Inst LLC, Dept Biomed Informat, Indianapolis, IN USA.
   [Imperiale, Thomas F.] Richard L Roudebush Vet Affairs Med Ctr, Ctr Innovat Hlth Serv Res & Dev, Indianapolis, IN 46202 USA.
C3 Baylor College of Medicine; Baylor College of Medicine; Indiana
   University System; Indiana University Bloomington; Indiana University
   System; Indiana University Bloomington; US Department of Veterans
   Affairs; Veterans Health Administration (VHA); Richard L. Roudebush VA
   Medical Center
RP Hou, JK (通讯作者)，One Baylor Plaza,BCM 901, Houston, TX 77030 USA.
EM jkhou@bcm.edu
OI Imperiale, Thomas/0000-0001-7586-1073
FU VA Health Services Research & Development Center for Innovations in
   Quality, Effectiveness and Safety, at the Michael E. DeBakey Veterans
   Affairs Medical Center, Houston, TX [CIN 13-413]; American Society for
   Gastrointestinal Endoscopy Covidien Senior Mentoring Award
FX Supported in part with resources at the VA Health Services Research &
   Development Center for Innovations in Quality, Effectiveness and Safety
   (CIN 13-413), at the Michael E. DeBakey Veterans Affairs Medical Center,
   Houston, TX (J.K.H.), and by an American Society for Gastrointestinal
   Endoscopy Covidien Senior Mentoring Award (T.F.I.).
CR Al-Haddad MA, 2010, HPB, V12, P688, DOI 10.1111/j.1477-2574.2010.00235.x
   Allen JI, 2013, CLIN GASTROENTEROL H, V11, P1527, DOI 10.1016/j.cgh.2013.09.011
   Ananthakrishnan AN, 2013, INFLAMM BOWEL DIS, V19, P1411, DOI 10.1097/MIB.0b013e31828133fd
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Denny JC, 2012, MED DECIS MAKING, V32, P188, DOI 10.1177/0272989X11400418
   Denny JC, 2010, J AM MED INFORM ASSN, V17, P383, DOI 10.1136/jamia.2010.004804
   Denny Joshua C, 2009, AMIA Annu Symp Proc, V2009, P141
   Harkema H, 2011, J AM MED INFORM ASSN, V18, pI150, DOI 10.1136/amiajnl-2011-000431
   Hou JK, 2013, DIGEST DIS SCI, V58, P936, DOI 10.1007/s10620-012-2433-8
   HUTCHINS W, 2005, 1 PUBLIC DEMONSTRATI
   IBM Systems and Technology, 2011, WATS SYST DES ANSW
   Imler TD, 2014, CLIN GASTROENTEROL H, V12, P1130, DOI 10.1016/j.cgh.2013.11.025
   Imler TD, 2013, CLIN GASTROENTEROL H, V11, P689, DOI 10.1016/j.cgh.2012.11.035
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Mehrabi S, 2013, STUD HEALTH TECHNOL, V192, P822, DOI 10.3233/978-1-61499-289-9-822
   Mehrotra A, 2012, GASTROINTEST ENDOSC, V75, P1233, DOI 10.1016/j.gie.2012.01.045
   Pohl H, 2014, ANN INTERN MED, V160, P154, DOI 10.7326/M13-0046
   Sada Y, 2013, MED CARE
   Schoen RE, 2010, GASTROENTEROLOGY, V138, P73, DOI 10.1053/j.gastro.2009.09.062
   Vo E, 2013, SURGERY, V154, P411, DOI 10.1016/j.surg.2013.05.022
NR 20
TC 15
Z9 15
U1 1
U2 17
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 1542-3565
EI 1542-7714
J9 CLIN GASTROENTEROL H
JI Clin. Gastroenterol. Hepatol.
PD AUG
PY 2014
VL 12
IS 8
BP 1257
EP 1261
DI 10.1016/j.cgh.2014.05.013
PG 5
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA AO2BG
UT WOS:000341119700010
PM 24858706
DA 2023-04-20
ER

PT J
AU Jovanovic, P
   Salkic, NN
   Zerem, E
AF Jovanovic, Predrag
   Salkic, Nermin N.
   Zerem, Enver
TI Artificial neural network predicts the need for therapeutic ERCP in
   patients with suspected choledocholithiasis
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID BILE-DUCT STONES; ACUTE BILIARY PANCREATITIS; LAPAROSCOPIC
   CHOLECYSTECTOMY; SCORING SYSTEM; GASTROINTESTINAL HEMORRHAGE; DIAGNOSIS;
   METAANALYSIS; VALIDATION; MANAGEMENT; FIBROSIS
AB Background: Selection of patients with the highest probability for therapeutic ERCP remains an important task in a clinical workup of patients with suspected choledocholithiasis (CDL).
   Objective: To determine whether an artificial neural network (ANN) model can improve the accuracy of selecting patients with a high probability of undergoing therapeutic ERCP among those with strong clinical suspicion of CDL and to compare it with our previously reported prediction model.
   Design: Prospective, observational study.
   Setting: Single, tertiary-care endoscopy center.
   Patients: Between January 2010 and September 2012, we prospectively recruited 291 consecutive patients who underwent ERCP after being referred to our center with firm suspicion for CDL.
   Interventions: Predictive scores for CDL based on a multivariate logistic regression model and ANN model.
   Main Outcome Measurements: The presence of common bile duct stones confirmed by ERCP.
   Results: There were 80.4% of patients with positive findings on ERCP. The area under the receiver-operating characteristic curve for our previously established multivariate logistic regression model was 0.787 (95% CI, 0.720-0.854; P < .001), whereas area under the curve for the ANN model was 0.884 (95% CI, 0.831-0.938; P < .001). The ANN model correctly classified 92.3% of patients with positive findings on ERCP and 69.6% patients with negative findings on ERCP.
   Limitations: Only those variables believed to be related to the outcome of interest were included. The majority of patients in our sample had positive findings on ERCP.
   Conclusions: An ANN model has better discriminant ability and accuracy than a multivariate logistic regression model in selecting patients for therapeutic ERCP.
C1 [Jovanovic, Predrag; Salkic, Nermin N.; Zerem, Enver] Univ Clin Ctr Tuzla, Dept Gastroenterol, Tuzla 75000, Bosnia & Herceg.
C3 University of Tuzla
RP Jovanovic, P (通讯作者)，Univ Clin Ctr Tuzla, Dept Gastroenterol, Trinova Bb, Tuzla 75000, Bosnia & Herceg.
EM prredo@yahoo.com
RI Salkic, Nermin N./A-1167-2009
OI Salkic, Nermin N./0000-0003-4727-9267
CR Abboud PAC, 1996, GASTROINTEST ENDOSC, V44, P450, DOI 10.1016/S0016-5107(96)70098-6
   Alponat A, 1997, SURG ENDOSC, V11, P928, DOI 10.1007/s004649900489
   Amato F, 2013, J APPL BIOMED, V11, P47, DOI 10.2478/v10136-012-0031-x
   Ansari D, 2013, AM J SURG, V205, P1, DOI 10.1016/j.amjsurg.2012.05.032
   BARKUN AN, 1994, ANN SURG, V220, P32, DOI 10.1097/00000658-199407000-00006
   Bates A., 2004, ABDOMINAL ULTRASOUND
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   BAXT WG, 1991, ANN INTERN MED, V115, P843, DOI 10.7326/0003-4819-115-11-843
   Bose SM, 2001, SURG TODAY, V31, P117, DOI 10.1007/s005950170194
   Brause R.W., 2001, MED ANAL DIAGNOSIS N, P1
   Broder JC., 2012, APPL RADIOL, V41, P9
   Burke HB, 1997, CANCER, V79, P857, DOI 10.1002/(SICI)1097-0142(19970215)79:4<857::AID-CNCR24>3.0.CO;2-Y
   Cucchetti A, 2007, GUT, V56, P253, DOI 10.1136/gut.2005.084434
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Das A, 2008, GASTROENTEROLOGY, V134, P65, DOI 10.1053/j.gastro.2007.10.037
   Girard MLG, 1990, SURG LIVER BILIARY T, P577
   Golub R, 1998, J AM COLL SURGEONS, V187, P584, DOI 10.1016/S1072-7515(98)00241-5
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   HOUDART R, 1995, AM J SURG, V170, P38, DOI 10.1016/S0002-9610(99)80249-9
   Jovanovic P, 2011, EUR J INTERN MED, V22, pE110, DOI 10.1016/j.ejim.2011.02.008
   Kato H, 2007, AM J ROENTGENOL, V189, P117, DOI 10.2214/AJR.07.2070
   Lee S., 1999, TXB GASTROENTEROLOGY, P2266
   Logeswaran R, 2006, MED BIOL ENG COMPUT, V44, P711, DOI 10.1007/s11517-006-0083-8
   Maple JT, 2010, GASTROINTEST ENDOSC, V71, P1, DOI 10.1016/j.gie.2009.09.041
   Menezes N, 2000, BRIT J SURG, V87, P1176, DOI 10.1046/j.1365-2168.2000.01511.x
   Mofidi R, 2007, SURGERY, V141, P59, DOI 10.1016/j.surg.2006.07.022
   Petrov MS, 2008, ANN SURG, V247, P250, DOI 10.1097/SLA.0b013e31815edddd
   Piscaglia F, 2006, EUR J GASTROEN HEPAT, V18, P1255, DOI 10.1097/01.meg.0000243885.55562.7e
   Prat F, 1999, ANN SURG, V229, P362, DOI 10.1097/00000658-199903000-00009
   RIEGER R, 1995, GASTROINTEST ENDOSC, V42, P6, DOI 10.1016/S0016-5107(95)70235-0
   Rojas R., 1996, NEURAL NETWORKS SYST, P151, DOI [10.1007/978-3-642-61068-4, DOI 10.1007/978-3-642-61068-4]
   Sargent DJ, 2001, CANCER-AM CANCER SOC, V91, P1636, DOI 10.1002/1097-0142(20010415)91:8+<1636::AID-CNCR1176>3.0.CO;2-D
   Sarli L, 2003, SURG ENDOSC, V17, P1396, DOI 10.1007/s00464-002-9200-4
   SELKER HP, 1995, J INVEST MED, V43, P468
   Sun XD, 2003, WORLD J GASTROENTERO, V9, P865, DOI 10.3748/wjg.v9.i4.865
   Tenner S, 2013, AM J GASTROENTEROL, V108, P1400, DOI 10.1038/ajg.2013.218
   TRONDSEN E, 1995, WORLD J SURG, V19, P852
   Trondsen E, 1995, WORLD J SURG, V19, P7
   Tu JV, 1996, J CLIN EPIDEMIOL, V49, P1225, DOI 10.1016/S0895-4356(96)00002-9
   Urquhart P, 2011, GASTROINTEST ENDOSC, V74, P378, DOI 10.1016/j.gie.2011.03.1256
   VOYLES CR, 1994, ANN SURG, V219, P744
   Voyles CR, 1994, ANN SURG, V219, P50
   Yoldas O, 2008, PANCREAS, V36, P90, DOI 10.1097/MPA.0b013e31812e964b
NR 43
TC 26
Z9 27
U1 0
U2 8
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD AUG
PY 2014
VL 80
IS 2
BP 260
EP 268
DI 10.1016/j.gie.2014.01.023
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA AO2KX
UT WOS:000341151700008
PM 24593947
DA 2023-04-20
ER

PT J
AU Fu, JJC
   Yu, YW
   Lin, HM
   Chai, JW
   Chen, CCC
AF Fu, Jachih J. C.
   Yu, Ya-Wen
   Lin, Hong-Mau
   Chai, Jyh-Wen
   Chen, Clayton Chi-Chang
TI Feature extraction and pattern classification of colorectal polyps in
   colonoscopic imaging
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Article
DE Computer-aided diagnosis; Colorectal polyps classification; Feature
   extraction; Support vector machines
ID PRINCIPAL COMPONENT ANALYSIS; FEATURE-SELECTION; CT COLONOGRAPHY; 2ND
   READER; DIAGNOSIS; ATHEROSCLEROSIS; QUALITY; IMAGES; SYSTEM
AB A computer-aided diagnostic system for colonoscopic imaging has been developed to classify colorectal polyps by type. The modules of the proposed system include image enhancement, feature extraction, feature selection and polyp classification. Three hundred sixty-five images (214 with hyperplastic polyps and 151 with adenomatous polyps) were collected from a branch of a medical center in central Taiwan. The raw images were enhanced by the principal component transform (PCT). The features of texture analysis, spatial domain and spectral domain were extracted from the first component of the PCT. Sequential forward selection (SFS) and sequential floating forward selection (SFFS) were used to select the input feature vectors for classification. Support vector machines (SVMs) were employed to classify the colorectal polyps by type. The classification performance was measured by the Az values of the Receiver Operating Characteristic curve. For all 180 features used as input vectors, the test data set yielded Az values of 88.7%. The Az value was increased by 2.6% (from 88.7% to 91.3%) and 4.4% (from 88.7% to 93.1%) for the features selected by the SFS and the SFFS, respectively. The SFS and the SFFS reduced the dimension of the input vector by 57.2% and 73.8%, respectively. The SFFS outperformed the SFS in both the reduction of the dimension of the feature vector and the classification performance. When the colonoscopic images were visually inspected by experienced physicians, the accuracy of detecting polyps by types was around 85%. The accuracy of the SFFS with the SVM classifier reached 96%. The classification performance of the proposed system outperformed the conventional visual inspection approach. Therefore, the proposed computer-aided system could be used to improve the quality of colorectal polyp diagnosis. (C) 2014 Published by Elsevier Ltd.
C1 [Fu, Jachih J. C.; Yu, Ya-Wen] Natl Yunlin Univ Sci & Technol, Dept Ind Engn & Management, Comp Aided Measurement & Diagnost Syst Lab, Douliu City 64002, Yunlin County, Taiwan.
   [Lin, Hong-Mau] Natl Taiwan Univ Hosp, Yun Lin Branch, Dept Colorectal Surg, Douliu City 64002, Yunlin County, Taiwan.
   [Chai, Jyh-Wen; Chen, Clayton Chi-Chang] Taichung Vet Gen Hosp, Dept Radiol, Taichung, Taiwan.
   [Chai, Jyh-Wen] China Med Univ, Coll Med, Taichung, Taiwan.
   [Chai, Jyh-Wen; Chen, Clayton Chi-Chang] Hung Kuang Univ, Dept Biomed Engn, Taichung, Taiwan.
   [Chen, Clayton Chi-Chang] Cent Taiwan Univ Sci & Technol, Dept Radiol Technol, Taichung, Taiwan.
   [Chen, Clayton Chi-Chang] Cent Taiwan Univ Sci & Technol, Grad Inst Radiol Sci, Taichung, Taiwan.
C3 National Yunlin University Science & Technology; National Taiwan
   University; National Taiwan University Hospital; Taichung Veterans
   General Hospital; China Medical University Taiwan; Hungkuang University;
   Central Taiwan University Science & Technology; Central Taiwan
   University Science & Technology
RP Yu, YW (通讯作者)，Natl Yunlin Univ Sci & Technol, Dept Ind Engn & Management, Comp Aided Measurement & Diagnost Syst Lab, 123,Sec 3,Univ Rd, Douliu City 64002, Yunlin County, Taiwan.
EM g9821802@yuntech.edu.tw
FU Taiwan's National Science Council [NSC 101-2221-E-224-029,
   102-2221-E-224-068]
FX This research was performed under the auspices of Taiwan's National
   Science Council (NSC 101-2221-E-224-029 and 102-2221-E-224-068).
CR Bert A, 2009, COMPUT MED IMAG GRAP, V33, P325, DOI 10.1016/j.compmedimag.2009.02.004
   Changchien CR, 2012, J ONCOL SOC, V24, P143
   Chowdhury TA, 2006, COMPUT MED IMAG GRAP, V30, P427, DOI 10.1016/j.compmedimag.2006.06.004
   Frohlich H, 2003, PROC INT C TOOLS ART, P142, DOI 10.1109/TAI.2003.1250182
   Fu JC, 2012, J IND PROD ENG, V29, P87, DOI 10.1080/10170669.2012.659220
   Fu JC, 2005, COMPUT MED IMAG GRAP, V29, P419, DOI 10.1016/j.compmedimag.2005.03.002
   FUNG T, 1987, PHOTOGRAMM ENG REM S, V53, P1649
   Han SM, 2008, J DIGIT IMAGING, V21, pS121, DOI 10.1007/s10278-008-9106-3
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Horng MH, 2009, EXPERT SYST APPL, V36, P8124, DOI 10.1016/j.eswa.2008.10.030
   Hung SY, 2006, EXPERT SYST APPL, V30, P93, DOI 10.1016/j.eswa.2005.09.067
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jianhua Yao, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P21
   Kara S, 2007, EXPERT SYST APPL, V32, P632, DOI 10.1016/j.eswa.2006.01.043
   Kim D, 2011, CHEM ENG SCI, V66, P6264, DOI 10.1016/j.ces.2011.09.004
   Kogermann K, 2011, EUR J PHARM SCI, V43, P278, DOI 10.1016/j.ejps.2011.05.001
   Latifoglu F, 2007, EXPERT SYST APPL, V33, P786, DOI 10.1016/j.eswa.2006.05.034
   Levin B, 2003, CA-CANCER J CLIN, V53, P44, DOI 10.3322/canjclin.53.1.44
   Liu BH, 2007, BIOCHEM BIOPH RES CO, V358, P136, DOI 10.1016/j.bbrc.2007.04.097
   Lo CS, 2012, COMPUT MATH APPL, V64, P1153, DOI 10.1016/j.camwa.2012.03.033
   Martinez ME, 2001, GASTROENTEROLOGY, V120, P1077, DOI 10.1053/gast.2001.23247
   Mehmed Kantardzic, 2003, DATA MINING CONCEPTS
   Neri E, 2011, EUR J RADIOL, V80, P303, DOI 10.1016/j.ejrad.2010.07.014
   Petrick N, 2008, RADIOLOGY, V246, P148, DOI 10.1148/radiol.2453062161
   Petrou M., 2000, IMAGE PROCESSING FUN
   RANSOHOFF DF, 1991, NEW ENGL J MED, V325, P37
   Razifar P, 2006, NEUROIMAGE, V33, P588, DOI 10.1016/j.neuroimage.2006.05.060
   Reneker J, 2006, J AM MED INFORM ASSN, V26, P51
   Shan J, 2012, ULTRASOUND MED BIOL, V38, P262, DOI 10.1016/j.ultrasmedbio.2011.10.022
   Tsai CY, 2008, PATTERN RECOGN LETT, V29, P616, DOI 10.1016/j.patrec.2007.11.013
   Yu SY, 2000, IEEE T MED IMAGING, V19, P115, DOI 10.1109/42.836371
   Zhang XJ, 2005, P ANN INT IEEE EMBS, P867
NR 32
TC 25
Z9 26
U1 0
U2 18
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD JUN
PY 2014
VL 38
IS 4
BP 267
EP 275
DI 10.1016/j.compmedimag.2013.12.009
PG 9
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA AI2TX
UT WOS:000336712100004
PM 24495469
DA 2023-04-20
ER

PT J
AU Sakai, P
   Faintuch, J
AF Sakai, Paulo
   Faintuch, Joel
TI Evolving endoscopic surgery
SO JOURNAL OF GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE endoscopic bariatric surgery; endoscopic cholangiopancreatography;
   endoscopic gastric plication; endoscopic gastrostomy; endoscopic
   resection; natural orifice surgery
ID SUBMUCOSAL DISSECTION; SLEEVE GASTRECTOMY; NECROSECTOMY; DRAINAGE;
   MYOTOMY; TRIAL
AB Since the days of Albukasim in medieval Spain, natural orifices have been regarded not only as a rather repugnant source of bodily odors, fluids and excreta, but also as a convenient invitation to explore and treat the inner passages of the organism. However, surgical ingenuity needed to be matched by appropriate tools and devices. Lack of technologically advanced instrumentation was a strong deterrent during almost a millennium until recent decades when a quantum jump materialized. Endoscopic surgery is currently a vibrant and growing subspecialty, which successfully handles millions of patients every year. Additional opportunities lie ahead which might benefit millions more, however, requiring even more sophisticated apparatuses, particularly in the field of robotics, artificial intelligence, and tissue repair (surgical suturing). This is a particularly exciting and worthwhile challenge, namely of larger and safer endoscopic interventions, followed by seamless and scarless recovery. In synthesis, the future is widely open for those who use together intelligence and creativity to develop new prototypes, new accessories and new techniques. Yet there are many challenges in the path of endoscopic surgery. In this new era of robotic endoscopy, one will likely need a virtual simulator to train and assess the performance of younger doctors. More evidence will be essential in multiple evolving fields, particularly to elucidate whether more ambitious and complex pathways, such as intrathoracic and intraperitoneal surgery via natural orifice transluminal endoscopic surgery (NOTES), are superior or not to conventional techniques.
C1 [Sakai, Paulo] Univ Sao Paulo, Sch Med, Gastrointestinal Endoscopy Div, BR-05403900 Sao Paulo, Brazil.
   [Faintuch, Joel] Univ Sao Paulo, Sch Med, BR-05403900 Sao Paulo, Brazil.
C3 Universidade de Sao Paulo; Universidade de Sao Paulo
RP Sakai, P (通讯作者)，Univ Sao Paulo, Sch Med, Gastrointestinal Endoscopy Div, BR-05403900 Sao Paulo, Brazil.
EM paulosakai@terra.com.br
CR Abu Dayyeh BK, 2013, GASTROINTEST ENDOSC, V78, P530, DOI 10.1016/j.gie.2013.04.197
   Artifon E L, 2013, GASTROINTEST ENDOSC, V77, pAB126
   Bakker OJ, 2012, JAMA-J AM MED ASSOC, V307, P1053, DOI 10.1001/jama.2012.276
   Cauche N, 2013, GASTROINTEST ENDOSC, V77, pAB204
   Chandrasegaram MD, 2012, SURG ENDOSC, V26, P323, DOI 10.1007/s00464-011-1870-3
   Cherian PT, 2010, SURG ENDOSC, V24, P2031, DOI 10.1007/s00464-010-0899-z
   Cordova H, 2013, GASTROINTEST ENDOSC, V77, P102, DOI 10.1016/j.gie.2012.09.008
   Decker A., 1944, AM J SURG, V64, P40, DOI 10.1016/S0002-9610(44)90478-2
   Deyhle P, 1973, ENDOSCOPY, V3, P143
   Dormann AJ, 2006, AM J GASTROENTEROL, V101, P1229, DOI 10.1111/j.1572-0241.2006.00541.x
   Eibach U, 2002, MED KLIN, V97, P558, DOI 10.1007/s00063-002-1196-y
   Endo S, 2014, J SURG ONCOL, V109, P208, DOI 10.1002/jso.23486
   Frattini Francesco, 2013, Surg Technol Int, V23, P84
   Fuchs KH, 2013, SURG ENDOSC, V27, P1456, DOI 10.1007/s00464-013-2870-2
   Garrison Fielding H., 1917, INTRO HIST MED
   Gotoda T, 2007, GASTRIC CANCER, V10, P1, DOI 10.1007/s10120-006-0408-1
   HIRSCHOWITZ B, 1961, LANCET, V1, P1074
   Horgan S, 2013, SURG ENDOSC, V27, P1872, DOI 10.1007/s00464-012-2736-z
   Iacopini F, 2013, GASTROINTEST ENDOSC, V77, pAB 350
   Inoue H, 2010, ENDOSCOPY, V42, P265, DOI 10.1055/s-0029-1244080
   Itoi T, 2012, GASTROINTEST ENDOSC, V75, P870, DOI 10.1016/j.gie.2011.10.020
   Jailwala J, 2000, CURR GASTROENTEROL R, V3, P188
   Jeurnink SM, 2010, GASTROINTEST ENDOSC, V71, P490, DOI 10.1016/j.gie.2009.09.042
   Kalloo AN, 2004, GASTROINTEST ENDOSC, V60, P114, DOI 10.1016/S0016-5107(04)01309-4
   Kantsevoy S, 2013, GASTROINTEST ENDOSC, V77, pAB146
   Moreira-Pinto J, 2012, ENDOSCOPY, V44, P354, DOI 10.1055/s-0031-1291594
   Noguera JF, 2012, SURG ENDOSC, V26, P3435, DOI 10.1007/s00464-012-2359-4
   Oka S, 2006, GASTROINTEST ENDOSC, V64, P877, DOI 10.1016/j.gie.2006.03.932
   Pasricha PJ, 2007, ENDOSCOPY, V39, P761, DOI 10.1055/s-2007-966764
   Phee SJ, 2012, CLIN GASTROENTEROL H, V10, P1117, DOI 10.1016/j.cgh.2012.05.019
   Ramos AC, 2008, SURG OBES RELAT DIS, V4, P660, DOI 10.1016/j.soard.2008.06.009
   Rische S, 2013, SCAND J GASTROENTERO, V48, P231, DOI 10.3109/00365521.2012.752029
   Rothstein Richard I, 2003, Gastrointest Endosc Clin N Am, V13, P89, DOI 10.1016/S1052-5157(02)00107-1
   Shiwaku H, 2013, GASTROINTEST ENDOSC, V77, P149, DOI 10.1016/j.gie.2012.02.008
   Souttar HS, 1924, BMJ-BRIT MED J, V1924, P782, DOI 10.1136/bmj.1.3305.782
   Spitali C, 2013, CASE REP SURG, V2013, DOI 10.1155/2013/852747
   Steele RJC, 2012, ENDOSCOPY, V44, pSE140, DOI 10.1055/s-0032-1309802
   Swidnicka-Siergiejko A, 2011, CAN J GASTROENTEROL, V25, P627, DOI 10.1155/2011/174163
   Tada M, 1989, STOMACH INTESTINE, V23, P373
   Tsesmeli N, 2009, ENDOSCOPY, V41, P1082, DOI 10.1055/s-0029-1215269
   Verdam FJ, 2012, J OBES, V2012, DOI 10.1155/2012/597871
   Villela EL, 2014, CLIN NUTR, V33, P221, DOI 10.1016/j.clnu.2013.04.015
   Wang X Y, 2013, GASTROINTEST ENDOSC, V77, pAB190
   WOLFF WI, 1973, ANN SURG, V178, P367, DOI 10.1097/00000658-197309000-00017
   Xu M-D, 2013, GASTROINTEST ENDOSC, V77, pAB194
NR 45
TC 2
Z9 3
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0815-9319
EI 1440-1746
J9 J GASTROEN HEPATOL
JI J. Gastroenterol. Hepatol.
PD JUN
PY 2014
VL 29
IS 6
BP 1132
EP 1138
DI 10.1111/jgh.12577
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA AH2TF
UT WOS:000335973300006
PM 24628672
DA 2023-04-20
ER

PT J
AU Sainju, S
   Bui, FM
   Wahid, KA
AF Sainju, Sonu
   Bui, Francis M.
   Wahid, Khan A.
TI Automated Bleeding Detection in Capsule Endoscopy Videos Using
   Statistical Features and Region Growing
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Wireless capsule endoscopy; Automated detection; Neural network; Image
   segmentation; Feature selection
ID IMAGE SEGMENTATION
AB Wireless Capsule Endoscopy (WCE) is a technology in the field of endoscopic imaging which facilitates direct visualization of the entire small intestine. Many algorithms are being developed to automatically identify clinically important frames in WCE videos. This paper presents a supervised method for automated detection of bleeding regions present in WCE frames or images. The proposed method characterizes the image regions by using statistical features derived from the first order histogram probability of the three planes of RGB color space. Despite being inconsistent and tiresome, manual selection of regions has been a popular technique for creating training data in the studies of capsule endoscopic images. We propose a semi-automatic region-annotation algorithm for creating training data efficiently. All possible combinations of different features are exhaustively analyzed to find the optimum feature set with the best performance. During operation, regions from images are obtained by applying a segmentation method. Finally, a trained neural network recognizes the patterns of the data arising from bleeding and non-bleeding regions.
C1 [Sainju, Sonu; Bui, Francis M.; Wahid, Khan A.] Univ Saskatchewan, Saskatoon, SK, Canada.
C3 University of Saskatchewan
RP Wahid, KA (通讯作者)，Univ Saskatchewan, Saskatoon, SK, Canada.
EM khan.wahid@usask.ca
OI Bui, Francis/0000-0002-8799-5965
FU Grand Challenges Canada (GCC) Star in Global Health; Natural Science and
   Engineering Research Council of Canada (NSERC)
FX This work was supported by Grand Challenges Canada (GCC) Star in Global
   Health and Natural Science and Engineering Research Council of Canada
   (NSERC). The authors would like to acknowledge Canada Foundation for
   Innovation (CFI) for providing the lab infrastructure and development
   tools.
CR Banu M.S., 2010, 2010 IEEE INT C COMP, P1
   Bishop C. M., 2006, PATTERN RECOGN, P227
   Buscaglia JM, 2008, CLIN GASTROENTEROL H, V6, P298, DOI 10.1016/j.cgh.2007.12.029
   Faigel DO, 2008, CAPSULE ENDOSCOPY
   Fu Y., 2011, ADV MATER RES-SWITZ, P1
   Hussain H, 2000, GASTROENTEROL CLIN N, V29, P445, DOI 10.1016/S0889-8553(05)70122-9
   Hwang S., 2006, P SOC PHOTO-OPT INS
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Ikonomakis N, 2000, J INTELL ROBOT SYST, V28, P5, DOI 10.1023/A:1008163913937
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Katz L B, 1999, Semin Gastrointest Dis, V10, P78
   Lee YG., 2011, WORLD ACAD SCI ENG T, V59, P2526
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Lucchese L., 1999, ALGORITHM FAST SEGME, P110
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Qureshi WA, 2004, NAT REV DRUG DISCOV, V3, P447, DOI 10.1038/nrd1385
   Sainju S, 2013, CAN CON EL COMP EN, P539
   Sergyan S, 2008, 2008 6TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS, P206
   Sun K, 2012, LECT NOTES COMPUT SC, V7202, P167, DOI 10.1007/978-3-642-31919-8_22
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P261, DOI 10.1016/B978-1-59749-272-0.50007-4
   Triester SL, 2005, AM J GASTROENTEROL, V100, P2407, DOI 10.1111/j.1572-0241.2005.00274.x
   TSENG DC, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P228, DOI 10.1109/ICPR.1992.201967
   Umbaugh SE, 1997, IEEE ENG MED BIOL, V16, P62, DOI 10.1109/51.603650
   Watt E, 2010, MEDICAL IMAGING INFORMATICS, P403, DOI 10.1007/978-1-4419-0385-3_10
NR 26
TC 77
Z9 79
U1 0
U2 19
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD APR
PY 2014
VL 38
IS 4
AR 25
DI 10.1007/s10916-014-0025-1
PG 11
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA AF1WB
UT WOS:000334503500011
PM 24696394
DA 2023-04-20
ER

PT J
AU Wyse, JM
   Chen, YI
   Sahai, V
AF Wyse, Jonathan M.
   Chen, Yen-I
   Sahai, V.
TI Celiac plexus neurolysis in the management of unresectable pancreatic
   cancer: When and how?
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Celiac plexus neurolysis; Endoscopic ultrasound; Pancreatic cancer;
   Pain; Opioid; Gastrointestinal endoscopy
ID SPINAL-CORD INFARCTION; QUALITY-OF-LIFE; ENDOSCOPIC ULTRASOUND; GANGLIA
   NEUROLYSIS; PAIN RELIEF; DOUBLE-BLIND; BLOCK; TRIAL; VISUALIZATION;
   TOMOGRAPHY
AB Pancreatic cancer is the second most common abdominal cancer in North America with an estimated 20% resectability at diagnosis, and overall 5-year survival of 5%. Pain is common in pancreatic cancer patients with 70%-80% suffering substantial pain. Celiac plexus neurolysis (CPN) is a technique that can potentially improve pain control in pancreatic cancer while preventing further escalation of opioid consumption. CPN is performed by injecting absolute alcohol into the celiac plexus neural network of ganglia. This review sets out to explore the current status of CPN in non-resectable pancreatic cancer. We will examine: (1) the efficacy and safety of percutaneous-CPN and endoscopic ultrasound guided-CPN; (2) specific technique modifications including bilateral (vs central) injections and celiac ganglia neurolysis; and (3) the issue of CPN timing, early at pancreatic cancer diagnosis vs traditional late use as salvage therapy. (C) 2014 Baishideng Publishing Group Co., Limited. All rights reserved.
C1 [Wyse, Jonathan M.] McGill Univ, Jewish Gen Hosp, Div Gastroenterol, Montreal, PQ H3T 1E2, Canada.
   [Chen, Yen-I] McGill Univ, Ctr Hlth, Montreal, PQ H3A 1A1, Canada.
   [Sahai, V.] Ctr Hosp Univ Montreal, Hop St Luc, Div Gastroenterol, Montreal, PQ H2X 1P1, Canada.
C3 McGill University; McGill University; Universite de Montreal
RP Wyse, JM (通讯作者)，McGill Univ, Jewish Gen Hosp, Div Gastroenterol, 3755 Chemin Cote Ste Catherine, Montreal, PQ H3T 1E2, Canada.
EM jonathan.wyse@mcgill.ca
CR [Anonymous], 2013, CANC FACTS FIG 2013
   Ascunce G, 2011, GASTROINTEST ENDOSC, V73, P267, DOI 10.1016/j.gie.2010.10.029
   Bilimoria KY, 2007, CANCER-AM CANCER SOC, V110, P738, DOI 10.1002/cncr.22852
   Collins D, 2006, ENDOSCOPY, V38, P935, DOI 10.1055/s-2006-944734
   DAVIES DD, 1993, J ROY SOC MED, V86, P264
   de Oliveira R, 2004, PAIN, V110, P400, DOI 10.1016/j.pain.2004.04.023
   Doi S, 2013, ENDOSCOPY, V45, P362, DOI 10.1055/s-0032-1326225
   EISENBERG E, 1995, ANESTH ANALG, V80, P290, DOI 10.1097/00000539-199502000-00015
   Fujii L, 2012, ENDOSCOPY, V44, pE265, DOI 10.1055/s-0032-1309708
   Gimeno-Garcia AZ, 2012, ENDOSCOPY, V44, pE267, DOI 10.1055/s-0032-1309709
   Gleeson FC, 2007, ENDOSCOPY, V39, P620, DOI 10.1055/s-2007-966337
   Gress F, 1999, AM J GASTROENTEROL, V94, P900
   Gunaratnam NT, 2001, GASTROINTEST ENDOSC, V54, P316, DOI 10.1067/mge.2001.117515
   Ha Tae-In, 2008, Korean Journal of Internal Medicine, V23, P5, DOI 10.3904/kjim.2008.23.1.5
   Harada N, 1997, Gastrointest Endosc Clin N Am, V7, P237
   Iwata K, 2011, DIGEST ENDOSC, V23, P140, DOI 10.1111/j.1443-1661.2010.01046.x
   Jain PN, 2005, J PAIN PALLIAT CARE, V19, P15, DOI 10.1300/J354v19n03_04
   Jang HY, 2013, CLIN ENDOSC, V46, P306, DOI 10.5946/ce.2013.46.3.306
   Jemal A, 2008, CA-CANCER J CLIN, V58, P71, DOI 10.3322/CA.2007.0010
   Kawamata M, 1996, PAIN, V64, P597, DOI 10.1016/0304-3959(95)00189-1
   LeBlanc JK, 2011, GASTROINTEST ENDOSC, V74, P1300, DOI 10.1016/j.gie.2011.07.073
   LEBOVITS AH, 1989, PAIN, V36, P1, DOI 10.1016/0304-3959(89)90106-1
   Levy MJ, 2008, AM J GASTROENTEROL, V103, P98, DOI 10.1111/j.1572-0241.2007.01607.x
   Levy Michael J, 2012, Gastrointest Endosc Clin N Am, V22, P231, DOI 10.1016/j.giec.2012.04.003
   LILLEMOE KD, 1993, ANN SURG, V217, P447, DOI 10.1097/00000658-199305010-00004
   Loeve US, 2013, GASTROINTEST ENDOSC, V77, P151, DOI 10.1016/j.gie.2012.03.005
   MERCADANTE S, 1993, PAIN, V52, P187, DOI 10.1016/0304-3959(93)90130-H
   Michaels AJ, 2007, WORLD J GASTROENTERO, V13, P3575, DOI 10.3748/wjg.v13.i26.3575
   Mittal MK, 2012, NEUROLOGY, V78, pE57, DOI 10.1212/WNL.0b013e318248df51
   Nagels W, 2013, PAIN MED, V14, P1140, DOI 10.1111/pme.12176
   Polati E, 1998, BRIT J SURG, V85, P199
   Puli SR, 2009, DIGEST DIS SCI, V54, P2330, DOI 10.1007/s10620-008-0651-x
   Sahai AV, 2009, AM J GASTROENTEROL, V104, P326, DOI 10.1038/ajg.2008.64
   Sakamoto H, 2006, DIGEST ENDOSC, V18, P206, DOI DOI 10.1111/J.0915-5635.2006.00611.X
   Sakamoto H, 2010, AM J GASTROENTEROL, V105, P2599, DOI 10.1038/ajg.2010.339
   Santosh D, 2009, ALIMENT PHARM THER, V29, P979, DOI 10.1111/j.1365-2036.2009.03963.x
   Schmulewitz N, 2003, ENDOSCOPY, V35, pS49
   SHARFMAN WH, 1990, PAIN, V41, P267, DOI 10.1016/0304-3959(90)90003-V
   Wiersema MJ, 1996, GASTROINTEST ENDOSC, V44, P656, DOI 10.1016/S0016-5107(96)70047-0
   Wiersema MJ, 2001, REGION ANESTH PAIN M, V26, P159, DOI 10.1053/rapm.2001.20450
   Wong GY, 2004, JAMA-J AM MED ASSOC, V291, P1092, DOI 10.1001/jama.291.9.1092
   Wyse JM, 2011, J CLIN ONCOL, V29, P3541, DOI 10.1200/JCO.2010.32.2750
   Yan BM, 2007, AM J GASTROENTEROL, V102, P430, DOI 10.1111/j.1572-0241.2006.00967.x
   Zhang CL, 2008, DIGEST DIS SCI, V53, P856, DOI 10.1007/s10620-007-9905-2
NR 44
TC 33
Z9 38
U1 0
U2 3
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 8226 REGENCY DR, PLEASANTON, CA 94588 USA
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD MAR 7
PY 2014
VL 20
IS 9
BP 2186
EP 2192
DI 10.3748/wjg.v20.i9.2186
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA AC7FE
UT WOS:000332692300007
PM 24605017
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Fu, YA
   Zhang, W
   Mandal, M
   Meng, MQH
AF Fu, Yanan
   Zhang, Wei
   Mandal, Mrinal
   Meng, Max Q. -H.
TI Computer-Aided Bleeding Detection in WCE Video
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Bleeding detection; superpixel; wireless capsule endoscopy (WCE)
ID WIRELESS CAPSULE ENDOSCOPY
AB Wireless capsule endoscopy (WCE) can directly take digital images in the gastrointestinal tract of a patient. It has opened a new chapter in small intestine examination. However, a major problem associated with this technology is that too many images need to be manually examined by clinicians. Currently, there is no standard for capsule endoscopy image interpretation and classification. Most state-of-the-art CAD methods often suffer from poor performance, high computational cost, or multiple empirical thresholds. In this paper, a new method for rapid bleeding detection in theWCE video is proposed. We group pixels through superpixel segmentation to reduce the computational complexity while maintaining high diagnostic accuracy. Feature of each superpixel is extracted using the red ratio in RGB space and fed into support vector machine for classification. Also, the influence of edge pixels has been removed in this paper. Comparative experiments show that our algorithm is superior to the existing methods in terms of sensitivity, specificity, and accuracy.
C1 [Fu, Yanan; Zhang, Wei] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
   [Mandal, Mrinal] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
   [Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Shandong University; University of Alberta; Chinese University of Hong
   Kong
RP Fu, YA (通讯作者)，Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
EM fyasdu@gmail.com; davidzhang@sdu.edu.cn; mmandal@ualberta.ca;
   max@ee.cuhk.edu.hk
RI Meng, Q./GSI-6185-2022; meng, meng/GWZ-7461-2022; Meng, Max
   Q.-H./C-8078-2009
FU National Science Foundation of China (NSFC) [61203253]
FX Manuscript received September 2, 2012; revised November 26, 2012 and
   February 28, 2013; accepted March 11, 2013. Date of publication April
   12, 2013; date of current version March 3, 2014. This work was supported
   by the National Science Foundation of China (NSFC) under Grant 61203253.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Al-Rahayfeh A. A., 2010, INT J MULTIMEDIA APP, V2, P1
   Ali A, 2004, CLEV CLIN J MED, V71, P415, DOI 10.3949/ccjm.71.5.415
   Berens J, 2000, IEE P-VIS IMAGE SIGN, V147, P349, DOI 10.1049/ip-vis:20000630
   Boulougoura M., 2004, P 2 IASTED INT C BIO
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Fu Y., 2011, ADV MATER RES-SWITZ, P1
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Gonzales RC., 2002, DIGITAL IMAGE PROCES
   Hwang S., 2006, P SOC PHOTO-OPT INS, V6144, P1
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jung YS, 2008, INT CONF BIOMED, P859, DOI 10.1109/BMEI.2008.216
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Khun PC, 2009, 2009 INTERNATIONAL CONFERENCE ON BIOMEDICAL AND PHARMACEUTICAL ENGINEERING, P39
   Lau PY, 2007, P ANN INT IEEE EMBS, P5601, DOI 10.1109/IEMBS.2007.4353616
   Lee NM, 2010, EXPERT REV GASTROENT, V4, P503, DOI 10.1586/EGH.10.44
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Liu JG, 2009, OPTIM ENG, V10, P289, DOI 10.1007/s11081-008-9066-y
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Penna Barbara, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1864
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rey JF, 2008, NEW CHALLENGES IN GASTROINTESTINAL ENDOSCOPY, P55, DOI 10.1007/978-4-431-78889-8_4
   Zuckerman GR, 2000, GASTROENTEROLOGY, V118, P201, DOI 10.1016/S0016-5085(00)70430-6
NR 32
TC 126
Z9 127
U1 2
U2 30
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD MAR
PY 2014
VL 18
IS 2
BP 636
EP 642
DI 10.1109/JBHI.2013.2257819
PG 7
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA AD1IK
UT WOS:000332987400028
PM 24608063
DA 2023-04-20
ER

PT J
AU El-Serag, HB
   Hashmi, A
   Garcia, J
   Richardson, P
   Alsarraj, A
   Fitzgerald, S
   Vela, M
   Shaib, Y
   Abraham, NS
   Velez, M
   Cole, R
   Rodriguez, MB
   Anand, B
   Graham, DY
   Kramer, JR
AF El-Serag, Hashem B.
   Hashmi, Ali
   Garcia, Jose
   Richardson, Peter
   Alsarraj, Abeer
   Fitzgerald, Stephanie
   Vela, Marcelo
   Shaib, Yasser
   Abraham, Neena S.
   Velez, Maria
   Cole, Rhonda
   Rodriguez, Margot B.
   Anand, Bhupinderjit
   Graham, David Y.
   Kramer, Jennifer R.
TI Visceral abdominal obesity measured by CT scan is associated with an
   increased risk of Barrett's oesophagus: a case-control study
SO GUT
LA English
DT Article
DE Epidemiology; Obesity
ID ADIPOSE-TISSUE VOLUME; COMPUTED-TOMOGRAPHY; BODY-FAT;
   INSULIN-RESISTANCE; INFLAMMATION; METAANALYSIS; DISEASE; WOMEN;
   COMPLICATIONS; ADOLESCENTS
AB Objective Abdominal obesity has been associated with increased risk of Barrett's oesophagus (BE) but the underlying mechanism is unclear. We examined the association between visceral adipose tissue (VAT) and subcutaneous adipose tissue (SAT) and the risk of BE.
   Design A case-control study among eligible patients scheduled for elective oesophagastroduodenoscopy (EGD) and in a sample of patients eligible for screening colonoscopy recruited at the primary care clinic. All cases with definitive BE and a random sample of controls without BE were invited to undergo standardised mid-abdomen non-contrast computerised axial tomography images, which were analysed by semiautomated image segmentation software. The effect of VAT and SAT surface areas and their ratio (VAT to SAT) on BE were analysed in logistic regression models.
   Results A total of 173 BE cases, 343 colonoscopy controls and 172 endoscopy controls underwent study EGD and CT scan. Participants with BE were more than twice as likely to be in the highest tertile of VAT to SAT ratio (OR: 2.42 (1.51 to 3.88) and adjusted OR 1.47 (0.88 to 2.45)) than colonoscopy controls, especially for those long (3cm) segment BE (3.42 (1.67 to 7.01) and adjusted OR 1.93 (0.92 to 4.09)) and for white men (adjusted OR 2.12 (1.15 to 3.90)). Adjustment for gastroesophageal reflux disease (GERD) symptoms and proton pump inhibitors (PPI) use attenuated this association, but there was a significant increase in BE risk even in the absence of GERD or PPI use.
   Conclusions Large amount of visceral abdominal fat relative to subcutaneous fat is associated with a significant increase in the risk of BE. GERD may mediate some but not all of this association.
C1 [El-Serag, Hashem B.; Richardson, Peter; Alsarraj, Abeer; Fitzgerald, Stephanie; Kramer, Jennifer R.] Michael E DeBakey VA Med Ctr, Houston VA HSR&D Ctr, Excellence Sect, Houston, TX 77030 USA.
   [El-Serag, Hashem B.; Hashmi, Ali; Garcia, Jose; Richardson, Peter; Alsarraj, Abeer; Fitzgerald, Stephanie; Vela, Marcelo; Shaib, Yasser; Abraham, Neena S.; Velez, Maria; Cole, Rhonda; Rodriguez, Margot B.; Anand, Bhupinderjit; Graham, David Y.; Kramer, Jennifer R.] Baylor Coll Med, Houston, TX 77030 USA.
   [El-Serag, Hashem B.; Hashmi, Ali; Alsarraj, Abeer; Fitzgerald, Stephanie; Vela, Marcelo; Shaib, Yasser; Abraham, Neena S.; Velez, Maria; Cole, Rhonda; Anand, Bhupinderjit; Graham, David Y.] Michael E DeBakey VA Med Ctr, Dept Gastroenterol & Hepatol, Houston, TX 77030 USA.
   [Garcia, Jose] Michael E DeBakey VA Med Ctr, Dept Endocrinol Metab & Diabet, Houston, TX 77030 USA.
   [Richardson, Peter; Alsarraj, Abeer; Fitzgerald, Stephanie; Kramer, Jennifer R.] Michael E DeBakey VA Med Ctr, Houston, TX 77030 USA.
   [Rodriguez, Margot B.] Michael E DeBakey VA Med Ctr, Dept Radiol, Houston, TX 77030 USA.
C3 Baylor College of Medicine; Baylor College of Medicine; Baylor College
   of Medicine; Baylor College of Medicine; Baylor College of Medicine;
   Baylor College of Medicine
RP El-Serag, HB (通讯作者)，Michael E DeBakey VA Med Ctr, Houston VA HSR&D Ctr, Excellence Sect Hlth Serv Res, 2002 Holcombe Blvd 152, Houston, TX 77030 USA.
EM hasheme@bcm.edu
RI Graham, David/AAL-2165-2021
FU NIH [NCI R01 116845]; Houston VA HSR&D Center of Excellence [HFP90-020];
   Texas Digestive Disease Center NIH [DK58338]; NIDDK [K24-04-107]
FX This work is funded in part by NIH grant NCI R01 116845, the Houston VA
   HSR&D Center of Excellence (HFP90-020), and the Texas Digestive Disease
   Center NIH DK58338. Dr El-Serag is also supported by NIDDK K24-04-107.
CR Akiyama T, 2009, BMC GASTROENTEROL, V9, DOI 10.1186/1471-230X-9-56
   Anand O, 2008, BEST PRACT RES CL GA, V22, P661, DOI 10.1016/j.bpg.2008.02.001
   BAUMGARTNER RN, 1988, AM J CLIN NUTR, V48, P936, DOI 10.1093/ajcn/48.4.936
   Bonekamp S, 2008, INT J OBESITY, V32, P100, DOI 10.1038/sj.ijo.0803696
   Cook MB, 2008, AM J GASTROENTEROL, V103, P292, DOI 10.1111/j.1572-0241.2007.01621.x
   Corley DA, 2007, GUT, V56, P756, DOI 10.1136/gut.2006.109413
   Edelstein ZR, 2007, GASTROENTEROLOGY, V133, P403, DOI 10.1053/j.gastro.2007.05.026
   El-Serag HB, 2008, GUT, V57, DOI 10.1136/gut.2007.127878
   El-Serag HB, 2005, AM J GASTROENTEROL, V100, P2151, DOI 10.1111/j.1572-0241.2005.00251.x
   Fabbrini E, 2009, P NATL ACAD SCI USA, V106, P15430, DOI 10.1073/pnas.0904944106
   Giovannucci E., 2007, Gastroenterology, V132, P2208, DOI 10.1053/j.gastro.2007.03.050
   Hampel H, 2005, ANN INTERN MED, V143, P199, DOI 10.7326/0003-4819-143-3-200508020-00006
   Kaess BM, 2012, DIABETOLOGIA, V55, P2622, DOI 10.1007/s00125-012-2639-5
   Kamat P, 2009, ANN THORAC SURG, V87, P655, DOI 10.1016/j.athoracsur.2008.08.003
   Koska J, 2008, AM J CLIN NUTR, V87, P295, DOI 10.1093/ajcn/87.2.295
   KVIST H, 1986, INT J OBESITY, V10, P53
   KVIST H, 1988, INT J OBESITY, V12, P249
   KVIST H, 1988, AM J CLIN NUTR, V48, P1351, DOI 10.1093/ajcn/48.6.1351
   Mathieu P, 2009, HYPERTENSION, V53, P577, DOI 10.1161/HYPERTENSIONAHA.108.110320
   Mortimore IL, 1998, AM J RESP CRIT CARE, V157, P280, DOI 10.1164/ajrccm.157.1.9703018
   Nam SY, 2010, GASTROENTEROLOGY, V139, P1902, DOI 10.1053/j.gastro.2010.08.019
   Nelsen EM, 2012, CLIN GASTROENTEROL H, V10, P728, DOI 10.1016/j.cgh.2012.03.007
   Picardo SL, 2012, DIGEST SURG, V29, P251, DOI 10.1159/000341498
   Saito T, 2012, ENDOCR J, V59, P39, DOI 10.1507/endocrj.EJ11-0132
   SEIDELL JC, 1988, EUR J CLIN NUTR, V42, P805
   Sharma P, 2009, NEW ENGL J MED, V361, P2548, DOI 10.1056/NEJMcp0902173
   Siegel MJ, 2007, RADIOLOGY, V242, P846, DOI 10.1148/radiol.2423060111
   Srinivasan S, 2006, J CLIN ENDOCR METAB, V91, P2074, DOI 10.1210/jc.2006-0241
   THAETE FL, 1995, INT J OBESITY, V19, P464
   Winberg H, 2012, SCAND J GASTROENTERO, V47, P397, DOI 10.3109/00365521.2012.667145
   Xi B, 2012, OBES REV, V13, P287, DOI 10.1111/j.1467-789X.2011.00944.x
   Yudkin JS, 2007, HORM METAB RES, V39, P707, DOI 10.1055/s-2007-985898
   Zhao GX, 2011, BMC PSYCHIATRY, V11, DOI 10.1186/1471-244X-11-130
NR 33
TC 87
Z9 90
U1 0
U2 10
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0017-5749
EI 1468-3288
J9 GUT
JI Gut
PD FEB
PY 2014
VL 63
IS 2
BP 220
EP 228
DI 10.1136/gutjnl-2012-304189
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 286SD
UT WOS:000329488100012
PM 23408348
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Lloyd, GR
   Almond, LM
   Stone, N
   Shepherd, N
   Sanders, S
   Hutchings, J
   Barr, H
   Kendall, C
AF Lloyd, Gavin Rhys
   Almond, L. Max
   Stone, Nick
   Shepherd, Neil
   Sanders, Scott
   Hutchings, Joanne
   Barr, Hugh
   Kendall, Catherine
TI Utilising non-consensus pathology measurements to improve the diagnosis
   of oesophageal cancer using a Raman spectroscopic probe
SO ANALYST
LA English
DT Article
ID BARRETTS-ESOPHAGUS; POTENTIAL TOOL; LYMPH-NODES; CLASSIFICATION;
   ADENOCARCINOMA; DYSPLASIA; NEOPLASIA; MODELS
AB The application of semi-supervised methodology to improve the classification performance of a Raman spectroscopic probe for the diagnosis of oesophageal cancer is described. It is well known that gold standard histopathology diagnosis can be highly subjective, particularly for diseases which have several stages, such as cancer. A 'consensus' pathology decision can be obtained to ensure a robust gold standard by obtaining a diagnosis from several experts and samples are then only included in standard classification models if they have been assigned the same pathology by all experts. This can result in a significant number of samples that are excluded from the analysis as no consensus was reached. In this work semi-supervised methodology was used to extend Principal Component Analysis followed by Linear Discriminant Analysis (PCA-LDA) to incorporate samples without consensus pathology when discriminating between benign and oesophageal cancer specimens measured using a Raman endoscopic probe ex vivo. We demonstrate that a fully semi-supervised approach improved sensitivity and specificity from 73% and 78% (PCA-LDA) to 78% and 84% (semi-supervised) for discriminating between intestinal metaplasia and dysplasia and from 44% and 66% (PCA-LDA) to 63% and 72% (semi-supervised) when discriminating between intestinal metaplasia and low grade dysplasia.
C1 [Lloyd, Gavin Rhys; Almond, L. Max; Sanders, Scott; Hutchings, Joanne; Barr, Hugh; Kendall, Catherine] Gloucestershire Hosp NHS Fdn Trust, Biophoton Res Unit, Gloucester GL1 3NN, England.
   [Stone, Nick] Univ Exeter, Coll Engn Math & Phys Sci, Exeter EX4 4QL, Devon, England.
   [Shepherd, Neil] Cheltenham Gen Hosp, Gloucestershire Cellular Pathol Lab, Cheltenham GL53 7AN, Glos, England.
   [Sanders, Scott] Warwickshire Nuffield Hosp, Dept Pathol, Royal Leamington Spa CV32 6RW, England.
   [Barr, Hugh] Gloucestershire Hosp NHS Fdn Trust, Dept Surg, Gloucester GL1 3NN, England.
C3 Gloucestershire Hospitals NHS Foundation Trust; University of Exeter;
   Gloucestershire Hospitals NHS Foundation Trust; Cheltenham General
   Hospital; Gloucestershire Hospitals NHS Foundation Trust
RP Kendall, C (通讯作者)，Gloucestershire Hosp NHS Fdn Trust, Biophoton Res Unit, Great Western Rd, Gloucester GL1 3NN, England.
RI Lloyd, Gavin/D-3503-2011; Lloyd, Gavin/P-4212-2019; Shepherd, Neil
   A/AAV-3565-2021
OI Lloyd, Gavin/0000-0001-7989-6695; Lloyd, Gavin/0000-0001-7989-6695;
   Stone, Nick/0000-0001-5603-3731; Almond, Max/0000-0003-4133-312X;
   Kendall, Catherine/0000-0002-7705-853X
FU National Institute for Health Research [II-LA-1111-20007,
   NF-SI-0611-10065, CSA/03/07/017] Funding Source: researchfish;
   Department of Health [CSA/03/07/017, II-LA-1111-20007] Funding Source:
   Medline
CR Almond LM, 2011, J BIOPHOTONICS, V4, P685, DOI 10.1002/jbio.201100041
   [Anonymous], NATURE STAT LEARNING
   Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785
   Beleites C, 2013, CHEMOMETR INTELL LAB, V122, P12, DOI 10.1016/j.chemolab.2012.12.003
   Bennett KP, 1999, ADV NEUR IN, V11, P368
   BLOT WJ, 1991, JAMA-J AM MED ASSOC, V265, P1287, DOI 10.1001/jama.265.10.1287
   Brereton R.G., 2009, CHEMOMETRICS PATTERN
   Brereton RG., 2003, CHEMOMETRICS DATA AN, DOI DOI 10.1002/0470863242
   Brereton RG, 2010, ANALYST, V135, P230, DOI 10.1039/b918972f
   Brereton RG, 2011, J CHEMOMETR, V25, P225, DOI 10.1002/cem.1397
   Bytzer P, 1999, AM J GASTROENTEROL, V94, P86
   Cai D, 2007, P IEEE C COMP VIS PA, V11, P1, DOI DOI 10.1109/CVPR.2007.383054
   Crow P, 2003, BRIT J CANCER, V89, P106, DOI 10.1038/sj.bjc.6601059
   Day JCC, 2009, PHYS MED BIOL, V54, P7077, DOI 10.1088/0031-9155/54/23/003
   Devesa SS, 1998, CANCER, V83, P2049, DOI 10.1002/(SICI)1097-0142(19981115)83:10<2049::AID-CNCR1>3.0.CO;2-2
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Hanlon EB, 2000, PHYS MED BIOL, V45, pR1, DOI 10.1088/0031-9155/45/2/201
   Horsnell J, 2010, ANALYST, V135, P3042, DOI 10.1039/c0an00527d
   Hutchings J, 2008, PROC SPIE, V6853, DOI 10.1117/12.786440
   Kendall C, 2003, J PATHOL, V200, P602, DOI 10.1002/path.1376
   Kohonen T, 1998, NEUROCOMPUTING, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Li D, 2010, J CHEMOMETR, V24, P273, DOI 10.1002/cem.1288
   Lloyd GR, 2013, ANALYST, V138, P3900, DOI 10.1039/c2an36579k
   Lloyd GR, 2012, VIB SPECTROSC, V60, P43, DOI 10.1016/j.vibspec.2012.02.015
   Montgomery E, 2001, HUM PATHOL, V32, P368, DOI 10.1053/hupa.2001.23510
   Shetty G, 2006, BRIT J CANCER, V94, P1460, DOI 10.1038/sj.bjc.6603102
   Smith J, 2003, TECHNOL CANCER RES T, V2, P327, DOI 10.1177/153303460300200407
   Stone N, 2000, LARYNGOSCOPE, V110, P1756, DOI 10.1097/00005537-200010000-00037
   Stone N., 2006, HDB VIBRATIONAL SPEC
   Stone N, 2007, ANALYST, V132, P899, DOI 10.1039/b705029a
   Toher D, 2011, J CHEMOMETR, V25, P621, DOI 10.1002/cem.1408
   Widjaja E, 2008, INT J ONCOL, V32, P653
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yousef F, 2008, AM J EPIDEMIOL, V168, P237, DOI 10.1093/aje/kwn121
   Zhu X, 2009, SYNTH LECT ARTIF INT, V3, P1, DOI 10.2200/S00196ED1V01Y200906AIM006
NR 35
TC 15
Z9 16
U1 0
U2 14
PU ROYAL SOC CHEMISTRY
PI CAMBRIDGE
PA THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS,
   ENGLAND
SN 0003-2654
EI 1364-5528
J9 ANALYST
JI Analyst
PY 2014
VL 139
IS 2
BP 381
EP 388
DI 10.1039/c3an01163a
PG 8
WC Chemistry, Analytical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry
GA 274YS
UT WOS:000328642700005
PM 24287592
DA 2023-04-20
ER

PT J
AU Luukkainen-Soilu, MK
   Bochko, V
   Valisuo, P
   Peltoniemi, OAT
   Rosenberg, PH
   Karkamo, V
   Alander, J
   Spillmann, T
AF Luukkainen-Soilu, Maarit K.
   Bochko, Vladimir
   Valisuo, Petri
   Peltoniemi, Olli A. T.
   Rosenberg, Per H.
   Karkamo, Veera
   Alander, Jarmo
   Spillmann, Thomas
TI Endoscopic visual and near infrared diffuse reflectance spectral
   analysis for the recognition of healthy porcine gastric and small
   intestinal watt a feasibility study
SO JOURNAL OF NEAR INFRARED SPECTROSCOPY
LA English
DT Article
DE endoscopy; intestine; healthy pig; NIR diffuse reflectance spectral
   analysis
ID RAMAN-SPECTROSCOPY; DIAGNOSIS; FLUORESCENCE; DRUGS; RATS
AB Recent investigations have proved the usefulness of spectroscopy in endoscopic examinations of the gastrointestinal tract in human medicine. However, current commercially available spectroscopy methods are relatively expensive. Near infrared (NIR) diffuse reflectance spectroscopy is a more cost-effective method. To assess its applicability for gastrointestinal endoscopy in veterinary medicine, in a pilot study we tested its feasibility for the differentiation of parts of the healthy gastrointestinal wall of pigs. Both white light standard endoscopy and NIR endoscopy were performed on the corpus, antrum and duodenum of seven clinically healthy pigs. General and gastrointestinal health was assessed by history, clinical examination and post-mortem examination. The spectral values of NIR endoscopy were obtained at intervals of about 0.3 nm in the range of 195-1118nm. The method for the analysis of endoscopically taken NIR spectra consisted of pre-processing, feature extraction and classification. After smoothing, down-sampling and feature computing, spectral data were analysed using the principal component analysis (PCA) and partial least squares (PLS) techniques. The best algorithm performance was achieved using the spectra-PCA-SVC, giving a classification rate of 0.76. Further research is needed to assess the applicability of NIR endoscopy in other species and in animals showing gastrointestinal pathology. To improve the classification rate, probe calibration must be optimised and cleanness of the gastrointestinal tract ensured.
C1 [Luukkainen-Soilu, Maarit K.; Spillmann, Thomas] Univ Helsinki, Fac Vet Med, Dept Equine & Small Anim Med, FIN-00014 Helsinki, Finland.
   [Peltoniemi, Olli A. T.] Univ Helsinki, Fac Vet Med, Dept Prod Anim Med, Saarentaus 04920, Finland.
   [Rosenberg, Per H.] Univ Helsinki, Helsinki Univ Hosp, Dept Anesthesiol & Intens Care Med, Helsinki 00029, Finland.
   [Karkamo, Veera] Univ Helsinki, Fac Vet Med, Dept Vet Biosci, FIN-00014 Helsinki, Finland.
   [Bochko, Vladimir; Valisuo, Petri; Alander, Jarmo] Univ Vaasa, Fac Technol, Dept Elect & Energy Engn, Vaasa 65101, Finland.
C3 University of Helsinki; University of Helsinki; University of Helsinki;
   Helsinki University Central Hospital; University of Helsinki; University
   of Vaasa
RP Luukkainen-Soilu, MK (通讯作者)，Univ Helsinki, Fac Vet Med, Dept Equine & Small Anim Med, POB 57 Viikintie 49, FIN-00014 Helsinki, Finland.
EM Thomas.Spillmann@helsinki.fi
RI Spillmann, Thomas/AAI-8481-2020; Välisuo, Petri/AAP-4951-2021
OI Välisuo, Petri/0000-0002-9566-6408; Karkamo, Veera/0000-0002-3592-8226;
   Peloniemi, Olli/0000-0002-9481-1837; Spillmann,
   Thomas/0000-0002-0176-7428
FU Helvi Knuutila Foundation, Finland; Finnish Veterinary Association;
   Botnia-Atlantica, a project of the European Regional Development Fund;
   Tekes, Finland; Microrobotics project; Field NIRce
FX Supported by: Helvi Knuutila Foundation, Finland; Finnish Veterinary
   Association, Field NIRce sponsored by Botnia-Atlantica, a project of the
   European Regional Development Fund and the Microrobotics project funded
   by Tekes, Finland.
CR Beljebbar A, 2009, CRIT REV ONCOL HEMAT, V72, P255, DOI 10.1016/j.critrevonc.2009.09.004
   Breiman L., 1984, CLASSIFICATION REGRE, DOI [10.1002/widm.8, DOI 10.1002/WIDM.8]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   DaCosta RS, 2005, CURR OPIN GASTROEN, V21, P70
   DaCosta RS, 2006, BEST PRACT RES CL GA, V20, P41, DOI 10.1016/j.bpg.2005.08.003
   Dacosta RS, 2002, J GASTROEN HEPATOL, V17, pS85, DOI 10.1046/j.1440-1746.17.s1.8.x
   Dekker E, 2005, EUR J GASTROEN HEPAT, V17, P803, DOI 10.1097/00042737-200508000-00004
   Dhar A, 2006, GASTROINTEST ENDOSC, V63, P257, DOI 10.1016/j.gie.2005.07.026
   Ferrari M, 2012, J NEAR INFRARED SPEC, V20, pVII, DOI 10.1255/jnirs.982
   Ferraty F., 2006, SPR S STAT
   Flecknell P, 2002, ALTEX-ALTERN TIEREXP, V19, P73
   Friedland Shai, 2004, Gastrointest Endosc Clin N Am, V14, P539, DOI 10.1016/j.giec.2004.03.011
   Fulljames C, 1999, ITAL J GASTROENTEROL, V31, P695
   Gandjbakhche AH, 2001, CR ACAD SCI IV-PHYS, V2, P1073, DOI 10.1016/S1296-2147(01)01251-3
   Horecker BL, 1943, J BIOL CHEM, V148, P173
   Ito S, 2006, J MED INVESTIG, V53, P1, DOI 10.2152/jmi.53.1
   Kaihara M, 2007, J NEAR INFRARED SPEC, V15, P371, DOI 10.1255/jnirs.752
   Kawabata T, 2008, J GASTROENTEROL, V43, P283, DOI 10.1007/s00535-008-2160-2
   Matz M.E., 2010, TXB VET INTERNAL MED, V1, P443
   McCarthy T.C., 2005, VET ENDOSCOPY SMALL, P282
   Molckovsky A, 2003, GASTROINTEST ENDOSC, V57, P396, DOI 10.1067/mge.2003.105
   Pellicer A, 2011, SEMIN FETAL NEONAT M, V16, P42, DOI 10.1016/j.siny.2010.05.003
   RAINSFORD KD, 1986, INT J TISSUE REACT, V8, P1
   RAINSFORD KD, 1982, EUR J RHEUMATOL INFL, V5, P148
   Reif R, 2007, APPL OPTICS, V46, P7317, DOI 10.1364/AO.46.007317
   Rollins AM, 2001, BEST PRACT RES CL GA, V15, P227, DOI 10.1053/bega.2000.0171
   Shim MG, 1997, J RAMAN SPECTROSC, V28, P131, DOI 10.1002/(SICI)1097-4555(199702)28:2/3<131::AID-JRS68>3.0.CO;2-S
   Shim MG, 2000, PHOTOCHEM PHOTOBIOL, V72, P146, DOI 10.1562/0031-8655(2000)072<0146:IVNIRS>2.0.CO;2
   Silverman, 1997, FUNCTIONAL DATA ANAL, DOI DOI 10.1007/978-1-4757-7107-7
   Stone N, 2000, LARYNGOSCOPE, V110, P1756, DOI 10.1097/00005537-200010000-00037
   Tuchin V., 2015, TISSUE OPTICS LIGHT, DOI 10.1117/3.1003040
   Wolf M, 2012, J NEAR INFRARED SPEC, V20, P43, DOI 10.1255/jnirs.972
NR 32
TC 1
Z9 1
U1 1
U2 12
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0967-0335
EI 1751-6552
J9 J NEAR INFRARED SPEC
JI J. Near Infrared Spectrosc.
PY 2014
VL 22
IS 1
BP 19
EP 26
DI 10.1255/jnirs.1086
PG 8
WC Chemistry, Applied; Spectroscopy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Spectroscopy
GA AF2SA
UT WOS:000334561100004
DA 2023-04-20
ER

PT J
AU Szczypinski, P
   Klepaczko, A
   Pazurek, M
   Daniel, P
AF Szczypinski, Piotr
   Klepaczko, Artur
   Pazurek, Marek
   Daniel, Piotr
TI Texture and color based image segmentation and pathology detection in
   capsule endoscopy videos
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE Capsule endoscopy; Feature selection; Texture analysis; Medical image
   analysis
ID FEATURE-SELECTION; EXPERIENCE
AB This paper presents an in-depth study of several approaches to exploratory analysis of wireless capsule endoscopy images (WCE). It is demonstrated that versatile texture and color based descriptors of image regions corresponding to various anomalies of the gastrointestinal tract allows their accurate detection of pathologies in a sequence of WCE frames. Moreover, through classification of single pixels described by texture features of their neighborhood, the images can be segmented into homogeneous areas well matched to the image content. For both, detection and segmentation tasks the same procedure is applied which consists of features calculation, relevant feature subset selection and classification stages. This general three-stage framework is realized using various recognition strategies. In particular, the performance of the developed Vector Supported Convex Hull classification algorithm is compared against Support Vector Machines run in configuration with two different feature selection methods. (C) 2012 Elsevier Ireland Ltd. All rights reserved.
C1 [Szczypinski, Piotr; Klepaczko, Artur] Tech Univ Lodz, Inst Elect, Med Elect Div, PL-90924 Lodz, Poland.
   [Pazurek, Marek; Daniel, Piotr] Med Univ Lodz, Fac Med, Dept Digest Tract Dis, PL-90153 Lodz, Poland.
C3 Lodz University of Technology; Medical University Lodz
RP Szczypinski, P (通讯作者)，Tech Univ Lodz, Inst Elect, Med Elect Div, Ul Wolczanska 211-215, PL-90924 Lodz, Poland.
EM pms@p.lodz.pl
RI Klepaczko, Artur/AAB-5519-2019; Szczypiński, Piotr M/R-1964-2017;
   Klepaczko, Artur/R-4901-2017
OI Klepaczko, Artur/0000-0003-4045-5870; Szczypiński, Piotr
   M/0000-0002-9956-0862; Klepaczko, Artur/0000-0003-4045-5870
CR Adler DG., 2003, HOSP PHYS, V39, P14
   [Anonymous], DATA MINING PRACTICA
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Barbosa D. J. C., 2008, 30TH ANNUAL INTERNAT, P3012
   Barbosa DC, 2012, BIOMED ENG ONLINE, V11, DOI 10.1186/1475-925X-11-3
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Bourbakis N., 2005, PROC 5TH IEEE SYMPOS
   Chait MM, 2010, WORLD J GASTRO ENDOS, V2, P388, DOI 10.4253/wjge.v2.i12.388
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Coimbra M., 2005, IEE SEMINAR DIGESTS, V2005, P105
   Coimbra M., IEEE ICASSP, V2, P1164
   Coimbra M., 2006, P IEEE INT C AC SPEE, V2, P1164
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Dy JG, 2004, J MACH LEARN RES, V5, P845
   Freedman D. A., 2005, STATISTICAL MODELS T
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Goenka MK, 2011, WORLD J GASTROENTERO, V17, P774, DOI 10.3748/wjg.v17.i6.774
   Hwang S., PROCEEDINGS OF THE I, P678
   Klepaczko Artur, 2009, Machine Graphics & Vision, V18, P125
   Klepaczko A, 2011, PATTERN ANAL APPL, V14, P415, DOI 10.1007/s10044-010-0192-8
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Li BP, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P234, DOI 10.1109/WCICA.2008.4592930
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Lukashok H. P., 2011, MULTIPLE INTESTINAL
   Mackiewicz M, 2008, PROC SPIE, V6914, DOI 10.1117/12.770510
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Martinez J. M., 2004, MPEG 7 OVERVIEW
   Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424, DOI 10.1109/TPAMI.2004.105
   Pudil P, 2005, ADV SOFT COMP, P53
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Scapa E, 2002, AM J GASTROENTEROL, V97, P2776, DOI 10.1111/j.1572-0241.2002.07021.x
   Siedlecki W., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P197, DOI 10.1142/S0218001488000145
   Swain P, 2005, GUT, V54, P323, DOI 10.1136/gut.2004.047282
   Szczypinski P, 2009, LECT NOTES COMPUT SC, V5807, P664
   Szczypinski PM, 2009, MED IMAGE ANAL, V13, P312, DOI 10.1016/j.media.2008.12.002
   Szczypinski PM, 2009, COMPUT METH PROG BIO, V94, P66, DOI 10.1016/j.cmpb.2008.08.005
   Vapnik V, 1995, THE NATURE OF STATIS
   Vilarino F, 2006, PATTERN RECOGN LETT, V27, P875, DOI 10.1016/j.patrec.2005.10.011
   Wartel F, 2007, GUT, V56, P1132, DOI 10.1136/gut.2006.097733
NR 42
TC 85
Z9 90
U1 2
U2 38
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD JAN
PY 2014
VL 113
IS 1
BP 396
EP 411
DI 10.1016/j.cmpb.7017.09.004
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 254QR
UT WOS:000327180900036
PM 23164524
DA 2023-04-20
ER

PT J
AU Zhang, H
   Li, LH
   Zhu, HB
   Han, H
   Song, BW
   Liang, ZR
AF Zhang, Hao
   Li, Lihong
   Zhu, Hongbin
   Han, Hao
   Song, Bowen
   Liang, Zhengrong
TI Integration of 3D scale-based pseudo-enhancement correction and partial
   volume image segmentation for improving electronic colon cleansing in CT
   colonograpy
SO JOURNAL OF X-RAY SCIENCE AND TECHNOLOGY
LA English
DT Article
DE CT colonography; electronic colon cleansing; pseudo-enhancement
   correction; partial volume image segmentation; computer-aided detection
ID COLORECTAL NEOPLASIA; TISSUE MIXTURES; MAP SOLUTION; EM APPROACH;
   COLONOSCOPY; CANCER; FRAMEWORK; MODELS
AB Orally administered tagging agents are usually used in CT colonography (CTC) to differentiate residual bowel content from native colonic structures. However, the high-density contrast agents tend to introduce pseudo-enhancement (PE) effect on neighboring soft tissues and elevate their observed CT attenuation value toward that of the tagged materials (TMs), which may result in an excessive electronic colon cleansing (ECC) since the pseudo-enhanced soft tissues are incorrectly identified as TMs. To address this issue, we integrated a 3D scale-based PE correction into our previous ECC pipeline based on the maximum a posteriori expectation-maximization partial volume (PV) segmentation. The newly proposed ECC scheme takes into account both the PE and PV effects that commonly appear in CTC images. We evaluated the new scheme on 40 patient CTC scans, both qualitatively through display of segmentation results, and quantitatively through radiologists' blind scoring (human observer) and computer-aided detection (CAD) of colon polyps (computer observer). Performance of the presented algorithm has shown consistent improvements over our previous ECC pipeline, especially for the detection of small polyps submerged in the contrast agents. The CAD results of polyp detection showed that 4 more submerged polyps were detected for our new ECC scheme over the previous one.
C1 [Zhang, Hao; Zhu, Hongbin; Han, Hao; Song, Bowen; Liang, Zhengrong] SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
   [Zhang, Hao; Liang, Zhengrong] SUNY Stony Brook, Dept Biomed Engn, Stony Brook, NY 11794 USA.
   [Li, Lihong] CUNY Coll Staten Isl, Dept Engn Sci & Phys, Staten Isl, NY USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook; City University of New York
   (CUNY) System; College of Staten Island (CUNY)
RP Liang, ZR (通讯作者)，SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
EM jerome.liang@sunysb.edu
RI han, hao/HNS-0623-2023; Han, Hao/D-5618-2015
OI Han, Hao/0000-0002-9387-7279
FU NIH of the National Cancer Institute [CA082402, CA143111]
FX This work was partly supported by NIH grants #CA082402 and #CA143111 of
   the National Cancer Institute. The authors would like to thank Dr.
   Jiamin Liu for helpful discussion on this topic. The authors would also
   like to thank the anonymous reviewers for their constructive comments
   and suggestions that greatly improve the quality of the manuscript.
CR BARTRAM CI, 1994, CLIN RADIOL, V49, P365, DOI 10.1016/S0009-9260(05)81818-5
   chambers J., 1991, STAT MODELS S
   CHOI HS, 1991, IEEE T MED IMAGING, V10, P395, DOI 10.1109/42.97590
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   EDDY DM, 1990, ANN INTERN MED, V113, P373, DOI 10.7326/0003-4819-113-5-373
   EREMINA D, 2006, SPIE MED IMAGING, V6144, pD1
   Fenlon HM, 1999, NEW ENGL J MED, V341, P1496, DOI 10.1056/NEJM199911113412003
   Gluecker TM, 2003, RADIOLOGY, V227, P378, DOI 10.1148/radiol.2272020293
   Hong LC, 1997, IEEE T NUCL SCI, V44, P1297, DOI 10.1109/23.597004
   Johnson CD, 2003, GASTROENTEROLOGY, V125, P311, DOI 10.1016/S0016-5085(03)00894-1
   Khotanzad A, 1999, IEEE T IMAGE PROCESS, V8, P734, DOI 10.1109/83.760340
   Levin B, 2003, CA-CANCER J CLIN, V53, P44, DOI 10.3322/canjclin.53.1.44
   Li LH, 2002, PROC SPIE, V4683, P406, DOI 10.1117/12.463607
   LIANG Z, 1997, IEEE NUCL SCI SOC ME
   Liang ZR, 2009, IEEE T MED IMAGING, V28, P297, DOI 10.1109/TMI.2008.2004670
   Liang ZR, 2003, P ANN INT IEEE EMBS, V25, P682, DOI 10.1109/IEMBS.2003.1279855
   Liu JM, 2008, MED PHYS, V35, P5664, DOI 10.1118/1.3013552
   Nappi J, 2008, MED IMAGE ANAL, V12, P413, DOI 10.1016/j.media.2008.01.001
   Nappi J, 2007, PROC SPIE, V6514, DOI 10.1117/12.710186
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Saha PK, 2001, IEEE T MED IMAGING, V20, P1140, DOI 10.1109/42.963817
   SANTAGO P, 1995, IEEE T IMAGE PROCESS, V4, P1531, DOI 10.1109/83.469934
   Siegel R, 2013, CA-CANCER J CLIN, V63, P11, DOI 10.3322/caac.21166
   Van Leemput K, 2003, IEEE T MED IMAGING, V22, P105, DOI 10.1109/TMI.2002.806587
   Wang S, 2008, MED PHYS, V35, P5787, DOI 10.1118/1.3013591
   Wang ZG, 2006, IEEE T BIO-MED ENG, V53, P1635, DOI 10.1109/TBME.2006.877793
   Yee J, 2001, RADIOLOGY, V219, P685, DOI 10.1148/radiology.219.3.r01jn40685
   Zhu H, 2009, J CANC MANAG RES DOV, V1, P1
NR 28
TC 15
Z9 15
U1 0
U2 6
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0895-3996
EI 1095-9114
J9 J X-RAY SCI TECHNOL
JI J. X-Ray Sci. Technol.
PY 2014
VL 22
IS 2
BP 271
EP 283
DI 10.3233/XST-140424
PG 13
WC Instruments & Instrumentation; Optics; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Instruments & Instrumentation; Optics; Physics
GA AE9TS
UT WOS:000334353600010
PM 24699352
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Gadermayr, M
   Liedlgruber, M
   Uhl, A
   Vecsei, A
AF Gadermayr, M.
   Liedlgruber, M.
   Uhl, A.
   Vecsei, A.
TI Evaluation of different distortion correction methods and interpolation
   techniques for an automated classification of celiac disease
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE Endoscopy; Celiac disease; Barrel-type distortion; Distortion
   correction; Medical image classification
ID DISTRIBUTIONS; GLUTEN
AB Due to the optics used in endoscopes, a typical degradation observed in endoscopic images are barrel-type distortions. In this work we investigate the impact of methods used to correct such distortions in images on the classification accuracy in the context of automated celiac disease classification.
   For this purpose we compare various different distortion correction methods and apply them to endoscopic images, which are subsequently classified. Since the interpolation used in such methods is also assumed to have an influence on the resulting classification accuracies, we also investigate different interpolation methods and their impact on the classification performance. In order to be able to make solid statements about the benefit of distortion correction we use various different feature extraction methods used to obtain features for the classification.
   Our experiments show that it is not possible to make a clear statement about the usefulness of distortion correction methods in the context of an automated diagnosis of celiac disease. This is mainly due to the fact that an eventual benefit of distortion correction highly depends on the feature extraction method used for the classification. (c) 2013 The Author. Published by Elsevier Ireland Ltd. All rights reserved.
C1 [Gadermayr, M.; Liedlgruber, M.; Uhl, A.] Salzburg Univ, Dept Comp Sci, A-5020 Salzburg, Austria.
   [Vecsei, A.] Med Univ, St Anna Childrens Hosp, Dept Pediat, Vienna, Austria.
C3 Salzburg University; Saint Anna Children's Hospital
RP Gadermayr, M (通讯作者)，Salzburg Univ, Dept Comp Sci, A-5020 Salzburg, Austria.
EM mgadermayr@cosy.sbg.ac.at; mliedl@cosy.sbg.ac.at; uhl@cosy.sbg.ac.at
OI , Michael/0000-0003-1450-9222; Liedlgruber, Michael/0000-0001-8035-6426
FU Austrian Science Fund (FWF) [24366]; Austrian Science Fund (FWF) [P
   24366] Funding Source: researchfish
FX This work is partially funded by the Austrian Science Fund (FWF) under
   Project No. 24366.
CR Alvarez L, 2009, J MATH IMAGING VIS, V35, P36, DOI 10.1007/s10851-009-0153-2
   Asari KV, 1999, IEEE T MED IMAGING, V18, P345, DOI 10.1109/42.768843
   Ayala G, 2001, IEEE T PATTERN ANAL, V23, P1430, DOI 10.1109/34.977566
   Barreto JP, 2007, 3DTV CONF, P354
   Borcharrt T. B., 2009, PROCEEDINGS OF THE 2
   Cammarota G, 2007, ENDOSCOPY, V39, P46, DOI 10.1055/s-2006-945044
   Coifman R. R., 1992, IEEE TRANSITIONS INF, V38, P719
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Fitzgibbon AW, 2001, PROC CVPR IEEE, P125
   Gadermayr M., 2012, TECH REP 2012 06
   Gasbarrini A, 2003, GASTROINTEST ENDOSC, V57, P348, DOI 10.1067/mge.2003.116
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gschwandtner M., 2010, PROCEEDINGS OF THE 1
   Gschwandtner M., 2012, PROCEEDINGS OF THE I
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P177
   Haemmerle-Uhl J, 2012, LECT NOTES COMPUT SC, V7512, P574, DOI 10.1007/978-3-642-33454-2_71
   Hafner M., 2006, PROCEEDINGS OF THE I
   Hafner M., 2009, P 9 INT C INF TECHN, P1
   HANEISHI H, 1995, IEEE T MED IMAGING, V14, P548, DOI 10.1109/42.414620
   Hanna G, 2001, WORLD J SURG, V25, P1419, DOI 10.1007/s00268-001-0127-z
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hartley R, 2007, IEEE T PATTERN ANAL, V29, P1309, DOI 10.1109/TPAMI.2007.1147
   Hegenbart S, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P718
   Helferty JP, 2001, IEEE T MED IMAGING, V20, P605, DOI 10.1109/42.932745
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li W., 2008, PROCEEDINGS OF MEDIC, V2008
   Liedigruber M., 2012, IEEE REV BIOMEDICAL, V4, P73
   Liedlgruber Michael, 2007, 9th WSEAS International Conference on Mathematical Methods and Computational Techniques in Electrical Engineering (MMACTEE '07). 6th WSEAS International Conference on Non-Linear Analysis, Non-Linear Systems and Chaos (NOLASC '07). 7th WSEAS International, P147
   Liedlgruber Michael, 2011, Efficient Decision Support Systems - Practice and Challenges in Biomedical Related Domain, P195
   Liedlgruber M., 2011, TECH REP 2011 01
   Liedlgruber M., 2011, PROCEEDINGS OF THE 1
   MARSH MN, 1992, GASTROENTEROLOGY, V102, P330, DOI 10.1016/0016-5085(92)91819-P
   Melo R, 2012, IEEE T BIO-MED ENG, V59, P634, DOI 10.1109/TBME.2011.2177268
   Oberhuber G, 1999, EUR J GASTROEN HEPAT, V11, P1185, DOI 10.1097/00042737-199910000-00019
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Petroniene R, 2005, AM J GASTROENTEROL, V100, P685, DOI 10.1111/j.1572-0241.2005.41069.x
   Rautkorpi R, 2004, LECT NOTES COMPUT SC, V3211, P753
   Saito N., 1995, Journal of Mathematical Imaging and Vision, V5, P337, DOI 10.1007/BF01250288
   Sun H.-X., 2008, PROCEEDINGS OF THE 1, P25
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Uhl A, 2011, INT SYMP IMAGE SIG, P727
   Wang F.P., 2010, ALKALOIDS CHEM BIOL, P1, DOI DOI 10.1016/S1099-4831(10)69001-3
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 45
TC 18
Z9 19
U1 1
U2 16
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD DEC
PY 2013
VL 112
IS 3
BP 694
EP 712
DI 10.1016/j.cmpb.2013.07.001
PG 19
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 235VW
UT WOS:000325750100032
PM 23981585
OA hybrid, Green Submitted, Green Published
DA 2023-04-20
ER

PT J
AU Bell, CS
   Obstein, KL
   Valdastri, P
AF Bell, Charreau S.
   Obstein, Keith L.
   Valdastri, Pietro
TI Image partitioning and illumination in image-based pose detection for
   teleoperated flexible endoscopes
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Artificial neural networks; Pose estimation; Localization; Optical flow;
   Visual odometry; Closed-loop control; Teleoperation; Narrow band
   imaging; Flexible endoscopes; Colonoscopes; Gastrointestinal endoscopy
ID REGISTRATION; NAVIGATION; TRACKING; TECHNOLOGIES; SYSTEM; REAL
AB Objective: Colorectal cancer is one of the leading causes of cancer-related deaths in the world, although it can be effectively treated if detected early. Teleoperated flexible endoscopes are an emerging technology to ease patient apprehension about the procedure, and subsequently increase compliance. Essential to teleoperation is robust feedback reflecting the change in pose (i.e., position and orientation) of the tip of the endoscope. The goal of this study is to first describe a novel image-based tracking system for teleoperated flexible endoscopes, and subsequently determine its viability in a clinical setting. The proposed approach leverages artificial neural networks (ANNs) to learn the mapping that links the optical flow between two sequential images to the change in the pose of the camera. Secondly, the study investigates for the first time how narrow band illumination (NBI) - today available in commercial gastrointestinal endoscopes - can be applied to enhance feature extraction, and quantify the effect of NBI and white light illumination (WLI), as well as their color information, on the strength of features extracted from the endoscopic camera stream.
   Methods and materials: In order to provide the best features for the neural networks to learn the change in pose based on the image stream, we investigated two different imaging modalities - WLI and NBI - and we applied two different spatial partitions - lumen-centered and grid-based - to create descriptors used as input to the ANNs. An experiment was performed to compare the error of these four variations, measured in root mean square error (RMSE) from ground truth given by a robotic arm, to that of a commercial state-of-the-art magnetic tracker. The viability of this technique for a clinical setting was then tested using the four ANN variations, a magnetic tracker, and a commercial colonoscope. The trial was performed by an expert endoscopist (>2000 lifetime procedures) on a colonoscopy training model with porcine blood, and the RMSE of the ANN output was calculated with respect to the magnetic tracker readings. Using the image stream obtained from the commercial endoscope, the strength of features extracted was evaluated.
   Results: In the first experiment, the best ANNs resulted from grid-based partitioning under WLI (2.42 mm RMSE) for position, and from lumen-centered partitioning under NBI (1.69 degrees RMSE) for rotation. By comparison, the performance of the tracker was 2.49 mm RMSE in position and 0.89 degrees RMSE in rotation. The trial with the commercial endoscope indicated that lumen-centered partitioning was the best overall, while NBI outperformed WLI in terms of illumination modality. The performance of lumen-centered partitioning with NBI was 1.03 +/- 0.8 mm RMSE in positional degrees of freedom (DOF), and 1.26 +/- 0.98 degrees RMSE in rotational DOF, while with WLI, the performance was 1.56 +/- 1.15 mm RMSE in positional DOF and 2.45 +/- 1.90 degrees RMSE in rotational DOF. Finally, the features extracted under NBI were found to be twice as strong as those extracted under WLI, but no significance in feature strengths was observed between a grayscale version of the image, and the red, blue, and green color channels.
   Conclusions: This work demonstrates that both WLI and NBI, combined with feature partitioning based on the anatomy of the colon, provide valid mechanisms for endoscopic camera pose estimation via image stream. Illumination provided by WLI and NBI produce ANNs with similar performance which are comparable to that of a state-of-the-art magnetic tracker. However, NBI produces features that are stronger than WLI, which enables more robust feature tracking, and better performance of the ANN in terms of accuracy. Thus, NBI with lumen-centered partitioning resulted the best approach among the different variations tested for vision-based pose estimation. The proposed approach takes advantage of components already available in commercial gastrointestinal endoscopes to provide accurate feedback about the motion of the tip of the endoscope. This solution may serve as an enabling technology for closed-loop control of teleoperated flexible endoscopes. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Bell, Charreau S.; Obstein, Keith L.; Valdastri, Pietro] Vanderbilt Univ, Dept Mech Engn, Nashville, TN 37235 USA.
   [Obstein, Keith L.; Valdastri, Pietro] Vanderbilt Univ, Med Ctr, Dept Gastroenterol Hepatol & Nutr, Nashville, TN 37232 USA.
C3 Vanderbilt University; Vanderbilt University
RP Bell, CS (通讯作者)，Vanderbilt Univ, Dept Mech Engn, 2301 Vanderbilt Pl,PMB 351826, Nashville, TN 37235 USA.
EM charreau.s.bell@vanderbilt.edu; keith.obstein@vanderbilt.edu;
   pietro.valdastri@vanderbilt.edu
RI Valdastri, Pietro/AAG-1706-2019
OI Valdastri, Pietro/0000-0002-2280-5438
FU Center for Compact and Efficient Fluid Power under the National Science
   Foundation [0540834]; Broad Medical Research Program of The Broad
   Foundation
FX This work was supported by the Center for Compact and Efficient Fluid
   Power under the National Science Foundation award #0540834, and by the
   Broad Medical Research Program of The Broad Foundation. The authors
   would also like to thank Trevor Bruns, Marco Beccani, Christian Di
   Natali, and Jack Noble for their assistance in this work.
CR Asano F, 2010, CLIN CHEST MED, V31, P75, DOI 10.1016/j.ccm.2009.08.007
   Bradski G., 2000, DOBBS J SOFTWARE TOO
   Bricault I, 1998, IEEE T MED IMAGING, V17, P703, DOI 10.1109/42.736022
   Bulat J, 2007, P ANN INT IEEE EMBS, P2815, DOI 10.1109/IEMBS.2007.4352914
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   Deguchi D, 2003, INT CONGR SER, V1256, P460, DOI 10.1016/S0531-5131(03)00331-5
   Deguchi D, 2009, MED IMAGE ANAL, V13, P621, DOI 10.1016/j.media.2009.06.001
   Erdemir E, 2012, P 21 IEEE INT S ROB
   Gao MY, 2010, IEEE T BIO-MED ENG, V57, P2891, DOI 10.1109/TBME.2010.2051947
   Guizilini V, 2013, INT J ROBOT RES, V32, P526, DOI 10.1177/0278364912472245
   Hartley R., 2004, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hasan M., 2009, AMERICAN SOC GASTROI, V16, P1
   Hecht-Nielsen R, 1987, P INT C NEUR NETW
   Jianfei Liu, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562990
   Keller H, 2012, P IEEE RAS-EMBS INT, P859, DOI 10.1109/BioRob.2012.6290795
   Keller J, 2011, GASTROINTEST ENDOSC, V73, P22, DOI 10.1016/j.gie.2010.08.053
   Khan GN, 1996, IMAGE VISION COMPUT, V14, P763, DOI 10.1016/S0262-8856(96)01085-2
   Korin H, 1992, MAGNETIC RESONANCE M, P23
   KRISHNAN SM, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P610, DOI 10.1109/IEMBS.1994.411878
   Levenberg K., 1944, Q APPL MATH, P164, DOI DOI 10.1090/QAM/10666
   Lucas B. D., 1981, P INT JOINT C ART IN, P24
   Mahoney AW, 2012, P IEEE RAS-EMBS INT, P1632, DOI 10.1109/BioRob.2012.6290306
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Masson N, 2009, I S BIOMED IMAGING, P1350, DOI 10.1109/ISBI.2009.5193315
   Mori K, 2002, MED IMAGE ANAL, V6, P321, DOI 10.1016/S1361-8415(02)00089-0
   Obstein KL, 2013, WORLD J GASTROENTERO, V19, P431, DOI 10.3748/wjg.v19.i4.431
   Obstein KL, 2011, GASTROINTEST ENDOSC, V73, P315, DOI 10.1016/j.gie.2010.09.005
   Pasha SF, 2012, AM J GASTROENTEROL, V107, P363, DOI 10.1038/ajg.2011.436
   Postic G, 2002, AM J GASTROENTEROL, V97, P3182
   Reilink R., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P2076, DOI 10.1109/IROS.2011.6048383
   Reilink R, 2010, IEEE INT C INT ROBOT, P2339, DOI 10.1109/IROS.2010.5652248
   Rey JF, 2012, GASTROINTEST ENDOSC, V75, P373, DOI 10.1016/j.gie.2011.09.030
   Ruiter J, 2012, P IEEE RAS-EMBS INT, P761, DOI 10.1109/BioRob.2012.6290272
   Saxena A, 2007, IJCAI 07 P 20 INT JO
   SCHALKOFF R, 1992, PATTERN RECOGNITION
   Schalkoff R. J., 1997, ARTIFICIAL NEURAL NE
   SHERWOOD L, 2007, HUMAN PHYSL CELLS SY
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Siciliano B, 2009, ADV TXB CONTR SIG PR, P1
   Stein GP, 2000, IEEE INT VEH S IV200
   Suzuki K, 2012, INT J BIOMED IMAGING, V2012, DOI 10.1155/2012/792079
   Suzuki T, 1999, P 1999 IEEE IEEJ JSA
   Szura M, 2012, SURG ENDOSC, V26, P632, DOI 10.1007/s00464-011-1930-8
   Thormahlen T, 2002, FALK S MED IM GASTR
   Tian H, 2001, MED BIOL ENG COMPUT, V39, P8, DOI 10.1007/BF02345260
   Troccaz J, 2012, MED ROBOTICS
   Valdastri P, 2012, SURG ENDOSC, V26, P1238, DOI 10.1007/s00464-011-2054-x
   Valdastri P, 2012, ANNU REV BIOMED ENG, V14, P397, DOI 10.1146/annurev-bioeng-071811-150006
   van der Stap N, 2012, P IEEE RAS-EMBS INT, P13, DOI 10.1109/BioRob.2012.6290804
   van der Stap N, 2013, SURG ENDOSC, V27, P3539, DOI 10.1007/s00464-013-3003-7
   Vital Signs Cancer screening colorectal cancer, VIT SIGNS CANC SCREE
   Wang XN, 2010, IEEE ENG MED BIO, P4375, DOI 10.1109/IEMBS.2010.5627100
   Wilson S, 2005, WDIC2005 APRS WORKSH, V1
   Xia S., 2003, SYSTEMICS CYBERN INF, V1, P7
   Zabulis X, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3921, DOI 10.1109/IROS.2008.4650969
   Zhang Z, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P1653
   Zhenghao Shi, 2010, Proceedings Second International Symposium on Networking and Network Security (ISNNS 2010), P23
NR 59
TC 11
Z9 11
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD NOV
PY 2013
VL 59
IS 3
BP 185
EP 196
DI 10.1016/j.artmed.2013.09.002
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 270EC
UT WOS:000328300700005
PM 24188575
DA 2023-04-20
ER

PT J
AU Mahapatra, D
   Schueffler, P
   Tielbeek, JAW
   Buhmann, JM
   Vos, FM
AF Mahapatra, Dwarikanath
   Schueffler, Peter
   Tielbeek, Jeroen A. W.
   Buhmann, Joachim M.
   Vos, Franciscus M.
TI A Supervised Learning Approach for Crohn's Disease Detection Using
   Higher-Order Image Statistics and a Novel Shape Asymmetry Measure
SO JOURNAL OF DIGITAL IMAGING
LA English
DT Article
DE Crohn's Disease; Detection; Classifiers; Features
ID PATTERN-CLASSIFICATION; MAGNETIC-RESONANCE; MR; REGISTRATION; SEVERITY;
   MODEL; CT
AB Increasing incidence of Crohn's disease (CD) in the Western world has made its accurate diagnosis an important medical challenge. The current reference standard for diagnosis, colonoscopy, is time-consuming and invasive while magnetic resonance imaging (MRI) has emerged as the preferred noninvasive procedure over colonoscopy. Current MRI approaches assess rate of contrast enhancement and bowel wall thickness, and rely on extensive manual segmentation for accurate analysis. We propose a supervised learning method for the identification and localization of regions in abdominal magnetic resonance images that have been affected by CD. Low-level features like intensity and texture are used with shape asymmetry information to distinguish between diseased and normal regions. Particular emphasis is laid on a novel entropy-based shape asymmetry method and higher-order statistics like skewness and kurtosis. Multi-scale feature extraction renders the method robust. Experiments on real patient data show that our features achieve a high level of accuracy and perform better than two competing methods.
C1 [Mahapatra, Dwarikanath; Schueffler, Peter; Buhmann, Joachim M.] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
   [Tielbeek, Jeroen A. W.; Vos, Franciscus M.] Univ Amsterdam, Acad Med Ctr, Dept Radiol, NL-1105 AZ Amsterdam, Netherlands.
   [Vos, Franciscus M.] Delft Univ Technol, Quantitat Imaging Grp, Delft, Netherlands.
   [Mahapatra, Dwarikanath] Dept Comp Sci, CH-8092 Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; University of
   Amsterdam; Academic Medical Center Amsterdam; Delft University of
   Technology
RP Mahapatra, D (通讯作者)，Dept Comp Sci, CAB F61-1,Univ Str 6, CH-8092 Zurich, Switzerland.
EM dmahapatra@gmail.com
RI Buhmann, Joachim/AAU-4760-2020; Schüffler, Peter/C-1821-2018; Tielbeek,
   Jeroen/AAC-3608-2019
OI Schüffler, Peter/0000-0002-1353-8921; 
FU European Community [270379]
FX This research was partly funded from the European Community's Seventh
   Framework Programme (FP7/2007-2013): the VIGOR++ Project (grant
   agreement number 270379).
CR ATASOY S, 2011, MICCAI, V6893, P83
   Avni U, 2011, LECT NOTES COMPUT SC, V6893, P199, DOI 10.1007/978-3-642-23626-6_25
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Berks M, 2011, LECT NOTES COMPUT SC, V6801, P510, DOI 10.1007/978-3-642-22092-0_42
   Bhushan M, 2011, LECT NOTES COMPUT SC, V6891, P476, DOI 10.1007/978-3-642-23623-5_60
   Bodily KD, 2006, RADIOLOGY, V238, P505, DOI 10.1148/radiol.2382041159
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng J, 2011, LECT NOTES COMPUT SC, V6893, P91, DOI 10.1007/978-3-642-23626-6_12
   Davatzikos C, 2008, NEUROBIOL AGING, V29, P514, DOI 10.1016/j.neurobiolaging.2006.11.010
   DEVALOIS RL, 1982, VISION RES, V22, P545, DOI 10.1016/0042-6989(82)90113-4
   Fuchs TJ, 2011, COMPUT MED IMAG GRAP, V35, P515, DOI 10.1016/j.compmedimag.2011.02.006
   Horsthuis K, 2008, RADIOLOGY, V247, P64, DOI 10.1148/radiol.2471070611
   IGLESIAS JE, 2011, MICCAI, V6893, P58
   IRVING B, 2011, MICCAI, V6893, P133
   JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391
   Kelm BM, 2011, LECT NOTES COMPUT SC, V6893, P25, DOI 10.1007/978-3-642-23626-6_4
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kovalev VA, 1999, IEEE T IMAGE PROCESS, V8, P346, DOI 10.1109/83.748890
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu Z, 2011, LECT NOTES COMPUT SC, V6893, P124, DOI 10.1007/978-3-642-23626-6_16
   Mahapatra Dwarikanath, 2012, Abdominal Imaging. Computational and Clinical Applications. Proceedings of the 4th International Workshop. Held in Conjunction with MICCAI 2012, P97, DOI 10.1007/978-3-642-33612-6_11
   Mahapatra D, 2008, 13 INT C BIOM ENG, P639
   MAHAPATRA D, 2011, P MICCAI, V6893, P420
   Mahapatra D, 2008, SPIE HVEI, P1
   Mahapatra D, 2012, IEEE T IMAGE PROCESS, V21, P170, DOI 10.1109/TIP.2011.2162738
   Mahapatra D, 2010, LECT NOTES COMPUT SC, V6361, P493
   Mahapatra D, 2011, IEEE T BIO-MED ENG, V58, P991, DOI 10.1109/TBME.2010.2093576
   Mahapatra D, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P953, DOI 10.1109/ICME.2008.4607594
   Mahapatra D, 2008, I S BIOMED IMAGING, P1119, DOI 10.1109/ISBI.2008.4541197
   Mahapatra D, 2008, LECT NOTES COMPUT SC, V5241, P771, DOI 10.1007/978-3-540-85988-8_92
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MARY JY, 1989, GUT, V30, P983, DOI 10.1136/gut.30.7.983
   MONTILLO A, 2011, MICCAI, V6801, P184
   Pauly O, 2011, LECT NOTES COMPUT SC, V6893, P239, DOI 10.1007/978-3-642-23626-6_30
   Petrou M, 2006, IEEE T IMAGE PROCESS, V15, P3020, DOI 10.1109/TIP.2006.877516
   Rimola J, 2009, GUT, V58, P1113, DOI 10.1136/gut.2008.167957
   Schunk Klaus, 2002, Top Magn Reson Imaging, V13, P409, DOI 10.1097/00002142-200212000-00005
   Verma R, 2008, ACAD RADIOL, V15, P966, DOI 10.1016/j.acra.2008.01.029
   Vos FM, 2012, IEEE ENG MED BIO, P3974, DOI 10.1109/EMBC.2012.6346837
   Xu R, 2011, LECT NOTES COMPUT SC, V6893, P183, DOI 10.1007/978-3-642-23626-6_23
   Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008
NR 42
TC 11
Z9 12
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0897-1889
EI 1618-727X
J9 J DIGIT IMAGING
JI J. Digit. Imaging
PD OCT
PY 2013
VL 26
IS 5
BP 920
EP 931
DI 10.1007/s10278-013-9576-9
PG 12
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA 223VF
UT WOS:000324838900013
PM 23392736
OA Green Published, Green Submitted
DA 2023-04-20
ER

PT J
AU Bevilacqua, V
AF Bevilacqua, Vitoantonio
TI Three-dimensional virtual colonoscopy for automatic polyps detection by
   artificial neural network approach: New tests on an enlarged cohort of
   polyps
SO NEUROCOMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Conference on Intelligent Computing (ICIC)
CY AUG 11-14, 2011
CL Zhengzhou, PEOPLES R CHINA
SP IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Sci Fdn China
DE Computer-aided diagnosis system; Supervised artificial neural network;
   Image processing and segmentation; Three-dimensional virtual
   colonoscopy; Colonic polyps detection
ID COMPUTER-AIDED DETECTION; FALSE POSITIVES; REDUCTION; MODEL;
   COLONOGRAPHY; SEGMENTATION; FRAMEWORK; NODULES
AB Introduction and objective: In computer aided diagnosis (CAD) tools searching for colonrectal polyps and based on three dimensions virtual colonoscopy (3DVC) using computed tomography (CT) images, the reduction of the occurrence of false-positives (FPs) still represents a challenge because they are source of unreliability. Following an encouraging previous supervised approach Bevilacqua et al., Three-dimensional Virtual Colonoscopy for Polyps Detection by Supervised Artificial Neural Networks D.-S. Huang et al. (Eds.): ICIC, LNBI 6840, Springer-Verlag, Berlin Heidelberg, (2011), pp. 596-603, the aim of this work is to discuss, in details, how the adopted strategies, designed and tested on an initial reduced data set, reveals good performance and robustness in terms of FPs reduction on an enlarged cohort of new cases.
   Materials and methods: At the beginning, materials consisted only in 10 different polyps, diagnosed, by expert radiologists, in 6 different patients, scanning 16 rows helical CT multi slices with a resolution of I mm. Moreover from those 10 polyps only 7 polyps were initially used for the analysis, excluding 2 tumors with diameter bigger than I cm, and one polyp hardly recognizable due to fecal stool. In this paper, thanks to a new accurate phase of collecting data, materials grow impressively and then consist in total of 43 polyps all useful for the study. The whole data set was merged by using the former data set of colonrectal exams from the clinical operative unit called "Sezione di Diagnostica per Immagini" of Di.M.I.M.P. of Policlinico of Bad and the new ones coming from two new collaborations: the Oncology department of Faculty of Medicine of University of Pisa participating, as the former, to the IMPACT study (Italian Multicenter Polyps Accuracy CTC Study) Regge, Linear and nonlinear feedforward neural network classifiers: a comprehensive understanding, J. Intell. Syst, 9 (1) 1999, 1-38 and, more recently, the operative unit of radiology of the "Istituto Tumori Giovanni Paolo II" of Bad. Starting from computed tomography colonography (CTC) images, several volumes were scanned by means of three different supervised artificial neural networks (ANNs) architectures based on error back propagation training algorithm Huang and Ma, Linear and nonlinear feedforward neural network classifiers: a comprehensive understanding, J. Intell. Syst, 9 (1) 1999, 1-38. All the training sets were built by using polyps and non-polyps sub-volume samples, whose dimensions were correlated to the volume of the polyps to be detected.
   Results: The performance of the best ANN architecture, trained by using a training set of 27 sessile polyps from the new 43 available dataset, were evaluated in terms of FPs and false-negatives and compared to the results shown in Bevilacqua et al., Three-dimensional Virtual Colonoscopy for Polyps Detection by Supervised Artificial Neural Networks D.-S. Huang et al. (Eds.): ICIC, LNBI 6840, Springer-Verlag, Berlin Heidelberg, (2011), pp. 596-603 where a cross validation strategy was used to overcome the small number of the old available dataset Huang, The bottleneck behaviour in linear feedforward neural network classifiers and their breakthrough, J. Comput Sci. Technol., 14 (1) 1999, 34-43. Good performances in terms of generalization and robustness of the previous work, are then shown by the fact that the free-response operator characteristic analysis do not change significantly thanks to the enlargement of the available data.
   Conclusions: This testing determined that the supervised ANN approach is consistent and reveals good performance; at the same time it is fairly intuitive that it is necessary to train a method by using polyps and non-polyps samples and that, for this reason, the overall performance could be improved by a larger dataset diagnosed by expert radiologists. (C) 2012 Elsevier B.V. All rights reserved.
C1 Politecn Bari, Dipartimento Elettrotecn & Elettron, I-70126 Bari, Italy.
C3 Politecnico di Bari
RP Bevilacqua, V (通讯作者)，Politecn Bari, Dipartimento Elettrotecn & Elettron, Via Orabona 4, I-70126 Bari, Italy.
EM bevilacqua@poliba.it
RI Bevilacqua, Vitoantonio/AAF-5588-2020
OI Bevilacqua, Vitoantonio/0000-0002-3088-0788
CR Bellotti R, 2007, MED PHYS, V34, P4901, DOI 10.1118/1.2804720
   Bevilacqua V., 2011, LNBI, V6840, P596
   Bevilacqua V, 2009, LECT NOTES COMPUT SC, V5754, P965, DOI 10.1007/978-3-642-04070-2_102
   Chen D, 2006, LECT NOTES COMPUT SC, V4091, P372
   FULLERTON GD, 1980, MED PHYSICS MONOGRAP, V6, P125
   Gabrielli F., EPIDEMIOLOGIA
   Huang D.-S., 1996, SYSTEMATIC THEORY NE
   Huang DS, 2008, IEEE T NEURAL NETWOR, V19, P2099, DOI 10.1109/TNN.2008.2004370
   Huang Deshuang, 1999, Journal of Computer Science and Technology (English Language Edition), V14, P34, DOI 10.1007/BF02952485
   Huang DS, 1998, IEEE T SYST MAN CY B, V28, P477, DOI 10.1109/3477.678658
   Huang DS, 1999, INT J PATTERN RECOGN, V13, P1083, DOI 10.1142/S0218001499000604
   HUANG DS, 1999, J INTELLIGENT SYSTEM, V9, P1
   International Commissioning on Radiation Units and Measurements, 2008, J ICRU, V8
   LEE JSJ, 1987, IEEE T ROBOTIC AUTOM, V3, P142, DOI 10.1109/JRA.1987.1087088
   Macari M, 2005, RADIOLOGY, V237, P819, DOI 10.1148/radiol.2373041717
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Regge D., 2009, J AM MED ASS, V301
   Suzuki K, 2005, ACAD RADIOL, V12, P191, DOI 10.1016/j.acra.2004.11.017
   Suzuki K, 2001, NEURAL PROCESS LETT, V13, P43, DOI 10.1023/A:1009639214138
   Suzuki K., MED PHYS, P30
   Suzuki K, 2006, MED PHYS, V33, P3814, DOI 10.1118/1.2349839
   van Ginneken B, 2010, MED IMAGE ANAL, V14, P707, DOI 10.1016/j.media.2010.05.005
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Yoshida H, 2005, ABDOM IMAGING, V30, P26, DOI 10.1007/s00261-004-0244-x
NR 24
TC 22
Z9 23
U1 0
U2 36
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0925-2312
J9 NEUROCOMPUTING
JI Neurocomputing
PD SEP 20
PY 2013
VL 116
SI SI
BP 62
EP 75
DI 10.1016/j.neucom.2012.03.026
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 172AI
UT WOS:000320971900009
DA 2023-04-20
ER

PT J
AU DiMagno, MJ
   DiMagno, EP
AF DiMagno, Matthew J.
   DiMagno, Eugene P.
TI Chronic pancreatitis
SO CURRENT OPINION IN GASTROENTEROLOGY
LA English
DT Review
DE chronic pancreatitis; exocrine pancreatic insufficiency; pain
ID ISLET AUTOTRANSPLANTATION; EXOCRINE INSUFFICIENCY; CELIAC-DISEASE;
   ENZYMES; PAIN; PANCREATECTOMY; MALDIGESTION; CIMETIDINE; DIAGNOSIS;
   EFFICACY
AB Purpose of reviewWe review selected important clinical observations reported in 2012.
   Recent findingsCeliac disease is a risk factor for pancreatitis. Patients with recurrent acute pancreatitis likely have chronic pancreatitis, do not benefit from pancreatic sphincterotomy, and may not benefit from biliary sphincterotomy. Analysis of endoscopic ultrasonography (EUS) images with an artificial neural network (ANN) program may improve chronic pancreatitis diagnosis compared with clinical interpretation of images. In a multicenter, randomized controlled trial of chronic pancreatitis patients, 90000 USP U of pancreatin with meals decreased fat malabsorption compared with placebo. Detection of visceral pain in chronic pancreatitis predicts pain relief from various treatments, but nonvisceral pain due to altered central pain processing may respond to agents such as pregabalin. Predictors of surgical pain relief include onset of symptoms less than 3 years and preoperatively no opioid use and less than five endoscopic procedures. Total pancreatectomy for presumed painful chronic pancreatitis remains controversial.
   SummaryCeliacs are at risk for pancreatitis. The diagnosis of chronic pancreatitis may be enhanced by ANN analysis of EUS imaging. Treatment of fat malabsorption requires 90000 USP U of lipase with meals. Relief of pain from organ directed treatment of chronic pancreatitis may depend upon timing of interventions and whether pain is visceral or nonvisceral.
C1 [DiMagno, Matthew J.] Univ Michigan, Sch Med, Ann Arbor, MI 48109 USA.
   [DiMagno, Eugene P.] Mayo Clin, Coll Med, Dept Internal Med, Div Gastroenterol & Hepatol, Rochester, MN USA.
C3 University of Michigan System; University of Michigan; Mayo Clinic
RP DiMagno, MJ (通讯作者)，Univ Michigan, Sch Med, Dept Internal Med, Div Gastroenterol & Hepatol, 1150 W Med Ctr Dr,Room 6520,MSRB I, Ann Arbor, MI 48109 USA.
EM mdimagno@umich.edu
FU National Institutes of Health [R21 AA017271]; Michigan Institute for
   Clinical and Health Research (MICHR)
FX M.J.D. receives research support from the National Institutes of Health
   (R21 AA017271) and the Michigan Institute for Clinical and Health
   Research (MICHR). M.J.D. received honoraria from Springer (New York, NY,
   USA) for an article published in Current Gastroenterology Reports and
   the British Medical Journal for articles published in BMJ Point of Care.
   E. P. D. has no financial or other relationship(s) to disclose.
CR Ali UA, 2012, ARCH SURG-CHICAGO, V147, P925, DOI 10.1001/archsurg.2012.1094
   Ammann RW, 1997, PANCREAS, V14, P215, DOI 10.1097/00006676-199704000-00001
   Bahuva R, 2012, PANCREAS, V42, P6
   Bellin MD, 2013, PANCREAS, V42, P317, DOI 10.1097/MPA.0b013e3182681182
   Bellin Melena D, 2012, Hosp Pract (1995), V40, P80, DOI 10.3810/hp.2012.08.992
   Bhardwaj P, 2009, GASTROENTEROLOGY, V136, P149, DOI 10.1053/j.gastro.2008.09.028
   Bouwense SAW, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042096
   Carroccio A, 2006, CLIN GASTROENTEROL H, V4, P455, DOI 10.1016/j.cgh.2005.12.027
   Cote GA, 2012, GASTROENTEROLOGY, V143, P1502, DOI 10.1053/j.gastro.2012.09.006
   DIMAGNO EP, 1973, NEW ENGL J MED, V288, P813, DOI 10.1056/NEJM197304192881603
   DIMAGNO EP, 1972, GASTROENTEROLOGY, V63, P25
   DIMAGNO EP, 1977, NEW ENGL J MED, V296, P1318, DOI 10.1056/NEJM197706092962304
   Forsmark CE, 2012, GASTROENTEROLOGY, V143, P533, DOI 10.1053/j.gastro.2012.07.029
   Homma T, 1997, PANCREAS, V15, P14, DOI 10.1097/00006676-199707000-00002
   LAYER P, 1994, GASTROENTEROLOGY, V107, P1481, DOI 10.1016/0016-5085(94)90553-3
   Ludvigsson JF, 2007, CLIN GASTROENTEROL H, V5, P1347, DOI 10.1016/j.cgh.2007.06.002
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644
   Patel RS, 1999, GASTROINTEST ENDOSC, V50, P823, DOI 10.1016/S0016-5107(99)70166-5
   Rabsztyn A, 2001, AM J GASTROENTEROL, V96, P1096
   Razavi D, 2011, PANCREATOLOGY, V11, P525, DOI 10.1159/000331773
   Reddy N, 2010, PANCREAS, V39, P1342
   REGAN PT, 1978, MAYO CLIN PROC, V53, P79
   REGAN PT, 1980, GASTROENTEROLOGY, V78, P484
   REGAN PT, 1979, GASTROENTEROLOGY, V77, P285
   REGAN PT, 1977, NEW ENGL J MED, V297, P854, DOI 10.1056/NEJM197710202971603
   Sadr-Azodi O, 2012, CLIN GASTROENTEROL H, V10, P1136, DOI 10.1016/j.cgh.2012.06.023
   Saftoiu A, 2012, CLIN GASTROENTEROL H, V10, P84, DOI 10.1016/j.cgh.2011.09.014
   Sikkens ECM, 2012, PANCREATOLOGY, V12, P71, DOI 10.1016/j.pan.2011.12.010
   Siriwardena AK, 2012, GASTROENTEROLOGY, V143, P655, DOI 10.1053/j.gastro.2012.05.046
   Sutherland DER, 2012, J AM COLL SURGEONS, V214, P409, DOI 10.1016/j.jamcollsurg.2011.12.040
   Thorat V, 2012, ALIMENT PHARM THER, V36, P426, DOI 10.1111/j.1365-2036.2012.05202.x
   Yin Z, 2012, ARCH SURG-CHICAGO, V147, P961, DOI 10.1001/archsurg.2012.2005
NR 32
TC 11
Z9 11
U1 0
U2 12
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0267-1379
EI 1531-7056
J9 CURR OPIN GASTROEN
JI Curr. Opin. Gastroenterol.
PD SEP
PY 2013
VL 29
IS 5
BP 531
EP 536
DI 10.1097/MOG.0b013e3283639370
PG 6
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 247CI
UT WOS:000326591300007
PM 23852141
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Hoffman, MR
   Jones, CA
   Geng, ZX
   Abelhalim, SM
   Walczak, CC
   Mitchell, AR
   Jiang, JJ
   McCulloch, TM
AF Hoffman, Matthew R.
   Jones, Corinne A.
   Geng, Zhixian
   Abelhalim, Suzan M.
   Walczak, Chelsea C.
   Mitchell, Alyssa R.
   Jiang, Jack J.
   McCulloch, Timothy M.
TI Classification of High-Resolution Manometry Data According to
   Videofluoroscopic Parameters Using Pattern Recognition
SO OTOLARYNGOLOGY-HEAD AND NECK SURGERY
LA English
DT Article
DE high-resolution manometry; pharyngeal swallow; MBSImP; videofluoroscopy
ID FIBEROPTIC ENDOSCOPIC EVALUATION; MODIFIED BARIUM SWALLOW; PHARYNGEAL
   SWALLOW; NEURAL-NETWORKS; ASPIRATION; DYSPHAGIA; IMPAIRMENTS; EXERCISE;
   EVENTS; STROKE
AB Objective To determine if pattern recognition techniques applied to high-resolution manometry (HRM) spatiotemporal plots of the pharyngeal swallow can identify features of disordered swallowing reported on the Modified Barium Swallow Impairment Profile (MBSImP).
   Study Design Case series evaluating new method of data analysis.
   Setting University hospital.
   Subjects and Methods Simultaneous HRM and videofluoroscopy was performed on 30 subjects (335 swallows) with dysphagia. Videofluoroscopic studies were scored according to the MBSImP guidelines while HRM plots were analyzed using a novel program. Pattern recognition using a multilayer perceptron artificial neural network (ANN) was performed to determine if 7 pharyngeal components of the MBSImP as well as penetration/aspiration status could be identified from the HRM plot alone. Receiver operating characteristic (ROC) analysis was also performed.
   Results MBSImP parameters were identified correctly as normal or disordered at an average rate of approximately 91% (area under the ROC curve ranged from 0.902 to 0.981). Classifications incorporating two MBSImP parameters resulted in classification accuracies over 93% (area under the ROC curve ranged from 0.963 to 0.989).
   Conclusion Pattern recognition coupled with multiparameter quantitative analysis of HRM spatiotemporal plots can be used to identify swallowing abnormalities, which are currently assessed using videofluoroscopy. The ability to provide quantitative, functional data at the bedside while avoiding radiation exposure makes HRM an appealing tool to supplement and, at times, replace traditional videofluoroscopic studies.
C1 [Hoffman, Matthew R.; Jones, Corinne A.; Geng, Zhixian; Abelhalim, Suzan M.; Walczak, Chelsea C.; Mitchell, Alyssa R.; Jiang, Jack J.; McCulloch, Timothy M.] Univ Wisconsin, Sch Med & Publ Hlth, Div Otolaryngol Head & Neck Surg, Dept Surg, Madison, WI 53792 USA.
C3 University of Wisconsin System; University of Wisconsin Madison
RP McCulloch, TM (通讯作者)，Univ Wisconsin, Sch Med & Publ Hlth, Ctr Clin Sci, Dept Surg,Div Otolaryngol Head & Neck Surg, 600 Highland Ave,Box 7375, Madison, WI 53792 USA.
EM mccull@surgery.wisc.edu
RI Jones, Corinne/K-7775-2019
OI Jiang, Jack J./0000-0002-3070-4952; Hoffman, Matthew/0000-0002-1923-0039
FU NIH [R21 DC011130A, F31 DC012495]
FX NIH grant numbers R21 DC011130A and F31 DC012495. The sponsor/funding
   source had no role in the design and conduct of this study.
CR Aviv JE, 1997, LARYNGOSCOPE, V107, P1254, DOI 10.1097/00005537-199709000-00018
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   BECK T J, 1990, Dysphagia, V5, P118, DOI 10.1007/BF02412634
   Bonilha HS, 2013, DYSPHAGIA, V28, P77, DOI 10.1007/s00455-012-9415-z
   Cook I J, 1989, Dysphagia, V4, P8, DOI 10.1007/BF02407397
   COOK IJ, 1992, GASTROENTEROLOGY, V103, P1229, DOI 10.1016/0016-5085(92)91508-2
   Croghan John E., 1994, Dysphagia, V9, P141, DOI 10.1007/BF00341256
   CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2
   Gullung JL, 2012, ANN OTO RHINOL LARYN, V121, P738, DOI 10.1177/000348941212101107
   Hila A, 2001, J CLIN GASTROENTEROL, V33, P355, DOI 10.1097/00004836-200111000-00003
   Hiss SG, 2003, LARYNGOSCOPE, V113, P1386, DOI 10.1097/00005537-200308000-00023
   Hoffman MR, 2013, LARYNGOSCOPE, V123, P713, DOI 10.1002/lary.23655
   JACOB P, 1989, GASTROENTEROLOGY, V97, P1469, DOI 10.1016/0016-5085(89)90391-0
   Kendall KA, 2001, ARCH OTOLARYNGOL, V127, P1224, DOI 10.1001/archotol.127.10.1224
   Lawson Georges, 2006, Curr Opin Otolaryngol Head Neck Surg, V14, P437, DOI 10.1097/MOO.0b013e3280106314
   Leder SB, 1998, DYSPHAGIA, V13, P19, DOI 10.1007/PL00009544
   Martin-Harris B, 2008, DYSPHAGIA, V23, P392, DOI 10.1007/s00455-008-9185-9
   Martin-Harris B, 2007, J SPEECH LANG HEAR R, V50, P585, DOI 10.1044/1092-4388(2007/041)
   MCCONNEL FMS, 1988, ARCH OTOLARYNGOL, V114, P1413
   McCulloch TM, 2010, ANN OTO RHINOL LARYN, V119, P369, DOI 10.1177/000348941011900602
   Mielens JD, 2012, J SPEECH LANG HEAR R, V55, P892, DOI 10.1044/1092-4388(2011/11-0088)
   Omari TI, 2011, GASTROENTEROLOGY, V140, P1454, DOI 10.1053/j.gastro.2011.02.051
   Palmer JB, 2000, AM FAM PHYSICIAN, V61, P2453
   Palmer JB, 1998, ARCH PHYS MED REHAB, V79, P691, DOI 10.1016/S0003-9993(98)90046-6
   PERLMAN AL, 1992, J SPEECH HEAR RES, V35, P734, DOI 10.1044/jshr.3504.734
   Robbins J, 2007, ARCH PHYS MED REHAB, V88, P150, DOI 10.1016/j.apmr.2006.11.002
   Rosenbek JC, 1996, DYSPHAGIA, V11, P93, DOI 10.1007/BF00417897
   SCHNEIDER I, 1994, ANN OTO RHINOL LARYN, V103, P31, DOI 10.1177/000348949410300105
   Shaker R, 1997, AM J PHYSIOL-GASTR L, V272, pG1518, DOI 10.1152/ajpgi.1997.272.6.G1518
   Stoeckli SJ, 2003, DYSPHAGIA, V18, P53, DOI 10.1007/s00455-002-0085-0
NR 30
TC 27
Z9 30
U1 0
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0194-5998
EI 1097-6817
J9 OTOLARYNG HEAD NECK
JI Otolaryngol. Head Neck Surg.
PD JUL
PY 2013
VL 149
IS 1
BP 126
EP 133
DI 10.1177/0194599813489506
PG 8
WC Otorhinolaryngology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology; Surgery
GA 285XD
UT WOS:000329427400018
PM 23728150
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Burdescu, DD
   Mihai, CG
   Stanescu, L
   Brezovan, M
AF Burdescu, Dumitru Dan
   Mihai, Cristian Gabriel
   Stanescu, Liana
   Brezovan, Marius
TI Automatic image annotation and semantic based image retrieval for
   medical domain
SO NEUROCOMPUTING
LA English
DT Article
DE Image annotation; Image segmentation; Relevance models; Ontologies;
   Content based image retrieval
ID TRANSLATION
AB Automatic image annotation is the process of assigning meaningful words to an image taking into account its content. This process is of great interest as it allows indexing, retrieving, and understanding of large collections of image data. This paper presents a system used in the medical domain for three distinct tasks: image annotation, semantic based image retrieval and content based image retrieval. An original image segmentation algorithm based on a hexagonal structure was used to perform the segmentation of medical images. Image's regions are described using a vocabulary of blobs generated from image features using the K-means clustering algorithm. The annotation and semantic based retrieval task is evaluated for two annotation models: Cross Media Relevance Model and Continuous-space Relevance Model. Semantic based image retrieval is performed using the methods provided by the annotation models. The ontology used by the annotation process was created in an original manner starting from the information content provided by the Medical Subject Headings (MeSH). The experiments were made using a database containing color images retrieved from medical domain using an endoscope and related to digestive diseases. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Burdescu, Dumitru Dan; Mihai, Cristian Gabriel; Brezovan, Marius] Univ Craiova, Fac Automat Comp & Elect, Craiova, Romania.
   [Stanescu, Liana] Univ Craiova, Fac Automat Comp & Elect, Software Engn Dept, Craiova, Romania.
C3 University of Craiova; University of Craiova
RP Stanescu, L (通讯作者)，Univ Craiova, Fac Automat Comp & Elect, Bvd Decebal 107, Craiova, Romania.
EM Burdescu@software.ucv.ro; mihai_gabriel@software.ucv.ro;
   stanescu@software.ucv.ro; marius.brezovan@software.ucv.ro
RI Brezovan, Marius/AAV-8004-2020
OI Brezovan, Marius/0000-0002-5586-3693
CR [Anonymous], 2003, P ACM C RES DEV INFO, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]
   [Anonymous], NON TRADITIONAL REF
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Biren S., 2007, SEMANTIC BASED VISUA
   Bresell Anders, 2006, Appl Bioinformatics, V5, P225, DOI 10.2165/00822942-200605040-00005
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Burdescu D. D., 2009, NEW METHOD SEGMENTAT
   Chronaki CE, 1997, MED INFORM, V22, P337, DOI 10.3109/14639239709010905
   Daniel E., 2003, NSF SYMPOSIUM ON NEX
   Daniel EA, 2003, THESIS
   DELBIMBO A, 2001, VISUAL INFORMATION R
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   GEVERS T, 2004, IMAGE SEARCH ENGINES
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Iancu Andreea, 2010, Proceedings 2010 International Multiconference on Computer Science and Information Technology (IMCSIT 2010), P717
   Igor F. A., 2010, PROCEEDINGS OF THE 1
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Kherfi ML, 2004, INT C PATT RECOG, P961, DOI 10.1109/ICPR.2004.1334418
   Kherfi Mohammed Lamine, 2006, SEMANTIC BASED VISUA
   Kononowicz AA, 2008, LECT NOTES COMPUT SC, V5103, P188, DOI 10.1007/978-3-540-69389-5_22
   Lavrenko V., 2004, PROCEEDINGS OF THE 1
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mihai Gabriel, 2010, Proceedings 2010 International Multiconference on Computer Science and Information Technology (IMCSIT 2010), P735
   Mori Y., 1999, MISRM99 FIRST INTERN
   Noy Natalya F., ONTOLOGY DEVELOPMENT
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Smith Jennifer Bradford, 1997, THESIS
   Stanescu L., 2006, INTERNATIONAL MULTI
   Steffen Staab, 2009, HDB ONTOLOGIES INT H
   Uschold M, 1996, KNOWL ENG REV, V11, P93, DOI 10.1017/S0269888900007797
NR 32
TC 19
Z9 20
U1 0
U2 43
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JUN 3
PY 2013
VL 109
SI SI
BP 33
EP 48
DI 10.1016/j.neucom.2012.07.030
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 136QX
UT WOS:000318379600006
DA 2023-04-20
ER

PT J
AU Hou, JK
   Chang, M
   Nguyen, T
   Kramer, JR
   Richardson, P
   Sansgiry, S
   D'Avolio, LW
   El-Serag, HB
AF Hou, Jason K.
   Chang, Mimi
   Thien Nguyen
   Kramer, Jennifer R.
   Richardson, Peter
   Sansgiry, Shubhada
   D'Avolio, Leonard W.
   El-Serag, Hashem B.
TI Automated Identification of Surveillance Colonoscopy in Inflammatory
   Bowel Disease Using Natural Language Processing
SO DIGESTIVE DISEASES AND SCIENCES
LA English
DT Article
DE Crohn's disease; Ulcerative colitis; Machine learning; Automated
   retrieval console
ID ULCERATIVE-COLITIS; GUIDELINES; DIAGNOSIS; SYSTEM
AB Differentiating surveillance from non-surveillance colonoscopy for colorectal cancer in patients with inflammatory bowel disease (IBD) using electronic medical records (EMR) is important for practice improvement and research purposes, but diagnosis code algorithms are lacking. The automated retrieval console (ARC) is natural language processing (NLP)-based software that allows text-based document-level classification.
   The purpose of this study was to test the feasibility and accuracy of ARC in identifying surveillance and non-surveillance colonoscopy in IBD using EMR.
   We performed a split validation study of electronic reports of colonoscopy pathology for patients with IBD from the Michael E. DeBakey VA Medical Center. A gastroenterologist manually classified pathology reports as either derived from surveillance or non-surveillance colonoscopy. Pathology reports were randomly split into two sets: 70 % for algorithm derivation and 30 % for validation. An ARC generated classification model was applied to the validation set of pathology reports. The performance of the model was compared with manual classification for surveillance and non-surveillance colonoscopy.
   A total of 575 colonoscopy pathology reports were available on 195 IBD patients, of which 400 reports were designated as training and 175 as testing sets. Within the testing set, a total of 69 pathology reports were classified as surveillance by manual review, whereas the ARC model classified 66 reports as surveillance for a recall of 0.77, precision of 0.80, and specificity of 0.88.
   ARC was able to identify surveillance colonoscopy for IBD without customized software programming. NLP-based document-level classification may be used to differentiate surveillance from non-surveillance colonoscopy in IBD.
C1 [Hou, Jason K.; Chang, Mimi; Kramer, Jennifer R.; Richardson, Peter; Sansgiry, Shubhada; El-Serag, Hashem B.] Michael E DeBakey VA Med Ctr, Houston VA HSR&D Ctr Excellence, Houston, TX USA.
   [Hou, Jason K.; Chang, Mimi; Kramer, Jennifer R.; Richardson, Peter; Sansgiry, Shubhada; El-Serag, Hashem B.] Baylor Coll Med, Dept Med, Houston, TX 77030 USA.
   [Hou, Jason K.; El-Serag, Hashem B.] Baylor Coll Med, Dept Med, Sect Gastroenterol & Hepatol, Houston, TX 77030 USA.
   [Thien Nguyen; D'Avolio, Leonard W.] VA Boston Healthcare Syst, Massachusetts Vet Epidemiol Res & Informat Ctr MA, Cooperat Studies Coordinating Ctr, Jamaica Plain, MA USA.
   [D'Avolio, Leonard W.] Harvard Univ, Sch Med, Div Aging, Boston, MA USA.
C3 Baylor College of Medicine; Baylor College of Medicine; Baylor College
   of Medicine; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); Harvard University; VA Boston Healthcare System;
   Harvard University; Harvard Medical School
RP Hou, JK (通讯作者)，1709 Dryden Rd,Suite 8-40, Houston, TX 77030 USA.
EM jkhou@bcm.edu
FU American College of Gastroenterology Junior Faculty Development Award;
   Houston VA HSR&D Center of Excellence [HFP90-020]; Department of
   Veterans Affairs, Veterans Health Administration, Health Services
   Research and Development Service [MRP05-305]; National Institutes of
   Health/National Institute of Diabetes and Digestive and Kidney Disease
   Center [P30 DK56338, K24 DK078154-05]
FX The research reported here was supported by the American College of
   Gastroenterology Junior Faculty Development Award to J.K. Hou, a pilot
   grant from the Houston VA HSR&D Center of Excellence (HFP90-020) to J.K.
   Hou, the Department of Veterans Affairs, Veterans Health Administration,
   Health Services Research and Development Service, grant MRP05-305 to
   J.R. Kramer, and the National Institutes of Health/National Institute of
   Diabetes and Digestive and Kidney Disease Center grant P30 DK56338, K24
   DK078154-05.
CR [Anonymous], MALLET MACHINE LEARN
   D'Avolio LW, 2010, J AM MED INFORM ASSN, V17, P375, DOI 10.1136/jamia.2009.001412
   Farraye FA, 2010, GASTROENTEROLOGY, V138, P746, DOI [10.1053/j.gastro.2009.12.035, 10.1053/j.gastro.2009.12.037]
   Farwell WR, 2011, JNCI-J NATL CANCER I, V103, P885, DOI 10.1093/jnci/djr108
   Kornbluth A, 2010, AM J GASTROENTEROL, V105, P501, DOI 10.1038/ajg.2009.727
   Kottachchi D, 2009, CAN J GASTROENTEROL, V23, P613, DOI 10.1155/2009/691850
   Savova GK, 2010, J AM MED INFORM ASSN, V17, P507, DOI 10.1136/jamia.2009.001560
   Shiner B, 2012, J EVAL CLIN PRACT, V18, P698, DOI 10.1111/j.1365-2753.2011.01634.x
   Velayos FS, 2010, GASTROENTEROLOGY, V139, P1511, DOI 10.1053/j.gastro.2010.07.039
NR 9
TC 25
Z9 25
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0163-2116
EI 1573-2568
J9 DIGEST DIS SCI
JI Dig. Dis. Sci.
PD APR
PY 2013
VL 58
IS 4
BP 936
EP 941
DI 10.1007/s10620-012-2433-8
PG 6
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Gastroenterology & Hepatology
GA 126HX
UT WOS:000317605800007
PM 23086115
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Sgourakis, G
   Gockel, I
   Lang, H
AF Sgourakis, George
   Gockel, Ines
   Lang, Hauke
TI Endoscopic and surgical resection of T1a/T1b esophageal neoplasms: A
   systematic review
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Superficial esophageal cancer; Endoscopic resection; Mucosal
   infiltration; Submucosal involvement; Recurrent tumor; Controversies in
   treatment; Squamous cell carcinoma; Adenocarcinoma; Lymphatic invasion;
   Vascular invasion; Submucosal layer; Superficial submucosal layer;
   Middle third submucosal layer; Deep third submucosal layer; Esophageal
   cancer; Endoscopic gastrointestinal surgical procedures; Endoscopic
   gastrointestinal surgery; Lymph node dissection; Dysplasia
ID SQUAMOUS-CELL CARCINOMA; HIGH-GRADE DYSPLASIA; LYMPH-NODE METASTASIS;
   OBLIQUE ASPIRATION MUCOSECTOMY; MUCOSAL RESECTION; BARRETTS-ESOPHAGUS;
   SUBMUCOSAL DISSECTION; EARLY ADENOCARCINOMA; GASTRIC-CANCER;
   INTRAEPITHELIAL NEOPLASIA
AB AIM: To investigate potential therapeutic recommendations for endoscopic and surgical resection of T1a/T1b esophageal neoplasms.
   METHODS: A thorough search of electronic data-bases MEDLINE, Embase, Pubmed and Cochrane Library, from 1997 up to January 2011 was performed. An analysis was carried out, pooling the effects of outcomes of 4241 patients enrolled in 80 retrospective studies. For comparisons across studies, each reporting on only one endoscopic method, we used a random effects meta-regression of the log-odds of the outcome of treatment in each study. "Neural networks" as a data mining technique was employed in order to establish a prediction model of lymph node status in superficial submucosal esophageal carcinoma. Another data mining technique, the " feature selection and root cause analysis", was used to identify the most important predictors of local recurrence and metachronous cancer development in endoscopically resected patients, and lymph node positivity in squamous carcinoma (SCC) and adenocarcinoma (ADC) separately in surgically resected patients.
   RESULTS: Endoscopically resected patients: Low grade dysplasia was observed in 4% of patients, high grade dysplasia in 14.6%, carcinoma in situ in 19%, mucosal cancer in 54%, and submucosal cancer in 16% of patients. There were no significant differences between endoscopic mucosal resection and endoscopic submucosal dissection (ESD) for the following parameters: complications, patients submitted to surgery, positive margins, lymph node positivity, local recurrence and metachronous cancer. With regard to piecemeal resection, ESD performed better since the number of cases was significantly less [coefficient: -7.709438, 95% CI: (-11.03803, -4.380844), P < 0.001]; hence local recurrence rates were significantly lower [coefficient: -4.033528, 95% CI: (-6.151498, -1.915559), P < 0.01]. A higher rate of esophageal stenosis was observed following ESD [coefficient: 7.322266, 95% CI: (3.810146, 10.83439), P < 0.001]. A significantly greater number of SCC patients were submitted to surgery (log-odds, ADC: -2.1206 +/- 0.6249 vs SCC: 4.1356 +/- 0.4038, P < 0.05). The odds for re-classification of tumor stage after endoscopic resection were 53% and 39% for ADC and SCC, respectively. Local tumor recurrence was best predicted by grade 3 differentiation and piecemeal resection, metachronous cancer development by the carcinoma in situ component, and lymph node positivity by lymphovascular invasion. With regard to surgically resected patients: Significant differences in patients with positive lymph nodes were observed between ADC and SCC [coefficient: 1.889569, 95% CI: (0.3945146, 3.384624), P < 0.01). In contrast, lymphovascular and microvascular invasion and grade 3 patients between histologic types were comparable, the respective rank order of the predictors of lymph node positivity was: Grade 3, lymphovascular invasion (L+), microvascular invasion (V+), submucosal (Sm) 3 invasion, Sm2 invasion and Sm1 invasion. Histologic type (ADC/SCC) was not included in the model. The best predictors for SCC lymph node positivity were Sm3 invasion and (V+). For ADC, the most important predictor was (L+).
   CONCLUSION: Local tumor recurrence is predicted by grade 3, metachronous cancer by the carcinoma in-situ component, and lymph node positivity by L+. T1b cancer should be treated with surgical resection. (C) 2013 Baishideng. All rights reserved.
C1 [Sgourakis, George; Gockel, Ines; Lang, Hauke] Johannes Gutenberg Univ Hosp Mainz, Dept Gen & Abdominal Surg, D-55131 Mainz, Germany.
   [Sgourakis, George] Red Cross Hosp Athens, Surg Dept 2, Athens 11526, Greece.
   [Sgourakis, George] Red Cross Hosp Athens, Surg Oncol Unit Korgialenio Benakio, Athens 11526, Greece.
C3 Johannes Gutenberg University of Mainz
RP Sgourakis, G (通讯作者)，Red Cross Hosp Athens, Surg Dept 2, 11 Mantzarou St, Athens 11526, Greece.
EM ggsgourakis@yahoo.gr
OI Sgourakis, George/0000-0002-7900-2003
CR ALBRECHT RF, 1993, ARTIFICIAL NEURAL NE
   Amano T, 2007, PATHOL INT, V57, P759, DOI 10.1111/j.1440-1827.2007.02171.x
   Araki K, 2002, CANCER-AM CANCER SOC, V94, P570, DOI 10.1002/cncr.10190
   Birkmeyer JD, 2002, NEW ENGL J MED, V346, P1128, DOI 10.1056/NEJMsa012337
   Bollschweiler E, 2006, ENDOSCOPY, V38, P149, DOI 10.1055/s-2006-924993
   Buskens CJ, 2004, GASTROINTEST ENDOSC, V60, P703, DOI 10.1016/S0016-5107(04)02017-6
   Buttar NS, 2001, GASTROINTEST ENDOSC, V54, P682, DOI 10.1067/mge.2001.119875
   Cao Y, 2009, ENDOSCOPY, V41, P751, DOI 10.1055/s-0029-1215053
   Chaves DM, 2010, CLINICS, V65, P377, DOI 10.1590/S1807-59322010000400005
   Chennat J, 2009, AM J GASTROENTEROL, V104, P2684, DOI 10.1038/ajg.2009.465
   Chino O, 1998, J SURG ONCOL, V67, P18, DOI 10.1002/(SICI)1096-9098(199801)67:1<18::AID-JSO4>3.0.CO;2-P
   Chino O, 1997, SURG TODAY, V27, P9, DOI 10.1007/BF01366933
   Ciocirlan M, 2007, ENDOSCOPY, V39, P24, DOI 10.1055/s-2006-945182
   Conio M, 2005, WORLD J GASTROENTERO, V11, P6650, DOI 10.3748/wjg.v11.i42.6650
   Eguchi T, 2006, MODERN PATHOL, V19, P475, DOI 10.1038/modpathol.3800557
   Ell C, 2000, GASTROENTEROLOGY, V118, P670, DOI 10.1016/S0016-5085(00)70136-3
   Ell C, 2007, GASTROINTEST ENDOSC, V65, P3, DOI 10.1016/j.gie.2006.04.033
   ENDO M, 1993, ENDOSCOPY, V25, P672, DOI 10.1055/s-2007-1010430
   Endo M, 1997, Dis Esophagus, V10, P155
   Espinel J, 2009, REV ESP ENFERM DIG, V101, P403, DOI 10.4321/s1130-01082009000600005
   Fujishiro M, 2009, DIGEST ENDOSC, V21, P109, DOI 10.1111/j.1443-1661.2009.00837.x
   Gen P, 2008, CANCER-AM CANCER SOC, V112, P1020, DOI [10.1002/cncr.23265, 10.1002/cncr23265]
   Gerke H, 2011, GASTROINTEST ENDOSC, V74, P761, DOI 10.1016/j.gie.2011.06.009
   Gockel I, 2009, J SURG ONCOL, V100, P191, DOI 10.1002/jso.21336
   Goda K, 2009, DIS ESOPHAGUS, V22, P453, DOI 10.1111/j.1442-2050.2009.00942.x
   GOSEKI N, 1992, CANCER, V69, P1088
   Higuchi K, 2007, ENDOSCOPY, V39, P36, DOI 10.1055/s-2006-945148
   Hull MJ, 2006, AM J SURG PATHOL, V30, P114, DOI 10.1097/01.pas.0000180438.56528.a0
   IDE H, 1994, WORLD J SURG, V18, P321, DOI 10.1007/BF00316810
   Iguchi Y, 2009, J GASTROEN HEPATOL, V24, P1733, DOI 10.1111/j.1440-1746.2009.05892.x
   Ikeda Y, 1996, ANN THORAC SURG, V62, P835, DOI 10.1016/S0003-4975(96)00392-X
   Ishihara R, 2008, GASTROINTEST ENDOSC, V68, P1066, DOI 10.1016/j.gie.2008.03.1114
   Ishii N, 2010, SURG ENDOSC, V24, P335, DOI 10.1007/s00464-009-0560-x
   *JAP SOC ES DIS, 2001, GUID CLIN PATH STUD
   Kim DU, 2008, J GASTROEN HEPATOL, V23, P619, DOI 10.1111/j.1440-1746.2007.05259.x
   Kimura H, 1999, HEPATO-GASTROENTEROL, V46, P285
   Kuwano H, 2002, SURGERY, V131, pS14, DOI 10.1067/msy.2002.119289
   KUWANO H, 1992, J SURG ONCOL, V50, P149, DOI 10.1002/jso.2930500304
   Larghi A, 2005, GASTROINTEST ENDOSC, V62, P16, DOI 10.1016/S0016-5107(05)00319-6
   Leers JM, 2011, ANN SURG, V253, P271, DOI 10.1097/SLA.0b013e3181fbad42
   Lewis JT, 2008, AM J SURG PATHOL, V32, P566, DOI 10.1097/PAS.0b013e31815bf8c7
   Lin LF, 2008, J CHIN MED ASSOC, V71, P347, DOI 10.1016/S1726-4901(08)70137-0
   Liu LX, 2005, AM J SURG PATHOL, V29, P1079
   Lopes CV, 2007, SURG ENDOSC, V21, P820, DOI 10.1007/s00464-006-9187-3
   Maish MS, 2004, ANN THORAC SURG, V78, P1777, DOI 10.1016/j.athoracsur.2004.04.064
   Makuuchi H, 1997, Diagn Ther Endosc, V3, P211, DOI 10.1155/DTE.3.211
   Manner H, 2008, AM J GASTROENTEROL, V103, P2589, DOI 10.1111/j.1572-0241.2008.02083.x
   Matsumoto M, 2006, J GASTROINTEST SURG, V10, P1016, DOI 10.1016/j.gassur.2006.01.009
   Nakajima Y, 2002, JPN J CANCER RES, V93, P305, DOI 10.1111/j.1349-7006.2002.tb02173.x
   Naritaka Y, 2001, HEPATO-GASTROENTEROL, V48, P1015
   Natsugoe S, 2004, J GASTROINTEST SURG, V8, P631, DOI 10.1016/j.gassur.2004.02.004
   Nijhawan PK, 2000, GASTROINTEST ENDOSC, V52, P328, DOI 10.1067/mge.2000.105777
   Noguchi H, 2000, SURG LAPARO ENDO PER, V10, P343
   Nomura T, 2000, ENDOSCOPY, V32, P277, DOI 10.1055/s-2000-7379
   Nonaka K, 2010, WORLD J GASTRO ENDOS, V2, P69, DOI 10.4253/wjge.v2.i2.69
   Ohashi K, 2002, VIRCHOWS ARCH, V441, P350, DOI 10.1007/s00428-002-0689-7
   OHNO S, 1991, CANCER, V68, P335, DOI 10.1002/1097-0142(19910715)68:2<335::AID-CNCR2820680222>3.0.CO;2-I
   Ono S, 2009, GASTROINTEST ENDOSC, V70, P860, DOI 10.1016/j.gie.2009.04.044
   Ota M, 2003, SURG ENDOSC, V17, P1429, DOI 10.1007/s00464-002-8708-y
   PARAF F, 1995, AM J SURG PATHOL, V19, P183, DOI 10.1097/00000478-199502000-00007
   Pech O, 2007, ENDOSCOPY, V39, P30, DOI 10.1055/s-2006-945040
   Pech O, 2004, AM J GASTROENTEROL, V99, P1226, DOI 10.1111/j.1572-0241.2004.30628.x
   Pechz O, 2008, GUT, V57, P1200, DOI 10.1136/gut.2007.142539
   Peters FR, 2008, GASTROINTEST ENDOSC, V67, P604, DOI 10.1016/j.gie.2007.08.039
   Pouw RE, 2008, ENDOSCOPY, V40, P892, DOI 10.1055/s-2008-1077675
   Prasad GA, 2007, AM J GASTROENTEROL, V102, P2380, DOI 10.1111/j.1572-0241.2007.01419.x
   Prasad GA, 2009, GASTROENTEROLOGY, V137, P815, DOI 10.1053/j.gastro.2009.05.059
   Repici A, 2010, GASTROINTEST ENDOSC, V71, P715, DOI 10.1016/j.gie.2009.11.020
   Rice TW, 1998, ANN THORAC SURG, V65, P787, DOI 10.1016/S0003-4975(97)01387-8
   Scheil-Bertram S, 2008, MODERN PATHOL, V21, P961, DOI 10.1038/modpathol.2008.73
   SCHMIDT LW, 1986, GASTROENTEROLOGY, V91, P1456, DOI 10.1016/0016-5085(86)90201-5
   Schroder W, 2009, J GASTROINTEST SURG, V13, P223, DOI 10.1007/s11605-008-0719-0
   Sepesi B, 2010, J AM COLL SURGEONS, V210, P418, DOI 10.1016/j.jamcollsurg.2010.01.003
   Sgourakis G, 2012, AM SURGEON, V78, P195
   Sgourakis G, 2011, EXPERT REV ANTICANC, V11, P601, DOI [10.1586/ERA.10.150, 10.1586/era.10.150]
   Shimizu Y, 2001, GASTROINTEST ENDOSC, V54, P190, DOI 10.1067/mge.2001.116877
   Shiozaki H, 2002, J SURG ONCOL, V79, P166, DOI 10.1002/jso.10074
   Soehendra N, 1997, ENDOSCOPY, V29, P380
   SOGA J, 1982, CANCER, V50, P1641, DOI 10.1002/1097-0142(19821015)50:8<1641::AID-CNCR2820500830>3.0.CO;2-9
   Stahl M, 2010, ANN ONCOL, V21, pv46, DOI 10.1093/annonc/mdq163
   Takeo Y, 2001, HEPATO-GASTROENTEROL, V48, P453
   Takeshita K, 1997, GUT, V40, P123, DOI 10.1136/gut.40.1.123
   Tanabe S, 2008, GASTROINTEST ENDOSC, V67, P814, DOI 10.1016/j.gie.2007.11.034
   Teoh AYB, 2010, J CLIN GASTROENTEROL, V44, pE190, DOI 10.1097/MCG.0b013e3181ce52fb
   Tomita N, 2008, PATHOL INT, V58, P282, DOI 10.1111/j.1440-1827.2008.02224.x
   TSUTSUI S, 1995, AM J GASTROENTEROL, V90, P1858
   Urabe Y, 2011, J GASTROEN HEPATOL, V26, P275, DOI 10.1111/j.1440-1746.2010.06503.x
   Vieth M, 2004, ENDOSCOPY, V36, P776, DOI 10.1055/s-2004-825802
   Westerterp M, 2005, VIRCHOWS ARCH, V446, P497, DOI 10.1007/s00428-005-1243-1
   Wright A, 2005, AMIA ANN S P, P829
   YOKOYAMA A, 1995, CANCER, V76, P928, DOI 10.1002/1097-0142(19950915)76:6<928::AID-CNCR2820760604>3.0.CO;2-5
   YOSHIKANE H, 1994, AM J GASTROENTEROL, V89, P702
   Zehetner J, 2011, J THORAC CARDIOV SUR, V141, P39, DOI 10.1016/j.jtcvs.2010.08.058
NR 93
TC 96
Z9 109
U1 0
U2 24
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 8226 REGENCY DR, PLEASANTON, CA 94588 USA
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD MAR 7
PY 2013
VL 19
IS 9
BP 1424
EP 1437
DI 10.3748/wjg.v19.i9.1424
PG 14
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 104NT
UT WOS:000316001700013
PM 23539431
OA Green Published, hybrid
DA 2023-04-20
ER

PT J
AU Malekian, V
   Amirfattahi, R
   Sadri, S
   Mokhtari, M
   Aghaie, A
   Rezaeian, M
AF Malekian, Vahid
   Amirfattahi, Rasoul
   Sadri, Saeid
   Mokhtari, Mojgan
   Aghaie, Alireza
   Rezaeian, Mandie
TI Computer aided measurement of sub-epithelial collagen band in colon
   biopsies for collagenous colitis diagnosis
SO MICRON
LA English
DT Review
DE Collagenous colitis; Sub-epithelial collagen; Computer-assisted
   diagnosis; Adaboost; MLP neural network; Wavelet decomposition
ID MICROSCOPIC COLITIS
AB This paper presents a novel computer aided technique for screening of Collagenous Colitis (CC). CC is a type of microscopic colitis mostly characterized by chronic watery diarrhea which is a common feature with a range of other etiologies. Routine paraclinical tests from CC patients such as endoscopic and radiographic studies are usually normal, and diagnosis must be made by biopsy. The gold standard for a confirmative diagnosis of CC is to measure the thickness of the sub-epithelial collagen (SEC) in colon tissue samples. Visual inspection of microscopic samples is often time-consuming, cumbersome and subject to human errors. This fact demonstrates the necessity of developing an automated method which assists pathologists in evaluating histopathological samples more accurately in the busy clinical environment. To the best of our knowledge, this is the first time that a computer-assisted diagnosis algorithm has been applied to CC detection. The proposed method uses a pre-trained Multi-Layer Perceptron neural network to segment SEC band in colon tissue images. We compared a variety of different color and texture descriptors and explore the best set of features for this task. The investigation of the proposed method shows 94.5% specificity and 95.6% sensitivity rate. (C) 2012 Elsevier Ltd. All rights reserved.
C1 [Malekian, Vahid] Amirkabir Univ Technol, Dept Biomed Engn, Tehran Polytech, Tehran 158754413, Iran.
   [Amirfattahi, Rasoul; Sadri, Saeid; Rezaeian, Mandie] Isfahan Univ Technol, Dept Elect & Comp Engn, Digital Signal Proc Res Lab, Esfahan 8415683111, Iran.
   [Mokhtari, Mojgan] Isfahan Univ Med Sci, Dept Pathol, Esfahan 734618174, Iran.
   [Aghaie, Alireza] Islamic Azad Univ, Dept Comp, Najafabad Branch, Esfahan, Iran.
C3 Amirkabir University of Technology; Isfahan University of Technology;
   Isfahan University Medical Science; Islamic Azad University
RP Malekian, V (通讯作者)，Amirkabir Univ Technol, Dept Biomed Engn, Tehran Polytech, Tehran 158754413, Iran.
EM V.malekian@aut.ac.ir; fattahi@cc.iut.ac.ir; sadri@cc.iut.ac.ir;
   mokhtari@med.mui.ac.ir; ali.r.aghaei@gmail.com; m.rezaeian@ec.iut.ac.ir
RI mokhtari, mojgan/V-6377-2017; Amirfattahi, Rassoul/AAA-7793-2022
OI Rezaeian, Mahdie/0000-0003-2333-1593; Sadri, Saeid/0000-0002-3954-5089
CR Bonderup OK, 2003, GUT, V52, P248, DOI 10.1136/gut.52.2.248
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Esgiar A N, 1998, IEEE Trans Inf Technol Biomed, V2, P197, DOI 10.1109/4233.735785
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Freeman HJ, 2008, WORLD J GASTROENTERO, V14, P1643, DOI 10.3748/wjg.14.1643
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gonzales RC., 2002, DIGITAL IMAGE PROCES
   Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865
   Hagan MT, 1996, NEURAL NETWORK DESIG
   Hough P.V.C., 1962, US Patent, Patent No. [3,969,654, 3969654]
   Krishnan MMR, 2012, MICRON, V43, P352, DOI 10.1016/j.micron.2011.09.016
   Malekian V., 2011, MVIP C TEHR, P1535
   Masood K., 2008, ANN BMVA, V4, P1
   Nyhlin N, 2006, ALIMENT PHARM THER, V23, P1525, DOI 10.1111/j.1365-2036.2006.02913.x
   Pardi DS, 2007, GUT, V56, P504, DOI 10.1136/gut.2006.105890
   Pardi DS, 2002, AM J GASTROENTEROL, V97, P794
   Pascua MF, 2010, CLIN MED INSIGHTS-GA, V3, P11
   Pattreson D., 1996, ARTIFICIAL NEURAL NE
   Penney DP, 2002, BIOTECH HISTOCHEM, V77, P237, DOI 10.1080/714028210
   Sands BE, 2004, GASTROENTEROLOGY, V126, P1518, DOI 10.1053/j.gastro.2004.02.072
   Tchernev EB, 2005, NEURAL COMPUT, V17, P1646, DOI 10.1162/0899766053723096
   van der Wouden EJ, 2009, NETH J MED, V67, P41
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Webster J., 2009, MED INSTRUMENTATION
   Williams JJ, 2010, AGE AGEING, V39, P162, DOI 10.1093/ageing/afp243
NR 25
TC 4
Z9 4
U1 0
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0968-4328
J9 MICRON
JI Micron
PD FEB
PY 2013
VL 45
BP 59
EP 67
DI 10.1016/j.micron.2012.10.015
PG 9
WC Microscopy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Microscopy
GA 081OY
UT WOS:000314332700008
PM 23200274
DA 2023-04-20
ER

PT J
AU Eisner, R
   Greiner, R
   Tso, V
   Wang, HL
   Fedorak, RN
AF Eisner, Roman
   Greiner, Russell
   Tso, Victor
   Wang, Haili
   Fedorak, Richard N.
TI A Machine-Learned Predictor of Colonic Polyps Based on Urinary
   Metabolomics
SO BIOMED RESEARCH INTERNATIONAL
LA English
DT Article
ID FECAL OCCULT-BLOOD; COLORECTAL-CANCER; SKELETAL-MUSCLE; AVERAGE-RISK;
   SELECTION; NORMALIZATION; PROFILE; TESTS; MASS
AB We report an automated diagnostic test that uses the NMR spectrum of a single spot urine sample to accurately distinguish patients who require a colonoscopy from those who do not. Moreover, our approach can be adjusted to tradeoff between sensitivity and specificity. We developed our system using a group of 988 patients (633 normal and 355 who required colonoscopy) who were all at average or above-average risk for developing colorectal cancer. We obtained a metabolic profile of each subject, based on the urine samples collected from these subjects, analyzed via H-1-NMR and quantified using targeted profiling. Each subject then underwent a colonoscopy, the gold standard to determine whether he/she actually had an adenomatous polyp, a precursor to colorectal cancer. The metabolic profiles, colonoscopy outcomes, and medical histories were then analysed using machine learning to create a classifier that could predict whether a future patient requires a colonoscopy. Our empirical studies show that this classifier has a sensitivity of 64% and a specificity of 65% and, unlike the current fecal tests, allows the administrators of the test to adjust the tradeoff between the two.
C1 [Eisner, Roman; Greiner, Russell] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
   [Tso, Victor; Fedorak, Richard N.] Univ Alberta, Zeidler Ledcor Ctr, Div Gastroenterol, Edmonton, AB T6G 2X8, Canada.
   [Wang, Haili] Univ Alberta Hosp, WC Mackenzie Hlth Sci Ctr 2D2 29, Dept Surg, Edmonton, AB T6G 2R7, Canada.
C3 University of Alberta; University of Alberta; University of Alberta
RP Eisner, R (通讯作者)，Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
EM reisner@ualberta.ca
RI Greiner, Russell/AAQ-4502-2020
OI Greiner, Russell/0000-0001-8327-934X; Fedorak,
   Richard/0000-0002-7382-0080
CR Allison JE, 1996, NEW ENGL J MED, V334, P155, DOI 10.1056/NEJM199601183340304
   Arlt A., 2012, ONCOGENE
   Bollard ME, 2005, NMR BIOMED, V18, P143, DOI 10.1002/nbm.935
   Cheng Y, 2012, J PROTEOME RES, V11, P1354, DOI 10.1021/pr201001a
   Craig A, 2006, ANAL CHEM, V78, P2262, DOI 10.1021/ac0519312
   Dieterle F, 2006, ANAL CHEM, V78, P4281, DOI 10.1021/ac051632c
   Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004
   Eisner R, 2011, METABOLOMICS, V7, P25, DOI 10.1007/s11306-010-0232-9
   Farshidfar F, 2012, GENOME MED, V4, DOI 10.1186/gm341
   Frank E, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P1269, DOI 10.1007/978-0-387-09823-4_66
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   HOLMES E, 1994, ANAL BIOCHEM, V220, P284, DOI 10.1006/abio.1994.1339
   Huang T, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016036
   Imperiale TF, 2004, NEW ENGL J MED, V351, P2704, DOI 10.1056/NEJMoa033403
   International Agency for Research on Cancer and World Health Organization, 2008, GLOBOCAN 2008
   Leddin DJ, 2010, CAN J GASTROENTEROL, V24, P705, DOI 10.1155/2010/683171
   Ma YL, 2012, ANN SURG, V255, P720, DOI 10.1097/SLA.0b013e31824a9a8b
   Madsen R, 2010, ANAL CHIM ACTA, V659, P23, DOI 10.1016/j.aca.2009.11.042
   Mal M, 2012, ANAL BIOANAL CHEM, V403, P483, DOI 10.1007/s00216-012-5870-5
   Maroun Jean, 2003, Chronic Dis Can, V24, P91
   Miyagi Y, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024143
   National Cancer Institute Web site, COL RECT CANC
   Nishiumi S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040459
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Pesarin F, 2001, MULTIVARIATE PERMUTA
   Provost FJ, 1997, ANAL VISUALIZATION C
   Qiu YP, 2010, J PROTEOME RES, V9, P1627, DOI 10.1021/pr901081y
   Qiu YP, 2009, J PROTEOME RES, V8, P4844, DOI 10.1021/pr9004162
   Russell S., 2002, ARTIF INTELL
   Scott M. J. J., 1998, P 9 BRIT MACH VIS C, P304
   Spratlin JL, 2009, CLIN CANCER RES, V15, P431, DOI 10.1158/1078-0432.CCR-08-1059
   Stretch C, 2012, J NUTR, V142, P14, DOI 10.3945/jn.111.147751
   Sun L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038845
   Taylor DP, 2011, GENET MED, V13, P737, DOI 10.1097/GIM.0b013e3182180c71
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tibshirani R., 2001, ELEMENTS STAT LEARNI
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang H., 2005, GASTROENTEROLOGY S, V140, pS40
   Wang HL, 2010, FUTURE ONCOL, V6, P1395, DOI [10.2217/fon.10.107, 10.2217/FON.10.107]
   Wang WZ, 2010, MOL BIOSYST, V6, P1947, DOI 10.1039/c004994h
   Weljie AM, 2006, ANAL CHEM, V78, P4430, DOI 10.1021/ac060209g
   Whitlock EP, 2008, ANN INTERN MED, V149, P638, DOI 10.7326/0003-4819-149-9-200811040-00245
   Wishart DS, 2008, TRAC-TREND ANAL CHEM, V27, P228, DOI 10.1016/j.trac.2007.12.001
   Wishart DS, 2013, NUCLEIC ACIDS RES, V41, pD801, DOI 10.1093/nar/gks1065
   Wong CKW, 2012, INT J COLORECTAL DIS, V27, P1657, DOI 10.1007/s00384-012-1518-3
   Xia JG, 2009, NUCLEIC ACIDS RES, V37, pW652, DOI 10.1093/nar/gkp356
NR 46
TC 26
Z9 27
U1 0
U2 11
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2314-6133
EI 2314-6141
J9 BIOMED RES INT
JI Biomed Res. Int.
PY 2013
VL 2013
AR 303982
DI 10.1155/2013/303982
PG 11
WC Biotechnology & Applied Microbiology; Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Research & Experimental Medicine
GA 252WQ
UT WOS:000327042100001
PM 24307992
OA Green Published, gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Segui, S
   Drozdzal, M
   Vilarino, F
   Malagelada, C
   Azpiroz, F
   Radeva, P
   Vitria, J
AF Segui, Santi
   Drozdzal, Michal
   Vilarino, Fernando
   Malagelada, Carolina
   Azpiroz, Fernando
   Radeva, Petia
   Vitria, Jordi
TI Categorization and Segmentation of Intestinal Content Frames for
   Wireless Capsule Endoscopy
SO IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE
LA English
DT Article
DE Image segmentation; informative frames; intestinal content; machine
   learning; wireless capsule endoscopy (WCE)
ID SMALL-BOWEL; TRANSIT-TIME; SYSTEM
AB Wireless capsule endoscopy (WCE) is a device that allows the direct visualization of gastrointestinal tract with minimal discomfort for the patient, but at the price of a large amount of time for screening. In order to reduce this time, several works have proposed to automatically remove all the frames showing intestinal content. These methods label frames as {intestinal content - clear} without discriminating between types of content (with different physiological meaning) or the portion of image covered. In addition, since the presence of intestinal content has been identified as an indicator of intestinal motility, its accurate quantification can show a potential clinical relevance. In this paper, we present a method for the robust detection and segmentation of intestinal content in WCE images, together with its further discrimination between turbid liquid and bubbles. Our proposal is based on a twofold system. First, frames presenting intestinal content are detected by a support vector machine classifier using color and textural information. Second, intestinal content frames are segmented into {turbid, bubbles, and clear} regions. We show a detailed validation using a large dataset. Our system outperforms previous methods and, for the first time, discriminates between turbid from bubbles media.
C1 [Segui, Santi; Drozdzal, Michal; Radeva, Petia; Vitria, Jordi] Univ Barcelona, Dept Matemat Aplicada & Anal, E-08007 Barcelona, Spain.
   [Segui, Santi; Drozdzal, Michal; Vilarino, Fernando; Radeva, Petia; Vitria, Jordi] Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
   [Vilarino, Fernando] Univ Autonoma Barcelona, Dept Comp Sci, E-08193 Barcelona, Spain.
   [Malagelada, Carolina; Azpiroz, Fernando] Univ Hosp Vall dHebron, Digest Syst Res Unit, Barcelona 08035, Spain.
C3 University of Barcelona; Autonomous University of Barcelona; Centre de
   Visio per Computador (CVC); Autonomous University of Barcelona; Hospital
   Universitari Vall d'Hebron
RP Segui, S (通讯作者)，Univ Barcelona, Dept Matemat Aplicada & Anal, E-08007 Barcelona, Spain.
EM ssegui@cvc.uab.es; michal.drozdzal@ub.edu; azpiroz.fernando@gmail.com;
   cmalagelada@gmail.com; fernando@cvc.uab.es; petia@cvc.uab.es;
   jordi.vitria@ub.edu
RI Vilarino, Fernando/AAU-4306-2020; Vitrià, Jordi/AAF-9668-2020; Segui,
   Santi/E-4860-2010; Radeva, Petia/I-3385-2015; Malagelada,
   Carolina/F-3743-2016
OI Vilarino, Fernando/0000-0002-7705-4141; Vitrià,
   Jordi/0000-0003-1484-539X; Segui, Santi/0000-0002-8603-138X; Radeva,
   Petia/0000-0003-0047-5172; Malagelada, Carolina/0000-0001-7097-1492;
   Azpiroz, Fernando/0000-0002-7327-960X
FU Given Imaging Ltd., Yoqneam Israel; MICINN [TIN2009-14404-C02,
   CSD2007-00018]
FX This work was supported in part by a Research Grant from Given Imaging
   Ltd., Yoqneam Israel, and by the MICINN Grant TIN2009-14404-C02 and
   CONSOLIDER-INGENIO 2010 Grant CSD2007-00018.
CR Aizerman M. A., 1964, AUTOMAT REM CONTR, V25, P821, DOI DOI 10.1234/12345678
   Bailey Trevor, 1995, INTERACTIVE SPATIAL
   Barrett K., 2006, PHYSL GASTROINTESTIN, V2
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Campisi P, 2002, IEEE T IMAGE PROCESS, V11, P37, DOI 10.1109/83.977881
   Ciaccio EJ, 2010, COMPUT METH PROG BIO, V100, P39, DOI 10.1016/j.cmpb.2010.02.005
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Fireman Z, 2003, GUT, V52, P390, DOI 10.1136/gut.52.3.390
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Hai V, 2006, INT C PATT RECOG, P980
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Igual L., 2008, 4th European Conference of the International Federation for Medical and Biological Engineering - ECIFMBE 2008, P1536
   Jung YS, 2008, INT CONF BIOMED, P859, DOI 10.1109/BMEI.2008.216
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Lee J, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1041
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mackiewicz M., 2011, NEW TECHNIQUES GASTR, V1
   Mail S., 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587630
   Malagelada C, 2012, NEUROGASTROENT MOTIL, V24, P223, DOI 10.1111/j.1365-2982.2011.01823.x
   Malagelada C, 2008, GASTROENTEROLOGY, V135, P1155, DOI 10.1053/j.gastro.2008.06.084
   Malagelada J.-R., 2010, DETERMINANTS GASTRIC
   Metzger YC, 2009, REP MED IMAG, V2, P7, DOI DOI 10.2147/RMI.S4227]
   Moglia Andrea, 2008, Recent Patents on Biomedical Engineering, V1, P24, DOI 10.2174/1874764710801010024
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Schulmann K, 2005, AM J GASTROENTEROL, V100, P27, DOI 10.1111/j.1572-0241.2005.40102.x
   Segui S, 2008, LECT NOTES COMPUT SC, V5008, P251
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Szczypinski PM, 2009, MED IMAGE ANAL, V13, P312, DOI 10.1016/j.media.2008.12.002
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Vilarino F., 2006, P 18 INT C PATT REC, P20
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Vu H, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P74, DOI 10.1109/ROBIO.2009.4912982
   Vu H, 2009, COMPUT BIOL MED, V39, P16, DOI 10.1016/j.compbiomed.2008.10.005
   Yagi Y., 2007, Inflammopharmacology, V15, P78, DOI 10.1007/s10787-006-0010-5
   Yamada T., 2011, PRINCIPLES CLIN GAST
NR 41
TC 28
Z9 29
U1 0
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1089-7771
EI 1558-0032
J9 IEEE T INF TECHNOL B
JI IEEE T. Inf. Technol. Biomed.
PD NOV
PY 2012
VL 16
IS 6
BP 1341
EP 1352
DI 10.1109/TITB.2012.2221472
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA 053JT
UT WOS:000312268300040
PM 24218705
DA 2023-04-20
ER

PT J
AU Karargyris, A
   Pouagare, M
   Karargyris, O
   Bourbakis, N
AF Karargyris, A.
   Pouagare, M.
   Karargyris, O.
   Bourbakis, N.
TI AUTOMATIC DETECTION OF SIMILARITIES AND DIFFERENCES BETWEEN SMALL BOWEL
   POLYPS AND ULCERS WITH A DATA MINING APPROACH IN WIRELESS CAPSULE
   ENDOSCOPY VIDEOS
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
LA English
DT Article
DE Medical imaging; wireless capsule endoscopy; blood-based; bleeding;
   protrusions; polyps; ulcers; small bowel; data mining
ID CT COLONOGRAPHY; COLOR; SEGMENTATION
AB Over the past decade Wireless Capsule Endoscopy (WCE) technology has become a very useful tool for diagnosing diseases within the human digestive tract. Using WCE physicians can examine the digestive tract in a minimum invasive way searching for pathological abnormalities such as bleeding, polyps, ulcers and Crohn's disease. In order for WCE to be more effective for gastroenterologists, engineers have developed software methods to automatically detect these diseases at high successful rate. Using proposed a synergistic methodology for automatic discovering polyps (protrusions) and ulcers in WCE video frames, a data mining approach is used that offers useful information about ulcers, polyps and normal tissues and their visual similarities. Finally, results of the methodology are given and statistical comparisons are also presented relevant to other works.
C1 [Karargyris, A.; Bourbakis, N.] Wright State Univ, Coll Engn, Assist Technol Res Ctr, Dayton, OH 45435 USA.
   [Pouagare, M.] WSU, Dayton, OH USA.
   [Karargyris, O.] KAT Hosp, Athens, Greece.
   [Bourbakis, N.] AIIS, Dayton, OH USA.
C3 University System of Ohio; Wright State University Dayton; University
   System of Ohio; Wright State University Dayton
RP Karargyris, A (通讯作者)，Wright State Univ, Coll Engn, Assist Technol Res Ctr, Dayton, OH 45435 USA.
EM akarargyris@gmail.com; okarargyris@gmail.com;
   nikolaos.bourbakis@wright.edu
FU AIIS Inc.
FX This work is partially supported by AIIS Inc.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   [Anonymous], 2008, WHAT I NEED KNOW COL
   [Anonymous], 2001, WELL CONN REP
   [Anonymous], 2007, INT J INF TECHNOL
   Barbosa DJC, 2009, IEEE ENG MED BIO, P6683, DOI 10.1109/IEMBS.2009.5334013
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen Dongqing, 2007, IEEE INT C IM PROC I, V5
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Haralick R.M., 1973, IEEE T SYSTEMS MAN C, V3
   Inoue T, 2001, IEEE IJCNN, P1449, DOI 10.1109/IJCNN.2001.939575
   Jerebko AK, 2003, P SOC PHOTO-OPT INS, V5031, P359, DOI 10.1117/12.480696
   Karargyris A., 2008, P 8 IEEE INT C BIOIN, P1
   Karargyris A, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P143, DOI 10.1109/LISSA.2009.4906730
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Karargyris A, 2009, I S BIOMED IMAGING, P554, DOI 10.1109/ISBI.2009.5193107
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karnam Umaprasanna S., CURRENT TREATMENT OP, V4, P15
   Kerker J, 2008, Z GASTROENTEROL, V46, P339, DOI 10.1055/s-2007-963774
   Konukoglu E, 2007, IEEE T MED IMAGING, V26, P1649, DOI 10.1109/TMI.2007.901429
   LAU PY, 2007, P INT C IEEE ENG MED
   Li BP, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P234, DOI 10.1109/WCICA.2008.4592930
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   MOGHADDAMZADEH A, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P83, DOI 10.1109/FUZZY.1994.343713
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   Sidhu R, 2007, GASTROENTEROL NURS, V30, P45, DOI 10.1097/00001610-200701000-00005
   SMITH SM, 1995, TR95SMS1 DEF RES AG
   Sosna J, 2003, AM J ROENTGENOL, V181, P1593, DOI 10.2214/ajr.181.6.1811593
   Thornton E, 2010, RADIOGRAPHICS, V30, P201, DOI 10.1148/rg.301095519
   Tkalcic M., 2003, IEEE REGION, V8, P304
   Vapnik Vladimir N., 1989, STAT LEARNING THEORY
   Aziz Faisal, EMEDICINE WEBSITE PE
   WEBSTER MA, 1985, J OPT SOC AM A, V2, P1124, DOI 10.1364/JOSAA.2.001124
   Yao JH, 2004, IEEE T MED IMAGING, V23, P1344, DOI 10.1109/TMI.2004.826941
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
   Zhao LX, 2006, IEEE T VIS COMPUT GR, V12, P885, DOI 10.1109/TVCG.2006.158
   [No title captured]
NR 38
TC 2
Z9 2
U1 0
U2 11
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-2130
EI 1793-6349
J9 INT J ARTIF INTELL T
JI Int. J. Artif. Intell. Tools
PD OCT
PY 2012
VL 21
IS 5
SI SI
AR 1240021
DI 10.1142/S0218213012400210
PG 18
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 031KD
UT WOS:000310637200003
DA 2023-04-20
ER

PT J
AU Saraf, SS
   Udupi, GR
   Hajare, SD
AF Saraf, Santosh S.
   Udupi, G. R.
   Hajare, Santosh D.
TI Analysis of Endoscopy Video Using Machine Learning Techniques
SO JOURNAL OF MEDICAL IMAGING AND HEALTH INFORMATICS
LA English
DT Article
DE Upper GI Endoscopy; Video Processing; Support Vector Machine; Neural
   Network; Machine Learning
ID CAPSULE ENDOSCOPY; WAVELET TRANSFORM; NEURAL-NETWORKS; CLASSIFICATION;
   IDENTIFICATION; DIAGNOSIS; TUTORIAL
AB Upper Gastro-Intestinal (GI) Endoscopy is used to observe the organs esophagus, stomach and duodenum. With the push endoscopy the video length is short with the quality of video dependent on the patient comfort compared to a fairly smooth video of Wireless Capsule Endoscopy (WCE). We present a method to identify organs using low level image features like color and texture using classifiers like Support Vector Machine, Neural Network etc. We report results comparable to that of WCE video. The scheme could be coupled with image based decision support systems for diagnosis of the respective organs.
C1 [Saraf, Santosh S.] Gogte Inst Technol, Dept Elect & Commun Engn, Res Ctr, Belgaum 560008, Karnataka, India.
   [Udupi, G. R.] Vishwanathrao Desphande Rural Inst Technol, Haliyal 581329, Karnataka, India.
   [Hajare, Santosh D.] KLE Hosp & Res Ctr, Dept Gastroenterol, Belgaum 560006, Karnataka, India.
C3 K.L.E. Academy of Higher Education & Research
RP Saraf, SS (通讯作者)，Gogte Inst Technol, Dept Elect & Commun Engn, Res Ctr, Belgaum 560008, Karnataka, India.
RI Saraf, Santosh S/F-1282-2018
OI Saraf, Santosh S/0000-0002-8105-7388
CR Acharya UR, 2009, J MECH MED BIOL, V9, P539, DOI 10.1142/S0219519409003152
   Acharya UR, 2008, J MECH MED BIOL, V8, P363, DOI 10.1142/S0219519408002668
   Anadan K., 2010, J MECH MED BIOL, V10, P683
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P1513, DOI 10.1016/S0167-8655(02)00390-2
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   Bishop Christopher M., 1995, NEURAL NETWORKS PATT, DOI DOI 10.5555/235248
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bresci G, 2004, J GASTROENTEROL, V39, P803, DOI 10.1007/s00535-003-1377-3
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Canu S., 2005, SVM KERNEL METHODS M
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Gay G, 2004, ENDOSCOPY, V36, P913, DOI 10.1055/s-2004-825868
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Kohavi R., 1998, MACH LEARN, V30, P271, DOI DOI 10.1023/A:1017181826899
   Krzanowski W. J., 2000, PRINCIPLES MULTIVARI
   Lee J, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1041
   Meghnefi F, 2004, J MECH MED BIOL, V4, P273, DOI 10.1142/S021951940400103X
   Menegaz G, 2001, IEEE IMAGE PROC, P173, DOI 10.1109/ICIP.2001.958981
   Messadi M, 2010, J MECH MED BIOL, V10, P467, DOI 10.1142/S0219519410003514
   Mezghani N, 2008, J MECH MED BIOL, V8, P45, DOI 10.1142/S0219519408002474
   Ng EYK, 2005, J MECH MED BIOL, V5, P165, DOI 10.1142/S0219519405001370
   Saraf Santosh S, 2010, Open Med Inform J, V4, P58, DOI 10.2174/1874431101004020058
   Saraf SS, 2009, J MECH MED BIOL, V9, P527, DOI 10.1142/S0219519409003097
   Seber G. A. F., 1984, MULTIVARIATE OBSERVA, DOI DOI 10.1002/9780470316641
   Soiwar G., 2001, P IEEE INT C FUZZ SY
   SPYRIDONOS P, 2006, P 9 MICCAI COP DENM
   Tang SJ, 2002, ENDOSCOPY, V34, P735, DOI 10.1055/s-2002-33448
   van der Walt C., 2006, P 16 ANN S PATT REC, P166
   Vapnik V., 1999, NATURE STAT LEARNING
NR 30
TC 2
Z9 2
U1 0
U2 5
PU AMER SCIENTIFIC PUBLISHERS
PI VALENCIA
PA 26650 THE OLD RD, STE 208, VALENCIA, CA 91381-0751 USA
SN 2156-7018
EI 2156-7026
J9 J MED IMAG HEALTH IN
JI J. Med. Imaging Health Inform.
PD JUN
PY 2012
VL 2
IS 2
BP 97
EP 101
DI 10.1166/jmihi.2012.1070
PG 5
WC Mathematical & Computational Biology; Radiology, Nuclear Medicine &
   Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology; Radiology, Nuclear Medicine &
   Medical Imaging
GA 066KL
UT WOS:000313219600001
DA 2023-04-20
ER

PT J
AU Kubota, K
   Kuroda, J
   Yoshida, M
   Ohta, K
   Kitajima, M
AF Kubota, Keisuke
   Kuroda, Junko
   Yoshida, Masashi
   Ohta, Keiichiro
   Kitajima, Masaki
TI Medical image analysis: computer-aided diagnosis of gastric cancer
   invasion on endoscopic images
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
LA English
DT Article
DE Computer-aided diagnosis; Pattern recognition; Medical image analysis;
   Gastric cancer; Depth of wall invasion; Endoscopic images
ID ARTIFICIAL NEURAL-NETWORK; FALSE POSITIVES; PERFORMANCE; TOMOGRAPHY;
   POLYPS; ENDOSONOGRAPHY; RADIOLOGISTS; SUPPRESSION; REDUCTION; LESIONS
AB The aim of this study was to investigate the efficacy of diagnosing depth of wall invasion of gastric cancer on endoscopic images using computer-aided pattern recognition.
   The back propagation algorithm was used for computer training. Data of 344 patients who underwent gastrectomy or endoscopic tumor resection between 2001 and 2010 and their 902 endoscopic images were collected. The images were divided into ten groups among which the number of patients and images were almost equally distributed according to T staging. The computer learning was performed using about 800 images from all but one group, and the accuracy rate of diagnosing the depth of wall invasion of gastric cancer was calculated using the remaining group of about 90 images. The various numbers of input layers, hidden layers, and learning counts were updated, and the ideal setting was decided. Similar learning and diagnostic procedures were repeated ten times using every group and all 902 images were tested. The accuracy rate was calculated based on the ideal setting.
   The most appropriate setting was a resolution of 16 x 16, a hidden layer of 240, and a learning count of 50. In the next step, using all the images on the ideal setting, the overall accuracy rate was 64.7%. The diagnostic accuracy was 77.2, 49.1, 51.0, and 55.3% in the T1, T2, T3, and T4 stagings, respectively. The accuracy was 68.9% in T1a(M) staging and 63.6% in T1b(SM) staging. The positive predictive values were 80.1, 41.6, 51.4, and 55.8% in the T1, T2, T3, and T4 staging, respectively. It was 69.2% in T1a(M) staging and 68.3% in T1b(SM) staging.
   Computer-aided diagnosis is useful for diagnosing depth of wall invasion of gastric cancer on endoscopic images.
C1 [Kubota, Keisuke; Kuroda, Junko; Yoshida, Masashi; Ohta, Keiichiro; Kitajima, Masaki] Int Univ Hlth & Welf, Dept Gastroenterol Surg, Mita Hosp, Minato Ku, Tokyo 1088329, Japan.
C3 International University of Health & Welfare
RP Kubota, K (通讯作者)，Int Univ Hlth & Welf, Dept Gastroenterol Surg, Mita Hosp, Minato Ku, Mita 1-4-3, Tokyo 1088329, Japan.
EM kubota@iuhw.ac.jp
RI Yoshida, Masashi/ABG-7085-2021
CR CHAN HP, 1987, MED PHYS, V14, P538, DOI 10.1118/1.596065
   Drukker K, 2005, RADIOLOGY, V237, P834, DOI 10.1148/radiol.2373041418
   Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822
   Gilhuijs KGA, 1998, MED PHYS, V25, P1647, DOI 10.1118/1.598345
   Horsch K, 2004, ACAD RADIOL, V11, P272, DOI 10.1016/S1076-6332(03)00719-0
   Japanese Gastric Cancer Association, 2010, JAP CLASS GASTR CARC
   Kienle P, 2002, DIGESTION, V66, P230, DOI 10.1159/000068360
   Kim HJ, 2005, RADIOLOGY, V236, P879, DOI 10.1148/radiol.2363041101
   Oda S, 2009, AM J ROENTGENOL, V193, pW397, DOI 10.2214/AJR.09.2431
   Polkowski M, 2004, ENDOSCOPY, V36, P617, DOI 10.1055/s-2004-814522
   Sakai K, 2003, FDN APPL DIGITAL IMA
   Shimoyama S, 2004, GASTROINTEST ENDOSC, V60, P50, DOI 10.1016/S0016-5107(04)01312-4
   Sobin L., 2009, TNM CLASSIFICATION M, V7th ed.
   Suzuki K, 2008, MED PHYS, V35, P694, DOI 10.1118/1.2829870
   Suzuki K, 2006, MED PHYS, V33, P3814, DOI 10.1118/1.2349839
   Suzuki K, 2009, PHYS MED BIOL, V54, pS31, DOI 10.1088/0031-9155/54/18/S03
   Tsendsuren T, 2006, WORLD J GASTROENTERO, V12, P43, DOI 10.3748/wjg.v12.i1.43
   Wakelin SJ, 2002, EUR J RADIOL, V41, P161, DOI 10.1016/S0720-048X(01)00418-1
   Yamashita K, 2008, AM J NEURORADIOL, V29, P1153, DOI 10.3174/ajnr.A1037
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
NR 20
TC 45
Z9 47
U1 1
U2 11
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0930-2794
EI 1432-2218
J9 SURG ENDOSC
JI Surg. Endosc.
PD MAY
PY 2012
VL 26
IS 5
BP 1485
EP 1489
DI 10.1007/s00464-011-2036-z
PG 5
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA 929ZG
UT WOS:000303103900041
PM 22083334
DA 2023-04-20
ER

PT J
AU Li, BP
   Meng, MQH
AF Li, Baopu
   Meng, Max Q. -H.
TI Tumor Recognition in Wireless Capsule Endoscopy Images Using Textural
   Features and SVM-Based Feature Selection
SO IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE
LA English
DT Article
DE Feature selection; support vector machine (SVM); texture; tumor
   recognition; wireless capsule endoscopy (WCE) image
ID CLASSIFICATION
AB Tumor in digestive tract is a common disease and wireless capsule endoscopy (WCE) is a relatively new technology to examine diseases for digestive tract especially for small intestine. This paper addresses the problem of automatic recognition of tumor for WCE images. Candidate color texture feature that integrates uniform local binary pattern and wavelet is proposed to characterize WCE images. The proposed features are invariant to illumination change and describe multiresolution characteristics of WCE images. Two feature selection approaches based on support vector machine, sequential forward floating selection and recursive feature elimination, are further employed to refine the proposed features for improving the detection accuracy. Extensive experiments validate that the proposed computer-aided diagnosis system achieves a promising tumor recognition accuracy of 92.4% in WCE images on our collected data.
C1 [Li, Baopu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Li, Baopu; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese University of Hong Kong
RP Li, BP (通讯作者)，Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM bpli@ee.cuhk.edu.hk; max@ee.cuhk.edu.hk
RI Meng, Max Q.-H./C-8078-2009; Meng, Q./GSI-6185-2022; meng,
   meng/GWZ-7461-2022
FU Hong Kong Research Grants Council (RGC) [415709, 415611]; Innovation and
   Technology Support Programme, Hong Kong [ITS/430/09]
FX Manuscript received January 18, 2011; revised January 9, 2012, and
   August 23, 2011; accepted January 19, 2012. Date of publication January
   24, 2012; date of current version May 4, 2012. This work was supported
   by the Hong Kong Research Grants Council (RGC) General Research Fund
   under Grant 415709 and Grant 415611, and by the Innovation and
   Technology Support Programme (ITS/430/09) in Hong Kong.
CR Adler DG., 2003, HOSP PHYS, V39, P14
   [Anonymous], 2007, CANC STAT HONG KONG
   Baopu Li, 2009, 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2009), P498, DOI 10.1109/IROS.2009.5354726
   Bejakovic S, 2009, IEEE INT CONF ROBOT, P3755
   Carlo JT, 2005, AM J SURG, V190, P886, DOI 10.1016/j.amjsurg.2005.08.015
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chao Hu, 2009, International Journal of Information Acquisition, V6, P257, DOI 10.1142/S0219878909001989
   Chen YW, 2005, COMBINING SVMS VARIO
   Dash M., 1997, Intelligent Data Analysis, V1
   Duin R. P. W., 2007, PR TOOLS 4 1 METLAB
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Hsu C. W., 2003, PRACTICAL GUIDE SUPP
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Schulmann K, 2005, AM J GASTROENTEROL, V100, P27, DOI 10.1111/j.1572-0241.2005.40102.x
   Unser M, 2003, IEEE T IMAGE PROCESS, V12, P1080, DOI 10.1109/TIP.2003.812329
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Vapnik V. N., 1998, STAT LEARNING THEORY, V1
   Wang L, 2005, THEORY APPL SUPPORT, DOI [10.1002/9781118197448, DOI 10.1002/9781118197448]
   Zabulis X, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3921, DOI 10.1109/IROS.2008.4650969
NR 30
TC 103
Z9 104
U1 1
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1089-7771
EI 1558-0032
J9 IEEE T INF TECHNOL B
JI IEEE T. Inf. Technol. Biomed.
PD MAY
PY 2012
VL 16
IS 3
BP 323
EP 329
DI 10.1109/TITB.2012.2185807
PG 7
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA 941WF
UT WOS:000303997700004
PM 22287246
DA 2023-04-20
ER

PT J
AU Srygley, FD
   Gerardo, CJ
   Tran, T
   Fisher, DA
AF Srygley, F. Douglas
   Gerardo, Charles J.
   Tran, Tony
   Fisher, Deborah A.
TI Does This Patient Have a Severe Upper Gastrointestinal Bleed?
SO JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION
LA English
DT Article
ID ARTIFICIAL NEURAL-NETWORK; BLOOD UREA NITROGEN; NASOGASTRIC ASPIRATION;
   TRACT HEMORRHAGE; CREATININE RATIO; ENDOSCOPY; MANAGEMENT; LAVAGE; NEED;
   COLONOSCOPY
AB Context Emergency physicians must determine both the location and the severity of acute gastrointestinal bleeding (GIB) to optimize the diagnostic and therapeutic approaches.
   Objectives To identify the historical features, symptoms, signs, bedside maneuvers, and basic laboratory test results that distinguish acute upper GIB (UGIB) from acute lower GIB (LGIB) and to risk stratify those patients with a UGIB least likely to have severe bleeding that necessitates an urgent intervention.
   Data Sources A structured search of MEDLINE (1966-September 2011) and reference lists from retrieved articles, review articles, and physical examination textbooks.
   Study Selection High-quality studies were included of adult patients who were either admitted with GIB or evaluated in emergency departments with bedside evaluations and/or routine laboratory tests, and studies that did not include endoscopic findings in prediction models. The initial search yielded 2628 citations, of which 8 were retained that tested methods of identifying a UGIB and 18 that identified methods of determining the severity of UGIB.
   Data Extraction One author abstracted the data (prevalence, sensitivity, specificity, and likelihood ratios [LRs]) and assessed methodological quality, with confirmation by another author. Data were combined using random effects measures.
   Data Synthesis The majority of patients (N=1776) had an acute UGIB (prevalence, 63%; 95% CI, 51%-73%). Several clinical factors increase the likelihood that a patient has a UGIB, including a patient-reported history of melena (LR range, 5.15.9), melenic stool on examination (LR, 25; 95% CI, 4-174), a nasogastric lavage with blood or coffee grounds (LR, 9.6; 95% CI, 4.0-23.0), and a serum urea nitrogen: creatinine ratio of more than 30 (summary LR, 7.5; 95% CI, 2.8-12.0). Conversely, the presence of blood clots in stool (LR, 0.05; 95% CI, 0.01-0.38) decreases the likelihood of a UGIB. Of the patients clinically diagnosed with acute UGIB, 36% (95% CI, 29%-44%) had severe bleeding. A nasogastric lavage with red blood (summary LR, 3.1; 95% CI, 1.2-14.0), tachycardia (LR, 4.9; 95% CI, 3.2-7.6), or a hemoglobin level of less than 8 g/dL (LR range, 4.5-6.2) increase the likelihood of a severe UGIB requiring urgent intervention. A Blatchford score of 0 (summary LR, 0.02; 95% CI, 0-0.05) decreases the likelihood that a UGIB requires urgent intervention.
   Conclusions Melena, nasogastric lavage with blood or coffee grounds, or serum urea nitrogen: creatinine ratio of more than 30 increase the likelihood of a UGIB. Blood clots in the stool make a UGIB much less likely. The Blatchford clinical prediction score, which does not require nasogastric lavage, is very efficient for identifying patients who do not require urgent intervention. JAMA. 2012;307(10):1072-1079 www.jama.com
C1 [Srygley, F. Douglas; Tran, Tony; Fisher, Deborah A.] Duke Univ, Med Ctr, Dept Med, Durham, NC 27710 USA.
   [Gerardo, Charles J.] Duke Univ, Med Ctr, Dept Surg, Durham, NC 27710 USA.
   [Fisher, Deborah A.] Durham Vet Affairs Med Ctr, Ctr Hlth Serv Res Primary Care, Durham, NC USA.
C3 Duke University; Duke University; US Department of Veterans Affairs;
   Veterans Health Administration (VHA); Durham VA Medical Center
RP Srygley, FD (通讯作者)，Duke Univ, Med Ctr, Dept Med, POB 3913, Durham, NC 27710 USA.
EM srygl001@mc.duke.edu
FU Veterans Affairs Health Services [RCD 03-174]
FX Dr Fisher is supported in part by a Veterans Affairs Health Services
   Research and Development Career Development Transition Award (RCD
   03-174).
CR Adamopoulos AB, 2003, EUR J GASTROEN HEPAT, V15, P381, DOI 10.1097/00042737-200304000-00008
   Aljebreen AM, 2004, GASTROINTEST ENDOSC, V59, P172, DOI 10.1016/S0016-5107(03)02543-4
   Barkun AN, 2010, ANN INTERN MED, V152, P101, DOI 10.7326/0003-4819-152-2-201001190-00009
   Best Carolyn, 2007, Nurs Stand, V21, P39
   Blatchford O, 1997, BMJ-BRIT MED J, V315, P510, DOI 10.1136/bmj.315.7107.510
   Blatchford O, 2000, LANCET, V356, P1318, DOI 10.1016/S0140-6736(00)02816-6
   Borenstein M., 2009, INTRO METAANALYSIS
   Chalasani N, 1997, AM J GASTROENTEROL, V92, P1796
   CHAMPION MC, 1982, ANN SURG, V195, P314, DOI 10.1097/00000658-198203000-00011
   Chandra S, 2011, AM J EMERG MED
   Chen GC, 2007, AM J EMERG MED, V25, P774, DOI 10.1016/j.ajem.2006.12.024
   CUELLAR RE, 1990, ARCH INTERN MED, V150, P1381, DOI 10.1001/archinte.150.7.1381
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Das A, 2008, GASTROENTEROLOGY, V134, P65, DOI 10.1053/j.gastro.2007.10.037
   Esrailian E, 2008, ALIMENT PHARM THER, V28, P1199, DOI 10.1111/j.1365-2036.2008.03838.x
   Farooq FT, 2012, AM J EMERG MED, V30, P129, DOI 10.1016/j.ajem.2010.11.007
   Feldman M, 2009, SLEISINGER FORDTRANS, P211
   Garcia-Tsao G, 2007, AM J GASTROENTEROL, V102, P2086, DOI 10.1111/j.1572-0241.2007.01481.x
   Green BT, 2005, AM J GASTROENTEROL, V100, P2395, DOI 10.1111/j.1572-0241.2005.00306.x
   Healthcare Cost and Utilization Project (HCUP), 2011, HCUP CLIN CLASS SOFT
   HILSMAN J H, 1950, J Med Assoc Ga, V39, P402
   Huang ES, 2011, GASTROINTEST ENDOSC, V74, P971, DOI 10.1016/j.gie.2011.04.045
   Lanas A, 2009, AM J GASTROENTEROL, V104, P1633, DOI 10.1038/ajg.2009.164
   LeBlond RF, 2009, DEGOWINS DIAGNOSTIC
   Lee SD, 2004, J CLIN GASTROENTEROL, V38, P861, DOI 10.1097/00004836-200411000-00005
   LUKE RG, 1964, GUT, V5, P77, DOI 10.1136/gut.5.1.77
   Marmo R, 2008, AM J GASTROENTEROL, V103, P1639, DOI 10.1111/j.1572-0241.2008.01865.x
   Masaoka T, 2007, J GASTROEN HEPATOL, V22, P1404, DOI 10.1111/j.1440-1746.2006.04762.x
   Menke J, 2010, METHOD INFORM MED, V49, P54, DOI 10.3414/ME09-01-0001
   MORTENSEN PB, 1994, DAN MED BULL, V41, P237
   OLSEN LH, 1991, BRIT J SURG, V78, P71, DOI 10.1002/bjs.1800780122
   Palamidessi N, 2010, ACAD EMERG MED, V17, P126, DOI 10.1111/j.1553-2712.2009.00609.x
   Pallin DJ, 2011, GASTROINTEST ENDOSC, V74, P981, DOI 10.1016/j.gie.2011.07.007
   Pang SH, 2010, GASTROINTEST ENDOSC, V71, P1134, DOI 10.1016/j.gie.2010.01.028
   Pillai Jain Bhaskara, 2005, Interact Cardiovasc Thorac Surg, V4, P429, DOI 10.1510/icvts.2005.109488
   RICHARDS RJ, 1990, J CLIN GASTROENTEROL, V12, P500, DOI 10.1097/00004836-199010000-00004
   Romagnuolo J, 2007, ARCH INTERN MED, V167, P265, DOI 10.1001/archinte.167.3.265
   Schiff L, 1942, AM J MED SCI, V203, P409, DOI 10.1097/00000441-194203000-00016
   Schmulewitz N, 2003, GASTROINTEST ENDOSC, V58, P841, DOI 10.1016/S0016-5107(03)02304-6
   Simel DL, 2009, J CLIN EPIDEMIOL, V62, P1292, DOI 10.1016/j.jclinepi.2009.02.007
   Singer AJ, 1999, ANN EMERG MED, V33, P652, DOI 10.1016/S0196-0644(99)70194-0
   SNOOK JA, 1986, LANCET, V1, P1064
   Spiegel BMR, 2009, GASTROINTEST ENDOSC, V70, P236, DOI 10.1016/j.gie.2008.12.053
   Srirajaskanthan R, 2010, INT J CLIN PRACT, V64, P868, DOI 10.1111/j.1742-1241.2009.02267.x
   Stanley AJ, 2009, LANCET, V373, P42, DOI 10.1016/S0140-6736(08)61769-9
   STOLZING H, 1991, HEPATO-GASTROENTEROL, V38, P224
   Sung JJY, 2011, GUT, V60, P1170, DOI 10.1136/gut.2010.230292
   Targownik LE, 2007, CAN J GASTROENTEROL, V21, P425, DOI 10.1155/2007/636032
   Thomsen TW, 2006, NEW ENGL J MED, V354, DOI 10.1056/NEJMvcm050183
   Witting MD, 2006, AM J EMERG MED, V24, P280, DOI 10.1016/j.ajem.2005.11.005
   Witting MD, 2004, ANN EMERG MED, V43, P525, DOI 10.1016/j.annemergmed.2003.09.002
   ZUCKERMAN GR, 1995, DIGEST DIS SCI, V40, P1614, DOI 10.1007/BF02212679
NR 52
TC 103
Z9 121
U1 1
U2 12
PU AMER MEDICAL ASSOC
PI CHICAGO
PA 330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA
SN 0098-7484
EI 1538-3598
J9 JAMA-J AM MED ASSOC
JI JAMA-J. Am. Med. Assoc.
PD MAR 14
PY 2012
VL 307
IS 10
BP 1072
EP 1079
DI 10.1001/jama.2012.253
PG 8
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 908GU
UT WOS:000301479700028
PM 22416103
DA 2023-04-20
ER

PT J
AU Malagelada, C
   De Lorio, F
   Segui, S
   Mendez, S
   Drozdzal, M
   Vitria, J
   Radeva, P
   Santos, J
   Accarino, A
   Malagelada, JR
   Azpiroz, F
AF Malagelada, C.
   De Lorio, F.
   Segui, S.
   Mendez, S.
   Drozdzal, M.
   Vitria, J.
   Radeva, P.
   Santos, J.
   Accarino, A.
   Malagelada, J. R.
   Azpiroz, F.
TI Functional gut disorders or disordered gut function? Small bowel
   dysmotility evidenced by an original technique
SO NEUROGASTROENTEROLOGY AND MOTILITY
LA English
DT Article
DE capsule endoscopy; computer vision analysis; machine learning technique;
   small bowel motility
ID JEJUNAL MOTILITY; PRESSURE WAVES; GAS RETENTION; MACHINE
AB Background This study aimed to determine the proportion of cases with abnormal intestinal motility among patients with functional bowel disorders. To this end, we applied an original method, previously developed in our laboratory, for analysis of endoluminal images obtained by capsule endoscopy. This novel technology is based on computer vision and machine learning techniques. Methods The endoscopic capsule (Pillcam SB1; Given Imaging, Yokneam, Israel) was administered to 80 patients with functional bowel disorders and 70 healthy subjects. Endoluminal image analysis was performed with a computer vision program developed for the evaluation of contractile events (luminal occlusions and radial wrinkles), noncontractile patterns (open tunnel and smooth wall patterns), type of content (secretions, chyme) and motion of wall and contents. Normality range and discrimination of abnormal cases were established by a machine learning technique. Specifically, an iterative classifier (one-class support vector machine) was applied in a random population of 50 healthy subjects as a training set and the remaining subjects (20 healthy subjects and 80 patients) as a test set. Key Results The classifier identified as abnormal 29% of patients with functional diseases of the bowel (23 of 80), and as normal 97% of healthy subjects (68 of 70) (P < 0.05 by chi-squared test). Patients identified as abnormal clustered in two groups, which exhibited either a hyper- or a hypodynamic motility pattern. The motor behavior was unrelated to clinical features. Conclusions & Inferences With appropriate methodology, abnormal intestinal motility can be demonstrated in a significant proportion of patients with functional bowel disorders, implying a pathologic disturbance of gut physiology.
C1 [Malagelada, C.; De Lorio, F.; Mendez, S.; Santos, J.; Accarino, A.; Malagelada, J. R.; Azpiroz, F.] Hosp Gen Valle dHebron, Digest Syst Res Unit, Barcelona 08035, Spain.
   [Malagelada, C.; De Lorio, F.; Mendez, S.; Santos, J.; Accarino, A.; Malagelada, J. R.; Azpiroz, F.] Ctr Invest Biomed Red Enfermedades Hepat & Digest, Barcelona, Spain.
   [Malagelada, C.; De Lorio, F.; Mendez, S.; Santos, J.; Accarino, A.; Malagelada, J. R.; Azpiroz, F.] Univ Autonoma Barcelona, Dept Med, E-08193 Barcelona, Spain.
   [Segui, S.; Drozdzal, M.; Vitria, J.; Radeva, P.] Comp Vis Ctr, Bellaterra, Spain.
C3 CIBER - Centro de Investigacion Biomedica en Red; CIBEREHD; Autonomous
   University of Barcelona; Centre de Visio per Computador (CVC)
RP Azpiroz, F (通讯作者)，Hosp Gen Valle dHebron, Digest Syst Res Unit, Barcelona 08035, Spain.
EM azpiroz.fernando@gmail.com
RI Radeva, Petia/I-3385-2015; Heredia, Josefina/I-1166-2012; Santos,
   Javier/O-1501-2014; Vitrià, Jordi/AAF-9668-2020; Garaventa, Anna
   Accarino/Q-8658-2017; Segui, Santi/E-4860-2010; Malagelada,
   Carolina/F-3743-2016
OI Radeva, Petia/0000-0003-0047-5172; Santos, Javier/0000-0002-4798-5033;
   Vitrià, Jordi/0000-0003-1484-539X; Segui, Santi/0000-0002-8603-138X;
   Malagelada, Carolina/0000-0001-7097-1492; Azpiroz,
   Fernando/0000-0002-7327-960X
FU Given Imaging; Spanish Ministry of Education (Direccion General de
   Investigacion) [SAF 2009-07416]; Fundacio La Marato TV3
   [MARATV3_072010]; Instituto de Salud Carlos III
FX This work was supported in part by Given Imaging, the Spanish Ministry
   of Education (Direccion General de Investigacion, SAF 2009-07416), and
   Fundacio La Marato TV3 (MARATV3_072010). Ciberehd is funded by the
   Instituto de Salud Carlos III.
CR Accarino A, 1993, J GASTROINTEST MOTIL, V3, P5
   Caldarella MP, 2002, GASTROENTEROLOGY, V122, P1748, DOI 10.1053/gast.2002.33658
   Camci F, 2008, PATTERN RECOGN, V41, P3021, DOI 10.1016/j.patcog.2008.04.001
   Clemens CHM, 2003, AM J GASTROENTEROL, V98, P1838, DOI 10.1016/S0002-9270(03)00374-5
   De Iorio F, 2009, NEUROGASTROENT MOTIL, V21, DOI 10.1111/j.1365-2982.2009.01363.x
   KELLOW JE, 1988, GUT, V29, P1236, DOI 10.1136/gut.29.9.1236
   KELLOW JE, 1987, GASTROENTEROLOGY, V92, P1885, DOI 10.1016/0016-5085(87)90620-2
   KUMAR D, 1985, LANCET, V2, P973
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Malagelada C, 2008, GASTROENTEROLOGY, V135, P1155, DOI 10.1053/j.gastro.2008.06.084
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Quigley Eamonn M M, 2010, Gastroenterology, V139, P346, DOI 10.1053/j.gastro.2010.05.031
   Ringner M, 2008, NAT BIOTECHNOL, V26, P303, DOI 10.1038/nbt0308-303
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   RUSS JC, 2007, IMAGE PROCESSING HDB
   Salvioli B, 2005, GASTROENTEROLOGY, V128, P574, DOI 10.1053/j.gastro.2004.12.047
   Schmidt T, 1996, SCAND J GASTROENTERO, V31, P581, DOI 10.3109/00365529609009131
   Serra J, 2002, GASTROENTEROLOGY, V123, P700, DOI 10.1053/gast.2002.35394
   Serra J, 2010, NEUROGASTROENT MOTIL, V22, P401, DOI 10.1111/j.1365-2982.2009.01447.x
   Simren M, 2000, DIGEST DIS SCI, V45, P2151, DOI 10.1023/A:1010770302403
   Small PK, 1997, SCAND J GASTROENTERO, V32, P39, DOI 10.3109/00365529709025061
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Stanghellini V, 2005, CLIN GASTROENTEROL H, V3, P449, DOI 10.1016/S1542-3565(04)00675-5
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Vapnik V., 1999, NATURE STAT LEARNING
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P178
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Wackerbauer R, 1998, NEUROGASTROENT MOTIL, V10, P331
   Waljee AK, 2010, AM J GASTROENTEROL, V105, P1224, DOI 10.1038/ajg.2010.173
NR 30
TC 23
Z9 26
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1350-1925
EI 1365-2982
J9 NEUROGASTROENT MOTIL
JI Neurogastroenterol. Motil.
PD MAR
PY 2012
VL 24
IS 3
BP 223
EP E105
DI 10.1111/j.1365-2982.2011.01823.x
PG 8
WC Gastroenterology & Hepatology; Clinical Neurology; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Neurosciences & Neurology
GA 888JX
UT WOS:000300000900009
PM 22129212
DA 2023-04-20
ER

PT J
AU Kumar, R
   Zhao, Q
   Seshamani, S
   Mullin, G
   Hager, G
   Dassopoulos, T
AF Kumar, Rajesh
   Zhao, Qian
   Seshamani, Sharmishtaa
   Mullin, Gerard
   Hager, Gregory
   Dassopoulos, Themistocles
TI Assessment of Crohn's Disease Lesions in Wireless Capsule Endoscopy
   Images
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Content-based image retrieval; Crohn's disease; statistical
   classification; wireless capsule endoscopy (CE)
ID AUTOMATIC DETECTION; SMALL-BOWEL; SUPPORT; COLOR; DIAGNOSIS; SYSTEM
AB Capsule endoscopy (CE) provides noninvasive access to a large part of the small bowel that is otherwise inaccessible without invasive and traumatic treatment. However, it also produces large amounts of data (approximately 50 000 images) that must be then manually reviewed by a clinician. Such large datasets provide an opportunity for application of image analysis and supervised learning methods. Automated analysis of CE images has only focused on detection, and often only for bleeding. Compared to these detection approaches, we explored assessment of discrete disease for lesions created by mucosal inflammation in Crohn's disease (CD). Our work is the first study to systematically explore supervised classification for CD lesions, a classifier cascade to classify discrete lesions, as well as quantitative assessment of lesion severity. We used a well-developed database of 47 studies for evaluation of these methods. The developed methods show high agreement with ground truth severity ratings manually assigned by an expert, and good precision (>90% for lesion detection) and recall (>90%) for lesions of varying severity.
C1 [Kumar, Rajesh] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.
   [Dassopoulos, Themistocles] Washington Univ, Sch Med, St Louis, MO 63130 USA.
C3 Johns Hopkins University; Washington University (WUSTL)
RP Kumar, R (通讯作者)，Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.
EM rajesh@jhu.edu; qzhao@jhu.edu; shtaaa@gmail.com; gmullin1@jhmi.edu;
   hager@cs.jhu.edu; themos@im.wustl.edu
RI Hager, Gregory D/A-3222-2010; Mullin, Gerry/H-5294-2019
OI Mullin, Gerry/0000-0001-5317-6788
FU National Institutes of Health [5R21EB008227-02]; Johns Hopkins
   University
FX Manuscript received January 17, 2011; revised May 10, 2011, August 7,
   2011, and October 7, 2011; accepted October 10, 2011. Date of
   publication October 18, 2011; date of current version January 20, 2012.
   This work was supported in part by the National Institutes of Health
   under Grant 5R21EB008227-02 and Johns Hopkins University internal funds.
   Asterisk indicates corresponding author.
CR Bashar MK, 2008, LECT NOTES COMPUT SC, V5242, P603, DOI 10.1007/978-3-540-85990-1_72
   Bejakovic S, 2009, IEEE INT CONF ROBOT, P3755
   Bishop C. M., 2006, PATTERN RECOGNITION
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cauvin JM, 2003, IEEE T INF TECHNOL B, V7, P256, DOI 10.1109/TITB.2003.823293
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Coimbra M., 2006, P IEEE INT C AC SPEE, V2, P1164
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Gerber J, 2007, GASTROINTEST ENDOSC, V66, P1188, DOI 10.1016/j.gie.2007.06.003
   Gralnev IM, 2008, ALIMENT PHARM THERAP, V27, P146, DOI 10.1111/j.1365-2036.2007.03556.x
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hwang S, 2006, PROC SPIE, V6144, DOI 10.1117/12.654109
   I. Given Imaging, 2009, I GIVEN IMAGING
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Igual L, 2007, LECT NOTES COMPUT SC, V4673, P293
   Jung YS, 2008, INT CONF BIOMED, P859, DOI 10.1109/BMEI.2008.216
   Kumar R, 2009, I S BIOMED IMAGING, P1314, DOI 10.1109/ISBI.2009.5193306
   Lee J., 2007, ACM S APPL COMP SEOU
   Lewis BS, 2008, WORLD J GASTROENTERO, V14, P4137, DOI 10.3748/wjg.14.4137
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe D., 1999, P 7 IEEE INT C COMPU, P1150
   Mackiewicz M, 2008, PROC SPIE, V6914, DOI 10.1117/12.770510
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Muller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Nakamura T, 2008, J GASTROENTEROL, V43, P93, DOI 10.1007/s00535-007-2153-6
   Raju Gottumukkala S, 2007, Gastroenterology, V133, P1694, DOI 10.1053/j.gastro.2007.06.008
   Rey JF, 2006, GASTROINTEST ENDOSC, V63, pAB176, DOI 10.1016/j.gie.2006.03.381
   Rutgeerts P, 2007, GUT, V56, P453, DOI 10.1136/gut.2005.088732
   Schnitzler F, 2009, INFLAMM BOWEL DIS, V15, P1295, DOI 10.1002/ibd.20927
   Seshamani S, 2011, IEEE T MED IMAGING, V30, P1468, DOI 10.1109/TMI.2011.2119326
   Seshamani S, 2009, LECT NOTES COMPUT SC, V5761, P582, DOI 10.1007/978-3-642-04268-3_72
   Sonka M., 2007, IMAGE PROCESSING ANA
   Tong S, 2001, P 9 ACM INT C MULT A
   Vilarino F, 2006, INT C PATT RECOG, P719
   Vu H, 2007, LECT NOTES COMPUT SC, V4791, P775
   Xia SR, 2005, P ANN INT IEEE EMBS, P1720
   Zhao Q., 2011, P 33 ANN INT C IEEE
   Zheng MM, 2005, COMPUT BIOL MED, V35, P259, DOI 10.1016/j.compbiomed.2004.01.002
NR 40
TC 59
Z9 59
U1 1
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD FEB
PY 2012
VL 59
IS 2
BP 355
EP 362
DI 10.1109/TBME.2011.2172438
PG 8
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 895PF
UT WOS:000300507800008
PM 22020661
DA 2023-04-20
ER

PT J
AU Lin, SF
   Chen, HT
   Tsai, TL
AF Lin, Sheng-Fuu
   Chen, Hsien-Tse
   Tsai, Tung-Lung
TI AUTOMATIC IDENTIFYING LARYNGOPHARYNGEAL REFLUX USING ARTIFICIAL NEURAL
   NETWORK
SO BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS
LA English
DT Article
DE Laryngopharyngeal Reflux; Feature extraction; Image processing;
   Artificial neural network
ID ENDOSCOPY; DIAGNOSIS; PICTURES; DISEASE
AB Laryngopharyngeal Reflux mostly leads to burns of the pharynx and larynx by reflux from gastric acid and also leads to different degrees of burns in the esophagus and the stomach. This paper aims to develop a technique for analyzing pharyngeal and laryngeal images. With techniques of digital image processing, this paper can choose the suitable images from burns of the pharynx and larynx to obtain the feature zones of burns of the pharynx and larynx. Artificial neural network helps physicians to develop the diagnostic standard about the burns severity of Laryngopharyngeal Reflux. This paper divides the types of the complications into three degrees and compares with other ways (Hanson et al.(5) and Ilgner et al.(6)). The results can be the technical assistance in helping physicians to diagnose the severity of Laryngopharyngeal Reflux and to make a more precise diagnosis.
C1 [Lin, Sheng-Fuu; Chen, Hsien-Tse] Natl Chiao Tung Univ, Dept Elect Engn, Taipei, Taiwan.
   [Tsai, Tung-Lung] Taipei Vet Gen Hosp, Dept Otolaryngol, Taipei, Taiwan.
   [Tsai, Tung-Lung] Natl Yang Ming Univ, Dept Otolaryngol, Taipei 112, Taiwan.
   [Tsai, Tung-Lung] Natl Yang Ming Univ, Inst Clin Med, Sch Med, Taipei 112, Taiwan.
C3 National Yang Ming Chiao Tung University; Taipei Veterans General
   Hospital; National Yang Ming Chiao Tung University; National Yang Ming
   Chiao Tung University
RP Lin, SF (通讯作者)，1001 Ta Hsueh Rd, Hsinchu 30010, Taiwan.
EM sflin@mail.nctu.edu.tw
FU National Science Council [NSC 96-2221-E-009-238]
FX This work was supported partially by the National Science Council under
   Grant NSC 96-2221-E-009-238.
CR Arango L, 2000, HEPATO-GASTROENTEROL, V47, P174
   Beaver ME, 2003, OTOLARYNG HEAD NECK, V128, P103, DOI 10.1067/mhn.2003.10
   Belafsky PC, 2001, LARYNGOSCOPE, V111, P1313, DOI 10.1097/00005537-200108000-00001
   Chang YL, 1997, COMPUT VIS IMAGE UND, V67, P186, DOI 10.1006/cviu.1997.0527
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Gonzales RC., 2002, DIGITAL IMAGE PROCES
   Hanson DG, 1998, J VOICE, V12, P78
   Hill RK, 2004, LARYNGOSCOPE, V114, P1557, DOI 10.1097/00005537-200409000-00010
   Ilgner JFR, 2003, ACTA OTO-LARYNGOL, V123, P730, DOI 10.1080/00016480310000412
   Leizza R, 2002, P 15 BRAZ S COMP GRA, P300
   LI HW, 1986, COMPUT VISION GRAPH, V36, P139, DOI 10.1016/0734-189X(86)90073-3
   Men S, 2007, J DIGIT IMAGING, V20, P67, DOI 10.1007/s10278-006-0857-4
   Pang B, 2005, IEEE T MED IMAGING, V24, P946, DOI 10.1109/TMI.2005.850552
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Zheng Q, 2004, CYTOM PART A, V57A, P1, DOI 10.1002/cyto.a.10106
NR 15
TC 3
Z9 3
U1 0
U2 2
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 1016-2372
J9 BIOMED ENG-APP BAS C
JI Biomed. Eng.-Appl. Basis Commun.
PD FEB
PY 2012
VL 24
IS 1
BP 47
EP 56
DI 10.4015/S1016237212002949
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 916CO
UT WOS:000302074800006
DA 2023-04-20
ER

PT J
AU Saftoiu, A
   Vilmann, P
   Gorunescu, F
   Janssen, J
   Hocke, M
   Larsen, M
   Iglesias-Garcia, J
   Arcidiacono, P
   Will, U
   Giovannini, M
   Dietrich, CF
   Havre, R
   Gheorghe, C
   McKay, C
   Gheonea, DI
   Ciurea, T
AF Saftoiu, Adrian
   Vilmann, Peter
   Gorunescu, Florin
   Janssen, Jan
   Hocke, Michael
   Larsen, Michael
   Iglesias-Garcia, Julio
   Arcidiacono, Paolo
   Will, Uwe
   Giovannini, Marc
   Dietrich, Cristoph F.
   Havre, Roald
   Gheorghe, Cristian
   McKay, Colin
   Gheonea, Dan Ionut
   Ciurea, Tudorel
CA European EUS Elastography Multicen
TI Efficacy of an Artificial Neural Network- Based Approach to Endoscopic
   Ultrasound Elastography in Diagnosis of Focal Pancreatic Masses
SO CLINICAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE Tissue Elasticity; Cancer; Pancreas; Tumor; Mass
ID REAL-TIME ELASTOGRAPHY; FINE-NEEDLE-ASPIRATION; DIFFERENTIAL-DIAGNOSIS;
   EUS ELASTOGRAPHY; CANCER; BENIGN; IMAGES; BIOPSY
AB BACKGROUND & AIMS: By using strain assessment, real-time endoscopic ultrasound (EUS) elastography provides additional information about a lesion's characteristics in the pancreas. We assessed the accuracy of real-time EUS elastography in focal pancreatic lesions using computer-aided diagnosis by artificial neural network analysis. METHODS: We performed a prospective, blinded, multicentric study at of 258 patients (774 recordings from EUS elastography) who were diagnosed with chronic pancreatitis (n = 47) or pancreatic adenocarcinoma (n = 211) from 13 tertiary academic medical centers in Europe (the European EUS Elastography Multicentric Study Group). We used postprocessing software analysis to compute individual frames of elastography movies recorded by retrieving hue histogram data from a dynamic sequence of EUS elastography into a numeric matrix. The data then were analyzed in an extended neural network analysis, to automatically differentiate benign from malignant patterns. RESULTS: The neural computing approach had 91.14% training accuracy (95% confidence interval [CI], 89.87%-92.42%) and 84.27% testing accuracy (95% CI, 83.09%-85.44%). These results were obtained using the 10-fold cross-validation technique. The statistical analysis of the classification process showed a sensitivity of 87.59%, a specificity of 82.94%, a positive predictive value of 96.25%, and a negative predictive value of 57.22%. Moreover, the corresponding area under the receiver operating characteristic curve was 0.94 (95% CI, 0.91%-0.97%), which was significantly higher than the values obtained by simple mean hue histogram analysis, for which the area under the receiver operating characteristic was 0.85. CONCLUSIONS: Use of the artificial intelligence methodology via artificial neural networks supports the medical decision process, providing fast and accurate diagnoses.
C1 [Gheonea, Dan Ionut] Univ Med & Pharm, Res Ctr Gastroenterol & Hepatol, Dept Gastroenterol, Craiova 200349, Dolj, Romania.
   [Gorunescu, Florin] Univ Med & Pharm, Dept Biostat & Comp Sci, Craiova 200349, Dolj, Romania.
   [Saftoiu, Adrian; Vilmann, Peter] Univ Copenhagen, Gentofte & Herlev Hosp, Dept Surg Gastroenterol, DK-1168 Copenhagen, Denmark.
   [Janssen, Jan] Univ Witten Herdecke, Helios Klinikum, Wuppertal, Germany.
   [Hocke, Michael] Hosp Meiningen, Dept Internal Med 2, Meiningen, Germany.
   [Larsen, Michael] Odense Univ Hosp, Ctr Surg Ultrasound, Dept Surg, DK-5000 Odense, Denmark.
   [Iglesias-Garcia, Julio] Univ Hosp, Santiago De Compostela, Spain.
   [Arcidiacono, Paolo] Univ Vita Salute San Raffaele, Gastroenterol & Gastrointestinal Endoscopy Unit, Milan, Italy.
   [Will, Uwe] Wald Klinikum, SRH, Gera, Germany.
   [Giovannini, Marc] Inst J Paoli I Calmettes, Endoscop Unit, Marseilles, France.
   [Dietrich, Cristoph F.] Caritas Krankenhaus Bad Mergentheim, Med Klin 2, Bad Mergentheim, Germany.
   [Havre, Roald] Haukeland Hosp, Natl Ctr Ultrasound Gastroenterol, N-5021 Bergen, Norway.
   [Havre, Roald] Univ Bergen, Inst Med, Bergen, Norway.
   [Gheorghe, Cristian] Fundeni Clin Inst Digest Dis & Liver Transplantat, Bucharest, Romania.
   [McKay, Colin] Glasgow Royal Infirm, Glasgow G4 0SF, Lanark, Scotland.
C3 University of Medicine & Pharmacy of Craiova; University of Medicine &
   Pharmacy of Craiova; University of Copenhagen; Helios Kliniken; Witten
   Herdecke University; University of Southern Denmark; Odense University
   Hospital; Vita-Salute San Raffaele University; UNICANCER; Institut
   Paoli-Calmette (IPC); Caritas Hospital Bad Mergentheim; University of
   Hamburg; University Medical Center Hamburg-Eppendorf; University of
   Bergen; Haukeland University Hospital; University of Bergen; Institutul
   Clinic Fundeni; University of Glasgow
RP Gheonea, DI (通讯作者)，Univ Med & Pharm, Res Ctr Gastroenterol & Hepatol, Dept Gastroenterol, Petru Rares 2, Craiova 200349, Dolj, Romania.
EM digheonea@gmail.com
RI Ciurea, Tudorel/G-3226-2016; Gheonea, Dan Ionut/C-3578-2012; Belciug,
   Smaranda/B-9381-2011; Arcidiacono, Paolo Giorgio/K-2122-2018; Havre,
   Roald Flesland/L-5337-2013; Stoean, Ruxandra/C-7241-2008; Ciurea,
   Tudorel/C-3647-2012; Stoean, Catalin/C-7242-2008; Saftoiu,
   Adrian/C-2792-2011; Vilmann, Peter/AAJ-8401-2020; Vilmann,
   Peter/AAP-2730-2021; Dominguez-Munoz, J. Enrique/Q-8922-2017; Gorunescu,
   Florin/B-9480-2011
OI Arcidiacono, Paolo Giorgio/0000-0001-6692-7720; Havre, Roald
   Flesland/0000-0003-3004-551X; Stoean, Ruxandra/0000-0002-9849-5712;
   Stoean, Catalin/0000-0001-5917-1857; Saftoiu,
   Adrian/0000-0001-7993-8269; Dominguez-Munoz, J.
   Enrique/0000-0001-8283-3185; Ciurea, Tudorel/0009-0009-9860-0795; Ignee,
   Andre/0000-0002-2388-2945; Gorunescu, Florin/0000-0001-6826-2785
FU Ministry of Education and Research, Romania [42-110/2008]; PANGEN
FX This study was partially supported by a PANGEN project financed by the
   Ministry of Education and Research, Romania (contract number
   42-110/2008).
CR Bercoff J, 2003, ULTRASOUND MED BIOL, V29, P1387, DOI 10.1016/S0301-5629(03)00978-5
   Bishop Christopher M., 1995, NEURAL NETWORKS PATT, DOI DOI 10.5555/235248
   Bojunga J, 2010, THYROID, V20, P1145, DOI 10.1089/thy.2010.0079
   Cochlin DL, 2002, CLIN RADIOL, V57, P1014, DOI 10.1053/crad.2002.0989
   Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Eloubeidi MA, 2008, J GASTROEN HEPATOL, V23, P567, DOI 10.1111/j.1440-1746.2007.05119.x
   Friedrich-Rust M, 2007, AM J ROENTGENOL, V188, P758, DOI 10.2214/AJR.06.0322
   Gheonea DI, 2010, WORLD J GASTROENTERO, V16, P1720, DOI 10.3748/wjg.v16.i14.1720
   Giovannini M, 2006, ENDOSCOPY, V38, P344, DOI 10.1055/s-2006-925158
   Giovannini M, 2009, WORLD J GASTROENTERO, V15, P1587, DOI 10.3748/wjg.15.1587
   Gorunescu F, 2011, EXPERT SYST, V28, P33, DOI 10.1111/j.1468-0394.2010.00540.x
   Haykin S., 1999, KNOWL ENG REV, V2nd
   Hirche TO, 2008, ENDOSCOPY, V40, P910, DOI 10.1055/s-2008-1077726
   Iglesias-Garcia J, 2010, GASTROENTEROLOGY, V139, P1172, DOI 10.1053/j.gastro.2010.06.059
   Iglesias-Garcia J, 2009, GASTROINTEST ENDOSC, V70, P1101, DOI 10.1016/j.gie.2009.05.011
   Janssen J, 2007, ENDOSCOPY, V39, P952, DOI 10.1055/s-2007-966946
   Janssen J, 2007, GASTROINTEST ENDOSC, V65, P971, DOI 10.1016/j.gie.2006.12.057
   Jenssen C, 2009, BEST PRACT RES CL GA, V23, P743, DOI 10.1016/j.bpg.2009.05.006
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644
   Saftoiu A, 2006, ULTRASCHALL MED, V27, P535, DOI 10.1055/s-2006-927117
   Saftoiu A, 2011, ENDOSCOPY, V43, P596, DOI 10.1055/s-0030-1256314
   Saftoiu A, 2008, GASTROINTEST ENDOSC, V68, P1086, DOI 10.1016/j.gie.2008.04.031
   Saftoiu A, 2007, AM J ROENTGENOL, V189, pW232, DOI 10.2214/AJR.07.2571
   Saftoiu A, 2007, GASTROINTEST ENDOSC, V66, P291, DOI 10.1016/j.gie.2006.12.039
   Saftoiu Adrian, 2006, J Gastrointestin Liver Dis, V15, P161
   Sommerfeld HJ, 2003, UROLOGE A, V42, P941, DOI 10.1007/s00120-003-0297-4
   Varadarajulu S, 2005, GASTROINTEST ENDOSC, V62, P728, DOI 10.1016/j.gie.2005.06.051
   Vilmann P, 2006, J GASTROEN HEPATOL, V21, P1646, DOI 10.1111/j.1440-1746.2006.04475.x
NR 29
TC 121
Z9 125
U1 2
U2 55
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1542-3565
EI 1542-7714
J9 CLIN GASTROENTEROL H
JI Clin. Gastroenterol. Hepatol.
PD JAN
PY 2012
VL 10
IS 1
BP 84
EP U167
DI 10.1016/j.cgh.2011.09.014
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 872LZ
UT WOS:000298812400022
PM 21963957
DA 2023-04-20
ER

PT J
AU Shen, Y
   Guturu, P
   Buckles, BP
AF Shen, Yao
   Guturu, Parthasarathy (Partha)
   Buckles, Bill P.
TI Wireless Capsule Endoscopy Video Segmentation Using an Unsupervised
   Learning Approach Based on Probabilistic Latent Semantic Analysis With
   Scale Invariant Features
SO IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE
LA English
DT Article
DE Classification; probabilistic latent semantic analysis; scale invariant
   feature transform; video segmentation; wireless capsule endoscopy
AB Since wireless capsule endoscopy (WCE) is a novel technology for recording the videos of the digestive tract of a patient, the problem of segmenting the WCE video of the digestive tract into subvideos corresponding to the entrance, stomach, small intestine, and large intestine regions is not well addressed in the literature. A selected few papers addressing this problem follow supervised leaning approaches that presume availability of a large database of correctly labeled training samples. Considering the difficulties in procuring sizable WCE training data sets needed for achieving high classification accuracy, we introduce in this paper an unsupervised learning approach that employs Scale Invariant Feature Transform (SIFT) for extraction of local image features and the probabilistic latent semantic analysis (pLSA) model used in the linguistic content analysis for data clustering. Results of experimentation indicate that this method compares well in classification accuracy with the state-of-the-art supervised classification approaches to WCE video segmentation.
C1 [Shen, Yao; Buckles, Bill P.] Univ N Texas, Dept Comp Sci & Engn, Coll Engn, Denton, TX 76203 USA.
   [Guturu, Parthasarathy (Partha)] Univ N Texas, Dept Elect Engn, Coll Engn, Denton, TX 76203 USA.
C3 University of North Texas System; University of North Texas Denton;
   University of North Texas System; University of North Texas Denton
RP Shen, Y (通讯作者)，Univ N Texas, Dept Comp Sci & Engn, Coll Engn, Denton, TX 76203 USA.
EM ys0116@unt.edu; guturu@unt.edu; bbuckles@unt.edu
OI Buckles, Bill/0000-0002-3385-9933
CR Berens J., 2002, THESIS U E ANGLIA NO
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Boulougoura M., 2005, P 2 IASTED C BIOM EN, P405
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Culliford A, 2005, GASTROINTEST ENDOSC, V62, P55, DOI 10.1016/S0016-5107(05)01566-X
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gay G., 2004, ENDOSCOPY, V36
   Given Imaging, 2011, PILLC SB CAPS END PR
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lowe D., 1999, P 7 IEEE INT C COMPU, P1150
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Maieron A, 2004, ENDOSCOPY, V36, P864, DOI 10.1055/s-2004-825852
   Se S, 2001, IEEE INT CONF ROBOT, P2051, DOI 10.1109/ROBOT.2001.932909
   Shah M., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Swain P, 2005, GUT, V54, P323, DOI 10.1136/gut.2004.047282
   Toews M, 2010, NEUROIMAGE, V49, P2318, DOI 10.1016/j.neuroimage.2009.10.032
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
NR 23
TC 36
Z9 39
U1 0
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1089-7771
EI 1558-0032
J9 IEEE T INF TECHNOL B
JI IEEE T. Inf. Technol. Biomed.
PD JAN
PY 2012
VL 16
IS 1
BP 98
EP 105
DI 10.1109/TITB.2011.2171977
PG 8
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA 892AX
UT WOS:000300260000012
PM 22010158
DA 2023-04-20
ER

PT J
AU Pan, GB
   Yan, GZ
   Qiu, XL
   Cui, JH
AF Pan, Guobing
   Yan, Guozheng
   Qiu, Xiangling
   Cui, Jiehao
TI Bleeding Detection in Wireless Capsule Endoscopy Based on Probabilistic
   Neural Network
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Wireless capsule endoscopy; Gastrointestinal tract; Probabilistic neural
   network; Bleeding detection
ID PERFORMANCE
AB Wireless Capsule Endoscopy (WCE), which allows clinicians to inspect the whole gastrointestinal tract (GI) noninvasively, has bloomed into one of the most efficient technologies to diagnose the bleeding in GI tract. However WCE generates large amount of images in one examination of a patient. It is hard for clinicians to leave continuous time to examine the full WCE images, and this is the main factor limiting the wider application of WCE in clinic. A novel intelligent bleeding detection based on Probabilistic Neural Network (PNN) is proposed in this paper. The features of bleeding region in WCE images distinguishing from non-bleeding region are extracted. A PNN classifier is built to recognize bleeding regions in WCE images. Finally the intelligent bleeding detection method is implemented through programming. The experiments show this method can correctly recognize the bleeding regions in WCE images and clearly mark them out. The sensitivity and specificity on image level are measured as 93.1% and 85.6% respectively.
C1 [Pan, Guobing; Yan, Guozheng; Qiu, Xiangling; Cui, Jiehao] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Pan, GB (通讯作者)，Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China.
EM Guobpan@gmail.com
FU National Hi-Tech Research and Development Program (863) of China
   [2006AA04Z368]; National Natural Science Foundation of China [30570485]
FX This research was supported by the National Hi-Tech Research and
   Development Program (863) of China (2006AA04Z368) and the National
   Natural Science Foundation of China (30570485).
CR ALTMAN DG, 1994, BRIT MED J, V308, P1552, DOI 10.1136/bmj.308.6943.1552
   [Anonymous], 2009, PROB NEUR NETW
   Bourbakis N, 2005, BIBE 2005: 5th IEEE Symposium on Bioinformatics and Bioengineering, P324
   Buscaglia JM, 2008, CLIN GASTROENTEROL H, V6, P298, DOI 10.1016/j.cgh.2007.12.029
   Canlas KR, 2008, J CLIN GASTROENTEROL, V42, P844, DOI 10.1097/MCG.0b013e318038d312
   Chan FS, 2008, ASIAN J SURG, V31, P96, DOI 10.1016/S1015-9584(08)60066-4
   Eliakim R, 2004, DIGEST LIVER DIS, V36, P519, DOI 10.1016/j.dld.2004.03.011
   Hwang S., 2006, P SOC PHOTO-OPT INS, V6144, P1
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jung Y. S., INT C BIOMEDICAL ENG, V1, P859
   Kameda N, 2006, GASTROINTEST ENDOSC, V63, pAB162, DOI 10.1016/j.gie.2006.03.329
   Li BP, 2008, CAN CON EL COMP EN, P1875
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Mackiewicz M., 2008, SPIE, V6914, pR1
   National digestive diseases information clearinghouse, 2004, BLEED DIG TRACT, V7, P1
   Pan G., 2009, Journal of Medical Engineering & Technology, V33, P575, DOI 10.1080/03091900903111974
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Storch IM, 2006, GASTROINTEST ENDOSC, V63, pAB192, DOI 10.1016/j.gie.2006.03.443
   Sturniolo GC, 2006, AM J MED, V119, P341, DOI 10.1016/j.amjmed.2005.08.029
   Swain P., 2001, SPIE, V4158, P19
NR 20
TC 83
Z9 87
U1 1
U2 17
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD DEC
PY 2011
VL 35
IS 6
BP 1477
EP 1484
DI 10.1007/s10916-009-9424-0
PG 8
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA 859ZJ
UT WOS:000297914200014
PM 20703770
DA 2023-04-20
ER

PT J
AU Leeds, J
   McAlindon, ME
   Grant, J
   Robson, HE
   Morley, SR
   James, G
   Hoeroldt, B
   Kapur, K
   Dear, K
   Hensman, J
   Worden, K
   Sanders, DS
AF Leeds, John
   McAlindon, Mark E.
   Grant, Julia
   Robson, Helen E.
   Morley, Stephen R.
   James, Gary
   Hoeroldt, Barbara
   Kapur, Kapil
   Dear, Keith
   Hensman, James
   Worden, Keith
   Sanders, David S.
TI Albumin level and patient age predict outcomes in patients referred for
   gastrostomy insertion: internal and external validation of a gastrostomy
   score and comparison with artificial neural networks
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID PERCUTANEOUS ENDOSCOPIC GASTROSTOMY; UPPER GASTROINTESTINAL HEMORRHAGE;
   CANCER-PATIENTS; INTENSIVE-CARE; MORTALITY; COMPLICATIONS; SURVIVAL;
   STROKE
AB Background: Significant mortality after gastrostomy insertion remains and some risk factors have been identified, but no predictive scoring system exists.
   Objective: To identify risk factors for mortality, formulate a predictive scoring system, and validate the score. Comparison to an artificial neural network (ANN).
   Design: Endoscopic database analysis.
   Setting: Six hospitals (2 teaching hospitals) in the South Yorkshire region, United Kingdom.
   Patients: This study involved all patients referred for gastrostomy insertion.
   Intervention: Generation of clinical scores to predict 30-day mortality in patients undergoing gastrostomy insertion.
   Main Outcome Measurements: Risk factors for 30-day mortality. Internal and external validation of the score. Comparison with an ANN.
   Results: Univariate analysis showed that 30-day mortality was associated with age, albumin levels, and cardiac and neurological comorbidities. Multivariate analysis showed that only age and albumin levels were independent. Modeling provided scores of 0, 1, 2, and 3 corresponding to 30-day mortalities of 0% (0-2.1), 7% (2.9-13.9), 21.3% (13.5-30.9), and 37.3% (24.1-51.9), respectively. Application of the scoring system at the other teaching hospital and the 4 district general hospitals gave 30-day mortality rates that were not significantly different from those predicted. Receiver operating characteristic curves for the score and the ANN were comparable.
   Limitations: Nonrandomized study. Score not used as a decision-making tool.
   Conclusion: The gastrostomy score provides an estimate of 30-day mortality for patients (and their relatives) when gastrostomy insertion is being discussed. This score requires evaluation as a decision-making tool in clinical practice. ANN analysis results were similar to the outcomes from the clinical score. (Gastrointest Endosc 2011;74:1033-9.)
C1 [Leeds, John; McAlindon, Mark E.; Grant, Julia; Robson, Helen E.; Sanders, David S.] Royal Hallamshire Hosp, Gastroenterol & Liver Unit, Sheffield S10 2JF, S Yorkshire, England.
   [Morley, Stephen R.] Royal Hallamshire Hosp, Dept Clin Chem, Sheffield S10 2JF, S Yorkshire, England.
   [James, Gary] Doncaster Royal Infirm, Dept Gastroenterol, Doncaster DN2 5LT, England.
   [Hoeroldt, Barbara] Rotherham Dist Gen Hosp, Dept Gastroenterol, Rotherham, S Yorkshire, England.
   [Kapur, Kapil] Barnsley Dist Gen Hosp, Dept Gastroenterol, Barnsley, S Yorkshire, England.
   [Dear, Keith] Chesterfield & N Derbyshire Royal Hosp, Dept Gastroenterol, Chesterfield, Derby, England.
   [Hensman, James; Worden, Keith] Univ Sheffield, Dept Mech Engn, Sheffield, S Yorkshire, England.
C3 University of Sheffield; University of Sheffield; University of
   Sheffield
RP Leeds, J (通讯作者)，Aberdeen Royal Infirm, Room 2-39,Ashgrove House,Foresterhill Rd, Aberdeen AB25 2ZN, Scotland.
EM j.leeds@nhs.net
RI Leeds, John/W-4890-2019
OI Leeds, John/0000-0002-5140-6225; Worden, Keith/0000-0002-1035-238X;
   Hensman, James/0000-0002-4989-3589; Hoeroldt,
   Barbara/0000-0001-8154-8155
FU Bardhan Research and Education Trust of Rotherham, Core; Sheffield
   Charitable Trust
FX Funding was provided by The Bardhan Research and Education Trust of
   Rotherham, Core, and the Sheffield Charitable Trust. No other financial
   relationships relevant to this publication were disclosed.
CR Abuksis G, 2000, AM J GASTROENTEROL, V95, P128
   BAXT WG, 1992, ANN EMERG MED, V21, P1439, DOI 10.1016/S0196-0644(05)80056-3
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   BEST WR, 1976, GASTROENTEROLOGY, V70, P439
   Bishop Christopher M., 1995, NEURAL NETWORKS PATT, DOI DOI 10.5555/235248
   Blomberg J, 2011, GASTROINTEST ENDOSC, V73, P29, DOI 10.1016/j.gie.2010.09.012
   CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Das A, 2008, GASTROENTEROLOGY, V134, P65, DOI 10.1053/j.gastro.2007.10.037
   Dennis M, 2005, LANCET, V365, P2005, DOI 10.1016/S0140-6736(05)66691-3
   Donnan GA, 2005, LANCET, V365, P729
   Figueiredo FAF, 2007, ENDOSCOPY, V39, P333, DOI 10.1055/s-2007-966198
   Forrest EH, 2005, GUT, V54, P1174, DOI 10.1136/gut.2004.050781
   GAUDERER MWL, 1980, J PEDIATR SURG, V15, P872, DOI 10.1016/S0022-3468(80)80296-X
   GIBSON SE, 1992, ANN OTO RHINOL LARYN, V101, P46, DOI 10.1177/000348949210100113
   HIGAKI F, 2007, AM J GASTROENTEROL, V102, P1
   Janes S E J, 2005, J Postgrad Med, V51, P23
   Johnston SD, 2008, GASTROINTEST ENDOSC, V68, P223, DOI 10.1016/j.gie.2007.10.019
   Lang A, 2004, ENDOSCOPY, V36, P522, DOI 10.1055/s-2004-814400
   Nabney I.T., 2004, NETLAB ALGORITHMS PA
   Nickas G, 2000, ARCH INTERN MED, V160, P541, DOI 10.1001/archinte.160.4.541
   Norton B, 1996, BRIT MED J, V312, P13, DOI 10.1136/bmj.312.7022.13
   Potgieter PD, 1996, INTENS CARE MED, V22, P1301, DOI 10.1007/s001340050255
   Rockall TA, 1996, GUT, V38, P316, DOI 10.1136/gut.38.3.316
   Rotondano G, 2011, GASTROINTEST ENDOSC, V73, P218, DOI 10.1016/j.gie.2010.10.006
   Sanders DS, 2002, AM J GASTROENTEROL, V97, P2239
   Sanders DS, 2000, AM J GASTROENTEROL, V95, P1472, DOI 10.1111/j.1572-0241.2000.02079.x
   SENFT M, 1993, SUPPORT CARE CANCER, V1, P272, DOI 10.1007/BF00366049
   Takayama T, 2009, EUR J GASTROEN HEPAT, V21, P1279, DOI 10.1097/MEG.0b013e32832a4eae
   Tarassenko L., 1998, GUIDE NEURAL COMPUTI
NR 30
TC 17
Z9 17
U1 0
U2 3
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD NOV
PY 2011
VL 74
IS 5
BP 1033
EP U262
DI 10.1016/j.gie.2011.07.043
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 845ZP
UT WOS:000296867300014
PM 22032317
DA 2023-04-20
ER

PT J
AU Cheng, DC
   Ting, WC
   Chen, YF
   Jiang, XY
AF Cheng, Da-Chuan
   Ting, Wen-Chien
   Chen, Yung-Fu
   Jiang, Xiaoyi
TI AUTOMATIC DETECTION OF COLORECTAL POLYPS IN STATIC IMAGES
SO BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS
LA English
DT Article
DE Colorectal polyps detection; Textural features; Support vector machine
ID FEATURE-EXTRACTION; CLASSIFICATION; COLONOSCOPY; FEATURES; SYSTEM
AB Colorectal cancer continues to be one of the leading causes of mortality worldwide. Scanning using colorectal endoscopy is a useful and common method in clinical examinations. However, the scanning and polyps detections are performed by physicians. Failures to detect polyps might be caused due to lack of experience or knowledge. The purpose of this paper is to discover a scheme able to distinguish polyps from normal tissue in static images off-line. Texture features are studied for the discrimination between polyps and normal tissue. Two useful and simple features are proposed. The student's t-test is applied in selecting useful features to reduce the computation time. The support vector machine is used as a classifier to identify the position of polyps. A study on the numbers in the training patterns is done in order to select an optimal ratio between the polyps and non-polyps sub-images. Seventy-four colonoscopic images are collected to test the system. Half are used as training images and half for testing. The experimental result shows the system can identify all polyps if the colonoscopic images contain a single polyp. The sensitivity is 86.2% and the false-positive rate is 1.26 marks per image.
C1 [Cheng, Da-Chuan] China Med Univ, Dept Biomed Imaging & Radiol Sci, Taichung, Taiwan.
   [Ting, Wen-Chien] China Med Univ Hosp, Taichung, Taiwan.
   [Chen, Yung-Fu] China Med Univ, Dept Hlth Serv Adm, Taichung, Taiwan.
   [Jiang, Xiaoyi] Univ Munster, Dept Math & Comp Sci, D-4400 Munster, Germany.
C3 China Medical University Taiwan; China Medical University Taiwan; China
   Medical University Hospital - Taiwan; China Medical University Taiwan;
   University of Munster
RP Cheng, DC (通讯作者)，China Med Univ, Dept Biomed Imaging & Radiol Sci, 91 Xueshi Rd, Taichung, Taiwan.
EM dccheng@mail.cmu.edu.tw; milka3670@pchome.com.tw;
   yungfu@mail.cmu.edu.tw; xjiang@math.uni-muenster.de
RI Jiang, Xiaoyi/AAA-3532-2022; Cheng, Da-Chuan/M-2431-2013
OI Jiang, Xiaoyi/0000-0001-7678-9528; Cheng, Da-Chuan/0000-0001-7955-9234
FU China Medical University [CMU-95-280]
FX The authors would like to acknowledge China Medical University for
   supporting this research work under project CMU-95-280.
CR *AM CANC SOC, 2003, CANC FACTS FIG
   Chen YH, 2008, INT J PATTERN RECOGN, V22, P747, DOI 10.1142/S0218001408006454
   Cheng DC, 2008, LECT NOTES ARTIF INT, V5108, P62, DOI 10.1007/978-3-540-70715-8_6
   Chowdhury TA, 2006, COMPUT MED IMAG GRAP, V30, P427, DOI 10.1016/j.compmedimag.2006.06.004
   COHEN P, 1989, IEEE T ACOUST SPEECH, V37, P125, DOI 10.1109/29.17510
   CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008
   Esgiar A N, 1998, IEEE Trans Inf Technol Biomed, V2, P197, DOI 10.1109/4233.735785
   Esgiar AN, 1998, ANAL QUANT CYTOL, V20, P297
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Luaces O, 2009, ARTIF INTELL MED, V45, P63, DOI 10.1016/j.artmed.2008.11.005
   Nagata S, 2000, INT J ONCOL, V16, P927
   OHANIAN PP, 1992, PATTERN RECOGN, V25, P819, DOI 10.1016/0031-3203(92)90036-I
   Oktay Ayse Betul, 2011, J MED BIOL IN PRESS
   Perner P, 2002, ARTIF INTELL MED, V26, P161, DOI 10.1016/S0933-3657(02)00057-X
   Puig D, 2007, INT J PATTERN RECOGN, V21, P1159, DOI 10.1142/S0218001407005879
   REX DK, 1990, GASTROENTEROLOGY, V98, P855, DOI 10.1016/0016-5085(90)90007-N
   Rizzi M, 2010, J MED BIOL ENG, V30, P181
   Scholkopf B, 2002, ENCY BIOSTATISTICS
   Shih FY, 2008, INT J PATTERN RECOGN, V22, P323, DOI 10.1142/S0218001408006223
   Taylor SA, 2006, RADIOLOGY, V239, P759, DOI 10.1148/radiol.2392050483
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Walker R. F., 1995, Conference Proceedings DICTA-95. Digital Image Computing: Techniques and Applications, P643
NR 24
TC 11
Z9 12
U1 0
U2 4
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 1016-2372
EI 1793-7132
J9 BIOMED ENG-APP BAS C
JI Biomed. Eng.-Appl. Basis Commun.
PD OCT
PY 2011
VL 23
IS 5
BP 357
EP 367
DI 10.4015/S1016237211002761
PG 11
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 848OD
UT WOS:000297060000003
DA 2023-04-20
ER

PT J
AU Karargyris, A
   Bourbakis, N
AF Karargyris, Alexandros
   Bourbakis, Nikolaos
TI Detection of Small Bowel Polyps and Ulcers in Wireless Capsule Endoscopy
   Videos
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Bleeding; blood based; data mining; endoscopy; medical imaging; polyps;
   protrusions; small bowel; SUSAN edge detector; ulcers; wireless capsule
ID SPATIAL-FREQUENCY; SEGMENTATION
AB Over the last decade, wireless capsule endoscopy (WCE) technology has become a very useful tool for diagnosing diseases within the human digestive tract. Physicians using WCE can examine the digestive tract in a minimally invasive way searching for pathological abnormalities such as bleeding, polyps, ulcers, and Crohn's disease. To improve effectiveness of WCE, researchers have developed software methods to automatically detect these diseases at a high rate of success. This paper proposes a novel synergistic methodology for automatically discovering polyps (protrusions) and perforated ulcers in WCE video frames. Finally, results of the methodology are given and statistical comparisons are also presented relevant to other works.
C1 [Karargyris, Alexandros] NIH, Natl Lib Med, Bethesda, MD 20894 USA.
   [Bourbakis, Nikolaos] Wright State Univ, Assist Technol Res Ctr, Coll Engn, Dayton, OH 45435 USA.
   [Bourbakis, Nikolaos] AIIS, Dayton, OH 45458 USA.
C3 National Institutes of Health (NIH) - USA; NIH National Library of
   Medicine (NLM); University System of Ohio; Wright State University
   Dayton
RP Karargyris, A (通讯作者)，NIH, Natl Lib Med, Bethesda, MD 20894 USA.
EM akarargyris@gmail.com; nikolaos.bourbakis@wright.edu
FU American Institute of Indian Studies
FX Manuscript received December 14, 2010; revised March 3, 2011 and April
   18, 2011; accepted April 27, 2011. Date of publication May 16, 2011;
   date of current version September 21, 2011. This work was supported in
   part by the American Institute of Indian Studies. Asterisk indicates
   corresponding author.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   [Anonymous], 2007, INT J INF TECHNOL
   Barbosa DJC, 2009, IEEE ENG MED BIO, P6683, DOI 10.1109/IEMBS.2009.5334013
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Inoue T, 2001, IEEE IJCNN, P1449, DOI 10.1109/IJCNN.2001.939575
   Jerebko AK, 2003, P SOC PHOTO-OPT INS, V5031, P359, DOI 10.1117/12.480696
   Karargyris A, 2011, IEEE T MED IMAGING, V30, P957, DOI 10.1109/TMI.2010.2098882
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karnam Umaprasanna S., 2001, Curr Treat Options Gastroenterol, V4, P15, DOI 10.1007/s11938-001-0043-1
   Konukoglu E, 2007, IEEE T MED IMAGING, V26, P1649, DOI 10.1109/TMI.2007.901429
   Lau PY, 2007, P ANN INT IEEE EMBS, P5601, DOI 10.1109/IEMBS.2007.4353616
   Li BP, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P234, DOI 10.1109/WCICA.2008.4592930
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   MOGHADDAMZADEH A, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P83, DOI 10.1109/FUZZY.1994.343713
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   Sidhu R, 2007, GASTROENTEROL NURS, V30, P45, DOI 10.1097/00001610-200701000-00005
   Tkalcic M, 2003, IEEE REGION 8 EUROCON 2003, VOL A, PROCEEDINGS, P304
   Vapnik V.N., 1989, STAT LEARNING THEORY
   WEBSTER MA, 1985, J OPT SOC AM A, V2, P1124, DOI 10.1364/JOSAA.2.001124
   Yao JH, 2004, IEEE T MED IMAGING, V23, P1344, DOI 10.1109/TMI.2004.826941
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
   Zhao LX, 2006, IEEE T VIS COMPUT GR, V12, P885, DOI 10.1109/TVCG.2006.158
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 35
TC 119
Z9 122
U1 1
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD OCT
PY 2011
VL 58
IS 10
BP 2777
EP 2786
DI 10.1109/TBME.2011.2155064
PN 1
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 823JR
UT WOS:000295119000009
PM 21592915
DA 2023-04-20
ER

PT J
AU Fusaroli, P
   Saftoiu, A
   Mancino, MG
   Caletti, G
   Eloubeidi, MA
AF Fusaroli, Pietro
   Saftoiu, Adrian
   Mancino, Maria Grazia
   Caletti, Giancarlo
   Eloubeidi, Mohamad A.
TI Techniques of image enhancement in EUS (with videos)
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
ID ENDOSCOPIC ULTRASOUND ELASTOGRAPHY; FINE-NEEDLE-ASPIRATION;
   NEURAL-NETWORK ANALYSIS; PANCREATIC-CANCER; DIFFERENTIAL-DIAGNOSIS;
   SCANNING ECHOENDOSCOPE; PORTAL-HYPERTENSION; ESOPHAGEAL-VARICES; VOLUME
   MEASUREMENT; HARMONIC EUS
C1 [Fusaroli, Pietro; Mancino, Maria Grazia; Caletti, Giancarlo] Univ Bologna, Hosp Imola, Gastroenterol Unit, Dept Clin Med, Bologna, Italy.
   [Saftoiu, Adrian] Univ Med & Pharm, Res Ctr Gastroenterol & Hepatol, Craiova, Romania.
   [Eloubeidi, Mohamad A.] Amer Univ Beirut, Med Ctr, Beirut, Lebanon.
C3 Azienda USL di Imola; University of Bologna; University of Medicine &
   Pharmacy of Craiova; American University of Beirut
RP Fusaroli, P (通讯作者)，Univ Bologna AUSL Imola, Osped Castel S Pietro Terme BO, Viale Oriani 1, I-40024 Bologna, Italy.
RI Saftoiu, Adrian/C-2792-2011; Mancino, Maria Grazia/AAC-4125-2022;
   Fusaroli, Pietro/AAC-2182-2020
OI Saftoiu, Adrian/0000-0001-7993-8269; mancino, maria
   grazia/0000-0003-1771-5056; Fusaroli, Pietro/0000-0002-4397-9314
CR Abe T, 2008, WORLD J GASTROENTERO, V14, P4054, DOI 10.3748/wjg.14.4054
   Agarwal B, 2004, AM J GASTROENTEROL, V99, P844, DOI 10.1111/j.1572-0241.2004.04177.x
   Sanchez MVA, 2009, GASTROINTEST ENDOSC, V69, pS71, DOI 10.1016/j.gie.2008.12.004
   Anderson MA, 2002, GASTROINTEST ENDOSC, V56, P573, DOI 10.1067/mge.2002.127761
   Bhutani MS, 2008, GASTROINTEST ENDOSC, V67, P868, DOI 10.1016/j.gie.2007.12.061
   Bhutani MS, 2004, ENDOSCOPY, V36, P385, DOI 10.1055/s-2004-814320
   Buchanan GN, 2005, DIS COLON RECTUM, V48, P141, DOI 10.1007/s10350-004-0752-3
   CALETTI G, 1990, GASTROINTEST ENDOSC, V36, pS21, DOI 10.1016/S0016-5107(90)71011-5
   CALETTI GC, 1986, SCAND J GASTROENTERO, V21, P74, DOI 10.3109/00365528609091866
   Claudon M, 2008, ULTRASCHALL MED, V29, P28, DOI 10.1055/s-2007-963785
   Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036
   Dietrich CF, 2005, Z GASTROENTEROL, V43, P1219, DOI 10.1055/s-2005-858662
   Dietrich CF, 2008, CLIN GASTROENTEROL H, V6, P590, DOI 10.1016/j.cgh.2008.02.030
   Eisen GM, 2001, GASTROINTEST ENDOSC, V54, P811, DOI 10.1016/S0016-5107(01)70082-X
   Eloubeidi MA, 2003, CANCER CYTOPATHOL, V99, P285, DOI 10.1002/cncr.11643
   Eloubeidi MA, 2008, J GASTROEN HEPATOL, V23, P567, DOI 10.1111/j.1440-1746.2007.05119.x
   Eloubeidi MA, 2007, J GASTROINTEST SURG, V11, P813, DOI 10.1007/s11605-007-0151-x
   Frey H, 2003, RADIOLOGE, V43, P850, DOI 10.1007/s00117-003-0943-2
   Fritscher-Ravens A, 2005, AM J GASTROENTEROL, V100, P1296, DOI 10.1111/j.1572-0241.2005.41681.x
   Fritscher-Ravens A, 2002, AM J GASTROENTEROL, V97, P2768
   Fusaroli P, 2007, ENDOSCOPY, V39, P813, DOI 10.1055/s-2007-966590
   Fusaroli P, 2010, CLIN GASTROENTEROL H, V8, P629, DOI 10.1016/j.cgh.2010.04.012
   Futawatari N, 2008, ANTICANCER RES, V28, P2907
   Giovannini M, 2006, ENDOSCOPY, V38, P344, DOI 10.1055/s-2006-925158
   Giovannini M, 2009, WORLD J GASTROENTERO, V15, P1587, DOI 10.3748/wjg.15.1587
   GORUNESCU F, EXPERT SYSTEMS
   Hirche TO, 2008, ENDOSCOPY, V40, P910, DOI 10.1055/s-2008-1077726
   Hirooka Y, 1997, GASTROINTEST ENDOSC, V46, P166, DOI 10.1016/S0016-5107(97)70067-1
   Hocke M, 2006, WORLD J GASTROENTERO, V12, P246, DOI 10.3748/wjg.v12.i2.246
   Hunerbein M, 2000, SURG ENDOSC-ULTRAS, V14, P1005, DOI 10.1007/s004640000345
   Iglesias-Garcia J, 2010, GASTROENTEROLOGY, V139, P1172, DOI 10.1053/j.gastro.2010.06.059
   Iglesias-Garcia J, 2009, GASTROINTEST ENDOSC, V70, P1101, DOI 10.1016/j.gie.2009.05.011
   Inui K, 2006, ENDOSCOPY, V38, pS47, DOI 10.1055/s-2006-946651
   Ishikawa H, 2003, GASTROINTEST ENDOSC, V57, P931, DOI 10.1016/S0016-5107(03)70037-6
   Ishikawa T, 2010, GASTROINTEST ENDOSC, V71, P951, DOI 10.1016/j.gie.2009.12.023
   Janssen J, 2007, ENDOSCOPY, V39, P952, DOI 10.1055/s-2007-966946
   Janssen J, 2007, GASTROINTEST ENDOSC, V65, P971, DOI 10.1016/j.gie.2006.12.057
   Kim JC, 2002, SURG ENDOSC, V16, P1280, DOI 10.1007/s00464-001-8277-5
   Kitano M, 2008, GASTROINTEST ENDOSC, V67, P141, DOI 10.1016/j.gie.2007.07.045
   Krishna NB, 2009, GASTROINTEST ENDOSC, V70, P70, DOI 10.1016/j.gie.2008.10.030
   Kumon RE, 2007, GASTROINTEST ENDOSC, V66, P1096, DOI 10.1016/j.gie.2007.05.052
   Molin S, 1999, Eur J Ultrasound, V10, P171, DOI 10.1016/S0929-8266(99)00061-0
   Murad-Regadas SM, 2010, DIS COLON RECTUM, V53, P1035, DOI 10.1007/DCR.0b013e3181dce163
   Napoleon B, 2010, ENDOSCOPY, V42, P564, DOI 10.1055/s-0030-1255537
   Nguyen VX, 2010, J ULTRAS MED, V29, P1345, DOI 10.7863/jum.2010.29.9.1345
   Niwa K, 2004, J GASTROEN HEPATOL, V19, P454, DOI 10.1111/j.1440-1746.2003.03317.x
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644
   Ohno E, 2009, ANN SURG, V249, P628, DOI 10.1097/SLA.0b013e3181a189a8
   Papanikolaou IS, 2009, SCAND J GASTROENTERO, V44, P93, DOI 10.1080/00365520802400859
   Romagnuolo J, 2011, GASTROINTEST ENDOSC, V73, P52, DOI 10.1016/j.gie.2010.09.014
   Saftoiu A, 2006, ULTRASCHALL MED, V27, P535, DOI 10.1055/s-2006-927117
   Saftoiu A, 2006, J ULTRAS MED, V25, P363
   SAFTOIU A, 2011, WORLD J GAS IN PRESS
   SAFTOIU A, 2011, ENDOSCOPY IN PRESS
   Saftoiu A, 2008, GASTROINTEST ENDOSC, V68, P1086, DOI 10.1016/j.gie.2008.04.031
   Saftoiu A, 2007, GASTROINTEST ENDOSC, V66, P291, DOI 10.1016/j.gie.2006.12.039
   Saftoiu Adrian, 2006, J Gastrointestin Liver Dis, V15, P161
   Saftoiu A, 2010, GASTROINTEST ENDOSC, V72, P739, DOI 10.1016/j.gie.2010.02.056
   Saftoiu A, 2009, J GASTROINTEST LIVER, V18, P501
   Sakamoto H, 2008, ULTRASOUND MED BIOL, V34, P525, DOI 10.1016/j.ultrasmedbio.2007.09.018
   Sakamoto H, 2011, GASTROINTEST ENDOSC, V73, P227, DOI 10.1016/j.gie.2010.10.011
   Santoro GA, 2007, DIS COLON RECTUM, V50, P359, DOI 10.1007/s10350-006-0767-z
   Sato T, 2006, J GASTROENTEROL, V41, P28, DOI 10.1007/s00535-005-1719-4
   Sato T, 2003, DIGEST ENDOSC, V15, P275
   Sato T, 2008, AM J GASTROENTEROL, V103, P575, DOI 10.1111/j.1572-0241.2007.01644.x
   Sato T, 2009, HEPATOL RES, V39, P126, DOI 10.1111/j.1872-034X.2008.00415.x
   Seicean A, 2010, ULTRASCHALL MED, V31, P571, DOI 10.1055/s-0029-1245833
   Shiina Tsuyoshi, 2002, J Med Ultrason (2001), V29, P119, DOI 10.1007/BF02481234
   Soriano A, 2004, AM J GASTROENTEROL, V99, P492, DOI 10.1111/j.1572-0241.2004.04087.x
   Sumiyama K, 2002, GASTROINTEST ENDOSC, V55, P723, DOI 10.1067/mge.2002.123276
   Tokiyama H, 1999, J GASTROEN HEPATOL, V14, P1212, DOI 10.1046/j.1440-1746.1999.02031.x
   Varadarajulu S, 2005, GASTROINTEST ENDOSC, V62, P728, DOI 10.1016/j.gie.2005.06.051
   Watanabe M, 2004, ENDOSCOPY, V36, P976, DOI 10.1055/s-2004-825866
   West RL, 2005, INT J COLORECTAL DIS, V20, P328, DOI 10.1007/s00384-004-0693-2
   Xia Y, 2010, GASTROINTEST ENDOSC, V72, P637, DOI 10.1016/j.gie.2010.04.013
   Yoshino J, 2000, ENDOSCOPY, V32, P624
   Zhang MM, 2010, GASTROINTEST ENDOSC, V72, P978, DOI 10.1016/j.gie.2010.06.042
NR 77
TC 35
Z9 38
U1 1
U2 13
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD SEP
PY 2011
VL 74
IS 3
BP 645
EP 655
DI 10.1016/j.gie.2011.03.1246
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 817GV
UT WOS:000294660200027
PM 21679945
DA 2023-04-20
ER

PT J
AU Bergholt, MS
   Zheng, W
   Lin, K
   Ho, KY
   Teh, M
   Yeoh, KG
   So, JBY
   Huang, ZW
AF Bergholt, Mads Sylvest
   Zheng, Wei
   Lin, Kan
   Ho, Khek Yu
   Teh, Ming
   Yeoh, Khay Guan
   So, Jimmy Bok Yan
   Huang, Zhiwei
TI In vivo diagnosis of gastric cancer using Raman endoscopy and ant colony
   optimization techniques
SO INTERNATIONAL JOURNAL OF CANCER
LA English
DT Article
DE gastric cancer; neoplasia; Raman endoscopy; in vivo diagnosis; ant
   colony optimization; swarm intelligence
ID GENETIC ALGORITHMS; OPTICAL DIAGNOSIS; FEATURE-SELECTION; SPECTROSCOPY;
   AUTOFLUORESCENCE; STOMACH; TISSUE; IDENTIFICATION; PROLIFERATION;
   FLUORESCENCE
AB This study aims to evaluate the clinical utility of image-guided Raman endoscopy for in vivo diagnosis of neoplastic lesions in the stomach at gastroscopy. A rapid-acquisition image-guided Raman endoscopy system with 785-nm excitation has been developed to acquire in vivo gastric tissue Raman spectra within 0.5 sec during clinical gastroscopic examinations. A total of 1,063 in vivo Raman spectra were acquired from 238 tissue sites of 67 gastric patients, in which 934 Raman spectra were from normal tissue whereas 129 Raman spectra were from neoplastic gastric tissue. The swarm intelligence-based algorithm (i.e., ant colony optimization (ACO) integrated with linear discriminant analysis (LDA)) was developed for spectral variables selection to identify the biochemical important Raman bands for differentiation between normal and neoplastic gastric tissue. The ACO-LDA algorithms together with the leave-one tissue site-out, cross validation method identified seven diagnostically important Raman bands in the regions of 850-875, 1,090-1,110, 1,120-1,130, 1,170-1,190, 1,320-1,340, 1,655-1,665 and 1,730-1,745 cm(-1) related to proteins, nucleic acids and lipids of tissue and provided a diagnostic sensitivity of 94.6% and specificity of 94.6% for distinction of gastric neoplasia. The predictive sensitivity of 89.3% and specificity of 97.8% were also achieved for an independent test validation dataset (20% of total dataset). This work demonstrates for the first time that the real-time image-guided Raman endoscopy associated with ACO-LDA diagnostic algorithms has potential for the noninvasive, in vivo diagnosis and detection of gastric neoplasia during clinical gastroscopy.
C1 [Bergholt, Mads Sylvest; Zheng, Wei; Lin, Kan; Huang, Zhiwei] Natl Univ Singapore, Fac Engn, Dept Bioengn, Opt Bioimaging Lab, Singapore 117576, Singapore.
   [Ho, Khek Yu; Yeoh, Khay Guan] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Med, Singapore 117576, Singapore.
   [Ho, Khek Yu; Teh, Ming; Yeoh, Khay Guan; So, Jimmy Bok Yan] Natl Univ Singapore Hosp, Singapore 117548, Singapore.
   [Teh, Ming] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Pathol, Singapore 117576, Singapore.
   [So, Jimmy Bok Yan] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Surg, Singapore 117576, Singapore.
C3 National University of Singapore; National University of Singapore;
   National University of Singapore; National University of Singapore;
   National University of Singapore
RP Huang, ZW (通讯作者)，Natl Univ Singapore, Fac Engn, Dept Bioengn, Opt Bioimaging Lab, 9 Engn Dr 1, Singapore 117576, Singapore.
EM biehzw@nus.edu.sg
RI b, a/K-7942-2012; So, Jimmy BY/B-5761-2011; Huang, Zhiwei/A-2576-2009
OI Bergholt, Mads Sylvest/0000-0003-3986-8942; Huang,
   Zhiwei/0000-0002-0104-9135; So, Jimmy, Bok-Yan/0000-0002-9772-7905
FU National Medical Research Council; Biomedical Research Council; National
   University of Singapore
FX Grant sponsors: National Medical Research Council, Biomedical Research
   Council, National University of Singapore
CR Al-Ani A., 2005, INT J COMPUT INTELL, V2, P53
   Axon A, 2006, BEST PRACT RES CL GA, V20, P697, DOI 10.1016/j.bpg.2006.03.015
   Curran S, 1999, J PATHOL, V189, P300, DOI 10.1002/(SICI)1096-9896(199911)189:3<300::AID-PATH456>3.0.CO;2-C
   Dorigo M, 2005, THEOR COMPUT SCI, V344, P243, DOI 10.1016/j.tcs.2005.05.020
   Drezek R, 2001, J BIOMED OPT, V6, P385, DOI 10.1117/1.1413209
   Georgakoudi I, 2001, GASTROENTEROLOGY, V120, P1620, DOI 10.1053/gast.2001.24842
   Greene CS, 2008, LECT NOTES COMPUT SC, V5217, P37, DOI 10.1007/978-3-540-87527-7_4
   Guyon, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Huang ZW, 2010, J BIOMED OPT, V15, DOI 10.1117/1.3420115
   Huang ZW, 2009, OPT LETT, V34, P758, DOI 10.1364/OL.34.000758
   Huang ZW, 2005, PHOTOCHEM PHOTOBIOL, V81, P1219, DOI 10.1562/2005-02-24-RA-449
   Huang ZW, 2004, INT J ONCOL, V24, P59
   Huang ZW, 2003, INT J CANCER, V107, P1047, DOI 10.1002/ijc.11500
   Huang ZW, 2001, OPT LETT, V26, P1782, DOI 10.1364/OL.26.001782
   Hughes JH, 1998, CANCER CYTOPATHOL, V84, P289, DOI 10.1002/(SICI)1097-0142(19981025)84:5<289::AID-CNCR4>3.0.CO;2-L
   HUNG J, 1991, LASER SURG MED, V11, P99, DOI 10.1002/lsm.1900110203
   Kanan HR, 2008, APPL MATH COMPUT, V205, P716, DOI 10.1016/j.amc.2008.05.115
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Leardi R, 1998, CHEMOMETR INTELL LAB, V41, P195, DOI 10.1016/S0169-7439(98)00051-3
   Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131
   LUCASIUS CB, 1994, ANAL CHIM ACTA, V286, P135, DOI 10.1016/0003-2670(94)80155-X
   MAEDA K, 1995, BRIT J CANCER, V72, P319, DOI 10.1038/bjc.1995.331
   Mayinger B, 2004, GASTROINTEST ENDOSC, V59, P191, DOI 10.1016/S0016-5107(03)02687-7
   Overhiser AJ, 2008, REV GASTROENTEROL DI, V8, P186
   Ressom HW, 2007, BIOINFORMATICS, V23, P619, DOI 10.1093/bioinformatics/btl678
   Saeys Y, 2007, BIOINFORMATICS, V23, pI418, DOI 10.1093/bioinformatics/btm177
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Schut TCB, 2000, ANAL CHEM, V72, P6010, DOI 10.1021/ac000780u
   SEASHOLTZ MB, 1993, ANAL CHIM ACTA, V277, P165, DOI 10.1016/0003-2670(93)80430-S
   Shamsipur M, 2006, J CHEMOMETR, V20, P146, DOI 10.1002/cem.1002
   Short KW, 2005, BIOPHYS J, V88, P4274, DOI 10.1529/biophysj.103.038604
   Stone N, 2004, FARADAY DISCUSS, V126, P141, DOI 10.1039/b304992b
   Teh SK, 2008, BRIT J CANCER, V98, P457, DOI 10.1038/sj.bjc.6604176
   Teh SK, 2010, BRIT J SURG, V97, P550, DOI 10.1002/bjs.6913
   Teh SK, 2010, INT J CANCER, V126, P1920, DOI 10.1002/ijc.24935
   Teh SK, 2009, J RAMAN SPECTROSC, V40, P908, DOI 10.1002/jrs.2197
   Teh SK, 2009, ANALYST, V134, P1232, DOI 10.1039/b811008e
   Teh SK, 2008, J BIOMED OPT, V13, DOI 10.1117/1.2939406
   Verdecchia A, 2003, EUR J CANCER, V39, P1603, DOI 10.1016/S0959-8049(03)00360-5
   Yeoh KG, 2007, J GASTROEN HEPATOL, V22, P970, DOI 10.1111/j.1440-1746.2007.04956.x
NR 40
TC 93
Z9 94
U1 0
U2 39
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0020-7136
EI 1097-0215
J9 INT J CANCER
JI Int. J. Cancer
PD JUN 1
PY 2011
VL 128
IS 11
BP 2673
EP 2680
DI 10.1002/ijc.25618
PG 8
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA 748EE
UT WOS:000289372000017
PM 20726002
OA Bronze
DA 2023-04-20
ER

PT J
AU Rodriguez-Diaz, E
   Castanon, DA
   Singh, SK
   Bigio, IJ
AF Rodriguez-Diaz, Eladio
   Castanon, David A.
   Singh, Satish K.
   Bigio, Irving J.
TI Spectral classifier design with ensemble classifiers and
   misclassification-rejection: application to elastic-scattering
   spectroscopy for detection of colonic neoplasia
SO JOURNAL OF BIOMEDICAL OPTICS
LA English
DT Article
DE ensemble classifiers; error rejection; diagnostic algorithms;
   elastic-scattering spectroscopy; colorectal cancer screening; neoplasia;
   endoscopic diagnosis; support vector machines
ID DIFFUSE-REFLECTANCE SPECTROSCOPY; HIGH-GRADE DYSPLASIA; MULTIVARIATE
   STATISTICAL ALGORITHM; COLONOSCOPIC MISS RATES; SUPPORT VECTOR MACHINE;
   FLUORESCENCE-SPECTRA; CERVICAL PRECANCER; OPTICAL DIAGNOSIS; CANCER;
   AUTOFLUORESCENCE
AB Optical spectroscopy has shown potential as a real-time, in vivo, diagnostic tool for identifying neoplasia during endoscopy. We present the development of a diagnostic algorithm to classify elastic-scattering spectroscopy (ESS) spectra as either neoplastic or non-neoplastic. The algorithm is based on pattern recognition methods, including ensemble classifiers, in which members of the ensemble are trained on different regions of the ESS spectrum, and misclassification-rejection, where the algorithm identifies and refrains from classifying samples that are at higher risk of being misclassified. These "rejected" samples can be reexamined by simply repositioning the probe to obtain additional optical readings or ultimately by sending the polyp for histopathological assessment, as per standard practice. Prospective validation using separate training and testing sets result in a baseline performance of sensitivity = .83, specificity = .79, using the standard framework of feature extraction (principal component analysis) followed by classification (with linear support vector machines). With the developed algorithm, performance improves to Se similar to 0.90, Sp similar to 0.90, at a cost of rejecting 20-33% of the samples. These results are on par with a panel of expert pathologists. For colonoscopic prevention of colorectal cancer, our system could reduce biopsy risk and cost, obviate retrieval of non-neoplastic polyps, decrease procedure time, and improve assessment of cancer risk. (C) 2011 Society of Photo-Optical Instrumentation Engineers (SPIE). [DOI:10.1117/1.3592488]
C1 [Rodriguez-Diaz, Eladio; Singh, Satish K.; Bigio, Irving J.] Boston Univ, Dept Med, Gastroenterol Sect, Sch Med, Boston, MA 02118 USA.
   [Castanon, David A.] Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA.
   [Singh, Satish K.; Bigio, Irving J.] Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA.
C3 Boston University; Boston University; Boston University
RP Rodriguez-Diaz, E (通讯作者)，Boston Univ, Dept Med, Gastroenterol Sect, Sch Med, Med Campus,Suite 504,650 Albany St, Boston, MA 02118 USA.
EM eladior@bu.edu
OI Bigio, Irving/0000-0003-4168-1466; Singh, Satish/0000-0002-7664-3155
FU Bernard M. Gordon Center for Subsurface Sensing and Imaging Systems
   under National Science Foundation [EEC-9986821]; National Cancer
   Institute (NIH) [U54-CA104677]
FX The authors acknowledge the financial support of the Bernard M. Gordon
   Center for Subsurface Sensing and Imaging Systems, under the Engineering
   Research Centers Program of the National Science Foundation (Award No.
   EEC-9986821) and by the National Cancer Institute (NIH) under Grant No.
   U54-CA104677.
CR Aksela M, 2006, PATTERN RECOGN, V39, P608, DOI 10.1016/j.patcog.2005.08.017
   Baak JPA, 2002, J CLIN PATHOL, V55, P910, DOI 10.1136/jcp.55.12.910
   Bigio IJ, 2000, J BIOMED OPT, V5, P221, DOI 10.1117/1.429990
   BIGIO IJ, 2000, J R COLL SURG EDINBU, V45, P267
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang SK, 2005, J BIOMED OPT, V10, DOI 10.1117/1.1899686
   CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406
   CORDELLA LP, 1995, IEEE T NEURAL NETWOR, V6, P1140, DOI 10.1109/72.410358
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   David A, 2005, PATTERN RECOGN LETT, V26, P1029, DOI 10.1016/j.patrec.2004.09.048
   De Stefano C, 2000, IEEE T SYST MAN CY C, V30, P84, DOI 10.1109/5326.827457
   de Veld DCG, 2005, LASER SURG MED, V36, P356, DOI 10.1002/lsm.20122
   Dhar A, 2006, GASTROINTEST ENDOSC, V63, P257, DOI 10.1016/j.gie.2005.07.026
   Duda R. O., 2001, PATTERN CLASSIFICATI, V2nd
   Dunn JM, 2010, GASTROENTEROLOGY, V138, pS664
   Fang H, 2003, IEEE J SEL TOP QUANT, V9, P267, DOI 10.1109/JSTQE.2003.812515
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fukunaga K, 1990, INTRO STAT PATTERN R
   Fumera G, 2002, LECT NOTES COMPUT SC, V2388, P68
   Fumera G, 2000, LECT NOTES COMPUT SC, V1876, P863
   FUMERA G, 2002, 8 CONV ASS IT INT AR
   Ge ZF, 1998, APPL SPECTROSC, V52, P833, DOI 10.1366/0003702981944571
   Georgakoudi I, 2001, GASTROENTEROLOGY, V120, P1620, DOI 10.1053/gast.2001.24842
   Golub G. H., 1996, MATRIX COMPUTATIONS, P694
   Hansen L. K., 1997, Open Systems & Information Dynamics, V4, P159, DOI 10.1023/A:1009643503022
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jemal A, 2008, CA-CANCER J CLIN, V58, P71, DOI 10.3322/CA.2007.0010
   Johnson KS, 2004, J BIOMED OPT, V9, P1122, DOI 10.1117/1.1802191
   Kuncheva L, 2004, COMBINING PATTERN CL, DOI [10.1002/0471660264, DOI 10.1002/0471660264]
   LEE C, 1993, IEEE T GEOSCI REMOTE, V31, P792, DOI 10.1109/36.239901
   Lin WM, 2004, J BIOMED OPT, V9, P180, DOI 10.1117/1.1628244
   Lovat LB, 2006, GUT, V55, P1078, DOI 10.1136/gut.2005.081467
   Lovat Laurence, 2004, Gastrointest Endosc Clin N Am, V14, P507, DOI 10.1016/j.giec.2004.03.006
   Lovat LB, 2004, GASTROENTEROLOGY, V126, pA22
   Majumder SK, 2005, J BIOMED OPT, V10, DOI 10.1117/1.1897396
   Majumder SK, 2005, LASER SURG MED, V36, P323, DOI 10.1002/lsm.20160
   Mourant J R, 1996, J Biomed Opt, V1, P192, DOI 10.1117/12.231372
   Mourant JR, 1995, LASER SURG MED, V17, P350, DOI 10.1002/lsm.1900170403
   MUKHERJEE S, 1999, 182AI MIT CTR BIOL C, V182
   Palmer GM, 2003, IEEE T BIO-MED ENG, V50, P1233, DOI 10.1109/TBME.2003.818488
   Platt JC, 2000, ADV NEUR IN, P61
   Postic G, 2002, AM J GASTROENTEROL, V97, P3182
   Ramanujam N, 1996, PHOTOCHEM PHOTOBIOL, V64, P720, DOI 10.1111/j.1751-1097.1996.tb03130.x
   Ramanujam N, 1996, LASER SURG MED, V19, P46, DOI 10.1002/(SICI)1096-9101(1996)19:1<46::AID-LSM7>3.3.CO;2-J
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Reif R, 2007, APPL OPTICS, V46, P7317, DOI 10.1364/AO.46.007317
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rodriguez-Diaz E, 2011, ROBOT CIM-INT MANUF, V27, P249, DOI 10.1016/j.rcim.2010.06.006
   RODRIGUEZDIAZ E, 2009, P 48 IEEE C DEC CONT, P2558
   SCHAPIRE RE, 1999, P COMP LEARN THEOR 4
   Skurichina M, 2005, LECT NOTES COMPUT SC, V3541, P165
   Smith RA, 2009, CA-CANCER J CLIN, V59, P27, DOI 10.3322/caac.20008
   Tortorella F, 2003, LECT NOTES ARTIF INT, V2734, P106
   Tumer K, 1998, IEEE T BIO-MED ENG, V45, P953, DOI 10.1109/10.704864
   Tung SY, 2001, AM J GASTROENTEROL, V96, P2628
   Vapnik V, 1998, STAT LEARNING THEORY
   Wallace MB, 2000, GASTROENTEROLOGY, V119, P677, DOI 10.1053/gast.2000.16511
   YUAN C, 2003, P IEEE INT C COMP VI, V1, P419
   Zhu Y, 2008, J CHEMOMETR, V22, P130, DOI 10.1002/cem.1117
   Zhu Y, 2009, J BIOMED OPT, V14, DOI 10.1117/1.3194291
   Zonios G, 1999, APPL OPTICS, V38, P6628, DOI 10.1364/AO.38.006628
NR 64
TC 22
Z9 23
U1 0
U2 3
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1083-3668
EI 1560-2281
J9 J BIOMED OPT
JI J. Biomed. Opt.
PD JUN
PY 2011
VL 16
IS 6
AR 067009
DI 10.1117/1.3592488
PG 16
WC Biochemical Research Methods; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
GA 796XM
UT WOS:000293086800035
PM 21721830
OA Bronze, Green Published
DA 2023-04-20
ER

PT J
AU Vecsei, A
   Amann, G
   Hegenbart, S
   Liedlgruber, M
   Uhl, A
AF Vecsei, A.
   Amann, G.
   Hegenbart, S.
   Liedlgruber, M.
   Uhl, A.
TI Automated Marsh-like classification of celiac disease in children using
   local texture operators
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Celiac disease; Computer-aided classification; Endoscopy; LBP; Marsh
   classification; Children
ID ENDOSCOPIC APPROACH; INTESTINAL VILLI; GLUTEN; VISUALIZATION; DIAGNOSIS;
   ACCURACY; BIOPSY
AB Automated classification of duodenal texture patches with histological ground truth in case of pediatric celiac disease is proposed. The classical focus of classification in this context is a two-class problem: mucosa affected by celiac disease and unaffected duodenal tissue. We extend this focus and apply classification according to a modified Marsh scheme into four classes. In addition to other techniques used previously for classification of endoscopic imagery, we apply local binary pattern (LBP) operators and propose two new operator types, one of which adapts to the different properties of wavelet transform subbands. The achieved results are promising in that operators based on LBP turn out to achieve better results compared to many other texture classification techniques as used in earlier work. Specifically, the proposed wavelet-based LBP scheme achieved the best overall accuracy of all feature extraction techniques considered in the two-class case and was among the best in the four-class scheme. Results also show that a classification into four classes is feasible in principle however when compared to the two-class case we note that there is still room for improvement due to various reasons discussed. (C) 2011 Elsevier Ltd. All rights reserved.
C1 [Hegenbart, S.; Liedlgruber, M.; Uhl, A.] Salzburg Univ, Dept Comp Sci, A-5020 Salzburg, Austria.
   [Vecsei, A.] St Anna Childrens Hosp Vienna, Vienna, Austria.
   [Amann, G.] Vienna Med Univ, Dept Pathol, Vienna, Austria.
C3 Salzburg University; Saint Anna Children's Hospital; Medical University
   of Vienna
RP Liedlgruber, M (通讯作者)，Salzburg Univ, Dept Comp Sci, A-5020 Salzburg, Austria.
EM mliedl@cosy.sbg.ac.at
OI Liedlgruber, Michael/0000-0001-8035-6426
FU Austrian National Bank "Jubilaumsfonds" [12991]
FX This work has been supported by the Austrian National Bank
   "Jubilaumsfonds", Project no. 12991. We acknowledge the help of Georg
   Wimmer in computing some feature vectors and significance data.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Cammarota G, 2007, ENDOSCOPY, V39, P46, DOI 10.1055/s-2006-945044
   Cammarota G, 2006, ALIMENT PHARM THER, V23, P61, DOI 10.1111/j.1365-2036.2006.02732.x
   Cammarota G, 2004, GASTROINTEST ENDOSC, V60, P732, DOI 10.1016/S0016-5107(04)02170-4
   Chand N, 2006, J CLIN GASTROENTEROL, V40, P3, DOI 10.1097/01.mcg.0000190644.01661.2b
   Ciaccio EJ, 2010, COMPUT METH PROG BIO, V100, P39, DOI 10.1016/j.cmpb.2010.02.005
   Corazza GR, 2005, J CLIN PATHOL, V58, P573, DOI 10.1136/jcp.2004.023978
   DEWOUWER GV, 1997, P 9 INT C IM AN PROC, P327
   Ensari A, 2010, ARCH PATHOL LAB MED, V134, P826, DOI 10.1043/1543-2165-134.6.826
   Fasano A, 2003, ARCH INTERN MED, V163, P286, DOI 10.1001/archinte.163.3.286
   Fukunaga K, 1990, INTRO STAT PATTERN R
   Gasbarrini A, 2003, GASTROINTEST ENDOSC, V57, P348, DOI 10.1067/mge.2003.116
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gonzales RC., 2002, DIGITAL IMAGE PROCES
   Gross SA, 2006, AM J GASTROENTEROL, V101, P2717, DOI 10.1111/j.1572-0241.2006.00923.x
   Hafner M, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P177
   Hafner M, 2009, PATTERN ANAL APPL, V12, P407, DOI 10.1007/s10044-008-0136-8
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   HAFNER M, 2009, HDB RES ADV TECHNIQU, P335
   Hegenbart S, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P718
   Huang X., 2004, P 3 INT C IM GRAPH I, P1
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   KWITT R, 2007, P IEEE COMP SOC WORK, P1
   Liedlgruber M, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P707
   LIEDLGRUBER M, 2007, P 7 WSEAS INT C WAV, P147
   Liu P, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL I, P218, DOI 10.1109/ISECS.2009.219
   MAENPAA T, 2000, INT C PATT REC, V3, P3947
   Maenpaa T, 2003, THESIS U OULU
   Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MARSH MN, 1992, GASTROENTEROLOGY, V102, P330, DOI 10.1016/0016-5085(92)91819-P
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Niveloni S, 1998, GASTROINTEST ENDOSC, V47, P223, DOI 10.1016/S0016-5107(98)70317-7
   Oberhuber G, 1999, EUR J GASTROEN HEPAT, V11, P1185, DOI 10.1097/00042737-199910000-00019
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Petroniene R, 2005, AM J GASTROENTEROL, V100, P685, DOI 10.1111/j.1572-0241.2005.41069.x
   SAITO N, 1994, P SOC PHOTO-OPT INS, V2303, P2, DOI 10.1117/12.188763
   SAJN L, 2008, EURASIP J ADV SIG PR, V137, P137
   Sajn L, 2011, COMPUT METH PROG BIO, V104, pE75, DOI 10.1016/j.cmpb.2010.06.021
   SU Y, 2009, SMC 09 P 2009 IEEE I, P3274
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Vecsei A., 2008, 4 IET INT C ADV MED, P1, DOI [10.1049/cp:20080465, DOI 10.1049/CP:20080465]
   Vecsei A, 2009, COMPUT METH PROG BIO, V95, pS68, DOI 10.1016/j.cmpb.2009.02.017
   Vilarino F, 2009, BILDVERARBEITUNG MED, V22, P346
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   YOKOI K, 2007, MVA, P487
   Zuiderveld K., 1994, GRAPHICS GEMS
NR 51
TC 40
Z9 42
U1 0
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD JUN
PY 2011
VL 41
IS 6
BP 313
EP 325
DI 10.1016/j.compbiomed.2011.03.009
PG 13
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 784SN
UT WOS:000292178600003
PM 21513927
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Li, BP
   Meng, MQH
   Lau, JYW
AF Li, Baopu
   Meng, Max Q. -H.
   Lau, James Y. W.
TI Computer-aided small bowel tumor detection for capsule endoscopy
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Multi-scale local binary pattern; Classifier ensemble; Computer-aided
   tumor detection; Capsule endoscopy image
ID CLASSIFICATION
AB Objective: Capsule endoscopy is useful in the diagnosis of small bowel diseases. However, the large number of images produced in each test is a tedious task for physicians. To relieve burden of physicians, a new computer-aided detection scheme is developed in this study, which aims to detect small bowel tumors for capsule endoscopy.
   Methods and materials: A novel textural feature based on multi-scale local binary pattern is proposed to discriminate tumor images from normal images. Since tumor in small bowel exhibit great diversities in appearance, multiple classifiers are employed to improve detection accuracy. 1200 capsule endoscopy images chosen from 10 patients' data constitute test data in our experiment.
   Results: Multiple classifiers based on k-nearest neighbor, multilayer perceptron neural network and support vector machine, which are built from six different ensemble rules, are experimented in three different color spaces. The results demonstrate an encouraging detection accuracy of 90.50%, together with a sensitivity of 92.33% and a specificity of 88.67%.
   Conclusion: The proposed scheme using color texture features and classifier ensemble is promising for small bowel tumor detection in capsule endoscopy images. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Li, Baopu; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
   [Lau, James Y. W.] Chinese Univ Hong Kong, Inst Digest Dis, Prince Wales Hosp, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong; Chinese University of Hong Kong; Prince
   of Wales Hospital
RP Li, BP (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
EM greenfigo2008@gmail.com
RI Meng, Q./GSI-6185-2022; Lau, James Y. W./O-2612-2016; meng,
   meng/GWZ-7461-2022; Meng, Max Q.-H./C-8078-2009
OI Lau, James Y. W./0000-0003-0122-4068; 
FU Shun Hing Institute of Advanced Engineering of The Chinese University of
   Hong Kong [8115021]; Innovation and Technology Support Programme in Hong
   Kong [ITS/430/09]
FX This work was supported by SHIAE Project #8115021 of the Shun Hing
   Institute of Advanced Engineering of The Chinese University of Hong Kong
   and Innovation and Technology Support Programme (ITS/430/09) in Hong
   Kong. We thank the anonymous reviewers and editor for their valuable
   comments which greatly improved the quality and clarity of an earlier
   version of this paper.
CR Abyoto K. W., 1998, J TOKYO U INFORM SCI, V2, P49
   Adler DG., 2003, HOSP PHYS, V39, P14
   Alexandre LA, 2001, PATTERN RECOGN LETT, V22, P1283, DOI 10.1016/S0167-8655(01)00073-3
   BEJAKOVIC S, 2009, P INT C ROB AUT MAY, P2793
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   Boulougoura M, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P405
   Duin RP, 2007, PRTOOLS4 1 MATLAB TO, P2600
   GRABISCH M, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P145, DOI 10.1109/FUZZY.1995.409673
   Haykin S., 1996, NEURAL NETWORKS COMP
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   JOHN TC, 2005, AM J SURG, V190, P896
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Keller JM, 1996, INT J APPROX REASON, V15, P1, DOI 10.1016/0888-613X(95)00132-Z
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Postgate A, 2008, GASTROINTEST ENDOSC, V68, P1209, DOI 10.1016/j.gie.2008.06.035
   Signorelli C, 2005, ENDOSCOPY, V37, P1170, DOI 10.1055/s-2005-870410
   Vapnik V., 1999, NATURE STAT LEARNING
   Zabulis X, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3921, DOI 10.1109/IROS.2008.4650969
   Zhou ZW, 1999, WORLD J GASTROENTERO, V5, P273
NR 25
TC 47
Z9 49
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD MAY
PY 2011
VL 52
IS 1
BP 11
EP 16
DI 10.1016/j.artmed.2011.01.003
PG 6
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 780FT
UT WOS:000291840600002
PM 21353503
DA 2023-04-20
ER

PT J
AU Frackiewicz, M
   Palus, H
AF Frackiewicz, Mariusz
   Palus, Henryk
TI KHM CLUSTERING TECHNIQUE AS A SEGMENTATION METHOD FOR ENDOSCOPIC COLOUR
   IMAGES
SO INTERNATIONAL JOURNAL OF APPLIED MATHEMATICS AND COMPUTER SCIENCE
LA English
DT Article
DE biomedical colour image segmentation; k-harmonic means technique;
   k-means technique
AB In this paper, the idea of applying the k-harmonic means (KHM) technique in biomedical colour image segmentation is presented. The k-means (KM) technique establishes a background for the comparison of clustering techniques. Two original initialization methods for both clustering techniques and two evaluation functions are described. The proposed method of colour image segmentation is completed by a postprocessing procedure. Experimental tests realized on real endoscopic colour images show the superiority of KHM over KM.
C1 [Frackiewicz, Mariusz; Palus, Henryk] Silesian Tech Univ, Inst Automat Control, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Frackiewicz, M (通讯作者)，Silesian Tech Univ, Inst Automat Control, Ul Akad 16, PL-44100 Gliwice, Poland.
EM Mariusz.Frackiewicz@polsl.pl; Henryk.Palus@polsl.pl
RI Frackiewicz, Mariusz/K-8826-2019; Frackiewicz, Mariusz/U-9392-2018
OI Frackiewicz, Mariusz/0000-0002-3147-2348; Frackiewicz,
   Mariusz/0000-0002-3147-2348; Palus, Henryk/0000-0002-4044-7531
FU Polish Ministry of Science and Higher Education [R13 046 02]
FX The second author's participation in this work has been partially
   supported by the Polish Ministry of Science and Higher Education under
   Grant No. R13 046 02.
CR Bezdek JC., 1981, PATTERN RECOGN
   Borsotti M, 1998, PATTERN RECOGN LETT, V19, P741, DOI 10.1016/S0167-8655(98)00052-X
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   FRACKIEWICZ M, 2009, P 7 C COMP METH SYST, P469
   FRACKIEWICZ M, 2009, P 7 C COMP METH SYST, P333
   HAMERLY G, 2003, THESIS U CALIFORNIA
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   MacQueen J., 1967, P 5 BERKELEY S MATH, V1, P281
   Palus H, 2007, IMAGE PROCESS SER, P103
   Zhang B., 2000, HPL2000137 TR
   Zhang B, 1999, HPL1999124 TR
NR 12
TC 6
Z9 6
U1 0
U2 5
PU UNIV ZIELONA GORA PRESS
PI ZIELONA GORA
PA UL PODGORNA 50, ZIELONA GORA, 65-246, POLAND
SN 1641-876X
J9 INT J AP MAT COM-POL
JI Int. J. Appl. Math. Comput. Sci.
PD MAR
PY 2011
VL 21
IS 1
BP 203
EP 209
DI 10.2478/v10006-011-0015-0
PG 7
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Mathematics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Mathematics
GA 740AG
UT WOS:000288763300015
OA gold, Green Submitted
DA 2023-04-20
ER

PT J
AU Ong, JL
   Seghouane, AK
AF Ong, Ju Lynn
   Seghouane, Abd-Krim
TI Feature selection using mutual information in CT colonography
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Feature selection; Computed tomography; Support vector classifier;
   Mutual information
ID COMPUTER-AIDED DETECTION; FALSE POSITIVES; POLYPS; REDUCTION
AB Computed tomograpluc (CT) colonography is a promising alternative to traditional invasive colonoscopic methods used in the detection and removal of cancerous growths or polyps in the colon Existing computer-aided diagnosis (CAD) algorithms used in CT colonography typically employ the use of a classifier to discriminate between true and false positives generated by a polyp candidate detection system based on a set of features extracted from the candidates However these classifiers often suffer from a phenomenon termed the curse of dimensionality whereby there is a marked degradation in the performance of a classifier as the number of features used in the classifier is increased In addition an increase in the number of features used also contributes to an increase in computational complexity and demands on storage space
   This paper investigates the benefits of feature selection on a polyp candidate database with the aim of increasing specificity while preserving sensitivity Two new mutual information methods for feature selection are proposed in order to select a subset of features for optimum performance Initial results show that the performance of the widely used support vector machine (SVM) classifier is indeed better with the use of a small set of features with receiver operating characteristic curve (AUC) measures reaching 0 78-0 88 (C) 2010 Elsevier B V All rights reserved
C1 [Ong, Ju Lynn] Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT 2601, Australia.
   NICTA, Canberra, ACT 2601, Australia.
C3 Australian National University; Australian National University
RP Ong, JL (通讯作者)，Australian Natl Univ, Coll Engn & Comp Sci, GPO Box 4, Canberra, ACT 2601, Australia.
OI SEGHOUANE, ABD-KRIM/0000-0003-4619-734X
FU Australian Department of Communications Information Technology and the
   Arts; Australian Research Council; ICT Center of Excellence
FX NICTA is funded by the Australian Department of Communications
   Information Technology and the Arts and the Australian Research Council
   through Backing Australias Ability and the ICT Center of Excellence
   Program
CR Acar B, 2002, IEEE T MED IMAGING, V21, P1461, DOI 10.1109/TMI.2002.806405
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   BIESIADA J, 2005, P INT C RES EL APPL, P109
   Chen Y.-W., 2006, COMBINING SVMS VARIO
   DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jerebko A, 2006, LECT NOTES COMPUT SC, V4191, P169
   Kullback S., 1959, INFORM THEORY STAT
   Nappi J, 2007, ACAD RADIOL, V14, P287, DOI 10.1016/j.acra.2006.11.007
   Suzuki K, 2006, MED PHYS, V33, P3814, DOI 10.1118/1.2349839
   van Ravesteijn VF, IEEE T MED IN PRESS
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Yoshida H, 2005, ABDOM IMAGING, V30, P26, DOI 10.1007/s00261-004-0244-x
   Yoshida H, 2002, RADIOLOGY, V222, P327, DOI 10.1148/radiol.2222010506
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
   Zheng Y, 2006, P 29 ANN INT C EMBS, P4433
NR 19
TC 4
Z9 5
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD JAN 15
PY 2011
VL 32
IS 2
BP 337
EP 341
DI 10.1016/j.patrec.2010.09.012
PG 5
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 700AF
UT WOS:000285703800029
DA 2023-04-20
ER

PT J
AU Figueiredo, IN
   Figueiredo, PN
   Almeida, N
AF Figueiredo, Isabel N.
   Figueiredo, Pedro N.
   Almeida, Nuno
TI Image-Driven Parameter Estimation in Absorption-Diffusion Models of
   Chromoscopy
SO SIAM JOURNAL ON IMAGING SCIENCES
LA English
DT Article
DE image segmentation; inverse problems; partial differential
   equation-constrained optimization; Lagrange multipliers;
   absorption-diffusion equation
ID ABERRANT CRYPT FOCI; METHYLENE-BLUE; COLON-CANCER; CHROMOENDOSCOPY;
   QUANTIFICATION; PATHOGENESIS
AB The administration of dyes and subsequent examination, with a colorimetry visual criterion, is a gastroenterology procedure for distinguishing, in endoscopic images, normal and aberrant colonic crypts. These are thought to be possible precursors of colon cancer. In this paper a combined image segmentation and parameter estimation model is proposed for in vivo colonic crypt images, obtained with chromoscopic colonoscopy. The parameter estimation is an inverse problem. It is formulated as a PDE constrained optimization problem, and involves an absorption-diffusion equation. A Lagrange multiplier formulation is employed and analyzed for resolving this inverse problem. Using only the segmentation of the medical endoscopic image, which separates normal and aberrant crypts, the mathematical model proposed in this paper performs a mathematical and dimensionless quantification (medically noninvasive) of the dye absorption and diffusion coefficients, as well as the dye absorbed, in normal and aberrant colonic crypts. This mathematical quantification can be important for clinicians if it is able to provide a distinction between individuals with and without cancer. Numerical simulations, on a test image and on some medical endoscopic images, are presented for the validation and evaluation of the proposed mathematical model.
C1 [Figueiredo, Isabel N.] Univ Coimbra, CMUC, Dept Math, P-3001454 Coimbra, Portugal.
   [Figueiredo, Pedro N.] Univ Coimbra, Fac Med, P-3004504 Coimbra, Portugal.
   [Figueiredo, Pedro N.; Almeida, Nuno] Univ Hosp Coimbra, Dept Gastroenterol, P-3000075 Coimbra, Portugal.
C3 Universidade de Coimbra; Universidade de Coimbra; Universidade de
   Coimbra; Centro Hospitalar e Universitario de Coimbra (CHUC)
RP Figueiredo, IN (通讯作者)，Univ Coimbra, CMUC, Dept Math, P-3001454 Coimbra, Portugal.
EM isabelf@mat.uc.pt; pnf11@sapo.pt; nuno.p.almeida@clix.pt
RI Figueiredo, Isabel Narra/ABD-7828-2020
OI Figueiredo, Isabel Narra/0000-0002-0215-8851; Almeida,
   Nuno/0000-0003-0499-5888; Figueiredo, Pedro/0000-0001-9872-6341
FU UT Austin \ Portugal Program [UTAustin/MAT/0009/2008]
FX This work was partially supported by the research project
   UTAustin/MAT/0009/2008 of the UT Austin vertical bar Portugal Program
   (https://hfbic91acc83bd3594247h995u9bvnqn966605fiac.eds.tju.edu.cn/).
CR Adler DG, 2002, GASTROINTEST ENDOSC, V56, P657, DOI 10.1067/mge.2002.128540
   [Anonymous], TEXTS APPL MATH
   BIRD RP, 1987, CANCER LETT, V37, P147, DOI 10.1016/0304-3835(87)90157-1
   Bird RP, 2000, TOXICOL LETT, V112, P395, DOI 10.1016/S0378-4274(99)00261-1
   BIRD RP, 1995, CANCER LETT, V93, P55, DOI 10.1016/0304-3835(95)03788-X
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   comsol, COMS MULT
   Dinis-Ribeiro M, 2008, GASTROINTEST ENDOSC, V67, P1209, DOI 10.1016/j.gie.2007.12.043
   Evans L. C., 1998, GRADUATE STUD MATH, V19
   Figueiredo IN, 2010, IEEE T MED IMAGING, V29, P998, DOI 10.1109/TMI.2009.2036258
   Hidovic-Rowe D, 2005, PHYS MED BIOL, V50, P1071, DOI 10.1088/0031-9155/50/6/003
   Hogea C, 2008, J MATH BIOL, V56, P793, DOI 10.1007/s00285-007-0139-x
   Hurlstone DP, 2005, AM J GASTROENTEROL, V100, P1283, DOI 10.1111/j.1572-0241.2005.40891.x
   Ito K, 2008, ADV DES CONTROL, P1
   Kida M, 2003, ENDOSCOPY, V35, P590
   LUDOLPH RA, 1979, J PHYS CHEM-US, V83, P2793, DOI 10.1021/j100484a023
   MAURER H, 1979, MATH PROGRAM, V16, P98, DOI 10.1007/BF01582096
   Murray J, 2002, INTERDISCIP APPL MAT
   NAFTALIN RJ, 1995, J PHYSIOL-LONDON, V487, P479, DOI 10.1113/jphysiol.1995.sp020894
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Olliver JR, 2003, LANCET, V362, P373, DOI 10.1016/S0140-6736(03)14026-3
   Quarteroni A., 2007, TEXTS APPL MATH, V37
   RONCUCCI L, 1991, CANCER EPIDEM BIOMAR, V1, P57
   Swinehart D.F., 1962, J CHEM EDUC, V39, P333, DOI [DOI 10.1021/ED039P333, 10.1021/ed039p333]
   Takayama T, 1998, NEW ENGL J MED, V339, P1277, DOI 10.1056/NEJM199810293391803
   ZOWE J, 1979, APPL MATH OPT, V5, P49, DOI 10.1007/BF01442543
   [No title captured]
   [No title captured]
NR 28
TC 3
Z9 3
U1 0
U2 2
PU SIAM PUBLICATIONS
PI PHILADELPHIA
PA 3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA
SN 1936-4954
J9 SIAM J IMAGING SCI
JI SIAM J. Imaging Sci.
PY 2011
VL 4
IS 3
BP 884
EP 904
DI 10.1137/100798405
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Mathematics, Applied; Imaging Science & Photographic
   Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematics; Imaging Science & Photographic Technology
GA 827CW
UT WOS:000295405200005
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Kulas, Z
   Beres-Pawlik, E
   Wierzbicki, J
AF Kulas, Z.
   Beres-Pawlik, E.
   Wierzbicki, J.
TI Feed Forward Neural Network for Autofluorescence Imaging Classification
SO ACTA PHYSICA POLONICA A
LA English
DT Article
ID EARLY LUNG-CANCER; LOCALIZATION
AB The key elements in cancer diagnostics are the early identification and estimation of the tumor growth and its spread in order to determine the area to be operated on. The aim of our study was to develop new methods of analyzing autofluorescence images which will allow us an objective and accurate assessment of the location of a tumor and will also be helpful in determining the advancement of the disease. The proposed classification methods are based on neural network algorithms. An Olympus company endoscopic system was used for an autofluorescence intestine imaging study. The autofluorescence imaging analysis process can be divided into several main stages. The first step is preparation of a training data set. The second one involves selection of feature space, namely the selection of those features which enable distinguishing the pathologically altered areas from the healthy ones. Final stages of the analysis include pathologically changed tissue classification and diagnosis.
C1 [Kulas, Z.; Beres-Pawlik, E.] Wroclaw Univ Technol, Inst Telecommun Teleinformat & Acoust, PL-50370 Wroclaw, Poland.
   [Wierzbicki, J.] Wroclaw Med Univ, Dept Miniinvas & Proctol Surg, PL-50556 Wroclaw, Poland.
C3 Wroclaw University of Science & Technology; Wroclaw Medical University
RP Kulas, Z (通讯作者)，Wroclaw Univ Technol, Inst Telecommun Teleinformat & Acoust, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.
RI Wierzbicki, Jarosław/AAY-6015-2020
OI Wierzbicki, Jaroslaw/0000-0002-8444-8755
CR Boparai K., 2005, GASTROINTEST ENDOSC, V70, P947
   Curvers WL, 2009, GASTROINTEST ENDOSC, V70, P9, DOI 10.1016/j.gie.2008.10.026
   HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697
   Kara M, 2005, GASTROINTEST ENDOSC, V61, pAB101, DOI 10.1016/S0016-5107(05)00662-0
   Kleck W.L., 1980, DISCRIMINANT ANAL
   Konieczny G, 2009, ACTA PHYS POL A, V116, P344, DOI 10.12693/APhysPolA.116.344
   LAM S, 1993, CHEST, V103, pS12
   Lam S, 1998, CHEST, V113, P696, DOI 10.1378/chest.113.3.696
   Mayer-Base A., 2004, PATTERN RECOGNITION
   PALCIC B, 1991, CHEST, V99, P742, DOI 10.1378/chest.99.3.742
   Tabachnick B. G., 2012, USING MULTIVARIATE S
   Uedo N, 2005, GASTROINTEST ENDOSC, V62, P521, DOI 10.1016/j.gie.2005.06.031
   Wang TD, 2005, GASTROINTEST ENDOSC, V61, P686, DOI 10.1016/S0016-5107(05)00315-9
   Zeng HS, 1998, BIOIMAGING, V6, P151, DOI 10.1002/1361-6374(199812)6:4<151::AID-BIO1>3.0.CO;2-G
NR 14
TC 0
Z9 0
U1 0
U2 1
PU POLISH ACAD SCIENCES INST PHYSICS
PI WARSAW
PA AL LOTNIKOW 32-46, PL-02-668 WARSAW, POLAND
SN 0587-4246
EI 1898-794X
J9 ACTA PHYS POL A
JI Acta Phys. Pol. A
PD DEC
PY 2010
VL 118
IS 6
BP 1189
EP 1193
DI 10.12693/APhysPolA.118.1189
PG 5
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA 704DP
UT WOS:000286031600026
OA gold
DA 2023-04-20
ER

PT J
AU Maslekar, S
   Gardiner, AB
   Monson, JRT
   Duthie, GS
AF Maslekar, S.
   Gardiner, A. B.
   Monson, J. R. T.
   Duthie, G. S.
TI Artificial neural networks to predict presence of significant pathology
   in patients presenting to routine colorectal clinics
SO COLORECTAL DISEASE
LA English
DT Article
DE Artificial neural networks; lower gastrointestinal endoscopy; flexible
   sigmoidoscopy; colonoscopy
ID SYSTEMS; CANCER
AB Aim Artificial neural networks (ANNs) are computer programs used to identify complex relations within data. Routine predictions of presence of colorectal pathology based on population statistics have little meaning for individual patient. This results in large number of unnecessary lower gastrointestinal endoscopies (LGEs - colonoscopies and flexible sigmoidoscopies). We aimed to develop a neural network algorithm that can accurately predict presence of significant pathology in patients attending routine outpatient clinics for gastrointestinal symptoms.
   Method Ethics approval was obtained and the study was monitored according to International Committee on Harmonisation -Good Clinical Practice (ICH-GCP) standards. Three-hundred patients undergoing LGE prospectively completed a specifically developed questionnaire, which included 40 variables based on clinical symptoms, signs, past-and family history. Complete data sets of 100 patients were used to train the ANN; the remaining data was used for internal validation. The primary output used was positive finding on LGE, including polyps, cancer, diverticular disease or colitis. For external validation, the ANN was applied to data from 50 patients in primary care and also compared with the predictions of four clinicians.
   Results Clear correlation between actual data value and ANN predictions were found (r = 0.931; P = 0.0001). The predictive accuracy of ANN was 95% in training group and 90% (95% CI 84-96) in the internal validation set and this was significantly higher than the clinical accuracy (75%). ANN also showed high accuracy in the external validation group (89%).
   Conclusion Artificial neural networks offer the possibility of personal prediction of outcome for individual patients presenting in clinics with colorectal symptoms, making it possible to make more appropriate requests for lower gastrointestinal endoscopy.
C1 Univ Hull, Acad Surg Unit, Kingston Upon Hull HU6 7RX, N Humberside, England.
   Castle Hill Hosp, Kingston Upon Hull, N Humberside, England.
C3 University of Hull; University of Hull
RP Maslekar, S (通讯作者)，Univ Hull, Castle Hill Hosp, Acad Surg Unit, Castle Rd, Cottingham HU16 5JQ, East Yorkshire, England.
EM s.maslekar@hull.ac.uk
RI Gardiner, Angela/B-6941-2014
OI Gardiner, Angela/0000-0001-6209-8275; Maslekar,
   Sushil/0000-0002-8233-8480
CR Andriulli A, 2007, EUR J GASTROEN HEPAT, V19, P1055, DOI 10.1097/MEG.0b013e3282f198b2
   Bottaci L, 1997, LANCET, V350, P469, DOI 10.1016/S0140-6736(96)11196-X
   Chohan DPK, 2005, COLORECTAL DIS, V7, P450, DOI 10.1111/j.1463-1318.2005.00821.x
   Chu A, 2008, ARTIF INTELL MED, V42, P247, DOI 10.1016/j.artmed.2007.10.003
   CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2
   Das A, 2008, GASTROENTEROLOGY, V134, P65, DOI 10.1053/j.gastro.2007.10.037
   *DEP HLTH, 1999, 1999241 HSC DEP HLTH
   Gardiner A, 2004, DIS COLON RECTUM, V47, P192, DOI 10.1007/s10350-003-0026-5
   Harrison RF, 2005, ANN EMERG MED, V46, P431, DOI 10.1016/j.annemergmed.2004.09.012
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Jiwa M, 2004, BRIT J GEN PRACT, V54, P608
   Lahner E, 2005, WORLD J GASTROENTERO, V11, P5867, DOI 10.3748/wjg.v11.i37.5867
   Lim CP, 1997, ARTIF INTELL MED, V11, P215, DOI 10.1016/S0933-3657(97)00035-3
   McClelland J. L., 1986, PARALLEL DISTRIBUTED, V1, DOI DOI 10.7551/MITPRESS/5236.001.0001
   SHORTLIFFE EH, 1986, WESTERN J MED, V145, P830
   Terraz O, 2005, DIGESTION, V71, P72, DOI 10.1159/000084522
   1990, NEURAL NETWORK ARCHI
   1994, NEURAL NETWORKS COMP
NR 18
TC 5
Z9 5
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1462-8910
EI 1463-1318
J9 COLORECTAL DIS
JI Colorectal Dis.
PD DEC
PY 2010
VL 12
IS 12
BP 1254
EP 1259
DI 10.1111/j.1463-1318.2009.02005.x
PG 6
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 679NK
UT WOS:000284167900014
PM 19604289
DA 2023-04-20
ER

PT J
AU Suzuki, K
   Zhang, J
   Xu, JW
AF Suzuki, Kenji
   Zhang, Jun
   Xu, Jianwu
TI Massive-Training Artificial Neural Network Coupled With
   Laplacian-Eigenfunction-Based Dimensionality Reduction for
   Computer-Aided Detection of Polyps in CT Colonography
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Computer-aided diagnosis (CAD); nonlinear dimension reduction;
   pixel-based machine learning; virtual colonoscopy
ID FALSE POSITIVES; COLONIC POLYPS; LUNG NODULES; AUTOMATED DETECTION;
   CHEST RADIOGRAPHS; SCHEME; MTANN; CLASSIFICATION; DIAGNOSIS; CAD
AB A major challenge in the current computer-aided detection (CAD) of polyps in CT colonography (CTC) is to reduce the number of false-positive (FP) detections while maintaining a high sensitivity level. A pattern-recognition technique based on the use of an artificial neural network (ANN) as a filter, which is called a massive-training ANN (MTANN), has been developed recently for this purpose. The MTANN is trained with a massive number of subvolumes extracted from input volumes together with the teaching volumes containing the distribution for the "likelihood of being a polyp;" hence the term " massive training." Because of the large number of subvolumes and the high dimensionality of voxels in each input subvolume, the training of an MTANN is time-consuming. In order to solve this time issue and make an MTANN work more efficiently, we propose here a dimension reduction method for an MTANN by using Laplacian eigenfunctions (LAPs), denoted as LAP-MTANN. Instead of input voxels, the LAP-MTANN uses the dependence structures of input voxels to compute the selected LAPs of the input voxels from each input subvolume and thus reduces the dimensions of the input vector to the MTANN. Our database consisted of 246 CTC datasets obtained from 123 patients, each of whom was scanned in both supine and prone positions. Seventeen patients had 29 polyps, 15 of which were 5-9 mm and 14 were 10-25 mm in size. We divided our database into a training set and a test set. The training set included 10 polyps in 10 patients and 20 negative patients. The test set had 93 patients including 19 polyps in seven patients and 86 negative patients. To investigate the basic properties of a LAP-MTANN, we trained the LAP-MTANN with actual polyps and a single source of FPs, which were rectal tubes. We applied the trained LAP-MTANN to simulated polyps and rectal tubes. The results showed that the performance of LAP-MTANNs with 20 LAPs was advantageous over that of the original MTANN with 171 inputs. To test the feasibility of the LAP-MTANN, we compared the LAP-MTANN with the original MTANN in the distinction between actual polyps and various types of FPs. The original MTANN yielded a 95% (18/19) by-polyp sensitivity at an FP rate of 3.6 (338/93) per patient, whereas the LAP-MTANN achieved a comparable performance, i.e., an FP rate of 3.9 (367/93) per patient at the same sensitivity level. With the use of the dimension reduction architecture, the time required for training was reduced from 38 h to 4 h. The classification performance in terms of the area under the receiver-operating-characteristic curve of the LAP-MTANN (0.84) was slightly higher than that of the original MTANN (0.82) with no statistically significant difference (p-value= 0.48).
C1 [Suzuki, Kenji; Zhang, Jun; Xu, Jianwu] Univ Chicago, Dept Radiol, Chicago, IL 60637 USA.
C3 University of Chicago
RP Suzuki, K (通讯作者)，Univ Chicago, Dept Radiol, Chicago, IL 60637 USA.
EM suzuki@uchicago.edu
RI Xu, Jianwu/C-6090-2012; Suzuki, Kenji/A-1284-2007; zhang,
   jun/B-5061-2012
OI Suzuki, Kenji/0000-0002-3993-8309; 
FU National Cancer Institute/National Institutes of Health [R01CA120549];
   National Institutes of Health [S10 RR021039, P30 CA14599]
FX Manuscript received April 01, 2010; revised June 06, 2010; accepted June
   08, 2010. Date of publication June 21, 2010; date of current version
   November 03, 2010. This work was supported in part by the National
   Cancer Institute/National Institutes of Health under Grant R01CA120549
   and in part by the National Institutes of Health under Grant S10
   RR021039 and Grant P30 CA14599. Asterisk indicates corresponding author.
CR Acar B, 2002, IEEE T MED IMAGING, V21, P1461, DOI 10.1109/TMI.2002.806405
   Arimura H, 2004, ACAD RADIOL, V11, P617, DOI 10.1016/j.acra.2004.02.009
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102
   EGAN JP, 1961, J ACOUST SOC AM, V33, P993, DOI 10.1121/1.1908935
   Fukunaga K, 1990, INTRO STAT PATTERN R
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   He LF, 2008, IEEE T IMAGE PROCESS, V17, P749, DOI 10.1109/TIP.2008.919369
   He LF, 2009, PATTERN RECOGN, V42, P1977, DOI 10.1016/j.patcog.2008.10.013
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   Iordanescu G, 2004, MED PHYS, V31, P2855, DOI 10.1118/1.1790131
   Jerebko AK, 2003, ACAD RADIOL, V10, P154, DOI 10.1016/S1076-6332(03)80039-9
   Jerebko AK, 2003, MED PHYS, V30, P52, DOI 10.1118/1.1528178
   Jolliffe IT., 2002, PRINCIPAL COMPONENTE, V2nd
   Kiss G, 2002, EUR RADIOL, V12, P77, DOI 10.1007/s003300101040
   Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.3.CO;2-Q
   METZ CE, 1986, INVEST RADIOL, V21, P720, DOI 10.1097/00004424-198609000-00009
   Mika S, 1999, ADV NEUR IN, V11, P536
   Nappi J, 2003, MED PHYS, V30, P1592, DOI 10.1118/1.1576393
   Nappi J, 2002, J COMPUT ASSIST TOMO, V26, P493, DOI 10.1097/01.RCT.0000025350.64054.4E
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Summers RM, 2001, RADIOLOGY, V219, P51, DOI 10.1148/radiology.219.1.r01ap0751
   Summers RM, 2000, RADIOLOGY, V216, P284, DOI 10.1148/radiology.216.1.r00jl43284
   Suzuki K, 2006, IEEE T MED IMAGING, V25, P406, DOI 10.1109/TMI.2006.871549
   Suzuki K, 2005, ACAD RADIOL, V12, P1333, DOI 10.1016/j.acra.2005.06.017
   Suzuki K, 2005, ACAD RADIOL, V12, P191, DOI 10.1016/j.acra.2004.11.017
   Suzuki K, 2004, IEEE T MED IMAGING, V23, P330, DOI 10.1109/TMI.2004.824238
   Suzuki K, 2003, IEEE T PATTERN ANAL, V25, P1582, DOI 10.1109/TPAMI.2003.1251151
   Suzuki K, 2003, MED PHYS, V30, P1602, DOI 10.1118/1.1580485
   Suzuki K, 2003, COMPUT VIS IMAGE UND, V89, P1, DOI 10.1016/S1077-3142(02)00030-9
   Suzuki K, 2002, IEEE T SIGNAL PROCES, V50, P1787, DOI 10.1109/TSP.2002.1011218
   Suzuki K, 2008, MED PHYS, V35, P694, DOI 10.1118/1.2829870
   Suzuki K, 2006, MED PHYS, V33, P3814, DOI 10.1118/1.2349839
   Suzuki K, 2004, J NEURAL ENG, V1, P228, DOI 10.1088/1741-2560/1/4/006
   Suzuki K, 2010, MED PHYS, V37, P12, DOI 10.1118/1.3263615
   Suzuki K, 2009, PHYS MED BIOL, V54, pS31, DOI 10.1088/0031-9155/54/18/S03
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang SJ, 2008, MED PHYS, V35, P1377, DOI 10.1118/1.2870218
   Yao JH, 2004, IEEE T MED IMAGING, V23, P1344, DOI 10.1109/TMI.2004.826941
   Yoshida H, 2005, ABDOM IMAGING, V30, P26, DOI 10.1007/s00261-004-0244-x
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
   ROCKIT SOFTWARE VER
NR 46
TC 44
Z9 47
U1 1
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD NOV
PY 2010
VL 29
IS 11
BP 1907
EP 1917
DI 10.1109/TMI.2010.2053213
PG 11
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA 676TP
UT WOS:000283941800008
PM 20570766
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Zhang, MM
   Yang, H
   Jin, ZD
   Yu, JG
   Cai, ZY
   Li, ZS
AF Zhang, Min-Min
   Yang, Hua
   Jin, Zhen-Dong
   Yu, Jian-Guo
   Cai, Zhe-Yuan
   Li, Zhao-Shen
TI Differential diagnosis of pancreatic cancer from normal tissue with
   digital imaging processing and pattern recognition based on a support
   vector machine of EUS images
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID FINE-NEEDLE-ASPIRATION; ENDOSCOPIC ULTRASOUND; GUIDED FNA;
   MATHEMATICAL-MODELS; TEXTURAL FEATURES; BREAST-LESIONS; CLASSIFICATION;
   MASSES; ULTRASONOGRAPHY; ELASTOGRAPHY
AB Background: EUS can detect morphologic abnormalities of pancreatic cancer with high sensitivity but with limited specificity.
   Objective: To develop a classification model for differential diagnosis of pancreatic cancer by using a digital imaging processing (DIP) technique to analyze EUS images of the pancreas.
   Design: A retrospective, controlled, single-center design was used.
   Setting: The study took place at the Second Military Medical University, Shanghai, China.
   Patients: There were 153 pancreatic cancer and 63 noncancer patients in this study.
   Intervention: All patients underwent EUS-guided FNA and pathologic analysis.
   Main Outcome Measurements: EUS images were obtained and correlated with cytologic findings after FNA. Texture features were extracted from the region of interest, and multifractal dimension vectors were introduced in the feature selection to the frame of the M-band wavelet transform. The sequential forward selection process was used for a better combination of features. By using the area under the receiver operating characteristic curve and other texture features based on separability criteria, a predictive model was built, trained, and validated according to the support vector machine theory.
   Results: From 67 frequently used texture features, 20 better features were selected, resulting in a classification accuracy of 99.07% after being added to 9 other features. A predictive model was then built and trained. After 50 random tests, the average accuracy, sensitivity, specificity, positive predictive value, and negative predictive value for the diagnosis of pancreatic cancer were 97.98 +/- 1.23%, 94.32 +/- 0.03%, 99.45 +/- 0.01%, 98.65 +/- 0.02%, and 97.77 +/- 0.01%, respectively.
   Limitations: The limitations of this study include the small sample size and that the support vector machine was not performed in real time.
   Conclusion: The classification of EUS images for differentiating pancreatic cancer from normal tissue by DIP is quite useful. Further refinements of such a model could increase the accuracy of EUS diagnosis of tumors. (Gastrointest Endosc 2010;72:978-85.)
C1 [Zhang, Min-Min; Yang, Hua; Jin, Zhen-Dong; Li, Zhao-Shen] Second Mil Med Univ, Dept Gastroenterol, Changhai Hosp, Shanghai 200433, Peoples R China.
   [Yu, Jian-Guo; Cai, Zhe-Yuan] Fudan Univ, Dept Elect Engn, Shanghai 200433, Peoples R China.
C3 Naval Medical University; Fudan University
RP Jin, ZD (通讯作者)，Second Mil Med Univ, Dept Gastroenterol, Changhai Hosp, 168 Changhai Rd, Shanghai 200433, Peoples R China.
CR Agarwal B, 2004, AM J GASTROENTEROL, V99, P844, DOI 10.1111/j.1572-0241.2004.04177.x
   AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   Ardengh JC, 2007, J PANCREAS, V8, P413
   Brand B, 2000, SCAND J GASTROENTERO, V35, P1221
   Catalano MF, 1998, GASTROINTEST ENDOSC, V48, P11, DOI 10.1016/S0016-5107(98)70122-1
   CATER DC, 1990, GUT, V31, P494
   Chang RF, 2003, ACAD RADIOL, V10, P189, DOI 10.1016/S1076-6332(03)80044-2
   Christodoulou CI, 2003, IEEE T MED IMAGING, V22, P902, DOI 10.1109/TMI.2003.815066
   Das A, 2008, GASTROINTEST ENDOSC, V67, pAB98, DOI 10.1016/j.gie.2008.03.108
   Devijver P, 1982, PATTERN RECOGNITION
   DeWitt J, 2004, ANN INTERN MED, V141, P753, DOI 10.7326/0003-4819-141-10-200411160-00006
   El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569
   Eloubeidi MA, 2006, GASTROINTEST ENDOSC, V63, P622, DOI 10.1016/j.gie.2005.05.024
   Eloubeidi MA, 2003, AM J GASTROENTEROL, V98, P2663, DOI 10.1016/S0002-9270(03)01699-X
   Erickson RA, 2000, GASTROINTEST ENDOSC, V51, P184, DOI 10.1016/S0016-5107(00)70416-0
   GARRA BS, 1993, ULTRASONIC IMAGING, V15, P267, DOI 10.1006/uimg.1993.1017
   GOLDBERG V, 1992, MED PHYS, V19, P1475, DOI 10.1118/1.596804
   GU ZH, 1984, OPT ENG, V23, P727, DOI 10.1117/12.7973371
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harewood GC, 2002, AM J GASTROENTEROL, V97, P1386, DOI 10.1016/S0002-9270(02)04133-3
   Horwhat JD, 2006, GASTROINTEST ENDOSC, V63, P966, DOI 10.1016/j.gie.2005.09.028
   HSIA TC, 1981, IEEE T SYST MAN CYB, V11, P831
   Itoh A, 2006, RADIOLOGY, V239, P341, DOI 10.1148/radiol.2391041676
   Jacobson BC, 2007, GASTROINTEST ENDOSC, V66, P301, DOI 10.1016/j.gie.2007.02.013
   Janssen J, 2007, GASTROINTEST ENDOSC, V65, P971, DOI 10.1016/j.gie.2006.12.057
   Kolios MC, 2002, ULTRASOUND MED BIOL, V28, P589, DOI 10.1016/S0301-5629(02)00492-1
   Kumon RE, 2007, GASTROINTEST ENDOSC, V66, P1096, DOI 10.1016/j.gie.2007.05.052
   Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376
   Lee WL, 2003, IEEE T MED IMAGING, V22, P382, DOI 10.1109/TMI.2003.809593
   Levman J, 2008, IEEE T MED IMAGING, V27, P688, DOI 10.1109/TMI.2008.916959
   Levy MJ, 2007, GASTROINTEST ENDOSC, V66, P483, DOI 10.1016/j.gie.2007.03.1053
   LUX G, 1982, ENDOSCOPY, V14, P220, DOI 10.1055/s-2007-1021625
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mavroforakis ME, 2006, ARTIF INTELL MED, V37, P145, DOI 10.1016/j.artmed.2006.03.002
   Mishra G, 2006, GASTROINTEST ENDOSC, V63, P648, DOI 10.1016/j.gie.2005.11.056
   Mohamed SS, 2008, IEEE T MED IMAGING, V27, P548, DOI 10.1109/TMI.2007.911547
   Mohamed SS, 2005, PHYS MED BIOL, V50, pN175, DOI 10.1088/0031-9155/50/15/N02
   Nattkemper TW, 2005, ARTIF INTELL MED, V34, P129, DOI 10.1016/j.artmed.2004.09.001
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, p26A
   RAVENS AF, 2001, AM J GASTROENTEROL, V97, P2768
   Saftoiu A, 2007, GASTROINTEST ENDOSC, V66, P291, DOI 10.1016/j.gie.2006.12.039
   SARKAR N, 1994, IEEE T SYST MAN CYB, V24, P115, DOI 10.1109/21.259692
   THOMAS J, 2007, GASTROINTEST ENDOSC, V66, P277
   Van Holsbeke C, 2007, CLIN CANCER RES, V13, P4440, DOI 10.1158/1078-0432.CCR-06-2958
   Van Holsbeke C, 2009, CLIN CANCER RES, V15, P684, DOI 10.1158/1078-0432.CCR-08-0113
   Vapnik V., 1998, NATURE STATISTI810
   Varadarajulu S, 2005, GASTROINTEST ENDOSC, V62, P728, DOI 10.1016/j.gie.2005.06.051
   Vomweg TW, 2003, MED PHYS, V30, P2350, DOI 10.1118/1.1600871
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   WU CM, 1992, IEEE T MED IMAGING, V11, P141, DOI 10.1109/42.141636
   Xia Y, 2006, IEEE T IMAGE PROCESS, V15, P614, DOI 10.1109/TIP.2005.863029
   Zhu ZH, 2009, J CLIN ONCOL, V27, P1091, DOI 10.1200/JCO.2008.16.6991
NR 53
TC 50
Z9 55
U1 0
U2 8
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD NOV
PY 2010
VL 72
IS 5
BP 978
EP 985
DI 10.1016/j.gie.2010.06.042
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 678SU
UT WOS:000284101500012
PM 20855062
DA 2023-04-20
ER

PT J
AU Qi, X
   Pan, YS
   Sivak, MV
   Willis, JE
   Isenberg, G
   Rollins, AM
AF Qi, Xin
   Pan, Yinsheng
   Sivak, Michael V., Jr.
   Willis, Joseph E.
   Isenberg, Gerard
   Rollins, Andrew M.
TI Image analysis for classification of dysplasia in Barrett's esophagus
   using endoscopic optical coherence tomography
SO BIOMEDICAL OPTICS EXPRESS
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; BREAST-LESIONS; CT; CANCER; MASSES;
   SEGMENTATION; ENHANCEMENT; MAMMOGRAPHY; PERFORMANCE; ACCURACY
AB Barrett's esophagus (BE) and associated adenocarcinoma have emerged as a major health care problem. Endoscopic optical coherence tomography is a microscopic sub-surface imaging technology that has been shown to differentiate tissue layers of the gastrointestinal wall and identify dysplasia in the mucosa, and is proposed as a surveillance tool to aid in management of BE. In this work a computer-aided diagnosis (CAD) system has been demonstrated for classification of dysplasia in Barrett's esophagus using EOCT. The system is composed of four modules: region of interest segmentation, dysplasia-related image feature extraction, feature selection, and site classification and validation. Multiple feature extraction and classification methods were evaluated and the process of developing the CAD system is described in detail. Use of multiple EOCT images to classify a single site was also investigated. A total of 96 EOCT image-biopsy pairs (63 non-dysplastic, 26 low-grade and 7 high-grade dysplastic biopsy sites) from a previously described clinical study were analyzed using the CAD system, yielding an accuracy of 84% for classification of non-dysplastic vs. dysplastic BE tissue. The results motivate continued development of CAD to potentially enable EOCT surveillance of large surface areas of Barrett's mucosa to identify dysplasia. (C) 2010 Optical Society of America
C1 [Qi, Xin; Pan, Yinsheng; Rollins, Andrew M.] Case Western Reserve Univ, Dept Biomed Engn, Cleveland, OH 44106 USA.
   [Sivak, Michael V., Jr.; Isenberg, Gerard; Rollins, Andrew M.] Case Western Reserve Univ, Dept Med, Cleveland, OH 44106 USA.
   [Willis, Joseph E.] Case Western Reserve Univ, Dept Pathol, Cleveland, OH 44106 USA.
C3 Case Western Reserve University; Case Western Reserve University; Case
   Western Reserve University
RP Qi, X (通讯作者)，Case Western Reserve Univ, Dept Biomed Engn, Cleveland, OH 44106 USA.
EM Rollins@case.edu
FU National Institutes of Health [CA94304, CA114276]
FX The authors acknowledge the contributions of Brian Wolf, and Matthew
   Ford and the financial support of the National Institutes of Health
   (CA94304 and CA114276). The content is solely the responsibility of the
   authors and does not necessarily represent the official views of the
   National Institutes of Health.
CR Adler DC, 2009, ENDOSCOPY, V41, P773, DOI 10.1055/s-0029-1215045
   Bouma BE, 2000, GASTROINTEST ENDOSC, V51, P467, DOI 10.1016/S0016-5107(00)70449-4
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 1998, ANN STAT, V26, P801
   Breiman L., 1984, CLASSIFICATION REGRE, DOI [10.1002/widm.8, DOI 10.1002/WIDM.8]
   Burhenne LJW, 2000, RADIOLOGY, V215, P554
   Caudill M, 1992, UNDERSTANDING NEURAL
   CHAUDHURI BB, 1993, PATTERN RECOGN LETT, V14, P147, DOI 10.1016/0167-8655(93)90088-U
   Chen CM, 2003, RADIOLOGY, V226, P504, DOI 10.1148/radiol.2262011843
   Chen WJ, 2004, MED PHYS, V31, P1076, DOI 10.1118/1.1695652
   Chen Y, 2007, ENDOSCOPY, V39, P599, DOI 10.1055/s-2007-966648
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Das A, 2000, GASTROINTEST ENDOSC, V51, pAB93, DOI 10.1016/S0016-5107(00)14142-2
   Destounis SV, 2004, RADIOLOGY, V232, P578, DOI 10.1148/radiol.2322030034
   DeVault KR, 2000, DIGEST DIS, V18, P195, DOI 10.1159/000051399
   EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552
   Efron B., 1993, INTRO BOOTSTRAP, DOI 10.1007/978-1-4899-4541-9
   Ellis RL, 2007, RADIOLOGY, V245, P88, DOI 10.1148/radiol.2451060760
   Evans JA, 2006, CLIN GASTROENTEROL H, V4, P38, DOI 10.1016/S1542-3565(05)00746-9
   Falk GW, 1999, GASTROINTEST ENDOSC, V49, P170, DOI 10.1016/S0016-5107(99)70482-7
   Fisher N. I., 1995, STAT ANAL CIRCULAR D
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Giger ML, 2001, IEEE T MED IMAGING, V20, P1205, DOI 10.1109/TMI.2001.974915
   Gilhuijs KGA, 1998, MED PHYS, V25, P1647, DOI 10.1118/1.598345
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   Gur D, 2004, J NATL CANCER I, V96, P185, DOI 10.1093/jnci/djh067
   Hall FM, 2004, AM J ROENTGENOL, V182, P1598, DOI 10.2214/ajr.182.6.1821598
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HARWOOD D, 1995, PATTERN RECOGN LETT, V16, P1, DOI 10.1016/0167-8655(94)00061-7
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Hormick JL, 2007, GASTROENTEROL CLIN N, V36, P775, DOI 10.1016/j.gtc.2007.08.004
   Horng MH, 2002, COMPUT MED IMAG GRAP, V26, P33, DOI 10.1016/S0895-6111(01)00029-5
   Horsch K, 2004, ACAD RADIOL, V11, P272, DOI 10.1016/S1076-6332(03)00719-0
   Horsch K, 2002, MED PHYS, V29, P157, DOI 10.1118/1.1429239
   Huo ZM, 2000, MED PHYS, V27, P4, DOI 10.1118/1.598851
   Isenberg G, 2005, GASTROINTEST ENDOSC, V62, P825, DOI 10.1016/j.gie.2005.07.048
   Isenberg G, 2003, TECH GASTROINTEST EN, V5, P94
   Jackle S, 2000, ENDOSCOPY, V32, P750, DOI 10.1055/s-2000-7705
   Jolliffe IT., 2002, PRINCIPAL COMPONENT
   Joo S, 2004, IEEE T MED IMAGING, V23, P1292, DOI 10.1109/TMI.2004.834617
   Karlon WJ, 1998, ANAT RECORD, V252, P612, DOI 10.1002/(SICI)1097-0185(199812)252:4<612::AID-AR12>3.0.CO;2-1
   Kohonen T., 1987, SELF ORG ASS MEMORY
   Kupinski MA, 1998, IEEE T MED IMAGING, V17, P510, DOI 10.1109/42.730396
   Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376
   Li XD, 2000, ENDOSCOPY, V32, P921, DOI 10.1055/s-2000-9626
   Maley Carlo C, 2006, J Natl Compr Canc Netw, V4, P367
   Park J, 2001, ARTIF INTELL MED, V23, P277, DOI 10.1016/S0933-3657(01)00086-0
   Petrick N, 1996, MED PHYS, V23, P1685, DOI 10.1118/1.597756
   Pfau PR, 2003, GASTROINTEST ENDOSC, V58, P196, DOI 10.1067/mge.2003.344
   Pitas I., 2000, DIGITAL IMAGE PROCES
   Pitris C, 2000, J GASTROENTEROL, V35, P87, DOI 10.1007/s005350050019
   Poneros JM, 2001, GASTROENTEROLOGY, V120, P7, DOI 10.1053/gast.2001.20911
   Poneros John M, 2004, Gastrointest Endosc Clin N Am, V14, P573, DOI 10.1016/j.giec.2004.03.002
   Prasad AM, 2006, ECOSYSTEMS, V9, P181, DOI 10.1007/s10021-005-0054-1
   Qi X, 2004, GASTROENTEROLOGY, V126, pA351
   Qi X, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2337314
   Reunanen J., 2003, Journal of Machine Learning Research, V3, P1371, DOI 10.1162/153244303322753715
   Ripley B. D., 2007, PATTERN RECOGN
   Rollins AM, 1999, OPT LETT, V24, P1358, DOI 10.1364/OL.24.001358
   Rollins AM, 1998, OPT EXPRESS, V3, P219, DOI 10.1364/OE.3.000219
   Sahiner B, 2001, IEEE T MED IMAGING, V20, P1275, DOI 10.1109/42.974922
   Sahiner B, 2007, RADIOLOGY, V242, P716, DOI 10.1148/radiol.2423051464
   Sampliner RE, 2002, AM J GASTROENTEROL, V97, P1888
   Sayana H, 2007, Minerva Gastroenterol Dietol, V53, P157
   SCHMITT JM, 1994, PHYS MED BIOL, V39, P1705, DOI 10.1088/0031-9155/39/10/013
   SCHMITT JM, 1993, APPL OPTICS, V32, P6032, DOI 10.1364/AO.32.006032
   Sharma P, 2004, GASTROENTEROLOGY, V127, P310, DOI 10.1053/j.gastro.2004.04.010
   Sivak MV, 2000, GASTROINTEST ENDOSC, V51, P474, DOI 10.1016/S0016-5107(00)70450-0
   Sluimer I, 2006, IEEE T MED IMAGING, V25, P385, DOI 10.1109/TMI.2005.862753
   Solaymani-Dodaran M, 2005, AM J GASTROENTEROL, V100, P2616, DOI 10.1111/j.1572-0241.2005.00340.x
   Summers RM, 2002, ABDOM IMAGING, V27, P268, DOI 10.1007/s00261-001-0168-7
   Suzuki K, 2005, IEEE T MED IMAGING, V24, P1138, DOI 10.1109/TMI.2005.852048
   Taplin SH, 2006, AM J ROENTGENOL, V187, P1475, DOI 10.2214/AJR.05.0940
   Timp S, 2007, IEEE T MED IMAGING, V26, P945, DOI 10.1109/TMI.2007.897392
   Tuceryan M, 1998, HDB PATTERN RECOGNIT
   Tutuian Radu, 2003, Gastrointest Endosc Clin N Am, V13, P227, DOI 10.1016/S1052-5157(03)00009-6
   Vakoc BJ, 2007, GASTROINTEST ENDOSC, V65, P898, DOI 10.1016/j.gie.2006.08.009
   van Ginneken B, 2002, IEEE T MED IMAGING, V21, P139, DOI 10.1109/42.993132
   Uitert RL, 2007, IEEE T MED IMAGING, V26, P1069, DOI 10.1109/TMI.2007.896927
   Vieth M, 2006, ENDOSCOPY, V38, P1201, DOI 10.1055/s-2006-944993
   Vince DG, 2000, COMPUT MED IMAG GRAP, V24, P221, DOI 10.1016/S0895-6111(00)00011-2
   Westphal V, 2005, GASTROINTEST ENDOSC, V61, P537, DOI 10.1016/S0016-5107(05)00084-2
   White PM, 2001, RADIOLOGY, V219, P739, DOI 10.1148/radiology.219.3.r01ma16739
   Yu L, 2004, J MACH LEARN RES, V5, P1205
   Yun SH, 2006, NAT MED, V12, P1429, DOI 10.1038/nm1450
   Zuccaro G, 2001, AM J GASTROENTEROL, V96, P2633
NR 87
TC 40
Z9 41
U1 0
U2 6
PU Optica Publishing Group
PI WASHINGTON
PA 2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA
SN 2156-7085
J9 BIOMED OPT EXPRESS
JI Biomed. Opt. Express
PD OCT 1
PY 2010
VL 1
IS 3
BP 825
EP 847
DI 10.1364/BOE.1.000825
PG 23
WC Biochemical Research Methods; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
GA V21LM
UT WOS:000208209100009
PM 21258512
OA Green Published, Green Submitted
DA 2023-04-20
ER

PT J
AU Nguyen, VX
   Nguyen, CC
   Li, BX
   Das, A
AF Nguyen, Vien X.
   Nguyen, Cuong C.
   Li, Baoxin
   Das, Ananya
TI Digital Image Analysis Is a Useful Adjunct to Endoscopic
   Ultrasonographic Diagnosis of Subepithelial Lesions of the
   Gastrointestinal Tract
SO JOURNAL OF ULTRASOUND IN MEDICINE
LA English
DT Article
DE artificial neural network; digital image analysis; endoscopic
   ultrasonography; subepithelial lesions; submucosal lesions
ID EUS IMAGES; TEXTURE ANALYSIS; BREAST-TUMORS
AB Objective. The purpose of this study was to explore the role of digital image analysis in differentiating endoscopic ultrasonographic (EUS) features of potentially malignant gastrointestinal subepithelial lesions (SELs) from those of benign lesions. Methods. Forty-six patients with histopathologically confirmed gastrointestinal stromal tumors (GISTs), carcinoids, and lipomas who had undergone EUS evaluation were identified from our database. Representative regions of interest (ROIs) were selected from the EUS images, and features were extracted by texture analysis. On the basis of these features, an artificial neural network (ANN) was built, trained, and internally validated by unsupervised learning followed by supervised learning. Outcomes were the performance characteristics of the ANN. Results. A total of 106, 111, and 124 ROIs were selected from EUS images of 8, 10, and 28 patients with lipomas, carcinoids, and GISTs, respectively. For each ROI, 228 statistical parameters were extracted and later reduced to the 11 most informative features by principal component analysis. After training with 50% of the data, the remainder of the data were used to validate the ANN. The model was "good" in differentiating carcinoids and GISTs, with area under the receiver operating characteristic curve (AUC) values of 0.86 and 0.89, respectively. The model was "excellent" in identifying lipomas correctly, with an AUC of 0.92. Conclusions. Digital image analysis of EUS images is a useful noninvasive adjunct to EUS evaluation of SELs.
C1 [Nguyen, Vien X.; Nguyen, Cuong C.; Das, Ananya] Mayo Clin, Div Gastroenterol, Scottsdale, AZ 85259 USA.
   [Li, Baoxin] Arizona State Univ, Dept Comp Sci & Engn, Phoenix, AZ USA.
C3 Mayo Clinic; Mayo Clinic Phoenix; Arizona State University; Arizona
   State University-Downtown Phoenix
RP Nguyen, VX (通讯作者)，Mayo Clin, Div Gastroenterol, 13400 E Shea Blvd, Scottsdale, AZ 85259 USA.
EM nguyen.vien@mayo.edu
CR Bhutani MS, 2008, GASTROINTEST ENDOSC, V67, P868, DOI 10.1016/j.gie.2007.12.061
   Castellano G, 2004, CLIN RADIOL, V59, P1061, DOI 10.1016/j.crad.2004.07.008
   CATALANO MF, 1995, GASTROINTEST ENDOSC, V41, P115, DOI 10.1016/S0016-5107(05)80592-9
   Chak A, 1997, GASTROINTEST ENDOSC, V45, P468, DOI 10.1016/S0016-5107(97)70175-5
   Chak A, 2002, GASTROINTEST ENDOSC, V56, pS43, DOI 10.1067/mge.2002.127700
   Chen DR, 2000, SEMIN ULTRASOUND CT, V21, P308, DOI 10.1016/S0887-2171(00)90025-8
   CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2
   Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036
   GOLDBERG V, 1992, MED PHYS, V19, P1475, DOI 10.1118/1.596804
   Gonzales RC., 2002, DIGITAL IMAGE PROCES
   Gress F, 2001, GASTROINTEST ENDOSC, V53, P71, DOI 10.1067/mge.2001.111384
   HEDENBRO JL, 1991, SURG ENDOSC-ULTRAS, V5, P20, DOI 10.1007/BF00591381
   Hwang JH, 2006, GASTROENTEROLOGY, V130, P2217, DOI 10.1053/j.gastro.2006.04.033
   Hwang JH, 2004, GASTROENTEROLOGY, V126, P301, DOI 10.1053/j.gastro.2003.11.040
   Hwang JH, 2005, GASTROINTEST ENDOSC, V62, P202, DOI 10.1016/S0016-5107(05)01567-1
   KIMMEY MB, 1989, GASTROENTEROLOGY, V96, P433, DOI 10.1016/0016-5085(89)91568-0
   Kohonen T, 1984, SELF ORG ASS MEMORY
   Loren DE, 2002, GASTROINTEST ENDOSC, V56, P742, DOI 10.1067/mge.2002.128920
   Nesje Lars B, 2002, Eur J Ultrasound, V15, P45, DOI 10.1016/S0929-8266(01)00166-5
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644
   ODEGAARD S, 1992, GASTROINTEST ENDOSC, V38, P351, DOI 10.1016/S0016-5107(92)70431-3
   Polkowski Marcin, 2005, Gastrointest Endosc Clin N Am, V15, P33, DOI 10.1016/j.giec.2004.07.005
   Robb Richard A, 2000, BIOMEDICAL IMAGING V
   Saftoiu Adrian, 2003, Rom J Gastroenterol, V12, P215
   SAIDA P, 2006, ANNU REV BIOMED ENG, V8, P537
   YASUDA K, 1990, GASTROINTEST ENDOSC, V36, pS17, DOI 10.1016/S0016-5107(90)71010-3
   YOSHIKANE H, 1993, GASTROINTEST ENDOSC, V39, P375, DOI 10.1016/S0016-5107(93)70109-1
   Zakai David M., 2000, American Journal of Gastroenterology, V95, P2644
NR 28
TC 11
Z9 12
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0278-4297
EI 1550-9613
J9 J ULTRAS MED
JI J. Ultrasound Med.
PD SEP
PY 2010
VL 29
IS 9
BP 1345
EP 1351
DI 10.7863/jum.2010.29.9.1345
PG 7
WC Acoustics; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Radiology, Nuclear Medicine & Medical Imaging
GA 656RX
UT WOS:000282355400011
PM 20733191
DA 2023-04-20
ER

PT J
AU Sugimoto, M
AF Sugimoto, Maki
TI Recent advances in visualization, imaging, and navigation in
   hepatobiliary and pancreatic sciences
SO JOURNAL OF HEPATO-BILIARY-PANCREATIC SCIENCES
LA English
DT Article
DE Circulating tumor cells (CTCs); Magnetic resonance imaging (MRI);
   Hepatocellular carcinoma (HCC); Fluorescent imaging Indocyanine green
   (ICG); Carbon dioxide MDCT cholangiopancreatography (CMCP); Endoscopic
   ultrasonography-guided biliary drainage (EUS-BD); Natural orifice
   translumenal endoscopic surgery (NOTES); MR-laparoscopy; Image overlay
   navigation; OsiriX
AB Background/purpose Recent introduction of multi-detector CT (MDCT) and high-speed magnetic resonance (MR) imaging have dramatically advanced visualization and imaging technology in diagnostic and therapeutic strategy in hepatobiliary pancreatic disease. However, image diagnostics have progressed with a background of the essence of anatomy, pathology, and physiology. It is important to object the reflection of the patient's condition and pathology of each disease and remove pattern recognition in what they were depicted as an image. Visualization plays another important role in various medical diagnostics. Trends in scientific visualization will depend on advancements in molecular technology and computer hardware as well as trends in engineering disciplines.
   Methods In this special issue, the recent advances in visualization and imaging in the field of hepatobiliary and pancreatic sciences are featured including application of advanced visualization techniques, data management, data compression, feature extraction.
   Results We discuss the potential benefits of new technologies and procedures in hepatobiliary and pancreatic areas, that are circulating tumor cells, MR imaging for hepatocellular carcinoma, indocyanine green using fluorescence under infrared light observation, carbon dioxide enhanced MDCT virtual cholangiopancreatography, endoscopic ultrasonography-guided biliary drainage, natural orifice translumenal endoscopic surgery, MR-laparoscopy, and image overlay navigation surgery by OsiriX.
   Conclusion Some of the recent trends are discussed in terms of visualization and imaging in hapatobiliary and pancreatic sciences. The goal in using visualization is to assist existing scientific procedures by providing new insight through visual representation.
C1 Kobe Univ, Grad Sch Med, Dept Gastroenterol, Chuo Ku, Kobe, Hyogo 6500017, Japan.
C3 Kobe University
RP Sugimoto, M (通讯作者)，Kobe Univ, Grad Sch Med, Dept Gastroenterol, Chuo Ku, 7-5-1 Kusunoki Cho, Kobe, Hyogo 6500017, Japan.
EM sgmt@med.kobe-u.ac.jp
NR 0
TC 11
Z9 11
U1 0
U2 10
PU SPRINGER TOKYO
PI TOKYO
PA 1-11-11 KUDAN-KITA, CHIYODA-KU, TOKYO, 102-0073, JAPAN
SN 1868-6974
J9 J HEPATO-BIL-PAN SCI
JI J. Hepato-Biliary-Pancreat. Sci.
PD SEP
PY 2010
VL 17
IS 5
BP 574
EP 576
DI 10.1007/s00534-009-0192-5
PG 3
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 637UV
UT WOS:000280845100008
PM 19806300
DA 2023-04-20
ER

PT J
AU Szilagyi, L
   Benyo, Z
AF Szilagyi, L.
   Benyo, Z.
TI Development of a virtual reality guided diagnostic tool based on
   magnetic resonance imaging
SO ACTA PHYSIOLOGICA HUNGARICA
LA English
DT Article
DE virtual reality; virtual endoscope; computed tomography; magnetic
   resonance imaging; medical image computation; computer aided
   intervention
ID C-MEANS ALGORITHM; MEANS CLUSTERING-ALGORITHM; INTENSITY INHOMOGENEITY;
   MRI DATA; SEGMENTATION; ENDOSCOPY; IMAGES; MODELS; SHAPE; INFORMATION
AB Computed tomography (CT) and virtual reality (VR) made it possible to create internal views of the human body without actual penetration. During the last two decades, several endoscopic diagnosis procedures have received virtual counter candidates. This paper presents an own concept of a virtual reality guided diagnostic tool, based on magnetic resonance images representing parallel cross-sections of the investigated organ. A series of image processing methods are proposed for image quality enhancement, accurate segmentation in two dimensions, and three-dimensional reconstruction of detected surfaces. These techniques provide improved accuracy in image segmentation, and thus they represent excellent support for three dimensional imaging. The implemented software system allows interactive navigation within the investigated volume, and provides several facilities to quantify important physical properties including distances, areas, and volumes.
C1 [Benyo, Z.] Budapest Univ Technol & Econ, Dept Control Engn & Informat Technol, H-1117 Budapest, Hungary.
   [Szilagyi, L.] Sapientia Hungarian Sci Univ Transylvania, Fac Tech & Human Sci Tirgu Mures, Corunca 547367, Romania.
C3 Budapest University of Technology & Economics; Sapientia Hungarian
   University of Transylvania
RP Benyo, Z (通讯作者)，Budapest Univ Technol & Econ, Dept Control Engn & Informat Technol, Magyar Tudosok Krt 2, H-1117 Budapest, Hungary.
EM lalo@ms.sapientia.ro; benyo@iit.bme.hu
RI Benyo, Zoltan Prof. Dr. Habil./H-2900-2012; Szilágyi, László/C-3532-2011
FU Hungarian National Research Program (OTKA) [T069055]; Sapientia
   Institute for Research Programs; Domus Hungarica Scientiarum et Artium;
   Pro Progressio Foundation; Hungarian National Office for Research and
   Technology; Eurotrans and Communitas Foundations of Transylvania
FX This research was funded in part by Hungarian National Research Program
   (OTKA) under grant no. T069055, the Sapientia Institute for Research
   Programs, the Domus Hungarica Scientiarum et Artium, the Pro Progressio
   Foundation, the Hungarian National Office for Research and Technology,
   and the Eurotrans and Communitas Foundations of Transylvania.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Awate SP, 2005, LECT NOTES COMPUT SC, V3565, P677
   Battista G, 2009, ABDOM IMAGING, V34, P107, DOI 10.1007/s00261-008-9387-5
   Bernhardt TM, 2001, ABDOM IMAGING, V26, P325, DOI 10.1007/s002610000168
   Bezdek JC., 1981, PATTERN RECOGN
   Boctor EM, 2004, LECT NOTES COMPUT SC, V3217, P81
   Bookstein FL, 1997, COMPUT VIS IMAGE UND, V66, P97, DOI 10.1006/cviu.1997.0607
   Boor S, 2000, NEURORADIOLOGY, V42, P543, DOI 10.1007/s002340000329
   Bosch JG, 2002, IEEE T MED IMAGING, V21, P1374, DOI 10.1109/TMI.2002.806427
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Carrascosa P, 2008, ABDOM IMAGING, V33, P381, DOI 10.1007/s00261-007-9270-9
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Fan JL, 2003, PATTERN RECOGN LETT, V24, P1607, DOI 10.1016/S0167-8655(02)00401-4
   Fichtinger G, 2008, MED IMAGE ANAL, V12, P535, DOI 10.1016/j.media.2008.06.002
   Haker S, 2000, LECT NOTES COMPUT SC, V1935, P358
   Han P, 2000, EUR ARCH OTO-RHINO-L, V257, P578, DOI 10.1007/s004050000284
   Haponik EF, 1999, CLIN CHEST MED, V20, P201, DOI 10.1016/S0272-5231(05)70135-0
   Ichihara S, 2008, VIRCHOWS ARCH, V452, P41, DOI 10.1007/s00428-007-0528-y
   Inamoto K, 2005, ABDOM IMAGING, V30, P473, DOI 10.1007/s00261-004-0278-0
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KOLOSZAR J, 2006, SPRING C COMP GRAPH
   Krieger A, 2007, LECT NOTES COMPUT SC, V4792, P59
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   Li X, 2005, MED PHYS, V32, P2337, DOI 10.1118/1.1944912
   LORENSEN WE, 1987, P SIGGRAPH 87, V21, P163, DOI DOI 10.1145/37401.37422
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Men S, 2007, J DIGIT IMAGING, V20, P67, DOI 10.1007/s10278-006-0857-4
   Moorthy K, 2004, SURG ENDOSC, V18, P1613, DOI 10.1007/s00464-004-9002-y
   Morrin MM, 2000, DIS COLON RECTUM, V43, P303, DOI 10.1007/BF02258293
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nagy L, 2004, P ANN INT IEEE EMBS, V26, P1533
   Neri E, 2000, ABDOM IMAGING, V25, P59, DOI 10.1007/s002619910012
   Nielson GM, 2003, IEEE T VIS COMPUT GR, V9, P283, DOI 10.1109/TVCG.2003.1207437
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pal NR, 2005, IEEE T FUZZY SYST, V13, P517, DOI 10.1109/TFUZZ.2004.840099
   Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752
   Rohde V, 2001, ACTA NEUROCHIR, V143, P1085, DOI 10.1007/s007010100000
   Rosseland LA, 2005, ACTA ANAESTH SCAND, V49, P1456, DOI 10.1111/j.1399-6576.2005.00817.x
   Ruan S, 2002, COMPUT VIS IMAGE UND, V85, P54, DOI 10.1006/cviu.2002.0957
   Sahin G, 2004, SKELETAL RADIOL, V33, P9, DOI 10.1007/s00256-003-0704-3
   Sata N, 2007, ABDOM IMAGING, V32, P66, DOI 10.1007/s00261-006-9008-0
   Sata N, 2006, ABDOM IMAGING, V31, P326, DOI 10.1007/s00261-005-0359-8
   SEYMOUR NE, 2005, EUR SURG, V37, P298
   Siyal MY, 2005, PATTERN RECOGN LETT, V26, P2052, DOI 10.1016/j.patrec.2005.03.019
   Steinhaus H., 1957, B ACAD POLONAISE SCI, V4, P801
   Suri JS, 2002, IEEE T INF TECHNOL B, V6, P8, DOI 10.1109/4233.992158
   Suri JS, 2002, IEEE T INF TECHNOL B, V6, P338, DOI 10.1109/TITB.2002.804136
   Szilagyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   SZILAGYI L, 2008, THESIS BME BUDAPEST
   SZILAGYI L, 2009, IEEE C FUZZ SYST FUZ, P456
   Szilagyi L, 2008, LECT NOTES COMPUT SC, V5164, P527, DOI 10.1007/978-3-540-87559-8_55
   Szilagyi L, 2007, LECT NOTES COMPUT SC, V4633, P866
   Szilagyi SM, 2007, LECT NOTES COMPUT SC, V4466, P81
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wood BJ, 2002, AM FAM PHYSICIAN, V66, P107
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhan YQ, 2007, IEEE T MED IMAGING, V26, P779, DOI 10.1109/TMI.2006.89I497
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   INTERNET BRAIN SEGME
NR 62
TC 1
Z9 1
U1 0
U2 7
PU AKADEMIAI KIADO RT
PI BUDAPEST
PA PRIELLE K U 19, PO BOX 245,, H-1117 BUDAPEST, HUNGARY
SN 0231-424X
EI 1588-2683
J9 ACTA PHYSIOL HUNG
JI Acta Physiol. Hung.
PD SEP
PY 2010
VL 97
IS 3
BP 267
EP 280
DI 10.1556/APhysiol.97.2010.3.3
PG 14
WE Science Citation Index Expanded (SCI-EXPANDED)
GA 649JT
UT WOS:000281765600003
PM 20843765
DA 2023-04-20
ER

PT J
AU Voigt, D
   Dollinger, M
   Yang, AX
   Eysholdt, U
   Lohscheller, J
AF Voigt, Daniel
   Doellinger, Michael
   Yang, Anxiong
   Eysholdt, Ulrich
   Lohscheller, Joerg
TI Automatic diagnosis of vocal fold paresis by employing phonovibrogram
   features and machine learning methods
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE Computer-assisted diagnosis; Voice disorders; Vocal fold paresis;
   Phonovibrography; Feature extraction; Laryngeal high-speed video
   analysis
ID CLASSIFICATION; VIBRATIONS; PHONATION; FREQUENCY
AB The clinical diagnosis of voice disorders is based on examination of the rapidly moving vocal folds during phonation (f0: 80-300 Hz) with state-of-the-art endoscopic high-speed cameras. Commonly, analysis is performed in a subjective and time-consuming manner via slow-motion video playback and exhibits low inter- and intra-rater reliability. In this study an objective method to overcome this drawback is presented being based on Phonovibrography, a novel image analysis technique. For a collective of 45 normophonic and paralytic voices the laryngeal dynamics were captured by specialized Phonovibrogram features and analyzed with different machine learning algorithms. Classification accuracies reached 93% for 2-class and 73% for 3-class discrimination. The results were validated by subjective expert ratings given the same diagnostic criteria. The automatic Phonovibrogram analysis approach exceeded the experienced raters' classifications by 9%. The presented method holds a lot of potential for providing reliable vocal fold diagnosis support in the future. (C) 2010 Elsevier Ireland Ltd. All rights reserved.
C1 [Voigt, Daniel; Doellinger, Michael; Yang, Anxiong; Eysholdt, Ulrich] Univ Hosp Erlangen, Dept Phoniatr & Pediat Audiol, D-91054 Erlangen, Germany.
   [Lohscheller, Joerg] Univ Appl Sci Trier, Dept Comp Sci, D-54293 Trier, Germany.
C3 University of Erlangen Nuremberg
RP Voigt, D (通讯作者)，Univ Hosp Erlangen, Dept Phoniatr & Pediat Audiol, Bohlenplatz 21, D-91054 Erlangen, Germany.
EM daniel.voigt@uk-erlangen.de
OI Doellinger, Michael/0000-0003-2717-4820
FU Deutsche Forschungsgemeinschaft (DFG) [LO1413/2 1-3, EY15/11 3-4]
FX This work was funded by the Deutsche Forschungsgemeinschaft (DFG),
   grants LO1413/2 1-3 and EY15/11 3-4. The authors would like to thank the
   High Performance Computing Group at Regionales Rechenzentrum Erlangen
   (RRZE) for providing computational resources.
CR Arnold DV, 2002, IEEE T EVOLUT COMPUT, V6, P30, DOI [10.1109/4235.985690, 10.1023/A:1015059928466]
   BAKEN RJ, 1992, J VOICE, V6, P98, DOI 10.1016/S0892-1997(05)80123-7
   Bonilha HS, 2008, J VOICE, V22, P699, DOI 10.1016/j.jvoice.2007.03.002
   Braunschweig T, 2008, MED ENG PHYS, V30, P59, DOI 10.1016/j.medengphy.2006.12.007
   Carding PN, 2009, J LARYNGOL OTOL, V123, P823, DOI 10.1017/S0022215109005398
   Dejonckere PH, 2001, EUR ARCH OTO-RHINO-L, V258, P77, DOI 10.1007/s004050000299
   Diaz G, 2009, J BIOMED INFORM, V42, P296, DOI 10.1016/j.jbi.2008.11.005
   Doellinger M, 2009, CURR BIOINFORM, V4, P101, DOI 10.2174/157489309788184774
   Duda R. O., 2001, PATTERN CLASSIFICATI, V2nd
   Gelzinis A, 2008, COMPUT METH PROG BIO, V91, P36, DOI 10.1016/j.cmpb.2008.01.008
   Godino-Llorente JI, 2004, IEEE T BIO-MED ENG, V51, P380, DOI 10.1109/TBME.2003.820386
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Kohavi R., 1995, P INT JOINT C ART IN, P1137
   Krippendorf K., 2004, CONTENT ANAL INTRO I
   Little MA, 2007, BIOMED ENG ONLINE, V6, DOI 10.1186/1475-925X-6-23
   Lohscheller J, 2008, IEEE T MED IMAGING, V27, P300, DOI 10.1109/TMI.2007.903690
   Lohscheller J, 2007, MED IMAGE ANAL, V11, P400, DOI 10.1016/j.media.2007.04.005
   Mergell P, 2000, J ACOUST SOC AM, V108, P2996, DOI 10.1121/1.1314398
   ORLIKOFF RF, 1990, FOLIA PHONIATR, V42, P31, DOI 10.1159/000266017
   Cesar DCP, 2007, IEEE T BIO-MED ENG, V54, P1898, DOI 10.1109/TBME.2006.889780
   Qiu QJ, 2003, FOLIA PHONIATR LOGO, V55, P128, DOI 10.1159/000070724
   Rasch Thorsten, 2005, Logoped Phoniatr Vocol, V30, P9, DOI 10.1080/14015430510006640
   Rasp O, 2006, FOLIA PHONIATR LOGO, V58, P175, DOI 10.1159/000091731
   SATALOFF RT, 1987, J VOICE, V1, P191
   Schwarz R, 2006, IEEE T BIO-MED ENG, V53, P1099, DOI 10.1109/TBME.2006.873396
   Shin HJ, 2006, J BIOMED INFORM, V39, P227, DOI 10.1016/j.jbi.2005.04.002
   Svec JG, 1996, J VOICE, V10, P201, DOI 10.1016/S0892-1997(96)80047-6
   Umapathy K, 2005, IEEE T BIO-MED ENG, V52, P421, DOI 10.1109/TBME.2004.842962
   Verikas A, 2007, COMPUT METH PROG BIO, V85, P257, DOI 10.1016/j.cmpb.2006.11.002
   Verikas A, 2006, ARTIF INTELL MED, V36, P71, DOI 10.1016/j.artmed.2004.11.001
   Verikas A, 2009, EUR ARCH OTO-RHINO-L, V266, P1509, DOI 10.1007/s00405-009-1050-4
   Voigt D, 2010, ARTIF INTELL MED, V49, P51, DOI 10.1016/j.artmed.2010.01.001
   Wang D, 2009, ARTIF INTELL MED, V47, P63, DOI 10.1016/j.artmed.2009.05.002
   WENDLER J, 1992, J VOICE, V6, P149, DOI 10.1016/S0892-1997(05)80129-8
   Wurzbacher T, 2006, J ACOUST SOC AM, V120, P1012, DOI 10.1121/1.2211550
   Yan YL, 2005, J VOICE, V19, P161, DOI 10.1016/j.jvoice.2004.04.006
   Yan YL, 2007, J VOICE, V21, P604, DOI 10.1016/j.jvoice.2006.05.011
   ZHANG Y, 2006, CHAOS, V16
NR 39
TC 30
Z9 30
U1 0
U2 7
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD SEP
PY 2010
VL 99
IS 3
BP 275
EP 288
DI 10.1016/j.cmpb.2010.01.004
PG 14
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 643YQ
UT WOS:000281337700005
PM 20138386
DA 2023-04-20
ER

PT J
AU Huang, A
   Li, JA
   Summers, RM
   Petrick, N
   Hara, AK
AF Huang, Adam
   Li, Jiang
   Summers, Ronald M.
   Petrick, Nicholas
   Hara, Amy K.
TI Improving polyp detection algorithms for CT colonography: Pareto front
   approach
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Pareto front; Computer-aided detection; Polyp detection; CT
   colonography; Virtual colonoscopy
ID COMPUTER-AIDED DIAGNOSIS; TOMOGRAPHIC VIRTUAL COLONOSCOPY; SUPPORT
   VECTOR MACHINES; COLONIC POLYPS; COLORECTAL NEOPLASIA;
   FEATURE-SELECTION; CLASSIFICATION; SEGMENTATION; PERFORMANCE;
   OPTIMIZATION
AB We investigated a Pareto front approach to improve polyp detection algorithms for CT colonography (CTC). A dataset of 56 CTC colon surfaces with 87 proven positive detections of 53 polyps sized 4-60 mm was used to evaluate the performance of a one-step and a two-step curvature-based region growing algorithm. The algorithmic performance was statistically evaluated and compared based on the Pareto optimal solutions from 20 experiments by evolutionary algorithms. The false positive rate was lower (p < 0.05) by the two-step algorithm than by the one-step for 63% of all possible operating points. While operating at a suitable sensitivity level such as 90.8% (79/87) or 88.5% (77/87), the false positive rate was reduced by 24.4% (95% confidence intervals 17.9-31.0%) or 45.8% (95% confidence intervals 40.1-51.0%), respectively. We demonstrated that, with a proper experimental design, the Pareto optimization process can effectively help in fine-tuning and redesigning polyp detection algorithms. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Huang, Adam; Li, Jiang; Summers, Ronald M.] NIH, Imaging Biomarkers & Comp Aided Diag Lab, Ctr Clin, Bethesda, MD 20892 USA.
   [Huang, Adam] Natl Cent Univ, Res Ctr Adapt Data Anal, Jhongli, Taiwan.
   [Li, Jiang] Old Dominion Univ, Dept Elect & Comp Engn, Virginia Modeling Anal & Simulat Ctr, Norfolk, VA 23529 USA.
   [Petrick, Nicholas] US FDA, NIBIB, Ctr Devices & Radiol Hlth Lab Assessment, Silver Spring, MD 20993 USA.
   [Hara, Amy K.] Mayo Clin, Scottsdale, AZ 85259 USA.
C3 National Institutes of Health (NIH) - USA; NIH Clinical Center (CC);
   National Central University; Old Dominion University; National
   Institutes of Health (NIH) - USA; NIH National Institute of Biomedical
   Imaging & Bioengineering (NIBIB); US Food & Drug Administration (FDA);
   Mayo Clinic; Mayo Clinic Phoenix
RP Summers, RM (通讯作者)，NIH, Imaging Biomarkers & Comp Aided Diag Lab, Ctr Clin, Bldg 10,Room 1C368X MSC 1182, Bethesda, MD 20892 USA.
EM rms@nih.gov
RI Summers, Ronald/AAX-6290-2021
OI Huang, Adam/0000-0001-5478-2763
FU iCAD; National Institutes of Health (NIH) Clinical Center; National
   Institute of Biomedical Imaging and Bioengineering at NIH (NP); National
   Science Council of Republic of China (Taiwan) [NSC 98-2314-B-008-001,
   97-2627-B-008-007]
FX Authors A. Huang, J. Li, and R.M. Summers have pending and/or awarded
   patents for the subject matter described in the manuscript. Authors A.
   Huang and R.M. Summers receive patent royalties from iCAD. Author
   Summers' lab is supported in part by a Cooperative Research and
   Development Agreement with iCAD and received free research software from
   Viatronix.; We thank the anonymous reviewer who suggests adding the FN
   example in Fig. 8. This additional figure adds clarity to our discussion
   and leads us to correct an error in the operating parameter NB value
   given in (Huang et al., 2007). This research was conducted while the
   first and second authors were post-doctoral fellows supported by the
   intramural programs of the National Institutes of Health (NIH) Clinical
   Center. Support was also provided by the intramural program of the
   National Institute of Biomedical Imaging and Bioengineering at NIH (NP).
   This study utilized the high-performance computational capabilities of
   the NIH Biowulf PC/Linux cluster. The first author was partially
   supported by the National Science Council of Republic of China (Taiwan),
   NSC 98-2314-B-008-001 and 97-2627-B-008-007.
CR Anastasio MA, 1998, IEEE T MED IMAGING, V17, P1089, DOI 10.1109/42.746726
   Balsiger C., 2001, 103 TIK SWISS FED I, V8
   Bhotika R, 2006, LECT NOTES COMPUT SC, V4191, P479
   Bielen D, 2007, ABDOM IMAGING, V32, P571, DOI 10.1007/s00261-007-9293-2
   Bitter I, 2004, PRO BIOMED OPT IMAG, V5, P290, DOI 10.1117/12.536917
   Campadelli P, 2005, NEUROCOMPUTING, V68, P281, DOI 10.1016/j.neucom.2005.03.005
   CAMPBELL SR, 2007, P MED IMAG SPIE, V6511
   Carmo M.P., 1976, DIFFERENTIAL GEOMETR
   Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805
   Chen DQ, 2000, IEEE T MED IMAGING, V19, P1220, DOI 10.1109/42.897814
   Chowdhury TA, 2006, COMPUT MED IMAG GRAP, V30, P427, DOI 10.1016/j.compmedimag.2006.06.004
   Cotton PB, 2004, JAMA-J AM MED ASSOC, V291, P1713, DOI 10.1001/jama.291.14.1713
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Franaszek M, 2006, IEEE T MED IMAGING, V25, P358, DOI 10.1109/TMI.2005.863836
   Frimmel H, 2005, MED PHYS, V32, P2665, DOI 10.1118/1.1990288
   Hara AK, 1997, RADIOLOGY, V205, P59, DOI 10.1148/radiology.205.1.9314963
   Hong W, 2006, IEEE T VIS COMPUT GR, V12, P861, DOI 10.1109/TVCG.2006.112
   Huang A, 2005, PROC SPIE, V5746, P393, DOI 10.1117/12.594644
   HUANG A, 2007, P MED IMAG SPIE, V6514
   Jerebko AK, 2003, MED PHYS, V30, P52, DOI 10.1118/1.1528178
   Kiss G, 2006, ACAD RADIOL, V13, P1062, DOI 10.1016/j.acra.2006.05.002
   Knowles JD, 2000, EVOL COMPUT, V8, P149, DOI 10.1162/106365600568167
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Kupinski MA, 2001, IEEE T MED IMAGING, V20, P886, DOI 10.1109/42.952727
   Kupinski MA, 1999, IEEE T MED IMAGING, V18, P675, DOI 10.1109/42.796281
   LI J, 2007, P MED IMAG SPIE, V6514
   Li J, 2006, INT J ARTIF INTELL T, V15, P893, DOI 10.1142/S021821300600303X
   Li J, 2009, MED PHYS, V36, P201, DOI 10.1118/1.3040177
   Mani A, 2004, J COMPUT ASSIST TOMO, V28, P318, DOI 10.1097/00004728-200405000-00003
   Masutani Y, 2001, J COMPUT ASSIST TOMO, V25, P629, DOI 10.1097/00004728-200107000-00020
   Melonakos J, 2007, LECT NOTES COMPUT SC, V4792, P420
   MENDONCA P, 2008, P MICCAI WORKSH COMP, P33
   Messac A, 2003, STRUCT MULTIDISCIP O, V25, P86, DOI 10.1007/s00158-002-0276-1
   Nappi JJ, 2004, MED PHYS, V31, P860, DOI 10.1118/1.1668591
   Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Rockey DC, 2005, LANCET, V365, P305
   Sahiner B, 2000, MED PHYS, V27, P1509, DOI 10.1118/1.599017
   Summers RM, 2000, RADIOLOGY, V216, P284, DOI 10.1148/radiology.216.1.r00jl43284
   Summers RM, 2005, GASTROENTEROLOGY, V129, P1832, DOI 10.1053/j.gastro.2005.08.054
   Summers RM, 2006, ACAD RADIOL, V13, P1490, DOI 10.1016/j.acra.2006.09.051
   TUKEY JW, 1977, EXPLORATORY DATA ANA, P39
   van Wijk C, 2006, LECT NOTES COMPUT SC, V4191, P471
   Wagner RF, 1997, PROC SPIE, V3034, P467, DOI 10.1117/12.274133
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yao JH, 2005, P SOC PHOTO-OPT INS, V5746, P384, DOI 10.1117/12.594547
   Yao JH, 2004, IEEE T MED IMAGING, V23, P1344, DOI 10.1109/TMI.2004.826941
   Yee J, 2001, RADIOLOGY, V219, P685, DOI 10.1148/radiology.219.3.r01jn40685
   Yoshida H, 2005, ABDOM IMAGING, V30, P26, DOI 10.1007/s00261-004-0244-x
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
NR 50
TC 5
Z9 6
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD AUG 1
PY 2010
VL 31
IS 11
BP 1461
EP 1469
DI 10.1016/j.patrec.2010.03.013
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 624QO
UT WOS:000279834800028
PM 20548966
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Trovato, G
   Shikanai, M
   Ukawa, G
   Kinoshita, J
   Murai, N
   Lee, JW
   Ishii, H
   Takanishi, A
   Tanoue, K
   Ieiri, S
   Konishi, K
   Hashizume, M
AF Trovato, G.
   Shikanai, M.
   Ukawa, G.
   Kinoshita, J.
   Murai, N.
   Lee, J. W.
   Ishii, H.
   Takanishi, A.
   Tanoue, K.
   Ieiri, S.
   Konishi, K.
   Hashizume, M.
TI Development of a colon endoscope robot that adjusts its locomotion
   through the use of reinforcement learning
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Colon endoscope; Medical robot; Autonomous colonoscope; Forward/reverse
   screw; Reinforcement learning
ID COLORECTAL-CANCER; CAPSULE ENDOSCOPY
AB Purpose Fibre optic colonoscopy is usually performed with manual introduction and advancement of the endoscope, but there is potential for a robot capable of locomoting autonomously from the rectum to the caecum. A prototype robot was designed and tested.
   Methods The robot colonic endoscope consists in a front body with clockwise helical fin and a rear body with anticlockwise one, both connected via a DC motor. Input voltage is adjusted automatically by the robot, through the use of reinforcement learning, determining speed and direction (forward or backward).
   Results Experiments were performed both in-vitro and in-vivo, showing the feasibility of the robot. The device is capable of moving in a slippery environment, and reinforcement learning algorithms such as Q-learning and SARSA can obtain better results than simply applying full tension to the robot.
   Conclusions This self-propelled robotic endoscope has potential as an alternative to current fibre optic colonoscopy examination methods, especially with the addition of new sensors under development.
C1 [Trovato, G.; Shikanai, M.; Ukawa, G.; Kinoshita, J.; Murai, N.; Lee, J. W.; Ishii, H.; Takanishi, A.] Waseda Univ, Tokyo, Japan.
   [Tanoue, K.; Ieiri, S.; Konishi, K.; Hashizume, M.] Kyushu Univ Hosp, Fukuoka 812, Japan.
C3 Waseda University; Kyushu University
RP Trovato, G (通讯作者)，Waseda Univ, Tokyo, Japan.
EM gabrit20@yahoo.it
RI Ieiri, Satoshi/AFC-8801-2022; Trovato, Gabriele/P-1697-2019; Ieiri,
   Satoshi/AAO-1096-2021; Trovato, Gabriele/AAV-9209-2021
OI Ieiri, Satoshi/0000-0002-1250-093X; Trovato,
   Gabriele/0000-0003-2675-0216; Ieiri, Satoshi/0000-0002-1250-093X;
   Trovato, Gabriele/0000-0003-2675-0216
CR ABBEEL P, 2006, ICML 06 P 23 INT C M
   Abbeel Pieter, 2005, P 22 INT C MACH LEAR, P1
   ACCOTO D, 2001, P 2 WORLD TRIB C VIE, P728
   Asada M, 1996, MACH LEARN, V23, P279, DOI 10.1007/BF00117447
   BOYLE P, 2008, INT AGENCY RES CANC, V88, P123
   Church J, 1995, ENDOSCOPY COLON RECT
   Colquhoun P, 2006, SURG INNOV, V13, P81, DOI 10.1177/1553350606290163
   Cuschieri A, 1997, SURG ENDOSC-ULTRAS, V11, P91, DOI 10.1007/s004649900303
   Grundfest WS, 1994, US patent, Patent No. [5,337,732, 5337732]
   Hassan C, 2008, ENDOSCOPY, V40, P414, DOI 10.1055/s-2007-995565
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   ITO, 2007, P 25 ANN C ROB SOC J
   Johnston PG, 2006, ONCOLOGIST, V11, P970, DOI 10.1634/theoncologist.11-9-970
   KALMAR Z, 1998, LECT NOTES COMPUTER
   KASSIM I, 2006, ENG MED BIOL MAGAZIN
   Menciassi A, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1379, DOI 10.1109/IRDS.2002.1043947
   MOORE AW, 1990, 229 U CAMBR COMP LAB
   Phee L, 2002, IEEE T BIO-MED ENG, V49, P613, DOI 10.1109/TBME.2002.1001976
   SLATKIN AB, 1995, INT C INT ROB SYST P, V2, P2162
   Sutton R. S., 1998, INTRO REINFORCEMENT, V2, DOI DOI 10.1109/TNN.1998.712192
   TANAKA S, 2006, MED TREATMENT, V88, P123
   Uchibe E, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P1329, DOI 10.1109/IROS.1996.568989
   Valdastri P, 2009, IEEE T ROBOT, V25, P1047, DOI 10.1109/TRO.2009.2014127
   WICKHAM J, 1996, MIN INVAS THER ALLIE
NR 24
TC 17
Z9 17
U1 1
U2 18
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD JUL
PY 2010
VL 5
IS 4
BP 317
EP 325
DI 10.1007/s11548-010-0481-0
PG 9
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA 746ZJ
UT WOS:000289289500002
PM 20480247
DA 2023-04-20
ER

PT J
AU Buri, L
   Hassan, C
   Bersani, G
   Anti, M
   Bianco, MA
   Cipolletta, L
   Di Giulio, E
   Di Matteo, G
   Familiari, L
   Ficano, L
   Loriga, P
   Morini, S
   Pietropaolo, V
   Zambelli, A
   Grossi, E
   Intraligi, M
   Buscema, M
AF Buri, Luigi
   Hassan, Cesare
   Bersani, Gianluca
   Anti, Marcello
   Bianco, Maria Antonietta
   Cipolletta, Livio
   Di Giulio, Emilio
   Di Matteo, Giovanni
   Familiari, Luigi
   Ficano, Leonardo
   Loriga, Pietro
   Morini, Sergio
   Pietropaolo, Vincenzo
   Zambelli, Alessandro
   Grossi, Enzo
   Intraligi, Marco
   Buscema, Massimo
CA SIED Appropriateness Working Grp
TI Appropriateness Guidelines and Predictive Rules to Select Patients for
   Upper Endoscopy: A Nationwide Multicenter Study
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
AB OBJECTIVES: Selecting patients appropriately for upper endoscopy (EGD) is crucial for efficient use of endoscopy. The objective of this study was to compare different clinical strategies and statistical methods to select patients for EGD, namely appropriateness guidelines, age and/or alarm features, and multivariate and artificial neural network (ANN) models.
   METHODS: A nationwide, multicenter, prospective study was undertaken in which consecutive patients referred for EGD during a 1-month period were enrolled. Before EGD, the endoscopist assessed referral appropriateness according to the American Society for Gastrointestinal Endoscopy (ASGE) guidelines, also collecting clinical and demographic variables. Outcomes of the study were detection of relevant findings and new diagnosis of malignancy at EGD. The accuracy of the following clinical strategies and predictive rules was compared: (i) ASGE appropriateness guidelines (indicated vs. not indicated), (ii) simplified rule (>= 45 years or alarm features vs. <45 years without alarm features), (iii) logistic regression model, and (iv) ANN models.
   RESULTS: A total of 8,252 patients were enrolled in 57 centers. Overall, 3,803 (46%) relevant findings and 132 (1.6%) new malignancies were detected. Sensitivity, specificity, and area under the receiver-operating characteristic curve (AUC) of the simplified rule were similar to that of the ASGE guidelines for both relevant findings (82%/26%/0.55 vs. 88 %/27%/0.52) and cancer (97%/22%/0.58 vs. 98%/20%/0.58). Both logistic regression and ANN models seemed to be substantially more accurate in predicting new cases of malignancy, with an AUC of 0.82 and 0.87, respectively.
   CONCLUSIONS: A simple predictive rule based on age and alarm features is similarly effective to the more complex ASGE guidelines in selecting patients for EGD. Regression and ANN models may be useful in identifying a relatively small subgroup of patients at higher risk of cancer.
C1 [Buri, Luigi] Cattinara Hosp, Gastroenterol & Digest Endoscopy Unit, Trieste, Italy.
   [Hassan, Cesare; Morini, Sergio] Nuovo Regina Margherita, Dept Gastroenterol, Rome, Italy.
   [Bersani, Gianluca] Gastrointestinal Endoscopy Serv, Malatesta, Cesena, Italy.
   [Anti, Marcello] Belcolle Hosp, Gastroenterol Unit, Viterbo, Italy.
   [Bianco, Maria Antonietta; Cipolletta, Livio] Hosp Agostino Maresca, Div Gastroenterol & Digest Endoscopy ASL SUD NA3, Torre Del Greco, Italy.
   [Di Giulio, Emilio] Univ Roma La Sapienza, Digest & Liver Dis Unit, Sch Med 2, St Andrea Hosp, Rome, Italy.
   [Di Matteo, Giovanni] Saverio De Bellis Hosp, Gastroenterol Unit, Bari, Italy.
   [Familiari, Luigi] Policlin G Martino, Dept Gastroenterol, Messina, Italy.
   [Ficano, Leonardo] Univ Palermo, Surg & Oncol Dept, Palermo, Italy.
   [Loriga, Pietro] SS Trinita Hosp, Endoscopy Unit, Cagliari, Italy.
   [Pietropaolo, Vincenzo] Policlin La Sapienza, Gastroenterol Unit, Rome, Italy.
   [Zambelli, Alessandro] Maggiore Hosp, Gastroenterol Unit, Crema, Italy.
   [Grossi, Enzo] Bracco Imaging SpA, Med Affairs Europe, Milan, Italy.
   [Intraligi, Marco; Buscema, Massimo] Seme Res Ctr Sci Commun, Rome, Italy.
C3 Poliambulatorio Nuovo Regina Margherita; Sapienza University Rome;
   Azienda Ospedaliera Sant'Andrea; IRCCS Saverio de Bellis; AOU
   Policlinico Gaetano Martino; University of Messina; University of
   Palermo; Bracco
RP Hassan, C (通讯作者)，Nuovo Regina Margherita Hosp, Dept Gastroenterol & Digest Endoscopy, Via Morosini 30, I-00153 Rome, Italy.
EM cesareh@hotmail.com
RI Grossi, Enzo/AAF-7765-2020; hassan, cesare/H-2844-2012; Monica,
   Fabio/L-5943-2016
OI hassan, cesare/0000-0001-7167-1459; GROSSI, ENZO/0000-0003-0346-2684;
   Buscema, Paolo Massimo/0000-0003-4356-0510; DI MATTEO, Filippo
   Maria/0000-0001-6693-3389; GIACOBBE, Giuseppa/0000-0003-2093-7872; NERI,
   Matteo/0000-0001-8856-7690; Monica, Fabio/0000-0002-3064-1269;
   GABBRIELLI, Armando/0000-0001-5875-7952
CR Buscema M, 2005, ARTIF INTELL MED, V34, P279, DOI 10.1016/j.artmed.2004.12.001
   Buscema M, 2004, EXPERT SYST, V21, P63, DOI 10.1111/j.1468-0394.2004.00264.x
   BUSCEMA M, 2007, COMPUT INTELL NEUROS, V3, P1
NR 3
TC 17
Z9 18
U1 0
U2 1
PU NATURE PUBLISHING GROUP
PI NEW YORK
PA 75 VARICK ST, 9TH FLR, NEW YORK, NY 10013-1917 USA
SN 0002-9270
EI 1572-0241
J9 AM J GASTROENTEROL
JI Am. J. Gastroenterol.
PD JUN
PY 2010
VL 105
IS 6
BP 1327
EP 1337
DI 10.1038/ajg.2009.675
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 607OU
UT WOS:000278515700022
PM 20029414
DA 2023-04-20
ER

PT J
AU Deliyski, DD
   Hillman, RE
AF Deliyski, Dimitar D.
   Hillman, Robert E.
TI State of the art laryngeal imaging: research and clinical implications
SO CURRENT OPINION IN OTOLARYNGOLOGY & HEAD AND NECK SURGERY
LA English
DT Article
DE high-speed videoendoscopy; kymography; optical coherence tomography;
   videostroboscopy; voice assessment
ID VOCAL FOLD VIBRATIONS; OPTICAL COHERENCE TOMOGRAPHY; HIGH-SPEED
   VIDEOENDOSCOPY; DEPTH-KYMOGRAPHY; NORMAL SPEAKERS; DYNAMICS; SYSTEM;
   MODEL; VIDEOKYMOGRAPHY; VIDEO
AB Purpose of review
   This study provides a review of the latest advances in videostroboscopy, videokymography and high-speed videoendoscopy, and outlines the development of new laryngeal imaging modalities based on optical coherence tomography, laser depth-kymography, and magnetic resonance imaging (MRI), published in the past 2 years.
   Recent findings
   Videostroboscopy and videokymography: image quality has improved and several image processing and measurement techniques have been published. High-speed videoendoscopy: significant progress has been made through increased sensitivity and frame rates of the cameras, and the development of facilitative playbacks, phonovibrography and several image segmentation and measurement methods. Clinical evidence was presented through applications in phonosurgery, comparisons with videostroboscopy, normative data, and better understanding of voice production. Optical coherence tomography: latest developments allow the capture of dynamic high-resolution cross-sectional images of the vibrating vocal fold mucosa during phonation. Depth-kymography: new laser technique allowing recording of the vertical movements of the vocal folds during phonation in calibrated spatial values. Laryngeal magnetic resonance: new methods allow high-resolution imaging of laryngeal tissue microstructure, or measuring of dynamic laryngeal structures during phonation.
   Summary
   The endoscopic laryngeal imaging techniques have made significant advances increasing their clinical value, whereas techniques providing new types of potentially clinically relevant information have emerged.
C1 [Deliyski, Dimitar D.] Univ S Carolina, Dept Commun Sci & Disorders, Columbia, SC 29208 USA.
   [Deliyski, Dimitar D.] Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
   [Deliyski, Dimitar D.] Univ S Carolina, Interdisciplinary Math Inst, Columbia, SC 29208 USA.
   [Hillman, Robert E.] Massachusetts Gen Hosp, Ctr Laryngeal Surg & Voice Rehabil, Boston, MA 02114 USA.
   [Hillman, Robert E.] Harvard Univ, Sch Med, Dept Surg, Boston, MA 02115 USA.
   [Hillman, Robert E.] Harvard Univ, Sch Med, Dept Hlth Sci & Technol, Boston, MA USA.
C3 University of South Carolina System; University of South Carolina
   Columbia; University of South Carolina System; University of South
   Carolina Columbia; University of South Carolina System; University of
   South Carolina Columbia; Harvard University; Massachusetts General
   Hospital; Harvard University; Harvard Medical School; Harvard
   University; Harvard Medical School
RP Deliyski, DD (通讯作者)，Univ S Carolina, Dept Commun Sci & Disorders, 1621 Greene St,6th Floor, Columbia, SC 29208 USA.
EM ddeliyski@sc.edu
FU NIH National Institute on Deafness and Other Communication Disorders
   [R01 DC007640]; Institute for Laryngology and Voice Restoration
FX The work was supported by grants from the NIH National Institute on
   Deafness and Other Communication Disorders (R01 DC007640) and by the
   Institute for Laryngology and Voice Restoration.
CR Ahmad M, 2009, J VOICE, V23, P235, DOI 10.1016/j.jvoice.2007.08.008
   Bonilha HS, 2008, AM J SPEECH-LANG PAT, V17, P367, DOI 10.1044/1058-0360(2008/07-0059)
   Bonilha HS, 2008, LOGOP PHONIATR VOCO, V33, P136, DOI 10.1080/14015430701875588
   Bonilha HS, 2008, J VOICE, V22, P699, DOI 10.1016/j.jvoice.2007.03.002
   Braunschweig T, 2008, MED ENG PHYS, V30, P59, DOI 10.1016/j.medengphy.2006.12.007
   Burns JA, 2005, ANN OTO RHINOL LARYN, V114, P671, DOI 10.1177/000348940511400903
   Burns JA, 2009, LARYNGOSCOPE, V119, P2182, DOI 10.1002/lary.20654
   Crump JM, 2004, J VOICE, V18, P13, DOI 10.1016/S0892-1997(03)00087-0
   de Mul FFM, 2009, PHYS MED BIOL, V54, P3955, DOI 10.1088/0031-9155/54/13/002
   Deliyski D.D., 2007, PERSPECTIVES VOICE V, VVolume 17, P12, DOI DOI 10.1044/VVD17.1.12
   Deliyski DD, 2008, FOLIA PHONIATR LOGO, V60, P33, DOI 10.1159/000111802
   Doellinger M, 2009, J VOICE, V23, P175, DOI 10.1016/j.jvoice.2007.09.008
   Doellinger M, 2009, CURR BIOINFORM, V4, P101, DOI 10.2174/157489309788184774
   George NA, 2008, PHYS MED BIOL, V53, P2667, DOI 10.1088/0031-9155/53/10/015
   George NA, 2008, J BIOMED OPT, V13, DOI 10.1117/1.3041164
   GOLLA ME, 2009, P 6 INT WORKSH MOD A, P141
   Herrera VLM, 2009, LARYNGOSCOPE, V119, P2187, DOI 10.1002/lary.20643
   Hu A, 2009, ARCH OTOLARYNGOL, V135, P677, DOI 10.1001/archoto.2009.68
   Jiang JJ, 2008, LARYNGOSCOPE, V118, P1504, DOI 10.1097/MLG.0b013e318177096f
   Kawaida M, 2004, ORL-J OTO-RHIN-LARYN, V66, P267, DOI 10.1159/000081124
   Kendall KA, 2010, LARYNGEAL EVALUATION
   Kendall KA, 2009, ARCH OTOLARYNGOL, V135, P274, DOI 10.1001/archoto.2008.557
   Klein AM, 2006, ANN OTO RHINOL LARYN, V115, P277, DOI 10.1177/000348940611500405
   KOBLER JB, LARYNGOSCOP IN PRESS
   Lohscheller J, 2008, LARYNGOSCOPE, V118, P753, DOI 10.1097/MLG.0b013e318161f9e1
   Lohscheller J, 2008, ANN OTO RHINOL LARYN, V117, P484, DOI 10.1177/000348940811700703
   Lohscheller J, 2008, IEEE T MED IMAGING, V27, P300, DOI 10.1109/TMI.2007.903690
   Manfredi C, 2006, BIOMED SIGNAL PROCES, V1, P129, DOI 10.1016/j.bspc.2006.06.001
   Mehta DD, 2010, ANN OTO RHINOL LARYN, V119, P1
   Mehta DD, 2008, CURR OPIN OTOLARYNGO, V16, P211, DOI 10.1097/MOO.0b013e3282fe96ce
   MOUKALLED HJ, 2009, P 6 INT WORKSH MOD A, P137
   Murugappan S, 2009, ANN OTO RHINOL LARYN, V118, P44, DOI 10.1177/000348940911800108
   Orlikoff RF, 2009, J VOICE, V23, P164, DOI 10.1016/j.jvoice.2007.08.004
   Osma-Ruiz V, 2008, COMPUT MED IMAG GRAP, V32, P193, DOI 10.1016/j.compmedimag.2007.12.003
   Patel R, 2008, ANN OTO RHINOL LARYN, V117, P413, DOI 10.1177/000348940811700603
   Pickup BA, 2009, J BIOMECH, V42, P2219, DOI 10.1016/j.jbiomech.2009.06.039
   Popolo PS, 2008, ANN OTO RHINOL LARYN, V117, P404, DOI 10.1177/000348940811700602
   Qiu QJ, 2007, REV SCI INSTRUM, V78, DOI 10.1063/1.2430622
   SCHWARZ R, 2008, J ACOUST SOC AM, V123, P3740
   Schwarz R, 2008, J ACOUST SOC AM, V123, P2717, DOI 10.1121/1.2902167
   Sekimoto S, 2009, ACTA OTO-LARYNGOL, V129, P1524, DOI 10.3109/00016480802691168
   Selbie WS, 2002, J ACOUST SOC AM, V112, P1077, DOI 10.1121/1.1501586
   Shaw HS, 2008, J VOICE, V22, P23, DOI 10.1016/j.jvoice.2006.08.006
   Skalski A, 2008, ICSES 2008 INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS, CONFERENCE PROCEEDINGS, P223, DOI 10.1109/ICSES.2008.4673399
   Svec JG, 2007, ANN OTO RHINOL LARYN, V116, P172, DOI 10.1177/000348940711600303
   Tsunoda A, 2008, J LARYNGOL OTOL, V122, P78, DOI 10.1017/S0022215107000072
   Verikas A, 2009, EUR ARCH OTO-RHINO-L, V266, P1509, DOI 10.1007/s00405-009-1050-4
   Vokes DE, 2008, ANN OTO RHINOL LARYN, V117, P538, DOI 10.1177/000348940811700713
   Yan YL, 2007, J VOICE, V21, P604, DOI 10.1016/j.jvoice.2006.05.011
   Yang AX, 2010, J ACOUST SOC AM, V127, P1014, DOI 10.1121/1.3277165
   Yu LF, 2009, J BIOMED OPT, V14, DOI 10.1117/1.3268442
   Zhang Y, 2009, ANN OTO RHINOL LARYN, V118, P598, DOI 10.1177/000348940911800812
NR 52
TC 61
Z9 62
U1 0
U2 12
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA
SN 1068-9508
J9 CURR OPIN OTOLARYNGO
JI Curr. Opin. Otolaryngol. Head Neck Surg.
PD JUN
PY 2010
VL 18
IS 3
BP 147
EP 152
DI 10.1097/MOO.0b013e3283395dd4
PG 6
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology
GA 601ZC
UT WOS:000278105800001
PM 20463479
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Ito, E
   Fujii, M
   Hayashi, Y
   Jiang, ZG
   Nagatani, T
   Saito, K
   Kishida, Y
   Mori, K
   Wakabayashi, T
AF Ito, Eiji
   Fujii, Masazumi
   Hayashi, Yuichiro
   Jiang Zhengang
   Nagatani, Tetsuya
   Saito, Kiyoshi
   Kishida, Yugo
   Mori, Kensaku
   Wakabayashi, Toshihiko
TI Magnetically Guided 3-Dimensional Virtual Neuronavigation for
   Neuroendoscopic Surgery: Technique and Clinical Experience
SO NEUROSURGERY
LA English
DT Article
DE Flexible scope; Image segmentation; Magnetically guided system;
   Neuroendoscope; Neuronavigation; Virtual navigation
ID AUGMENTED REALITY; MICROVASCULAR DECOMPRESSION; COMPUTED-TOMOGRAPHY;
   IMAGE REGISTRATION; NAVIGATION; VISUALIZATION; FUSION; SYSTEM; CT;
   NEUROSURGERY
AB OBJECTIVE: The authors have developed a novel intraoperative neuronavigation with 3-dimensional (3D) virtual images, a 3D virtual navigation system, for neuroendoscopic surgery. The present study describes this technique and clinical experience with the system.
   METHODS: Preoperative imaging data sets were transferred to a personal computer to construct virtual endoscopic views with image segmentation software. An electromagnetic tracker was used to acquire the position and orientation of the tip of the neuroendoscope. Virtual endoscopic images were interlinked to an electromagnetic tracking system and demonstrated on the navigation display in real time. Accuracy and efficacy of the 3D virtual navigation system were evaluated in a phantom test and on 5 consecutive patients undergoing neuroendoscopic surgery.
   RESULTS: Virtual navigation views were consistent with actual endoscopic views and trajectory in both phantom testing and clinical neuroendoscopic surgery. Anatomic structures that can affect surgical approaches were adequately predicted with the virtual navigation system. The virtual semitransparent view contributed to a clear understanding of spatial relationships between surgical targets and surrounding structures. Surgical procedures in all patients were performed while confirming with virtual navigation. In neurosurgery with a flexible neuroscope, virtual navigation also demonstrated anatomic structures in real time.
   CONCLUSION: The interactive method of intraoperative visualization influenced the decision-making process during surgery and provided useful assistance in identifying safe approaches for neuroendoscopic surgery. The magnetically guided navigation system enabled navigation of surgical targets in both rigid and flexible endoscopic surgeries.
C1 [Ito, Eiji; Saito, Kiyoshi] Fukushima Med Univ, Dept Neurosurg, Fukushima 9601295, Japan.
   [Fujii, Masazumi; Nagatani, Tetsuya; Kishida, Yugo; Wakabayashi, Toshihiko] Nagoya Univ, Dept Neurosurg, Grad Sch Med, Nagoya, Aichi 4648601, Japan.
   [Hayashi, Yuichiro; Jiang Zhengang; Mori, Kensaku] Nagoya Univ, Dept Media Sci, Grad Sch Informat Sci, Nagoya, Aichi 4648601, Japan.
C3 Fukushima Medical University; Nagoya University; Nagoya University
RP Ito, E (通讯作者)，Fukushima Med Univ, Dept Neurosurg, 1 Hikarigaoka, Fukushima 9601295, Japan.
EM eito754@yahoo.co.jp
RI Wakabayashi, Toshihiko/I-3526-2012; de Lima, Juliana/R-7501-2018
OI Wakabayashi, Toshihiko/0000-0001-5254-2088; Mori,
   Kensaku/0000-0002-0100-4797
CR Birkfellner W, 1998, IEEE T MED IMAGING, V17, P737, DOI 10.1109/42.736028
   Blackwell M, 1998, CLIN ORTHOP RELAT R, P111, DOI 10.1097/00003086-199809000-00014
   Chen HJ, 2001, STEREOT FUNCT NEUROS, V76, P145, DOI 10.1159/000066711
   GANDHE AJ, 1994, NEUROSURGERY, V35, P463, DOI 10.1227/00006123-199409000-00015
   Giordano M, 2007, J NEUROSURG, V106, P1006, DOI 10.3171/jns.2007.106.6.1006
   Hautmann H, 2005, CHEST, V128, P382, DOI 10.1378/chest.128.1.382
   Iseki H, 1997, STEREOT FUNCT NEUROS, V68, P18, DOI 10.1159/000099897
   Kakizawa Y, 2003, J NEUROSURG, V98, P625, DOI 10.3171/jns.2003.98.3.0625
   Kashimura H, 2008, NEUROL MED-CHIR, V48, P418, DOI 10.2176/nmc.48.418
   Kassam Amin, 2005, Neurosurg Focus, V19, pE4
   Kassam Amin, 2005, Neurosurg Focus, V19, pE3
   Kawamata T, 2002, NEUROSURGERY, V50, P1393, DOI 10.1097/00006123-200206000-00038
   Kikinis R, 1996, NEUROSURGERY, V38, P640, DOI 10.1227/00006123-199604000-00003
   Kockro RA, 2000, NEUROSURGERY, V46, P118, DOI 10.1093/neurosurgery/46.1.118
   Mangano FT, 2006, NEUROSURGERY S2, V58, pE377
   Mao Y, 2003, CHINESE MED J-PEKING, V116, P1480
   Masutani Y, 1998, Comput Aided Surg, V3, P239, DOI 10.1002/(SICI)1097-0150(1998)3:5<239::AID-IGS3>3.0.CO;2-B
   Mori K, 1996, IEICE T INF SYST, VE79D, P809
   Mori K, 2002, CARS 2002: COMPUTER ASSISTED RADIOLOGY AND SURGERY, PROCEEDINGS, P467
   Nakada K, 2003, LECT NOTES COMPUT SC, V2879, P285
   Naraghi R, 2004, J NEUROSURG, V100, P1025, DOI 10.3171/jns.2004.100.6.1025
   Naraghi R, 2007, J NEUROSURG, V107, P1154, DOI 10.3171/JNS-07/12/1154
   NIMSKY C, 2006, NEUROSURGERY S2, V58
   Oldhafer KJ, 1999, CHIRURG, V70, P233, DOI 10.1007/s001040050636
   PLODER O, 1995, RADIOLOGE, V35, P569
   Pretorius ES, 1999, RADIOGRAPHICS, V19, P1143, DOI 10.1148/radiographics.19.5.g99se061143
   Raabe A, 2002, NEUROSURGERY, V50, P797, DOI 10.1097/00006123-200204000-00021
   Roessler K, 1997, ACTA NEUROCHIR, V139, P551, DOI 10.1007/BF02750999
   Rosahl SK, 2005, INT CONGR SER, V1281, P788, DOI 10.1016/j.ics.2005.03.295
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Satoh T, 2007, J NEUROSURG, V106, P82, DOI 10.3171/jns.2007.106.1.82
   Satoh T, 2007, NEUROSURGERY, V60, P104, DOI 10.1227/01.NEU.0000249213.34838.C9
   SCHICHOR C, 2008, NEUROSURGERY S1, V63
   Schwarz Y, 2003, RESPIRATION, V70, P516, DOI 10.1159/000074210
   Solomon SB, 1998, CHEST, V114, P1405, DOI 10.1378/chest.114.5.1405
   Solomon SB, 2000, CHEST, V118, P1783, DOI 10.1378/chest.118.6.1783
   Stadie AT, 2008, J NEUROSURG, V108, P382, DOI 10.3171/JNS/2008/108/2/0382
   Tanrikulu L, 2007, J NEUROSURG, V107, P1137, DOI 10.3171/JNS-07/12/1137
   Thomale UW, 2005, ZBL NEUROCHIR, V66, P126, DOI 10.1055/s-2005-836602
   Tirakotai W, 2004, ZBL NEUROCHIR, V65, P57
   Wagner W, 2000, ZBL NEUROCHIR, V61, P188, DOI 10.1055/s-2000-15599
   Watanabe Y, 2003, PEDIATR SURG INT, V19, P167, DOI 10.1007/s00383-002-0911-3
   Wolfsberger S, 2002, NEUROSURG REV, V25, P68, DOI 10.1007/s10143-001-0201-x
   Wolfsberger S, 2006, NEUROSURGERY, V59, P1001, DOI 10.1227/01.NEU.0000245594.61828.41
   Wong GKC, 2007, NEUROSURGERY, V61, P564, DOI 10.1227/01.NEU.0000290904.46061.0D
NR 45
TC 10
Z9 10
U1 0
U2 11
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 0148-396X
EI 1524-4040
J9 NEUROSURGERY
JI Neurosurgery
PD JUN
PY 2010
VL 66
IS 6
SU 2
BP ONS342
EP ONS353
DI 10.1227/01.NEU.0000369659.19479.AF
PG 12
WC Clinical Neurology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Surgery
GA 600LP
UT WOS:000277987900046
PM 20489524
DA 2023-04-20
ER

PT J
AU Figueiredo, IN
   Figueiredo, PN
   Stadler, G
   Ghattas, O
   Araujo, A
AF Figueiredo, Isabel N.
   Figueiredo, Pedro N.
   Stadler, Georg
   Ghattas, Omar
   Araujo, Aderito
TI Variational Image Segmentation for Endoscopic Human Colonic Aberrant
   Crypt Foci
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Active contours; endoscopic images; image segmentation; level sets
ID ACTIVE CONTOURS; DYNAMICS; QUANTIFICATION; PATHOGENESIS; ALGORITHMS;
   MUMFORD; CANCER
AB The aim of this paper is to introduce a variational image segmentation method for assessing the aberrant crypt foci (ACF) in the human colon captured in vivo by endoscopy. ACF are thought to be precursors for colorectal cancer, and therefore their early detection may play an important clinical role. We enhance the active contours without edges model of Chan and Vese to account for the ACF's particular structure. We employ level sets to represent the segmentation boundaries and discretize in space by finite elements and in (artificial) time by finite differences. The approach is able to identify the ACF, their boundaries, and some of the internal crypts' orifices.
C1 [Figueiredo, Isabel N.; Araujo, Aderito] Univ Coimbra, Ctr Math, Dept Math, P-3001454 Coimbra, Portugal.
   [Figueiredo, Pedro N.] Univ Coimbra, Fac Med, P-3001454 Coimbra, Portugal.
   [Figueiredo, Pedro N.] Univ Hosp Coimbra, Dept Gastroenterol, P-3000075 Coimbra, Portugal.
   [Stadler, Georg; Ghattas, Omar] Univ Texas Austin, Inst Computat Engn & Sci, Austin, TX 78712 USA.
C3 Universidade de Coimbra; Universidade de Coimbra; Universidade de
   Coimbra; Centro Hospitalar e Universitario de Coimbra (CHUC); University
   of Texas System; University of Texas Austin
RP Figueiredo, IN (通讯作者)，Univ Coimbra, Ctr Math, Dept Math, P-3001454 Coimbra, Portugal.
EM isabelf@mat.uc.pt
RI Stadler, Georg/D-2120-2013; Araújo, Adérito/Y-3142-2019; Araújo,
   Adérito/E-9863-2012; Figueiredo, Isabel Narra/ABD-7828-2020
OI Araújo, Adérito/0000-0002-9873-5974; Araújo,
   Adérito/0000-0002-9873-5974; Figueiredo, Isabel
   Narra/0000-0002-0215-8851; Figueiredo, Pedro/0000-0001-9872-6341
FU University of Texas at Austin-Portugal Program [UTAustin/MAT/0009/2008]
FX This work was supported in part by the University of Texas at
   Austin-Portugal Program under Research Project UTAustin/MAT/0009/2008.
CR Adler DG, 2002, GASTROINTEST ENDOSC, V56, P657, DOI 10.1067/mge.2002.128540
   [Anonymous], 1999, LEVEL SET METHODS FA
   BAJAJ C, 2006, TR0608 ICES U TEX
   Berkels B, 2008, J SCI COMPUT, V35, P1, DOI 10.1007/s10915-007-9157-5
   BIRD RP, 1987, CANCER LETT, V37, P147, DOI 10.1016/0304-3835(87)90157-1
   Bird RP, 2000, TOXICOL LETT, V112, P395, DOI 10.1016/S0378-4274(99)00261-1
   BIRD RP, 1995, CANCER LETT, V93, P55, DOI 10.1016/0304-3835(95)03788-X
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan T.F., 2005, IMAGE PROCESSING ANA
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   CUNHA AL, 2004, THESIS CARNEGIE MELL
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Drasdo D, 2001, NONLINEAR ANAL-THEOR, V47, P245, DOI 10.1016/S0362-546X(01)00173-0
   Engquist B, 2005, J COMPUT PHYS, V207, P28, DOI 10.1016/j.jcp.2004.09.018
   Esedoglu S, 2006, J COMPUT PHYS, V211, P367, DOI 10.1016/j.jcp.2005.05.027
   Ferlay J, 2007, ANN ONCOL, V18, P581, DOI 10.1093/annonc/mdl498
   FIGUEIREDO IN, 2008, ENDOSCOPY, V40, pA189
   Halm DR, 2000, AM J PHYSIOL-CELL PH, V278, pC212, DOI 10.1152/ajpcell.2000.278.1.C212
   Hurlstone DP, 2005, AM J GASTROENTEROL, V100, P1283, DOI 10.1111/j.1572-0241.2005.40891.x
   Jemal A, 2008, CA-CANCER J CLIN, V58, P71, DOI 10.3322/CA.2007.0010
   Johnston MD, 2007, P NATL ACAD SCI USA, V104, P4008, DOI 10.1073/pnas.0611179104
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   MCLELLAN EA, 1988, CANCER RES, V48, P6187
   Michor F, 2005, SEMIN CANCER BIOL, V15, P484, DOI 10.1016/j.semcancer.2005.06.005
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Osher S., 2003, LEVEL SET METHODS DY, V153
   Pitt-Francis J., 2006, COMP MATH MATH PHYS, V7, P177
   QI X, 2007, P SPIE ENDOSC MICROS, V6432
   RONCUCCI L, 1991, CANCER EPIDEM BIOMAR, V1, P57
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Takayama T, 1998, NEW ENGL J MED, V339, P1277, DOI 10.1056/NEJM199810293391803
   Tsai YHR, 2005, ACT NUMERIC, V14, P509, DOI 10.1017/S0962492904000273
   van Leeuwen IMM, 2006, CELL PROLIFERAT, V39, P157, DOI 10.1111/j.1365-2184.2006.00378.x
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Yu ZY, 2005, IEEE T IMAGE PROCESS, V14, P1324, DOI 10.1109/TIP.2005.852770
NR 38
TC 16
Z9 17
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD APR
PY 2010
VL 29
IS 4
BP 998
EP 1011
DI 10.1109/TMI.2009.2036258
PG 14
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA 575TJ
UT WOS:000276091000003
PM 19923042
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Grigorescu, SE
   Nevo, ST
   Liedenbaum, MH
   Truyen, R
   Stoker, J
   van Vliet, LJ
   Vos, FM
AF Grigorescu, Simona E.
   Nevo, Shelly T.
   Liedenbaum, Marjolein H.
   Truyen, Roel
   Stoker, Jaap
   van Vliet, Lucas J.
   Vos, Frans M.
TI Automated Detection and Segmentation of Large Lesions in CT Colonography
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Carcinomas; computer-aided detection; computerized tomographic (CT)
   colonography (CTC); image segmentation; LH histogram
ID COMPUTER-AIDED DETECTION; TOMOGRAPHIC VIRTUAL COLONOSCOPY; COLONIC POLYP
   SEGMENTATION; CONTRAST; SIZE; CAD; EXPERIENCE; SYSTEM
AB Computerized tomographic colonography is a minimally invasive technique for the detection of colorectal polyps and carcinoma. Computer-aided diagnosis (CAD) schemes are designed to help radiologists locating colorectal lesions in an efficient and accurate manner. Large lesions are often initially detected as multiple small objects, due to which such lesions may be missed or misclassified by CAD systems. We propose a novel method for automated detection and segmentation of all large lesions, i. e., large polyps as well as carcinoma. Our detection algorithm is incorporated in a classical CAD system. Candidate detection comprises preselection based on a local measure for protrusion and clustering based on geodesic distance. The generated clusters are further segmented and analyzed. The segmentation algorithm is a thresholding operation in which the threshold is adaptively selected. The segmentation provides a size measurement that is used to compute the likelihood of a cluster to be a large lesion. The large lesion detection algorithm was evaluated on data from 35 patients having 41 large lesions (19 of which malignant) confirmed by optical colonoscopy. At five false positive (FP) per scan, the classical system achieved a sensitivity of 78%, while the system augmented with the large lesion detector achieved 83% sensitivity. For malignant lesions, the performance at five FP/scan was increased from 79% to 95%. The good results on malignant lesions demonstrate that the proposed algorithm may provide relevant additional information for the clinical decision process.
C1 [Grigorescu, Simona E.; Nevo, Shelly T.; van Vliet, Lucas J.; Vos, Frans M.] Delft Univ Technol, Dept Imaging Sci & Technol, NL-2628 CJ Delft, Netherlands.
   [Liedenbaum, Marjolein H.; Stoker, Jaap; Vos, Frans M.] Univ Amsterdam, Acad Med Ctr, Dept Radiol, NL-1105 AZ Amsterdam, Netherlands.
   [Truyen, Roel] Philips Med Syst, Healthcare Informat, Dept Clin Sci & Adv Dev, NL-5684 PC Best, Netherlands.
C3 Delft University of Technology; University of Amsterdam; Academic
   Medical Center Amsterdam; Philips; Philips Healthcare
RP Vos, FM (通讯作者)，Delft Univ Technol, Dept Imaging Sci & Technol, NL-2628 CJ Delft, Netherlands.
EM s.e.grigorescu@tudelft.nl; m.h.liedenbaum@amc.uva.nl;
   roel.truyen@philips.com; j.stoker@amc.uva.nl; l.j.vanvliet@tudelft.nl;
   f.m.vos@tudelft.nl
RI van Vliet, Lucas/E-1678-2012; Stoker, Jaap/AAH-7597-2019
OI van Vliet, Lucas/0000-0001-7018-726X; Stoker, Jaap/0000-0002-9822-3784
FU Philips Healthcare B. V
FX This work was supported in part by Philips Healthcare B. V.
CR Bielen D, 2007, ABDOM IMAGING, V32, P571, DOI 10.1007/s00261-007-9293-2
   Burling D, 2006, EUR RADIOL, V16, P1737, DOI 10.1007/s00330-006-0189-2
   Chowdhury TA, 2008, IEEE T BIO-MED ENG, V55, P888, DOI 10.1109/TBME.2007.909506
   Copel L, 2007, RADIOLOGY, V244, P471, DOI 10.1148/radiol.2442060837
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   Hong W, 2006, IEEE T VIS COMPUT GR, V12, P861, DOI 10.1109/TVCG.2006.112
   Johnson KT, 2006, ACAD RADIOL, V13, P963, DOI 10.1016/j.acra.2006.04.008
   KIRALY AP, 2004, P CARS CHIC IL, P983
   KISS G, 2004, P MICCAI C ST MAL, P804
   Lauenstein TC, 2006, EUR RADIOL, V16, P1519, DOI 10.1007/s00330-006-0260-z
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Luboldt W, 2005, EUR RADIOL, V15, P247, DOI 10.1007/s00330-004-2497-8
   Masutani Y, 2001, J COMPUT ASSIST TOMO, V25, P629, DOI 10.1097/00004728-200107000-00020
   Morcos SK, 2001, EUR RADIOL, V11, P1267, DOI 10.1007/s003300000729
   Nappi J, 2003, MED PHYS, V30, P1592, DOI 10.1118/1.1576393
   Nappi JJ, 2004, MED PHYS, V31, P860, DOI 10.1118/1.1668591
   Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362
   Pekar V, 2001, IEEE VISUAL, P223, DOI 10.1109/VISUAL.2001.964515
   Pham T., 2005, IEEE INT C MULT EXP, P1
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   PILKINTON D, 2006, P SPIE MED IMAG, P984
   Sereda P, 2006, IEEE T VIS COMPUT GR, V12, P208, DOI 10.1109/TVCG.2006.39
   Serlie I, 2003, LECT NOTES COMPUT SC, V2879, P175
   Serlie IWO, 2008, AM J ROENTGENOL, V191, P1493, DOI 10.2214/AJR.07.2776
   Serlie IWO, 2007, IEEE T IMAGE PROCESS, V16, P2891, DOI 10.1109/TIP.2007.909407
   Soille P., 1999, MORPHOLOGICAL IMAGE, DOI DOI 10.1007/978-3-662-03939-7
   Summers RM, 2001, RADIOLOGY, V219, P51, DOI 10.1148/radiology.219.1.r01ap0751
   Summers RM, 2005, GASTROENTEROLOGY, V129, P1832, DOI 10.1053/j.gastro.2005.08.054
   Summers RM, 2006, ACAD RADIOL, V13, P1490, DOI 10.1016/j.acra.2006.09.051
   Taylor SA, 2004, EUR RADIOL, V14, P1025, DOI 10.1007/s00330-004-2262-z
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Van Gelder RE, 2004, GASTROENTEROLOGY, V127, P41, DOI 10.1053/j.gastro.2004.03.055
   van Ravesteijn VF, 2010, IEEE T MED IMAGING, V29, P120, DOI 10.1109/TMI.2009.2028576
   van Wijk C, 2008, AM J ROENTGENOL, V190, P1279, DOI 10.2214/AJR.07.2865
   VANWIJK C, IEEE T MED IN PRESS
   VANWIJK C, 2006, P MICCAI C COP DENM, P471
   Vining DJ, 1999, INT CONGR SER, V1182, P445
   Wan M, 2001, PROC SPIE, V4321, P483, DOI 10.1117/12.428176
   Yao JH, 2004, IEEE T MED IMAGING, V23, P1344, DOI 10.1109/TMI.2004.826941
   Yao JH, 2007, MED PHYS, V34, P1655, DOI 10.1118/1.2717411
   Yoshida H, 2004, SEMIN ULTRASOUND CT, V25, P419, DOI 10.1053/j.sult.2004.07.002
   Yoshida H, 2007, COMPUT MED IMAG GRAP, V31, P267, DOI 10.1016/j.compmedimag.2007.02.011
   Zalis ME, 2005, RADIOLOGY, V236, P3, DOI 10.1148/radiol.2361041926
NR 43
TC 4
Z9 5
U1 1
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD MAR
PY 2010
VL 57
IS 3
BP 675
EP 684
DI 10.1109/TBME.2009.2035632
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 561PR
UT WOS:000274990800020
PM 19884071
DA 2023-04-20
ER

PT J
AU Tischendorf, JJW
   Gross, S
   Winograd, R
   Hecker, H
   Auer, R
   Behrens, A
   Trautwein, C
   Aach, T
   Stehle, T
AF Tischendorf, J. J. W.
   Gross, S.
   Winograd, R.
   Hecker, H.
   Auer, R.
   Behrens, A.
   Trautwein, C.
   Aach, T.
   Stehle, T.
TI Computer-aided classification of colorectal polyps based on vascular
   patterns: a pilot study
SO ENDOSCOPY
LA English
DT Article
ID CONVENTIONAL COLONOSCOPY; CHROMOENDOSCOPY; DIAGNOSIS
AB Background and study aims: Recent studies have shown that narrow-band imaging (NBI) is a powerful diagnostic tool for differentiating between neoplastic and nonneoplastic colorectal polyps. The aim of the present study was to develop and evaluate a computer-based method for automated classification of colorectal polyps on the basis of vascularization features.
   Patients and methods: In a prospective pilot study with 128 patients who were undergoing zoom NBI colonoscopy, 209 detected polyps were visualized and subsequently removed for histological analysis. The proposed computer-based method consists of image preprocessing, vessel segmentation, feature extraction, and classification. The results of the automated classification were compared to those of human observers blinded to the histological gold standard.
   Results: Consensus decision between the human observers resulted in a sensitivity of 93.8% and a specificity of 85.7%. A "safe" decision, i.e., classifying polyps as neoplastic in cases when there was interobserver discrepancy, yielded a sensitivity of 96.9% and a specificity of 71.4%. The overall correct classification rates were 91.9% for the consensus decision and 90.9% for the safe decision. With ideal settings the computer-based approach achieved a sensitivity of approximately 90% and a specificity of approximately 70%, while the overall correct classification rate was 85.3%. The computer-based classification showed a specificity of 61.2% when a sensitivity of 93.8% was selected, and a 53.1% specificity with a sensitivity of 96.9%.
   Conclusions: Automated classification of colonic polyps on the basis of NBI vascularization features is feasible, but classification by observers is still superior. Further research is needed to clarify whether the performance of the automated classification system can be improved.
C1 [Tischendorf, J. J. W.; Gross, S.; Winograd, R.; Trautwein, C.] Rhein Westfal TH Aachen, Univ Hosp Aachen, Med Dept Gastroenterol Hepatol & Metab Dis 3, D-52074 Aachen, Germany.
   [Gross, S.; Auer, R.; Behrens, A.; Aach, T.; Stehle, T.] Rhein Westfal TH Aachen, Inst Imaging & Comp Vis, D-52074 Aachen, Germany.
   [Hecker, H.] Hannover Med Sch, Inst Biometry, D-3000 Hannover, Germany.
C3 RWTH Aachen University; RWTH Aachen University Hospital; RWTH Aachen
   University; Hannover Medical School
RP Tischendorf, JJW (通讯作者)，Rhein Westfal TH Aachen, Univ Hosp Aachen, Med Dept Gastroenterol Hepatol & Metab Dis 3, Pauwelsstr 30, D-52074 Aachen, Germany.
EM jtischendorf@ukaachen.de
RI Gross, Sebastian/ABG-9881-2020
OI Gross, Sebastian/0000-0002-4071-5305
FU Excellence Initiative of the German Federal and State Governments;
   Faculty of Medicine, RWTH Aachen University
FX This research project was supported by the Excellence Initiative of the
   German Federal and State Governments and the START Program of the
   Faculty of Medicine, RWTH Aachen University.
CR ATKIN WS, 1992, NEW ENGL J MED, V326, P658, DOI 10.1056/NEJM199203053261002
   Chiu HM, 2007, GUT, V56, P373, DOI 10.1136/gut.2006.099614
   Christianini N., 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   GROSS S, 2009, P SPIE MED IMAGING, P1
   Gross S., 2009, BILDVERARBEITUNG F R, P252, DOI DOI 10.1007/978-3-540-93860-6_51
   HAJER J, 2006, INF COMMUN TECHNOL, V2, P1130
   Heldwein W, 2005, ENDOSCOPY, V37, P1116, DOI 10.1055/s-2005-870512
   KOVESI P, 1999, VIDERE J COMPUTER VI, V1, P1
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Lieberman DA, 2007, GASTROENTEROLOGY, V133, P1077, DOI 10.1053/j.gastro.2007.07.006
   Martens HA, 1998, CHEMOMETR INTELL LAB, V44, P99, DOI 10.1016/S0169-7439(98)00167-1
   Rastogi A, 2008, GASTROINTEST ENDOSC, V67, P280, DOI 10.1016/j.gie.2007.07.036
   Risau W, 1997, NATURE, V386, P671, DOI 10.1038/386671a0
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Stehle T, 2006, ACTA POLYTECH, V46, P32
   STEHLE T, 2009, P SPIE MED IMAGING, P1
   Su MY, 2006, AM J GASTROENTEROL, V101, P2711, DOI 10.1111/j.1572-0241.2006.00932.x
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   Vapnik V, 1998, STAT LEARNING THEORY
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
NR 25
TC 94
Z9 97
U1 0
U2 6
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD MAR
PY 2010
VL 42
IS 3
BP 203
EP 207
DI 10.1055/s-0029-1243861
PG 5
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 562EH
UT WOS:000275031900004
PM 20101564
DA 2023-04-20
ER

PT J
AU Schwenninger, D
   Moller, K
   Liu, H
   Guttmann, J
AF Schwenninger, David
   Moeller, Knut
   Liu, Hui
   Guttmann, Josef
TI Automated Analysis of Intratidal Dynamics of Alveolar Geometry From
   Microscopic Endoscopy
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Alveolar mechanics; image processing; lung mechanics; mechanical
   ventilation; microscopic endoscopy
ID VENTILATION; MECHANICS
AB Alveolar parenchyma, the gas exchange area of the respiratory system, is prone to mechanical damage during mechanical ventilation. Development of lung protective ventilation strategies therefore requires a better understanding of alveolar dynamics during mechanical ventilation. In this paper, we propose a novel method for automated analysis of the intratidal geometry of subpleural alveoli based on the evaluation of video frames recorded from alveolar microscopy in an experimental setting. Our method includes the recording with a microscopic endoscope, feature extraction from image data, the analysis of a single frame, the tracking and analysis of single alveoli in a video sequence, and the evaluation of the obtained sequence of alveolar geometry data. Our method enables automated analysis of 2-D alveolar geometry with sufficient temporal resolution to follow intratidal dynamics. The developed method and the reproducibility of the results were successfully validated with manually segmented video frames.
C1 [Schwenninger, David; Liu, Hui; Guttmann, Josef] Univ Freiburg, Dept Anesthesiol & Crit Care Med, D-79085 Freiburg, Germany.
   [Moeller, Knut] Furtwangen Univ, Dept Biomed Engn, F-78054 Villingen Schwenningen, France.
C3 University of Freiburg
RP Schwenninger, D (通讯作者)，Univ Freiburg, Dept Anesthesiol & Crit Care Med, D-79085 Freiburg, Germany.
EM david.schwenninger@uniklinik-freiburg.de; moe@hs-furtwangen.de;
   franklinsh@hotmail.com; josef.guttmann@uniklinik-freiburg.de
FU Deutsche Forschungsgemeinschaft [GU561/6-1]; Ministerium fur
   Wissenschaft und Kultur Baden-Wurttemberg; Drager Medical, Lubeck,
   Germany
FX This work was supported in part by the Deutsche Forschungsgemeinschaft
   under Grant GU561/6-1 and in part by the Ministerium fur Wissenschaft
   und Kultur Baden-Wurttemberg and Drager Medical, Lubeck, Germany.
CR Amato MBP, 1998, NEW ENGL J MED, V338, P347, DOI 10.1056/NEJM199802053380602
   Beyer WH, 1987, CRC STANDARD MATH TA, P123
   Carney David, 2005, Crit Care Med, V33, pS122, DOI 10.1097/01.CCM.0000155928.95341.BC
   DALY BDT, 1975, RESP PHYSIOL, V24, P217, DOI 10.1016/0034-5687(75)90115-2
   Dreyfuss D, 1998, AM J RESP CRIT CARE, V157, P294, DOI 10.1164/ajrccm.157.1.9604014
   JAHNE B, 2005, DIGITALE BILDVERARBE, P114
   LaFollette Ryan, 2007, Nurs Crit Care, V12, P231, DOI 10.1111/j.1478-5153.2007.00224.x
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   NIEMAN GF, 1981, J APPL PHYSIOL, V51, P895, DOI 10.1152/jappl.1981.51.4.895
   PARKER JC, 1993, CRIT CARE MED, V21, P131, DOI 10.1097/00003246-199301000-00024
   Pavone LA, 2007, CRIT CARE, V11, DOI 10.1186/cc5940
   Popp A, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2162158
   Schiller HJ, 2001, CRIT CARE MED, V29, P1049, DOI 10.1097/00003246-200105000-00036
   SchWenninger D., 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P2335, DOI 10.1109/ICBBE.2008.916
   SCHWENNINGER D, 2009, CRIT CARE, V13, pS52
   STAHL CA, 2006, J BIOMECH, V39, pS598
   Terragni PP, 2003, EUR RESPIR J, V22, p15S, DOI 10.1183/09031936.03.00420303
   Tobin MJ, 2001, NEW ENGL J MED, V344, P1986, DOI 10.1056/NEJM200106283442606
   Villar J, 2005, Minerva Anestesiol, V71, P255
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
NR 20
TC 8
Z9 8
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD FEB
PY 2010
VL 57
IS 2
BP 415
EP 421
DI 10.1109/TBME.2009.2031630
PG 7
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 545VH
UT WOS:000273764600020
PM 19770085
DA 2023-04-20
ER

PT J
AU Vilarino, F
   Spyridonos, P
   DeIorio, F
   Vitria, J
   Azpiroz, F
   Radeva, P
AF Vilarino, Fernando
   Spyridonos, Panagiota
   DeIorio, Fosca
   Vitria, Jordi
   Azpiroz, Fernando
   Radeva, Petia
TI Intestinal Motility Assessment With Video Capsule Endoscopy: Automatic
   Annotation of Phasic Intestinal Contractions
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Imbalanced data classification; intestinal motility; video capsule
   endoscopy
ID CLASSIFICATION; DIAGNOSIS; SUPPORT
AB Intestinal motility assessment with video capsule endoscopy arises as a novel and challenging clinical fieldwork. This technique is based on the analysis of the patterns of intestinal contractions shown in a video provided by an ingestible capsule with a wireless micro-camera. The manual labeling of all the motility events requires large amount of time for offline screening in search of findings with low prevalence, which turns this procedure currently unpractical. In this paper, we propose a machine learning system to automatically detect the phasic intestinal contractions in video capsule endoscopy, driving a useful but not feasible clinical routine into a feasible clinical procedure. Our proposal is based on a sequential design which involves the analysis of textural, color, and blob features together with SVM classifiers. Our approach tackles the reduction of the imbalance rate of data and allows the inclusion of domain knowledge as new stages in the cascade. We present a detailed analysis, both in a quantitative and a qualitative way, by providing several measures of performance and the assessment study of interobserver variability. Our system performs at 70% of sensitivity for individual detection, whilst obtaining equivalent patterns to those of the experts for density of contractions.
C1 [Vilarino, Fernando; Spyridonos, Panagiota; Vitria, Jordi; Radeva, Petia] Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
   [Vilarino, Fernando; Spyridonos, Panagiota; Vitria, Jordi; Radeva, Petia] Univ Autonoma Barcelona, Dept Comp Sci, E-08193 Barcelona, Spain.
   [DeIorio, Fosca; Azpiroz, Fernando] HU Vall Hebron, Barcelona 08193, Spain.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Autonomous University of Barcelona; Hospital Universitari Vall
   d'Hebron
RP Vilarino, F (通讯作者)，Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
RI Vilarino, Fernando/AAU-4306-2020; Heredia, Josefina/I-1166-2012; Vitrià,
   Jordi/AAF-9668-2020; Radeva, Petia/I-3385-2015; Vitria,
   Jordi/C-7072-2008; Spyridonos, Panagiota/AAN-8293-2021
OI Vilarino, Fernando/0000-0002-7705-4141; Vitrià,
   Jordi/0000-0003-1484-539X; Radeva, Petia/0000-0003-0047-5172; Vitria,
   Jordi/0000-0003-1484-539X; Azpiroz, Fernando/0000-0002-7327-960X
FU Given Imaging Ltd; Yoqneam Israel, H. U. Vall d'Hebron, Barcelona, Spain
   [TIN200615308-C02, FIS-PI061290]
FX This work was supported in part by a research grant from Given Imaging
   Ltd., Yoqneam Israel, H. U. Vall d'Hebron, Barcelona, Spain, and in part
   by Project TIN200615308-C02 and Project FIS-PI061290. The technology and
   methods embraced by this disclosure have been filed for patent
   protection.
CR Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7
   [Anonymous], 1956, NONPARAMETRIC STAT B
   BAHSAR M, 2008, LECT NOTES COMPUTER, V5242, P603
   BOULOUGOURA M, 2005, P IASTED CBEI, P408
   Chawla N., 2003, C4 5 IMBALANCED DATA
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   DEIORIO F, 2005, GASTROENTEROLOGY, V128
   DEIORIO F, 2006, GASTROENTEROLOGY, V130, P43
   Domingos P., 1999, P 5 ACM SIGKDD INT C, V99, P155, DOI DOI 10.1145/312129.312220
   Fawcett T, 1997, DATA MIN KNOWL DISC, V1, P291, DOI 10.1023/A:1009700419189
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hansen MB, 2002, PHYSIOL RES, V51, P541
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Igual L, 2007, LECT NOTES COMPUT SC, V4673, P293
   Joachims Thorsten, 1998, MACHINE LEARNING ECM, P137, DOI [10.1007/BFb0026683, DOI 10.1007/BFB0026683]
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kellow JE, 1999, GUT, V45, P17
   KODOGIANNIS VS, 2004, P ICMSP MEDISP, P267
   Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027
   Magoulas GD, 2004, APPL SOFT COMPUT, V4, P369, DOI 10.1016/j.asoc.2004.01.005
   METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2
   Monard MC, 2002, FRONT ARTIF INTEL AP, V85, P173
   OHANIAN PP, 1992, PATTERN RECOGN, V25, P819, DOI 10.1016/0031-3203(92)90036-I
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Quigley EMM, 1996, GASTROENTEROL CLIN N, V25, P113, DOI 10.1016/S0889-8553(05)70368-X
   Quigley EMM, 1999, BEST PRACT RES CL GA, V13, P385, DOI 10.1053/bega.1999.0034
   RUSS JC, 1994, IMAGE PROCESSING HDB
   Segui S, 2008, LECT NOTES COMPUT SC, V5008, P251
   Spyridonos P, 2005, LECT NOTES COMPUT SC, V3708, P531
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Theodoridis S, 2003, PATTERN RECOGNITION
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Vapnik V., 1999, NATURE STAT LEARNING
   Vilarino F, 2006, INT C PATT RECOG, P719
   Vilarino F, 2005, LECT NOTES COMPUT SC, V3687, P783
   VILARINO F, 2006, THESIS U AUTONOMA BA
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P188
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P178
   Vilarino F, 2006, PATTERN RECOGN LETT, V27, P875, DOI 10.1016/j.patrec.2005.10.011
   Zheng MM, 2005, COMPUT BIOL MED, V35, P259, DOI 10.1016/j.compbiomed.2004.01.002
NR 40
TC 39
Z9 41
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD FEB
PY 2010
VL 29
IS 2
BP 246
EP 259
DI 10.1109/TMI.2009.2020753
PG 14
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA 551LS
UT WOS:000274211700003
PM 19423434
DA 2023-04-20
ER

PT J
AU Suzuki, K
   Rockey, DC
   Dachman, AH
AF Suzuki, Kenji
   Rockey, Don C.
   Dachman, Abraham H.
TI CT colonography: Advanced computer-aided detection scheme utilizing
   MTANNs for detection of "missed" polyps in a multicenter clinical trial
SO MEDICAL PHYSICS
LA English
DT Article
DE virtual colonoscopy; computer-aided diagnosis; missed lesions;
   colorectal cancer screening; false negatives
ID ARTIFICIAL NEURAL-NETWORK; FALSE POSITIVES; COLONIC POLYPS; TOMOGRAPHIC
   COLONOGRAPHY; COLORECTAL NEOPLASIA; VIRTUAL COLONOSCOPY; CONVENTIONAL
   COLONOSCOPY; DETECTION ALGORITHM; LUNG NODULES; PERFORMANCE
AB Purpose: The purpose of this study was to develop an advanced computer-aided detection (CAD) scheme utilizing massive-training artificial neural networks (MTANNs) to allow detection of "difficult" polyps in CT colonography (CTC) and to evaluate its performance on false-negative (FN) CTC cases that radiologists "missed" in a multicenter clinical trial.
   Methods: The authors developed an advanced CAD scheme consisting of an initial polyp-detection scheme for identification of polyp candidates and a mixture of expert MTANNs for substantial reduction in false positives (FPs) while maintaining sensitivity. The initial polyp-detection scheme consisted of (1) colon segmentation based on anatomy-based extraction and colon-based analysis and (2) detection of polyp candidates based on a morphologic analysis on the segmented colon. The mixture of expert MTANNs consisted of (1) supervised enhancement of polyps and suppression of various types of nonpolyps, (2) a scoring scheme for converting output voxels into a score for each polyp candidate, and (3) combining scores from multiple MTANNs by the use of a mixing artificial neural network. For testing the advanced CAD scheme, they created a database containing 24 FN cases with 23 polyps (range of 6-15 mm; average of 8 mm) and a mass (35 mm), which were "missed" by radiologists in CTC in the original trial in which 15 institutions participated.
   Results: The initial polyp-detection scheme detected 63% (15/24) of the missed polyps with 21.0 (505/24) FPs per patient. The MTANNs removed 76% of the FPs with loss of one true positive; thus, the performance of the advanced CAD scheme was improved to a sensitivity of 58% (14/24) with 8.6 (207/24) FPs per patient, whereas a conventional CAD scheme yielded a sensitivity of 25% at the same FP rate (the difference was statistically significant).
   Conclusions: With the advanced MTANN CAD scheme, 58% of the polyps missed by radiologists in the original trial were detected and with a reasonable number of FPs. The results suggest that the use of an advanced MTANN CAD scheme may potentially enhance the detection of "difficult" polyps. (C) 2010 American Association of Physicists in Medicine. [DOI: 10.1118/1.3263615]
C1 [Suzuki, Kenji; Dachman, Abraham H.] Univ Chicago, Dept Radiol, Chicago, IL 60637 USA.
   [Rockey, Don C.] Univ Texas SW Med Ctr Dallas, Dept Internal Med, Dallas, TX 75390 USA.
C3 University of Chicago; University of Texas System; University of Texas
   Southwestern Medical Center Dallas
RP Suzuki, K (通讯作者)，Univ Chicago, Dept Radiol, 5841 S Maryland Ave, Chicago, IL 60637 USA.
EM suzuki@uchicago.edu
RI Suzuki, Kenji/A-1284-2007
OI Suzuki, Kenji/0000-0002-3993-8309; Dachman, Abraham/0000-0002-7035-2752
FU National Cancer Institute/National Institutes of Health [R01CA120549];
   NIH [S10 RR021039, P30 CA14599]
FX The authors are grateful to Ms. E. F. Lanzl for improving the manuscript
   and Lena Gong and Joel Verceles for their assistance with experiments.
   This work was supported by Grant No. R01CA120549 from the National
   Cancer Institute/National Institutes of Health and partially by the NIH
   Grant Nos. S10 RR021039 and P30 CA14599.
CR American Cancer Society, 2008, CAN FACTS FIG 2008
   Baker ME, 2007, RADIOLOGY, V245, P140, DOI 10.1148/radiol.2451061116
   Cotton PB, 2004, JAMA-J AM MED ASSOC, V291, P1713, DOI 10.1001/jama.291.14.1713
   DACHMAN A, 2003, ATLAS VIRTUAL COLONO
   Dachman AH, 2008, RADIOLOGY, V249, P167, DOI 10.1148/radiol.2491080059
   Dachman AH, 2004, RADIOLOGY, V230, P319, DOI 10.1148/radiol.2302031113
   de Vries AH, 2009, EUR RADIOL, V19, P941, DOI 10.1007/s00330-008-1215-3
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Doshi T, 2007, RADIOLOGY, V244, P165, DOI 10.1148/radiol.2441061122
   Edwards DC, 2002, MED PHYS, V29, P2861, DOI 10.1118/1.1524631
   EGAN JP, 1961, J ACOUST SOC AM, V33, P993, DOI 10.1121/1.1908935
   Fenlon HM, 1999, NEW ENGL J MED, V341, P1496, DOI 10.1056/NEJM199911113412003
   Fletcher JG, 2007, AM J ROENTGENOL, V189, P277, DOI 10.2214/AJR.07.2289
   Fukunaga K, 1990, INTRO STAT PATTERN R
   Jerebko AK, 2003, ACAD RADIOL, V10, P154, DOI 10.1016/S1076-6332(03)80039-9
   Jerebko AK, 2005, ACAD RADIOL, V12, P479, DOI 10.1016/j.acra.2004.04.024
   Jerebko AK, 2003, MED PHYS, V30, P52, DOI 10.1118/1.1528178
   Johnson CD, 2003, GASTROENTEROLOGY, V125, P688, DOI 10.1016/S0016-5085(03)01058-8
   Kim DH, 2007, NEW ENGL J MED, V357, P1403, DOI 10.1056/NEJMoa070543
   Kiss G, 2002, EUR RADIOL, V12, P77, DOI 10.1007/s003300101040
   Kobayashi S., 1963, FDN DIFFERENTIAL GEO, VVolume 1
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Levin B, 2008, CA-CANCER J CLIN, V58, P130, DOI 10.3322/CA.2007.0018
   Li J, 2008, MED PHYS, V35, P3527, DOI 10.1118/1.2938517
   Nappi J, 2003, MED PHYS, V30, P1592, DOI 10.1118/1.1576393
   Nappi J, 2002, J COMPUT ASSIST TOMO, V26, P493, DOI 10.1097/01.RCT.0000025350.64054.4E
   Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362
   Petrick N, 2008, RADIOLOGY, V246, P148, DOI 10.1148/radiol.2453062161
   Pickhardt PJ, 2007, CANCER, V109, P2213, DOI 10.1002/cncr.22668
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Rockey DC, 2005, LANCET, V365, P305
   Sahiner B, 2008, NEURAL NETWORKS, V21, P476, DOI 10.1016/j.neunet.2007.12.012
   Sahiner B, 2008, MED PHYS, V35, P1559, DOI 10.1118/1.2868757
   Soetikno RM, 2008, JAMA-J AM MED ASSOC, V299, P1027, DOI 10.1001/jama.299.9.1027
   Summers RM, 2001, RADIOLOGY, V219, P51, DOI 10.1148/radiology.219.1.r01ap0751
   Suzuki K, 2006, IEEE T MED IMAGING, V25, P406, DOI 10.1109/TMI.2006.871549
   Suzuki K, 2005, IEEE T MED IMAGING, V24, P1138, DOI 10.1109/TMI.2005.852048
   Suzuki K, 2005, ACAD RADIOL, V12, P1333, DOI 10.1016/j.acra.2005.06.017
   Suzuki K, 2004, IEEE T MED IMAGING, V23, P330, DOI 10.1109/TMI.2004.824238
   Suzuki K, 2003, IEEE T PATTERN ANAL, V25, P1582, DOI 10.1109/TPAMI.2003.1251151
   Suzuki K, 2003, MED PHYS, V30, P1602, DOI 10.1118/1.1580485
   Suzuki K, 2008, MED PHYS, V35, P694, DOI 10.1118/1.2829870
   Suzuki K, 2006, MED PHYS, V33, P3814, DOI 10.1118/1.2349839
   Suzuki K, 2009, PHYS MED BIOL, V54, pS31, DOI 10.1088/0031-9155/54/18/S03
   Svensson MH, 2002, RADIOLOGY, V222, P337, DOI 10.1148/radiol.2222010669
   Taylor SA, 2008, RADIOLOGY, V247, P133, DOI 10.1148/radiol.2471070816
   van Gelder RE, 2004, RADIOLOGY, V233, P328, DOI 10.1148/radiol.2331031208
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Winawer SJ, 1997, GASTROENTEROLOGY, V112, P594, DOI 10.1053/gast.1997.v112.agast970594
   Yee J, 2001, RADIOLOGY, V219, P685, DOI 10.1148/radiology.219.3.r01jn40685
   Yoshida H, 2002, RADIOLOGY, V222, P327, DOI 10.1148/radiol.2222010506
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
NR 52
TC 36
Z9 38
U1 0
U2 3
PU AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0094-2405
J9 MED PHYS
JI Med. Phys.
PD JAN
PY 2010
VL 37
IS 1
BP 12
EP 21
DI 10.1118/1.3263615
PG 10
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA 538GI
UT WOS:000273172100003
PM 20175461
OA Green Published
DA 2023-04-20
ER

PT J
AU De Iorio, F
   Malagelada, C
   Azpiroz, F
   Maluenda, M
   Violanti, C
   Igual, L
   Vitria, J
   Malagelada, JR
AF De Iorio, F.
   Malagelada, C.
   Azpiroz, F.
   Maluenda, M.
   Violanti, C.
   Igual, L.
   Vitria, J.
   Malagelada, J. -R
TI Intestinal motor activity, endoluminal motion and transit
SO NEUROGASTROENTEROLOGY AND MOTILITY
LA English
DT Article
DE capsule endoscopy; computer vision analysis; endoluminal image analysis;
   glucagon; intestinal motor inhibition; machine learning techniques;
   small bowel motility; small bowel transit
ID GAS RETENTION; HUMANS; CONTRACTIONS; PERCEPTION; MOTILITY; MACHINE
AB P>A programme for evaluation of intestinal motility has been recently developed based on endoluminal image analysis using computer vision methodology and machine learning techniques. Our aim was to determine the effect of intestinal muscle inhibition on wall motion, dynamics of luminal content and transit in the small bowel. Fourteen healthy subjects ingested the endoscopic capsule (Pillcam, Given Imaging) in fasting conditions. Seven of them received glucagon (4.8 mu g kg-1 bolus followed by a 9.6 mu g kg-1 h-1 infusion during 1 h) and in the other seven, fasting activity was recorded, as controls. This dose of glucagon has previously shown to inhibit both tonic and phasic intestinal motor activity. Endoluminal image and displacement was analyzed by means of a computer vision programme specifically developed for the evaluation of muscular activity (contractile and non-contractile patterns), intestinal contents, endoluminal motion and transit. Thirty-minute periods before, during and after glucagon infusion were analyzed and compared with equivalent periods in controls. No differences were found in the parameters measured during the baseline (pretest) periods when comparing glucagon and control experiments. During glucagon infusion, there was a significant reduction in contractile activity (0.2 +/- 0.1 vs 4.2 +/- 0.9 luminal closures per min, P < 0.05; 0.4 +/- 0.1 vs 3.4 +/- 1.2% of images with radial wrinkles, P < 0.05) and a significant reduction of endoluminal motion (82 +/- 9 vs 21 +/- 10% of static images, P < 0.05). Endoluminal image analysis, by means of computer vision and machine learning techniques, can reliably detect reduced intestinal muscle activity and motion.
C1 [De Iorio, F.; Malagelada, C.; Azpiroz, F.; Maluenda, M.; Violanti, C.; Malagelada, J. -R] Univ Hosp Valle Hebron, Digest Syst Res Unit, Barcelona, Spain.
   [De Iorio, F.; Malagelada, C.; Azpiroz, F.; Maluenda, M.; Violanti, C.; Malagelada, J. -R] Ctr Invest Biomed Red Enfermedades Hepat & Digest, Barcelona, Spain.
   [De Iorio, F.; Malagelada, C.; Azpiroz, F.; Maluenda, M.; Violanti, C.; Malagelada, J. -R] Autonomous Univ Barcelona, Dept Med, Barcelona, Spain.
   [Igual, L.; Vitria, J.] Comp Vis Ctr, Bellaterra, Spain.
C3 Hospital Universitari Vall d'Hebron; CIBER - Centro de Investigacion
   Biomedica en Red; CIBEREHD; Autonomous University of Barcelona; Centre
   de Visio per Computador (CVC)
RP Azpiroz, F (通讯作者)，Hosp Gen Valle Hebron, Digest Syst Res Unit, Barcelona 08035, Spain.
EM azpiroz.fernando@gmail.com
RI Vitrià, Jordi/AAF-9668-2020; Igual, Laura/H-5606-2015; Heredia,
   Josefina/I-1166-2012; Malagelada, Carolina/F-3743-2016; Vitria,
   Jordi/C-7072-2008
OI Vitrià, Jordi/0000-0003-1484-539X; Igual, Laura/0000-0002-7225-7441;
   Malagelada, Carolina/0000-0001-7097-1492; Vitria,
   Jordi/0000-0003-1484-539X; Azpiroz, Fernando/0000-0002-7327-960X
FU Spanish Ministry of Education [SAF 2006-03907]; Spanish Ministry of
   Health [CM05/00012]; Fundacio La MaratoTV3 [MARATV3_072010]; Instituto
   de Salud Carlos III
FX Supported in part by Given Imaging, the Spanish Ministry of Education
   (Direccion General de Investigacion, SAF 2006-03907), the Spanish
   Ministry of Health (Ayuda para contratos postformacion sanitaria
   especializada, CM05/00012) and Fundacio La MaratoTV3 (MARATV3_072010).
   Ciberehd is funded by the Instituto de Salud Carlos III.; The authors
   thank Sara Mendez for performing and visualizing the studies; Santi
   Segui, Panagiota Spyridonos, Fernando Vilarinao and Petia Radeva for
   their contribution to the computer vision analysis program; Maite Casaus
   and Anna Aparici for technical support; and Gloria Santaliestra for
   secretarial assistance.
CR Caldarella MP, 2002, GASTROENTEROLOGY, V122, P1748, DOI 10.1053/gast.2002.33658
   DEIORIO F, 2006, GASTROENTEROLOGY, V130, pA473
   GREGERSEN H, 1988, SCAND J GASTROENTERO, V23, P42, DOI 10.3109/00365528809095932
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   IGUAL L, 2009, IFMB P BERL, P1536
   Malagelada C, 2008, GASTROENTEROLOGY, V135, P1155, DOI 10.1053/j.gastro.2008.06.084
   MALAGELADA JR, 1984, GASTROENTEROLOGY, V87, P1255
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   ROUILLON JM, 1991, GASTROENTEROLOGY, V101, P1606, DOI 10.1016/0016-5085(91)90398-5
   ROUILLON JM, 1991, AM J PHYSIOL, V261, pG280, DOI 10.1152/ajpgi.1991.261.2.G280
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   RUSS JC, 2007, IMAGE PROCESSING HDB
   Schirra J, 2000, GUT, V46, P622, DOI 10.1136/gut.46.5.622
   Serra J, 2001, AM J PHYSIOL-GASTR L, V281, pG138, DOI 10.1152/ajpgi.2001.281.1.G138
   Serra J, 1998, J PHYSIOL-LONDON, V506, P579, DOI 10.1111/j.1469-7793.1998.579bw.x
   SERRA J, 2006, NEUROGASTROENT MOTIL, V18, pA394
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Vilarino F, 2006, INT J COMPUT ASS RAD, V1, P9
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P188
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P178
NR 20
TC 14
Z9 14
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1350-1925
EI 1365-2982
J9 NEUROGASTROENT MOTIL
JI Neurogastroenterol. Motil.
PD DEC
PY 2009
VL 21
IS 12
DI 10.1111/j.1365-2982.2009.01363.x
PG 7
WC Gastroenterology & Hepatology; Clinical Neurology; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Neurosciences & Neurology
GA 517UN
UT WOS:000271644200005
PM 19614865
DA 2023-04-20
ER

PT J
AU Hafner, M
   Kwitt, R
   Uhl, A
   Gangl, A
   Wrba, F
   Vecsei, A
AF Haefner, Michael
   Kwitt, Roland
   Uhl, Andreas
   Gangl, Alfred
   Wrba, Friedrich
   Vecsei, Andreas
TI Feature extraction from multi-directional multi-resolution image
   transformations for the classification of zoom-endoscopy images
SO PATTERN ANALYSIS AND APPLICATIONS
LA English
DT Article
DE Zoom-endoscopy; Wavelet transform; Classification; Texture analysis
ID MAGNIFICATION CHROMOENDOSCOPY
AB In this article, we discuss the discriminative power of a set of image features, extracted from detail subbands of the Gabor wavelet transform and the dual-tree complex wavelet transform for the purpose of computer-assisted zoom-endoscopy image classification. We incorporate color channel information into the classification process and show that this leads to superior classification results, compared to luminance-channel-only-based image analysis.
C1 [Kwitt, Roland; Uhl, Andreas] Salzburg Univ, Dept Comp Sci, A-5020 Salzburg, Austria.
   [Haefner, Michael; Gangl, Alfred] Vienna Med Univ, Dept Clin Pathol, A-1090 Vienna, Austria.
   [Wrba, Friedrich] Vienna Med Univ, Dept Gastroenterol & Hepatol, A-1090 Vienna, Austria.
   [Vecsei, Andreas] St Anna Childrens Hosp, A-1090 Vienna, Austria.
C3 Salzburg University; Medical University of Vienna; Medical University of
   Vienna; Saint Anna Children's Hospital
RP Kwitt, R (通讯作者)，Salzburg Univ, Dept Comp Sci, A-5020 Salzburg, Austria.
EM rkwitt@gmx.at
RI Kwitt, Roland/AFS-8639-2022; jiang, shujie/A-2936-2014; Kwitt,
   Roland/HII-6060-2022
FU Austrian Science Fund (FWF) [L366-N15]
FX This work is funded by the Austrian Science Fund (FWF) under Project No.
   L366-N15.
CR Fukunaga K, 1990, INTRO STAT PATTERN R
   Hafner M, 2007, COMP MED SY, P159, DOI 10.1109/CBMS.2007.85
   Hafner M, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, P58
   HAFNER M, 2007, P 2007 IEEE MACH LEA, P99
   HAFNER M, 2006, P 3 INT C ADV MED SI
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hatipoglu S, 1999, IEE CONF PUBL, P344, DOI 10.1049/cp:19990340
   Hurlstone DP, 2002, AM J GASTROENTEROL, V97, P1069
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kingsbury N. G., 1998, P 8 IEEE DSP WORKSH, P9
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   KWITT R, 2007, P IEEE COMP SOC WORK
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Meining A, 2004, ENDOSCOPY, V36, P160, DOI 10.1055/s-2004-814183
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   SAITO N, 1994, P SOC PHOTO-OPT INS, V2303, P2, DOI 10.1117/12.188763
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   VANDEWOUVER G, 1997, P ICIAP INT C COMP A, P327
   Zuiderveld K., 1994, GRAPHICS GEMS
NR 22
TC 26
Z9 26
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1433-7541
EI 1433-755X
J9 PATTERN ANAL APPL
JI Pattern Anal. Appl.
PD DEC
PY 2009
VL 12
IS 4
BP 407
EP 413
DI 10.1007/s10044-008-0136-8
PG 7
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 509OV
UT WOS:000271028300008
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Saraf, SS
   Udupi, CR
   Hajare, SD
AF Saraf, Santosh S.
   Udupi, C. R.
   Hajare, Santosh D.
TI DECISION SUPPORT SYSTEM BASED ON DCT TEXTURE FEATURES FOR DIAGNOSIS OF
   ESOPHAGITIS
SO JOURNAL OF MECHANICS IN MEDICINE AND BIOLOGY
LA English
DT Article
DE Medical diagnosis; image processing; decision support system
ID GASTROESOPHAGEAL-REFLUX DISEASE; CLASSIFICATION; PREVALENCE
AB Esophagitis is essentially inflammation of the esophageal squamous mucosa. One of the major reasons for cause of Esophagitis is the acid reflux from the stomach. This condition is observed in the process of upper gastro-intestinal tract endoscopy and the diagnosis is arrived at by examining the images of the esophagus. The diagnosis is based on the observation of the lesions and coloration of the digestive mucosa. Our paper reports an implementation of Decision Support System (DSS) for diagnosis of Esophagitis based on the analysis of color and texture features of the images captured during the process of endoscopy. The Hue Saturation and Intensity color model is adapted. The statistical features of the Hue and Saturation form the color features and the texture features are determined by Discrete Cosine Transform coefficients of the image. The decision making structure is a feed forward neural network. The DSS has been tested and results are reported.
C1 [Saraf, Santosh S.] Gogte Inst Technol, Dept Elect & Commun Engn, Res Ctr, Belgaum, Karnataka, India.
   [Udupi, C. R.] Vishwanathrao Desphande Rural Inst Technol, Haliyal, Karnataka, India.
   [Hajare, Santosh D.] KLE Hosp & Res Ctr, Dept Gastroenterol, Belgaum, Karnataka, India.
C3 K.L.E. Academy of Higher Education & Research
RP Saraf, SS (通讯作者)，Gogte Inst Technol, Dept Elect & Commun Engn, Res Ctr, Belgaum, Karnataka, India.
EM santoshsaraf@git.edu; grudupi@yahoo.com; drsantoshhajare@hotmail.com
CR Allende DS, 2009, ADV ANAT PATHOL, V16, P161, DOI 10.1097/PAP.0b013e3181a186a3
   ANAND R, 1995, IEEE T NEURAL NETWOR, V6, P117, DOI 10.1109/72.363444
   ARIVAZHAGAN S, 2005, P ICCIMA 05
   ARMSTRONG DW, 1991, AMINO ACIDS, V1, P1
   BELIAKOV G, 2008, P IEEE WORLD C COMP, P1472
   Chen L, 2005, IEEE IJCNN, P1947
   Economou GPK, 1996, COMPUT CONTROL ENG J, V7, P177, DOI 10.1049/cce:19960404
   Gan Tao, 2007, Sheng Wu Yi Xue Gong Cheng Xue Za Zhi, V24, P756
   Gilger MA, 2008, J PEDIATR GASTR NUTR, V47, P141, DOI 10.1097/MPG.0b013e31815eeabe
   GOLAM S, DCT BASED TEXTURE CL
   Gorzalczany MB, 1996, ISIE'96 - PROCEEDINGS OF THE IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1 AND 2, P398, DOI 10.1109/ISIE.1996.548454
   HAGAN D, 1996, THOMSON LEARNING SIN
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   JEROME H, 1997, DATA MIN KNOWL DISC, V1, P55
   KOCK GH, 2008, MULTIVARIATE ANAL AS
   KOSE S, 1993, DIGEST ENDOSC, P62
   NA YH, 1994, KOREAN J GASTROINTES, V2, P145
   Nahum AM, 1978, ESOPHAGUS HDB ATLAS, DOI [10.1002/hed.2890060315, DOI 10.1002/HED.2890060315]
   PRATEEK S, 2008, AM J GASTROENTEROL, V103, P525
   Revett K, 2005, Eurocon 2005: The International Conference on Computer as a Tool, Vol 1 and 2 , Proceedings, P1124
   RIPLEY BD, 1994, J R STAT SOC B, V56, P409
   Saha S., 1995, Proceedings of the 1995 Fourteenth Southern Biomedical Engineering Conference (Cat. No.95TH0703-9), P134, DOI 10.1109/SBEC.1995.514459
   Seo KW, 2008, J MECH SCI TECHNOL, V22, P2475, DOI 10.1007/s12206-008-0708-y
   Wanas N, 1998, UNIVERSITY AND INDUSTRY - PARTNERS IN SUCCESS, CONFERENCE PROCEEDINGS VOLS 1-2, P918, DOI 10.1109/CCECE.1998.685648
   Wang A, 2009, DIGEST DIS SCI, V54, P964, DOI 10.1007/s10620-009-0742-3
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   WELCH E, 1991, IEEE PROCEEDINGS OF THE SOUTHEASTCON 91, VOLS 1 AND 2, P722, DOI 10.1109/SECON.1991.147852
   Witt H., 1997, Acta Endoscopica, V27, P239, DOI 10.1007/BF02969054
   Wong RKM, 2009, J GASTROEN HEPATOL, V24, P103, DOI 10.1111/j.1440-1746.2008.05680.x
   Zheng MM, 2002, IEEE CCEC 2002: CANADIAN CONFERENCE ON ELECTRCIAL AND COMPUTER ENGINEERING, VOLS 1-3, CONFERENCE PROCEEDINGS, P1116, DOI 10.1109/CCECE.2002.1013103
   ZHENG MM, 2001, 7 AUSTR NZ INT INF S, P107
NR 31
TC 3
Z9 3
U1 0
U2 2
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-5194
EI 1793-6810
J9 J MECH MED BIOL
JI J. Mech. Med. Biol.
PD DEC
PY 2009
VL 9
IS 4
BP 527
EP 538
DI 10.1142/S0219519409003097
PG 12
WC Biophysics; Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biophysics; Engineering
GA 625EB
UT WOS:000279876200005
DA 2023-04-20
ER

PT J
AU Takayama, T
   Takayama, K
   Inoue, A
   Funakoshi, S
   Serizawa, H
   Watanabe, N
   Kumagai, N
   Tsuchimoto, K
   Hibi, T
AF Takayama, Tetsuro
   Takayama, Kozo
   Inoue, Agamu
   Funakoshi, Shinsuke
   Serizawa, Hiroshi
   Watanabe, Noriaki
   Kumagai, Naoki
   Tsuchimoto, Kanji
   Hibi, Toshifumi
TI Prediction of survival and complications after percutaneous endoscopic
   gastrostomy in an individual by using clinical factors with an
   artificial neural network system
SO EUROPEAN JOURNAL OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Article
DE artificial neural network; percutaneous endoscopic gastrostomy;
   prediction; survival
ID LOWER-GASTROINTESTINAL HEMORRHAGE; CHRONIC HEPATITIS-C; TUBE PLACEMENT;
   OPTIMIZATION; EXPERIENCE; MORTALITY; GASTROENTEROLOGY; GUIDELINES;
   NUTRITION; OUTCOMES
AB Background The demand for percutaneous endoscopic gastrostomy (PEG) has increased because it is safe and a technically easy method, but it has risks of severe complications including death and a high mortality rate within 30 days. At present, we cannot predict survival or the incidence of complications before tube placement in an individual. Earlier studies have used traditional statistical analysis by assuming a linear relationship between clinical features, but most phenomena in the clinical situation are not linearly related. Aims We predicted the survival and complications before PEG placement in an individual by using artificial neural network (ANN) system, which can assess the nonlinear relationship.
   Methods We studied 100 patients who underwent PEG at the Kitasato Medical Institute Hospital from 1997 to 2005. Clinical data and laboratory data were used as input data. Complications related to PEG placement and survival dates were historically and prospectively measured. From the clinical data and laboratory data, we examined the prediction of outcome in individual patients using multiple logistic regression analysis and an ANN.
   Results The correct answer rate of survival by multiple logistic regression analysis was 67.9%. In contrast, using the ANN, we correctly predicted the survival date and aspiration pneumonia in 75 and 89% of patients, respectively. There was a nonlinear relationship among input factors and survival and complications.
   Conclusion We correctly predicted the outcome and complications of individual patients with PEG with a high correct answer rate. Our data show the potential of an ANN as a powerful tool in daily clinical use to individualize treatment ('tailor-made medicine') for PEG and reduce costs. Eur J Gastroenterol Hepatol 21:1279-1285 (C) 2009 Wolters Kluwer Health | Lippincott Williams & Wilkins.
C1 [Hibi, Toshifumi] Keio Univ, Sch Med, Dept Internal Med, Shinjuku Ku, Tokyo 1608582, Japan.
   [Takayama, Kozo] Hoshi Univ, Dept Pharmaceut, Tokyo 142, Japan.
   [Funakoshi, Shinsuke; Serizawa, Hiroshi; Watanabe, Noriaki; Kumagai, Naoki; Tsuchimoto, Kanji] Kitasato Inst Hosp, Dept Gastroenterol, Tokyo, Japan.
C3 Keio University; Hoshi University; Kitasato University
RP Hibi, T (通讯作者)，Keio Univ, Sch Med, Dept Internal Med, Shinjuku Ku, 35 Shinanomachi, Tokyo 1608582, Japan.
EM thibi@sc.itc.keio.ac.jp
RI Watanabe, Noriaki/AAC-4500-2019
OI Watanabe, Noriaki/0000-0002-3876-2794
CR AOYAMA T, 1990, J MED CHEM, V33, P2583, DOI 10.1021/jm00171a037
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   BAXT WG, 1991, ANN INTERN MED, V115, P843, DOI 10.7326/0003-4819-115-11-843
   Chong V. H., 2006, SMJ Singapore Medical Journal, V47, P383
   CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Das A, 2007, EUR J GASTROEN HEPAT, V19, P1064, DOI 10.1097/MEG.0b013e3282f198f7
   Fried TR, 2002, NEW ENGL J MED, V346, P1061, DOI 10.1056/NEJMsa012528
   Friedenberg F, 1997, JPEN-PARENTER ENTER, V21, P72, DOI 10.1177/014860719702100272
   GAUDERER MWL, 1980, J PEDIATR SURG, V15, P872, DOI 10.1016/S0022-3468(80)80296-X
   Grant MD, 1998, JAMA-J AM MED ASSOC, V279, P1973, DOI 10.1001/jama.279.24.1973
   Grossi E, 2007, DIGEST LIVER DIS, V39, P278, DOI 10.1016/j.dld.2006.10.003
   Grossi E, 2007, EUR J GASTROEN HEPAT, V19, P1046, DOI 10.1097/MEG.0b013e3282f198a0
   Haydon GH, 1998, EUR J GASTROEN HEPAT, V10, P485, DOI 10.1097/00042737-199806000-00009
   HULL MA, 1993, LANCET, V341, P869, DOI 10.1016/0140-6736(93)93072-9
   KAW M, 1994, DIGEST DIS SCI, V39, P738, DOI 10.1007/BF02087416
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Lee TH, 2007, J FORMOS MED ASSOC, V106, P685, DOI 10.1016/S0929-6646(08)60029-7
   LIGHT VL, 1995, GASTROINTEST ENDOSC, V42, P330, DOI 10.1016/S0016-5107(95)70132-X
   Lim CW, 2002, BIOL PHARM BULL, V25, P361, DOI 10.1248/bpb.25.361
   Maiellaro PA, 2004, CURR PHARM DESIGN, V10, P2101, DOI 10.2174/1381612043384240
   Mitchell SL, 2000, J GERONTOL A-BIOL, V55, pM735, DOI 10.1093/gerona/55.12.M735
   Naik AD, 2005, ALIMENT PHARM THERAP, V21, P1155, DOI 10.1111/j.1365-2036.2005.02464.x
   Nicholson FB, 2000, J GASTROEN HEPATOL, V15, P21, DOI 10.1046/j.1440-1746.2000.02004.x
   Norton B, 1996, BRIT MED J, V312, P13, DOI 10.1136/bmj.312.7022.13
   Pace F, 2007, EUR J GASTROEN HEPAT, V19, P1043, DOI 10.1097/MEG.0b013e3282f198e5
   PANOS MZ, 1994, GUT, V35, P1551, DOI 10.1136/gut.35.11.1551
   Rabeneck L, 1997, LANCET, V349, P496, DOI 10.1016/S0140-6736(96)07369-2
   Rabeneck L, 1996, J GEN INTERN MED, V11, P287, DOI 10.1007/BF02598270
   Sanders DS, 2002, AM J GASTROENTEROL, V97, P2239
   Sanders DS, 2000, AM J GASTROENTEROL, V95, P1472, DOI 10.1111/j.1572-0241.2000.02079.x
   Takayama K, 2000, J CONTROL RELEASE, V68, P175, DOI 10.1016/S0168-3659(00)00248-0
   Takayama K, 2003, ADV DRUG DELIVER REV, V55, P1217, DOI 10.1016/S0169-409X(03)00120-0
   Wu PC, 2001, J PHARM SCI-US, V90, P1004, DOI 10.1002/jps.1053
NR 34
TC 8
Z9 8
U1 0
U2 3
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0954-691X
EI 1473-5687
J9 EUR J GASTROEN HEPAT
JI Eur. J. Gastroenterol. Hepatol.
PD NOV
PY 2009
VL 21
IS 11
BP 1279
EP 1285
DI 10.1097/MEG.0b013e32832a4eae
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 513CX
UT WOS:000271301100008
PM 19478677
DA 2023-04-20
ER

PT J
AU Li, BP
   Meng, MQH
AF Li, Baopu
   Meng, Max Q. -H.
TI Texture analysis for ulcer detection in capsule endoscopy images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Capsule endoscopy image; Texture features; Curvelet transform; Local
   binary pattern; Neural network; Support vector machines
ID CLASSIFICATION; REPRESENTATION; GRAY
AB Capsule endoscopy (CE) has gradually seen its wide application in hospitals in the last few years because it can view the entire small bowel without invasiveness. However, CE produces too many images each time, thus causing a huge burden to physicians, so it is meaningful to help clinicians if we can employ computerized methods to diagnose. This paper presents a new texture extraction scheme for ulcer region discrimination in CE images. A new idea of curvelet based local binary pattern is proposed as textural features to distinguish ulcer regions from normal regions, which makes full use of curvelet transformation and local binary pattern. The proposed new textural features can capture multi-directional features and show robustness to illumination changes. Extensive classification experiments using multilayer perceptron neural network and support vector machines on our image data validate that it is promising to employ the proposed texture features to recognize ulcer regions in CE images. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Li, Baopu; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Li, BP (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM greenfigo2008@gmail.com
RI meng, meng/GWZ-7461-2022; Meng, Q./GSI-6185-2022; Meng, Max
   Q.-H./C-8078-2009
FU Hong Kong government [CUHK4213/04E]
FX The authors show sincere thanks to the unknown reviewers for their
   valuable comments which lead to a significant improvement of the paper.
   This project is supported by RGC Competitive Earmarked Research Grant
   #CUHK4213/04E of the Hong Kong government, awarded to Max Meng, and the
   authors should also thank James Lau and Yawen Chan, two experts in
   Prince of Wales Hospital in Hong Kong, for providing and collecting CE
   image data.
CR Adler DG., 2003, HOSP PHYS, V39, P14
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   Boulougoura M, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P405
   Candes E. J., 2006, ACTA NUMER, P1
   CANDES EJ, THESIS STANFORD U
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Daubechies I, 1992, 10 LECT WAVELETS
   FOURATI W, 2005, J TEST EVAL, V33, P181
   FRANCI RD, 2004, P 3 INT C CAPS END M
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Haykin S., 1996, NEURAL NETWORKS COMP
   *HONG KONG CANC RE, 2003, HIGHL CANC STAT
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   LAKOVIDIS DK, 2005, P 18 IEEE S COMP BAS
   Liao S, 2007, INT CONF ACOUST SPEE, P1221
   MINH ND, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI DOI 10.1109/TIP.2002.806252
   MULCAHY C, 1997, SPELMAN SCI MATH J, V1, P22
   OH JH, 2006, P SPIE MED IMAGING, V6144, P577
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140
   Starck JL, 2003, ASTRON ASTROPHYS, V398, P785, DOI 10.1051/0004-6361:20021571
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   TUCEYAN M, HDB PATTERN RECOGNIT, P207
   WU CM, 1992, IEEE T MED IMAGING, V11, P141, DOI 10.1109/42.141636
   Yoshida H, 2003, PHYS MED BIOL, V48, P3735, DOI 10.1088/0031-9155/48/22/008
NR 31
TC 98
Z9 101
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1336
EP 1342
DI 10.1016/j.imavis.2008.12.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200010
DA 2023-04-20
ER

PT J
AU Luo, SH
   Yan, YL
AF Luo, Shouhua
   Yan, Yuling
TI Implementation of a virtual laryngoscope system using efficient
   reconstruction algorithms
SO MEDICAL SCIENCE MONITOR
LA English
DT Article
DE virtual laryngoscope; CT; segmentation; surface rendering; octree; fly
   through
ID HELICAL CT; SEGMENTATION
AB Background: Conventional fiberoptic laryngoscope may cause discomfort to the patient and in some cases it call lead to side effects that include perforation, infection and hemorrhage. Virtual laryngoscopy (VL) call overcome this problem and further it may lower the risk of operation failures. Very few virtual endoscope (VE) based investigations of the larynx have been described in the literature.
   Material/Methods: CT data sets from a healthy subject were used for the VL studies. An algorithm of preprocessing and region-growing for 3-D image segmentation is developed. An octree based approach is applied in our VL system which facilitates a rapid constructing of iso-surfaces. Some locating techniques are used for fast rendering and navigation (fly-through).
   Results: Our VL visualization system provides for real time and efficient 'fly-through' navigation. The virtual camera call be arranged so that it moves along the airway in either direction. Snap shots were taken during fly-throughs. The system can automatically adjust the direction of the virtual camera and prevent collisions of the camera and the wall of the airway.
   Conclusions: A virtual laryngoscope (VL) system using OpenGL (Open Graphics Library) platform for inter-active rendering and 3D visualization of the laryngeal framework and upper airway is established. OpenGL is supported on major operating systems and works with every major windowing system. The VL system runs on regular PC workstations and was successfully tested and evaluated using CT data from a normal subject.
C1 [Yan, Yuling] Stanford Univ, Sch Med, Dept Otolaryngol, Stanford, CA 94305 USA.
   [Luo, Shouhua] Southeast Univ, Sch Biol Sci & Med Engn, Nanjing, Jiangsu, Peoples R China.
   [Yan, Yuling] Santa Clara Univ, Sch Engn, Santa Clara, CA 95053 USA.
C3 Stanford University; Southeast University - China; Santa Clara
   University
RP Yan, YL (通讯作者)，Stanford Univ, Sch Med, Dept Otolaryngol, 801 Welch Rd, Stanford, CA 94305 USA.
EM yyan1@scu.edu
CR Aschoff AJ, 1998, RADIOLOGE, V38, P810, DOI 10.1007/s001170050428
   CHEN D, 2001, IEEE T NUCL SCI, V48
   CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L
   Fried MP, 1999, ANN OTO RHINOL LARYN, V108, P221
   Gonzales R.C., 2001, DIGITAL IMAGE PROCES
   Lorensen WE, 1987, ACM SIGGRAPH COMPUTE, P163, DOI DOI 10.1145/37402.37422
   Rodenwaldt J, 1996, ROFO-FORTSCHR RONTG, V165, P80, DOI 10.1055/s-2007-1015718
   RUBIN G, 1996, RADIOLOGY, V99, P321
   SHEKHAR R, 1996, P IEEE VIS 96, P335
   VELASCO F, 2001, VISION MODELLING VIS
   Walshe P, 2002, CLIN OTOLARYNGOL, V27, P98, DOI 10.1046/j.1365-2273.2002.00539.x
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   WILHELMS J, 1992, ACM T GRAPHIC, V11, P201, DOI 10.1145/130881.130882
   Yan YL, 2007, LARYNGOSCOPE, V117, P1026, DOI 10.1097/MLG.0b013e31804f812f
NR 14
TC 0
Z9 1
U1 0
U2 1
PU INT SCIENTIFIC INFORMATION, INC
PI MELVILLE
PA 150 BROADHOLLOW RD, STE 114, MELVILLE, NY 11747 USA
SN 1643-3750
J9 MED SCI MONITOR
JI Med. Sci. Monitor
PD AUG
PY 2009
VL 15
IS 8
BP MT95
EP MT100
PG 6
WC Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine
GA 494XR
UT WOS:000269853500021
PM 19644429
DA 2023-04-20
ER

PT J
AU Vecsei, A
   Fuhrmann, T
   Liedlgruber, M
   Brunauer, L
   Payer, H
   Uhl, A
AF Vecsei, Andreas
   Fuhrmann, Thomas
   Liedlgruber, Michael
   Brunauer, Leonhard
   Payer, Hannes
   Uhl, Andreas
TI Automated classification of duodenal imagery in celiac disease using
   evolved Fourier feature vectors
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article; Proceedings Paper
CT Conference on Advances in Computer Based Medical Systems
CY 2007
CL Maribor, SLOVENIA
SP IEEE Tech Comm Computat Med
DE Bayes classifier; Endoscopy
ID INTEROBSERVER AGREEMENT; ENDOSCOPIC APPROACH; ACCURACY; GLUTEN; BIOPSY
AB Feature extraction techniques based on selection of highly discriminant Fourier filters have been developed for an automated classification of magnifying endoscope images with respect to pit patterns of colon lesions. These are applied to duodenal imagery for diagnosis of celiac disease. Features are extracted from the Fourier domain by selecting the most discriminant features using an evolutionary algorithm. Subsequent classification is performed with various standard algorithms (KNN, SVM, Bayes classifier) and combination of several Fourier filters and classifiers which is called multiclassifier. The obtained results are promising, due to a high specificity for the detection of mucosal damage typical of untreated celiac disease. (C) 2009 Elsevier Ireland Ltd. All rights reserved.
C1 [Fuhrmann, Thomas; Liedlgruber, Michael; Brunauer, Leonhard; Payer, Hannes; Uhl, Andreas] Salzburg Univ, Dept Comp Sci, A-5020 Salzburg, Austria.
   [Vecsei, Andreas] St Anna Childrens Hosp, A-1090 Vienna, Austria.
C3 Salzburg University; Saint Anna Children's Hospital
RP Uhl, A (通讯作者)，Salzburg Univ, Dept Comp Sci, Jakob Haringer Str 2, A-5020 Salzburg, Austria.
EM uhl@cosy.sbg.ac.at
OI Liedlgruber, Michael/0000-0001-8035-6426
CR Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cammarota G, 2007, ENDOSCOPY, V39, P46, DOI 10.1055/s-2006-945044
   Cammarota G, 2006, ALIMENT PHARM THER, V23, P61, DOI 10.1111/j.1365-2036.2006.02732.x
   Cammarota G, 2004, GASTROINTEST ENDOSC, V60, P732, DOI 10.1016/S0016-5107(04)02170-4
   Chand N, 2006, J CLIN GASTROENTEROL, V40, P3, DOI 10.1097/01.mcg.0000190644.01661.2b
   Duda R. O., 1973, PATTERN CLASSIFICATI
   Fukunaga K, 1990, INTRO STAT PATTERN R
   Gonzales RC., 2002, DIGITAL IMAGE PROCES
   HAFNER M, 2007, 20 IEEE INT S COMP B
   HAFNER M, 2007, IEEE WORKSH MACH LEA, P99
   MARSH MN, 1992, GASTROENTEROLOGY, V102, P330, DOI 10.1016/0016-5085(92)91819-P
   MAYER HA, EVOLUTIONARY ALGORIT
   Niveloni S, 1998, GASTROINTEST ENDOSC, V47, P223, DOI 10.1016/S0016-5107(98)70317-7
   Petroniene R, 2005, AM J GASTROENTEROL, V100, P685, DOI 10.1111/j.1572-0241.2005.41069.x
   Zuiderveld K., 1994, GRAPHICS GEMS
NR 15
TC 24
Z9 24
U1 0
U2 6
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD AUG
PY 2009
VL 95
IS 2
SU 1
BP S68
EP S78
DI 10.1016/j.cmpb.2009.02.017
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Medical Informatics
GA 491TI
UT WOS:000269602100008
PM 19356823
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Hafner, M
   Kwitt, R
   Uhl, A
   Wrba, F
   Gangl, A
   Vecsei, A
AF Haefner, Michael
   Kwitt, Roland
   Uhl, Andreas
   Wrba, Friedrich
   Gangl, Alfred
   Vecsei, Andreas
TI Computer-assisted pit-pattern classification in different wavelet
   domains for supporting dignity assessment of colonic polyps
SO PATTERN RECOGNITION
LA English
DT Article
DE Computer-assisted pit-pattern classification; Wavelet transformation;
   Colorectal cancer; Color-texture analysis
ID MAGNIFICATION CHROMOENDOSCOPY; MAGNIFYING COLONOSCOPY; COLORECTAL
   LESIONS; DIAGNOSIS; TRANSFORM; FEATURES; FLAT
AB In this paper, we show that zoom-endoscopy images can be well classified according to the pit-pattern classification scheme by using texture-analysis methods in different wavelet domains. We base our approach on three different variants of the wavelet transform and propose that the color channels of the RGB and LAB color model are an important source for computing image features with high discriminative power. Color-channel information is incorporated by either using simple feature vector concatenation and cross-cooccurrence matrices in the wavelet domain. Our experimental results based on k-nearest neighbor classification and forward feature selection exemplify the advantages of the different wavelet transforms and show that color-image analysis is superior to grayscale-image analysis regarding our medical image classification problem. (C) 2008 Elsevier Ltd. All rights reserved.
C1 [Kwitt, Roland; Uhl, Andreas] Salzburg Univ, Dept Comp Sci, A-5020 Salzburg, Austria.
   [Haefner, Michael; Gangl, Alfred] Vienna Med Univ, Dept Gastroenterol & Hepatol, A-1090 Vienna, Austria.
   [Wrba, Friedrich] Vienna Med Univ, Dept Clin Pathol, A-1090 Vienna, Austria.
   [Vecsei, Andreas] St Anna Childrens Hosp, A-1090 Vienna, Austria.
C3 Salzburg University; Medical University of Vienna; Medical University of
   Vienna; Saint Anna Children's Hospital
RP Kwitt, R (通讯作者)，Salzburg Univ, Dept Comp Sci, Jakob Huringer Str 2, A-5020 Salzburg, Austria.
EM rkwitt@gmx.at; uhl@cosy.sbg.ac.at
RI Kwitt, Roland/AFS-8639-2022; Kwitt, Roland/HII-6060-2022
FU Austrian Science Fund (FWF) [L366-N15]
FX This work is funded by the Austrian Science Fund (FWF) under Project no.
   L366-N15. We would like to thank the referees for some very helpful
   comments on the original version of the manuscript.
CR Bishop Christopher M., 1995, NEURAL NETWORKS PATT, DOI DOI 10.5555/235248
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   EVERITT BS, 1992, MONOGRAPHS STAT APPL, V45
   FLIEGE NJ, 1994, MULTIRATE DIGITAL SI
   Fu KI, 2004, ENDOSCOPY, V36, P1089, DOI 10.1055/s-2004-826039
   Fukunaga K, 1990, INTRO STAT PATTERN R
   Gonzales RC., 2002, DIGITAL IMAGE PROCES
   Hafner M, 2007, COMP MED SY, P159, DOI 10.1109/CBMS.2007.85
   Hafner M, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, P58
   HAFNER M, 2007, P 2007 IEEE MACH LEA, P99
   HAFNER M, 2006, P 3 INT C ADV MED SI
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hatipoglu S, 1999, IEE CONF PUBL, P344, DOI 10.1049/cp:19990340
   Hurlstone DP, 2004, GUT, V53, P284, DOI 10.1136/gut.2003.027623
   Hurlstone DP, 2002, AM J GASTROENTEROL, V97, P1069
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kato S, 2001, ENDOSCOPY, V33, P306, DOI 10.1055/s-2001-13700
   Kato S, 2006, WORLD J GASTROENTERO, V12, P1416, DOI 10.3748/wjg.v12.i9.1416
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kingsbury N. G., 1998, P 8 IEEE DSP WORKSH, P9
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   KWITT R, 2007, P IEEE COMP SOC WORK
   KWITT R, 2008, ADV SOFT COMPUTING, V45
   Lukac R, 2007, IMAGE PROCESS SER, P1
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Meining A, 2004, ENDOSCOPY, V36, P160, DOI 10.1055/s-2004-814183
   Nason Guy P., 1995, WAVELETS STAT, P281, DOI 10.1007/978-1-4612-2544-7_17
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   SAITO N, 1994, P SOC PHOTO-OPT INS, V2303, P2, DOI 10.1117/12.188763
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Selesnick IW, 2001, IEEE SIGNAL PROC LET, V8, P170, DOI 10.1109/97.923042
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   ZAMOLOTSKIKH A, 2006, P 2006 ACM S APPL CO, P582
NR 35
TC 26
Z9 26
U1 0
U2 3
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD JUN
PY 2009
VL 42
IS 6
BP 1180
EP 1191
DI 10.1016/j.patcog.2008.07.012
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 417CB
UT WOS:000264051600018
OA Green Submitted
DA 2023-04-20
ER

PT J
AU Liu, JG
   Yuan, XH
AF Liu, Jianguo
   Yuan, Xiaohui
TI Obscure bleeding detection in endoscopy images using support vector
   machines
SO OPTIMIZATION AND ENGINEERING
LA English
DT Article
DE Image classification; Support vector machine; Feature selection
AB Wireless capsule endoscopy (WCE) is a recently established imaging technology that requires no wired device intrusion and can be used to examine the entire small intestine non-invasively. Determining bleeding signs out of over 55,000 WCE images is a tedious and expensive job by human reviewing. Our goal is to develop an automatic obscure bleeding detection method by employing image color features and support vector machine (SVM) classifier. The bleeding lesion detection problem is a binary classification problem. We use SVMs for this problem and a new feature selection procedure is proposed. Our experiments show that SVM can be very efficient in processing unseen instances and may yield very high accuracy rate, in particular with our new proposed feature selection. More specifically, for this bleeding detection problem, training an SVM with 640 samples can be completed in as little as 0.01 second on a Dell workstation with dual Xeon CPUs, and classifying an image using the trained SVM can be done in as little as 0.03 milliseconds. The accuracy for both sensitivity and specificity can be over 99%.
C1 [Liu, Jianguo] Univ N Texas, Dept Math, Denton, TX 76203 USA.
   [Yuan, Xiaohui] Univ N Texas, Dept Comp Sci & Engn, Denton, TX 76203 USA.
C3 University of North Texas System; University of North Texas Denton;
   University of North Texas System; University of North Texas Denton
RP Liu, JG (通讯作者)，Univ N Texas, Dept Math, Denton, TX 76203 USA.
EM jgliu@unt.edu; xyuan@unt.edu
RI Yuan, Xiaohui/AAQ-1172-2020
OI Yuan, Xiaohui/0000-0001-6897-4563
CR Adler DG., 2003, HOSP PHYS, V39, P14
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P148, DOI 10.1145/288627.288651
   Fireman Z, 2002, ISR MED ASSOC J, V4, P717
   Majewski P, 2005, LECT NOTES ARTIF INT, V3533, P400
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Vapnik V. N., 1998, STAT LEARNING THEORY, V1
NR 11
TC 29
Z9 32
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1389-4420
EI 1573-2924
J9 OPTIM ENG
JI Optim. Eng.
PD JUN
PY 2009
VL 10
IS 2
BP 289
EP 299
DI 10.1007/s11081-008-9066-y
PG 11
WC Engineering, Multidisciplinary; Operations Research & Management
   Science; Mathematics, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Operations Research & Management Science; Mathematics
GA 451UZ
UT WOS:000266497700010
DA 2023-04-20
ER

PT J
AU Li, BP
   Meng, MQH
AF Li, Baopu
   Meng, Max Q-H.
TI Computer-Aided Detection of Bleeding Regions for Capsule Endoscopy
   Images
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Bleeding; capsule endoscopy image; chrominance moment; local binary
   pattern (LBP); multilayer perceptron neural network
ID CLASSIFICATION; COLOR; INVARIANTS; SCHEME; TISSUE; SKIN
AB Capsule endoscopy (CE) has been widely used to diagnose diseases in human digestive tract. However, a tough problem of this new technology is that too many images to be inspected by eyes cause a huge burden to physicians, so it is significant to investigate computerized diagnosis methods. In this paper, a new computer-aided system aimed for bleeding region detection in CE images is proposed. This new system exploits color texture feature, an important clue used by physicians, to analyze status of gastrointestinal tract. We put forward a new idea of chrominance moment as the color part of color texture feature, which makes full use of Tchebichef polynomials and illumination invariant of hue/saturation/intensity color space. Combined with uniform local binary pattern, a current texture representation model, it can be applied to discriminate normal regions and bleeding regions in CE images. Classification of bleeding regions using multilayer perceptron neural network is then deployed to verify performance of the proposed color texture features. Experimental results on our bleeding image data show that the proposed scheme is promising in detecting bleeding regions.
C1 [Li, Baopu; Meng, Max Q-H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Li, BP (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM bpli@ee.cuhk.edu.hk; max@ee.cuhk.edu.hk
RI meng, meng/GWZ-7461-2022; Meng, Q./GSI-6185-2022; Meng, Max
   Q.-H./C-8078-2009
FU Research Grants Council (RGC) Competitive Earmarked Research
   [CUHK4213/04E]; SHIAE of the Shun Hing Institute of Advanced Engineering
   of The Chinese University of Hong Kong [BME 12/08]
FX The work of M. Q.-H. Meng was supported by the Research Grants Council
   (RGC) Competitive Earmarked Research under Grant CUHK4213/04E of the
   Hong Kong Government, and SHIAE project #BME 12/08 of the Shun Hing
   Institute of Advanced Engineering of The Chinese University of Hong
   Kong.
CR Adeler D. G., 2003, P HOSP PHYS MAY, P14
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   Boulougoura M, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P405
   Bourbakis N, 2005, BIBE 2005: 5th IEEE Symposium on Bioinformatics and Bioengineering, P324
   CHAPPELOW JC, 2008, SPIE MED IMAG, V6915
   Chen JQ, 2005, IEEE T IMAGE PROCESS, V14, P1524, DOI 10.1109/TIP.2005.852204
   CHEN Y, P COMP GRAPH IM VIS, P137
   Chong CW, 2003, PATTERN RECOGN, V36, P1765, DOI 10.1016/S0031-3203(02)00353-9
   Christoyianni I, 2004, LECT NOTES COMPUT SC, V3025, P267
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Drukker K, 2005, RADIOLOGY, V237, P834, DOI 10.1148/radiol.2373041418
   Flusser J, 2006, PROC WRLD ACAD SCI E, V11, P196
   Francis R., 2004, 3 INT C CAPS END MIA
   Fu B, 2007, PATTERN RECOGN, V40, P691, DOI 10.1016/j.patcog.2006.05.020
   GEVERS T, 2001, COLOR IMAGE PROCESSI, pCH1
   Haykin S., 1996, NEURAL NETWORKS COMP
   *HONG KONG CANC RE, 2003, HIGHL CANC STAT
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   ILDERBRAND F, 1956, INTRO NUMERICAL ANAL
   Jain A, 1998, IEEE T IMAGE PROCESS, V7, P124, DOI 10.1109/83.650858
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   LIAPOUNOFF A, 1904, ANN TOULOUSE, V6, P5
   Machin P.S., 1994, CANC LETT, V77, P215
   MACKIEWICZ M, 2006, P IEEE INT C AC SPEE, V2, P597
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 1998, MOMENT FUNCTIONS IMA, DOI DOI 10.1142/3838
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Papathomas TV, 1997, IEEE T SYST MAN CY B, V27, P428, DOI 10.1109/3477.584950
   Stanley RJ, 2003, COMPUT MED IMAG GRAP, V27, P387, DOI 10.1016/S0895-6111(03)00030-2
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Tourassi GD, 2003, MED PHYS, V30, P2123, DOI 10.1118/1.1589494
   Tsumura N, 2003, ACM T GRAPHIC, V22, P770, DOI 10.1145/882262.882344
   Vilarino F, 2006, INT C PATT RECOG, P719
   Wang LZ, 1998, IEEE T IMAGE PROCESS, V7, P196, DOI 10.1109/83.660996
   WEISS GM, 2001, MLTR43 RUDG U DEP CO
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhao G, 2006, INT C PATT RECOG, P211
NR 41
TC 143
Z9 148
U1 0
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD APR
PY 2009
VL 56
IS 4
BP 1032
EP 1039
DI 10.1109/TBME.2008.2010526
PG 8
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 443UV
UT WOS:000265937200013
PM 19174349
DA 2023-04-20
ER

PT J
AU Szczypinski, PM
   Sriram, RD
   Sriram, PVJ
   Reddy, DN
AF Szczypinski, Piotr M.
   Sriram, Ram D.
   Sriram, Parupudi V. J.
   Reddy, D. Nageshwar
TI A model of deformable rings for interpretation of wireless capsule
   endoscopic videos
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Model of deformable rings; Deformable models; Video analysis; Wireless
   capsule endoscope; Gastrointestinal system
ID FEATURE-EXTRACTION; REGISTRATION; EXPERIENCE; TRACKING; 2-D
AB Wireless Capsule Endoscopy (WCE) provides a means to obtain a detailed video of the small intestine. A single session with WCE may produce nearly 8 h of video. Its interpretation is tedious task, which requires considerable expertise and is very stressful. The Model of Deformable Rings (MDR) was developed to preprocess WCE video and aid clinicians with its interpretation. The MDR uses a simplified model of a capsule's motion to flexibly match (register) consecutive video frames. Essentially, it computes motion-descriptive characteristics and produces a two-dimensional representation of the gastrointestinal (GI) tract's internal surface - a map. The motion-descriptive characteristics are used to indicate video fragments which exhibit segmentary contractions, peristalsis, refraction phases and areas of capsule retention. Within maps, certain characteristics that indicate areas of bleeding, ulceration and obscuring froth could be recognized. Therefore, the maps allow quick identification of such abnormal areas. The experimental results demonstrate that the number of discovered pathologies and gastrointestinal landmarks increases with the MDR technique. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Szczypinski, Piotr M.] Tech Univ Lodz, Inst Elect, PL-90924 Lodz, Poland.
   [Sriram, Ram D.] Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA.
   [Sriram, Parupudi V. J.] Texas Tech Univ, Hlth Sci Ctr, Dept Internal Med Gastroenterol, Lubbock, TX 79430 USA.
   [Reddy, D. Nageshwar] Asian Inst Gastroenterol, Hyderabad, Andhra Pradesh, India.
C3 Lodz University of Technology; National Institute of Standards &
   Technology (NIST) - USA; Texas Tech University System; Texas Tech
   University; Texas Tech University Health Science Center
RP Szczypinski, PM (通讯作者)，Tech Univ Lodz, Inst Elect, Wolczanska 211-215, PL-90924 Lodz, Poland.
EM pms@p.lodz.pl; sriram@nist.gov
RI Szczypiński, Piotr M/R-1964-2017
OI Szczypiński, Piotr M/0000-0002-9956-0862
FU US Department of Commerce's National Institute of Standards and
   Technology
FX Authors would like to thank Dr. Rajesh Gupta from the Asian Institute of
   Gastroenterology, Hyderabad, India for his help in assessment of the MDR
   technique.; This work was supported by the US Department of Commerce's
   National Institute of Standards and Technology. Any mention of
   organizations, agencies, vendors or commercial products in this document
   is for illustration only. It does not imply sponsorship, contract,
   recommendation or endorsement by NIST.
CR ADLER DG, 2003, HOSP PHYS, V5, P16
   CHRISTENSEN J, 1983, GUIDE GASTROINTESTIN
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   COIMBRA M, 2006, P SAMT 2006 ATH GREE, P17
   Coimbra M., 2006, P IEEE INT C AC SPEE, V2, P1164
   COIMBRA M, 2005, EWIMT 2005, P105
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   DELINGETTE H, 1994, IEEE WORKSH MOT NONR, P152
   Duda R.O., 1973, PATTERN CLASSIFICATI
   FUKUNAGA K, 1991, INTRO STAT PATTERN R
   Gerson Lauren B, 2004, Tech Vasc Interv Radiol, V7, P130, DOI 10.1053/j.tvir.2004.12.004
   Gonzalez R C, 1992, DIGITAL IMAGE PROCES
   Helferty JP, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P961
   Hu C., 2005, INT J INF ACQUIS, V02, P23, DOI DOI 10.1142/S0219878905000398
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kwon J, 2005, IEEE INT CONF ROBOT, P1303
   MACKIEWICZ M, 2006, P IEEE INT C AC SPEE, V2, P597
   MACKIEWICZ M, 2006, P MED IM UND AN C MA
   MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296, DOI 10.1109/72.363467
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Mori K, 2002, MED IMAGE ANAL, V6, P321, DOI 10.1016/S1361-8415(02)00089-0
   Mori K., 2001, P 4 INT C UTR NETH O, P14
   MORI K, 2006, P 9 INT C COP DENM O, V2, P645
   NAGAO J, 2004, P 7 INT C SAINT MEL, V2, P551
   NAGOKA T, 2005, P 3 ANN INT IEEE EMB, P130
   NEUENSCHWANDER W, 1995, ZIPLOCK SNAKES VELCR
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Scapa E, 2002, AM J GASTROENTEROL, V97, P2776, DOI 10.1111/j.1572-0241.2002.07021.x
   Sriram PVJ, 2004, J GASTROEN HEPATOL, V19, P63, DOI 10.1111/j.1440-1746.2004.03220.x
   Swain P, 2004, GUT, V53, P1866, DOI 10.1136/gut.2003.035576
   Swain P, 2003, GUT, V52, P48
   SZCZYPINSKI P, 1999, TECHNICAL SCI, V47, P263
   SZCZYPINSKI P, 2000, INT C SIGN EL SYST, P169
   SZCZYPINSKI PM, 2004, ENDOSCOPY S1, V36, pA76
   SZCZYPINSKI PM, 2004, VID INT REP COMP VIS, P167
   SZCZYPINSKI PM, 2005, ZESZYTY NAUKOWE ELEK, V10, P129
   SZCZYPINSKI PM, 2006, P INT C SIGN EL SYST, P297
   van Beek P, 1999, IEEE T CIRC SYST VID, V9, P353, DOI 10.1109/76.752101
   VILARINAO F, 2005, PATTERN RECOGN, P875
   Wang XN, 2005, P ANN INT IEEE EMBS, P2942
   Wang Y, 1996, IEEE T CIRC SYST VID, V6, P636
   Yamamoto H, 2005, J GASTROENTEROL, V40, P555, DOI 10.1007/s00535-005-1645-5
   [No title captured]
NR 44
TC 34
Z9 36
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD APR
PY 2009
VL 13
IS 2
BP 312
EP 324
DI 10.1016/j.media.2008.12.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA 433RT
UT WOS:000265224200010
PM 19157954
DA 2023-04-20
ER

PT J
AU Li, BP
   Meng, MQH
AF Li, Baopu
   Meng, Max Q. -H.
TI Computer-based detection of bleeding and ulcer in wireless capsule
   endoscopy images by chromaticity moments
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Wireless capsule endoscopy image; Color features; Tchebichef
   polynomials; Illumination invariant
ID COLOR; SKIN; INVARIANTS
AB The wireless capsule endoscopy (WCE) invented by Given Imaging has been gradually used in hospitals due to its great breakthrough that it can view the entire small bowel for gastrointestinal diseases. However, a tough problem associated with this new technology is that too many images to be examined by eyes cause a huge burden to physicians, so it is significant if we can help physicians do diagnosis using computerized methods. In this paper, a new method aimed for bleeding and ulcer detection in WCE images is proposed. This new approach mainly focuses on color feature, also a very powerful clue used by physicians for diagnosis, to judge the status of gastrointestinal tract. We propose a new idea of chromaticity moment as the features to discriminate normal regions and abnormal regions, which make full use of the Tchebichef polynomials and the illumination invariant of HSI color space, and we verify performances of the proposed features by employing neural network classifier. Experimental results on our present image data of bleeding and ulcer show that it is feasible to exploit the proposed chromaticity moments to detect bleeding and ulcer for WCE images. (C) 2008 Elsevier Ltd. All rights reserved.
C1 [Li, Baopu; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Li, BP (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM bpli@ee.cuhk.edu.hk
RI Meng, Q./GSI-6185-2022; meng, meng/GWZ-7461-2022; Meng, Max
   Q.-H./C-8078-2009
FU RGC Competitive Earmarked Research [CUHK4213/04E]
FX This project is supported by RGC Competitive Earmarked Research Grant
   #CUHK4213/04E of the Hong Kong government, awarded to Max Meng. The
   authors should also thank James Lau and Yawen Chan, two experts in
   Prince of Wales Hospital in Hong Kong, for providing and collecting the
   capsule endoscopy image data.
CR Adler DG., 2003, HOSP PHYS, V39, P14
   Arnott IDR, 2004, DIGEST DIS SCI, V49, P893, DOI 10.1023/B:DDAS.0000034545.58486.e6
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   Boulougoura M, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P405
   Chong CW, 2003, PATTERN RECOGN, V36, P1765, DOI 10.1016/S0031-3203(02)00353-9
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   FRANCIS RD, 2004, P 3 INT C CAPS END F
   Fu B, 2007, PATTERN RECOGN, V40, P691, DOI 10.1016/j.patcog.2006.05.020
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Gevers T, 2004, IEEE T PATTERN ANAL, V26, P113, DOI 10.1109/TPAMI.2004.1261083
   GEVERS T, 2006, COLOR FEATURES DETEC, pCH1
   GEVERS T, 2005, IEEE INT C IM PROC, V2, P714
   Haykin S., 1996, NEURAL NETWORKS COMP
   HILDERBRAND F, 1956, INTRO NUMERICAL ANAL
   Hwang S, 2006, P SPIE MED IMAGING, V6144, P577
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   KARKANIS SA, 2000, P 26 EUR C MAASTR NE, V2, P423
   Li CH, 2000, IEEE T MED IMAGING, V19, P1150, DOI 10.1109/42.896791
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 1998, MOMENT FUNCTIONS IMA, DOI DOI 10.1142/3838
   Nischik M, 1997, IEEE T MED IMAGING, V16, P711, DOI 10.1109/42.650868
   Parker SL, 1997, CA-CANCER J CLIN, V47, P5, DOI 10.3322/canjclin.47.1.5
   Schmid P, 1999, IEEE T MED IMAGING, V18, P164, DOI 10.1109/42.759124
   Stanley RJ, 2003, COMPUT MED IMAG GRAP, V27, P387, DOI 10.1016/S0895-6111(03)00030-2
   TEH CH, 1986, COMPUT VISION GRAPH, V33, P318, DOI 10.1016/0734-189X(86)90180-5
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Tsumura N, 2003, ACM T GRAPHIC, V22, P770, DOI 10.1145/882262.882344
   Tu JV, 1998, MED DECIS MAKING, V18, P229
   Van de Weijer J, 2006, IEEE T IMAGE PROCESS, V15, P118, DOI 10.1109/TIP.2005.860343
   Vilarino F, 2006, INT C PATT RECOG, P719
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zaqout I., 2005, Machine Graphics & Vision, V14, P61
NR 34
TC 95
Z9 97
U1 1
U2 19
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD FEB
PY 2009
VL 39
IS 2
BP 141
EP 147
DI 10.1016/j.compbiomed.2008.11.007
PG 7
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 416UF
UT WOS:000264030300005
PM 19147126
DA 2023-04-20
ER

PT J
AU Bonnel, J
   Khademi, A
   Krishnan, S
   Ioana, C
AF Bonnel, Julien
   Khademi, April
   Krishnan, Sridhar
   Ioana, Cornel
TI Small bowel image classification using cross-co-occurrence matrices on
   wavelet domain
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Small bowel images; Shift-invariant discrete wavelet transform; Color
   cross-co-occurrence matrices; Feature extraction; Classification
AB This paper presents a novel system to compute the automated classification of wireless capsule endoscope images. Classification is achieved by a classical statistical approach, but novel features are extracted from the wavelet domain and they contain both color and texture information. First, a shift-invariant discrete wavelet transform (SIDWT) is computed to ensure that the multiresolution feature extraction scheme is robust to shifts. The SIDWT expands the signal (in a shift-invariant way) over the basis functions which maximize information. Then cross-co-occurrence matrices of wavelet subbands are calculated and used to extract both texture and color information. Canonical discriminant analysis is utilized to reduce the feature space and then a simple 1D classifier with the leave one out method is used to automatically classify normal and abnormal small bowel images. A classification rate of 94.7% is achieved with a database of 75 images (41 normal and 34 abnormal cases). The high success rate could be attributed to the robust feature set which combines multiresolutional color and texture features, with shift, scale and semi-rotational invariance. This result is very promising and the method could be used in a computer-aided diagnosis system or a content-based image retrieval scheme. (c) 2008 Elsevier Ltd. All rights reserved.
C1 [Bonnel, Julien; Krishnan, Sridhar] Ryerson Univ, Dept Elect & Comp Engn, Toronto, ON, Canada.
   [Khademi, April] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 1A1, Canada.
C3 Toronto Metropolitan University; University of Toronto
RP Krishnan, S (通讯作者)，Ryerson Univ, Dept Elect & Comp Engn, Toronto, ON, Canada.
EM jbonnel@rnet.ryerson.ca; akhademi@ieee.org; krishnan@ee.ryerson.ca;
   Cornel.Ioana@lis.inpg.fr
RI Ioana, Cornel/C-4944-2019; Krishnan, Sridhar/AAA-2542-2019
OI Ioana, Cornel/0000-0001-6581-3000; Krishnan,
   Sridhar/0000-0002-4659-564X; Khademi, April/0000-0002-4932-0385
CR ABDELMOUNAIME S, 2006, INT J REMOTE SENS, V27, P3977
   Arvis V., 2004, Image Analysis & Stereology, V23, P63, DOI 10.5566/ias.v23.p63-72
   BEYLKIN G, 1992, SIAM J NUMER ANAL, V29, P1716, DOI 10.1137/0729097
   Bourbakis N, 2005, BIBE 2005: 5th IEEE Symposium on Bioinformatics and Bioengineering, P324
   BRADLEY AP, 2003, 7 INT C DIG IM COMP, P29
   Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   FLANDRIN P, 1999, TEMPS FREQUENCE
   *GIV IMAG LTD, 2006, PAT BROCH
   *GIV IMAG LTD, 2006, PILLCAM SB CAPS END
   *GIV IMAG LTD, 2006, PAT INF GUID
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jain A., 2000, IEEE T PATTERN ANAL, V22
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   KHADEMI A, 2006, THESIS RYERSON U, P1
   Kodogiannis VS, 2007, ENG APPL ARTIF INTEL, V20, P539, DOI 10.1016/j.engappai.2006.09.006
   Liang J, 1998, IEEE T IMAGE PROCESS, V7, P762, DOI 10.1109/83.668030
   Liang J, 1996, 1996 IEEE DIGITAL SIGNAL PROCESSING WORKSHOP, PROCEEDINGS, P69, DOI 10.1109/DSPWS.1996.555462
   Mallat S., 2008, WAVELET TOUR SIGNAL
   MUNIZ R, 2006, P IPCV 2006, P114
   PALM C, 2000, BRAUNSCHWEIG J, P49
   Rangayyan R. M., 2005, BIOMED EN S
   SHUTTLEWORTH JK, 2002, P IEEE CCECE CAN C, V2, P1134
   Unser M, 1996, P IEEE, V84, P626, DOI 10.1109/5.488704
NR 24
TC 12
Z9 13
U1 0
U2 2
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD JAN
PY 2009
VL 4
IS 1
BP 7
EP 15
DI 10.1016/j.bspc.2008.07.002
PG 9
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 402ME
UT WOS:000263017000003
DA 2023-04-20
ER

PT J
AU Miaou, SG
   Chang, FL
   Timotius, IK
   Huang, HC
   Su, JL
   Liao, RS
   Lin, TY
AF Miaou, Shaou-Gang
   Chang, Feng-Ling
   Timotius, Ivanna K.
   Huang, Han-Chang
   Su, Jenn-Lung
   Liao, Rung-Sheng
   Lin, Tah-Yeong
TI A Multi-stage Recognition System to Detect Different Types of
   Abnormality in Capsule Endoscope Images
SO JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING
LA English
DT Article
DE Automatic image recognition; Suspected blood indicator; Capsule
   endoscope; Chyme-blockage; Multistage recognition; White spots on small
   intestines
AB The capsule endoscope is a state-of the-art tool to detect abnormal problems of the small intestines, such as chyme blockage, suspected blood indicator (SBI), and white spots (ulcer). However, each examination using a capsule endoscope produces several tens of thousands images, and it it time-consuming for a physician to examine all the images. This paper proposes an automatic recognition system to identify suspected capsule endoscope images to save image viewing time. The system is basically a four-stage classifier. The first stage uses the hue, saturation, and intensity (HSI) color model to find the images with large yellow-green abnormal areas (could be chyme-blocked). For those not selected in the first stage, the second stage uses fuzzy c-means clustering analysis to further recognize the images with large abnormal areas (could be SBI). Most of the images encountered at the third stage have either large normal and uniform areas, or small abnormal areas. Thus, this stage attempts to exclude uniform images which are likely to be normal. finally, the last stage uses a back-propagation neural network to detect the images with small abnormal areas (could be white spots). Experimental results showed that this cascaded classification system could perform much better than its individual stages or some combinations of the stage. The overall recognition accuracy is about 89%, resulting in unavoidable misclassified images. However, the detection sensitivity for abnormal images by the system was as high as 97.7%. Furthermore, since abnormality of the small intestines usually appears in a group of consecutive images, it would be overlooked only when every abnormal image in the group was misclassified. Thus, as an abnormality screening tool for physicians, the proposed system is valuable.
C1 [Miaou, Shaou-Gang; Chang, Feng-Ling; Timotius, Ivanna K.; Huang, Han-Chang] Chung Yuan Christian Univ, Dept Elect Engn, Chungli 320, Taiwan.
   [Su, Jenn-Lung; Liao, Rung-Sheng] Chung Yuan Christian Univ, Dept Biomed Engn, Chungli 320, Taiwan.
   [Lin, Tah-Yeong] Chung Shan Inst Sci & Technol, Informat & Commun Res Div, Tao Yuan 325, Taiwan.
C3 Chung Yuan Christian University; Chung Yuan Christian University;
   Chung-Shan Institute of Science & Technology
RP Miaou, SG (通讯作者)，Chung Yuan Christian Univ, Dept Elect Engn, Chungli 320, Taiwan.
EM miaou@wavelet.el.cycu.edu.tw
RI Timotius, Ivanna Kristianti/HPH-6079-2023
OI Timotius, Ivanna Kristianti/0000-0002-3923-9073
CR [Anonymous], PATTERN RECOGN LETT
   Appleyard M, 2000, GASTROENTEROLOGY, V119, P1431, DOI 10.1053/gast.2000.20844
   Duda R. O., 2001, PATTERN CLASSIFICATI, V2nd
   Gong F, 2000, GASTROINTEST ENDOSC, V51, P725, DOI 10.1067/mge.2000.105724
   Gonzales R.C., 2008, DIGITAL IMAGE PROCES, V3rd
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   MEYER GW, 1988, COMPUT VISION GRAPH, V41, P57, DOI 10.1016/0734-189X(88)90117-X
   Nebeker F, 2002, IEEE ENG MED BIOL, V21, P17, DOI 10.1109/MEMB.2002.1016851
   Ripley B.D., 1993, STAT ASPECTS NEURAL
   SIEGEL S., 1988, NONPARAMETRIC STAT B
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 14
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1609-0985
EI 2199-4757
J9 J MED BIOL ENG
JI J. Med. Biol. Eng.
PY 2009
VL 29
IS 3
BP 114
EP 121
PG 8
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 526BY
UT WOS:000272263700002
DA 2023-04-20
ER

PT J
AU Vu, H
   Echigo, T
   Sagawaa, R
   Yagi, K
   Shiba, M
   Higuchi, K
   Arakawa, T
   Yagi, Y
AF Vu, Hai
   Echigo, Tomio
   Sagawaa, Ryusuke
   Yagi, Keiko
   Shiba, Masatsugu
   Higuchi, Kazuhide
   Arakawa, Tetsuo
   Yagi, Yasushi
TI Detection of contractions in adaptive transit time of the small bowel
   from wireless capsule endoscopy videos
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Gastrointestinal motility; Intestinal contraction detection; Wireless
   capsule endoscopic images
ID FEATURE-EXTRACTION
AB Recognizing intestinal contractions from wireless capsule endoscopy (WCE) image sequences provides a non-invasive method of measurement, and suggests a solution to the problems of traditional techniques for assessing intestinal motility. Based on the characteristics of contractile patterns and information on their frequencies, the contractions can be investigated using essential image features extracted from WCE videos. In this study, we proposed a coherent three-stage procedure using temporal and spatial features. The possible contractions are recognized by changes in the edge structure of the intestinal folds in Stage I and evaluating similarity features in consecutive frames in Stage 2. In order to take account of the properties of contraction frequency. we consider that the possible contractions are located within windows including consecutive frames. The size of these contraction windows is adjusted according to the passage of the WCE. These procedures aim to exclude as many non-contractions as possible. True contractions are determined through spatial analysis of directional information in Stage 3. Using the proposed method, 81% of true contractions are detected with a 37% false alarm rate for evaluations in the experiments. The overall performance of this method is better than that of previous methods, in terms of both the quality and quantity indices. The results suggest feasible data for further clinical applications. (c) 2008 Elsevier Ltd. All rights reserved.
C1 [Vu, Hai; Sagawaa, Ryusuke; Yagi, Yasushi] Osaka Univ, Dept Intelligent Media, Inst Sci & Ind Res, Osaka 5670047, Japan.
   [Echigo, Tomio] Osaka Electrocommun Univ, Dept Informat Engn, Osaka 5728530, Japan.
   [Yagi, Keiko] Kobe Pharmaceut Univ, Kobe, Hyogo 6588558, Japan.
   [Shiba, Masatsugu; Higuchi, Kazuhide; Arakawa, Tetsuo] Osaka City Univ, Grad Sch Med, Osaka 5458585, Japan.
C3 Osaka University; Osaka Electro-Communication University; Kobe
   Pharmaceutical University; Osaka Metropolitan University
RP Vu, H (通讯作者)，Osaka Univ, Dept Intelligent Media, Inst Sci & Ind Res, 8-1 Mihogaoka, Osaka 5670047, Japan.
EM vhai@am.sanken.osaka-u.ac.jp
RI Tomio, Echigo/AAI-6575-2020
OI Vu, Hai/0000-0003-2880-4417
CR Adler DG., 2003, HOSP PHYS, V39, P14
   *AM SOC GASTR END, 2002, GASTROINTEST ENDOSC, V56, P1866
   Bronzino J.D., 2006, BIOMEDICAL ENG HDB, DOI 10.1201/9781420003864.sec3
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   COIMBRA M, 2006, P IEEE INT C AC SPEE, V11, P1164
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   GLUKHOVSKY A, 2001, Patent No. 0187377
   Greenspan H, 2002, LECT NOTES COMPUT SC, V2353, P461
   GRUNDY D, 1985, GASTROINTESTINAL MOT
   HAI V, 2006, P 18 ICPR AUG, V3, P980
   Hansen MB, 2002, PHYSIOL RES, V51, P541
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Imam H, 2004, AM J PHYSIOL-GASTR L, V286, pG263, DOI 10.1152/ajpgi.00228.2003
   MACKIEWICZ M, 2006, P IEEE INT C AC SPEE, V2, P597
   MACKIEWICZ M, 2006, P INT C MED IM UND A
   SPYRIDONOS P, 2005, LECT NOTES COMPUTER, V3708
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Swain P, 2004, GUT, V53, P1866, DOI 10.1136/gut.2003.035576
   Thomas EA, 2004, AM J PHYSIOL-GASTR L, V286, pG564, DOI 10.1152/ajpgi.00369.2003
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P178
   Vilarino F, 2006, PATTERN RECOGN LETT, V27, P875, DOI 10.1016/j.patrec.2005.10.011
   Vu H, 2007, LECT NOTES COMPUT SC, V4791, P775
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   2007, MIXMOD VER 2 0 1
NR 25
TC 17
Z9 20
U1 0
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD JAN
PY 2009
VL 39
IS 1
BP 16
EP 26
DI 10.1016/j.compbiomed.2008.10.005
PG 11
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 407YD
UT WOS:000263399300003
PM 19061993
DA 2023-04-20
ER

PT J
AU Liu, JM
   Yao, JH
   Summers, RM
AF Liu, Jiamin
   Yao, Jianhua
   Summers, Ronald M.
TI Scale-based scatter correction for computer-aided polyp detection in CT
   colonography
SO MEDICAL PHYSICS
LA English
DT Article
DE biological organs; cancer; computerised tomography; image
   classification; image enhancement; image segmentation; medical image
   processing
ID IMAGE; SEGMENTATION; TOMOGRAPHY; POPULATION
AB CT colonography (CTC) is a feasible and minimally invasive method for the detection of colorectal polyps and cancer screening. Computer-aided detection (CAD) of polyps can improve consistency and sensitivity of virtual colonoscopy interpretation and reduce interpretation burden. However, high-density orally administered contrast agents have scatter effects on neighboring tissues. The scattering manifests itself as an artificial elevation in the observed CT attenuation values of the neighboring tissues. This pseudoenhancement phenomenon presents a problem for the application of computer-aided polyp detection, especially when polyps are submerged in the contrast agents. The authors have developed a scale-based correction method that minimizes scatter effects in CTC data by subtraction of the estimated scatter components from observed CT attenuations. By bringing a locally adaptive structure, object scale, into the correction framework, the region of neighboring tissues affected by contrast agents is automatically specified and adaptively changed in different parts of the image. The method was developed as one preprocessing step in the authors' CAD system and was tested by using leave-one-patient-out evaluation on 56 clinical CTC scans (supine or prone) from 28 patients. There were 50 colonoscopy-confirmed polyps measuring 6-9 mm. Visual evaluation indicated that the method reduced CT attenuation of pseudoenhanced polyps to the usual polyp Hounsfield unit range without affecting luminal air regions. For polyps submerged in contrast agents, the sensitivity of CAD with correction is increased 24% at a rate of ten false-positive detections per scan. For all polyps within 6-9 mm, the sensitivity of the authors' CAD with scatter correction is increased 8% at a rate of ten false-positive detections per scan. The authors' results indicated that CAD with this correction method as a preprocessing step can yield a high sensitivity and a relatively low FP rate in CTC.
C1 [Liu, Jiamin; Yao, Jianhua; Summers, Ronald M.] NIH, Dept Radiol, Bethesda, MD 20892 USA.
C3 National Institutes of Health (NIH) - USA
RP Summers, RM (通讯作者)，NIH, Dept Radiol, Bldg 10, Bethesda, MD 20892 USA.
EM rms@nih.gov
RI hu, kemin/H-4755-2011; Yao, Jianhua/GQZ-6627-2022; Summers,
   Ronald/AAX-6290-2021
OI Yao, Jianhua/0000-0001-9157-9596; 
FU Intramural Research Program of the NIH Clinical Center
FX This research was supported by the Intramural Research Program of the
   NIH Clinical Center. The authors thank Dr. Perry Pickhardt, Dr. J.
   Richard Choi, and Dr. William Schindler for providing CT colonography
   data.
CR HANGARTNER TN, 1987, MED PHYS, V14, P335, DOI 10.1118/1.596089
   JOSEPH PM, 1982, MED PHYS, V9, P464, DOI 10.1118/1.595111
   Lei TH, 2001, IEEE T MED IMAGING, V20, P689, DOI 10.1109/42.938238
   Nappi J, 2008, MED IMAGE ANAL, V12, P413, DOI 10.1016/j.media.2008.01.001
   Nyul LG, 2001, PROC SPIE, V4322, P1588, DOI 10.1117/12.431044
   Saha PK, 2001, IEEE T PATTERN ANAL, V23, P689, DOI 10.1109/34.935844
   Saha PK, 2001, IEEE T MED IMAGING, V20, P1140, DOI 10.1109/42.963817
   Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813
   Shidahara M, 2005, EUR J NUCL MED MOL I, V32, P1193, DOI 10.1007/s00259-005-1791-2
   Siewerdsen JH, 2006, MED PHYS, V33, P187, DOI 10.1118/1.2148916
   Summers RM, 2001, RADIOLOGY, V219, P51, DOI 10.1148/radiology.219.1.r01ap0751
   Summers RM, 2002, RADIOLOGY, V225, P391, DOI 10.1148/radiol.2252011619
   Summers RM, 2005, GASTROENTEROLOGY, V129, P1832, DOI 10.1053/j.gastro.2005.08.054
   SUMMERS RM, 2002, COMPUTER ASSISTED RA
   Yao J., 2005, SPIE MED IMAGING
   Yao JH, 2007, MED PHYS, V34, P1655, DOI 10.1118/1.2717411
   ZALIS M, 2006, FUNDAMENTALS VIRTUAL, P47
   Zalis ME, 2005, RADIOLOGY, V236, P118, DOI 10.1148/radiol.2361040231
   ZHUGE Y, 2002, P SPIE MED IM SAN DI, V4684, P1476
NR 19
TC 19
Z9 20
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD DEC
PY 2008
VL 35
IS 12
BP 5664
EP 5671
DI 10.1118/1.3013552
PG 8
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA 376VB
UT WOS:000261210000045
PM 19175123
OA Green Published, Green Accepted
DA 2023-04-20
ER

PT J
AU Saftoiu, A
   Vilmann, P
   Gorunescu, F
   Gheonea, DI
   Gorunescu, M
   Ciurea, T
   Popescu, GL
   Iordache, A
   Hassan, H
   Iordache, S
AF Saftoiu, Adrian
   Vilmann, Peter
   Gorunescu, Florin
   Gheonea, Dan Ionut
   Gorunescu, Marina
   Ciurea, Tudorel
   Popescu, Gabriel Lucian
   Iordache, Alexandru
   Hassan, Hazem
   Iordache, Sevastita
TI Neural network analysis of dynamic sequences of EUS elastography used
   for the differential diagnosis of chronic pancreatitis and pancreatic
   cancer
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID FINE-NEEDLE-ASPIRATION; ENDOSCOPIC ULTRASOUND ELASTOGRAPHY; FOCAL
   PANCREATITIS; VIRTUAL BIOPSY; ULTRASONOGRAPHY; YIELD; DISCRIMINATION;
   CARCINOMA; ACCURACY; DOPPLER
AB Background: EUS elastography is a newly developed imaging procedure that characterizes the differences of hardness and strain between diseased and normal tissue.
   Objective: To assess the accuracy of real-time EUS elastography in pancreatic lesions.
   Design: Cross-sectional feasibility study
   Patients: The study group included, in total, 68 patients with normal pancreas (N = 22), chronic pancreatitis (N = 11), pancreatic adenocarcinoma (N = 32), and pancreatic neuroendocrine tumors (N = 3). A subgroup analysis of 43 cases with focal pancreatic masses was also performed.
   Interventions: A postprocessing software analysis was used to examine the EUS elastography movies by calculating hue histograms of each individual image, data that were further subjected to an extended neural network analysis to differentiate benign from malignant patterns.
   Main Outcome Measurements: To differentiate normal pancreas, chronic pancreatitis, pancreatic cancer, and neroendocrine tumors.
   Results: Based on a cutoff of 175 for the mean hue histogram values recorded on the region of interest, the sensitivity, specificity, and accuracy of differentiation of benign and malignant masses were 91.4%, 87.9%, and 89.7%, respectively The positive and negative predictive values were 88.9% and 90.6%, respectively Multilayer perceptron neural networks with both one and two hidden layers of neurons (3-layer perceptron and 4-layer perceptron) were trained to learn how to classify cases as benign or malignant, and yielded an excellent testing performance of 95% on average, together with a high training performance that equaled 97% on average.
   Limitation: A lack of the surgical standard in all cases.
   Conclusions: EUS elastography is a promising method that allows characterization and differentiation of normal pancreas, chronic pancreatitis, and pancreatic cancer. The Currently developed methodology, based on artificial neural network processing of EUS elastography digitalized movies, enabled an optimal prediction of the types of pancreatic lesions. Future multicentric, randomized studies with adequate power will have to establish the clinical impact of this procedure for the differential diagnosis of focal pancreatic masses. (Gastrointest Endosc 2008;68:1086-94.)
C1 [Saftoiu, Adrian] Univ Med & Pharm Craiova, Res Ctr Gastroenterol & Hepatol, Dept Gastroenterol, Craiova 200490, Dolj, Romania.
   [Gorunescu, Florin; Gorunescu, Marina] Univ Med & Pharm Craiova, Dept Biostat & Comp Sci, Craiova 200490, Dolj, Romania.
   [Popescu, Gabriel Lucian; Iordache, Alexandru] Univ Med & Pharm Craiova, IT Ctr, Craiova 200490, Dolj, Romania.
   [Saftoiu, Adrian; Vilmann, Peter; Hassan, Hazem; Iordache, Sevastita] Gentofte Univ Hosp, Dept Surg Gastroenterol, Hellerup, Denmark.
C3 University of Medicine & Pharmacy of Craiova; University of Medicine &
   Pharmacy of Craiova; University of Medicine & Pharmacy of Craiova;
   University of Copenhagen; Herlev & Gentofte Hospital
RP Saftoiu, A (通讯作者)，Univ Med & Pharm Craiova, Res Ctr Gastroenterol & Hepatol, Dept Gastroenterol, Str Horia 11, Craiova 200490, Dolj, Romania.
RI Gheonea, Dan Ionut/C-3578-2012; Gorunescu, Florin/B-9480-2011; Ciurea,
   Tudorel/C-3647-2012; Saftoiu, Adrian/C-2792-2011; Vilmann,
   Peter/AAP-2730-2021; Vilmann, Peter/AAJ-8401-2020; Gorunescu,
   Marina/B-9483-2011; Ciurea, Tudorel/G-3226-2016
OI Gorunescu, Florin/0000-0001-6826-2785; Saftoiu,
   Adrian/0000-0001-7993-8269; Ciurea, Tudorel/0009-0009-9860-0795;
   Iordache, Sevastita/0000-0002-6280-6136
CR Agarwal B, 2004, AM J GASTROENTEROL, V99, P844, DOI 10.1111/j.1572-0241.2004.04177.x
   [Anonymous], IMAGEJ
   Becker D, 2001, GASTROINTEST ENDOSC, V53, P784, DOI 10.1067/mge.2001.115007
   Bhutani MS, 1997, ENDOSCOPY, V29, P635, DOI 10.1055/s-2007-1004270
   Brand B, 2000, SCAND J GASTROENTERO, V35, P1221
   Buscema M, 2005, ARTIF INTELL MED, V34, P279, DOI 10.1016/j.artmed.2004.12.001
   Buscema Massimo, 2007, Comput Intell Neurosci, P35021, DOI 10.1155/2007/35021
   Chang KJ, 2002, GASTROINTEST ENDOSC, V56, pS28, DOI 10.1067/mge.2002.127703
   DAYHOFF JE, 2001, CANCER S1, V91, P615
   Dietrich CF, 2005, Z GASTROENTEROL, V43, P1219, DOI 10.1055/s-2005-858662
   Eloubeidi MA, 2003, CANCER CYTOPATHOL, V99, P285, DOI 10.1002/cncr.11643
   Eloubeidi MA, 2003, AM J GASTROENTEROL, V98, P2663, DOI 10.1016/S0002-9270(03)01699-X
   Frey H, 2003, RADIOLOGE, V43, P850, DOI 10.1007/s00117-003-0943-2
   Fritscher-Ravens A, 2006, ENDOSCOPY, V38, P416, DOI 10.1055/s-2006-925277
   Fritscher-Ravens A, 2002, AM J GASTROENTEROL, V97, P2768
   Giovannini M, 2006, ENDOSCOPY, V38, P344, DOI 10.1055/s-2006-925158
   Haykin S. S., 1995, NEURAL NETWORKS COMP
   Hocke M, 2006, WORLD J GASTROENTERO, V12, P246, DOI 10.3748/wjg.v12.i2.246
   Itoh A, 2006, RADIOLOGY, V239, P341, DOI 10.1148/radiol.2391041676
   Itoi T, 2005, ENDOSCOPY, V37, P362, DOI 10.1055/s-2004-826156
   Jacobson BC, 2007, GASTROINTEST ENDOSC, V66, P301, DOI 10.1016/j.gie.2007.02.013
   Janssen J, 2007, GASTROINTEST ENDOSC, V65, P971, DOI 10.1016/j.gie.2006.12.057
   Klapman JB, 2005, AM J GASTROENTEROL, V100, P2658, DOI 10.1111/j.1572-0241.2005.00315.x
   Larghi A, 2004, GASTROINTEST ENDOSC, V59, P185, DOI 10.1016/S0016-5107(03)02538-0
   Micames CG, 2007, GASTROINTEST ENDOSC, V65, P979, DOI 10.1016/j.gie.2007.02.059
   Pang-Ning T., 2005, INTRO DATA MINING
   Ramesh AN, 2004, ANN ROY COLL SURG, V86, P334, DOI 10.1308/147870804290
   Raut CP, 2003, J GASTROINTEST SURG, V7, P118, DOI 10.1016/S1091-255X(02)00150-6
   Saftoiu A, 2006, ULTRASCHALL MED, V27, P535, DOI 10.1055/s-2006-927117
   Saftoiu A, 2006, J ULTRAS MED, V25, P363
   Saftoiu A, 2007, GASTROINTEST ENDOSC, V66, P291, DOI 10.1016/j.gie.2006.12.039
   Varadarajulu S, 2005, GASTROINTEST ENDOSC, V62, P728, DOI 10.1016/j.gie.2005.06.051
   Vilmann P, 2006, J GASTROEN HEPATOL, V21, P1646, DOI 10.1111/j.1440-1746.2006.04475.x
   Wallace MB, 2001, PANCREAS, V23, P26, DOI 10.1097/00006676-200107000-00004
   Ylagan LR, 2002, CANCER CYTOPATHOL, V96, P362, DOI 10.1002/cncr.10759
NR 35
TC 176
Z9 182
U1 2
U2 21
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD DEC
PY 2008
VL 68
IS 6
BP 1086
EP 1094
DI 10.1016/j.gie.2008.04.031
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 381VR
UT WOS:000261564500011
PM 18656186
DA 2023-04-20
ER

PT J
AU Tarnawski, W
   Fraczek, M
   Jelen, M
   Krecicki, T
   Zalesska-Krecicka, M
AF Tarnawski, W.
   Fraczek, M.
   Jelen, M.
   Krecicki, T.
   Zalesska-Krecicka, M.
TI The role of computer-assisted analysis in the evaluation of nuclear
   characteristics for the diagnosis of precancerous and cancerous lesions
   by contact laryngoscopy
SO ADVANCES IN MEDICAL SCIENCES
LA English
DT Article
DE contact endoscopy; computer-assisted diagnosis; endoscopic image
   interpretation; medical technologies applications
ID IN-VIVO DIAGNOSIS; NASOPHARYNGEAL CARCINOMA; ENDOSCOPY
AB Purpose: Contact endoscopy (CE), through the direct contact with the surface of the mucosa enables in vivo visualization of upper epithelial layers. There is a broad spectrum of laryngeal pathologies, as has been confirmed by earlier CE reports. The aim of the study was to resolve some of the limitations of CE through the application of computer-assisted image analysis. Quantitative and qualitative evaluation of nuclei was applied in the diagnosis of precancerous and cancerous lesions.
   Materials and Methods: Fifty four patients with various laryngeal pathologies were included in the study. Paraffin section histopathology showed 15 benign lesions, 12 precancerous lesions (5 mild and 7 severe dysplasias) and 27 invasive squamous cell cancers (SCC). After staining the mucous with 1% methylen blue, examination with contact endoscope (Karl Storz, Germany) connected to the C-7070 Wide Zoom Olympus high-resolution camera was performed.
   Results: The most discriminative parameters were revealed to be as follows: nucleus area (p<0.001), nuclei density index (p<0.001), elongation coefficient (p<0.05), nucleus area to equivalent area ratio (p<0.05). Computer-assisted image analysis composed with data mining techniques is presented for nuclei categorization.
   Conclusions: We established that computer-aided image analysis can indicate, with a high level of reliability, cases of severe dysplasia and carcinoma. By implementing the technique described in this paper, we can substantially increase the sensitivity of CE.
C1 [Tarnawski, W.] Wroclaw Univ Technol, Chair Syst & Comp Networks, PL-50370 Wroclaw, Poland.
   [Fraczek, M.; Krecicki, T.; Zalesska-Krecicka, M.] Wroclaw Med Univ, Dept Otolaryngol Head & Neck Surg, Wroclaw, Poland.
   [Jelen, M.] Wroclaw Med Univ, Dept Pathol Anat, Wroclaw, Poland.
C3 Wroclaw University of Science & Technology; Wroclaw Medical University;
   Wroclaw Medical University
RP Tarnawski, W (通讯作者)，Wroclaw Univ Technol, Chair Syst & Comp Networks, Wyb Wyspianskiego 27, PL-50370 Wroclaw, Poland.
EM wojciech.tarnawski@pwr.wroc.pl
RI Fraczek, Marcin/AAZ-5748-2021
OI Fraczek, Marcin/0000-0003-0181-122X
FU Polish national budget for scientific research [3 T11E 01128]
FX This work was financially supported by the Polish national budget for
   scientific research in 2005-2008 within grant No 3 T11E 01128, which is
   gratefully acknowledged.
CR ANDREA M, 1995, ANN OTO RHINOL LARYN, V104, P333, DOI 10.1177/000348949510400501
   ANDREA M, 1995, ACTA OTO-LARYNGOL, V115, P314, DOI 10.3109/00016489509139318
   ANDREA M, 1994, RIGID CONTACT END S2
   ANDREA M, 1995, ATLAS RIGID CONTACT
   Arens C, 2003, ANN OTO RHINOL LARYN, V112, P113, DOI 10.1177/000348940311200203
   Arens C, 1999, LARYNGO RHINO OTOL, V78, P685
   Cikojevic D, 2008, J LARYNGOL OTOL, V122, P836, DOI 10.1017/S0022215107000539
   Dobros W, 2000, OTOLARYNG HEAD NECK, V123, P770, DOI 10.1067/mhn.2000.111291
   GUSTAFSON EE, 1979, FUZZY CLUSTERING FUZ, P761
   Hamou J., 1980, ACTA ENDOSC, V10, P415
   Hamou JE, 1980, [International patent, US patent], Patent No. [4385810, WO/1980/001641, 4,385,810]
   Jain A., 1989, INFORM SYSTEMS SCI S
   Namyslowski G, 2004, MED SCI MONITOR, V10, pCR241
   Pak MW, 2002, LARYNGOSCOPE, V112, P1459, DOI 10.1097/00005537-200208000-00025
   Pak MW, 2001, LARYNGOSCOPE, V111, P1453, DOI 10.1097/00005537-200108000-00023
   Pelucchi S, 2007, Acta Otorhinolaryngol Ital, V27, P59
   TARNAWSKI W, POLISH J EN IN PRESS
   TARNAWSKI W, 2007, J MED INFORMATICS TE, V11, P213
   Tarnawski W, 2008, ADV INTEL SOFT COMPU, V47, P217
   WANG L, 1993, P 1991 IEEE INT S IN, P38
   Wardrop PJC, 2000, J LARYNGOL OTOL, V114, P437
   ZADEH LA, 1965, FUZZY SETS INFORM CO, V10, P338
NR 22
TC 8
Z9 8
U1 0
U2 4
PU MEDICAL UNIV BIALYSTOK
PI BIALYSTOK
PA UL KILINSKIEGO 1, BIALYSTOK, 15-089, POLAND
SN 1896-1126
EI 1898-4002
J9 ADV MED SCI-POLAND
JI Adv. Med. Sci.
PD DEC
PY 2008
VL 53
IS 2
BP 221
EP 227
DI 10.2478/v10039-008-0046-4
PG 7
WC Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine
GA V12MH
UT WOS:000207602800015
PM 19230308
DA 2023-04-20
ER

PT J
AU Wang, S
   Li, LH
   Cohen, H
   Mankes, S
   Chen, JJ
   Liang, ZR
AF Wang, Su
   Li, Lihong
   Cohen, Harris
   Mankes, Seth
   Chen, John J.
   Liang, Zhengrong
TI An EM approach to MAP solution of segmenting tissue mixture percentages
   with application to CT-based virtual colonoscopy
SO MEDICAL PHYSICS
LA English
DT Article
DE biological organs; biological tissues; computerised tomography;
   endoscopes; image segmentation; maximum likelihood estimation; medical
   image processing; virtual reality
ID EXTRACT COLON LUMEN; COLORECTAL NEOPLASIA; CLEANSING METHOD;
   COLONOGRAPHY; SEGMENTATION; IMAGES; CLASSIFICATION; POLYPS; MODELS
AB Electronic colon cleansing (ECC) is an emerging technique developed to segment the colon lumen from a patient's abdominal computed tomography colonography (CTC) images. However, the residue stool and fluid tagged by contrast materials as well as mixed tissue distribution with partial volume (PV) effect impose several challenges for ECC, resulting in incomplete and overcomplete cleansings. To address the PV effect, this work investigated an improved maximum a posteriori expectation-maximization (MAP-EM) image segmentation algorithm which simultaneously estimates tissue mixture percentages within each image voxel and statistical model parameters for the tissue distribution. Given the segmented tissue mixture information beyond the image voxel level, not only the PV effect has been satisfactorily addressed as a particular case of tissue mixture problem, but incomplete and overcomplete ECC causes could also be maximally avoided. For clinical application to CTC that involves several issues transferring from theoretical analysis to practical validation, an innovative initialization procedure and refined estimation strategy were proposed to build an ECC pipeline based on the MAP-EM segmentation. The pipeline was evaluated based on 52 patient CTC studies, downloaded from the website of the Virtual Colonoscopy Screening Resource Center, by two radiologists. A noticeable improvement over the authors' previous ECC pipeline was documented. Several typical cases were also presented to show visually the improved performance of the presented ECC pipeline.
C1 [Wang, Su; Li, Lihong; Cohen, Harris; Mankes, Seth; Liang, Zhengrong] SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
   [Liang, Zhengrong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   [Li, Lihong] CUNY Coll Staten Isl, Dept Engn Sci & Phys, Staten Isl, NY 10314 USA.
   [Chen, John J.] SUNY Stony Brook, Dept Prevent Med, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook; City University of New York
   (CUNY) System; College of Staten Island (CUNY); State University of New
   York (SUNY) System; State University of New York (SUNY) Stony Brook
RP Liang, ZR (通讯作者)，SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
EM jerome.liang@sunysb.edu
RI Cohen, Harris L./B-6590-2008
OI Cohen, Harris L./0000-0002-7985-6439
FU National Cancer Institute [CA082402, CA120917]
FX This work was partly supported by NIH Grant Nos. CA082402 and CA120917
   of the National Cancer Institute. The authors would like to acknowledge
   Dr. Matthew Barish for his comments on this work.
CR *AM CANC SOC, 2004, CANC FACTS FIG
   Amin Z, 1996, CLIN RADIOL, V51, P56, DOI 10.1016/S0009-9260(96)80221-2
   BARTRAM CI, 1994, CLIN RADIOL, V49, P365, DOI 10.1016/S0009-9260(05)81818-5
   Box G.E.P., 1978, STAT EXPT INTRO DESI
   Callstrom MR, 2001, RADIOLOGY, V219, P693, DOI 10.1148/radiology.219.3.r01jn22693
   Chen DQ, 2000, IEEE T MED IMAGING, V19, P1220, DOI 10.1109/42.897814
   CHOI HS, 1991, IEEE T MED IMAGING, V10, P395, DOI 10.1109/42.97590
   COIN CG, 1983, COMPUT RADIOL, V7, P215
   CURTIS H, 2000, AM J ROENTGENOL, V174, P493
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   EREMINA D, 2006, P SPIE MED IMAGING, V6144, pD1
   Fenlon HM, 1999, NEW ENGL J MED, V341, P1496, DOI 10.1056/NEJM199911113412003
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gersho A., 1991, SPRINGER INT SERIES
   Gokan Takehiko, 2002, Radiat Med, V20, P187
   Hara AK, 1996, GASTROENTEROLOGY, V110, P284, DOI 10.1053/gast.1996.v110.pm8536869
   Hogg R. V., 1987, APPL STAT ENG PHYS S
   HONG L, 1995, IEEE S FRONT BIOM VI, P26
   Hong LC, 1997, IEEE T NUCL SCI, V44, P1297, DOI 10.1109/23.597004
   Jemal A, 2007, CA-CANCER J CLIN, V57, P43, DOI 10.3322/canjclin.57.1.43
   Johnson CD, 2003, GASTROENTEROLOGY, V125, P311, DOI 10.1016/S0016-5085(03)00894-1
   Lakare S, 2002, PROC SPIE, V4683, P412, DOI 10.1117/12.463608
   Lefere PA, 2002, RADIOLOGY, V224, P393, DOI 10.1148/radiol.2241011222
   Li LH, 2002, PROC SPIE, V4683, P406, DOI 10.1117/12.463607
   Liang Z, 1999, P SOC PHOTO-OPT INS, V3660, P270, DOI 10.1117/12.349597
   LIANG Z, IEEE T MED IN PRESS
   LIANG Z, 1997, IEEE NUCL SCI SOC ME
   Liang ZR, 2003, P ANN INT IEEE EMBS, V25, P682, DOI 10.1109/IEMBS.2003.1279855
   Nappi J, 2008, MED IMAGE ANAL, V12, P413, DOI 10.1016/j.media.2008.01.001
   Nappi J, 2007, PROC SPIE, V6514, DOI 10.1117/12.710186
   Pickhardt PJ, 2003, AM J ROENTGENOL, V181, P799, DOI 10.2214/ajr.181.3.1810799
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Pineau BC, 2003, GASTROENTEROLOGY, V125, P304, DOI 10.1016/S0016-5085(03)00885-0
   Reed JE, 1997, J DIGIT IMAGING, V10, P70, DOI 10.1007/BF03168661
   SANTAGO P, 1995, IEEE T IMAGE PROCESS, V4, P1531, DOI 10.1109/83.469934
   Van Leemput K, 2003, IEEE T MED IMAGING, V22, P105, DOI 10.1109/TMI.2002.806587
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270
   VINING D, 1994, ANN M AM ROENTG RAY
   WANG S, SPIE MED IM IN PRESS
   Wang ZG, 2006, IEEE T BIO-MED ENG, V53, P1635, DOI 10.1109/TBME.2006.877793
   Yee J, 2001, RADIOLOGY, V219, P685, DOI 10.1148/radiology.219.3.r01jn40685
   Zalis ME, 2004, IEEE T MED IMAGING, V23, P1335, DOI 10.1109/TMI.2004.826050
   Zalis ME, 2001, AM J ROENTGENOL, V176, P646, DOI 10.2214/ajr.176.3.1760646
NR 43
TC 41
Z9 43
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD DEC
PY 2008
VL 35
IS 12
BP 5787
EP 5798
DI 10.1118/1.3013591
PG 12
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA 376VB
UT WOS:000261210000058
PM 19175136
OA Green Accepted, Green Published
DA 2023-04-20
ER

PT J
AU Malagelada, C
   De Iorio, F
   Azpiroz, F
   Accarino, A
   Segul, S
   Radeva, P
   Malagelada, JR
AF Malagelada, Carolina
   De Iorio, Fosca
   Azpiroz, Fernando
   Accarino, Anna
   Segul, Santi
   Radeva, Petia
   Malagelada, Juan-R.
TI New insight into intestinal motor function via noninvasive endoluminal
   image analysis
SO GASTROENTEROLOGY
LA English
DT Article
ID MOTILITY; OBSTRUCTION; MANOMETRY
AB Background & Aims: Evaluation of small bowel motility by intestinal manometry is invasive and requires expertise for interpretation. Our aim was to use capsule technology for evaluation of small bowel motor function based on a fully computerized image analysis program. Methods: Thirty-six consecutive patients with severe intestinal motor disorders (19 fulfilling manometric criteria of intestinal dysmotility and 17 not) and 50 healthy subjects received the endoscopic capsule (Pillcam; Given Imaging, Yokneam, Israel). Endoluminal image analysis was performed with a computer vision program specifically developed for the detection of contractile patterns (phasic luminal closure and radial wrinkles by wall texture analysis), noncontractile patterns (tunnel and wall appearance by Laplacian filtering), intestinal content (by color decomposition analysis), and endoluminal motion (by chromatic stability). Automatic classification of normal and abnormal intestinal motility was performed by means of a machine-learning technique. Results: As compared with healthy subjects, patients exhibited less contractile activity (25% less phasic luminal closures, P < .05) and more noncontractile patterns (151% more tunnel pattern, P < .05), static sequences (56% more static images, P < .01), and turbid intestinal content (94% more static turbid images, P < .01). On cross validation, the classifier identified as abnormal all but 1 patient with manometric criteria of dysmotility and as normal all healthy subjects. Out of the 17 patients without manometric criteria of dysmotility, 11 were identified as abnormal and 6 as normal. Conclusions: Our study shows that endoluminal image analysis, by means of computer vision and machine-learning techniques, constitutes a reliable, noninvasive, and automated diagnostic test of intestinal motor disorders.
C1 [Malagelada, Carolina; De Iorio, Fosca; Azpiroz, Fernando; Accarino, Anna; Malagelada, Juan-R.] Autonomous Univ Barcelona, Univ Hosp Vall Hebron, Digest Syst Res Unit, Ciberehd,Dept Med, E-08035 Barcelona, Spain.
   [Segul, Santi; Radeva, Petia] Comp Vis Ctr, Bellaterra, Spain.
C3 Autonomous University of Barcelona; CIBER - Centro de Investigacion
   Biomedica en Red; CIBEREHD; Hospital Universitari Vall d'Hebron; Centre
   de Visio per Computador (CVC)
RP Azpiroz, F (通讯作者)，Hosp Gen Valle Hebron, Digest Syst Res Unit, Barcelona 08035, Spain.
EM fernando.azpiroz@telefonica.net
RI Radeva, Petia/I-3385-2015; Garaventa, Anna Accarino/Q-8658-2017; Segui,
   Santi/E-4860-2010; Heredia, Josefina/I-1166-2012; Malagelada,
   Carolina/F-3743-2016
OI Radeva, Petia/0000-0003-0047-5172; Segui, Santi/0000-0002-8603-138X;
   Malagelada, Carolina/0000-0001-7097-1492; Azpiroz,
   Fernando/0000-0002-7327-960X
FU Spanish Ministry of Education [SAF 2006-03907]; Spanish Ministry of
   Health [CM05/00012]; Instituto de Salud Carlos III
FX Supported in part by Given Imaging, the Spanish Ministry of Education
   (Direccion General de Investigacion, SAF 2006-03907), the Spanish
   Ministry of Health (Ayuda para contratos post-formacion sanitaria
   especializada, CM05/00012), and the Instituto de Salud Carlos III (to
   Ciberehd). The authors thank Maria Maluenda and Caterina Violanti for
   performing and visualizing the studies; Laura Igual, Panagiota
   Spyridonos Fernando Vilarino, and Jordi! Vitria for their contribution
   to the computer vision analysis program; Maite Casaus and Anna Aparici
   for technical support; Christine O'Hara for English editing of the
   manuscript; and Gloria Santaliestra for secretarial assistance.
   Financial disclosure and conflicts of interest: Supported in part by
   Given Imaging. No conflicts of interest exist.
CR Camilleri M, 1998, GASTROENTEROLOGY, V115, P747, DOI 10.1016/S0016-5085(98)70155-6
   De loria F, 2005, GASTROENTEROLOGY, V128, pA24
   DELORIO F, 2006, GASTROENTEROLOGY, V130, pA473
   FRANK JW, 1994, AM J GASTROENTEROL, V89, P339
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Imam H, 2004, AM J PHYSIOL-GASTR L, V286, pG263, DOI 10.1152/ajpgi.00228.2003
   Kohonen T., 2001, SELF ORG MAPS, DOI 10.1007/978-3-642-56927-2
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Rao SSC, 1996, GASTROENTEROLOGY, V110, P740, DOI 10.1053/gast.1996.v110.pm8608883
   ROUILLON JM, 1991, GASTROENTEROLOGY, V101, P1606, DOI 10.1016/0016-5085(91)90398-5
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   RUSS JC, 2007, IMAGE PROCESSING HDB
   Segui S, 2007, LECT NOTES COMPUT SC, V4756, P773
   Serra J, 1998, J PHYSIOL-LONDON, V506, P579, DOI 10.1111/j.1469-7793.1998.579bw.x
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Stanghellini V, 2005, CLIN GASTROENTEROL H, V3, P449, DOI 10.1016/S1542-3565(04)00675-5
   STANGHELLINI V, 1987, GUT, V28, P5, DOI 10.1136/gut.28.1.5
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Vilarino F, 2006, INT J COMPUT ASS RAD, V1, P9
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P188
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P178
   Wingate D, 2002, J GASTROEN HEPATOL, V17, pS1, DOI 10.1046/j.1440-1746.17.s1.7.x
NR 22
TC 59
Z9 64
U1 0
U2 7
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD OCT
PY 2008
VL 135
IS 4
BP 1155
EP 1162
DI 10.1053/j.gastro.2008.06.084
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 359JM
UT WOS:000259982800022
PM 18691579
OA Bronze
DA 2023-04-20
ER

PT J
AU Wang, J
   Wang, S
   Li, LH
   Fan, Y
   Lu, HB
   Liang, ZR
AF Wang, Jing
   Wang, Su
   Li, Lihong
   Fan, Yi
   Lu, Hongbing
   Liang, Zhengrong
TI Virtual Colonoscopy Screening With Ultra Low-Dose CT and Less-Stressful
   Bowel Preparation: A Computer Simulation Study
SO IEEE TRANSACTIONS ON NUCLEAR SCIENCE
LA English
DT Article
DE Karhunen-Loeve transform; low dose computed tomography; noise reduction;
   partial volume image segmentation; penalized weighted least-squares;
   virtual colonoscopy
ID X-RAY CT; IMAGE-RECONSTRUCTION; COLORECTAL NEOPLASIA; NOISE-REDUCTION;
   SINOGRAM DATA; SINGLE-SLICE; TOMOGRAPHY; LIKELIHOOD
AB Computed tomography colonography (CTC) or CT-based virtual colonoscopy (VC) is an emerging tool for detection of colonic polyps. Compared to the conventional fiber-optic colonoscopy, VC has demonstrated the potential to become a mass screening modality in terms of safety, cost, and patient compliance. However, current CTC delivers excessive X-ray radiation to the patient during data acquisition. The radiation is a major concern for screening application of CTC. In this work, we performed a simulation study to demonstrate a possible ultra low-dose CT technique for VC. The ultra low-dose abdominal CT images were simulated by adding noise to the sinograms of the patient CTC images acquired with normal dose scans at 100 mAs levels. The simulated noisy sinogram or projection data were first processed by a Karhunen-Loeve domain penalized weighted least-squares (KL-PWLS) restoration method and then reconstructed by a filtered backprojection algorithm for the ultra low-dose CT images. The patient-specific virtual colon lumen was constructed and navigated by a VC system after electronic colon cleansing of the orally-tagged residue stool and fluid. By the KL-PWLS noise reduction, the colon lumen can successfully be constructed and the colonic polyp can be detected in an ultra low-dose level below 50 mAs. Polyp detection can be found more easily by the KL-PWLS noise reduction compared to the results using the conventional noise filters, such as Harming filter. These promising results indicate the feasibility of an ultra low-dose CTC pipeline for colon screening with less-stressful bowel preparation by fecal tagging with oral contrast.
C1 [Wang, Jing; Wang, Su; Fan, Yi; Liang, Zhengrong] SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
   [Li, Lihong] CUNY Coll Staten Isl, Dept Engn Sci & Phys, Staten Isl, NY 10314 USA.
   [Lu, Hongbing] Fourth Mil Med Univ, Dept Biomed Engn, Xian 710032, Shannxi, Peoples R China.
   [Liang, Zhengrong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; City University of New York (CUNY) System; College
   of Staten Island (CUNY); Air Force Military Medical University; State
   University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Wang, J (通讯作者)，Stanford Univ, Dept Radiat Oncol, Stanford, CA 94305 USA.
EM Jerome.Liang@sunysb.edu
RI Wang, Jing/N-7332-2019
OI Wang, Jing/0000-0002-8491-4146
FU NIH National Cancer Institute [CA082402, CAI 20917]; PSC-CUNY; National
   Nature Science Foundation of China [30470490]
FX This work was supported in part by the NIH National Cancer Institute
   under Grants CA082402 and CAI 20917. Dr. L. Li was supported in part by
   the PSC-CUNY award program. Dr. H. Lu was supported in p m by the
   National Nature Science Foundation of China under Grant 30470490.
CR *AM CANC SOC, 2004, CANC FACTS FIG
   Besson G, 1999, MED PHYS, V26, P415, DOI 10.1118/1.598533
   Brenner DJ, 2007, NEW ENGL J MED, V357, P2277, DOI 10.1056/NEJMra072149
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dendy PP, 2008, BRIT J RADIOL, V81, P1, DOI 10.1259/bjr/15413265
   Hong LC, 1997, IEEE T NUCL SCI, V44, P1297, DOI 10.1109/23.597004
   Hsieh J, 1997, MED PHYS, V24, P1375, DOI 10.1118/1.598026
   Hsieh J, 1998, MED PHYS, V25, P2139, DOI 10.1118/1.598410
   Jemal A, 2007, CA-CANCER J CLIN, V57, P43, DOI 10.3322/canjclin.57.1.43
   Kachelriess M, 2001, MED PHYS, V28, P475, DOI 10.1118/1.1358303
   La Riviere PJ, 2005, MED PHYS, V32, P1676, DOI 10.1118/1.1915015
   Lasio GM, 2007, PHYS MED BIOL, V52, P2247, DOI 10.1088/0031-9155/52/8/014
   LI J, 2002, P IEEE NUCL SCI S ME
   Li TF, 2004, IEEE T NUCL SCI, V51, P2505, DOI 10.1109/TNS.2004.834824
   LIANG Z, 1997, P IEEE NUCL SCI S ME
   Liang ZR, 2005, PROC SPIE, V5746, P810, DOI 10.1117/12.597437
   Linton OW, 2003, AM J ROENTGENOL, V181, P321, DOI 10.2214/ajr.181.2.1810321
   LU H, 2001, P IEEE NUCL SCI S ME
   Lu HB, 2002, PROC SPIE, V4682, P146, DOI 10.1117/12.465552
   Oguchi K, 2000, ACTA RADIOL, V41, P352, DOI 10.1080/028418500127345451
   Pan XC, 2003, MED PHYS, V30, P590, DOI 10.1118/1.1556608
   Paterson A, 2007, CLIN RADIOL, V62, P507, DOI 10.1016/j.crad.2006.12.004
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   PRESS WH, 1992, NUMERICAL RECIPES C, P50
   SIDDON R, 1986, MED PHYS, V12, P252
   Thibault J., 2006, P SOC PHOTO-OPT INS, V6065, P264
   THIBAULT JB, 2005, P INT C FULL 3D REC, P271
   Vijan S, 2007, AM J GASTROENTEROL, V102, P380, DOI 10.1111/j.1572-0241.2006.00970.x
   Wang J, 2005, MED PHYS, V32, P3389, DOI 10.1118/1.2064807
   WANG J, 2007, THESIS STONY BROOK U
   Wang J, 2008, PHYS MED BIOL, V53, P3327, DOI 10.1088/0031-9155/53/12/018
   Wang J, 2006, IEEE T MED IMAGING, V25, P1272, DOI 10.1109/TMI.2006.882141
   Wang J, 2006, IEEE T NUCL SCI, V53, P1230, DOI 10.1109/TNS.2006.874955
   Wang ZG, 2006, IEEE T BIO-MED ENG, V53, P1635, DOI 10.1109/TBME.2006.877793
   Wernick MN, 1999, IEEE T MED IMAGING, V18, P185, DOI 10.1109/42.764885
   Whiting BR, 2006, MED PHYS, V33, P3290, DOI 10.1118/1.2230762
NR 36
TC 21
Z9 22
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855 USA
SN 0018-9499
J9 IEEE T NUCL SCI
JI IEEE Trans. Nucl. Sci.
PD OCT
PY 2008
VL 55
IS 5
BP 2566
EP 2575
DI 10.1109/TNS.2008.2004557
PG 10
WC Engineering, Electrical & Electronic; Nuclear Science & Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Nuclear Science & Technology
GA 388JI
UT WOS:000262015700018
PM 19169383
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Klank, U
   Padoy, N
   Feussner, H
   Navab, N
AF Klank, Ulrich
   Padoy, Nicolas
   Feussner, Hubertus
   Navab, Nassir
TI Automatic feature generation in endoscopic images
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Feature generation; Classification; Endoscopic images; Evolutionary
   reinforcement learning; Cholecystectomy
ID CLASSIFICATION
AB Motivation Fiber optic endoscopy is essential for minimally invasive surgery, but endoscopic images are very challenging for computer vision algorithms, since they contain many effects like tissue deformations, specular reflections, smoke, variable illumination and field of view. We developed a method to extract features from endoscopic images usable for scene analysis and classification. These features could be used with data from other sensors for workflow analysis and recognition.
   Materials and methods Evolutionary reinforcement learning that automatically computes good features, making it possible to classify endoscopic images into their respective surgical phases. It is especially designed to abstract the relevant information from the highly noisy images automatically.
   Results Automatic feature extraction was used to classify images from endoscopic cholecystectomies into their respective surgical phases. These automatically computed features perform better than some classical features from computer vision. The automated feature extraction process enables reasonable classification rates for complex and difficult images where no good features are known.
   Conclusion We developed an automatic method that extracts features from images for use in classification. The method was applied to endoscopic images yielding promising results and demonstrating its feasibility under demanding conditions.
C1 [Klank, Ulrich; Padoy, Nicolas; Navab, Nassir] Tech Univ Munich, Boltzmannstr 3, D-85748 Garching, Germany.
   [Padoy, Nicolas] LORIA INRIA Lorraine, Nancy, France.
   [Feussner, Hubertus] TU, Klinikum Rechts Isar, Chirurg Klin & Poliklin, Munich, Germany.
C3 Technical University of Munich; Universite de Lorraine; Technical
   University of Munich; University of Munich
RP Klank, U (通讯作者)，Tech Univ Munich, Boltzmannstr 3, D-85748 Garching, Germany.
EM klank@in.tum.de
CR Ahmadi SA, 2006, LECT NOTES COMPUT SC, V4190, P420
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Francone, 1998, GENETIC PROGRAMMING
   Ghosh P, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P1171, DOI 10.1145/1143997.1144183
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Koza J.R., 1990, GENETIC PROGRAMMING
   Lo BPL, 2003, LECT NOTES COMPUT SC, V2878, P230
   Majewski P, 2005, LECT NOTES ARTIF INT, V3533, P400
   Nandi RJ, 2006, MED BIOL ENG COMPUT, V44, P683, DOI 10.1007/s11517-006-0077-6
   Ohnuma K, 2006, INT J COMPUT ASS RAD, V1, P442
   Scholkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Szymanski JJ, 2002, PROC SPIE, V4725, P338, DOI 10.1117/12.478765
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Zhang MJ, 2003, EURASIP J APPL SIG P, V2003, P841, DOI 10.1155/S1110865703303063
NR 15
TC 27
Z9 28
U1 0
U2 3
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD SEP
PY 2008
VL 3
IS 3-4
BP 331
EP 339
DI 10.1007/s11548-008-0223-8
PG 9
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA V33AC
UT WOS:000208990700017
DA 2023-04-20
ER

PT J
AU Huang, CR
   Chung, PC
   Sheu, BS
   Kuo, HJ
   Popper, M
AF Huang, Chun-Rong
   Chung, Pau-Choo
   Sheu, Bor-Shydng
   Kuo, Hsiu-Jui
   Popper, Mikulas
TI Helicobacter pylori - Related gastric histology classification using
   support-vector-machine-based feature selection
SO IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE
LA English
DT Article
DE endoscopy; feature selection; Helicobacter pylori (H. pylori); nonulcer
   dyspepsia; peptic ulcer; support vector machine (SVM)
ID TRIPLE THERAPY; NEURAL-NETWORK; INFECTION; SEGMENTATION; IMAGES
AB This study presents a computer-aided diagnosis system using sequential forward floating selection (SFFS) with support vector machine (SVM) to diagnose gastric histology of Heliobacter pylori (H. pylori) from endoscopic images. To achieve this goal, candidate image features associated with clinical symptoms ire extracted from endoscopic images. With these candidate features, the SFFS method is applied to select feature subsets, which perform the best classification results under SVM with respect to different histological features. By using the classifiers obtained from the feature subsets, a new diagnosis system is implemented to provide physicians with H. pylori-related histological results from endoscopic images.
C1 [Huang, Chun-Rong] Acad Sinica, Inst Informat Sci, Taipei 11523, Taiwan.
   [Chung, Pau-Choo; Kuo, Hsiu-Jui] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan.
   [Sheu, Bor-Shydng] Natl Cheng Kung Univ, Dept Internal Med, Tainan 70101, Taiwan.
   [Sheu, Bor-Shydng] Natl Cheng Kung Univ, Inst Clin Med, Tainan 70101, Taiwan.
C3 Academia Sinica - Taiwan; National Cheng Kung University; National Cheng
   Kung University; National Cheng Kung University
RP Huang, CR (通讯作者)，Acad Sinica, Inst Informat Sci, Taipei 11523, Taiwan.
EM nckuos@iis.sinica.edu.tw; pcchung@ee.ncku.edu.tw;
   sheubs@mail.ncku.edu.tw; xxray@neural.ee.ncku.edu.tw; popper@nczisk.sk
RI Chung, Pau-Choo/ABB-3574-2021
CR BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang C., 2001, LIBSVM LIB SUPPORT V
   COHEN A, 1992, COMMUN PUR APPL MATH, V45, P485, DOI 10.1002/cpa.3160450502
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Dixon MF, 1996, AM J SURG PATHOL, V20, P1161, DOI 10.1097/00000478-199610000-00001
   Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100
   ELOMAR EM, 1995, GASTROENTEROLOGY, V109, P681, DOI 10.1016/0016-5085(95)90374-7
   Garrett D, 2003, IEEE T NEUR SYS REH, V11, P141, DOI 10.1109/TNSRE.2003.814441
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jolli&REG;e I.T., 1986, PRINCIPAL COMPONENT
   KITTLER J, PATTERN RECOGNITION, P41
   KOCUR CM, 2003, IEEE ENG MED BIOL, V15, P95
   Kohavi R., 1994, P AAAI FALL S REL, P122
   Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2
   Kuipers E J, 2001, Curr Gastroenterol Rep, V3, P509, DOI 10.1007/s11894-001-0072-x
   Lee CC, 2003, IEEE T INF TECHNOL B, V7, P208, DOI 10.1109/TITB.2003.813795
   Ma WY, 1996, PROC CVPR IEEE, P425, DOI 10.1109/CVPR.1996.517107
   McColl KEL, 1997, GUT, V40, P302, DOI 10.1136/gut.40.3.302
   MCNITTGRAY MF, 1995, IEEE T MED IMAGING, V14, P537, DOI 10.1109/42.414619
   NADLER M, 1993, PATTERN RECOGN, P209
   NARENDRA P, 1977, IEEE T COMPUT, V26, P917, DOI 10.1109/TC.1977.1674939
   PARSONNET J, 1991, NEW ENGL J MED, V325, P1127, DOI 10.1056/NEJM199110173251603
   Pechenizkiy M, 2006, IEEE T INF TECHNOL B, V10, P533, DOI 10.1109/TITB.2006.875654
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Aldasoro CCR, 2007, IEEE T MED IMAGING, V26, P1, DOI 10.1109/TMI.2006.884637
   Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102
   Sheu BS, 1998, J FORMOS MED ASSOC, V97, P266
   Sheu BS, 1996, GASTROINTEST ENDOSC, V44, P683, DOI 10.1016/S0016-5107(96)70052-4
   Sheu BS, 2001, DIGEST DIS SCI, V46, P2700, DOI 10.1023/A:1012727513166
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760
   Unser M, 2003, IEEE T IMAGE PROCESS, V12, P1080, DOI 10.1109/TIP.2003.812329
   WALSH JH, 1995, NEW ENGL J MED, V333, P984, DOI 10.1056/NEJM199510123331508
   Yang HB, 1997, DIGEST DIS SCI, V42, P1835, DOI 10.1023/A:1018894606541
NR 37
TC 22
Z9 22
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1089-7771
EI 1558-0032
J9 IEEE T INF TECHNOL B
JI IEEE T. Inf. Technol. Biomed.
PD JUL
PY 2008
VL 12
IS 4
BP 523
EP 531
DI 10.1109/TITB.2007.913128
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA 327UP
UT WOS:000257754300012
PM 18632332
DA 2023-04-20
ER

PT J
AU Wang, S
   Zhu, HB
   Lu, HB
   Liang, ZR
AF Wang, Su
   Zhu, Hongbin
   Lu, Hongbing
   Liang, Zhengrong
TI Volume-based feature analysis of mucosa for automatic initial polyp
   detection in virtual colonoscopy
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Volume-based mucosa; Geometrical feature analysis; Virtual colonoscopy;
   Computer-aided detection; Weighted integral curvature in normal
   directions (WICND)
ID COMPUTER-AIDED DIAGNOSIS; CT COLONOGRAPHY; COLORECTAL NEOPLASIA; FINITE
   MIXTURES; COLONIC POLYPS; VISUALIZATION; SEGMENTATION; REDUCTION;
   ALGORITHM; SCHEME
AB Purpose A volume-based mucosa-based polyp candidate determination scheme for automatic polyp detection in computed colonography is presented in this paper.
   Methods Different from the one-layer mucosa that is widely accepted by the existing computer-aided detection methods, a thick mucosa region of 3-5 voxels wide is extracted, which excludes the direct applications of the traditional geometrical features. A fast marching-based adaptive gradient/curvature and weighted integral curvature along normal directions (WICND) are developed for this purpose, and polyp candidates are optimally determined by computing and clustering these fast marching-based adaptive geometrical features.
   Results By testing on 52 patients datasets in which 26 patients were found with polyps of size 4-22mm, both the locations and number of polyp candidates detected by WICND and previously developed linear integral curvature (LIC) were compared. Not only the number of false positives (FPs) was reduced from 706 to 132 on average, but also the detection sensitivity has been slightly improved.
   Conclusions WICND outperformed LIC mainly by significantly reducing the number of FPs, which promises to release our burden of machine learning in the feature space, especially for those polyps smaller than 5mm.
C1 [Wang, Su; Zhu, Hongbin; Liang, Zhengrong] SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
   [Lu, Hongbing] Fourth Mil Med Univ, Dept Biomed Engn Comp Applicat, Xian 710032, Shaanxi, Peoples R China.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; Air Force Military Medical University
RP Liang, ZR (通讯作者)，SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
EM suwang@mil.sunysb.edu; jzl@mil.sunysb.edu
FU NIH of the National Cancer Institute [CA082402, CA120917]; National
   Nature Science Foundation of China [30470490]
FX This work was partly supported by NIH Grant #CA082402 and #CA120917 of
   the National Cancer Institute. H. Lu was supported by the National
   Nature Science Foundation of China under Grant 30470490.
CR COIN CG, 1983, COMPUT RADIOL, V7, P215
   Dachman AH, 1998, AM J ROENTGENOL, V171, P989, DOI 10.2214/ajr.171.4.9762982
   EREMINA D, 2006, P SPIE MED IMAGING, V6144, pD1
   Ferrucci JT, 2001, AM J ROENTGENOL, V177, P975, DOI 10.2214/ajr.177.5.1770975
   Fletcher JG, 1999, AM J ROENTGENOL, V172, P1271, DOI 10.2214/ajr.172.5.10227501
   Gonzales RC., 2002, DIGITAL IMAGE PROCES
   Hong LC, 1997, IEEE T NUCL SCI, V44, P1297, DOI 10.1109/23.597004
   Johnson CD, 2000, RADIOLOGY, V216, P331, DOI 10.1148/radiology.216.2.r00au47331
   Johnson CD, 2003, GASTROENTEROLOGY, V125, P311, DOI 10.1016/S0016-5085(03)00894-1
   Kiss G, 2002, EUR RADIOL, V12, P77, DOI 10.1007/s003300101040
   Kiss G., 2002, P 7 INT WORKSH VIS M, P27
   Li LH, 2003, IEEE T NUCL SCI, V50, P1686, DOI 10.1109/TNS.2003.817334
   LIANG Z, 1992, IEEE T NUCL SCI, V39, P1126, DOI 10.1109/23.159772
   Liang Z, 2007, IEEE NUCL SCI S NSS
   Lichan Hong, 1995, Proceedings. 1995 Biomedical Visualization (Cat. No.95TB100001), P26, DOI 10.1109/BIOVIS.1995.528702
   Lichan Hong, 1997, Computer Graphics Proceedings, SIGGRAPH 97, P27, DOI 10.1145/258734.258750
   LORENSEN WE, 1995, ST HEAL T, V18, P221
   MONGA O, 1992, P 3 ANN C AI SIM PLA, P225
   Nappi J, 2002, J COMPUT ASSIST TOMO, V26, P493, DOI 10.1097/01.RCT.0000025350.64054.4E
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   Nappi JJ, 2004, MED PHYS, V31, P860, DOI 10.1118/1.1668591
   OBRIEN MJ, 1990, GASTROENTEROLOGY, V98, P371, DOI 10.1016/0016-5085(90)90827-N
   Paik DS, 2000, RADIOLOGY, V217, P370
   Paik DS, 2001, RADIOLOGY, V221, P332
   Paik DS, 1999, RADIOLOGY, V213P, P197
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Sanjay-Gopel S, 1998, IEEE T IMAGE PROCESS, V7, P1014, DOI 10.1109/83.701161
   SETHIAN JA, 1999, LEVEL SET METHODS FA
   Summers RM, 2001, RADIOLOGY, V219, P51, DOI 10.1148/radiology.219.1.r01ap0751
   Summers RM, 2000, RADIOLOGY, V216, P284, DOI 10.1148/radiology.216.1.r00jl43284
   van Wijk C, 2004, LECT NOTES COMPUT SC, V3216, P200
   Vining DJ, 1994, AM J ROENTGENOL, V162, pS104
   WANG S, 2008, INT WORKSH COMB IM A
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Wang ZG, 2006, IEEE T BIO-MED ENG, V53, P1635, DOI 10.1109/TBME.2006.877793
   Winawer SJ, 1997, GASTROENTEROLOGY, V112, P594, DOI 10.1053/gast.1997.v112.agast970594
   Yee J, 2001, RADIOLOGY, V219, P685, DOI 10.1148/radiology.219.3.r01jn40685
   Yoshida H, 2002, RADIOGRAPHICS, V22, P963, DOI 10.1148/radiographics.22.4.g02jl16963
   Yoshida H, 2002, RADIOLOGY, V222, P327, DOI 10.1148/radiol.2222010506
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 41
TC 12
Z9 12
U1 0
U2 2
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD JUN
PY 2008
VL 3
IS 1-2
BP 131
EP 142
DI 10.1007/s11548-008-0215-8
PG 12
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA V32ZZ
UT WOS:000208990400016
PM 19774204
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Yoon, SW
   Lee, C
   Kim, JK
   Lee, M
AF Yoon, Sung Won
   Lee, Chungkeun
   Kim, Jin Kwon
   Lee, Myoungho
TI Wavelet-based multi-resolution deformation for medical endoscopic image
   segmentation
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE multi-resolution; wavelet; snake; active contour model; segmentation
AB Image segmentation is an essential technique in image analysis. In spite of issues in contour initialization, boundary concavities and high-level computation, active contour models (snakes) are popular and successful method for segmentation among researchers. Segmentation process in snakes consists of calculation of energy and deformation of contour. In this paper, we present a new deformation method for active contour model, multi-resolution deformation based on wavelet ensuring powerful time reduction, high accuracy supported by stable results in convergence of an initial contour to target boundary in medical image segmentation.
C1 [Lee, Myoungho] Yonsei Univ, Sch Elect & Elect Engn, Med Elect & Informat LAB, Seoul 120749, South Korea.
C3 Yonsei University
RP Lee, M (通讯作者)，Yonsei Univ, Sch Elect & Elect Engn, Med Elect & Informat LAB, YERC 212C,134 Sinchon Dong, Seoul 120749, South Korea.
EM mhlee@yonsei.ac.kr
OI Lee, Chungkeun/0000-0002-4863-776X
CR Burrus C. S., 1998, INTRO WAVELETS WAVEL
   CHUANG CH, 2001, 2001 IEEE INT S CIRC, V2, P389
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Leroy B., 1996, P 12 INT C AN OPT SY, P58
   McInerney T, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P171, DOI 10.1109/MMBIA.1996.534069
   MEDINA VB, 2000, IEEE EMBS P 22 ANN I, V3, P1625
   Nava FP, 2003, PATTERN RECOGN, V36, P1119, DOI 10.1016/S0031-3203(02)00168-1
   WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   Yoon SW, 2004, IEICE T INF SYST, VE87D, P785
NR 13
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD JUN
PY 2008
VL 32
IS 3
BP 207
EP 214
DI 10.1007/s10916-007-9124-6
PG 8
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA 285KO
UT WOS:000254775900003
PM 18444357
DA 2023-04-20
ER

PT J
AU Das, A
   Nguyen, CC
   Li, F
   Li, BX
AF Das, Ananya
   Nguyen, Cuong C.
   Li, Feng
   Li, Baoxin
TI Digital image analysis of EUS images accurately differentiates
   pancreatic cancer from chronic pancreatitis and normal tissue
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article; Proceedings Paper
CT 3rd International Symposium on Natural Orifice Translumenal Endoscopic
   Surgery
CY JUL   10, 2008
CL San Francisco, CA
ID NEURAL-NETWORK; ENDOSCOPIC ULTRASOUND; DIAGNOSIS; LESIONS
AB Background: Concomitant changes of chronic pancreatitis markedly degrade the performance of EUS in diagnosing pancreatic adenocarcinoma (PC). Digital image analysis (DIA) of the spatial distribution of pixels in a US image has been used as an effective approach to tissue characterization.
   Objective: We applied the techniques of DIA to EUS images of the pancreas to develop a classification model capable of differentiating pancreatic adenocarcinoma from non-neoplastic tissue.
   Design: Representative regions of interest were digitally selected in EUS images of 3 groups of patients with normal pancreas (group 1), chronic pancreatitis (group 11), and pancreatic adenocarcinorna (group 111). Texture analyses were then performed by using image analysis software. Principal component analysis (PCA) was used for data reduction, and, later, a neural-network-based predictive model was built, trained, and validated.
   Setting: Tertiary academic medical center.
   Patients: Patients undergoing EUS of the pancreas.
   Results: A total of 110, 99, and 110 regions of interest in groups 1, 11, 111, respectively, were available for analysis. For each region, a total of 256 statistical parameters were extracted. Eleven parameters were subsequently retained by PCA. A neural network model was built, trained by using these parameters as input variables for prediction of PC, and then validated in the remainder of the data set. This model was very accurate in classifying PC with an area under the receiver operating characteristic curve of 0.93. Limitation: Exploratory study with a small number of patients.
   Conclusions: DIA of EUS images is accurate in differentiating PC from chronic inflammation and normal tissue. With the potential availability of real-time application, DIA can develop into a useful clinical diagnostic tool in pancreatic diseases and in certain Situations may obviate EUS-guided FNA.
C1 [Das, Ananya; Nguyen, Cuong C.; Li, Feng] Mayo Clin Arizona, Dept Internal Med, Div Gastroenterol & Hepatol, Scottsdale, AZ USA.
   [Li, Baoxin] Arizona State Univ, Dept Comp Sci & Engn, Phoenix, AZ USA.
C3 Mayo Clinic; Mayo Clinic Phoenix; Arizona State University; Arizona
   State University-Downtown Phoenix
RP Das, A (通讯作者)，Mayo Clin Scottsdale, Div Gastroenterol & Hepatol, 13400 E Shea Blvd, Scottsdale, AZ 85259 USA.
CR Brand B, 2000, SCAND J GASTROENTERO, V35, P1221
   Castellano G, 2004, CLIN RADIOL, V59, P1061, DOI 10.1016/j.crad.2004.07.008
   Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805
   CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Fritscher-Ravens A, 2006, ENDOSCOPY, V38, P416, DOI 10.1055/s-2006-925277
   Fritscher-Ravens A, 2002, AM J GASTROENTEROL, V97, P2768
   Gleeson Ferga C, 2007, Curr Gastroenterol Rep, V9, P123, DOI 10.1007/s11894-007-0006-3
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES, P585
   Haykin SS, 1999, NEURAL NETWORKS COMP
   Joliffe I T, 1992, Stat Methods Med Res, V1, P69, DOI 10.1177/096228029200100105
   Loren DE, 2002, GASTROINTEST ENDOSC, V56, P742, DOI 10.1067/mge.2002.128920
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644
   OSBORNE JW, 2004, RES EVALUAT, V9, P311
   Robb Richard A, 2000, BIOMEDICAL IMAGING V
   Varadarajulu S, 2005, GASTROINTEST ENDOSC, V62, P728, DOI 10.1016/j.gie.2005.06.051
   Wallace MB, 2001, GASTROINTEST ENDOSC, V53, P294, DOI 10.1067/mge.2001.112191
NR 17
TC 68
Z9 72
U1 1
U2 3
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD MAY
PY 2008
VL 67
IS 6
BP 861
EP 867
DI 10.1016/j.gie.2007.08.036
PG 7
WC Gastroenterology & Hepatology
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 300LA
UT WOS:000255824100015
PM 18179797
DA 2023-04-20
ER

PT J
AU Chu, A
   Ahn, H
   Halwan, B
   Kalmin, B
   Artifon, ELA
   Barkun, A
   Lagoudakis, MG
   Kumar, A
AF Chu, Adrienne
   Ahn, Hongshik
   Halwan, Bhawna
   Kalmin, Bruce
   Artifon, Everson L. A.
   Barkun, Alan
   Lagoudakis, Michail G.
   Kumar, Atul
TI A decision support system to facilitate management of patients with
   acute gastrointestinal bleeding
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE class prediction; cross validation; gastrointestinal bleeding; machine
   learning
ID ARTIFICIAL NEURAL-NETWORK; CLINICAL GUIDELINE; HOSPITAL LENGTH;
   HEMORRHAGE; RISK; DIAGNOSIS; PREDICTORS; MORTALITY
AB Objective: To develop a model to predict the bleeding source and identify the cohort amongst patients with acute gastrointestinal bleeding (GIB) who require urgent intervention, including endoscopy. Patients with acute GIB, an unpredictable event, are most commonly evaluated and managed by non-gastroenterologists. Rapid and consistently reliable risk stratification of patients with acute GIB for urgent endoscopy may potentially improve outcomes amongst such patients by targeting scarce health-care resources to those who need it the most.
   Design and methods: Using ICD-9 codes for acute GIB, 189 patients with acute GIB and all. available data variables required to develop and test models were identified from a hospital medical records database. Data on 122 patients was utilized for development of the model and on 67 patients utilized to perform comparative analysis of the models. Clinical data such as presenting signs and symptoms, demographic data, presence of co-morbidities, laboratory data and corresponding endoscopic diagnosis and outcomes were collected. Clinical data and endoscopic diagnosis collected for each patient was utilized to retrospectively ascertain optimal management for each patient. Clinical presentations and corresponding treatment was utilized as training examples. Eight mathematical models including artificial neural network (ANN), support vector machine (SVM), k-nearest neighbor, linear discriminant analysis (LDA), shrunken centroid (SC), random forest (RF), logistic regression, and boosting were trained and tested. The performance of these models was compared using standard statistical analysis and ROC curves.
   Results: Overall the random forest model best predicted the source, need for resuscitation, and disposition with accuracies of approximately 80% or higher (accuracy for endoscopy was greater than 75%). The area under ROC curve for RF was greater than 0.85, indicating excellent performance by the random forest model Conclusion: While most mathematical models are effective as a decision support system for evaluation and management of patients with acute GIB, in our testing, the RF model consistently demonstrated the best performance. Amongst patients presenting with acute GIB, mathematical models may facilitate the identification of the source of GIB, need for intervention and allow optimization of care and healthcare resource allocation; these however require further validation. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Kumar, Atul] SUNY Stony Brook, US Dept Vet Affairs, Stony Brook, NY 11794 USA.
   [Chu, Adrienne; Ahn, Hongshik] SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA.
   [Halwan, Bhawna] Suny Downstate Med Ctr, Brooklyn, NY 11203 USA.
   [Kalmin, Bruce] Med Univ S Carolina, Div Gastroenterol, Charleston, SC 29425 USA.
   [Artifon, Everson L. A.] Univ Sao Paulo, Sch Med, Sao Paulo, Brazil.
   [Barkun, Alan] McGill Univ, Montreal, PQ H3A 2T5, Canada.
   [Lagoudakis, Michail G.] Tech Univ Crete, Intelligent Syst Lab, Dept Elect & Comp Engn, Kounoupidiana 73100, Chania Hellas, Greece.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; US Department of Veterans Affairs; State University
   of New York (SUNY) System; State University of New York (SUNY) Stony
   Brook; State University of New York (SUNY) System; State University of
   New York (SUNY) Downstate Medical Center; Medical University of South
   Carolina; Universidade de Sao Paulo; McGill University; Technical
   University of Crete
RP Kumar, A (通讯作者)，SUNY Stony Brook, US Dept Vet Affairs, Stony Brook, NY 11794 USA.
EM atul.kumar2@va.gov
RI Lagoudakis, Michail/C-5145-2008
CR Adler DG, 2004, GASTROINTEST ENDOSC, V60, P497
   Ahn H, 2007, COMPUT STAT DATA AN, V51, P6166, DOI 10.1016/j.csda.2006.12.043
   BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2
   Baradarian R, 2004, AM J GASTROENTEROL, V99, P619, DOI 10.1111/j.1572-0241.2004.04073.x
   Barkun A, 2003, ANN INTERN MED, V139, P843, DOI 10.7326/0003-4819-139-10-200311180-00012
   Blatchford O, 2000, LANCET, V356, P1318, DOI 10.1016/S0140-6736(00)02816-6
   BORDLEY DR, 1985, JAMA-J AM MED ASSOC, V253, P3282, DOI 10.1001/jama.253.22.3282
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   CHONG CF, 2003, P AMIA S         NOV, P160
   Corley DA, 1998, AM J GASTROENTEROL, V93, P336, DOI 10.1111/j.1572-0241.1998.00336.x
   Das A, 2004, GASTROINTEST ENDOSC, V60, P85, DOI 10.1016/S0016-5107(04)01291-X
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   ETTA GH, 2004, GASTROINTEST ENDOSC, V59, P402
   Hay JA, 1997, JAMA-J AM MED ASSOC, V278, P2151, DOI 10.1001/jama.278.24.2151
   Hay JA, 1996, AM J MED, V100, P313, DOI 10.1016/S0002-9343(97)89490-9
   Jonnalagadda S, 2003, GASTROINTEST ENDOSC, V57, P418, DOI 10.1067/mge.2003.128
   KATULA SZ, 2003, S AFR MED J, V93, P286
   Kennedy RL, 1997, COMPUT METH PROG BIO, V52, P93, DOI 10.1016/S0169-2607(96)01782-8
   KLEBT F, 2004, INT J COLORECTAT DIS, P19
   Lisboa PJG, 2002, NEURAL NETWORKS, V15, P11, DOI 10.1016/S0893-6080(01)00111-3
   Lund LH, 2004, ARCH INTERN MED, V164, P1698, DOI 10.1001/archinte.164.15.1698-a
   Molinaro AM, 2005, BIOINFORMATICS, V21, P3301, DOI 10.1093/bioinformatics/bti499
   MORTENSEN PB, 1994, DAN MED BULL, V41, P237
   Palmer KR, 2002, GUT, V51, P1
   Prakash C, 2003, GASTROINTEST ENDOSC, V58, P330, DOI 10.1016/S0016-5107(03)00003-8
   Quirk DM, 1997, GASTROENTEROLOGY, V113, P1443, DOI 10.1053/gast.1997.v113.pm9352845
   Rockall TA, 1996, LANCET, V347, P1138, DOI 10.1016/S0140-6736(96)90607-8
   ROCKALL TA, 1995, BRIT MED J, V311, P222, DOI 10.1136/bmj.311.6999.222
   Rockall TA, 1996, GUT, V38, P316, DOI 10.1136/gut.38.3.316
   Rosenblatt KP, 2004, ANNU REV MED, V55, P97, DOI 10.1146/annurev.med.55.091902.105237
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1007/BF00116037
   Selaru FM, 2002, GASTROENTEROLOGY, V122, P606, DOI 10.1053/gast.2002.31904
   Strate LL, 2003, ARCH INTERN MED, V163, P838, DOI 10.1001/archinte.163.7.838
   Terdiman JP, 1997, AM J GASTROENTEROL, V92, P1805
   Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299
   Timmerman D, 1999, ULTRASOUND OBST GYN, V13, P17, DOI 10.1046/j.1469-0705.1999.13010017.x
   VAPNIK V, 1995, NATURE STAT EARNING
   VETAYOS FS, 2004, CLIN GASTROENTEROL H, V2, P485
   Zaragoza Marcet A, 2002, Rev Esp Enferm Dig, V94, P139
   ZIMMERMAN J, 1995, SCAND J GASTROENTERO, V30, P327, DOI 10.3109/00365529509093285
NR 41
TC 48
Z9 50
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD MAR
PY 2008
VL 42
IS 3
BP 247
EP 259
DI 10.1016/j.artmed.2007.10.003
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 279UD
UT WOS:000254379400006
PM 18063351
DA 2023-04-20
ER

PT J
AU Lohscheller, J
   Eysholdt, U
   Toy, H
   Dollinger, M
AF Lohscheller, Joerg
   Eysholdt, Ulrich
   Toy, Hikmet
   Doellinger, Michael
TI Phonovibrography: Mapping high-speed movies of vocal fold vibrations
   into 2-D diagrams for visualizing and analyzing the underlying laryngeal
   dynamics
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE classification; computer aided analysis; evidence based medicine;
   high-speed laryngoscopy; visualization; vocal fold dynamics
ID CLASSIFICATION; PROTOCOL; MODEL
AB Endoscopic high-speed laryngoscopy in combination with image analysis strategies is the most promising approach to investigate the interrelation between vocal fold vibrations and voice disorders. So far, due to the lack of an objective and standardized analysis procedure a unique characterization of vocal fold vibrations has not been achieved yet. We present a visualization and analysis strategy which transforms the segmented edges of vibrating vocal folds into a single 2-D image, denoted Phonovibrogram (PVG). Within a PVG the individual type of vocal fold vibration becomes uniquely characterized by specific geometric patterns. The PVG geometries give an intuitive access on the type and degree of the laryngeal asymmetry and can be quantified using an image segmentation approach. The PVG analysis was applied to 14 representative recordings derived from a high-speed database comprising normal and pathological voices. We demonstrate that PVGs are capable to differentiate and quantify different types of normal and pathological vocal fold vibrations. The objective and precise quantification of the PVG geometry may have the potential to realize a novel classification of vocal fold vibrations.
C1 [Lohscheller, Joerg; Eysholdt, Ulrich; Toy, Hikmet; Doellinger, Michael] Univ Erlangen Nurnberg, Sch Med, Dept Phoniatr & Pediat Audiol, D-91054 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Lohscheller, J (通讯作者)，Univ Erlangen Nurnberg, Sch Med, Dept Phoniatr & Pediat Audiol, D-91054 Erlangen, Germany.
EM joerg.lohscheller@uk-erlangen.de
OI Doellinger, Michael/0000-0003-2717-4820
CR ALLIN S, 2004, BIOMED IMAG MACRO NA, V1, P812
   BLESS DM, 1987, EAR NOSE THROAT J, V66, P48
   Decker GZ, 2007, J VOICE, V21, P273, DOI 10.1016/j.jvoice.2005.12.002
   Dejonckere PH, 2001, EUR ARCH OTO-RHINO-L, V258, P77, DOI 10.1007/s004050000299
   Dollinger M, 2002, IEEE T BIO-MED ENG, V49, P773, DOI 10.1109/TBME.2002.800755
   Eysholdt U, 2003, EUR ARCH OTO-RHINO-L, V260, P412, DOI 10.1007/s00405-003-0606-y
   Eysholdt U, 2003, HNO, V51, P710, DOI 10.1007/s00106-003-0804-3
   Friedrich G, 2005, LARYNGO RHINO OTOL, V84, P744, DOI 10.1055/s-2005-861450
   Hertegard Stellan, 2005, Curr Opin Otolaryngol Head Neck Surg, V13, P152, DOI 10.1097/01.moo.0000163451.98079.ba
   HIROSE H, 1988, ACTA OTO-LARYNGOL, P151
   Hoppe U., 2001, MECH HOARSENESS VISU
   JIANG JJQ, 1994, J VOICE, V8, P132, DOI 10.1016/S0892-1997(05)80305-4
   Kendall Katherine A, 2005, Curr Opin Otolaryngol Head Neck Surg, V13, P135, DOI 10.1097/01.moo.0000162262.26868.df
   Larsson H, 2000, LARYNGOSCOPE, V110, P2117, DOI 10.1097/00005537-200012000-00028
   Lohscheller J, 2007, MED IMAGE ANAL, V11, P400, DOI 10.1016/j.media.2007.04.005
   Mergell P, 2000, J ACOUST SOC AM, V108, P2996, DOI 10.1121/1.1314398
   Neubauer J, 2001, J ACOUST SOC AM, V110, P3179, DOI 10.1121/1.1406498
   Qiu QJ, 2003, FOLIA PHONIATR LOGO, V55, P128, DOI 10.1159/000070724
   Rasp O, 2006, FOLIA PHONIATR LOGO, V58, P175, DOI 10.1159/000091731
   Schade G, 2005, HNO, V53, P1085, DOI 10.1007/s00106-005-1285-3
   Schuberth S, 2002, LARYNGOSCOPE, V112, P1043, DOI 10.1097/00005537-200206000-00020
   Schutte HK, 1998, LARYNGOSCOPE, V108, P1206, DOI 10.1097/00005537-199808000-00020
   Schwarz R, 2006, IEEE T BIO-MED ENG, V53, P1099, DOI 10.1109/TBME.2006.873396
   Svec JG, 1996, J VOICE, V10, P201, DOI 10.1016/S0892-1997(96)80047-6
   TITZE IR, 1976, J ACOUST SOC AM, V60, P1366, DOI 10.1121/1.381230
   Tokuda I, 2005, CHAOS, V15, DOI 10.1063/1.1848232
   WESTPHAL LC, 1983, IEEE T ACOUST SPEECH, V31, P766, DOI 10.1109/TASSP.1983.1164104
   Wittenberg T, 1995, MACH VISION APPL, V8, P399, DOI 10.1007/BF01213501
   Wurzbacher T, 2006, J ACOUST SOC AM, V120, P1012, DOI 10.1121/1.2211550
   Yan YL, 2005, J VOICE, V19, P161, DOI 10.1016/j.jvoice.2004.04.006
NR 30
TC 119
Z9 119
U1 0
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD MAR
PY 2008
VL 27
IS 3
BP 300
EP 309
DI 10.1109/TMI.2007.903690
PG 10
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA 268DK
UT WOS:000253558400002
PM 18334426
DA 2023-04-20
ER

PT J
AU Suzuki, K
   Yoshida, H
   Nappi, J
   Armato, SG
   Dachman, AH
AF Suzuki, Kenji
   Yoshida, Hiroyuki
   Naeppi, Janne
   Armato, Samuel G., III
   Dachman, Abraham H.
TI Mixture of expert 3D massive-training ANNs for reduction of multiple
   types of false positives in CAD for detection of polyps in CT
   colonography
SO MEDICAL PHYSICS
LA English
DT Article
DE virtual colonoscopy; colon cancer; mixture of expert networks; CT
   colonography; computer-aided diagnosis; false-positive reduction;
   artificial neural network
ID ARTIFICIAL NEURAL-NETWORK; COMPUTER-AIDED DIAGNOSIS; COLONIC POLYPS;
   LUNG NODULES; TOMOGRAPHIC COLONOGRAPHY; VIRTUAL COLONOSCOPY; VOLUMETRIC
   FEATURES; AUTOMATED DETECTION; CHEST RADIOGRAPHS; SMALL NUMBER
AB One of the major challenges in computer-aided detection (CAD) of polyps in CT colonography (CTC) is the reduction of false-positive detections (FPs) without a concomitant reduction in sensitivity. A large number of FPs is likely to confound the radiologist's task of image interpretation, lower the radiologist's efficiency, and cause radiologists to lose their confidence in CAD as a useful tool. Major sources of FPs generated by CAD schemes include haustral folds, residual stool, rectal tubes, the ileocecal valve, and extra-colonic structures such as the small bowel and stomach. Our purpose in this study was to develop a method for the removal of various types of FPs in CAD of polyps while maintaining a high sensitivity. To achieve this, we developed a "mixture of expert" three-dimensional (3D) massive-training artificial neural networks (MTANNs) consisting of four 3D MTANNs that were designed to differentiate between polyps and four categories of FPs: (1) rectal tubes, (2) stool with bubbles, (3) colonic walls with haustral folds, and (4) solid stool. Each expert 3D MTANN was trained with examples from a specific non-polyp category along with typical polyps. The four expert 3D MTANNs were combined with a mixing artificial neural network (ANN) such that different types of FPs could be removed. Our database consisted of 146 CTC datasets obtained from 73 patients whose colons were prepared by standard pre-colonoscopy cleansing. Each patient was scanned in both supine and prone positions. Radiologists established the locations of polyps through the use of optical-colonoscopy reports. Fifteen patients had 28 polyps, 15 of which were 5-9 mm and 13 were 10-25 mm in size. The CTC cases were subjected to our previously reported CAD method consisting of centerline-based extraction of the colon, shape-based detection of polyp candidates, and a Bayesian-ANN-based classification of polyps. The original CAD method yielded 96.4% (27/28) by-polyp sensitivity with an average of 3.1 (224/73) FPs per patient. The mixture of expert 3D MTANNs removed 63% (142/224) of the FPs without the loss of any true positive; thus, the FP rate of our CAD scheme was improved to 1.1 (82/73) FPs per patient while the original sensitivity was maintained. By use of the mixture of expert 3D MTANNs, the specificity of a CAD scheme for detection of polyps in CTC was substantially improved while a high sensitivity was maintained. (C) 2008 American Association of Physicists in Medicine.
C1 [Suzuki, Kenji; Armato, Samuel G., III; Dachman, Abraham H.] Univ Chicago, Dept Radiol, Chicago, IL 60637 USA.
   [Yoshida, Hiroyuki; Naeppi, Janne] Harvard Univ, Massachusetts Gen Hosp, Dept Radiol, Boston, MA 02114 USA.
   [Yoshida, Hiroyuki; Naeppi, Janne] Harvard Univ, Sch Med, Boston, MA 02114 USA.
C3 University of Chicago; Harvard University; Massachusetts General
   Hospital; Harvard University; Harvard Medical School
RP Suzuki, K (通讯作者)，Univ Chicago, Dept Radiol, 5841 S Maryland Ave, Chicago, IL 60637 USA.
EM suzuki@uchicago.edu
RI Suzuki, Kenji/A-1284-2007; Näppi, Janne J/B-9424-2008
OI Suzuki, Kenji/0000-0002-3993-8309; Näppi, Janne J/0000-0002-0108-0992;
   Dachman, Abraham/0000-0002-7035-2752
FU NCI NIH HHS [R01CA120549] Funding Source: Medline
CR Acar B, 2002, IEEE T MED IMAGING, V21, P1461, DOI 10.1109/TMI.2002.806405
   Arimura H, 2004, ACAD RADIOL, V11, P617, DOI 10.1016/j.acra.2004.02.009
   Bishop Christopher M., 1995, NEURAL NETWORKS PATT, DOI DOI 10.5555/235248
   Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805
   DACHMAN A, 2003, ATLAS VIRTUAL COLONO
   Edwards DC, 2002, MED PHYS, V29, P2861, DOI 10.1118/1.1524631
   EGAN JP, 1961, J ACOUST SOC AM, V33, P993, DOI 10.1121/1.1908935
   Fletcher JG, 2005, CURR OPIN GASTROEN, V21, P90
   Frimmel H, 2004, MED PHYS, V31, P3046, DOI 10.1118/1.1790111
   FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   HANLEY JA, 1983, RADIOLOGY, V148, P839, DOI 10.1148/radiology.148.3.6878708
   Iordanescu G, 2004, MED PHYS, V31, P2855, DOI 10.1118/1.1790131
   Jemal A, 2005, CA-CANCER J CLIN, V55, P10, DOI 10.3322/canjclin.55.1.10
   Jerebko AK, 2003, ACAD RADIOL, V10, P154, DOI 10.1016/S1076-6332(03)80039-9
   Jerebko AK, 2005, ACAD RADIOL, V12, P479, DOI 10.1016/j.acra.2004.04.024
   Jerebko AK, 2003, MED PHYS, V30, P52, DOI 10.1118/1.1528178
   Johnson CD, 2000, RADIOLOGY, V216, P331, DOI 10.1148/radiology.216.2.r00au47331
   Kiss G, 2002, EUR RADIOL, V12, P77, DOI 10.1007/s003300101040
   Kupinski MA, 2001, IEEE T MED IMAGING, V20, P886, DOI 10.1109/42.952727
   Macari M, 2005, RADIOLOGY, V237, P819, DOI 10.1148/radiol.2373041717
   Metz CE, 1998, MED DECIS MAKING, V18, P110, DOI 10.1177/0272989X9801800118
   Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.3.CO;2-Q
   METZ CE, 1986, INVEST RADIOL, V21, P720, DOI 10.1097/00004424-198609000-00009
   Mosier CI, 1951, EDUC PSYCHOL MEAS, V11, P5, DOI 10.1177/001316445101100101
   Nappi J, 2004, PROC SPIE, V5370, P839, DOI 10.1117/12.536127
   Nappi J, 2003, MED PHYS, V30, P1592, DOI 10.1118/1.1576393
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   Nappi J, 2005, ACAD RADIOL, V12, P695, DOI 10.1016/j.acra.2004.12.026
   OJA E, 1983, SUBSPACE METHODS PAT
   Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362
   Summers RM, 2001, RADIOLOGY, V219, P51, DOI 10.1148/radiology.219.1.r01ap0751
   Summers RM, 2004, RADIOLOGY, V233, P266, DOI 10.1148/radiol.2331031326
   Summers RM, 2005, GASTROENTEROLOGY, V129, P1832, DOI 10.1053/j.gastro.2005.08.054
   Suzuki K, 2006, IEEE T MED IMAGING, V25, P406, DOI 10.1109/TMI.2006.871549
   Suzuki K, 2005, IEEE T MED IMAGING, V24, P1138, DOI 10.1109/TMI.2005.852048
   Suzuki K, 2005, ACAD RADIOL, V12, P1333, DOI 10.1016/j.acra.2005.06.017
   Suzuki K, 2005, ACAD RADIOL, V12, P191, DOI 10.1016/j.acra.2004.11.017
   Suzuki K, 2004, IEEE T MED IMAGING, V23, P330, DOI 10.1109/TMI.2004.824238
   Suzuki K, 2003, IEEE T PATTERN ANAL, V25, P1582, DOI 10.1109/TPAMI.2003.1251151
   Suzuki K, 2003, PROC SPIE, V5032, P1355, DOI 10.1117/12.480181
   Suzuki K, 2003, MED PHYS, V30, P1602, DOI 10.1118/1.1580485
   Suzuki K, 2002, IEICE T INF SYST, VE85D, P1710
   Suzuki K, 2002, IEEE T SIGNAL PROCES, V50, P1787, DOI 10.1109/TSP.2002.1011218
   Suzuki K, 2001, NEURAL PROCESS LETT, V13, P43, DOI 10.1023/A:1009639214138
   Suzuki K, 2006, MED PHYS, V33, P3814, DOI 10.1118/1.2349839
   Suzuki K, 2004, J NEURAL ENG, V1, P228, DOI 10.1088/1741-2560/1/4/006
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Winawer SJ, 1997, GASTROENTEROLOGY, V112, P594, DOI 10.1053/gast.1997.v112.agast970594
   Yoshida H, 2005, ABDOM IMAGING, V30, P26, DOI 10.1007/s00261-004-0244-x
   Yoshida H, 2004, SEMIN ULTRASOUND CT, V25, P419, DOI 10.1053/j.sult.2004.07.002
   Yoshida H, 2002, RADIOGRAPHICS, V22, P963, DOI 10.1148/radiographics.22.4.g02jl16963
   Yoshida H, 2002, RADIOLOGY, V222, P327, DOI 10.1148/radiol.2222010506
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
NR 54
TC 71
Z9 74
U1 0
U2 10
PU AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0094-2405
J9 MED PHYS
JI Med. Phys.
PD FEB
PY 2008
VL 35
IS 2
BP 694
EP 703
DI 10.1118/1.2829870
PG 10
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA 264VL
UT WOS:000253318400032
PM 18383691
DA 2023-04-20
ER

PT J
AU Das, A
   Ben-Menachem, T
   Farooq, FT
   Cooper, GS
   Chak, A
   Sivak, MV
   Wong, RCK
AF Das, Ananya
   Ben-Menachem, Tamir
   Farooq, Farees T.
   Cooper, Gregory S.
   Chak, Amitabh
   Sivak, Michael V., Jr.
   Wong, Richard C. K.
TI Artificial neural network as a predictive instrument in patients with
   acute nonvariceal upper gastrointestinal hemorrhage
SO GASTROENTEROLOGY
LA English
DT Article; Proceedings Paper
CT Digestive Disease Week Meeting/108th Annual Meeting of the
   American-Gastroenterological-Association
CY MAY 19-25, 2007
CL Washington, DC
SP Amer Gastroenterol Assoc, Amer Assoc Study Liver Dis, Amer Soc Gastrointestinal Endoscopy, Soc Surg Alimentary Tract
ID DECISION-SUPPORT-SYSTEMS; RANDOMIZED CONTROLLED-TRIAL;
   MYOCARDIAL-INFARCTION; SCORING SYSTEM; VALIDATION; EPIDEMIOLOGY;
   PERFORMANCE; ENDOSCOPY; DIAGNOSIS; OUTCOMES
AB Background & Aim: Triage of patients with acute upper gastrointestinal hemorrhage (UGIH) has traditionally required urgent upper endoscopy. The aim of this study is to evaluate the use of artificial neural network for nonendoscopic triage. Methods: A cohort of 387 patients was used to train (n = 194) and internally validate (n = 193) the neural network, which was then externally validated in 200 patients and compared with the clinical and complete Rockall score. Two outcome variables were assessed: major stigmata of recent hemorrhage and need for endoscopic therapy. Patient cohort data from 2 independent tertiary-care medical centers were prospectively collected. Adult patients hospitalized at both sites during the same time period with a primary diagnosis of acute nonvariceal UGIH. Results: In predicting the 2 measured outcomes, sensitivity of neural network was >80%, with high negative predictive values (92-96%) in both cohorts but with lower specificity in the external cohort. Both Rockall scores had adequate sensitivity (> 80%) but poor specificity (< 40%) at outcome prediction. Comparing areas under receiver operating characteristic curves, the clinical Rockall score was significantly inferior to neural network in both cohorts (<= 0.65 vs. >= 0.78), while in the external cohort, neural network performed similarly to the complete Rockall score ( >= 0.78). Conclusions: In acute nonvariceal UGIH, artificial neural network (nonendoscopic triage) performed as well as the complete Rockall score (endoscopic triage) at predicting stigmata of recent hemorrhage and need for endoscopic therapy, even when tested in an external patient population.
C1 [Das, Ananya] Mayo Clin Arizona, Div Gastroenterol, Scottsdale, AZ USA.
   [Ben-Menachem, Tamir] UMDNJ, Robert Wood Johnson Med Sch, New Brunswick, NJ USA.
   [Farooq, Farees T.; Cooper, Gregory S.; Chak, Amitabh; Sivak, Michael V., Jr.; Wong, Richard C. K.] Case Western Reserve Univ, Univ Hosp Case Med Ctr, Cleveland, OH 44106 USA.
C3 Mayo Clinic; Mayo Clinic Phoenix; Rutgers State University New
   Brunswick; Rutgers State University Medical Center; Case Western Reserve
   University; Case Western Reserve University Hospital
RP Wong, RCK (通讯作者)，Univ Hosp Case Med Ctr, Dept Med, Div Gastroenterol, 11100 Euclid Ave, Cleveland, OH 44106 USA.
EM richard.wong@UHhospitals.org
CR Barkun A, 2003, ANN INTERN MED, V139, P843, DOI 10.7326/0003-4819-139-10-200311180-00012
   BAXT WG, 1992, ANN EMERG MED, V21, P1439, DOI 10.1016/S0196-0644(05)80056-3
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   BAXT WG, 1991, ANN INTERN MED, V115, P843, DOI 10.7326/0003-4819-115-11-843
   Bishop Christopher M., 1995, NEURAL NETWORKS PATT, DOI DOI 10.5555/235248
   Blatchford O, 2000, LANCET, V356, P1318, DOI 10.1016/S0140-6736(00)02816-6
   Chan HP, 1999, MED PHYS, V26, P2654, DOI 10.1118/1.598805
   Cipolletta L, 2002, GASTROINTEST ENDOSC, V55, P1, DOI 10.1067/mge.2002.119219
   Classen DC, 1998, JAMA-J AM MED ASSOC, V280, P1360, DOI 10.1001/jama.280.15.1360
   CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2
   Cui YJ, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3444
   Das A, 2004, GASTROINTEST ENDOSC, V60, P85, DOI 10.1016/S0016-5107(04)01291-X
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Enns RA, 2006, WORLD J GASTROENTERO, V12, P7779, DOI 10.3748/wjg.v12.i48.7779
   Esrailian E, 2005, GASTROENTEROL CLIN N, V34, P589, DOI 10.1016/j.gtc.2005.08.006
   Fallah MA, 2000, MED CLIN N AM, V84, P1183, DOI 10.1016/S0025-7125(05)70282-0
   GILBERT DA, 1990, GASTROINTEST ENDOSC, V36, pS8
   Gralnek IM, 2004, GASTROINTEST ENDOSC, V60, P9, DOI 10.1016/S0016-5107(04)01524-X
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Haykin SS, 1999, NEURAL NETWORKS COMP
   Hunt DL, 1998, JAMA-J AM MED ASSOC, V280, P1339, DOI 10.1001/jama.280.15.1339
   JOHNSTON ME, 1994, ANN INTERN MED, V120, P135, DOI 10.7326/0003-4819-120-2-199401150-00007
   Klenzak JS, 1996, GASTROINTEST ENDOSC, V43, P247
   Laine L, 1996, GASTROINTEST ENDOSC, V43, P107, DOI 10.1016/S0016-5107(06)80109-4
   Lee JG, 1999, GASTROINTEST ENDOSC, V50, P755, DOI 10.1016/S0016-5107(99)70154-9
   LONGSTRETH GF, 1995, AM J GASTROENTEROL, V90, P206
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Morris AH, 2000, ANN INTERN MED, V132, P373, DOI 10.7326/0003-4819-132-5-200003070-00007
   Rockall TA, 1996, LANCET, V347, P1138, DOI 10.1016/S0140-6736(96)90607-8
   Rockall TA, 1996, GUT, V38, P316, DOI 10.1136/gut.38.3.316
   ROCKALL TA, 1995, LANCET, V346, P346, DOI 10.1016/S0140-6736(95)92227-X
   SAEED ZA, 1995, GASTROINTEST ENDOSC, V41, P561, DOI 10.1016/S0016-5107(95)70191-5
   Targownik LE, 2006, CLIN GASTROENTEROL H, V4, P1459, DOI 10.1016/j.cgh.2006.08.018
   Tham TCK, 2006, POSTGRAD MED J, V82, P757, DOI 10.1136/pmj.2006.048462
   van Leerdam ME, 2003, AM J GASTROENTEROL, V98, P1494, DOI 10.1016/S0002-9270(03)00299-5
   Vreeburg EM, 1999, GUT, V44, P331, DOI 10.1136/gut.44.3.331
NR 37
TC 47
Z9 48
U1 0
U2 3
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD JAN
PY 2008
VL 134
IS 1
BP 65
EP 74
DI 10.1053/j.gastro.2007.10.037
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Gastroenterology & Hepatology
GA 247GO
UT WOS:000252066400014
PM 18061180
OA Bronze
DA 2023-04-20
ER

PT J
AU Andriulli, A
   Grossi, E
   Buscema, M
   Pilotto, A
   Festa, V
   Perri, F
AF Andriulli, Angelo
   Grossi, Enzo
   Buscema, Massimo
   Pilotto, Alberto
   Festa, Virginia
   Perri, Francesco
TI Artificial neural networks can classify uninvestigated patients with
   dyspepsia
SO EUROPEAN JOURNAL OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Review
DE artificial intelligence; artificial neural networks; dyspepsia; H.
   pylori infection
ID CLASSIFICATION
AB There is consensus on investigating older patients presenting with or without alarm symptoms and/or risk factors, and irrespective of their Helicobacter pylori status. Remaining patients with uninvestigated dyspepsia, however, represents a 'grey' population for whom no clearly defined guidelines have been delineated. Physicians often struggle with the decision of whether or not to undertake noninvasive testing, treat dyspeptic patients empirically or perform an invasive endoscopy of the upper gastrointestinal tract. We have explored the contribution of artificial neural networks (ANNs) to provide appropriate interpretation of presenting complaints and clinical characteristics for these patients. By taking into account all the 86 recorded features of 101 dyspeptic patients, the overall predictive capability of ANNs in sorting out organic from functional disease amounted to 74.2% and increased to a figure of 85.0% when only the 55 best performing input variables were analyzed. The ANNs performed much better in extracting those patients with a functional dyspepsia (90% accuracy rate), but even in patients with organic disease the 80% accuracy value was remarkable. In patients with an uninvestigated dyspepsia, ANNs found a unique combination of socioenvironmental data, past medical history, risk factors for organic disease, and presenting abdominal complaints that each patient brings to the clinical encounter. With this ability, ANNs can be used to assist in the classification and treatment of patients with uninvestigated dyspepsia, and to bring a greater level of confidence to this process.
C1 [Andriulli, Angelo; Pilotto, Alberto; Festa, Virginia; Perri, Francesco] Casa Sollievo Sofferenza Hosp, IRCCS, Div Gastroenterol, I-71013 San Giovanni Rotondo, Italy.
   [Grossi, Enzo] Bracco Imaging SpA, Med Affairs Europe, Milan, Italy.
   [Buscema, Massimo] Seme Res Ctr Sci & Commun, Rome, Italy.
C3 IRCCS Casa Sollievo Della Sofferenza; Bracco
RP Andriulli, A (通讯作者)，Casa Sollievo Sofferenza Hosp, IRCCS, Div Gastroenterol, Viale Cappuccini 1, I-71013 San Giovanni Rotondo, Italy.
EM a.andriulli@operapadrepio.it
RI Perri, Francesco/AAF-4659-2020; Andriulli, Angelo/B-5027-2017; Grossi,
   Enzo/AAF-7765-2020
OI Perri, Francesco/0000-0001-8314-8016; Andriulli,
   Angelo/0000-0001-8862-7083; GROSSI, ENZO/0000-0003-0346-2684; Buscema,
   Paolo Massimo/0000-0003-4356-0510
CR Andriulli A, 2003, DIGEST LIVER DIS, V35, P222, DOI 10.1016/S1590-8658(03)00057-4
   Buscema M, 2005, ARTIF INTELL MED, V34, P279, DOI 10.1016/j.artmed.2004.12.001
   BUSCEMA M, 2000, 25 SEM
   El-Serag HB, 2004, ALIMENT PHARM THER, V19, P643, DOI 10.1111/j.1365-2036.2004.01897.x
   Fransen GAJ, 2004, ALIMENT PHARM THERAP, V20, P1045, DOI 10.1111/j.1365-2036.2004.02251.x
   *NAT GUID RES DEV, 2004, DYSP MAN AD PRIM CAR
   Schmidt N, 2005, ALIMENT PHARM THER, V21, P813, DOI 10.1111/j.1365-2036.2005.02425.x
   Talley NJ, 1998, GASTROENTEROLOGY, V114, P582, DOI 10.1016/S0016-5085(98)70542-6
   van Zanten SJOV, 2000, CAN MED ASSOC J, V162, pS3
NR 9
TC 4
Z9 4
U1 0
U2 5
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0954-691X
EI 1473-5687
J9 EUR J GASTROEN HEPAT
JI Eur. J. Gastroenterol. Hepatol.
PD DEC
PY 2007
VL 19
IS 12
BP 1055
EP 1058
DI 10.1097/MEG.0b013e3282f198b2
PG 4
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 279LN
UT WOS:000254356800006
PM 17998828
DA 2023-04-20
ER

PT J
AU Horowitz, N
   Moshkowitz, M
   Halpern, Z
   Leshno, M
AF Horowitz, Noya
   Moshkowitz, Menachem
   Halpern, Zamir
   Leshno, Moshe
TI Applying data mining techniques in the development of a diagnostics
   questionnaire for GERD
SO DIGESTIVE DISEASES AND SCIENCES
LA English
DT Article
ID GASTROESOPHAGEAL-REFLUX DISEASE; INITIAL VALIDATION; SYMPTOM
   QUESTIONNAIRE; DYSPEPSIA; TOOL; OMEPRAZOLE; SUBGROUPS; SEVERITY
AB Gastroesophageal reflux disease (GERD) is a common condition, managed mostly in primary care practice. Heartburn and acid regurgitation are considered primary symptoms, and are usually highly specific. However, the symptom spectrum is much wider and in many cases it is difficult to determine whether the patient has GERD or dyspepsia from another origin. The aim of this study is to develop a symptom score and rule for the diagnosis of GERD, using data mining techniques, to provide a clinical diagnostic tool for primary care practitioners in the evaluation and management of upper gastrointestinal symptoms. A diagnostic symptom questionnaire consisting of 15 items and based on the current literature was designed to measure the presence and severity of reflux and dyspepsia symptoms using a 5-point Likert-type scale. A total of 132 subjects with uninvestigated upper abdominal symptoms were prospectively recruited for symptom evaluation. All patients were interviewed and examined, underwent upper gastrointestinal endoscopy, and completed the questionnaire. Based on endoscopic findings as well as the medical interview, the subjects were classified as having reflux disease (GERD) or non-reflux disease (non-GERD). Data mining models and algorithms (neural networks, decision trees, and logistic regression) were used to build a short and simple new discriminative questionnaire. The most relevant variables discriminating GERD from non-GERD patients were heartburn, regurgitation, clinical response to antacids, sour taste, and aggravation of symptoms after a heavy meal. The sensitivity and specificity of the new symptom score were 70%-75% and 63%-78%, respectively. The area under the ROC curve for logistic regression and neural networks were 0.783 and 0.787, respectively. We present a new validated discriminative GERD questionnaire using data mining techniques. The questionnaire is useful, friendly, and short, and therefore can be easily applied in clinical practice for choosing the appropriate diagnostic workup for patients with upper gastrointestinal complaints.
C1 Tel Aviv Univ, Fac Management, IL-69978 Tel Aviv, Israel.
   Tel Aviv Sourasky Med Ctr, Dept Gastroenterol & Liver Dis, Tel Aviv, Israel.
   Tel Aviv Univ, Sackler Fac Med, IL-69978 Tel Aviv, Israel.
   Tel Aviv Univ, Fac Management, IL-69978 Tel Aviv, Israel.
C3 Tel Aviv University; Tel Aviv University; Sackler Faculty of Medicine;
   Tel Aviv Sourasky Medical Center; Tel Aviv University; Sackler Faculty
   of Medicine; Tel Aviv University
RP Leshno, M (通讯作者)，Tel Aviv Univ, Fac Management, IL-69978 Tel Aviv, Israel.
EM leshnom@post.tau.ac.il
CR Allen CJ, 2000, DIS ESOPHAGUS, V13, P265, DOI 10.1046/j.1442-2050.2000.00129.x
   Armstrong D, 1996, GASTROENTEROLOGY, V111, P85, DOI 10.1053/gast.1996.v111.pm8698230
   Brown WH, 2003, J CLIN GASTROENTEROL, V36, P222, DOI 10.1097/00004836-200303000-00008
   Carlsson R, 2000, BEST PRACT RES CL GA, V14, P827, DOI 10.1053/bega.2000.0127
   Carlsson R, 1998, SCAND J GASTROENTERO, V33, P1023
   ElOmar EM, 1996, EUR J GASTROEN HEPAT, V8, P967, DOI 10.1097/00042737-199610000-00006
   Fass R, 1999, ARCH INTERN MED, V159, P2161, DOI 10.1001/archinte.159.18.2161
   Fass R, 2001, AM J GASTROENTEROL, V96, P303
   GRAINGER SL, 1994, POSTGRAD MED J, V70, P154, DOI 10.1136/pgmj.70.821.154
   Hand D., 2001, ADAP COMP MACH LEARN
   Junghard O, 1998, EUR J SURG, V164, P106
   KLINELEIDY N, 2000, DIGEST DIS SCI, V45, P1172
   Klosgen W., 2002, HDB DATA MINING KNOW
   Kolodny M, 1998, EUR J SURG, V164, P104, DOI 10.1080/11024159850191346
   LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5
   LOCKE GR, 1994, MAYO CLIN PROC, V69, P539, DOI 10.1016/S0025-6196(12)62245-9
   Manterola C, 2002, J CLIN EPIDEMIOL, V55, P1041, DOI 10.1016/S0895-4356(02)00454-7
   Moayyedi P, 1998, ALIMENT PHARM THER, V12, P1257
   Moayyedi P, 1999, AM J GASTROENTEROL, V94, P3122, DOI 10.1111/j.1572-0241.1999.01502.x
   Mujica VR, 1999, POSTGRAD MED, V105, P53, DOI 10.3810/pgm.1999.01.498
   Numans ME, 2003, ALIMENT PHARM THER, V17, P1049, DOI 10.1046/j.1365-2036.2003.01549.x
   Ofman JJ, 2003, AM J GASTROENTEROL, V98, pS8, DOI 10.1016/S0002-9270(03)00010-8
   Ofman JJ, 2002, DIGEST DIS SCI, V47, P1863, DOI 10.1023/A:1016421401519
   Rothman M, 2001, DIGEST DIS SCI, V46, P1540, DOI 10.1023/A:1010660425522
   Schenk BE, 1997, AM J GASTROENTEROL, V92, P1997
   Shaw M, 2004, GUT, V53, P25, DOI 10.1136/gut.2003.034280
   Shaw M, 1998, ALIMENT PHARM THERAP, V12, P1067
   Shaw MJ, 2001, AM J GASTROENTEROL, V96, P52
   SMALL PK, 1995, GUT, V36, P189, DOI 10.1136/gut.36.2.189
   Stanghellini V, 1999, AM J GASTROENTEROL, V94, P2080
   Stanghellini V, 2004, ALIMENT PHARM THER, V19, P463, DOI 10.1046/j.1365-2036.2004.01861.x
   Stanghellini V, 2003, DIGEST LIVER DIS, V35, P843, DOI 10.1016/j.dld.2003.09.003
   TALLEY NJ, 1987, GUT, V28, P40, DOI 10.1136/gut.28.1.40
   TALLEY NJ, 1995, AUST NZ J MED, V25, P302, DOI 10.1111/j.1445-5994.1995.tb01894.x
   TALLEY NJ, 1993, GASTROENTEROLOGY, V105, P1378, DOI 10.1016/0016-5085(93)90142-Y
   TALLEY NJ, 1989, ANN INTERN MED, V111, P671, DOI 10.7326/0003-4819-111-8-671
   Tibshirani R., 2001, ELEMENTS STAT LEARNI
   Wallace MB, 2001, GUT, V49, P29, DOI 10.1136/gut.49.1.29
   WEUSTEN BLAM, 1994, GASTROENTEROLOGY, V107, P1741, DOI 10.1016/0016-5085(94)90815-X
   Wong WM, 2003, ALIMENT PHARM THER, V17, P1407, DOI 10.1046/j.1365-2036.2003.01576.x
NR 40
TC 17
Z9 19
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0163-2116
EI 1573-2568
J9 DIGEST DIS SCI
JI Dig. Dis. Sci.
PD AUG
PY 2007
VL 52
IS 8
BP 1871
EP 1878
DI 10.1007/s10620-006-9202-5
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 185UN
UT WOS:000247736000022
PM 17420944
DA 2023-04-20
ER

PT J
AU Lohscheller, J
   Toy, H
   Rosanowski, F
   Eysholdt, U
   Dollinger, M
AF Lohscheller, Joerg
   Toy, Hikmet
   Rosanowski, Frank
   Eysholdt, Ulrich
   Doellinger, Michael
TI Clinically evaluated procedure for the reconstruction of vocal fold
   vibrations from endoscopic digital high-speed videos
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE high-speed imaging; vocal folds; image segmentation; clinical
   application
ID VOICE; VIDEOKYMOGRAPHY; GLOTTOGRAPHY; KYMOGRAPHY; DYNAMICS; IMAGES;
   CHEST; PITCH
AB Investigation of voice disorders requires the examination of vocal fold vibrations. State of the art is the recording of endoscopic highspeed movies which capture vocal fold vibrations in real-time. It enables investigating the interrelation between disturbances of vocal fold vibrations and voice disorders. However, the lack of clinical studies and of a standardized procedure to reconstruct vocal fold vibrations from high-speed videos constrain the clinical acceptance of the high-speed technique.
   An image processing approach is presented that extracts the vibrating vocal fold edges from digital high-speed movies. The initial segmentation is principally based on a seeded region-growing algorithm. Even in movies with low image quality the algorithm segments successfully the glottal area by an introduced two-dimensional threshold matrix. Following segmentation, the vocal fold edges are reconstructed from the computed time-varying glottal area. The performance of the procedure was objectively evaluated within a study comprising 372 high-speed recordings. The accuracy of vocal fold reconstruction exceeds manual segmentation results obtained by clinical experts. The algorithm reaches an information flow-rate of up to 98 images per second. The robustness and high accuracy of the procedure makes it suitable for the application in clinical routine. It enables an objective and highly accurate description of vocal fold vibrations which is essential to realize extensive clinical studies which focus on the classification of voice disorders. (c) 2007 Elsevier B.V. All rights reserved.
C1 Dept Phoniat & Pediat Audiol, D-91054 Erlangen, Germany.
RP Lohscheller, J (通讯作者)，Dept Phoniat & Pediat Audiol, Bohlenpl 21, D-91054 Erlangen, Germany.
EM Joerg.Lohscheller@phoni.imed.uni-erlangen.de
OI Doellinger, Michael/0000-0003-2717-4820
CR BAER T, 1983, J ACOUST SOC AM, V73, P1304, DOI 10.1121/1.389279
   Betke M, 2003, MED IMAGE ANAL, V7, P265, DOI 10.1016/S1361-8415(03)00007-0
   Bless D M, 1987, Ear Nose Throat J, V66, P289
   Chaturvedi A, 2005, PHYS MED BIOL, V50, P1405, DOI 10.1088/0031-9155/50/7/005
   Dollinger M, 2005, METHOD INFORM MED, V44, P384
   Dollinger M, 2003, METHOD INFORM MED, V42, P271
   Eysholdt U, 2003, EUR ARCH OTO-RHINO-L, V260, P412, DOI 10.1007/s00405-003-0606-y
   Eysholdt U, 2003, HNO, V51, P710, DOI 10.1007/s00106-003-0804-3
   Eysholdt U, 1996, FOLIA PHONIATR LOGO, V48, P163, DOI 10.1159/000266404
   Hertegard Stellan, 2005, Curr Opin Otolaryngol Head Neck Surg, V13, P152, DOI 10.1097/01.moo.0000163451.98079.ba
   Hertegard Stellan, 2003, Logoped Phoniatr Vocol, V28, P133, DOI 10.1080/14015430310015246
   HIRANO M, 1970, FOLIA PHONIATR, V22, P1, DOI 10.1159/000263363
   HIROSE H, 1988, ACTA OTO-LARYNGOL, P151
   Hoppe U, 2003, J VOICE, V17, P370, DOI 10.1067/S0892-1997(03)00019-5
   HOPPE U, 2001, P 22 C UN EUR PHON F
   ISSHIKI N, 1977, ANN OTO RHINOL LARYN, V86, P58, DOI 10.1177/000348947708600109
   Larsson H, 2000, LARYNGOSCOPE, V110, P2117, DOI 10.1097/00005537-200012000-00028
   Lindestad Per-Ake, 2004, Logoped Phoniatr Vocol, V29, P162, DOI 10.1080/14015430410020339
   Lohscheller J, 2004, IEEE T BIO-MED ENG, V51, P1394, DOI 10.1109/TBME.2004.827938
   Mergell P, 2000, J ACOUST SOC AM, V108, P2996, DOI 10.1121/1.1314398
   Miyaji M, 1999, Nihon Jibiinkoka Gakkai Kaiho, V102, P354
   Plant RL, 2005, LARYNGOSCOPE, V115, P2087, DOI 10.1097/01.mlg.0000184324.45040.17
   Qiu QJ, 2003, FOLIA PHONIATR LOGO, V55, P128, DOI 10.1159/000070724
   Rasp O, 2006, FOLIA PHONIATR LOGO, V58, P175, DOI 10.1159/000091731
   Ruben RJ, 2000, LARYNGOSCOPE, V110, P241, DOI 10.1097/00005537-200002010-00010
   Schade G, 2005, HNO, V53, P1085, DOI 10.1007/s00106-005-1285-3
   Schilham AMR, 2006, MED IMAGE ANAL, V10, P247, DOI 10.1016/j.media.2005.09.003
   Scholl I., 1997, ADV QUANTITATIVE LAR, P29
   Schuster M, 2006, EUR ARCH OTO-RHINO-L, V263, P188, DOI 10.1007/s00405-005-0974-6
   Schuster M, 2005, EUR ARCH OTO-RHINO-L, V262, P477, DOI 10.1007/s00405-004-0862-5
   Svec JG, 1996, J VOICE, V10, P201, DOI 10.1016/S0892-1997(96)80047-6
   Thomson SL, 2005, J ACOUST SOC AM, V118, P1689, DOI 10.1121/1.2000787
   Tigges M, 1999, COMPUT MED IMAG GRAP, V23, P323, DOI 10.1016/S0895-6111(99)00030-0
   Titze I. R., 1994, PRINCIPLES VOICE PRO
   TITZE IR, 1976, J ACOUST SOC AM, V60, P1366, DOI 10.1121/1.381230
   Wittenberg T, 1995, MACH VISION APPL, V8, P399, DOI 10.1007/BF01213501
   WOOD SA, 1995, COMPUT MED IMAG GRAP, V19, P145, DOI 10.1016/0895-6111(94)00034-4
   World Health Organization, 2006, INT CLASS DIS REL HL
   Yan YL, 2005, J VOICE, V19, P161, DOI 10.1016/j.jvoice.2004.04.006
   Zhang K, 2006, J ACOUST SOC AM, V119, P1050, DOI 10.1121/1.2159433
NR 40
TC 122
Z9 122
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1361-8415
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD AUG
PY 2007
VL 11
IS 4
BP 400
EP 413
DI 10.1016/j.media.2007.04.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA 201VQ
UT WOS:000248861100007
PM 17544839
DA 2023-04-20
ER

PT J
AU Kodogiannis, VS
   Boulougoura, M
   Wadge, E
   Lygouras, JN
AF Kodogiannis, V. S.
   Boulougoura, M.
   Wadge, E.
   Lygouras, J. N.
TI The usage of soft-computing methodologies in interpreting capsule
   endoscopy
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE endoscopic image; fusion; computer aided diagnosis; neural network;
   feature extraction; texture; fuzzy systems
ID CLASSIFICATION; MICROSYSTEMS; DIAGNOSIS; ALGORITHM; LESIONS; SYSTEM
AB Computerised processing of medical images can ease the search of the representative features in the images. The endoscopic images possess rich information expressed by texture and regions affected by diseases, such as ulcer or coli, may have different texture features. In this paper schemes have been developed to extract features from the texture spectra in the chromatic and achromatic domains for a selected region of interest from each colour component histogram of images acquired by the M2A Swallowable Imaging Capsule. The implementation of neural network schemes and the concept of fusion of multiple classifiers have been also adopted in this paper. The preliminary test results support the feasibility of the proposed method. (c) 2006 Elsevier Ltd. All rights reserved.
C1 Univ Westminster, Ctr Syst Anal, Sch Comp Sci, London HA1 3TP, England.
   IBM Hellas SA, GR-15232 Athens, Greece.
   Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
C3 University of Westminster; International Business Machines (IBM);
   Democritus University of Thrace
RP Kodogiannis, VS (通讯作者)，Univ Westminster, Ctr Syst Anal, Sch Comp Sci, London HA1 3TP, England.
EM kodogiv@wmin.ac.uk
RI Kodogiannis, Vassilis/D-1299-2016
CR ARENA A, 2005, ICMCC C JUN 2005 NET
   Arshak K, 2004, MICROELECTRON INT, V21, P8, DOI 10.1108/13565360410549675
   Boulougoura M, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P405
   Bourbakis N, 2005, BIBE 2005: 5th IEEE Symposium on Bioinformatics and Bioengineering, P324
   Chen C. H., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P1074
   Chen S, 1996, INT J CONTROL, V64, P829, DOI 10.1080/00207179608921659
   CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341
   Gletsos M, 2003, IEEE T INF TECHNOL B, V7, P153, DOI 10.1109/TITB.2003.813793
   Gonzalez R. C., 1987, DIGITAL IMAGE PROCES
   GRABISCH M, 1992, FUZZY SET SYST, V50, P293, DOI 10.1016/0165-0114(92)90227-U
   Haga Y, 2004, P IEEE, V92, P98, DOI 10.1109/JPROC.2003.820545
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HE DC, 1991, PATTERN RECOGN, V24, P391, DOI 10.1016/0031-3203(91)90052-7
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   John R., 2000, FUZZY SYSTEMS MED
   Karkanis SA, 2000, EUROMICRO CONF PROC, pA423
   Kodogiannis V., 2004, P INT C MED SIGN PRO, P262
   Kodogiannis VS, 2001, J INTELL FUZZY SYST, V11, P65
   Kodogiannis VS, 2002, FUZZY SET SYST, V128, P413, DOI 10.1016/S0165-0114(01)00076-8
   Kosko B., 1992, NEURAL NETWORKS FUZZ
   KRISHNAN S, 1998, INT C IEEE ENG MED B, V2, P895
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P1678, DOI 10.1109/IEMBS.1998.747232
   Krishnan SM, 1997, P ANN INT IEEE EMBS, V19, P1121, DOI 10.1109/IEMBS.1997.756549
   KRISHNAN SM, 1999, P 1 JOINT BMES EMBS, V2, P1149
   KUNCHEVA L, 2000, FUZZY CLASSIFIER DES
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P1295, DOI 10.1016/S0002-9270(03)00245-4
   Magoulas GD, 2004, APPL SOFT COMPUT, V4, P369, DOI 10.1016/j.asoc.2004.01.005
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Mitra S, 2002, IEEE T NEURAL NETWOR, V13, P3, DOI 10.1109/72.977258
   NAGASAKO K, 1998, ATLAS GASTROENTEROLO
   Orr MJL, 1993, 59 U ED CTR COGN SCI
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Pavlou A. K., 2001, INT C NEUR NETW EXP, P231
   SEBE N, 2000, INT C PATT REC, V3, P959
   Spyridonos P., 2005, P ADV CONC INT VIS S, P575
   Sugeno M., 1977, FUZZY MEASURES FUZZY, V78, P89
   Vilarino F., 2005, P 3 EUR MED BIOL ENG, P3443
   Wang L., 1994, ADAPTIVE FUZZY SYSTE
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   YAGER RR, 1993, INT J MAN MACH STUD, V39, P187, DOI 10.1006/imms.1993.1059
NR 40
TC 26
Z9 26
U1 1
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD JUN
PY 2007
VL 20
IS 4
BP 539
EP 553
DI 10.1016/j.engappai.2006.09.006
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Multidisciplinary; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Engineering
GA 165OK
UT WOS:000246314600012
DA 2023-04-20
ER

PT J
AU Yan, YL
   Luo, SH
   McWhorter, A
AF Yan, Yuling
   Luo, Shouhua
   McWhorter, Andrew
TI Virtual laryngoscopy: a noninvasive tool for the assessment of laryngeal
   tumor extent
SO LARYNGOSCOPE
LA English
DT Article
DE larynx; virtual laryngoscope; CT; reconstruction; segmentation
ID HELICAL CT; ENDOSCOPY
AB Objectives: Present a clinical application of virtual laryngoscopy (VL) in the assessment of laryngeal tumor and its extent.
   Study Design: CT data from two subjects are acquired for this preliminary study. One subject is a healthy volunteer and the other is a patient with laryngeal tumor. The laryngeal framework and upper airway are reconstructed using CT data, which allows for computer-aided internal and external anatomical views and interactive fly-through.
   Methods: These CT data are reconstructed into 0.5 mm slice images, resulting in a total of 200-300 image slices. An advanced commercial visualization software (AMIRA) is used for 3D image segmentation, reconstruction and surface rendering of laryngeal anatomical structures.
   Results: The 3D laryngeal framework and upper airway are reconstructed for both the tumor patient and the healthy subject. The conventional views of the reconstructed vocal folds are compared with those obtained from fiber-optic laryngoscope. Additionally, unique views of the vocal folds obtained from retrograde visualization and fly-through are presented, which are not possible to obtain using conventional endoscope imaging. The segmented anatomical model and the tumor from the patient's CT images were displayed individually to show the distribution of the tumor and its extent as well as spatial and contextual relationships to the larynx and airway anatomical structures.
   Conclusions: This study demonstrated the potential application of VL as a noninvasive clinical diagnostic tool for the assessment of laryngeal tumor and its extent. Our preliminary results demonstrated that the VL may provide valuable insights for the diagnosis and treatment planning for laryngeal and airway tumors. The noninvasive VL may complement the invasive laryngoscopic examinations for the staging of tumors and follow-ups on surgical interventions.
C1 Stanford Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Stanford, CA 94305 USA.
   SE Univ, Dept Biomed Engn, Nanjing, Jiangsu, Peoples R China.
   Louisiana State Univ, Dept Otolaryngol, New Orleans, LA USA.
C3 Stanford University; Southeast University - China; Louisiana State
   University System
RP Yan, YL (通讯作者)，Stanford Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, 801 Welch Rd, Stanford, CA 94305 USA.
EM yyan@ohns.stanford.edu
CR Aschoff AJ, 1998, RADIOLOGE, V38, P810, DOI 10.1007/s001170050428
   Burke AJ, 2000, LARYNGOSCOPE, V110, P23, DOI 10.1097/00005537-200001000-00005
   Fried MP, 1999, ANN OTO RHINOL LARYN, V108, P221
   Lorensen WE, 1987, ACM SIGGRAPH COMPUTE, P163, DOI DOI 10.1145/37402.37422
   Luo SH, 2005, P ANN INT IEEE EMBS, P5157
   Robb Richard A, 2000, BIOMEDICAL IMAGING V
   Rodenwaldt J, 1996, ROFO-FORTSCHR RONTG, V165, P80, DOI 10.1055/s-2007-1015718
   Rubin GD, 1996, RADIOLOGY, V199, P321, DOI 10.1148/radiology.199.2.8668772
   Walshe P, 2002, CLIN OTOLARYNGOL, V27, P98, DOI 10.1046/j.1365-2273.2002.00539.x
   AMIRA 3 1 USERS GUID
NR 10
TC 8
Z9 8
U1 0
U2 6
PU WILEY-BLACKWELL
PI MALDEN
PA COMMERCE PLACE, 350 MAIN ST, MALDEN 02148, MA USA
SN 0023-852X
J9 LARYNGOSCOPE
JI Laryngoscope
PD JUN
PY 2007
VL 117
IS 6
BP 1026
EP 1030
DI 10.1097/MLG.0b013e31804f812f
PG 5
WC Medicine, Research & Experimental; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine; Otorhinolaryngology
GA 174ET
UT WOS:000246925000015
PM 17545865
DA 2023-04-20
ER

PT J
AU Cardoso, J
   Boer, J
   Morreau, H
   Fodde, R
AF Cardoso, J.
   Boer, J.
   Morreau, H.
   Fodde, R.
TI Expression and genomic profiling of colorectal cancer
SO BIOCHIMICA ET BIOPHYSICA ACTA-REVIEWS ON CANCER
LA English
DT Review
DE colorectal cancer; expression profiling; genomic profiling; array CGH;
   genomics; adenoma; carcinoma; metastasis
ID ABERRANT CRYPT FOCI; COPY-NUMBER CHANGES; MITOTIC CHECKPOINT GENES;
   HIGH-RESOLUTION ANALYSIS; COLON-CANCER; MICROSATELLITE INSTABILITY;
   BETA-CATENIN; CDNA MICROARRAY; BREAST-CANCER; STEM-CELLS
AB Colorectal cancer still represents a paradigm for the elucidation of the cellular, genetic and molecular mechanisms that underly solid tumor initiation, progression to malignancy, and metastasis to distal organ sites. The relative ease with which pathological specimens can be obtained by either surgery or endoscopy from different stages of tumor progression has facilitated the application of omics technologies to allow the genome-wide analysis both at the RNA (gene expression) and DNA (aneuploidy) levels. Here, we have reviewed the multiplicity of studies appeared to date in the scientific literature on the expression and genomic analysis of colorectal cancer, and attempted an integration of the profiling data generated and made available in the public domain. This approach is likely to pinpoint specific chromosomal loci and the corresponding genes which (i) play rate-limiting roles in colorectal cancer, (ii) represent putative diagnostic and prognostic markers for the accurate prediction of clinical outcome and response to treatment, and (iii) encompass potential therapeutic targets. Moreover, cross-species data mining and integration of the human colorectal cancer profiles with those obtained from mouse models of intestinal tumorigenesis will even more contribute to the elucidation of highly conserved pathways and cellular functions underlying malignancy in the GI tract. Notwithstanding the above promises, tumor heterogeneity, limited cohort sizes, and methodological differences among experimental and bioinformatic approaches still poses main obstacles towards the optimal utilization and integration of omics profiles. (c) 2006 Elsevier B.V. All rights reserved.
C1 Erasmus Univ, Ctr Med, Dept Pathol, Josephine Nefkens Inst, NL-3000 CA Rotterdam, Netherlands.
   Leiden Univ, Ctr Med, Dept Pathol, Leiden, Netherlands.
C3 Erasmus University Rotterdam; Erasmus MC; Leiden University; Leiden
   University - Excl LUMC
RP Fodde, R (通讯作者)，Erasmus Univ, Ctr Med, Dept Pathol, Josephine Nefkens Inst, POB 2040, NL-3000 CA Rotterdam, Netherlands.
EM r.rodde@erasmusmc.nl
RI Fodde, Riccardo/AAW-9394-2021; Boer, Judith/A-7546-2010
OI Fodde, Riccardo/0000-0001-9839-4324; Boer, Judith/0000-0003-4848-7789;
   Cardoso, Joana/0000-0002-8720-8845
CR Agrawal D, 2002, J NATL CANCER I, V94, P513
   Aguirre AJ, 2004, P NATL ACAD SCI USA, V101, P9067, DOI 10.1073/pnas.0402932101
   *AIOC RES, 1997, WASH WCRF AICR WORLD
   Al-Hajj M, 2003, P NATL ACAD SCI USA, V100, P3983, DOI 10.1073/pnas.0530291100
   Albertson DG, 2000, NAT GENET, V25, P144, DOI 10.1038/75985
   Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745
   Andreyev HJN, 2001, BRIT J CANCER, V85, P692, DOI 10.1054/bjoc.2001.1964
   Arango D, 2004, BRIT J CANCER, V91, P1931, DOI 10.1038/sj.bjc.6602215
   Arango D, 2005, GASTROENTEROLOGY, V129, P874, DOI 10.1053/j.gastro.2005.06.066
   AUGENLICHT LH, 1987, CANCER RES, V47, P6017
   AUGENLICHT LH, 1991, P NATL ACAD SCI USA, V88, P3286, DOI 10.1073/pnas.88.8.3286
   Augenlicht LH, 2001, NAT GENET, V28, P104, DOI 10.1038/88800
   BAKER RC, 1989, ACTA ARITH, V53, P217, DOI 10.4064/aa-53-3-217-250
   Banerjea A, 2004, MOL CANCER, V3, DOI 10.1186/1476-4598-3-21
   Bardelli A, 2003, SCIENCE, V300, P949, DOI 10.1126/science.1082596
   Bardi G, 1997, BRIT J CANCER, V76, P765, DOI 10.1038/bjc.1997.459
   BARDI G, 1995, GENE CHROMOSOME CANC, V12, P97, DOI 10.1002/gcc.2870120204
   BARRIER A, 2005, ONCOGENE
   Bentz M, 1998, GENE CHROMOSOME CANC, V21, P172, DOI 10.1002/(SICI)1098-2264(199802)21:2<172::AID-GCC14>3.3.CO;2-T
   Bernards R, 2002, NATURE, V418, P823, DOI 10.1038/418823a
   Bertucci F, 2004, ONCOGENE, V23, P1377, DOI 10.1038/sj.onc.1207262
   BHATTACHARYYA NP, 1994, P NATL ACAD SCI USA, V91, P6319, DOI 10.1073/pnas.91.14.6319
   Biemer-Huttmann AE, 2000, CLIN CANCER RES, V6, P1909
   Bingham SA, 2003, LANCET, V361, P1496, DOI 10.1016/S0140-6736(03)13174-1
   BIRD RP, 1987, CANCER LETT, V37, P147, DOI 10.1016/0304-3835(87)90157-1
   Birkenkamp-Demtroder K, 2002, CANCER RES, V62, P4352
   Birkenkamp-Demtroder K, 2005, GUT, V54, P374, DOI 10.1136/gut.2003.036848
   Blobe GC, 2000, NEW ENGL J MED, V342, P1350, DOI 10.1056/NEJM200005043421807
   Boland CR, 1998, CANCER RES, V58, P5248
   Bonnet D, 1997, NAT MED, V3, P730, DOI 10.1038/nm0797-730
   BOS JL, 1987, NATURE, V327, P293, DOI 10.1038/327293a0
   Brabletz T, 1999, AM J PATHOL, V155, P1033, DOI 10.1016/S0002-9440(10)65204-2
   Brabletz T, 2005, NAT REV CANCER, V5, P744, DOI 10.1038/nrc1694
   Buffart TE, 2005, CELL ONCOL, V27, P57
   Cahill DP, 1999, TRENDS CELL BIOL, V9, pM57, DOI 10.1016/S0962-8924(99)01661-X
   Cahill DP, 1998, NATURE, V392, P300, DOI 10.1038/32688
   CAMPS J, 2005, CARCINOGENESIS
   Cardoso J, 2006, CANCER RES, V66, P2514, DOI 10.1158/0008-5472.CAN-05-2407
   Cardoso J, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh142
   Chan TL, 2001, ONCOGENE, V20, P4871, DOI 10.1038/sj.onc.1204653
   Clarke PA, 2003, CANCER RES, V63, P6855
   Coussens LM, 2002, NATURE, V420, P860, DOI 10.1038/nature01322
   Crnogorac-Jurcevic T, 2002, ONCOGENE, V21, P4587, DOI 10.1038/sj.onc.1205570
   Dan S, 2002, CANCER RES, V62, P1139
   DARRIGO A, 2005, INT J CANC
   Davies H, 2002, NATURE, V417, P949, DOI 10.1038/nature00766
   Davison EJ, 2005, GENE CHROMOSOME CANC, V44, P384, DOI 10.1002/gcc.20252
   de la Chapelle A, 2004, NAT REV CANCER, V4, P769, DOI 10.1038/nrc1453
   DELATTRE O, 1989, LANCET, V2, P353
   DeRisi J, 1996, NAT GENET, V14, P457
   Di Pietro M, 2005, GASTROENTEROLOGY, V129, P1047, DOI 10.1053/j.gastro.2005.06.028
   Diep CB, 2006, GENE CHROMOSOME CANC, V45, P31, DOI 10.1002/gcc.20261
   Dolcetti R, 1999, AM J PATHOL, V154, P1805, DOI 10.1016/S0002-9440(10)65436-3
   Douglas EJ, 2004, CANCER RES, V64, P4817, DOI 10.1158/0008-5472.CAN-04-0328
   Dunican DS, 2002, ONCOGENE, V21, P3253, DOI 10.1038/sj.onc.1205431
   Duval A, 2002, ANN GENET-PARIS, V45, P71, DOI 10.1016/S0003-3995(02)01115-2
   Ein-Dor L, 2005, BIOINFORMATICS, V21, P171, DOI 10.1093/bioinformatics/bth469
   Eppert K, 1996, CELL, V86, P543, DOI 10.1016/S0092-8674(00)80128-2
   Eshleman JR, 1998, ONCOGENE, V17, P719, DOI 10.1038/sj.onc.1201986
   FEARON ER, 1990, CELL, V61, P759, DOI 10.1016/0092-8674(90)90186-I
   Fodde R, 2001, NAT CELL BIOL, V3, P433, DOI 10.1038/35070129
   Fodde R, 2001, NAT REV CANCER, V1, P55, DOI 10.1038/35094067
   FORRESTER K, 1987, NATURE, V327, P298, DOI 10.1038/327298a0
   Frederiksen CM, 2003, J CANCER RES CLIN, V129, P263, DOI 10.1007/s00432-003-0434-x
   Fukasawa K, 1996, SCIENCE, V271, P1744, DOI 10.1126/science.271.5256.1744
   Ghadimi BM, 2005, J CLIN ONCOL, V23, P1826, DOI 10.1200/JCO.2005.00.406
   Giacomini CP, 2005, CANCER RES, V65, P9200, DOI 10.1158/0008-5472.CAN-04-4163
   GIARETTI W, 1994, LAB INVEST, V71, P904
   Gillespie JW, 2001, CANCER J, V7, P32
   Giovannucci E, 1996, JNCI-J NATL CANCER I, V88, P1717, DOI 10.1093/jnci/88.23.1717
   Glebov OK, 2003, CANCER EPIDEM BIOMAR, V12, P755
   Graeber TG, 2005, NAT GENET, V37, P7, DOI 10.1038/ng0105-7
   Groner RS, 2005, CANCER-AM CANCER SOC, V104, P395, DOI 10.1002/cncr.21170
   Guidoboni M, 2001, AM J PATHOL, V159, P297, DOI 10.1016/S0002-9440(10)61695-1
   HABETS GGM, 1992, CYTOGENET CELL GENET, V60, P200, DOI 10.1159/000133336
   Halford S, 2002, CANCER RES, V62, P53
   Hegde P, 2001, CANCER RES, V61, P7792
   Iacopetta B, 2003, HUM MUTAT, V21, P271, DOI 10.1002/humu.10175
   Ichikawa Y, 2002, BIOCHEM BIOPH RES CO, V296, P497, DOI 10.1016/S0006-291X(02)00732-5
   Ilyas M, 1997, P NATL ACAD SCI USA, V94, P10330, DOI 10.1073/pnas.94.19.10330
   Inoue Y, 2006, INT J ONCOL, V28, P479
   Inoue Y, 2004, INT J ONCOL, V25, P1641
   IONOV Y, 1993, NATURE, V363, P558, DOI 10.1038/363558a0
   Jemal A, 2002, CA-CANCER J CLIN, V52, P23, DOI 10.3322/canjclin.52.1.23
   Jones AM, 2005, ONCOGENE, V24, P118, DOI 10.1038/sj.onc.1208194
   Jones PA, 2002, NAT REV GENET, V3, P415, DOI 10.1038/nrg816
   KALLIONIEMI OP, 1994, GENE CHROMOSOME CANC, V10, P231, DOI 10.1002/gcc.2870100403
   Kaplan KB, 2001, NAT CELL BIOL, V3, P429, DOI 10.1038/35070123
   Kim H, 2004, ONCOGENE, V23, P6218, DOI 10.1038/sj.onc.1207853
   Kinzler KW, 1996, CELL, V87, P159, DOI 10.1016/S0092-8674(00)81333-1
   Kirchhoff M, 1998, CYTOMETRY, V31, P163, DOI 10.1002/(SICI)1097-0320(19980301)31:3<163::AID-CYTO3>3.0.CO;2-M
   Kitahara O, 2001, CANCER RES, V61, P3544
   Koehler A, 2004, J PATHOL, V204, P65, DOI 10.1002/path.1606
   Komori T, 2004, J EXP CLIN CANC RES, V23, P521
   Komuro K, 2005, J SURG RES, V124, P216, DOI 10.1016/j.jss.2004.10.009
   Kruhoffer M, 2005, BRIT J CANCER, V92, P2240, DOI 10.1038/sj.bjc.6602621
   Kwon HC, 2004, DIS COLON RECTUM, V47, P141, DOI 10.1007/s10350-003-0032-7
   Labianca R, 2004, CRIT REV ONCOL HEMAT, V51, P145, DOI 10.1016/j.critrevonc.2004.03.003
   Lamlum H, 2000, P NATL ACAD SCI USA, V97, P2225, DOI 10.1073/pnas.040564697
   Lammi L, 2004, AM J HUM GENET, V74, P1043, DOI 10.1086/386293
   Lechner S, 2003, GUT, V52, P1148, DOI 10.1136/gut.52.8.1148
   Leclerc D, 2004, J CELL BIOCHEM, V93, P1242, DOI 10.1002/jcb.20236
   Lengauer C, 1998, NATURE, V396, P643, DOI 10.1038/25292
   Li MH, 2004, INT J ONCOL, V24, P305
   Liefers GJ, 2002, EUR J CANCER, V38, P872, DOI 10.1016/S0959-8049(02)00055-2
   Lin YM, 2002, ONCOGENE, V21, P4120, DOI 10.1038/sj.onc.1205518
   LIPSHUTZ RJ, 1995, BIOTECHNIQUES, V19, P442
   Ma XJ, 2003, P NATL ACAD SCI USA, V100, P5974, DOI 10.1073/pnas.0931261100
   Mamounas E, 1999, J CLIN ONCOL, V17, P1349, DOI 10.1200/JCO.1999.17.5.1349
   Mariadason JM, 2004, DRUG RESIST UPDATE, V7, P209, DOI 10.1016/j.drup.2004.05.001
   Mariadason JM, 2003, CANCER RES, V63, P8791
   MARKOWITZ S, 1995, SCIENCE, V268, P1336, DOI 10.1126/science.7761852
   Martinez C, 2005, J PATHOL, V206, P100, DOI 10.1002/path.1755
   Mehta KR, 2005, CLIN CANCER RES, V11, P1791, DOI 10.1158/1078-0432.CCR-04-1418
   Minn AJ, 2005, NATURE, V436, P518, DOI 10.1038/nature03799
   Miyoshi Yasuo, 1992, Human Molecular Genetics, V1, P229
   MOERTEL CG, 1990, NEW ENGL J MED, V322, P352, DOI 10.1056/NEJM199002083220602
   MOERTEL CG, 1995, ANN INTERN MED, V122, P321, DOI 10.7326/0003-4819-122-5-199503010-00001
   Mori Y, 2003, CANCER RES, V63, P4577
   Mori Y, 2004, CANCER RES, V64, P2434, DOI 10.1158/0008-5472.CAN-03-3508
   Morin PJ, 1997, SCIENCE, V275, P1787, DOI 10.1126/science.275.5307.1787
   MULERIS M, 1990, CANCER GENET CYTOGEN, V46, P143, DOI 10.1016/0165-4608(90)90100-O
   Muro S, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-3-r21
   Nakao K, 2004, CARCINOGENESIS, V25, P1345, DOI 10.1093/carcin/bgh134
   Nosho K, 2005, BRIT J CANCER, V92, P1193, DOI 10.1038/sj.bjc.6602442
   Notterman DA, 2001, CANCER RES, V61, P3124
   Nucci MR, 1997, HUM PATHOL, V28, P1396, DOI 10.1016/S0046-8177(97)90230-6
   Otsuka M, 2001, BIOCHEM BIOPH RES CO, V289, P876, DOI 10.1006/bbrc.2001.6047
   Paoni NF, 2003, PHYSIOL GENOMICS, V15, P228, DOI 10.1152/physiolgenomics.00078.2003
   Papanikolaou A, 1998, CANCER LETT, V130, P29, DOI 10.1016/S0304-3835(98)00101-3
   Papanikolaou A, 2000, CARCINOGENESIS, V21, P1567, DOI 10.1093/carcin/21.8.1567
   Parsons DW, 2005, NATURE, V436, P792, DOI 10.1038/436792a
   PARSONS R, 1993, CELL, V75, P1227, DOI 10.1016/0092-8674(93)90331-J
   Peltomaki P, 2003, J CLIN ONCOL, V21, P1174, DOI 10.1200/JCO.2003.04.060
   Perou CM, 1999, P NATL ACAD SCI USA, V96, P9212, DOI 10.1073/pnas.96.16.9212
   Pihan G, 2003, CANCER CELL, V4, P89, DOI 10.1016/S1535-6108(03)00195-8
   Pinheiro NA, 2001, CANCER LETT, V172, P67, DOI 10.1016/S0304-3835(01)00625-5
   Pinkel D, 1998, NAT GENET, V20, P207, DOI 10.1038/2524
   Platzer P, 2002, CANCER RES, V62, P1134
   Polakis P, 1999, CURR OPIN GENET DEV, V9, P15, DOI 10.1016/S0959-437X(99)80003-3
   Pollack JR, 1999, NAT GENET, V23, P41, DOI 10.1038/12640
   Pollack JR, 2002, P NATL ACAD SCI USA, V99, P12963, DOI 10.1073/pnas.162471999
   POWELL SM, 1992, NATURE, V359, P235, DOI 10.1038/359235a0
   PURDIE CA, 1991, AM J PATHOL, V138, P807
   Rajagopalan H, 2002, NATURE, V418, P934, DOI 10.1038/418934a
   Rajagopalan H, 2004, NATURE, V428, P77, DOI 10.1038/nature02313
   Ramaswamy S, 2003, NAT GENET, V33, P49, DOI 10.1038/ng1060
   Ransohoff DF, 2004, NAT REV CANCER, V4, P309, DOI 10.1038/nrc1322
   Raychaudhuri S, 2000, Pac Symp Biocomput, P455
   Reichling T, 2005, CANCER RES, V65, P166
   Reya T, 2001, NATURE, V414, P105, DOI 10.1038/35102167
   Reya T, 2005, NATURE, V434, P843, DOI 10.1038/nature03319
   Richter H, 2003, AM J PATHOL, V163, P287, DOI 10.1016/S0002-9440(10)63652-8
   ROSENBERG DW, 1995, CANCER LETT, V92, P209, DOI 10.1016/0304-3835(95)03797-Z
   Rubinfeld B, 1996, SCIENCE, V272, P1023, DOI 10.1126/science.272.5264.1023
   Samuels Y, 2004, SCIENCE, V304, P554, DOI 10.1126/science.1096502
   SCHENA M, 1995, SCIENCE, V270, P467, DOI 10.1126/science.270.5235.467
   Scherf U, 2000, NAT GENET, V24, P236, DOI 10.1038/73439
   Scherl-Mostageer M, 2001, ONCOGENE, V20, P4402, DOI 10.1038/sj.onc.1204566
   Schmidt WM, 2004, INT J CANCER, V112, P200, DOI 10.1002/ijc.20401
   Selaru FM, 2002, GASTROENTEROLOGY, V122, P606, DOI 10.1053/gast.2002.31904
   Shi YG, 2003, CELL, V113, P685, DOI 10.1016/S0092-8674(03)00432-X
   Shichiri M, 2002, CANCER RES, V62, P13
   Shih IM, 2001, CANCER RES, V61, P818
   Shih W, 2005, ONCOL REP, V13, P517
   Shimizu D, 2005, INT J ONCOL, V27, P371
   Singh SK, 2004, ONCOGENE, V23, P7267, DOI 10.1038/sj.onc.1207946
   SMITH AJ, 1994, CANCER RES, V54, P5527
   Snijders AM, 2001, NAT GENET, V29, P263, DOI 10.1038/ng754
   SolinasToldo S, 1997, GENE CHROMOSOME CANC, V20, P399, DOI 10.1002/(SICI)1098-2264(199712)20:4<399::AID-GCC12>3.0.CO;2-I
   Sorlie T, 2001, P NATL ACAD SCI USA, V98, P10869, DOI 10.1073/pnas.191367098
   Sparks AB, 1998, CANCER RES, V58, P1130
   St Croix B, 2000, SCIENCE, V289, P1197
   Stuart RO, 2004, P NATL ACAD SCI USA, V101, P615, DOI 10.1073/pnas.2536479100
   Takagi Y, 1996, GASTROENTEROLOGY, V111, P1369, DOI 10.1053/gast.1996.v111.pm8898652
   Takayama T, 2001, GASTROENTEROLOGY, V121, P599, DOI 10.1053/gast.2001.27203
   Takemasa I, 2001, BIOCHEM BIOPH RES CO, V285, P1244, DOI 10.1006/bbrc.2001.5277
   Tanami H, 2005, LAB INVEST, V85, P1118, DOI 10.1038/labinvest.3700312
   Thiagalingam S, 2001, P NATL ACAD SCI USA, V98, P2698, DOI 10.1073/pnas.051625398
   Thiagalingam S, 1996, NAT GENET, V13, P343, DOI 10.1038/ng0796-343
   THIBODEAU SN, 1993, SCIENCE, V260, P816, DOI 10.1126/science.8484122
   TOMATIS L, 1990, EXP PATHOL-JENA, V40, P251, DOI 10.1016/S0232-1513(11)80309-9
   Tomlinson I, 2002, J PATHOL, V197, P6, DOI 10.1002/path.1071
   Tsunoda T, 2001, ANTICANCER RES, V21, P137
   Tusher VG, 2001, P NATL ACAD SCI USA, V98, P5116, DOI 10.1073/pnas.091062498
   van de Vijver MJ, 2002, NEW ENGL J MED, V347, P1999, DOI 10.1056/NEJMoa021967
   van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Wang WG, 2001, CANCER RES, V61, P5505
   Wang YX, 2004, J CLIN ONCOL, V22, P1564, DOI 10.1200/JCO.2004.08.186
   Wang YX, 2005, LANCET, V365, P671, DOI 10.1016/S0140-6736(05)17947-1
   Wang ZH, 2004, CANCER RES, V64, P2998, DOI 10.1158/0008-5472.CAN-04-0587
   WARBURG O, 1956, SCIENCE, V124, P269
   Weigelt B, 2003, P NATL ACAD SCI USA, V100, P15901, DOI 10.1073/pnas.2634067100
   Westbrook TF, 2005, CELL, V121, P837, DOI 10.1016/j.cell.2005.03.033
   Whitehall VLJ, 2001, CANCER RES, V61, P827
   Wielenga VJM, 1999, AM J PATHOL, V154, P515, DOI 10.1016/S0002-9440(10)65297-2
   Williams NS, 2003, CLIN CANCER RES, V9, P931
   Yuan ZQ, 2003, ONCOGENE, V22, P6304, DOI 10.1038/sj.onc.1206609
   Zembutsu H, 2002, CANCER RES, V62, P518
   Zhou XF, 2005, CANCER GENET CYTOGEN, V159, P53, DOI 10.1016/j.cancergencyto.2004.09.014
   Zou TT, 2002, ONCOGENE, V21, P4855, DOI 10.1038/sj.onc.1205613
   1999, J CLIN ONCOL, V17, P1356
NR 203
TC 96
Z9 105
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0304-419X
EI 1879-2561
J9 BBA-REV CANCER
JI Biochim. Biophys. Acta-Rev. Cancer
PD JAN
PY 2007
VL 1775
IS 1
BP 103
EP 137
DI 10.1016/j.bbcan.2006.08.004
PG 35
WC Biochemistry & Molecular Biology; Biophysics; Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biophysics; Oncology
GA 123TD
UT WOS:000243317700007
PM 17010523
DA 2023-04-20
ER

PT J
AU Tonet, O
   Thoranaghatte, RU
   Megali, G
   Dario, P
AF Tonet, Oliver
   Thoranaghatte, Ramesh U.
   Megali, Giuseppe
   Dario, Paolo
TI Tracking endoscopic instruments without a localizer: A
   shape-analysis-based approach
SO COMPUTER AIDED SURGERY
LA English
DT Article; Proceedings Paper
CT 14th Conference on Medicine Meets Virtual Reality
CY JAN 24-27, 2006
CL Long Beach, CA
DE localization; tracking; shape analysis; pinhole camera; laparoscopy
ID CAMERA CALIBRATION; DEVICE; SURGERY; ACCURACY; MOTION; RANGE
AB We present an approach to localizing endoscopic instruments with respect to the camera position, based purely on processing of the endoscope image. No localizers are needed; the only requirement is a colored strip at the distal part of the instrument shaft to facilitate image segmentation. The method exploits perspective image analysis applied to the cylindrical shape of the instrument shaft, allowing measurement of the instrument position and orientation with five degrees of freedom. We describe the method theoretically, and experimentally derive calibration curves for tuning the parameters of the algorithm. Results show that the method can be used for applications where accuracy is not critical, such as workspace measurement, gesture analysis, augmented-reality guidance, telementoring, etc. If this method is used in combination with an endoscope tracker or a robotic camera holder, full localization with respect to the patient reference frame can be achieved.
C1 [Tonet, Oliver; Megali, Giuseppe; Dario, Paolo] Scuola Super Sant Anna, CRIM Lab, I-56025 Pontedera, PI, Italy.
   [Tonet, Oliver; Megali, Giuseppe; Dario, Paolo] Univ Pisa, Ctr Computer Assisted Surg, EndoCAS, I-56100 Pisa, Italy.
   [Thoranaghatte, Ramesh U.] Univ Bern, Inst Surg Technol & Biomech, MEM Res Ctr, Bern, Switzerland.
C3 Scuola Superiore Sant'Anna; University of Pisa; University of Bern
RP Tonet, O (通讯作者)，Scuola Super Sant Anna, CRIM Lab, Viale Piaggio 34, I-56025 Pontedera, PI, Italy.
EM oly@sssup.it
CR AN KN, 1988, J BIOMECH, V21, P613, DOI 10.1016/0021-9290(88)90225-4
   Birkfellner W, 1998, LECT NOTES COMPUT SC, V1496, P343, DOI 10.1007/BFb0056218
   Chassat F, 1998, LECT NOTES COMPUT SC, V1496, P277, DOI 10.1007/BFb0056211
   DATTANASIO S, 2000, P IEEE INT C ROB AUT, V2, P1586
   Day JS, 1998, J BIOMECH, V31, P957, DOI 10.1016/S0021-9290(98)00089-X
   FRIETS EM, 1989, IEEE T BIO-MED ENG, V36, P608, DOI 10.1109/10.29455
   FU KS, 1987, ROBOTICS
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Khadem R, 2000, Comput Aided Surg, V5, P98, DOI 10.1002/1097-0150(2000)5:2<98::AID-IGS4>3.0.CO;2-H
   Li Q, 1999, Comput Aided Surg, V4, P314, DOI 10.1002/(SICI)1097-0150(1999)4:6<314::AID-IGS3>3.0.CO;2-G
   MARMULLA R, 1997, P 11 INT S EXH, P863
   Megali G, 2006, IEEE T BIO-MED ENG, V53, P1911, DOI 10.1109/TBME.2006.881784
   Meskers CGM, 1999, J BIOMECH, V32, P629, DOI 10.1016/S0021-9290(99)00011-1
   Milne AD, 1996, J BIOMECH, V29, P791, DOI 10.1016/0021-9290(96)83335-5
   Pratt W. K., 1991, DIGITAL IMAGE PROCES
   Rohling R, 1995, J Image Guid Surg, V1, P30, DOI 10.1002/(SICI)1522-712X(1995)1:1<30::AID-IGS5>3.0.CO;2-N
   ROUX C, 1997, CONT PERSPECTIVES 3
   Ryan MJ, 1996, J NEUROSURG, V85, P287, DOI 10.3171/jns.1996.85.2.0287
   Schmerber S, 2001, Comput Aided Surg, V6, P1
   TOFT P, 1996, THESIS TU DELFT NETH
   TROBAUGH JW, 1994, COMPUT MED IMAG GRAP, V18, P235, DOI 10.1016/0895-6111(94)90048-5
   TROCCAZ J, 1997, P 1 JOINT C COMP VIS, P727
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   VOROS S, 2006, P 1 IEEE RAS EMBS IN
   WATANABE E, 1987, SURG NEUROL, V27, P543, DOI 10.1016/0090-3019(87)90152-2
   Wei GQ, 1997, IEEE ENG MED BIOL, V16, P40, DOI 10.1109/51.566151
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 27
TC 37
Z9 37
U1 1
U2 9
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1092-9088
EI 1097-0150
J9 COMPUT AIDED SURG
JI Comput. Aided Surg.
PD JAN
PY 2007
VL 12
IS 1
BP 35
EP 42
DI 10.1080/10929080701210782
PG 8
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
GA 303GA
UT WOS:000256027800005
PM 17364657
DA 2023-04-20
ER

PT J
AU Lim, CS
   Lam, SK
   Tian, H
   Srikanthan, T
AF Lim, C. S.
   Lam, S. K.
   Tian, H.
   Srikanthan, T.
TI Efficient architectures for segmentation of endoscopic images in
   micro-robotic auto navigation systems
SO INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS
LA English
DT Article
DE image segmentation; endoscopic images; architecture
ID LUMEN REGION; EXTRACTION; BOUNDARY
AB This paper presents novel techniques and their architectural translations for real-time image segmentation of endoscopic images, which are required for micro-robotic auto navigation systems. The proposed technique is based on a two-step process to segment the lumen regions from encloscopic images. In the first step, an adaptive progressive thresholding technique based on Otsu's method is employed to obtain a preliminary region of interest of the lumen region. A novel architecture for the between-class variance computation of Otsu's method is presented to meet the real-time requirements of the system. The proposed implementation employs binary logarithmic computations to eliminate the complex divisions and multiplications in Otsu's procedure. In the second step, an Iris filter is employed to enhance the boundary of the region of interest to facilitate an accurate detection of the lumen region. An architecture based on the coordinate rotation digital computer is proposed to simplify the complex computations of trigonometric functions required by the Iris filter operation. Software simulations demonstrate that the proposed technique requires a significantly smaller number of iterations to obtain an accurate segmentation result as compared to a previously reported method. In addition, synthesis results on the field-programmable gate array show that the proposed architectures can achieve high performance with low hardware resource utilization.
C1 Nanyang Technol Univ, Ctr High Performance Embedded Syst, Singapore, Singapore.
   Agcy Sci Technol & Res, Bioinformat Inst, Singapore, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University; Agency for Science
   Technology & Research (A*STAR); A*STAR - Bioinformatics Institute (BII)
RP Lim, CS (通讯作者)，Nanyang Technol Univ, Ctr High Performance Embedded Syst, Singapore, Singapore.
EM ascslim@ntu.edu.sg; assklam@ntu.edu.sg; tianhui@bii.a-star.edu.sg;
   astsrikan@ntu.edu.sg
RI Lam, Siew Kei/B-9224-2008
CR Asari KV, 1999, MICROPROCESS MICROSY, V23, P493, DOI 10.1016/S0141-9331(99)00057-5
   DARIO P, 1997, P IEEE INT C ROB AUT, V2, P1567
   KHAN GN, 1989, P 6 C MED INF MEDINF, P1455
   Kobatake H, 1999, IEEE T IMAGE PROCESS, V8, P1029, DOI 10.1109/83.777084
   Kumar S, 1999, MED BIOL ENG COMPUT, V37, P600, DOI 10.1007/BF02513354
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   TAN CS, 1994, P WORLD C MED PHYS B, P614
   Tian H, 2001, MED BIOL ENG COMPUT, V39, P8, DOI 10.1007/BF02345260
   Volder J.E., 1959, IRE T ELECT COMPUTER, VEC-8, P330, DOI 10.1109/TEC.1959.5222693
NR 9
TC 3
Z9 3
U1 0
U2 2
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-8436
EI 1793-6942
J9 INT J HUM ROBOT
JI Int. J. Humanoid Robot.
PD DEC
PY 2006
VL 3
IS 4
BP 523
EP 545
DI 10.1142/S0219843606000886
PG 23
WC Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Robotics
GA 214SX
UT WOS:000249759500008
DA 2023-04-20
ER

PT J
AU Seo, KW
   Min, BR
   Lee, DW
AF Seo, Kwang-wook
   Min, Byeong-ro
   Lee, Dae-weon
TI The detection of esophagitis by using Back Propagation Network algorithm
SO JOURNAL OF MECHANICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Back Propagation Network; endoscopy; esophagitis; texture
AB The results of this study suggest the use of a Back Propagation Network (BPN) algorithm for the detection of esophageal erosions or abnormalities - which are the important signs of esophagitis - in the analysis of the color and textural aspects of clinical images obtained by endoscopy. The authors have investigated the optimization of the learning condition by the number of neurons in the hidden layer within the structure of the neural network. By optimizing learning parameters, we learned and have validated esophageal erosion images and/or ulcers functioning as the critical diagnostic criteria for esophagitis and associated abnormalities. Validation was established by using twenty clinical images. The success rates for detection of esophagitis during calibration and during validation were 97.91% and 96.83%, respectively.
C1 Sungkyunkwan Univ, Dept Biomech Engn, Suwon 440746, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Lee, DW (通讯作者)，Sungkyunkwan Univ, Dept Biomech Engn, Suwon 440746, South Korea.
EM daeweon@skku.edu
CR Fockens P, 2002, BEST PRACT RES CL GA, V16, P999, DOI 10.1053/bega.2002.0337
   Karkanis SA, 2000, EUROMICRO CONF PROC, pA423
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   NA YH, 1994, KOREAN J GASTROINTES, V2, P145
   NGUYEN D, 2001, IEEE INT JOINT C NEU, V3, P21
   Parker J.R., 1997, ALGORITHMS IMAGE PRO, P150
   SEO KW, 2004, J KOREA SOC MED BIOL, V25, P545
   Tjoa MP, 2001, P ANN INT IEEE EMBS, V23, P2665, DOI 10.1109/IEMBS.2001.1017331
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   YOON YH, 2001, KOREAN J GASTROINTES, V23, P144
   Zheng MM, 2002, IEEE CCEC 2002: CANADIAN CONFERENCE ON ELECTRCIAL AND COMPUTER ENGINEERING, VOLS 1-3, CONFERENCE PROCEEDINGS, P1116, DOI 10.1109/CCECE.2002.1013103
   ZHENG MM, 2001, 7 AUSTR NZ INT INF S, P107
NR 12
TC 1
Z9 1
U1 0
U2 0
PU KOREAN SOC MECHANICAL ENGINEERS
PI SEOUL
PA KSTC NEW BLD. 7TH FLOOR, 635-4 YEOKSAM-DONG KANGNAM-KU, SEOUL 135-703,
   SOUTH KOREA
SN 1738-494X
EI 1976-3824
J9 J MECH SCI TECHNOL
JI J. Mech. Sci. Technol.
PD NOV
PY 2006
VL 20
IS 11
BP 1873
EP 1880
DI 10.1007/BF03027580
PG 8
WC Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 146MX
UT WOS:000244939700009
DA 2023-04-20
ER

PT J
AU Suzuki, K
   Yoshida, H
   Nappi, J
   Dachman, AH
AF Suzuki, Kenji
   Yoshida, Hiroyuki
   Nappi, Janne
   Dachman, Abraham H.
TI Massive-training artificial neural network (MTANN) for reduction of
   false positives in computer-aided detection of polyps: Suppression of
   rectal tubes
SO MEDICAL PHYSICS
LA English
DT Article
DE virtual colonoscopy; colon cancer; CT colonography; computer-aided
   detection; pattern recognition; artificial neural network
ID CT COLONOGRAPHY; COLONIC POLYPS; LUNG NODULES; TOMOGRAPHIC COLONOGRAPHY;
   VIRTUAL COLONOSCOPY; VOLUMETRIC FEATURES; AUTOMATED DETECTION;
   DIAGNOSTIC SCHEME; CHEST RADIOGRAPHS; SMALL NUMBER
AB One of the limitations of the current computer-aided detection (CAD) of polyps in CT colonography (CTC) is a relatively large number of false-positive (FP) detections. Rectal tubes (RTs) are one of the typical sources of FPs because a portion of a RT, especially a portion of a bulbous tip, often exhibits a cap-like shape that closely mimics the appearance of a small polyp. Radiologists can easily recognize and dismiss RT-induced FPs; thus, they may lose their confidence in CAD as an effective tool if the CAD scheme generates such "obvious" FPs due to RTs consistently. In addition, RT-induced FPs may distract radiologists from less common true positives in the rectum. Therefore, removal RT induced FPs as well as other types of FPs is desirable while maintaining a high sensitivity in the detection of polyps. We developed a three-dimensional (3D) massive-training artificial neural network (MTANN) for distinction between polyps and RTs in 3D CTC volumetric data. The 3D MTANN is a supervised volume-processing technique which is trained with input CTC volumes and the corresponding "teaching" volumes. The teaching volume for a polyp contains a 3D Gaussian distribution, and that for a RT contains zeros for enhancement of polyps and suppression of RTs, respectively. For distinction between polyps and nonpolyps including RTs, a 3D scoring method based on a 3D Gaussian weighting function is applied to the output of the trained 3D MTANN. Our database consisted of CTC examinations of 73 patients, scanned in both supine and prone positions (146 CTC data sets in total), with optical colonoscopy as a reference standard for the presence of polyps. Fifteen patients had 28 polyps; 15 of which were 5-9 mm and 13 were 10-25 mm in size. These CTC cases were subjected to our previously reported CAD scheme that included centerline-based segmentation of the colon, shape-based detection of polyps, and reduction of FPs by use of a Bayesian neural network based on geometric and texture features. Application of this CAD scheme yielded 96.4% (27/28) by-polyp sensitivity with 3.1 (224/73) Fps per patient, among which 20 FPs were caused by RTs. To eliminate the FPs due to RTs and possibly other normal structures, we trained a 3D MTANN with ten representative polyps and ten RTs, and applied the trained 3D MTANN, to the above CAD true- and false-positive detections. In the output volumes of the 3D MTANN, polyps were represented by distributions of bright voxels, whereas RTs and other normal structures partly similar to RTs appeared as darker voxels, indicating the ability of the 3D MTANN to suppress RTs as well as other normal structures effectively. Application of the 3D MTANN to the CAD detections showed that the 3D MTANN eliminated all RT-induced 20 FPs, as, well as 53 FPs due to other causes, without removal of any true positives. Overall, the 3D MTANN was able to reduce the FP rate of the CAD scheme from 3.1 to 2.1 FPs per patient (33% reduction), while the original by-polyp sensitivity of 96.4% was maintained. (c) 2006 American Association of Physicists in Medicine.
C1 Univ Chicago, Dept Radiol, Chicago, IL 60637 USA.
   Massachusetts Gen Hosp, Dept Radiol, Boston, MA 02114 USA.
   Harvard Univ, Sch Med, Boston, MA 02114 USA.
C3 University of Chicago; Harvard University; Massachusetts General
   Hospital; Harvard University; Harvard Medical School
RP Suzuki, K (通讯作者)，Univ Chicago, Dept Radiol, 5841 S Maryland Ave, Chicago, IL 60637 USA.
EM suzuki@uchicago.edu
RI Suzuki, Kenji/A-1284-2007; Näppi, Janne J/B-9424-2008
OI Suzuki, Kenji/0000-0002-3993-8309; Näppi, Janne J/0000-0002-0108-0992;
   Dachman, Abraham/0000-0002-7035-2752
CR Acar B, 2002, IEEE T MED IMAGING, V21, P1461, DOI 10.1109/TMI.2002.806405
   Arimura H, 2004, ACAD RADIOL, V11, P617, DOI 10.1016/j.acra.2004.02.009
   CHAKRABORTY DP, 1990, RADIOLOGY, V174, P873, DOI 10.1148/radiology.174.3.2305073
   Fletcher JG, 2005, CURR OPIN GASTROEN, V21, P90
   Frimmel H, 2004, MED PHYS, V31, P3046, DOI 10.1118/1.1790111
   FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   HANLEY JA, 1983, RADIOLOGY, V148, P839, DOI 10.1148/radiology.148.3.6878708
   Iordanescu G, 2004, MED PHYS, V31, P2855, DOI 10.1118/1.1790131
   Jerebko AK, 2003, ACAD RADIOL, V10, P154, DOI 10.1016/S1076-6332(03)80039-9
   Jerebko AK, 2003, MED PHYS, V30, P52, DOI 10.1118/1.1528178
   Johnson CD, 2000, RADIOLOGY, V216, P331, DOI 10.1148/radiology.216.2.r00au47331
   Kiss G, 2002, EUR RADIOL, V12, P77, DOI 10.1007/s003300101040
   Kupinski MA, 2001, IEEE T MED IMAGING, V20, P886, DOI 10.1109/42.952727
   Macari M, 2005, RADIOLOGY, V237, P819, DOI 10.1148/radiol.2373041717
   Metz CE, 1998, MED DECIS MAKING, V18, P110, DOI 10.1177/0272989X9801800118
   Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.3.CO;2-Q
   METZ CE, 1986, INVEST RADIOL, V21, P720, DOI 10.1097/00004424-198609000-00009
   Nappi J, 2004, PROC SPIE, V5370, P839, DOI 10.1117/12.536127
   Nappi J, 2003, MED PHYS, V30, P1592, DOI 10.1118/1.1576393
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   Nappi J, 2005, ACAD RADIOL, V12, P695, DOI 10.1016/j.acra.2004.12.026
   Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Summers RM, 2001, RADIOLOGY, V219, P51, DOI 10.1148/radiology.219.1.r01ap0751
   Summers RM, 2004, RADIOLOGY, V233, P266, DOI 10.1148/radiol.2331031326
   Summers RM, 2005, GASTROENTEROLOGY, V129, P1832, DOI 10.1053/j.gastro.2005.08.054
   Suzuki K, 2006, IEEE T MED IMAGING, V25, P406, DOI 10.1109/TMI.2006.871549
   Suzuki K, 2005, IEEE T MED IMAGING, V24, P1138, DOI 10.1109/TMI.2005.852048
   Suzuki K, 2005, ACAD RADIOL, V12, P1333, DOI 10.1016/j.acra.2005.06.017
   Suzuki K, 2005, ACAD RADIOL, V12, P191, DOI 10.1016/j.acra.2004.11.017
   Suzuki K, 2004, IEEE T MED IMAGING, V23, P330, DOI 10.1109/TMI.2004.824238
   Suzuki K, 2003, IEEE T PATTERN ANAL, V25, P1582, DOI 10.1109/TPAMI.2003.1251151
   Suzuki K, 2003, PROC SPIE, V5032, P1355, DOI 10.1117/12.480181
   Suzuki K, 2003, MED PHYS, V30, P1602, DOI 10.1118/1.1580485
   Suzuki K, 2002, IEICE T INF SYST, VE85D, P1710
   Suzuki K, 2002, IEEE T SIGNAL PROCES, V50, P1787, DOI 10.1109/TSP.2002.1011218
   SUZUKI K, 1995, SYST COMPUT JPN, V26, P66, DOI 10.1002/scj.4690260807
   Suzuki K, 2001, NEURAL PROCESS LETT, V13, P43, DOI 10.1023/A:1009639214138
   Suzuki K, 2004, J NEURAL ENG, V1, P228, DOI 10.1088/1741-2560/1/4/006
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Yoshida H, 2005, ABDOM IMAGING, V30, P26, DOI 10.1007/s00261-004-0244-x
   Yoshida H, 2004, SEMIN ULTRASOUND CT, V25, P419, DOI 10.1053/j.sult.2004.07.002
   Yoshida H, 2002, RADIOGRAPHICS, V22, P963, DOI 10.1148/radiographics.22.4.g02jl16963
   Yoshida H, 2002, RADIOLOGY, V222, P327, DOI 10.1148/radiol.2222010506
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
NR 46
TC 79
Z9 81
U1 1
U2 10
PU AMER ASSOC PHYSICISTS MEDICINE AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0094-2405
J9 MED PHYS
JI Med. Phys.
PD OCT
PY 2006
VL 33
IS 10
BP 3814
EP 3824
DI 10.1118/1.2349839
PG 11
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA 097CN
UT WOS:000241424100023
PM 17089846
DA 2023-04-20
ER

PT J
AU Wang, ZG
   Liang, ZR
   Li, X
   Li, LH
   Li, B
   Eremina, D
   Lu, HB
AF Wang, Zigang
   Liang, Zhengrong
   Li, Xiang
   Li, Lihong
   Li, Bin
   Eremina, Daria
   Lu, Hongbing
TI An improved electronic colon cleansing method for detection of colonic
   polyps by virtual colonoscopy
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE CAD; image segmentation; partial volume effect; virtual colonoscopy
ID COMPUTER-AIDED DETECTION; PARTIAL VOLUME SEGMENTATION; CT COLONOGRAPHY;
   COLORECTAL NEOPLASIA; MAXIMUM-LIKELIHOOD; BOWEL PREPARATION; EM
   ALGORITHM; FEASIBILITY; IMAGES; POPULATION
AB Electronic colon cleansing (ECC) aims to segment the colon lumen from a patient abdominal image acquired using an oral contrast agent for colonic material tagging, so that a virtual colon model can be constructed. Virtual colonoscopy (VC) provides fly-through navigation within the colon model, looking for polyps on the inner surface in a manner analogous to that of fiber optic colonoscopy. We have built an ECC pipeline for a commercial VC navigation system. In this paper, we present an improved ECC method. It is based on a partial-volume (PV) image-segmentation framework, which is derived using the well-established statistical expectation-maximization algorithm. The presented ECC method was evaluated by both visual inspection and computer-aided detection of polyps (CADpolyp) within the cleansed colon lumens obtained using 20 patient datasets. Compared to our previous ECC pipeline, which does not sufficiently consider the PV effect, the method presented in this paper demonstrates improved polyp detection by both visual judgment and CADpolyp measure.
C1 SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
   SUNY Stony Brook, Dept Phys & Astron, Stony Brook, NY 11794 USA.
   SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   SUNY Stony Brook, Dept Biomed Engn, Stony Brook, NY 11794 USA.
   SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook; State University of New York
   (SUNY) System; State University of New York (SUNY) Stony Brook; State
   University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook
RP Liang, ZR (通讯作者)，SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
EM jzl@mil.sunysb.edu
FU NCI NIH HHS [CA82402, R01 CA082402] Funding Source: Medline
CR *AM CANC SOC, 2004, ANN REP CANC FACTS
   Amin Z, 1996, CLIN RADIOL, V51, P56, DOI 10.1016/S0009-9260(96)80221-2
   Callstrom MR, 2001, RADIOLOGY, V219, P693, DOI 10.1148/radiology.219.3.r01jn22693
   Chen DQ, 2000, IEEE T MED IMAGING, V19, P1220, DOI 10.1109/42.897814
   Chiou RCH, 1999, IEEE T NUCL SCI, V46, P1045, DOI 10.1109/23.790824
   CHOI HS, 1991, IEEE T MED IMAGING, V10, P395, DOI 10.1109/42.97590
   COIN CG, 1983, COMPUT RADIOL, V7, P215
   Dachille F, 2001, PROC SPIE, V4321, P500, DOI 10.1117/12.428179
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fenlon HM, 1999, NEW ENGL J MED, V341, P1496, DOI 10.1056/NEJM199911113412003
   Ferrucci JT, 2001, AM J ROENTGENOL, V177, P975, DOI 10.2214/ajr.177.5.1770975
   Ge YR, 1999, J COMPUT ASSIST TOMO, V23, P786, DOI 10.1097/00004728-199909000-00029
   Gonzalez R C, 1992, DIGITAL IMAGE PROCES
   Hara AK, 1997, RADIOLOGY, V205, P59, DOI 10.1148/radiology.205.1.9314963
   Hara AK, 1996, GASTROENTEROLOGY, V110, P284, DOI 10.1053/gast.1996.v110.pm8536869
   HONG L, 1995, P S BIOM VIS, P26
   Hong LC, 1997, IEEE T NUCL SCI, V44, P1297, DOI 10.1109/23.597004
   Johnson CD, 2003, GASTROENTEROLOGY, V125, P311, DOI 10.1016/S0016-5085(03)00894-1
   KIJEWSKI MF, 1987, PHYS MED BIOL, V32, P565, DOI 10.1088/0031-9155/32/5/003
   Lakare S, 2002, PROC SPIE, V4683, P412, DOI 10.1117/12.463608
   Lee T Y, 1999, IEEE Trans Inf Technol Biomed, V3, P139, DOI 10.1109/4233.767089
   Lefere PA, 2002, RADIOLOGY, V224, P393, DOI 10.1148/radiol.2241011222
   LEI TH, 1992, IEEE T MED IMAGING, V11, P53, DOI 10.1109/42.126910
   Li X, 2004, PROC SPIE, V5370, P1419, DOI 10.1117/12.535230
   Liang Z, 2001, INNERVISION, V16, P40
   LIANG Z, 1997, C REC IEEE NUCL SCI
   Liang ZR, 2005, PROC SPIE, V5746, P415, DOI 10.1117/12.597357
   Liang ZR, 2005, PROC SPIE, V5746, P810, DOI 10.1117/12.597437
   Liang ZR, 2003, P ANN INT IEEE EMBS, V25, P682, DOI 10.1109/IEMBS.2003.1279855
   LORENSEN W, 1995, EXPLORATION CROSS SE, P221
   MENG XL, 1993, BIOMETRIKA, V80, P267, DOI 10.1093/biomet/80.2.267
   OBRIEN MJ, 1990, GASTROENTEROLOGY, V98, P371, DOI 10.1016/0016-5085(90)90827-N
   Paik DS, 1998, MED PHYS, V25, P629, DOI 10.1118/1.598244
   Paik DS, 2001, RADIOLOGY, V221, P332
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Pineau BC, 2003, GASTROENTEROLOGY, V125, P304, DOI 10.1016/S0016-5085(03)00885-0
   SERLIE I, 2003, P MICCAI, V2, P175
   Summers RM, 2001, RADIOLOGY, V219, P51, DOI 10.1148/radiology.219.1.r01ap0751
   Van Leemput K, 2003, IEEE T MED IMAGING, V22, P105, DOI 10.1109/TMI.2002.806587
   VINING D, 1994, P ANN M AM ROENTG RA, P104
   VINING DJ, 1999, VIRTUAL COLONOSCOPY, P445
   Wan M, 2002, IEEE T MED IMAGING, V21, P1450, DOI 10.1109/TMI.2002.806409
   Wan M, 2000, PROC SPIE, V3978, P165, DOI 10.1117/12.383395
   Wang Z, 2004, PROC SPIE, V5370, P972, DOI 10.1117/12.535664
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Wang ZG, 2003, PROC SPIE, V5032, P843, DOI 10.1117/12.481915
   WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060
   Yee J, 2001, RADIOLOGY, V219, P685, DOI 10.1148/radiology.219.3.r01jn40685
   Yoshida H, 2002, RADIOLOGY, V222, P327, DOI 10.1148/radiol.2222010506
   Zalis ME, 2004, IEEE T MED IMAGING, V23, P1335, DOI 10.1109/TMI.2004.826050
   Zalis ME, 2001, AM J ROENTGENOL, V176, P646, DOI 10.2214/ajr.176.3.1760646
NR 51
TC 52
Z9 57
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD AUG
PY 2006
VL 53
IS 8
BP 1635
EP 1646
DI 10.1109/TBME.2006.877793
PG 12
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 066XH
UT WOS:000239263400019
PM 16916098
OA Green Accepted
DA 2023-04-20
ER

PT J
AU Vilarino, F
   Spyridonous, P
   Vitria, J
   Azpiroz, F
   Radeva, P
AF Vilarino, F.
   Spyridonous, P.
   Vitria, J.
   Azpiroz, F.
   Radeva, P.
TI Cascade analysis for intestinal contraction detection
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Intestine video analysis; Anisotropic features; Support vector machine;
   Cascade of classifiers
AB In this work, we address the study of intestinal contractions in a novel approach based on a machine learning framework to process data from Wireless Capsule Video Endoscopy Wireless endoscopy represents a unique way to visualize the intestine motility by creating long videos to visualize intestine dynamics. In this paper we argue that to analyze huge amount of wireless endoscopy data and define robust methods for contraction detection we should base our approach on sophisticated machine learning techniques. In particular, we propose a cascade of classifiers in order to remove different physiological phenomenon and obtain the motility pattern of small intestines. Our results show obtaining high specificity and sensitivity rates that highlight the high efficiency of the selected approach and support the feasibility of the proposed methodology in the automatic detection and analysis of intestine contractions.
C1 [Vilarino, F.; Vitria, J.; Radeva, P.] Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
   [Vilarino, F.; Vitria, J.; Radeva, P.] Univ Autonoma Barcelona, Dept Comp Sci, E-08193 Barcelona, Spain.
   [Azpiroz, F.] Hosp Valle De Hebron, Barcelona, Spain.
   [Spyridonous, P.] Univ Patras, Comp Lab, Sch Med, GR-26110 Patras, Greece.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Autonomous University of Barcelona; Hospital Universitari Vall
   d'Hebron; University of Patras
RP Vilarino, F (通讯作者)，Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
RI Radeva, Petia/I-3385-2015; Vitrià, Jordi/AAF-9668-2020; Vilarino,
   Fernando/AAU-4306-2020
OI Radeva, Petia/0000-0003-0047-5172; Vitrià, Jordi/0000-0003-1484-539X;
   Vilarino, Fernando/0000-0002-7705-4141; Azpiroz,
   Fernando/0000-0002-7327-960X
CR Boulougoura M., 2005, P 2 IASTED C BIOM EN, P405
   Hansen MB, 2002, PHYSIOL RES, V51, P541
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kellow JE, 1999, GUT, V45, P17
   Kodogiannis V., 2004, P INT C MED SIGN PRO, P262
   Magoulas GD, 2004, APPL SOFT COMPUT, V4, P369, DOI 10.1016/j.asoc.2004.01.005
   Rey JF, 2004, ENDOSCOPY, V36, P656, DOI 10.1055/s-2004-814557
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Vapnik V., 1999, NATURE STAT LEARNING
NR 10
TC 3
Z9 4
U1 0
U2 0
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD JUN
PY 2006
VL 1
SU 1
BP 9
EP 10
PG 2
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA V32YQ
UT WOS:000208986900004
DA 2023-04-20
ER

PT J
AU Coimbra, MT
   Cunha, JPS
AF Coimbra, Miguel Tavares
   Cunha, Joao Paulo Silva
TI MPEG-7 visual descriptors - Contributions for automated feature
   extraction in capsule endoscopy
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
LA English
DT Article
DE mPEG-7; video annotation; visual descriptors; wireless capsule endoscopy
ID SMALL-BOWEL
AB Recent advances in miniaturization led to the development of what is now called the endoscopic capsule. This small device is swallowed by a patient ana films the whole gastrointestinal tract, allowing the detection of abnormalities. Currently, a doctor typically needs up to two hours to analyze a full exam, so automation is desirable. This paper presents a methodology for measuring the potential of selected visual MPEG-7 descriptors for the task of specific medical event detection such as blood, ulcers. Experiments show that the best results are obtained by the Scalable Color and Homogenous Texture descriptors, especially if only relevant coefficients are used.
C1 Univ Aveiro, IEETA, P-3810193 Aveiro, Portugal.
C3 Universidade de Aveiro
RP Coimbra, MT (通讯作者)，Univ Aveiro, IEETA, P-3810193 Aveiro, Portugal.
EM Miguel.coimbra@ieeta.pt; jcunha@det.ua.pt
RI Cunha, João Paulo S/F-9039-2010; Cunha, João Paulo/AAL-1526-2021
OI Cunha, João Paulo S/0000-0003-4131-9045; Coimbra,
   Miguel/0000-0001-7501-6523
CR Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   CHONG AK, 2003, MED J, V178, P532
   Eidenberger H, 2003, P SOC PHOTO-OPT INS, V5150, P476, DOI 10.1117/12.503064
   Fritscher-Ravens A, 2002, DIGEST DIS, V20, P127, DOI 10.1159/000067484
   Ge ZZ, 2004, WORLD J GASTROENTERO, V10, P1349
   Hara AK, 2004, RADIOLOGY, V230, P260, DOI 10.1148/radiol.2301021535
   HOWARTH P, 2004, NOTEBOOK CROSS L SEP
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   JENSEN DM, 2002, GASTROINTEST ENDOSC, V55, pAB125
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Lewis BS, 2002, GASTROINTEST ENDOSC, V55, pAB125
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   *MPEG, MPEG7
   Mylonaki M, 2002, GASTROINTEST ENDOSC, V55, pAB146
   Pennazio M, 2004, GASTROENTEROLOGY, V126, P643, DOI 10.1053/j.gastro.2003.11.057
   Pennazio M, 2002, GASTROINTEST ENDOSC, V55, pAB87
   Qureshi WA, 2004, NAT REV DRUG DISCOV, V3, P447, DOI 10.1038/nrd1385
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   YAMADA A, ISOIECJTC1SC29WG11N3
   2002, 159383 ISO IEC
   2003, 159386 ISO IEC
NR 22
TC 126
Z9 130
U1 0
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1051-8215
EI 1558-2205
J9 IEEE T CIRC SYST VID
JI IEEE Trans. Circuits Syst. Video Technol.
PD MAY
PY 2006
VL 16
IS 5
BP 628
EP 637
DI 10.1109/TCSVT.2006.873158
PG 10
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 041UW
UT WOS:000237482800006
DA 2023-04-20
ER

PT J
AU Magoulas, GD
AF Magoulas, GD
TI Neuronal networks and textural descriptors for automated tissue
   classification in endoscopy
SO ONCOLOGY REPORTS
LA English
DT Article
DE neuronal network; endoscopy; automated tissue classification;
   statistical descriptor
ID COLONOSCOPIC DIAGNOSIS; ALGORITHM; STEPSIZE
AB This study examines the potential of neuronal networks and textural feature extraction for recognising suspicious regions in endoscopy under variable perceptual conditions and systematic or random noise in the data. Second-order statistics and discrete wavelet transform-based methodologies are examined in terms of their discrimination abilities, and several neuronal network learning algorithms are compared in terms of success. The results provide numerical evidence that neuronal networks are capable of classifying offline and online tissue samples extracted from standard images and VHS videotape recordings of colonoscopy procedures with satisfactory success rates. This type of technology could prove to be useful for developing intelligent adaptive systems that will assist medical experts in real-time to automate minimally invasive diagnostic procedures.
C1 Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HX, England.
C3 University of London; Birkbeck University London
RP Magoulas, GD (通讯作者)，Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, Malet St, London WC1E 7HX, England.
EM gmagoulas@dcs.bbk.ac.uk
RI Magoulas, George/D-5597-2014
OI Magoulas, George/0000-0003-1884-0772
CR HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697
   Karkanis S, 2000, MINIM INVASIV THER, V9, P225, DOI 10.1080/13645700009169652
   Kudo S, 2000, WORLD J SURG, V24, P1081, DOI 10.1007/s002680010154
   LEONDES CT, 1998, NEURAL NETWORK SYSTE, V5
   Looney CG, 1997, PATTERN RECOGNITION
   Magoulas G. D., 2004, WSEAS Transactions on Computers, V3, P1729
   Magoulas GD, 2004, APPL SOFT COMPUT, V4, P369, DOI 10.1016/j.asoc.2004.01.005
   Magoulas GD, 1999, NEURAL COMPUT, V11, P1769, DOI 10.1162/089976699300016223
   Magoulas GD, 2001, NONLINEAR ANAL-THEOR, V47, P3425, DOI 10.1016/S0362-546X(01)00458-8
   Magoulas GD, 1997, NEURAL NETWORKS, V10, P69, DOI 10.1016/S0893-6080(96)00052-4
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   RIEDMILLER M, 1993, P IEEE INT C NEUR NE, P586
   Sharkey AJC, 1997, KNOWL ENG REV, V12, P231, DOI 10.1017/S0269888997003123
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
NR 14
TC 6
Z9 6
U1 0
U2 0
PU PROFESSOR D A SPANDIDOS
PI ATHENS
PA 1, S MERKOURI ST, EDITORIAL OFFICE,, ATHENS 116 35, GREECE
SN 1021-335X
J9 ONCOL REP
JI Oncol. Rep.
PY 2006
VL 15
SI SI
BP 997
EP 1000
PG 4
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA 022OS
UT WOS:000236066000004
PM 16525689
DA 2023-04-20
ER

PT S
AU Spinko, V
   Shi, DM
   Ng, WS
   Leong, JL
AF Spinko, Vladimir
   Shi, Daming
   Ng, Wan Sing
   Leong, Jern-Lin
BE Wang, J
   Yi, Z
   Zurada, JM
   Lu, BL
   Yin, H
TI Gabor neural network for endoscopic image registration
SO ADVANCES IN NEURAL NETWORKS - ISNN 2006, PT 2, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 3rd International Symposium on Neural Networks (ISNN 2006)
CY MAY 28-31, 2006
CL Chengdu, PEOPLES R CHINA
SP Univ Elect Sci & Technol China, Chinese Univ Hong Kong, Asia Pacific Neural Network Assembly, European Neural Network Soc, IEEE Circuits & Syst Soc, IEEE Computat Intelligence Soc, Int Neural Network Soc, Natl Nat Sci Fdn China, KC Wong Educ Fdn, Hong Kong
ID WAVELET NETWORKS
AB In this paper we present a Gabor Wavelet Network, a wavelet neural network based on Gabor functions, applied to image registration. Although wavelet network is time consuming technique, we decrease computational costs by incorporating three techniques: gradient-based feature selection, Gabor filtering, and wavelet neural network. Similarity criterion is built upon analyzing intensity function with Gabor Wavelet Network, which carries out the image registration by both gradient-based and texture features.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore 639798, Singapore.
   Singapore Gen Hosp, Dept Otolaryngol, Singapore 169608, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University; Nanyang Technological
   University & National Institute of Education (NIE) Singapore; Nanyang
   Technological University; Singapore General Hospital
RP Spinko, V (通讯作者)，Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM vlad0001@ntu.edu.sg; asdmshi@ntu.edu.sg; MWSNG@ntu.edu.sg;
   ljlent@gmail.com
RI Shi, Daming/F-6017-2013
CR Christensen O, 2001, B AM MATH SOC, V38, P273, DOI 10.1090/S0273-0979-01-00903-X
   Gabor D., 1946, IEE LONDON, V93, P429
   HEIL CE, 1989, SIAM REV, V31, P628, DOI 10.1137/1031129
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kruger V, 2002, IMAGE VISION COMPUT, V20, P665, DOI 10.1016/S0262-8856(02)00056-2
   Kruger V, 2002, J OPT SOC AM A, V19, P1112, DOI 10.1364/JOSAA.19.001112
   SHI J, 1994, IEEE C COMP VIS PATT, P593
   ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591
   Zhang QH, 1997, IEEE T NEURAL NETWOR, V8, P227, DOI 10.1109/72.557660
NR 9
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-34437-3
J9 LECT NOTES COMPUT SC
PY 2006
VL 3972
BP 480
EP 485
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA BET84
UT WOS:000239483000070
DA 2023-04-20
ER

PT S
AU Spyridonos, P
   Vilarino, F
   Vitria, J
   Azpiroz, F
   Radeva, P
AF Spyridonos, Panagiota
   Vilarino, Fernando
   Vitria, Jordi
   Azpiroz, Fernando
   Radeva, Petia
BE Larsen, R
   Nielsen, M
   Sporring, J
TI Anisotropic feature extraction from endoluminal images for detection of
   intestinal contractions
SO MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI
   2006, PT 2
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Medical Image Computing and
   Computer-Assisted Intervention (MICCAI 2006)
CY OCT 01-06, 2006
CL Copenhagen, DENMARK
SP AstraZeneca, Ctr Clin & Basic Res, Claron, Elsevier, General Elect, Medtronic, No Digital Inc, Siemens Corp Res, Springer, Visiopharm
AB Wireless endoscopy is a very recent and at the same time unique technique allowing to visualize and study the occurrence of contractions and to analyze the intestine motility. Feature extraction is essential for getting efficient patterns to detect contractions in wireless video endoscopy of small intestine. We propose a novel method based on anisotropic image filtering and efficient statistical classification of contraction features. In particular, we apply the image gradient tensor for mining informative skeletons from the original image and a sequence of descriptors for capturing the characteristic pattern of contractions. Features extracted from the endoluminal images were evaluated in terms of their discriminatory ability in correct classifying images as either belonging to contractions or not. Classification was performed by means of a support vector machine classifier with a radial basis function kernel. Our classification rates gave sensitivity of the order of 90.84% and specificity of the order of 94.43% respectively. These preliminary results highlight the high efficiency of the selected descriptors and support the feasibility of the proposed method in assisting the automatic detection and analysis of contractions.
C1 Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
   Univ Autonoma Barcelona, Dept Comp Sci, E-08193 Barcelona, Spain.
   Hosp Univ Vall Hebron, Barcelona, Spain.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Autonomous University of Barcelona; Hospital Universitari Vall
   d'Hebron
RP Spyridonos, P (通讯作者)，Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
RI Vilarino, Fernando/AAU-4306-2020; Radeva, Petia/I-3385-2015; Vitria,
   Jordi/C-7072-2008; Vitrià, Jordi/AAF-9668-2020; Spyridonos,
   Panagiota/AAN-8293-2021; Heredia, Josefina/I-1166-2012
OI Vilarino, Fernando/0000-0002-7705-4141; Radeva,
   Petia/0000-0003-0047-5172; Vitria, Jordi/0000-0003-1484-539X; Vitrià,
   Jordi/0000-0003-1484-539X; Azpiroz, Fernando/0000-0002-7327-960X
CR Acar B, 2002, IEEE T MED IMAGING, V21, P1461, DOI 10.1109/TMI.2002.806405
   Boulougoura M., 2005, P 2 IASTED C BIOM EN, P405
   Cyganek B, 2003, LECT NOTES COMPUT SC, V2658, P721
   Hansen MB, 2002, PHYSIOL RES, V51, P541
   IDDEN G, 2000, NATURE, P541
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kellow JE, 1999, GUT, V45, P17
   KODOGIANNIS VS, 2004, P INT C MED SIGN PRO, P262
   Magoulas GD, 2004, APPL SOFT COMPUT, V4, P369, DOI 10.1016/j.asoc.2004.01.005
   Rey JF, 2004, ENDOSCOPY, V36, P656, DOI 10.1055/s-2004-814557
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Vapnik V., 1999, NATURE STAT LEARNING
NR 12
TC 19
Z9 23
U1 0
U2 3
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-44727-X
J9 LECT NOTES COMPUT SC
PY 2006
VL 4191
BP 161
EP 168
PG 8
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Radiology, Nuclear Medicine &
   Medical Imaging
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA BFF19
UT WOS:000241556700020
PM 17354768
OA Bronze
DA 2023-04-20
ER

PT S
AU Vilarino, F
   Spyridonos, P
   Vitria, J
   Malagelada, C
   Radeva, P
AF Vilarino, Fernando
   Spyridonos, Panagiota
   Vitria, Jordi
   Malagelada, Carolina
   Radeva, Petia
BE MartinezTrinidad, JF
   Ochoa, JAC
   Kittler, J
TI A machine learning framework using SOMs: Applications in the intestinal
   motility assessment
SO PROGRESS IN PATTERN RECOGNITON, IMAGE ANALYSIS AND APPLICATIONS,
   PROCEEDINGS
SE LECTURE NOTES IN COMPUTER SCIENCE
LA English
DT Article; Proceedings Paper
CT 11th Iberoamerican Conference in Pattern Recognition
CY NOV 14-17, 2006
CL Cancun, MEXICO
SP Adv Technol Applicat Ctr Cuba, Mexican Assoc Pattern Recognit, Mexican Assoc Comp Vis, Neurocomp & Robotics, Cuban Assoc Pattern Recognit, Spanish Assoc Pattern Recognit & Image Anal, Portuguese Assoc Pattern Recognit, SIGPR-SBC, Chilean Assoc Pattern Recognit
ID VIDEO CAPSULE ENDOSCOPY; CLASSIFICATION; DISEASE; NETWORKS
AB Small Bowel Motility Assessment by means of Wireless Capsule Video Endoscopy constitutes a novel clinical methodology in which a capsule with a micro-camera attached to it is swallowed by the patient, emitting a RF signal which is recorded as a video of its trip throughout the gut. In order to overcome the main drawbacks associated with this technique -mainly related to the large amount of visualization time required-, our efforts have been focused on the development of a machine learning system, built up in sequential stages, which provides the specialists with the useful part of the video, rejecting those parts not valid for analysis. We successfully used Self Organized Maps in a general semi-supervised framework with the aim of tackling the different learning stages of our system. The analysis of the diverse types of images and the automatic detection of intestinal contractions is performed under the perspective of intestinal motility assessment in a clinical environment.
C1 Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
   Hosp Valle De Hebron, E-08035 Barcelona, Spain.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Hospital Universitari Vall d'Hebron
RP Vilarino, F (通讯作者)，Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
EM fernando@cvc.uab.es
RI Spyridonos, Panagiota/AAN-8293-2021; Vilarino, Fernando/AAU-4306-2020;
   Vitrià, Jordi/AAF-9668-2020; Vitria, Jordi/C-7072-2008; Malagelada,
   Carolina/F-3743-2016; Radeva, Petia/I-3385-2015
OI Vilarino, Fernando/0000-0002-7705-4141; Vitrià,
   Jordi/0000-0003-1484-539X; Vitria, Jordi/0000-0003-1484-539X;
   Malagelada, Carolina/0000-0001-7097-1492; Radeva,
   Petia/0000-0003-0047-5172
CR Ali A, 2004, CLEV CLIN J MED, V71, P415, DOI 10.3949/ccjm.71.5.415
   ANZALI S, 1998, DRUG DISC DES, V11, P273
   Christodoulou CI, 1999, IEEE T BIO-MED ENG, V46, P169, DOI 10.1109/10.740879
   Eliakim R, 2004, WORLD J GASTROENTERO, V10, P1238
   Fireman Z, 2002, ISR MED ASSOC J, V4, P717
   Fireman Z, 2003, GUT, V52, P390, DOI 10.1136/gut.52.3.390
   Glasser K, 1998, UNIX REV-PERFORM COM, V16, P9
   Gonzales RC., 2002, DIGITAL IMAGE PROCES
   GOSTOUT C, 2003, HOSP PHYS, V39, P14
   Kohonen T., 2001, SELF ORG MAPS, DOI 10.1007/978-3-642-56927-2
   Lux CJ, 1998, GROWTH DEVELOP AGING, V62, P95
   Quigley EMM, 1996, GASTROENTEROL CLIN N, V25, P113, DOI 10.1016/S0889-8553(05)70368-X
   Rey JF, 2004, ENDOSCOPY, V36, P656, DOI 10.1055/s-2004-814557
   RUSS JC, 1994, IMAGE PROCESSING HDB
   Schulmann K, 2005, AM J GASTROENTEROL, V100, P27, DOI 10.1111/j.1572-0241.2005.40102.x
   Spyridonos P, 2005, LECT NOTES COMPUT SC, V3708, P531
   *TEC ASS, 2003, 17 TEC ASS BLUE CROS
   Van Biesen W, 1998, NEPHROL DIAL TRANSPL, V13, P59, DOI 10.1093/ndt/13.1.59
   Vapnik V., 1999, NATURE STAT LEARNING
   Vilarino F, 2005, LECT NOTES COMPUT SC, V3687, P783
   Vilarino F, 2006, PATTERN RECOGN LETT, V27, P875, DOI 10.1016/j.patrec.2005.10.011
   Walker AJ, 1999, LANCET, V354, P1518, DOI 10.1016/S0140-6736(99)02186-8
NR 22
TC 8
Z9 9
U1 0
U2 6
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-46556-1
J9 LECT NOTES COMPUT SC
PY 2006
VL 4225
BP 188
EP 197
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Imaging Science & Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology
GA BFF53
UT WOS:000241598400019
OA Bronze
DA 2023-04-20
ER

PT S
AU Kodogiannis, V
   Chowdrey, HS
AF Kodogiannis, V
   Chowdrey, HS
BE Duch, W
   Kacprzyk, J
   Zadrozny, S
TI A neurofuzzy methodology for the diagnosis of wireless-capsule
   endoscopic images
SO ARTIFICIAL NEURAL NETWORKS: BIOLOGICAL INSPIRATIONS - ICANN 2005, PT 1,
   PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Artificial Neural Networks (ICANN 2005)
CY SEP 11-15, 2005
CL Warsaw, POLAND
SP European Neural Network Soc, Int Neural Network Soc, Japanese Neural Network Soc, IEEE Computat Intelligence Soc
AB In this paper, a detection system to support medical diagnosis and detection of abnormal lesions by processing endoscopic images is presented. The endoscopic images possess rich information expressed by texture. Schemes have been developed to extract new texture features from the texture spectra in the chromatic and achromatic domains for a selected region of interest from each colour component histogram of images acquired by the new M2A Swallowable Capsule. The implementation of an advanced fuzzy inference neural network which combines fuzzy systems and clustering schemes and the concept of fusion of multiple classifiers dedicated to specific feature parameters have been also adopted in this paper. The preliminary test results support the feasibility of the proposed method.
C1 Univ Westminster, Sch Comp Sci, Mechatron Grp, London HA1 3TP, England.
   Univ Westminster, Sch Biosci, Dept Biomed Sci, London W1W 6UW, England.
C3 University of Westminster; University of Westminster
RP Kodogiannis, V (通讯作者)，Univ Westminster, Sch Comp Sci, Mechatron Grp, London HA1 3TP, England.
EM kodogiv@wmin.ac.uk; h.s.chowdrey@wrnin.ac.uk
RI Kodogiannis, Vassilis/D-1299-2016
CR Boulougoura M, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P405
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   KUNCHEVA L, 2000, FUZZY CLASSIFIER DES
   Wadge E., 2003, INT C NEUR NETW EXP, P93
NR 5
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-28752-3
J9 LECT NOTES COMPUT SC
PY 2005
VL 3696
BP 647
EP 652
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Biomedical; Neurosciences
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Neurosciences & Neurology
GA BCZ96
UT WOS:000232193800100
DA 2023-04-20
ER

PT S
AU Kodogiannis, VS
   Wadge, E
   Boulougoura, M
   Christou, K
AF Kodogiannis, VS
   Wadge, E
   Boulougoura, M
   Christou, K
BE Bozanis, P
   Houstis, EN
TI Detecting abnormalities in capsule endoscopic images by textural
   description and neural networks
SO ADVANCES IN INFORMATICS, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 10th Panhellenic Conference on Informatics (PCI 2005)
CY NOV 11-13, 2005
CL Volos, GREECE
SP Alpha Bank, Microsoft Hellas, Hellen Org Telecommun, Div Thessaly, Minicipal Volos, Univ Thessaly, Fdn Res & Technol, Hellas FORTH, Ctr Res & Technol, Hellas CERTH
AB In this paper, a detection system to support medical diagnosis and detection of abnormal lesions by processing endoscopic images is presented. The endoscopic images possess rich information expressed by texture. Schemes have been developed to extract texture features from the texture spectra in the chromatic and achromatic domains for a selected region of interest from each colour component histogram of images acquired by the new M2A Swallowable Capsule. The implementation of an advanced neural network scheme and the concept of fusion of multiple classifiers have been also adopted in this paper. The preliminary test results support the feasibility of the proposed method.
C1 Univ Westminster, Mechatron Grp, Sch Comp Sci, London HA1 3TP, England.
C3 University of Westminster
RP Kodogiannis, VS (通讯作者)，Univ Westminster, Mechatron Grp, Sch Comp Sci, London HA1 3TP, England.
EM kodogiv@wmin.ac.uk
RI Kodogiannis, Vassilis/D-1299-2016
CR Boulougoura M, 2004, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING, P405
   Haga Y, 2004, P IEEE, V92, P98, DOI 10.1109/JPROC.2003.820545
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   John R., 2000, FUZZY SYSTEMS MED
   KUNCHEVA L, 2000, FUZZY CLASSIFIER DES
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Wadge E., 2003, Proceedings of the International Conference of Computational Methods in Sciences and Engineering 2003 (ICCMSE 2003), P673
   Wadge E., 2003, INT C NEUR NETW EXP, P93
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Xu L, 1998, NEUROCOMPUTING, V19, P223, DOI 10.1016/S0925-2312(97)00091-X
NR 11
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 3-540-29673-5
J9 LECT NOTES COMPUT SC
PY 2005
VL 3746
BP 735
EP 745
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA BDJ02
UT WOS:000233675500070
DA 2023-04-20
ER

PT J
AU Magoulas, GD
   Plagianakos, VP
   Vrahatis, MN
AF Magoulas, GD
   Plagianakos, VP
   Vrahatis, MN
TI Neural network-based colonoscopic diagnosis using on-line learning and
   differential evolution
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE minimally invasive imaging procedures; back-propagation networks;
   medical image interpretation; on-line learning; differential evolution
   strategies; artificial evolution
ID CONVERGENCE; ALGORITHM
AB In this paper, on-line training of neural networks is investigated in the context of computer-assisted colonoscopic diagnosis. A memory-based adaptation of the learning rate for the on-line back-propagation ( BP) is proposed and used to seed an on-line evolution process that applies a differential evolution ( DE) strategy to ( re-) adapt the neural network to modified environmental conditions. Our approach looks at on-line training from the perspective of tracking the changing location of an approximate solution of a pattern-based, and thus, dynamically changing, error function. The proposed hybrid strategy is compared with other standard training methods that have traditionally been used for training neural networks off-line. Results in interpreting colonoscopy images and frames of video sequences are promising and suggest that networks trained with this strategy detect malignant regions of interest with accuracy. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HX, England.
   Univ Patras, Dept Math, GR-26110 Patras, Greece.
   Univ Patras, UPAIRC, GR-26110 Patras, Greece.
C3 University of London; Birkbeck University London; University of Patras;
   University of Patras
RP Magoulas, GD (通讯作者)，Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, Malet St, London WC1E 7HX, England.
EM gmagoulas@dcs.bbk.ac.uk; vpp@math.upatras.gr; vrahatis@math.upatras.gr
RI Magoulas, George/D-5597-2014; Vrahatis, Michael N./G-2187-2014
OI Magoulas, George/0000-0003-1884-0772; 
CR Almeida LB, 1998, PARAMETER ADAPTATION, P111
   Angeline P. J., 1997, Evolutionary Programming VI. 6th International Conference, EP97. Proceedings, P335, DOI 10.1007/BFb0014823
   Anguita D., 2001, P EUR S INT TECHN HY, P1
   BATTITI R, 1992, NEURAL COMPUT, V4, P141, DOI 10.1162/neco.1992.4.2.141
   DELANEY PM, 1998, METHODS DIS INVESTIG
   Doulamis AD, 2000, IEEE T NEURAL NETWOR, V11, P137, DOI 10.1109/72.822517
   HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697
   HANKA R, 1996, HEALTHCARE COMPUTING, P275
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Innocent PR, 1997, ARTIF INTELL MED, V11, P241, DOI 10.1016/S0933-3657(97)00032-8
   JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2
   Karkanis S, 2000, MINIM INVASIV THER, V9, P225, DOI 10.1080/13645700009169652
   KARKANIS SA, 2001, P IEEE INT C IM PROC
   Kudo S, 2000, WORLD J SURG, V24, P1081, DOI 10.1007/s002680010154
   LEONDES CT, 1998, NEURAL NETWORK SYSTE, V5
   Looney CG, 1997, PATTERN RECOGNITION
   Magoulas GD, 1999, NEURAL COMPUT, V11, P1769, DOI 10.1162/089976699300016223
   Magoulas GD, 2001, NONLINEAR ANAL-THEOR, V47, P3425, DOI 10.1016/S0362-546X(01)00458-8
   MAGOULAS GD, 1997, MATH NEURAL NETWORKS, P245
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Nagata S, 2000, INT J ONCOL, V16, P927
   Phee SJ, 1998, IEEE ENG MED BIOL, V17, P81, DOI 10.1109/51.677173
   PLAGIANAKOS VP, 2001, ADV CONVEX ANAL GLOB, V54, P421
   PLAGIANAKOS VP, 2001, ADV CONVEX ANAL GLOB, V54, P433
   RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623
   Roehl NM, 2001, NEURAL COMPUT APPL, V10, P101, DOI 10.1007/s005210170002
   Saad David., 1998, ON LINE LEARNING NEU
   SALOMON R, 1998, LECT NOTES COMPUTER, V1363
   SCHRAUDOLPH NN, 1998, IDSIA0998
   SCHRAUDOLPH NN, 1999, IDSIA0999
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sutton R. S., 1993, P INT C MACHINE LEAR
   SUTTON RS, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P171
   VAVAK F, 1996, LECT NOTES COMPUTER, V1143
   VOGL TP, 1988, BIOL CYBERN, V59, P257, DOI 10.1007/BF00332914
NR 35
TC 65
Z9 68
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD SEP
PY 2004
VL 4
IS 4
BP 369
EP 379
DI 10.1016/j.asoc.2004.01.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 900IK
UT WOS:000227208400004
OA Green Submitted, Green Accepted
DA 2023-04-20
ER

PT J
AU Guvenir, HA
   Emeksiz, N
   Ikizler, N
   Ormeci, N
AF Guvenir, HA
   Emeksiz, N
   Ikizler, N
   Ormeci, N
TI Diagnosis of gastric carcinoma by classification on feature projections
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE machine learning; voting; feature projection; benefit maximization;
   gastric carcinoma
ID DIFFERENTIAL-DIAGNOSIS; CANCER; RULES
AB A new classification algorithm, called benefit maximizing classifier on feature projections (BCFP), is developed and applied to the problem of diagnosis of gastric carcinoma. The domain contains records of patients with known diagnosis through gastroscopy results. Given a training set of such records, the BCFP classifier learns how to differentiate a new case in the domain. BCFP represents a concept in the form of feature projections on each feature dimension separately. Classification in the BCFP algorithm is based on a voting among the individual predictions made on each feature. In the gastric carcinoma domain, a lesion can be an indicator of one of nine different Levels of gastric carcinoma, from early to late stages. The benefit of correct classification of early levels is much more than that of late cases. Also, the costs of wrong classifications are not symmetric. In the training phase, the BCFP algorithm learns classification rules that maximize the benefit of classification. In the querying phase, using these rules, the BCFP algorithm tries to make a prediction maximizing the benefit. A genetic algorithm is applied to select the relevant features. The performance of the BCFP algorithm is evaluated in terms of accuracy and running time. The rules induced are verified by experts of the domain. (C) 2004 Elsevier B.V. All rights reserved.
C1 Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
   Cent Bank Republ Turkey, Ankara, Turkey.
   Ankara Univ, Sch Med, TR-06100 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University; Central Bank of the Republic of
   Turkey; Ankara University
RP Guvenir, HA (通讯作者)，Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM guvenir@cs.bilkent.edu.tr
RI Guvenir, Halil Altay/A-7861-2010; Ikizler-Cinbis, Nazli/E-8961-2013;
   Ormeci, Necati/K-1194-2018
OI Guvenir, Halil Altay/0000-0003-2589-316X; 
CR Demiroz G, 1997, LECT NOTES ARTIF INT, V1224, P85
   Domingos P., 1999, P 5 ACM SIGKDD INT C, V99, P155, DOI DOI 10.1145/312129.312220
   Duda R.O., 1973, PATTERN CLASSIFICATI
   Goldberg, 1989, GENETIC ALGORITHM SE
   Guvenir HA, 1997, COMPUT CARDIOL, V24, P433, DOI 10.1109/CIC.1997.647926
   Guvenir HA, 2000, EXPERT SYST APPL, V18, P43, DOI 10.1016/S0957-4174(99)00049-4
   Guvenir HA, 1996, MACH LEARN, V23, P47
   Guvenir HA, 1998, ARTIF INTELL MED, V13, P147, DOI 10.1016/S0933-3657(98)00028-1
   HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932
   John GH, 1994, P 11 INT C MACH LEAR, P121, DOI [10.1016/B978-1-55860-335-6.50023-4, DOI 10.1016/B978-1-55860-335-6.50023-4]
   KAJITANI T, 1981, JPN J SURG, V11, P127
   KONONENKO I, 1993, APPL ARTIF INTELL, V7, P317, DOI 10.1080/08839519308949993
   Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027
   Kurihara H, 1998, JPN J CLIN ONCOL, V28, P233, DOI 10.1093/jjco/28.3.233
   ORMECI N, 1993, RECENT ADV MANAGE DI, P339
   Ting KM, 2003, COMPUT INTELL-US, V19, P186, DOI 10.1111/1467-8640.00219
   TORII A, 1994, CANCER DETECT PREV, V18, P437
   *U WAIK SOFTW DOC, WEK, V3
   YANG J, 1998, FEATURE EXTRACTION C
   Yokota T, 1999, CAN J SURG, V42, P371
NR 20
TC 8
Z9 9
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD JUL
PY 2004
VL 31
IS 3
BP 231
EP 240
DI 10.1016/j.artmed.2004.03.003
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 848ZD
UT WOS:000223505900005
PM 15302089
OA Green Published
DA 2023-04-20
ER

PT J
AU Huang, CR
   Sheu, BS
   Chung, PC
   Yang, HB
AF Huang, CR
   Sheu, BS
   Chung, PC
   Yang, HB
TI Computerized diagnosis of Helicobacter pylori infection and associated
   gastric inflammation from endoscopic images by refined feature selection
   using a neural network
SO ENDOSCOPY
LA English
DT Article
ID PEPTIC-ULCER DISEASE; TRIPLE THERAPY; DUAL THERAPY; ATROPHY; CANCER;
   CLASSIFICATION; ERADICATION; HISTOLOGY
AB Background and Study Aim: We investigated whether analysis of endoscopic images using a refined feature selection with neural network (RFSNN) technique could predict Helicobacter pylori-related gastric histological features.
   Patients and Methods: A total of 104 dyspeptic patients were prospectively enrolled for panendoscopy and gastric biopsy for histological evaluation using the updated Sydney system. The endoscopic images of each patient were analyzed to obtain 84 image parameters. The significant image parameters from 30 randomly selected patients (15 with and 15 without H. pylori infection) associated with histological features were used to develop the RFSNN model. This was then used to test the sensitivity and specificity of the image parameters obtained from the remaining 74 patients for the prediction of the presence of H. pylori infection and related histological features.
   Results: The RFSNN technique had a sensitivity of 85.4% and a specificity of 90.9% for the detection of H. pylori infection. Moreover, RFSNN was highly accurate (> 80%) in predicting the presence of gastric atrophy, intestinal metaplasia and the severity of H. pylori-related gastric inflammation.
   Conclusions: RFSNN is an effective computerized technique for assessing the presence of H. pylori infection and related gastric inflammation and precancerous lesions. By using RFSNN to analyze endoscopic images, a comprehensive evaluation of the stomach may be done, thus avoiding the need for invasive but localized biopsy sampling for histological examination.
C1 Natl Cheng Kung Univ Hosp, Dept Internal Med, Tainan 70428, Taiwan.
   Natl Cheng Kung Univ, Dept Elect Engn, Tainan, Taiwan.
   Natl Cheng Kung Univ, Dept Pathol, Tainan 70101, Taiwan.
   Ton Yen Gen Hosp, Chu Pei, Taiwan.
C3 National Cheng Kung University; National Cheng Kung University Hospital;
   National Cheng Kung University; National Cheng Kung University
RP Sheu, BS (通讯作者)，Natl Cheng Kung Univ Hosp, Dept Internal Med, 138 Sheng Li Rd, Tainan 70428, Taiwan.
EM sheubs@mail.ncku.edu.tw
RI Chung, Pau-Choo/ABB-3574-2021
CR CORREA P, 1995, J NATL CANCER I, V87, P1731, DOI 10.1093/jnci/87.23.1731
   Dixon MF, 1996, AM J SURG PATHOL, V20, P1161, DOI 10.1097/00000478-199610000-00001
   Haykin S., 1999, KNOWL ENG REV, V2nd
   Jang TJ, 2001, INT J CANCER, V93, P629, DOI 10.1002/ijc.1394
   Kashiwagi H, 2003, ENDOSCOPY, V35, P9, DOI 10.1055/s-2003-36397
   McColl KEL, 1997, GUT, V40, P302, DOI 10.1136/gut.40.3.302
   PARKER DB, 1987, IEEE 1 INT C NEUR NE
   PARSONNET J, 1991, NEW ENGL J MED, V325, P1127, DOI 10.1056/NEJM199110173251603
   Robert MH, 1973, IEEE T SYST MAN CYB, VSMC-3, P610
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sheu BS, 1998, J FORMOS MED ASSOC, V97, P266
   Sheu BS, 1996, GASTROINTEST ENDOSC, V44, P683, DOI 10.1016/S0016-5107(96)70052-4
   Sheu BS, 2001, DIGEST DIS SCI, V46, P2700, DOI 10.1023/A:1012727513166
   Tabata H, 1999, DIGEST DIS SCI, V44, P2027, DOI 10.1023/A:1026622418625
   UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760
   WALSH JH, 1995, NEW ENGL J MED, V333, P984, DOI 10.1056/NEJM199510123331508
   Yagi K, 2002, ENDOSCOPY, V34, P376, DOI 10.1055/s-2002-25281
   Yang HB, 1997, DIGEST DIS SCI, V42, P1835, DOI 10.1023/A:1018894606541
NR 18
TC 32
Z9 33
U1 0
U2 5
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD JUL
PY 2004
VL 36
IS 7
BP 601
EP 608
DI 10.1055/s-2004-814519
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 835LG
UT WOS:000222484000005
PM 15243882
DA 2023-04-20
ER

PT J
AU Serrano-Durba, A
   Serrano, AJ
   Magdalena, JR
   Martin, JD
   Soria, E
   Dominguez, C
   Estornell, F
   Garcia-Ibarra, F
AF Serrano-Durba, A
   Serrano, AJ
   Magdalena, JR
   Martin, JD
   Soria, E
   Dominguez, C
   Estornell, F
   Garcia-Ibarra, F
TI The use of neural networks for predicting the result of endoscopic
   treatment for vesico-ureteric reflux
SO BJU INTERNATIONAL
LA English
DT Article
DE neural network; VUR; reflux; endoscopic treatment
ID RADICAL PROSTATECTOMY; LOGISTIC-REGRESSION; INJECTION; CHILDREN; DISEASE
AB Objective To create an artificial neural network (ANN) to aid in predicting the results of endoscopic treatment for vesico-ureteric reflux (VUR).
   Materials and Methods During 1999-2001 we used endoscopic treatment in 261 ureteric units with VUR of all grades and causes. An ANN based on multilayer perceptron architecture was created using an 11 x 6 x 1 structure, taking the following as variables: the cause and grade of VUR, the patient's age and sex, the type of implanted substance and its volume, the number of treatments, the affected ureter, the endoscopic findings, and the type of cystography used. In all, 174 cases were used as training samples for the ANN and 87 to validate it. We calculated the sensitivity, specificity, positive (PPV) and negative predictive values (NPV), and the success rate (%) of the system.
   Results In the training group the ANN gave a sensitivity of 86.4%, a specificity of 89.5%, a PPV of 76% and NPV of 94%, with a success rate of 88.6%. In the same training group logistic regression (LR) gave respective values of 68.2%, 58.8%, 39%, 82.7% and 61.4%. In the validation group the respective values for the ANN were 71.4%, 81.6%, 58.8%, 88.6% and 78.9%, and in the same validation group the LR gave 64.4%, 50%, 32.1%, 79.2% and 53.9%. The Wilcoxon test confirmed the independence of both methods (P < 0.001).
   Conclusion The ANN is an effective tool for assisting the urologist in indicating and applying endoscopic treatments for VUR.
C1 La Fe Childrens Hosp, Serv Urol, Valencia, Spain.
   Univ Valencia, Dept Elect Engn, Valencia, Spain.
C3 University of Valencia
RP Serrano-Durba, A (通讯作者)，Hosp Infantil La Fe, Serv Urol Infantil, Ave Campanar 21, Valencia 46009, Spain.
EM serrano_agu@gva.es
RI Serrano-López, Antonio J./L-5701-2014; Martín-Guerrero, José
   D./L-8146-2014
OI Serrano-López, Antonio J./0000-0002-3863-8611; Martín-Guerrero, José
   D./0000-0001-9378-0285; Soria Olivas, Emilio/0000-0002-9148-8405;
   Magdalena, Rafael/0000-0003-3752-8231
CR Borque A, 2001, J UROLOGY, V166, P1672, DOI 10.1016/S0022-5347(05)65651-0
   Chertin B, 2002, J UROLOGY, V167, P1443, DOI 10.1016/S0022-5347(05)65340-2
   Chiang D, 2003, BJU INT, V91, P661, DOI 10.1046/j.1464-410X.2003.03067.x
   DEWAN PA, 1995, AUST NZ J SURG, V65, P642, DOI 10.1111/j.1445-2197.1995.tb00671.x
   DURBA AS, 2002, UROL INTEGR INVEST, V7, P490
   Finne P, 2001, BJU INT, V88, P825, DOI 10.1046/j.1464-4096.2001.02461.x
   Herz D, 2001, J UROLOGY, V166, P1880, DOI 10.1016/S0022-5347(05)65712-6
   LEVITT SB, 1981, PEDIATRICS, V67, P392
   Mattfeldt T, 1999, BJU INT, V84, P316
   ODONNELL B, 1984, BRIT MED J, V289, P7, DOI 10.1136/bmj.289.6436.7
   OhnoMachado L, 1997, COMPUT BIOL MED, V27, P55, DOI 10.1016/S0010-4825(96)00036-4
   Ortenberg J, 1998, UROL CLIN N AM, V25, P151, DOI 10.1016/S0094-0143(05)70441-9
   Puri P, 1998, J UROLOGY, V160, P1007, DOI 10.1016/S0022-5347(01)62683-1
   SCHULMAN CC, 1992, EUR J PEDIATR SURG, V2, P32, DOI 10.1055/s-2008-1063396
   Schumacher M, 1996, COMPUT STAT DATA AN, V21, P661, DOI 10.1016/0167-9473(95)00032-1
   SERRANO A, 2002, P 6 INT WORK C ART N, P345
   Shoskes DA, 1998, TRANSPLANT P, V30, P1316, DOI 10.1016/S0041-1345(98)00257-7
   Trsinar B, 1999, EUR UROL, V36, P635
NR 18
TC 7
Z9 8
U1 2
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1464-4096
EI 1464-410X
J9 BJU INT
JI BJU Int.
PD JUL
PY 2004
VL 94
IS 1
BP 120
EP 122
DI 10.1111/j.1464-410X.2004.04912.x
PG 3
WC Urology & Nephrology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Urology & Nephrology
GA 832TM
UT WOS:000222290100027
PM 15217444
DA 2023-04-20
ER

PT J
AU Hoppe, H
   Quattropani, C
   Spreng, A
   Mattich, J
   Netzer, P
   Dinkel, HP
AF Hoppe, H
   Quattropani, C
   Spreng, A
   Mattich, J
   Netzer, P
   Dinkel, HP
TI Virtual colon dissection with CT colonography compared with axial
   interpretation and conventional colonoscopy: Preliminary results
SO AMERICAN JOURNAL OF ROENTGENOLOGY
LA English
DT Article
ID COMPUTED TOMOGRAPHIC COLONOGRAPHY; COLORECTAL POLYPS; CANCER;
   OPTIMIZATION; SEGMENTATION; PERFORMANCE; FEASIBILITY; NEOPLASIA; MODES
AB OBJECTIVE. The aim of this study was to determine whether a new virtual colon dissection 3D visualization technique for CT colonography has a shorter analysis time and better sensitivity for detection of colonic polyps than interpretation of axial CT images.
   SUBJECTS AND METHODS. CT colonography was performed in 22 patients using 4-MDCT followed by conventional colonoscopy on the same day. The CT colonography data sets were analyzed by virtual colon dissection, which virtually bisects and unfolds the colon along its longitudinal axis to inspect the inner colonic surface for polyps. The same CT data sets were independently evaluated using axial interpretation. All data sets were independently interpreted by two radiologists in a blinded manner.
   RESULTS. Conventional colonoscopy revealed 31 colonic lesions in 20 patients. Twenty-two of the lesions were smaller than 10 mm; nine were 10 turn or larger. Two of the original 22 patients were excluded, one because of residual stool and fluid and the other because of an impassable stenosing rectal wall cancer. For virtual colon dissection, the per-lesion sensitivity was 42% for observer 1 and 68% for observer 2; for axial interpretation, the respective sensitivities were 48% and 61%. For polyps 10 mm or larger, the respective sensitivities were 67% and 89% for virtual colon dissection and 89% and 100% for axial interpretation. The average time for reconstruction and analysis of virtual colon dissection was 36.8 min versus 29.2 min for axial images. Virtual colon dissection was feasible in both the supine and the prone positions in 45.5% of colonic segments, in either the supine or the prone position in 24.5%, and in neither position in 30% of segments.
   CONCLUSION. Although virtual colon dissection may facilitate detection of colonic polyps in isolated cases, its detection rate is not superior to axial interpretation, which is mainly attributable to failed rendering of insufficiently distended colonic segments or regions with residual feces. Virtual colon dissection is also the more time-consuming of the two procedures. With further improvement of path-finding and image segmentation, however, virtual colon dissection has the potential to be a useful interpretation tool for CT colonography.
C1 Univ Bern, Inselspital, Inst Diagnost Radiol, CH-3010 Bern, Switzerland.
   Univ Bern, Inselspital, Dept Gastroenterol, CH-3010 Bern, Switzerland.
C3 University of Bern; University Hospital of Bern; University of Bern;
   University Hospital of Bern
RP Dinkel, HP (通讯作者)，Univ Bern, Inselspital, Inst Diagnost Radiol, Freiburgstr 10, CH-3010 Bern, Switzerland.
EM hans-peter.dinkel@insel.ch
CR Beaulieu CF, 1999, RADIOLOGY, V212, P203, DOI 10.1148/radiology.212.1.r99jl17203
   Chen SC, 1999, AM J ROENTGENOL, V172, P595, DOI 10.2214/ajr.172.3.10063842
   Dachman AH, 1998, AM J ROENTGENOL, V171, P989, DOI 10.2214/ajr.171.4.9762982
   Dave SB, 1999, ACAD RADIOL, V6, P398, DOI 10.1016/S1076-6332(99)80190-1
   Fenlon HM, 1999, NEW ENGL J MED, V341, P1496, DOI 10.1056/NEJM199911113412003
   Ferrucci JT, 2001, AM J ROENTGENOL, V177, P975, DOI 10.2214/ajr.177.5.1770975
   Fletcher JG, 2000, EUR RADIOL, V10, P786, DOI 10.1007/s003300051006
   Fletcher JG, 2001, J COMPUT ASSIST TOMO, V25, P864, DOI 10.1097/00004728-200111000-00006
   Fletcher JG, 2000, RADIOLOGY, V216, P704, DOI 10.1148/radiology.216.3.r00au41704
   Halpern EF, 2003, RADIOLOGY, V226, P12, DOI 10.1148/radiol.2261011712
   Hara AK, 1997, RADIOLOGY, V205, P59, DOI 10.1148/radiology.205.1.9314963
   Johnson CD, 2003, GASTROENTEROLOGY, V125, P311, DOI 10.1016/S0016-5085(03)00894-1
   LEVIN T, 1997, CA CANC J CLIN, V154, P154
   Macari M, 2000, AM J ROENTGENOL, V174, P1543, DOI 10.2214/ajr.174.6.1741543
   Macari M, 2001, AM J ROENTGENOL, V176, P137, DOI 10.2214/ajr.176.1.1760137
   McFarland EG, 2001, RADIOLOGY, V218, P375, DOI 10.1148/radiology.218.2.r01ja47375
   Nappi J, 2002, J COMPUT ASSIST TOMO, V26, P493, DOI 10.1097/01.RCT.0000025350.64054.4E
   Netzer P, 1999, DIS COLON RECTUM, V42, P661, DOI 10.1007/BF02234146
   Oto A, 2003, EUR RADIOL, V13, P1657, DOI 10.1007/s00330-002-1770-y
   Paik DS, 2000, J COMPUT ASSIST TOMO, V24, P179, DOI 10.1097/00004728-200003000-00001
   Power NP, 2002, BRIT J RADIOL, V75, P401, DOI 10.1259/bjr.75.893.750401
   Reed JE, 1997, J DIGIT IMAGING, V10, P70, DOI 10.1007/BF03168661
   Royster AP, 1997, AM J ROENTGENOL, V169, P1237, DOI 10.2214/ajr.169.5.9353434
   Summers RM, 2000, RADIOLOGY, V216, P284, DOI 10.1148/radiology.216.1.r00jl43284
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   WINGO PA, 1995, CA-CANCER J CLIN, V45, P8, DOI 10.3322/canjclin.45.1.8
   Yee J, 2001, RADIOLOGY, V219, P685, DOI 10.1148/radiology.219.3.r01jn40685
NR 27
TC 55
Z9 57
U1 1
U2 2
PU AMER ROENTGEN RAY SOC
PI RESTON
PA 1891 PRESTON WHITE DR, SUBSCRIPTION FULFILLMENT, RESTON, VA 22091 USA
SN 0361-803X
EI 1546-3141
J9 AM J ROENTGENOL
JI Am. J. Roentgenol.
PD MAY
PY 2004
VL 182
IS 5
BP 1151
EP 1158
DI 10.2214/ajr.182.5.1821151
PG 8
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA 815DF
UT WOS:000221022300011
PM 15100110
DA 2023-04-20
ER

PT J
AU Ma, X
   Brett, PN
   Wright, MT
   Griffiths, MV
AF Ma, X
   Brett, PN
   Wright, MT
   Griffiths, MV
TI A flexible digit with tactile feedback for invasive clinical
   applications
SO PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART H-JOURNAL OF
   ENGINEERING IN MEDICINE
LA English
DT Article
DE tactile; sensor; minimal invasive surgery; endoscopy; flexible digit;
   neural network application
AB This paper describes research on measurement of tactile sense using a flexible digit appropriate to endoscopy and minimal access surgery. It is envisaged that the sensing method will facilitate the navigation of flexible invasive devices, such as endoscopes, and also aid diagnosis using tactile perception as well as visual observation. The proposed master-slave digit system incorporates the application of the distributive sensing method applied to tactile sensing in order to discriminate different contact conditions of the flexible digit. The paper concentrates on the description of the application of this method and places this in the context of the user and the integrated system. The approach to sensing is able to discriminate the position, magnitude, distributed profile and width of the applied contacting load by using only four sensing points. Values to describe these parameters are evaluated to an accuracy greater than 93 per cent.
C1 Aston Univ, Sch Engn & Appl Sci, Birmingham B4 7ET, W Midlands, England.
C3 Aston University
RP Ma, X (通讯作者)，Aston Univ, Sch Engn & Appl Sci, Birmingham B4 7ET, W Midlands, England.
OI Ma, Xianghong/0000-0003-4957-2942
CR BRETT PN, 2000, WORLD C MED ENG IEEE
   Cook R.D., CONCEPTS APPL FINITE
   DAKE JM, 1991, P 5 INT C ADV ROB 19, P888
   DARIO P, 2000, IEEE T INF TECHN MAR, V4
   Davies BL, 1994, P 1 INT C MED ROB CO, P258
   Harris SJ, 1997, P I MECH ENG H, V211, P317, DOI 10.1243/0954411971534449
   Ma XH, 2002, IEEE T INSTRUM MEAS, V51, P331, DOI 10.1109/19.997833
   TAYLOR RH, 1990, J ROBOTICS SOC J OCT, P111
   TONGPADUNGROD P, 2003, INT J SENSORS ACTUAT
NR 9
TC 14
Z9 14
U1 0
U2 2
PU PROFESSIONAL ENGINEERING PUBLISHING LTD
PI BURY ST EDMUNDS
PA NORTHGATE AVENUE, BURY ST EDMUNDS IP32 6BW, SUFFOLK, ENGLAND
SN 0954-4119
J9 P I MECH ENG H
JI Proc. Inst. Mech. Eng. Part H-J. Eng. Med.
PD MAY
PY 2004
VL 218
IS H3
BP 151
EP 157
DI 10.1243/095441104323118860
PG 7
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 832OJ
UT WOS:000222276500001
PM 15239565
DA 2023-04-20
ER

PT S
AU Kiss, G
   Van Cleynenbreugel, J
   Marchal, G
   Suetens, P
AF Kiss, G
   Van Cleynenbreugel, J
   Marchal, G
   Suetens, P
BE Barillot, C
   Haynor, DR
   Hellier, P
TI Computer Aided Detection in CT colonography, via spin images
SO MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION - MICCAI
   2004, PT 2, PROCEEDINGS
SE Lecture Notes in Computer Science
LA English
DT Article; Proceedings Paper
CT 7th International Conference on Medical Image Computing and
   Computer-Assisted Intervention (MICCAI 2004)
CY SEP 26-29, 2004
CL St Malo, FRANCE
SP IRISA, CNRS, Univ Rennes
AB A technique for Computer Aided Detection (CAD) of colonic polyps, in Computed Tomographic (CT) Colonography is presented. Following the segmentation of the colonic wall, normal wall is identified using a fast geometric scheme able to approximate local curvature. The remaining structures are modeled using spin images and then compared to a set of existing polypoid models. Locations with the highest probability of being colonic polyps are labeled as final candidates. Models are computed by an unsupervised learning technique, using a leave one out technique on a study group of 50 datasets. True positive and false positive findings were determined, employing fiber optic colonoscopy as standard of reference. The detection rate for polyps larger than 6 mm was above 85%, with an average false positive detection rate of 2.75 per case. The overall computation time for the method is approximately 6 minutes. Initial results show that Computer Aided Detection is feasible and that our method holds potential for screening purposes.
C1 Univ Hosp Gasthuisberg, Fac Med & Engn, Radiol ESAT,PSI, B-3000 Louvain, Belgium.
C3 KU Leuven; University Hospital Leuven
RP Kiss, G (通讯作者)，Univ Hosp Gasthuisberg, Fac Med & Engn, Radiol ESAT,PSI, Herestr 49, B-3000 Louvain, Belgium.
EM Gabriel.Kiss@uz.kuleuven.ac.be
CR ANDREW J, 1997, THESIS CARNEGIE MELL
   Ballard D. H., 1982, COMPUTER VISION, P123
   GASTROENTERICO TA, 1998, DATI PIANIFICAZIONE
   Kiss G, 2003, LECT NOTES COMPUT SC, V2878, P746
   Kiss G., 2002, P 7 INT WORKSH VIS M, P27
   MORSON BC, 1966, P ROY SOC MED, V59, P607, DOI 10.1177/003591576605900710
   SUMMERS RM, 2000, FEASIBILITY STUDY RA, P284
   Vining DJ, 1994, RADIOLOGY, V193, P446
   WIEMKER R, 2001, P COMP ASS RAD SURG
   YSOHIDA H, 2001, IEEE T MED IMAGING, P1261
NR 10
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 3-540-22977-9
J9 LECT NOTES COMPUT SC
PY 2004
VL 3217
BP 804
EP 812
PN 2
PG 9
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Imaging Science & Photographic Technology; Radiology,
   Nuclear Medicine & Medical Imaging
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Imaging Science & Photographic Technology; Radiology,
   Nuclear Medicine & Medical Imaging
GA BAZ67
UT WOS:000224322400098
DA 2023-04-20
ER

PT J
AU Das, A
   Ben-Menachem, T
   Cooper, GS
   Chak, A
   Sivak, MV
   Gonet, JA
   Wong, RCK
AF Das, A
   Ben-Menachem, T
   Cooper, GS
   Chak, A
   Sivak, MV
   Gonet, JA
   Wong, RCK
TI Prediction of outcome in acute lower-gastrointestinal haemorrhage based
   on an artificial neural network: internal and external validation of a
   predictive model
SO LANCET
LA English
DT Article; Proceedings Paper
CT Digestive Disease Week Meeting/102nd Annual Meeting of the
   American-Gastroenterological-Association
CY MAY 20-23, 2001
CL ATLANTA, GA
SP Amer Gastroenterol Assoc
ID DIAGNOSIS; DECISION
AB Background Models based on artificial neural networks (ANN) are useful in predicting outcome of various disorders. There is currently no useful predictive model for risk assessment in acute lower-gastrointestinal haemorrhage. We investigated whether ANN models using information available during triage could predict clinical outcome in patients with this disorder.
   Methods ANN and multiple-logistic-regression (MLR) models were constructed from non-endoscopic data of patients admitted with acute lower-gastrointestinal haemorrhage. The performance of ANN in classifying patients into high-risk and low-risk groups was compared with that of another validated scoring system (BLEED), with the outcome variables recurrent bleeding, death, and therapeutic interventions for control of haemorrhage. The ANN models were trained with data from patients admitted to the primary institution during the first 12 months (n=120) and then internally validated with data from patients admitted to the same institution during the next 6 months (n=70). The ANN models were then externally validated and direct comparison made with MLR in patients admitted to an independent institution in another US state (n=142).
   Findings Clinical features were similar for training and validation groups. The predictive accuracy of ANN was significantly better than that of BLEED (predictive accuracy in internal validation group for death 87% vs 21%; for recurrent bleeding 89% vs 41%; and for intervention 96% vs 46%) and similar to MLR. During external validation, ANN performed well in predicting death (97%), recurrent bleeding (93%), and need for intervention (94%), and it was superior to MLR (70%. 73%, and 70%, respectively).
   Interpretation ANN can accurately predict the outcome for patients presenting with acute lower-gastrointestinal haemorrhage and may be generally useful for the risk stratification of these patients.
C1 Case Western Reserve Univ, Univ Hosp Cleveland, Dept Med, Div Gastroenterol, Cleveland, OH 44106 USA.
   Henry Ford Hosp, Div Gastroenterol, Detroit, MI 48202 USA.
C3 Case Western Reserve University; Case Western Reserve University
   Hospital; University Hospitals of Cleveland; Henry Ford Health System;
   Henry Ford Hospital
RP Wong, RCK (通讯作者)，Univ Hosp Cleveland, Div Gastroenterol Wearn 247, 11100 Euclid Ave, Cleveland, OH 44106 USA.
EM rxw16@po.cwru.edu
CR BAXT WG, 1992, ANN EMERG MED, V21, P1439, DOI 10.1016/S0196-0644(05)80056-3
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   BAXT WG, 1991, ANN INTERN MED, V115, P843, DOI 10.7326/0003-4819-115-11-843
   BLAKELEY DD, 1995, ANN INTERN MED, V122, P360, DOI 10.7326/0003-4819-122-5-199503010-00007
   Blatchford O, 2000, LANCET, V356, P1318, DOI 10.1016/S0140-6736(00)02816-6
   Bottaci L, 1997, LANCET, V350, P469, DOI 10.1016/S0140-6736(96)11196-X
   CROSS SS, 1995, LANCET, V346, P1075, DOI 10.1016/S0140-6736(95)91746-2
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Hay JA, 1997, JAMA-J AM MED ASSOC, V278, P2151, DOI 10.1001/jama.278.24.2151
   Haykin SS, 1999, NEURAL NETWORKS COMP
   Heden B, 1997, CIRCULATION, V96, P1798, DOI 10.1161/01.CIR.96.6.1798
   Jensen DM, 2000, NEW ENGL J MED, V342, P78, DOI 10.1056/NEJM200001133420202
   JOHNSTON ME, 1994, ANN INTERN MED, V120, P135, DOI 10.7326/0003-4819-120-2-199401150-00007
   Klenzak JS, 1996, GASTROINTEST ENDOSC, V43, P247
   Kollef MH, 1997, CRIT CARE MED, V25, P1125, DOI 10.1097/00003246-199707000-00011
   Lapuerta P, 1997, HEPATOLOGY, V25, P302
   Morris AH, 2000, ANN INTERN MED, V132, P373, DOI 10.7326/0003-4819-132-5-200003070-00007
   Rockall TA, 1996, GUT, V38, P316, DOI 10.1136/gut.38.3.316
   SCHROCK TR, 1989, SURG CLIN N AM, V69, P1309
   Selaru FM, 2002, GASTROENTEROLOGY, V122, P606, DOI 10.1053/gast.2002.31904
   Sinha M, 2001, J TRAUMA, V50, P308, DOI 10.1097/00005373-200102000-00018
   TOURASSI GD, 1993, RADIOLOGY, V189, P555, DOI 10.1148/radiology.189.2.8210389
   Vreeburg EM, 1999, GUT, V44, P331, DOI 10.1136/gut.44.3.331
   Zuckerman GR, 1999, GASTROINTEST ENDOSC, V49, P228, DOI 10.1016/S0016-5107(99)70491-8
   Zuckerman GR, 1998, GASTROINTEST ENDOSC, V48, P606, DOI 10.1016/S0016-5107(98)70043-4
NR 25
TC 137
Z9 141
U1 0
U2 5
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0140-6736
EI 1474-547X
J9 LANCET
JI Lancet
PD OCT 18
PY 2003
VL 362
IS 9392
BP 1261
EP 1266
DI 10.1016/S0140-6736(03)14568-0
PG 6
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC General & Internal Medicine
GA 734CD
UT WOS:000186036900008
PM 14575969
DA 2023-04-20
ER

PT J
AU Karkanis, SA
   Iakovidis, DK
   Maroulis, DE
   Karras, DA
   Tzivras, M
AF Karkanis, SA
   Iakovidis, DK
   Maroulis, DE
   Karras, DA
   Tzivras, M
TI Computer-aided tumor detection in endoscopic video using color wavelet
   features
SO IEEE TRANSACTIONS ON INFORMATION TECHNOLOGY IN BIOMEDICINE
LA English
DT Article
DE color texture; computer aided colonoscopy; image analysis; medical
   imaging; polyp detection; wavelet features
ID CT COLONOGRAPHY; FLEXIBLE SIGMOIDOSCOPY; FEATURE-EXTRACTION; TEXTURE
   ANALYSIS; CLASSIFICATION; SEGMENTATION; POLYPS; DIAGNOSIS; COLONOSCOPY;
   LESIONS
AB We present an approach to the detection of tumors in colonoscopic video. It is based on a new color feature extraction scheme to represent the different regions in the frame sequence. This scheme is built on the wavelet decomposition. The features named as color wavelet covariance (CWC) are based on the covariances of second-order textural measures and an optimum subset of them is proposed after the application of a selection algorithm. The proposed approach is supported by a linear discriminant analysis (LDA) procedure for the characterization of the image regions along the video frames. The whole methodology has been applied on real data sets of color colonoscopic videos. The performance in the detection of abnormal colonic regions corresponding to adenomatous polyps has been estimated high, reaching 97% specificity and 90% sensitivity.
C1 Univ Athens, Dept Informat & Telecommun, Realtime Syst & Image Anal Grp, GR-15784 Athens, Greece.
   Hellen Aerosp Ind, Schematari, Greece.
   Univ Athens, Sch Med, Dept Pathophysiol, Gastroenterol Sect, GR-11527 Athens, Greece.
C3 National & Kapodistrian University of Athens; Athens Medical School;
   National & Kapodistrian University of Athens
RP Karkanis, SA (通讯作者)，Technol Educ Inst Lamia, Dept Informat & Comp Technol, Lamia 35100, Greece.
EM sk@teilam.gr; rtsimage@di.uoa.gr; rtsimage@di.uoa.gr;
   dkarras@haicorp.com; dkarras@haicorp.com
RI Karkanis, Stavros/AAZ-1155-2021; Karras, Dimitrios Alexios/AAD-7229-2019
OI Karras, Dimitrios Alexios/0000-0002-2759-8482; Maroulis,
   Dimitris/0000-0002-2721-9219; Iakovidis, Dimitris/0000-0002-5027-5323
CR Abyoto K. W., 1998, J TOKYO U INFORM SCI, V2, P49
   [Anonymous], 1997, P INT C MACHINE LEAR
   ARCHIMANDRITIS A, 1993, J CLIN GASTROENTEROL, V17, P87, DOI 10.1097/00004836-199307000-00023
   Armitage P., 1987, STAT METHODS MED RES
   CAELLI T, 1993, PATTERN RECOGN, V26, P461, DOI 10.1016/0031-3203(93)90102-3
   CHAMBERLIN DG, 1980, COLOR ITS MANAGEMENT
   Chen C.H., 1998, HDB PATTERN RECOGNIT, P207
   Chiu CC, 2000, COMPUT METH PROG BIO, V61, P77, DOI 10.1016/S0169-2607(99)00031-0
   Drimbarean A, 2001, PATTERN RECOGN LETT, V22, P1161, DOI 10.1016/S0167-8655(01)00058-7
   Dubuisson-Jolly MP, 2000, IMAGE VISION COMPUT, V18, P823, DOI 10.1016/S0262-8856(99)00050-5
   DUCHNOWSKI P, 1995, INT CONF ACOUST SPEE, P109, DOI 10.1109/ICASSP.1995.479285
   Enderwick CY, 1997, P ANN INT IEEE EMBS, V19, P810, DOI 10.1109/IEMBS.1997.757772
   Eom KB, 1999, IMAGE VISION COMPUT, V17, P233, DOI 10.1016/S0262-8856(98)00105-X
   Esgiar A N, 1998, IEEE Trans Inf Technol Biomed, V2, P197, DOI 10.1109/4233.735785
   Esgiar AN, 1998, ANAL QUANT CYTOL, V20, P297
   FEARON ER, 1990, CELL, V61, P759, DOI 10.1016/0092-8674(90)90186-I
   Fischer S, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P323, DOI 10.1109/ICIP.1996.559498
   Fortin C., 1991, P IEEE 17 ANN NE BIO
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HOUSTON AG, 1991, BIOMEDICAL IMAGE PRO
   ITZKOWITZ SH, 1998, SLEISINGER FORDTRANS, V2
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   Johnson CD, 2000, RADIOLOGY, V216, P331, DOI 10.1148/radiology.216.2.r00au47331
   JULESZ B, 1986, BIOL CYBERN, V54, P245, DOI 10.1007/BF00318420
   Karkanis S, 2000, MINIM INVASIV THER, V9, P225, DOI 10.1080/13645700009169652
   Karkanis SA, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P833, DOI 10.1109/ICIP.2001.958623
   Karkanis SA, 2001, IEEE IMAGE PROC, P281, DOI 10.1109/ICIP.2001.959008
   KEITH J, 1996, VIDEO DEMYSTIFIED
   Kendall M., 1970, RANK CORRELATION MET
   Kenney J. F., 1962, MATH STAT 1, V1, P252
   Kim SH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P76, DOI 10.1109/AFGR.1998.670928
   Kondepudy R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P577, DOI 10.1109/CVPR.1993.341072
   Kudo S, 2000, WORLD J SURG, V24, P1081, DOI 10.1007/s002680010154
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   LACHMANN F, 1992, P SOC PHOTO-OPT INS, V1652, P72, DOI 10.1117/12.59413
   Li CH, 2000, IEEE T MED IMAGING, V19, P1150, DOI 10.1109/42.896791
   Liapis S, 1998, P EUR SIGN PROC C, P1341
   LOONEY GC, 1997, PATTERN RECOGN, P316
   Mac M, 2002, PHOTOCH PHOTOBIO SCI, V1, P24, DOI 10.1039/b106798b
   MACARI M, 2002, VIRT COL
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Mirmehdi M, 2000, IEEE T PATTERN ANAL, V22, P142, DOI 10.1109/34.825753
   Mojsilovic A, 1999, P SOC PHOTO-OPT INS, V3644, P441, DOI 10.1117/12.348464
   Nagata S, 2000, INT J ONCOL, V16, P927
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   PAIK DS, 1999, RAD SOC N AM 85 SCI
   Palm C, 2000, PROCEEDINGS OF THE FIFTH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1 AND 2, pA45
   Parker SL, 1997, CA-CANCER J CLIN, V47, P5, DOI 10.3322/canjclin.47.1.5
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Paschos G, 1998, PATTERN RECOGN LETT, V19, P643, DOI 10.1016/S0167-8655(98)00038-5
   Paschos G, 2000, PATTERN RECOGN LETT, V21, P837, DOI 10.1016/S0167-8655(00)00043-X
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   REX DK, 1990, GASTROENTEROLOGY, V98, P855, DOI 10.1016/0016-5085(90)90007-N
   Saar B, 2000, INVEST RADIOL, V35, P521, DOI 10.1097/00004424-200009000-00001
   SCHARCANSKI J, 1994, PATTERN RECOGN LETT, V15, P191, DOI 10.1016/0167-8655(94)90048-5
   SCHUMEYER RP, P SPIE VIS COMM IM P, V3309, P189
   SEMLER G, 1987, EUR ARCH PSY CLIN N, V236, P214, DOI 10.1007/BF00383851
   SMITH AR, 1997, THESIS COLUMBIA U NY
   Sujana H, 1996, ULTRASOUND MED BIOL, V22, P1177, DOI 10.1016/S0301-5629(96)00144-5
   Sun QB, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P130, DOI 10.1109/AFGR.1998.670937
   Swets J A, 2000, Psychol Sci Public Interest, V1, P1, DOI 10.1111/1529-1006.001
   THOMPSON E, 1992, BEHAV BRAIN SCI, V15, P1, DOI 10.1017/S0140525X00067248
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Van de Wouwer G, 1999, PATTERN RECOGN, V32, P443, DOI 10.1016/S0031-3203(98)00035-1
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   VANDENBROUCKE N, 2000, P IEEE ICIP VANC CAN, V2, P800
   VOLGELSTEIN B, 1998, NEW ENGL J MED, V319, P525
   West D, 2000, ARTIF INTELL MED, V20, P183, DOI 10.1016/S0933-3657(00)00063-4
   WILLIAMS AR, 1982, GUT, V23, P835, DOI 10.1136/gut.23.10.835
   Wyszecki Gunter, 1982, COLOR SCI CONCEPTS M, V2nd
   Yang J., 1995, CMUCS95210
   Yoshida H, 2000, RADIOLOGY, V217, P582
   ZEKI S, 1983, NEUROSCIENCE, V9, P741, DOI 10.1016/0306-4522(83)90265-8
   2000, CANC FACTS FIGURES
NR 79
TC 314
Z9 327
U1 0
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1089-7771
EI 1558-0032
J9 IEEE T INF TECHNOL B
JI IEEE T. Inf. Technol. Biomed.
PD SEP
PY 2003
VL 7
IS 3
BP 141
EP 152
DI 10.1109/TITB.2003.813794
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA 721VA
UT WOS:000185338100001
PM 14518727
DA 2023-04-20
ER

PT J
AU Ilgner, JFR
   Palm, C
   Schutz, AG
   Spitzer, K
   Westhofen, M
   Lehmann, TM
AF Ilgner, JFR
   Palm, C
   Schutz, AG
   Spitzer, K
   Westhofen, M
   Lehmann, TM
TI Colour texture analysis for quantitative laryngoscopy
SO ACTA OTO-LARYNGOLOGICA
LA English
DT Article
DE diagnostic laryngoscopy; electronic imaging; endoscopy; neoplastic
   larynx disease
ID VOCAL FOLD VIBRATION; HIGH-SPEED; LARYNGEAL-CANCER; ENDOSCOPY
AB Objective-Whilst considerable progress has been made in enhancing the quality of indirect laryngoscopy and image processing, the evaluation of clinical findings is still based on the clinician's judgement. The aim of this paper was to examine the feasibility of an objective computer-based method for evaluating laryngeal disease.
   Material and Methods-Digitally recorded images obtained by 90degrees- and 70degrees-angled indirect rod laryngoscopy using standardized white balance values were made of 16 patients and 19 healthy subjects. The digital images were evaluated manually by the clinician based on a standardized questionnaire, and suspect lesions were marked and classified on the image. Following colour separation, normal vocal cord areas as well as suspect lesions were analyzed automatically using co-occurrence matrices, which compare colour differences between neighbouring pixels over a predefined distance.
   Results-Whilst colour histograms did not provide sufficient information for distinguishing between healthy and diseased tissues, consideration of the blue content of neighbouring pixels enabled a correct classification in 81.4% of cases. If all colour channels (red, green and blue) were regarded simultaneously, the best classification correctness obtained was 77.1%.
   Conclusions-Although only a very basic classification differentiating between healthy and diseased tissue was attempted, the results showed progress compared to grey-scale histograms, which have been evaluated before. The results document a first step towards an objective, machine-based classification of laryngeal images, which could provide the basis for further development of an expert system for use in indirect laryngoscopy.
C1 Univ Hosp Aachen, Dept Otorhinolaryngol Plast Head & Neck Surg, DE-52057 Aachen, Germany.
   Aachen Univ Technol RWTH, Inst Med Informat, Aachen, Germany.
C3 RWTH Aachen University; RWTH Aachen University Hospital; RWTH Aachen
   University
RP Ilgner, JFR (通讯作者)，Univ Hosp Aachen, Dept Otorhinolaryngol Plast Head & Neck Surg, Pauwelsstr 30, DE-52057 Aachen, Germany.
RI Westhofen, Martin/ABB-2550-2020; Ilgner, Justus/AEX-5098-2022; Palm,
   Christoph/F-4943-2014
OI Ilgner, Justus/0000-0003-0062-2830; Palm, Christoph/0000-0001-9468-2871
CR Arens C, 1999, LARYNGO RHINO OTOL, V78, P685
   BRADLEY AP, 1995, P INF PROC MED IM 14, P375
   FUKUNAGA K, 1973, INTRO STAT PATTERN R
   Gallivan RP, 1999, LARYNGOSCOPE, V109, P1570, DOI 10.1097/00005537-199910000-00005
   GOTLIEB CC, 1990, COMPUT VISION GRAPH, V51, P70, DOI 10.1016/S0734-189X(05)80063-5
   Granqvist S, 2001, J ACOUST SOC AM, V110, P3193, DOI 10.1121/1.1397321
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HASSAN H, 1998, ADV QUANTITATIVE LAR, P135
   HESS MM, 1993, ANN OTO RHINOL LARYN, V102, P502, DOI 10.1177/000348949310200703
   Hess MM, 2000, J VOICE, V14, P255, DOI 10.1016/S0892-1997(00)80034-X
   Maurer D, 1996, ANN OTO RHINOL LARYN, V105, P975, DOI 10.1177/000348949610501208
   Miyaji M, 1998, Nihon Jibiinkoka Gakkai Kaiho, V101, P1099
   PALM C, 2000, ADV QUANTITATIVE LAR, P49
   PELIKAN E, 1995, THESIS AACHEN U TECH
   Pigott RW, 2002, BRIT J PLAST SURG, V55, P32, DOI 10.1054/bjps.2001.3732
   Svec JG, 1996, J VOICE, V10, P201, DOI 10.1016/S0892-1997(96)80047-6
   Svec JG, 2000, J ACOUST SOC AM, V108, P1397, DOI 10.1121/1.1289205
   Tigges M, 1999, COMPUT MED IMAG GRAP, V23, P323, DOI 10.1016/S0895-6111(99)00030-0
   Triglia JM, 2002, ANN OTO RHINOL LARYN, V111, P36, DOI 10.1177/000348940211100106
   Zargi M, 1997, EUR ARCH OTO-RHINO-L, V254, pS113, DOI 10.1007/BF02439739
   ZARGI M, 1997, ACTA OTOLARYNGOL S S, V527, P125
   ZRUNEK M, 1991, EUR ARCH OTO-RHINO-L, V248, P445, DOI 10.1007/BF00627631
NR 22
TC 28
Z9 28
U1 0
U2 6
PU TAYLOR & FRANCIS AS
PI OSLO
PA CORT ADELERSGT 17, PO BOX 2562, SOLLI, 0202 OSLO, NORWAY
SN 0001-6489
J9 ACTA OTO-LARYNGOL
JI Acta Oto-Laryngol.
PD AUG
PY 2003
VL 123
IS 6
BP 730
EP 734
DI 10.1080/00016480310000412
PG 5
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology
GA 706ME
UT WOS:000184456800011
PM 12953773
DA 2023-04-20
ER

PT J
AU Maroulis, DE
   Iakovidis, DK
   Karkanis, SA
   Karras, DA
AF Maroulis, DE
   Iakovidis, DK
   Karkanis, SA
   Karras, DA
TI CoLD: a versatile detection system for colorectal lesions in endoscopy
   video-frames
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE medical imaging; computer aided diagnosis; endoscopy; texture; neural
   networks; colorectal lesions
ID NEURAL-NETWORK; UNIVERSAL APPROXIMATION; TEXTURE CLASSIFICATION;
   SEGMENTATION; DIAGNOSIS; MICROCALCIFICATIONS; COLONOSCOPY; FEATURES
AB In this paper, we present CoLD (colorectal lesions detector) an innovative detection system to support colorectal cancer diagnosis and detection of pre-cancerous polyps, by processing endoscopy images or video frame sequences acquired during colonoscopy. It utilizes second-order statistical features that are calculated on the wavelet transformation of each image to discriminate amongst regions of normal or abnormal tissue. An artificial neural network performs the classification of the features. CoLD integrates the feature extraction and classification algorithms under a graphical user interface, which allows both novice and expert users to utilize effectively all system's functions. It has been developed in close cooperation with gastroenterology specialists and has been tested on various colonoscopy videos. The detection accuracy of the proposed system has been estimated to be more than 95%,,. As it has been resulted, it can be used as a supplementary diagnostic tool for colorectal lesions. (C) 2002 Elsevier Science Ireland Ltd. All rights reserved.
C1 Univ Athens, Dept Informat & Telecommun, RTS Image Grp, Athens 15784, Greece.
   Hellen Aerosp Ind, Schematari, Greece.
C3 National & Kapodistrian University of Athens
RP Maroulis, DE (通讯作者)，Univ Athens, Dept Informat & Telecommun, RTS Image Grp, Athens 15784, Greece.
EM rtsimage@di.uoa.gr; dakarras@hol.gr
RI Karkanis, Stavros/AAZ-1155-2021; Karras, Dimitrios Alexios/AAD-7229-2019
OI Karras, Dimitrios Alexios/0000-0002-2759-8482; Iakovidis,
   Dimitris/0000-0002-5027-5323; Maroulis, Dimitris/0000-0002-2721-9219
CR Abramovich F, 2000, J ROY STAT SOC D-STA, V49, P1, DOI 10.1111/1467-9884.00216
   [Anonymous], 1992, 10 LECT WAVELETS
   BARRON AR, 1993, IEEE T INFORM THEORY, V39, P930, DOI 10.1109/18.256500
   Berrais A, 1997, ADV ENG SOFTW, V28, P31, DOI 10.1016/S0965-9978(96)00030-0
   Bodnarova A, 2000, PATTERN ANAL APPL, V3, P254, DOI 10.1007/s100440070010
   Chiu CC, 2000, COMPUT METH PROG BIO, V61, P77, DOI 10.1016/S0169-2607(99)00031-0
   Cohen A., 1995, WAVELETS MULTISCALE
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hauta-Kasari M, 1999, PATTERN ANAL APPL, V2, P275, DOI 10.1007/s100440050036
   Haykin S., 1996, NEURAL NETWORKS COMP
   HORNIK K, 1990, NEURAL NETWORKS, V3, P551, DOI 10.1016/0893-6080(90)90005-6
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   *INT CORP, 1999, INT REC PRIM LIB REF
   Jiang YL, 1996, RADIOLOGY, V198, P671, DOI 10.1148/radiology.198.3.8628853
   JULESZ B, 1986, BIOL CYBERN, V54, P245, DOI 10.1007/BF00318420
   Karkanis S, 2000, MINIM INVASIV THER, V9, P225, DOI 10.1080/13645700009169652
   Karkanis S, 1999, P WORKSH MACH LEARN, P59
   Karkanis SA, 2000, EUROMICRO CONF PROC, pA423
   KARKANIS SA, 2001, IN PRESS IEEE INT C
   Karras DA, 1998, KYBERNETES, V27, P224, DOI 10.1108/03684929810209405
   Kassim AA, 2000, MACH VISION APPL, V11, P257, DOI 10.1007/s001380050109
   Kudo S, 2000, WORLD J SURG, V24, P1081, DOI 10.1007/s002680010154
   Latif-Amet A, 2000, IMAGE VISION COMPUT, V18, P543, DOI 10.1016/S0262-8856(99)00062-1
   Lim CP, 1997, ARTIF INTELL MED, V11, P215, DOI 10.1016/S0933-3657(97)00035-3
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MANGO LJ, 1994, CANCER LETT, V77, P155, DOI 10.1016/0304-3835(94)90098-1
   Meyer Y., 1993, WAVELETS ALGORITHMS
   MILLER AS, 1992, MED BIOL ENG COMPUT, V30, P449, DOI 10.1007/BF02457822
   Myers B., 2000, ACM Transactions on Computer-Human Interaction, V7, P3, DOI 10.1145/344949.344959
   Nagata S, 2000, INT J ONCOL, V16, P927
   RAO AR, 1993, CVGIP-GRAPH MODEL IM, V55, P218, DOI 10.1006/cgip.1993.1016
   REX DK, 1990, GASTROENTEROLOGY, V98, P855, DOI 10.1016/0016-5085(90)90007-N
   Shneiderman B, 2010, DESIGNING USER INTER
   Sziranyi T, 1998, COMPUT VIS IMAGE UND, V71, P255, DOI 10.1006/cviu.1997.0646
   TOURASSI GD, 1993, RADIOLOGY, V189, P555, DOI 10.1148/radiology.189.2.8210389
   Tsujii O, 1999, PATTERN RECOGN, V32, P891, DOI 10.1016/S0031-3203(98)00099-5
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Vanrell M, 1997, MACH VISION APPL, V9, P262, DOI 10.1007/s001380050047
   Vince DG, 2000, COMPUT MED IMAG GRAP, V24, P221, DOI 10.1016/S0895-6111(00)00011-2
NR 40
TC 86
Z9 88
U1 0
U2 5
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD FEB
PY 2003
VL 70
IS 2
BP 151
EP 166
AR PII S0169-2607(02)00007-X
DI 10.1016/S0169-2607(02)00007-X
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 638ZT
UT WOS:000180603700006
PM 12507791
DA 2023-04-20
ER

PT J
AU Tjoa, MP
   Krishnan, SM
AF Tjoa, Marta P.
   Krishnan, Shankar M.
TI Feature extraction for the analysis of colon status from the endoscopic
   images
SO BIOMEDICAL ENGINEERING ONLINE
LA English
DT Article
AB Background: Extracting features from the colonoscopic images is essential for getting the features, which characterizes the properties of the colon. The features are employed in the computer-assisted diagnosis of colonoscopic images to assist the physician in detecting the colon status.
   Methods: Endoscopic images contain rich texture and color information. Novel schemes are developed to extract new texture features from the texture spectra in the chromatic and achromatic domains, and color features for a selected region of interest from each color component histogram of the colonoscopic images. These features are reduced in size using Principal Component Analysis (PCA) and are evaluated using Backpropagation Neural Network (BPNN).
   Results : Features extracted from endoscopic images were tested to classify the colon status as either normal or abnormal. The classification results obtained show the features' capability for classifying the colon's status. The average classification accuracy, which is using hybrid of the texture and color features with PCA (tau = 1%), is 97.72%. It is higher than the average classification accuracy using only texture (96.96%, tau = 1%) or color (90.52%, tau = 1%) features.
   Conclusion: In conclusion, novel methods for extracting new texture- and color-based features from the colonoscopic images to classify the colon status have been proposed. A new approach using PCA in conjunction with BPNN for evaluating the features has also been proposed. The preliminary test results support the feasibility of the proposed method.
C1 [Tjoa, Marta P.; Krishnan, Shankar M.] Nanyang Techol Univ, BioMed Engn Res Ctr, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University
RP Tjoa, MP (通讯作者)，Nanyang Techol Univ, BioMed Engn Res Ctr, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM ph093147@ntu.edu.sg; esmkrish@ntu.edu.sg
FU Nanyang Technological University in Singapore
FX The authors wish to extend their sincere appreciation to Nanyang
   Technological University in Singapore for their research grant.
CR Esgiar A N, 1998, IEEE Trans Inf Technol Biomed, V2, P197, DOI 10.1109/4233.735785
   Esgiar AN, 2002, IEEE T INF TECHNOL B, V6, P54, DOI 10.1109/4233.992163
   GOTLIEB CC, 1990, COMPUT VISION GRAPH, V51, P70, DOI 10.1016/S0734-189X(05)80063-5
   HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697
   HE DC, 1991, PATTERN RECOGN, V24, P391, DOI 10.1016/0031-3203(91)90052-7
   Karkanis SA, 2000, P 26 EUR C WORKSH ME
   Kato H, 1993, ELECT VIDEOENDOSCOPY
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P1678, DOI 10.1109/IEMBS.1998.747232
   Krishnan SM, 1999, P 1 JOINT BMES EMBS
   Krishnan SM, 1997, P 19 INT C IEEE EMBS
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623
   SHANG CG, 1994, PATTERN RECOGN, V27, P675, DOI 10.1016/0031-3203(94)90046-9
   Todman AG, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P1379, DOI 10.1109/CCECE.2001.933655
NR 15
TC 54
Z9 62
U1 0
U2 2
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
EI 1475-925X
J9 BIOMED ENG ONLINE
JI Biomed. Eng. Online
PY 2003
VL 2
AR 9
DI 10.1186/1475-925X-2-9
PG 17
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA VI5XS
UT WOS:000497962600009
PM 12713670
OA Green Published, gold
DA 2023-04-20
ER

EF