FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Gimeno-Garcia, AZ
   Hernandez-Perez, A
   Nicolas-Perez, D
   Hernandez-Guerra, M
AF Gimeno-Garcia, Antonio Z.
   Hernandez-Perez, Anjara
   Nicolas-Perez, David
   Hernandez-Guerra, Manuel
TI Artificial Intelligence Applied to Colonoscopy: Is It Time to Take a
   Step Forward?
SO CANCERS
LA English
DT Review
DE colonoscopy; artificial intelligence; CADe; CADx
ID COMPUTER-AIDED DIAGNOSIS; IMPROVING ADENOMA DETECTION; SMALL COLORECTAL
   POLYPS; ENDOSCOPIC DIAGNOSIS; GASTROINTESTINAL ENDOSCOPY; SYSTEM;
   CLASSIFICATION; NEOPLASIA; LESIONS; HISTOLOGY
AB Simple Summary In recent years, there has been an exponential rise in artificial intelligence-based technology. Artificial intelligence has been applied to several medical disciplines, such as gastroenterology. In the field of endoscopy, a wide variety of applications for artificial intelligence algorithms have been developed or are in a process of improvement. Computer-aided polyp detection and characterization are two of the most studied applications. In addition, there are several reports of other potential applications, such as the assessment of bowel preparation quality, while another future prospect is the prediction of cancer invasion depth. However, certain concerns remain, such as the universal use of this technology in clinical practice, impact on the incidence of interval colorectal cancer, cost-effectiveness, workload and patient burden. Growing evidence indicates that artificial intelligence (AI) applied to medicine is here to stay. In gastroenterology, AI computer vision applications have been stated as a research priority. The two main AI system categories are computer-aided polyp detection (CADe) and computer-assisted diagnosis (CADx). However, other fields of expansion are those related to colonoscopy quality, such as methods to objectively assess colon cleansing during the colonoscopy, as well as devices to automatically predict and improve bowel cleansing before the examination, predict deep submucosal invasion, obtain a reliable measurement of colorectal polyps and accurately locate colorectal lesions in the colon. Although growing evidence indicates that AI systems could improve some of these quality metrics, there are concerns regarding cost-effectiveness, and large and multicentric randomized studies with strong outcomes, such as post-colonoscopy colorectal cancer incidence and mortality, are lacking. The integration of all these tasks into one quality-improvement device could facilitate the incorporation of AI systems in clinical practice. In this manuscript, the current status of the role of AI in colonoscopy is reviewed, as well as its current applications, drawbacks and areas for improvement.
C1 [Gimeno-Garcia, Antonio Z.; Hernandez-Perez, Anjara; Nicolas-Perez, David; Hernandez-Guerra, Manuel] Hosp Univ Canarias, Gastroenterol Dept, San Cristobal De La Lagun 38200, Tenerife, Spain.
   [Gimeno-Garcia, Antonio Z.; Hernandez-Perez, Anjara; Nicolas-Perez, David; Hernandez-Guerra, Manuel] Univ La Laguna, Inst Univ Tecnol Biomed ITB, San Cristobal De La Lagun 38200, Tenerife, Spain.
   [Gimeno-Garcia, Antonio Z.; Hernandez-Perez, Anjara; Nicolas-Perez, David; Hernandez-Guerra, Manuel] Univ La Laguna, Internal Med Dept, Ctr Invest Biomed Canarias CIBICAN, San Cristobal De La Lagun 38200, Tenerife, Spain.
C3 Universidad de la Laguna; Universidad de la Laguna; Universidad de la
   Laguna
RP Gimeno-Garcia, AZ (通讯作者)，Hosp Univ Canarias, Gastroenterol Dept, San Cristobal De La Lagun 38200, Tenerife, Spain.; Gimeno-Garcia, AZ (通讯作者)，Univ La Laguna, Inst Univ Tecnol Biomed ITB, San Cristobal De La Lagun 38200, Tenerife, Spain.; Gimeno-Garcia, AZ (通讯作者)，Univ La Laguna, Internal Med Dept, Ctr Invest Biomed Canarias CIBICAN, San Cristobal De La Lagun 38200, Tenerife, Spain.
EM agimenog@ull.edu.es
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Ahmad A, 2022, ENDOSCOPY, DOI 10.1055/a-1966-0661
   Ahmad OF, 2019, FRONTLINE GASTROENTE, V10, P198, DOI 10.1136/flgastro-2018-101047
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Anderson R, 2020, GASTROENTEROLOGY, V158, P1287, DOI 10.1053/j.gastro.2019.12.031
   Aniwan S, 2023, GASTROINTEST ENDOSC, V97, P507, DOI 10.1016/j.gie.2022.09.023
   Areia M, 2022, LANCET DIGIT HEALTH, V4, pE436, DOI 10.1016/S2589-7500(22)00042-5
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Atkin W, 2017, LANCET, V389, P1299, DOI 10.1016/S0140-6736(17)30396-3
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Berzin TM, 2020, GASTROINTEST ENDOSC, V92, P951, DOI 10.1016/j.gie.2020.06.035
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Ciuti G, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061648
   Beaton D, 2022, ENDOSCOPY, V54, P270, DOI 10.1055/a-1409-5531
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deliwala SS, 2021, INT J COLORECTAL DIS, V36, P2291, DOI 10.1007/s00384-021-03929-3
   Gao QY, 2015, AM J GASTROENTEROL, V110, P501, DOI 10.1038/ajg.2015.49
   Gimeno-Garcia AZ, 2023, GASTROINTEST ENDOSC, V97, P528, DOI 10.1016/j.gie.2022.09.029
   Gopalswamy N, 1997, GASTROINTEST ENDOSC, V46, P497, DOI 10.1016/S0016-5107(97)70003-8
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Gubbiotti A, 2022, EXPERT REV GASTROENT, V16, P819, DOI 10.1080/17474124.2022.2128761
   Gurudu SR, 2011, AM J GASTROENTEROL, V106, P1466, DOI 10.1038/ajg.2011.125
   Hassan C, 2022, CLIN GASTROENTEROL H, V20, P2505, DOI 10.1016/j.cgh.2022.04.045
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hossain Ejaz, 2023, DEN Open, V3, pe178, DOI 10.1002/deo2.178
   Houwen BBSL, 2023, SCAND J GASTROENTERO, V58, P649, DOI 10.1080/00365521.2022.2151320
   Hsieh YH, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11061113
   Huang D, 2022, INT J COLORECTAL DIS, V37, P495, DOI 10.1007/s00384-021-04062-x
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Joseph J, 2021, WORLD J GASTROENTERO, V27, P4802, DOI 10.3748/wjg.v27.i29.4802
   Kader R, 2023, DIGEST ENDOSC, V35, P645, DOI 10.1111/den.14500
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kang JHE, 2021, ALIMENT PHARM THER, V54, P1232, DOI 10.1111/apt.16622
   Kobayashi S, 2019, UNITED EUR GASTROENT, V7, P914, DOI 10.1177/2050640619845987
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Koyama Y, 2022, SURG ENDOSC, V36, P5032, DOI 10.1007/s00464-021-08863-7
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kwak MS, 2022, DIGEST ENDOSC, V34, P1188, DOI 10.1111/den.14318
   Lam Angela Y, 2022, Gastrointest Endosc Clin N Am, V32, P329, DOI 10.1016/j.giec.2021.12.010
   Lee JY, 2022, GASTROINTEST ENDOSC, V95, P512, DOI 10.1016/j.gie.2021.11.041
   Leung FW, 2011, ENDOSCOPY, V43, P816, DOI 10.1055/s-0030-1256407
   Li JL, 2021, EUR J GASTROEN HEPAT, V33, P1041, DOI 10.1097/MEG.0000000000001906
   Liu W, 2022, ENDOSCOPY, V54, P972, DOI 10.1055/a-1799-8297
   Lu YB, 2022, AM J GASTROENTEROL, V117, P1437, DOI 10.14309/ajg.0000000000001900
   Lu ZH, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2022.53840
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Marcondes FO, 2018, DIGEST DIS SCI, V63, P856, DOI 10.1007/s10620-018-4947-1
   Messmann H, 2022, ENDOSCOPY, DOI 10.1055/a-1950-5694
   Minami S, 2022, CANCERS, V14, DOI 10.3390/cancers14215361
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mohan BP, 2020, ECLINICALMEDICINE, V29-30, DOI 10.1016/j.eclinm.2020.100622
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Naik N, 2022, FRONT SURG, V9, DOI 10.3389/fsurg.2022.862322
   Nazarian S, 2021, J MED INTERNET RES, V23, DOI 10.2196/27370
   Neri E, 2020, RADIOL MED, V125, P517, DOI 10.1007/s11547-020-01135-9
   O'Connor SA, 2016, ENDOSC INT OPEN, V4, pE642, DOI 10.1055/s-0042-105864
   Orlovic M, 2023, GASTROINTEST ENDOSC, V98, P73, DOI 10.1016/j.gie.2023.01.054
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Pannala Rahul, 2020, VideoGIE, V5, P598, DOI 10.1016/j.vgie.2020.08.013
   Parsa N, 2021, THER ADV GASTROINTES, V14, DOI 10.1177/26317745211014698
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Robertson DJ, 2017, GASTROENTEROLOGY, V152, P1217, DOI 10.1053/j.gastro.2016.08.053
   Rondonotti E, 2023, ENDOSCOPY, V55, P14, DOI 10.1055/a-1852-0330
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Shah S, 2023, J GASTROEN HEPATOL, V38, P162, DOI 10.1111/jgh.16059
   Shaukat A, 2015, GASTROENTEROLOGY, V149, P952, DOI 10.1053/j.gastro.2015.06.044
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Spadaccini M, 2022, FUTURE ONCOL, V18, P1405, DOI 10.2217/fon-2021-1135
   Spadaccini M, 2021, LANCET GASTROENTEROL, V6, P793, DOI 10.1016/S2468-1253(21)00215-6
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tavanapong W, 2022, IEEE J BIOMED HEALTH, V26, P3950, DOI 10.1109/JBHI.2022.3160098
   Thayalasekaran S, 2020, GASTROINTEST ENDOSC, V92, P840, DOI 10.1016/j.gie.2020.06.046
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Tokunaga M, 2021, GASTROINTEST ENDOSC, V93, P647, DOI 10.1016/j.gie.2020.07.053
   Troya J, 2022, ENDOSCOPY, V54, P1009, DOI 10.1055/a-1770-7353
   van der Zander QEW, 2021, ENDOSCOPY, V53, P1219, DOI 10.1055/a-1343-1597
   Vleugels JLA, 2017, GASTROINTEST ENDOSC, V85, P1169, DOI 10.1016/j.gie.2016.12.014
   von Renteln D, 2023, GUT, V72, P417, DOI 10.1136/gutjnl-2022-328654
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   Yanai S, 2016, DIGEST ENDOSC, V28, P274, DOI 10.1111/den.12568
   Yao LW, 2023, DIGEST ENDOSC, V35, P625, DOI 10.1111/den.14493
   Yao LW, 2022, ENDOSCOPY, V54, P757, DOI 10.1055/a-1706-6174
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhang YC, 2021, J LAPAROENDOSC ADV S, V31, P1143, DOI 10.1089/lap.2020.0777
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
   Zhou J, 2020, GASTROINTEST ENDOSC, V91, P428, DOI 10.1016/j.gie.2019.11.026
NR 106
TC 0
Z9 0
U1 4
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-6694
J9 CANCERS
JI Cancers
PD APR
PY 2023
VL 15
IS 8
AR 2193
DI 10.3390/cancers15082193
PG 15
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA E7IR9
UT WOS:000977243200001
PM 37190122
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Noor, MN
   Nazir, M
   Khan, SA
   Song, OY
   Ashraf, I
AF Noor, Muhammad Nouman
   Nazir, Muhammad
   Khan, Sajid Ali
   Song, Oh-Young
   Ashraf, Imran
TI Efficient Gastrointestinal Disease Classification Using Pretrained Deep
   Convolutional Neural Network
SO ELECTRONICS
LA English
DT Article
DE gastrointestinal disease; deep learning; WCE images; contrast
   enhancement; stomach cancer
ID CANCER STATISTICS
AB Gastrointestinal (GI) tract diseases are on the rise in the world. These diseases can have fatal consequences if not diagnosed in the initial stages. WCE (wireless capsule endoscopy) is the advanced technology used to inspect gastrointestinal diseases such as ulcerative-colitis, polyps, esophagitis, and ulcers. WCE produces thousands of frames for a single patient's procedure for which manual examination is tiresome, time-consuming, and prone to error; therefore, an automated procedure is needed. WCE images suffer from low contrast which increases inter-class and intra-class similarity and reduces the anticipated performance. In this paper, an efficient GI tract disease classification technique is proposed which utilizes an optimized brightness-controlled contrast-enhancement method to improve the contrast of the WCE images. The proposed technique applies a genetic algorithm (GA) for adjusting the values of contrast and brightness within an image by modifying the fitness function, which improves the overall quality of WCE images. This quality improvement is reported using qualitative measures, such as peak signal to noise ratio (PSNR), mean square error (MSE), visual information fidelity (VIF), similarity index (SI), and information quality index (IQI). As a second step, data augmentation is performed on WCE images by applying multiple transformations, and then, transfer learning is used to fine-tune a modified pre-trained model on WCE images. Finally, for the classification of GI tract disease, the extracted features are passed through multiple machine-learning classifiers. To show the efficacy of the proposed technique in the improvement in classification performance, the results are reported for the original dataset as well as the contrast-enhanced dataset. The results show an overall improvement of 15.26% in accuracy, 13.3% in precision, 16.77% in recall rate, and 15.18% in F-measure. Finally, a comparison with the existing techniques shows that the proposed framework outperforms the state-of-the-art techniques.
C1 [Noor, Muhammad Nouman; Nazir, Muhammad] HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.
   [Khan, Sajid Ali] Fdn Univ Islamabad, Dept Software Engn, Islamabad 44000, Pakistan.
   [Song, Oh-Young] Sejong Univ, Dept Software, Seoul 05006, South Korea.
   [Ashraf, Imran] HITEC Univ, Dept Comp Engn, Taxila 47080, Pakistan.
C3 NITEC University; Quaid I Azam University; Sejong University; NITEC
   University
RP Song, OY (通讯作者)，Sejong Univ, Dept Software, Seoul 05006, South Korea.
EM muhammad.nazir@hitecuni.edu.pk; oysong@sejong.edu
RI Ashraf, Imran/T-3635-2019; Noor, Muhammad Nouman/HWQ-5109-2023
OI Ashraf, Imran/0000-0002-8271-6496; Song, Oh-Young/0000-0002-7142-5976
CR Ahmed Ali, 2022, Proceedings of International Conference on Data Science and Applications: ICDSA 2021. Lecture Notes in Networks and Systems (288), P631, DOI 10.1007/978-981-16-5120-5_48
   Alhajlah M, 2023, CMC-COMPUT MATER CON, V75, P2227, DOI 10.32604/cmc.2023.031890
   Amiri Z, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103219
   [Anonymous], CA CANCER J CLIN, DOI [10.3322/CAAC.21254, DOI 10.3322/caac.21254]
   Azhari H, 2018, AM J GASTROENTEROL, V113, pS682
   Bae K., 2019, ARXIV
   Bang CS, 2021, J MED INTERNET RES, V23, DOI 10.2196/33267
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Cicceri G, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-0211-8
   Escobar J., 2021, 2021 23 S IMAGE SIGN, P1, DOI 10.1109/STSIVA53688.2021.9591995
   Feng L, 2019, IEEE T IND INFORM, V15, P3016, DOI 10.1109/TII.2019.2902604
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Higuchi N, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0269728
   Ho Y, 2020, IEEE ACCESS, V8, P4806, DOI 10.1109/ACCESS.2019.2962617
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jain S, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104789
   Ji XD, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0461-4
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2020, IEEE ACCESS, V8, P197969, DOI 10.1109/ACCESS.2020.3034217
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Korkmaz M.F., 2017, P 2017 IEEE 15 INT S, P327
   Koyama S, 2022, BMC NEUROL, V22, DOI 10.1186/s12883-022-02711-4
   Kumar AC, 2022, IRBM, V43, P251, DOI 10.1016/j.irbm.2021.10.003
   Lan LB, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106971
   Lee JH, 2019, SURG ENDOSC, V33, P3790, DOI 10.1007/s00464-019-06677-2
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li S, 2022, IET IMAGE PROCESS, V16, P2384, DOI 10.1049/ipr2.12495
   Ling TS, 2021, ENDOSCOPY, V53, P469, DOI 10.1055/a-1229-0920
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Mohapatra S, 2023, AIN SHAMS ENG J, V14, DOI 10.1016/j.asej.2022.101942
   Muruganantham P, 2022, J MED BIOL ENG, V42, P157, DOI 10.1007/s40846-022-00686-8
   Noor Muhammad Nouman, 2022, International Journal of Software Innovation, V10, DOI 10.4018/IJSI.293268
   Noor M.N., 2021, P NAT C ENG COMP TEC
   Noya F, 2017, IEEE ENG MED BIO, P3158, DOI 10.1109/EMBC.2017.8037527
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Patel V, 2016, CRIT REV BIOMED ENG, V44, P493, DOI 10.1615/CritRevBiomedEng.2017025035
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Reddy GT, 2022, MULTIMED TOOLS APPL, V81, P41429, DOI 10.1007/s11042-020-09988-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Seo S, 2021, FRONT PHARMACOL, V12, DOI 10.3389/fphar.2021.670670
   Shafiq M, 2020, COMPUT SECUR, V94, DOI 10.1016/j.cose.2020.101863
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Szczypinski P, 2011, LECT NOTES ARTIF INT, V6678, P140, DOI 10.1007/978-3-642-21219-2_19
   Usman MA, 2016, COMPUT MED IMAG GRAP, V54, P16, DOI 10.1016/j.compmedimag.2016.09.005
   Wang S, 2019, PROC SPIE, V11198, DOI 10.1117/12.2540456
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
NR 53
TC 1
Z9 1
U1 1
U2 1
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD APR
PY 2023
VL 12
IS 7
AR 1557
DI 10.3390/electronics12071557
PG 20
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Physics
GA F5MX9
UT WOS:000982797400001
OA gold
DA 2023-08-21
ER

PT J
AU Shen, MH
   Huang, CC
   Chen, YT
   Tsai, YJ
   Liou, FM
   Chang, SC
   Phan, NN
AF Shen, Ming-Hung
   Huang, Chi-Cheng
   Chen, Yu-Tsung
   Tsai, Yi-Jian
   Liou, Fou-Ming
   Chang, Shih-Chang
   Phan, Nam Nhut
TI Deep Learning Empowers Endoscopic Detection and Polyps Classification: A
   Multiple-Hospital Study
SO DIAGNOSTICS
LA English
DT Article
DE colorectal cancer; endoscopic; deep learning
ID COLORECTAL POLYPS; DIAGNOSIS
AB The present study aimed to develop an AI-based system for the detection and classification of polyps using colonoscopy images. A total of about 256,220 colonoscopy images from 5000 colorectal cancer patients were collected and processed. We used the CNN model for polyp detection and the EfficientNet-b0 model for polyp classification. Data were partitioned into training, validation and testing sets, with a 70%, 15% and 15% ratio, respectively. After the model was trained/validated/tested, to evaluate its performance rigorously, we conducted a further external validation using both prospective (n = 150) and retrospective (n = 385) approaches for data collection from 3 hospitals. The deep learning model performance with the testing set reached a state-of-the-art sensitivity and specificity of 0.9709 (95% CI: 0.9646-0.9757) and 0.9701 (95% CI: 0.9663-0.9749), respectively, for polyp detection. The polyp classification model attained an AUC of 0.9989 (95% CI: 0.9954-1.00). The external validation from 3 hospital results achieved 0.9516 (95% CI: 0.9295-0.9670) with the lesion-based sensitivity and a frame-based specificity of 0.9720 (95% CI: 0.9713-0.9726) for polyp detection. The model achieved an AUC of 0.9521 (95% CI: 0.9308-0.9734) for polyp classification. The high-performance, deep-learning-based system could be used in clinical practice to facilitate rapid, efficient and reliable decisions by physicians and endoscopists.
C1 [Shen, Ming-Hung] Fu Jen Catholic Univ, Fu Jen Catholic Univ Hosp, Dept Surg, New Taipei City 24205, Taiwan.
   [Shen, Ming-Hung] Fu Jen Catholic Univ, Coll Med, Sch Med, New Taipei City 24205, Taiwan.
   [Huang, Chi-Cheng] Taipei Vet Gen Hosp, Dept Surg, Taipei City 11217, Taiwan.
   [Huang, Chi-Cheng] Natl Taiwan Univ, Inst Epidemiol & Prevent Med, Coll Publ Hlth, Taipei City 10663, Taiwan.
   [Chen, Yu-Tsung] Fu Jen Catholic Univ Hosp, Dept Internal Med, New Taipei City 24205, Taiwan.
   [Tsai, Yi-Jian] Fu Jen Catholic Univ Hosp, Dept Surg, Div Colorectal Surg, New Taipei City 24205, Taiwan.
   [Tsai, Yi-Jian] Natl Taiwan Univ, Grad Inst Biomed Elect & Bioinformat, Dept Elect Engn, Taipei City 10663, Taiwan.
   [Liou, Fou-Ming] ASUSTeK Comp Inc, Taipei City 11259, Taiwan.
   [Chang, Shih-Chang] Cathay Gen Hosp, Dept Surg, Div Colorectal Surg, Taipei City 106443, Taiwan.
   [Phan, Nam Nhut] Natl Taiwan Univ, Ctr Genom & Precis Med, Bioinformat & Biostat Core, Taipei City 10055, Taiwan.
C3 Fu Jen Catholic University; Fu Jen Catholic University Hospital; Fu Jen
   Catholic University; Taipei Veterans General Hospital; National Taiwan
   University; Fu Jen Catholic University; Fu Jen Catholic University
   Hospital; Fu Jen Catholic University; Fu Jen Catholic University
   Hospital; National Taiwan University; ASUSTek Computer; Cathay General
   Hospital; National Taiwan University
RP Chang, SC (通讯作者)，Cathay Gen Hosp, Dept Surg, Div Colorectal Surg, Taipei City 106443, Taiwan.; Phan, NN (通讯作者)，Natl Taiwan Univ, Ctr Genom & Precis Med, Bioinformat & Biostat Core, Taipei City 10055, Taiwan.
EM cgh06719@cgh.org.tw; namphanpro@gmail.com
RI Phan, Nam Nhut/GLU-3273-2022
CR Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Chaib S., 2017, P 9 INT C DIG IM PRO, P712
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chubak J, 2019, CANCER EPIDEM BIOMAR, V28, P91, DOI 10.1158/1055-9965.EPI-18-0452
   Colucci Philomena M, 2003, Clin Med Res, V1, P261
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dodge S, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Grosu S, 2021, RADIOLOGY, V299, P326, DOI 10.1148/radiol.2021202363
   He J., 2021, ARXIV
   Health Promotion Administration Ministry of Health and Welfare, 2016, CANC REGISTRY ANN RE
   Hinton G. E., 2009, SCHOLARPEDIA, V4, P5947, DOI DOI 10.4249/SCHOLARPEDIA.5947
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P49, DOI 10.1159/000481230
   Kuznetsov K, 2006, ENDOSCOPY, V38, P76, DOI 10.1055/s-2005-921114
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Levine JS, 2006, NEW ENGL J MED, V355, P2551, DOI 10.1056/NEJMcp063038
   LONGACRE TA, 1990, AM J SURG PATHOL, V14, P524, DOI 10.1097/00000478-199006000-00003
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Nadimi ES, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106531
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2012, CANCER EPIDEM BIOMAR, V21, P411, DOI 10.1158/1055-9965.EPI-11-1020
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Soffer S, 2020, GASTROINTEST ENDOSC, V92, P831, DOI 10.1016/j.gie.2020.04.039
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thompson N. C., 2022, ARXIV
   Tsuneki M, 2022, J ORAL BIOSCI, V64, P312, DOI 10.1016/j.job.2022.03.003
   Turan M, 2022, MED IMAGE ANAL, V82, DOI 10.1016/j.media.2022.102587
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 48
TC 0
Z9 0
U1 4
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD APR
PY 2023
VL 13
IS 8
AR 1473
DI 10.3390/diagnostics13081473
PG 11
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA E8VQ8
UT WOS:000978258600001
PM 37189575
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Zhu, JB
   Ge, MF
   Chang, ZM
   Dong, WF
AF Zhu, Jianbo
   Ge, Mingfeng
   Chang, Zhimin
   Dong, Wenfei
TI GCCSwin-UNet: Global Context and Cross-Shaped Windows Vision Transformer
   Network for Polyp Segmentation
SO PROCESSES
LA English
DT Article
DE deep learning; colorectal cancer; colonoscopy images; vision
   transformer; medical image segmentation
AB Accurate polyp segmentation is of great importance for the diagnosis and treatment of colon cancer. Convolutional neural networks (CNNs) have made significant strides in the processing of medical images in recent years. The limited structure of convolutional operations prevents CNNs from learning adequately about global and long-range semantic information interactions, despite the remarkable performance they have attained. Therefore, the GCCSwin-UNet framework is suggested in this study. Specifically, the model utilizes an encoder-decoder structure, using the patch-embedding layer for feature downsampling and the CSwin Transformer block as the encoder for contextual feature extraction. To restore the feature map's spatial resolution during upsampling operations, a symmetric decoder and patch expansion layer are also created. In order to help the backbone module to do better feature learning, we also create a global context module (GCM) and a local position-enhanced module (LPEM). We conducted extensive experiments on the Kvasir-SEG and CVC-ClinicDB datasets, and compared them with existing methods. GCCSwin-UNet reached remarkable results with Dice and MIoU of 86.37% and 83.19% for Kvasir-SEG, respectively, and 91.26% and 84.65% for CVC-ClinicDB, respectively. Finally, quantitative analysis and statistical tests are applied to further demonstrate the validity and plausibility of our method.
C1 [Zhu, Jianbo; Dong, Wenfei] Shandong Univ Tradit Chinese Med, Sch Intelligence & Informat Engn, Jinan 250355, Peoples R China.
   [Zhu, Jianbo; Ge, Mingfeng; Chang, Zhimin; Dong, Wenfei] Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Suzhou 215163, Peoples R China.
C3 Shandong University of Traditional Chinese Medicine; Chinese Academy of
   Sciences; Suzhou Institute of Biomedical Engineering & Technology, CAS
RP Ge, MF (通讯作者)，Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Suzhou 215163, Peoples R China.
EM gemf@sibet.ac.cn
OI dong, wen fei/0000-0003-1319-3166
FU National Key R&D Program of China [2021YFB3602200]
FX This study was funded by the National Key R&D Program of China (No.
   2021YFB3602200).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Biller LH, 2021, JAMA-J AM MED ASSOC, V325, P669, DOI 10.1001/jama.2021.0106
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Cao H., 2021, ARXIV
   Chen LC, 2017, Arxiv, DOI arXiv:1706.05587
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chu XX, 2021, Arxiv, DOI [arXiv:2102.10882, DOI 10.48550/ARXIV.2102.10882]
   Ciardiello F, 2022, CA-CANCER J CLIN, V72, P372, DOI 10.3322/caac.21728
   de Lange T., 2020, P INT C MULT MOD DAE
   Dong X., 2022, P IEEECVF C COMPUTER
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Du N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155371
   Fan D.P., 2020, P INT C MEDICAL IMAG
   Fang Y., 2019, P INT C MED IM COMP
   Gao YH, 2021, LECT NOTES COMPUT SC, V12903, P61, DOI 10.1007/978-3-030-87199-4_6
   Gross S., 2009, BILDVERARBEITUNG F R, P252
   Ho JAT, 2019, Arxiv, DOI arXiv:1912.12180
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Jemal A., 2020, CA-CANCER J CLIN, V70, p7, DOI DOI 10.3322/caac.21208
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Ji GP, 2021, LECT NOTES COMPUT SC, V12901, P142, DOI 10.1007/978-3-030-87193-2_14
   Le Alexander, 2021, Int J Clin Res Trials, V6, DOI 10.15344/2456-8007/2021/157
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Ronneberger O, 2015, 161207003 ARXIV
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Shaw P, 2018, Arxiv, DOI arXiv:1803.02155
   Tian Y, 2021, Arxiv, DOI arXiv:2101.03285
   Tolstikhin I. O., 2021, P NEURIPS, V34, P24261
   Turner JK, 2013, EUR J GASTROEN HEPAT, V25, P562, DOI 10.1097/MEG.0b013e32835d1f2d
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A, 2017, ADV NEUR IN, V30
   Xu JJ, 2019, ADV NEUR IN, V32
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhu JB, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104593
NR 37
TC 0
Z9 0
U1 12
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-9717
J9 PROCESSES
JI Processes
PD APR
PY 2023
VL 11
IS 4
AR 1035
DI 10.3390/pr11041035
PG 14
WC Engineering, Chemical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA E8AC5
UT WOS:000977696300001
OA gold
DA 2023-08-21
ER

PT J
AU Mori, Y
   Wang, P
   Loberg, M
   Misawa, M
   Repici, A
   Spadaccini, M
   Correale, L
   Antonelli, G
   Yu, HG
   Gong, DX
   Ishiyama, M
   Kudo, S
   Kamba, S
   Sumiyama, K
   Saito, Y
   Nishino, H
   Liu, PX
   Brown, JRG
   Mansour, NM
   Gross, SA
   Kalager, M
   Bretthauer, M
   Rex, DK
   Sharma, P
   Berzin, TM
   Hassan, C
AF Mori, Yuichi
   Wang, Pu
   Loberg, Magnus
   Misawa, Masashi
   Repici, Alessandro
   Spadaccini, Marco
   Correale, Loredana
   Antonelli, Giulio
   Yu, Honggang
   Gong, Dexin
   Ishiyama, Misaki
   Kudo, Shin-ei
   Kamba, Shunsuke
   Sumiyama, Kazuki
   Saito, Yutaka
   Nishino, Haruo
   Liu, Peixi
   Brown, Jeremy R. Glissen
   Mansour, Nabil M.
   Gross, Seth A.
   Kalager, Mette
   Bretthauer, Michael
   Rex, Douglas K.
   Sharma, Prateek
   Berzin, Tyler M.
   Hassan, Cesare
TI Impact of Artificial Intelligence on Colonoscopy Surveillance After
   Polyp Removal: A Pooled Analysis of Randomized Trials
SO CLINICAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE Computer-Aided Diagnosis; Surveillance Interval; Machine Learning
ID COLORECTAL ADENOMAS; SYSTEM
AB BACKGROUND AND AIMS: Artificial intelligence (AI) tools aimed at improving polyp detection have been shown to in-crease the adenoma detection rate during colonoscopy. However, it is unknown how increased polyp detection rates by AI affect the burden of patient surveillance after polyp removal. METHODS: We conducted a pooled analysis of 9 randomized controlled trials (5 in China, 2 in Italy, 1 in Japan, and 1 in the United States) comparing colonoscopy with or without AI detection aids. The primary outcome was the proportion of patients recommended to undergo intensive surveil-lance (ie, 3-year interval). We analyzed intervals for AI and non-AI colonoscopies for the U.S. and European recommendations separately. We estimated proportions by calculating relative risks using the Mantel-Haenszel method. RESULTS: A total of 5796 patients (51% male, mean 53 years of age) were included; 2894 underwent AI -assisted colonoscopy and 2902 non-AI colonoscopy. When following U.S. guidelines, the pro-portion of patients recommended intensive surveillance increased from 8.4% (95% CI, 7.4%- 9.5%) in the non-AI group to 11.3% (95% CI, 10.2%-12.6%) in the AI group (absolute differ-ence, 2.9% [95% CI, 1.4%-4.4%]; risk ratio, 1.35 [95% CI, 1.16-1.57]). When following Euro-pean guidelines, it increased from 6.1% (95% CI, 5.3%-7.0%) to 7.4% (95% CI, 6.5%-8.4%) (absolute difference, 1.3% [95% CI, 0.01%-2.6%]; risk ratio, 1.22 [95% CI, 1.01-1.47]). CONCLUSIONS: The use of AI during colonoscopy increased the proportion of patients requiring intensive co-lonoscopy surveillance by approximately 35% in the United States and 20% in Europe (absolute increases of 2.9% and 1.3%, respectively). While this may contribute to improved cancer prevention, it significantly adds patient burden and healthcare costs.
C1 [Mori, Yuichi; Loberg, Magnus; Kalager, Mette; Bretthauer, Michael] Univ Oslo, Clin Effectiveness Res Grp, Oslo, Norway.
   [Mori, Yuichi; Loberg, Magnus; Kalager, Mette; Bretthauer, Michael] Oslo Univ Hosp, Dept Transplantat Med, Oslo, Norway.
   [Mori, Yuichi; Misawa, Masashi; Ishiyama, Misaki; Kudo, Shin-ei] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Japan.
   [Wang, Pu; Liu, Peixi] Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Sichuan, Peoples R China.
   [Repici, Alessandro; Spadaccini, Marco; Correale, Loredana; Hassan, Cesare] Humanitas Clin & Res Ctr IRCCS, Endoscopy Unit, Rozzano, Italy.
   [Repici, Alessandro; Hassan, Cesare] Humanitas Univ, Dept Biomed Sci, Pieve Emanuele, Italy.
   [Antonelli, Giulio] Osped Castelli Hosp, Gastroenterol & Digest Endoscopy Unit, Ariccia, Rome, Italy.
   [Antonelli, Giulio] Sapienza Univ Rome, Dept Anat Histol Forens Med & Orthoped Sci, Rome, Italy.
   [Yu, Honggang; Gong, Dexin] Wuhan Univ, Dept Gastroenterol, Renmin Hosp, Wuhan, Peoples R China.
   [Yu, Honggang; Gong, Dexin] Wuhan Univ, Key Lab Hubei Prov Digest Syst Dis, Renmin Hosp, Wuhan, Peoples R China.
   [Yu, Honggang; Gong, Dexin] Wuhan Univ, Hubei Prov Clin Res Ctr Digest Dis Minimally Inva, Renmin Hosp, Wuhan, Peoples R China.
   [Kamba, Shunsuke; Sumiyama, Kazuki] Jikei Univ, Dept Endoscopy, Sch Med, Tokyo, Japan.
   [Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Tokyo, Japan.
   [Nishino, Haruo] Matsushima Hosp, Coloproctol Ctr, Yokohama, Japan.
   [Brown, Jeremy R. Glissen] Duke Univ, Div Gastroenterol, Med Ctr, Durham, NC USA.
   [Mansour, Nabil M.] Baylor Coll Med, Sect Gastroenterol & Hepatol, Houston, TX USA.
   [Gross, Seth A.] NYU, Div Gastroenterol & Hepatol, Langone Hlth, New York, NY USA.
   [Rex, Douglas K.] Indiana Univ Sch Med, Div Gastroenterol Hepatol, Indianapolis, IN USA.
   [Sharma, Prateek] Kansas City VA Med Ctr, Dept Gastroenterol & Hepatol, Kansas City, KS USA.
   [Sharma, Prateek] Univ Kansas, Sch Med, Kansas City, KS USA.
   [Berzin, Tyler M.] Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Boston, MA USA.
   [Berzin, Tyler M.] Harvard Med Sch, Boston, MA USA.
C3 University of Oslo; University of Oslo; Showa University; Sichuan
   Provincial People's Hospital; Humanitas University; Sapienza University
   Rome; Wuhan University; Wuhan University; Wuhan University; Jikei
   University; National Cancer Center - Japan; Duke University; Baylor
   College of Medicine; New York University; Indiana University System;
   Indiana University Bloomington; University of Kansas; University of
   Kansas Medical Center; Harvard University; Beth Israel Deaconess Medical
   Center; Harvard University; Harvard Medical School
RP Mori, Y (通讯作者)，Univ Oslo, Clin Effectiveness Res Grp, Gaustad Sykehus,Bygg 20,Sognsvannsveien 21, N-0372 Oslo, Norway.
EM yuichi.mori@medisin.uio.no
RI Spadaccini, Marco/HOH-7613-2023; Repici, Alessandro/HFH-8162-2022;
   hassan, cesare/H-2844-2012; Misawa, Masashi/H-9004-2019; Sharma,
   Prateek/IZE-3910-2023
OI Spadaccini, Marco/0000-0003-3909-9012; Repici,
   Alessandro/0000-0002-1621-6450; hassan, cesare/0000-0001-7167-1459;
   Misawa, Masashi/0000-0002-8520-2036; Mori, Yuichi/0000-0003-2262-0334;
   Wang, Pu/0000-0002-1234-309X; Antonelli, Giulio/0000-0003-1797-3864;
   Glissen Brown, Jeremy/0000-0002-7204-7241
FU European Commission (Horizon2020 MSCA-IF) [101026196]; Japan Society for
   the Promotion of Science [19KK0421]; Japan Agency for Medical Research
   and Development [18ck0106272h0002]
FX Yuichi Mori was supported by the European Commission (Horizon2020
   MSCA-IF No. 101026196) and the Japan Society for the Promotion of
   Science (No. 19KK0421) . Shunsuke Kamba was supported by the Japan
   Agency for Medical Research and Development (18ck0106272h0002) .
CR Areia M, 2022, LANCET DIG HLTH, V4, P436
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Duvvuri A, 2021, GASTROENTEROLOGY, V160, P1986, DOI 10.1053/j.gastro.2021.01.214
   Glissen Brown JR, 2022, CLIN GASTROENTEROL H, P4
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gupta SK, 2020, GASTROENTEROLOGY, V158, pS493
   Hassan C., 2021, GASTROINTEST ENDOSC, V93
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Kalager M, 2018, GASTROENTEROLOGY, V155, P592, DOI 10.1053/j.gastro.2018.07.037
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Meester RGS, 2019, ANN INTERN MED, V171, P612, DOI 10.7326/M18-3633
   Misawa M, 2022, GASTROINTEST ENDOSC, V93, P3
   Mori Y, 2021, GASTROENTEROLOGY, V161, P774, DOI 10.1053/j.gastro.2021.04.078
   Repici A, 2020, GASTROENTEROLOGY, V159, P7
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Saito Y, 2021, DIGEST ENDOSC, V33, P486, DOI 10.1111/den.13972
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   van Heijningen EMB, 2015, GUT, V64, P1584, DOI 10.1136/gutjnl-2013-306453
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
NR 28
TC 4
Z9 4
U1 1
U2 2
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1542-3565
EI 1542-7714
J9 CLIN GASTROENTEROL H
JI Clin. Gastroenterol. Hepatol.
PD APR
PY 2023
VL 21
IS 4
BP 949
EP +
DI 10.1016/j.cgh.2022.08.022
EA MAR 2023
PG 13
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA F3OD3
UT WOS:000981461800001
PM 36038128
OA hybrid
DA 2023-08-21
ER

PT J
AU Chin, SE
   Wan, FT
   Ladlad, J
   Chue, KM
   Teo, EK
   Lin, CL
   Foo, FJ
   Koh, FH
AF Chin, Shuen-Ern
   Wan, Fang-Ting
   Ladlad, Jasmine
   Chue, Koy-Min
   Teo, Eng-Kiong
   Lin, Cui-Li
   Foo, Fung-Joon H.
   Koh, Frederick
TI One-year review of real-time artificial intelligence (AI)-aided
   endoscopy performance
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
LA English
DT Review
DE Artificial intelligence; Polyp detection; Colonoscopy; Adenoma
   detection; Endoscopy
ID COMPUTER-AIDED DETECTION; COLORECTAL-CANCER; QUALITY INDICATORS; ADENOMA
   DETECTION; COLONOSCOPY; PREVENTION; SYSTEM
AB BackgroundColonoscopies have long been the gold standard for detection of pre-malignant neoplastic lesions of the colon. Our previous study tried real-time artificial intelligence (AI)-aided colonoscopy over a three-month period and found significant improvements in collective and individual endoscopist's adenoma detection rates compared to baseline. As an expansion, this study evaluates the 1-year performance of AI-aided colonoscopy in the same institution.MethodsA prospective cohort study was conducted in a single institution in Singapore. The AI software used was GI Genius (TM) Intelligent Endoscopy Module, US-DG-2000309 (c) 2021 Medtronic. Between July 2021 and June 2022, polypectomy rates in non-AI-aided colonoscopies and AI-aided colonoscopies were calculated and compared. Some of the AI-aided colonoscopies were recorded and video reviewed. A "hit" was defined as a sustained detection of an area by the AI. If a polypectomy was performed for a "hit," its histology was reviewed. Additional calculations for polyp detection rate (PDR), adenoma detection rate (ADR), and adenoma detection per colonoscopy (ADPC) were performed. Cost analysis was performed to determine cost effectiveness of subscription to the AI program.Results2433 AI-aided colonoscopies were performed between July 2021 and June 2022 and compared against 1770 non-AI-aided colonoscopies. AI-aided colonoscopies yielded significantly higher rates of polypectomies (33.6%) as compared with non-AI-aided colonoscopies (28.4%) (p < 0.001). Among the AI-aided colonoscopies, 1050 were reviewed and a final 843 were included for additional analysis. The polypectomy to "hit" ratio was 57.4%, PDR = 45.6%, ADR = 32.4%, and ADPC = 2.08. Histological review showed that 25 polyps (3.13%) were sessile-serrated adenomas. Cost analysis found that the increased polypectomy rates in AI-aided colonoscopes led to an increase in revenue, which covered the subscription cost with an excess of USD 20,000.ConclusionAI-aided colonoscopy is a cost effective means of improving colonoscopy quality and may help advance colorectal cancer screening in Singapore.
C1 [Chin, Shuen-Ern; Wan, Fang-Ting] Lee Kong Chian Sch Med, 11 Mandalay Rd, Singapore 308232, Singapore.
   [Ladlad, Jasmine; Foo, Fung-Joon H.; Koh, Frederick] SingHealth, Sengkang Gen Hosp, Dept Gen Surg, Colorectal Serv, 110 Sengkang East Way, Singapore 544886, Singapore.
   [Chue, Koy-Min] Sengkang Gen Hosp, Endoscopy Ctr, Div Hyperacute Care, 110 Sengkang East Way, Singapore 544886, Singapore.
   [Teo, Eng-Kiong; Lin, Cui-Li] SingHealth, Sengkang Gen Hosp, Dept Gastroenterol & Hepatol, 110 Sengkang East Way, Singapore 544886, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University
RP Koh, FH (通讯作者)，SingHealth, Sengkang Gen Hosp, Dept Gen Surg, Colorectal Serv, 110 Sengkang East Way, Singapore 544886, Singapore.
EM frederickkohhx@gmail.com
OI , Shuen Ern/0000-0001-6183-8518
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Chan HP, 2020, MED PHYS, V47, pE218, DOI 10.1002/mp.13764
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Koh FH, 2023, SURG ENDOSC, V37, P165, DOI 10.1007/s00464-022-09470-w
   Lee JK, 2020, GASTROENTEROLOGY, V158, P884, DOI 10.1053/j.gastro.2019.09.039
   Leung FW, 2021, GASTROINTEST ENDOSC, V93, P86, DOI 10.1016/j.gie.2020.07.059
   Lieberman DA, 2000, NEW ENGL J MED, V343, P162, DOI 10.1056/NEJM200007203430301
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Millan MS, 2008, DIS COLON RECTUM, V51, P1217, DOI 10.1007/s10350-008-9315-3
   Niikura R, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185294
   Redaelli A, 2003, PHARMACOECONOMICS, V21, P1213, DOI 10.2165/00019053-200321170-00001
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Shah SK, 2022, CANCER RES COMMUN, V2, P561, DOI [10.1158/2767-9764.crc-22-0079, 10.1158/2767-9764.CRC-22-0079]
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang JX, 2020, J CANCER, V11, P5953, DOI 10.7150/jca.46661
NR 25
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0930-2794
EI 1432-2218
J9 SURG ENDOSC
JI Surg. Endosc.
PD AUG
PY 2023
VL 37
IS 8
BP 6402
EP 6407
DI 10.1007/s00464-023-09979-8
EA MAR 2023
PG 6
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA L4YJ0
UT WOS:000953339400004
PM 36932187
DA 2023-08-21
ER

PT J
AU Zhu, Y
   Zhang, DF
   Wu, HL
   Fu, PY
   Feng, L
   Zhuang, K
   Geng, ZH
   Li, KK
   Zhang, XH
   Zhu, BQ
   Qin, WZ
   Lin, SL
   Zhang, Z
   Chen, TY
   Huang, Y
   Xu, XY
   Liu, JZ
   Wang, S
   Zhang, W
   Li, QL
   Zhou, PH
AF Zhu, Yan
   Zhang, Dan-Feng
   Wu, Hui-Li
   Fu, Pei-Yao
   Feng, Li
   Zhuang, Kun
   Geng, Zi-Han
   Li, Kun-Kun
   Zhang, Xiao-Hong
   Zhu, Bo-Qun
   Qin, Wen-Zheng
   Lin, Sheng-Li
   Zhang, Zhen
   Chen, Tian-Yin
   Huang, Yuan
   Xu, Xiao-Yue
   Liu, Jing-Zheng
   Wang, Shuo
   Zhang, Wei
   Li, Quan-Lin
   Zhou, Ping-Hong
TI Improving bowel preparation for colonoscopy with a smartphone
   application driven by artificial intelligence
SO NPJ DIGITAL MEDICINE
LA English
DT Article
ID PATIENT EDUCATION; QUALITY; INSTRUCTIONS; ENDOSCOPY; IMPACT
AB Optimal bowel preparation is a prerequisite for a successful colonoscopy; however, the rate of inadequate bowel preparation remains relatively high. In this study, we establish a smartphone app that assesses patient bowel preparation using an artificial intelligence (AI)-based prediction system trained on labeled photographs of feces in the toilet and evaluate its impact on bowel preparation quality in colonoscopy outpatients. We conduct a prospective, single-masked, multicenter randomized clinical trial, enrolling outpatients who own a smartphone and are scheduled for a colonoscopy. We screen 578 eligible patients and randomize 524 in a 1:1 ratio to the control or AI-driven app group for bowel preparation. The study endpoints are the percentage of patients with adequate bowel preparation and the total BBPS score, compliance with dietary restrictions and purgative instructions, polyp detection rate, and adenoma detection rate (secondary). The prediction system has an accuracy of 95.15%, a specificity of 97.25%, and an area under the curve of 0.98 in the test dataset. In the full analysis set (n = 500), adequate preparation is significantly higher in the AI-driven app group (88.54 vs. 65.59%; P < 0.001). The mean BBPS score is 6.74 +/- 1.25 in the AI-driven app group and 5.97 +/- 1.81 in the control group (P < 0.001). The rates of compliance with dietary restrictions (93.68 vs. 83.81%, P = 0.001) and purgative instructions (96.05 vs. 84.62%, P < 0.001) are significantly higher in the AI-driven app group, as is the rate of additional purgative intake (26.88 vs. 17.41%, P = 0.011). Thus, our AI-driven smartphone app significantly improves the quality of bowel preparation and patient compliance.
C1 [Zhu, Yan; Zhang, Dan-Feng; Fu, Pei-Yao; Geng, Zi-Han; Zhu, Bo-Qun; Qin, Wen-Zheng; Lin, Sheng-Li; Zhang, Zhen; Chen, Tian-Yin; Huang, Yuan; Xu, Xiao-Yue; Liu, Jing-Zheng; Li, Quan-Lin; Zhou, Ping-Hong] Fudan Univ, Zhongshan Hosp, Endoscopy Ctr, Shanghai, Peoples R China.
   [Zhu, Yan; Zhang, Dan-Feng; Fu, Pei-Yao; Geng, Zi-Han; Zhu, Bo-Qun; Qin, Wen-Zheng; Lin, Sheng-Li; Zhang, Zhen; Chen, Tian-Yin; Huang, Yuan; Xu, Xiao-Yue; Liu, Jing-Zheng; Li, Quan-Lin; Zhou, Ping-Hong] Fudan Univ, Zhongshan Hosp, Endoscopy Res Inst, Shanghai, Peoples R China.
   [Zhu, Yan; Zhang, Dan-Feng; Fu, Pei-Yao; Geng, Zi-Han; Zhu, Bo-Qun; Qin, Wen-Zheng; Lin, Sheng-Li; Zhang, Zhen; Chen, Tian-Yin; Huang, Yuan; Xu, Xiao-Yue; Liu, Jing-Zheng; Li, Quan-Lin; Zhou, Ping-Hong] Shanghai Collaborat Innovat Ctr Endoscopy, Shanghai, Peoples R China.
   [Wu, Hui-Li; Li, Kun-Kun] Zhengzhou Cent Hosp, Dept Gastroenterol, Zhengzhou, Henan, Peoples R China.
   [Feng, Li; Zhang, Xiao-Hong] Cent Hosp Minhang Dist, Endoscopy Ctr, Shanghai, Peoples R China.
   [Zhuang, Kun] Xian Cent Hosp, Dept Gastroenterol, Xian, Shaanxi, Peoples R China.
   [Wang, Shuo] Fudan Univ, Digital Med Res Ctr, Sch Basic Med Sci, Shanghai, Peoples R China.
   [Wang, Shuo] Shanghai Key Lab Med Imaging Comp & Comp Assisted, Shanghai, Peoples R China.
   [Zhang, Wei] Fudan Univ, Sch Publ Hlth, Dept Biostat, Shanghai, Peoples R China.
C3 Fudan University; Fudan University; Zhengzhou University; Fudan
   University; Fudan University
RP Li, QL; Zhou, PH (通讯作者)，Fudan Univ, Zhongshan Hosp, Endoscopy Ctr, Shanghai, Peoples R China.; Li, QL; Zhou, PH (通讯作者)，Fudan Univ, Zhongshan Hosp, Endoscopy Res Inst, Shanghai, Peoples R China.; Li, QL; Zhou, PH (通讯作者)，Shanghai Collaborat Innovat Ctr Endoscopy, Shanghai, Peoples R China.
EM li.quanlin@zs-hospital.sh.cn; zhou.pinghong@zs-hospital.sh.cn
RI Wang, lili/IXD-9828-2023; zhang, danfeng/GWN-2402-2022; Li,
   Yuan/IXD-9067-2023; li, wei/IUQ-2973-2023; .., What/IXW-6776-2023
FU National Key R&D Program of China [2019YFC1315800]; National Natural
   Science Foundation of China [82170555, 82203193]; Zhongshan Hospital
   Clinical Research Fund [2020ZSLC50]; Major Project of Shanghai Municipal
   Science and Technology Committee [19441905200]; Natural Science
   Foundation of Shanghai [20DZ1100102]
FX AcknowledgementsThis study was supported by grants from the National Key
   R&D Program of China (2019YFC1315800), the National Natural Science
   Foundation of China (82170555 and 82203193), Zhongshan Hospital Clinical
   Research Fund (2020ZSLC50), Major Project of Shanghai Municipal Science
   and Technology Committee (19441905200), and Natural Science Foundation
   of Shanghai (20DZ1100102). We thank Jie Gong, Zhi-Pei Zhang, Wen-Long
   Wu, Te Luo, Wu-Chao Tao, Man Guo, Zhuo-Qi Wang, Ting Xia, Qiu-Cheng
   Wang, De-Jia Sun, Yuan-Jin Chen, Qin-Yu Ke, Yuan-Feng Qiao, Chang Xiao,
   and Jia-Yan Wang for their kindness and support of this research.
CR Abuksis G, 2001, AM J GASTROENTEROL, V96, P1786, DOI 10.1016/S0002-9270(01)02435-2
   Alvarez-Gonzalez MA, 2016, ENDOSCOPY, V48, P1003, DOI 10.1055/s-0042-111320
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Bretthauer M, 2016, JAMA INTERN MED, V176, P894, DOI 10.1001/jamainternmed.2016.0960
   Enestvedt BK, 2012, CLIN GASTROENTEROL H, V10, P1225, DOI 10.1016/j.cgh.2012.08.029
   Gimeno-Garcia AZ, 2017, AM J GASTROENTEROL, V112, P951, DOI 10.1038/ajg.2017.53
   Guo BM, 2020, J ADV NURS, V76, P1037, DOI 10.1111/jan.14295
   Guo XY, 2017, GASTROINTEST ENDOSC, V85, P90, DOI 10.1016/j.gie.2016.05.012
   Harewood GC, 2003, GASTROINTEST ENDOSC, V58, P76, DOI 10.1067/mge.2003.294
   Hassan C, 2013, ENDOSCOPY, V45, P142, DOI 10.1055/s-0032-1326186
   Hassan C, 2021, ENDOSC INT OPEN, V09, pE627, DOI 10.1055/a-1373-4799
   Hassan C, 2019, ENDOSCOPY, V51, P775, DOI 10.1055/a-0959-0505
   Hillyer GC, 2012, J CANCER EDUC, V27, P526, DOI 10.1007/s13187-012-0364-x
   Kang XY, 2016, CLIN GASTROENTEROL H, V14, P429, DOI 10.1016/j.cgh.2015.09.038
   Liu XD, 2014, GUT, V63, P125, DOI 10.1136/gutjnl-2012-304292
   Liu Z, 2017, J DIGEST DIS, V18, P84, DOI 10.1111/1751-2980.12446
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Rice SC, 2016, AM J GASTROENTEROL, V111, P1564, DOI 10.1038/ajg.2016.450
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Sinonquel P, 2021, DIGEST ENDOSC, V33, P242, DOI 10.1111/den.13888
   Spiegel BMR, 2011, AM J GASTROENTEROL, V106, P875, DOI 10.1038/ajg.2011.75
   Sung JJY, 2015, GUT, V64, P121, DOI 10.1136/gutjnl-2013-306503
   Suzuki H, 2021, DIGEST ENDOSC, V33, P254, DOI 10.1111/den.13897
   Tae JW, 2012, GASTROINTEST ENDOSC, V76, P804, DOI 10.1016/j.gie.2012.05.026
   Walter B, 2019, GASTROINTEST ENDOSC, V89, P506, DOI 10.1016/j.gie.2018.08.014
   Wang SL, 2019, EUR J GASTROEN HEPAT, V31, P170, DOI 10.1097/MEG.0000000000001303
   Wu LL, 2021, ENDOSCOPY, V53, P1199, DOI 10.1055/a-1350-5583
NR 27
TC 0
Z9 0
U1 3
U2 3
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2398-6352
J9 NPJ DIGIT MED
JI npj Digit. Med.
PD MAR 14
PY 2023
VL 6
IS 1
AR 41
DI 10.1038/s41746-023-00786-y
PG 9
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA 9W8LF
UT WOS:000949327500002
PM 36918730
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Gan, PL
   Li, PL
   Xia, HF
   Zhou, X
   Tang, XW
AF Gan, Peiling
   Li, Peiling
   Xia, Huifang
   Zhou, Xian
   Tang, Xiaowei
TI The application of artificial intelligence in improving colonoscopic
   adenoma detection rate: Where are we and where are we going
SO GASTROENTEROLOGIA Y HEPATOLOGIA
LA English
DT Review
DE Artificial intelligence; Adenoma detection rate; Convolutional neural
   networks; Computer-aided diagnosis
ID COMPUTER-AIDED DIAGNOSIS; COLORECTAL POLYP HISTOLOGY; LONGER WITHDRAWAL
   TIME; LEARNING ALGORITHM; MISS RATE; SYSTEM; CLASSIFICATION; LESIONS;
   ENDOCYTOSCOPY; ENDOSCOPY
AB Colorectal cancer (CRC) is one of the common malignant tumors in the world. Colonoscopy is the crucial examination technique in CRC screening programs for the early detection of precursor lesions, and treatment of early colorectal cancer, which can reduce the morbidity and mortality of CRC significantly. However, pooled polyp miss rates during colonoscopic examination are as high as 22%. Artificial intelligence (AI) provides a promising way to improve the colonoscopic adenoma detection rate (ADR). It might assist endoscopists in avoiding missing polyps and offer an accurate optical diagnosis of suspected lesions. Herein, we described some of the milestone studies in using AI for colonoscopy, and the future application directions of AI in improving colonoscopic ADR. (c) 2022 Elsevier Espana, S.L.U. All rights reserved.
C1 [Gan, Peiling; Li, Peiling; Xia, Huifang; Zhou, Xian; Tang, Xiaowei] Southwest Med Univ, Affiliated Hosp, Dept Gastroenterol, Luzhou, Peoples R China.
   [Tang, Xiaowei] Chinese Peoples Liberat Army Gen Hosp, Med Ctr 1, Dept Gastroenterol, Beijing, Peoples R China.
C3 Southwest Medical University; Chinese People's Liberation Army General
   Hospital
RP Tang, XW (通讯作者)，Southwest Med Univ, Affiliated Hosp, Dept Gastroenterol, Luzhou, Peoples R China.; Tang, XW (通讯作者)，Chinese Peoples Liberat Army Gen Hosp, Med Ctr 1, Dept Gastroenterol, Beijing, Peoples R China.
RI Li, Peiling/HCI-0440-2022
FU Youth Foundation of Southwest Medical University [0903-00031099];
   Doctoral research start-up funding project of Affiliated Hospital of
   Southwest Medical University [16229]; Cooperation Project of Southwest
   Medical University and Luzhou Government [2019LZXNYDJ24]
FX This study is independent research funded by the following grants: Youth
   Foundation of Southwest Medical University (No. 0903-00031099), Doctoral
   research start-up funding project of Affiliated Hospital of Southwest
   Medical University (No. 16229), Cooperation Project of Southwest Medical
   University and Luzhou Government (No. 2019LZXNYDJ24).
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   [Anonymous], WHO CANC STAT
   Butterly L, 2014, AM J GASTROENTEROL, V109, P417, DOI 10.1038/ajg.2013.442
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hazewinkel Y, 2013, GASTROINTEST ENDOSC, V77, P916, DOI 10.1016/j.gie.2012.12.018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hirakawa T, 2014, IEEE ENG MED BIO, P4739, DOI 10.1109/EMBC.2014.6944683
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2014, J GASTROEN HEPATOL, V29, P83, DOI 10.1111/jgh.12374
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Lee TJW, 2013, ENDOSCOPY, V45, P20, DOI 10.1055/s-0032-1325803
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Memmert D, 2010, J GEN PSYCHOL, V137, P129, DOI 10.1080/00221301003645061
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2013, ENDOSCOPY, V45, P98, DOI 10.1055/s-0032-1325932
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Okamoto T, 2015, IEEE ENG MED BIO, P2997, DOI 10.1109/EMBC.2015.7319022
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rogart JN, 2008, AM J GASTROENTEROL, V103, P2841, DOI 10.1111/j.1572-0241.2008.02085.x
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Shaukat A, 2015, GASTROENTEROLOGY, V149, P952, DOI 10.1053/j.gastro.2015.06.044
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Stadthagen G, 2013, PLOS GENET, V9, DOI 10.1371/journal.pgen.1003913
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Uchiyama K, 2017, J CROHNS COLITIS, V11, P963, DOI 10.1093/ecco-jcc/jjx026
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vleugels JLA, 2019, GASTROENTEROLOGY, V156, P623, DOI 10.1053/j.gastro.2018.10.050
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Wolfe JM, 2006, VIS COGN, V14, P749, DOI 10.1080/13506280500195292
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 61
TC 0
Z9 0
U1 3
U2 5
PU ELSEVIER ESPANA SLU
PI BARCELONA
PA AV JOSEP TARRADELLAS, 20-30, 1ERA PLANTA, BARCELONA, CP-08029, SPAIN
SN 0210-5705
J9 GASTROENT HEPAT-BARC
JI Gastroenterol. Hepatol.
PD MAR
PY 2023
VL 46
IS 3
BP 203
EP 213
DI 10.1016/j.gastrohep.2022.03.009
EA MAR 2023
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA A5SO2
UT WOS:000955718900001
PM 35489584
DA 2023-08-21
ER

PT J
AU Mori, Y
   East, JE
   Hassan, C
   Halvorsen, N
   Berzin, TM
   Byrne, M
   von Renteln, D
   Hewett, DG
   Repici, A
   Ramchandani, M
   Al Khatry, M
   Kudo, S
   Wang, P
   Yu, HG
   Saito, Y
   Misawa, M
   Parasa, S
   Matsubayashi, CO
   Ogata, H
   Tajiri, H
   Pausawasdi, N
   Dekker, E
   Ahmad, OF
   Sharma, P
   Rex, DK
AF Mori, Yuichi
   East, James E.
   Hassan, Cesare
   Halvorsen, Natalie
   Berzin, Tyler M.
   Byrne, Michael
   von Renteln, Daniel
   Hewett, David G.
   Repici, Alessandro
   Ramchandani, Mohan
   Al Khatry, Maryam
   Kudo, Shin-ei
   Wang, Pu
   Yu, Honggang
   Saito, Yutaka
   Misawa, Masashi
   Parasa, Sravanthi
   Matsubayashi, Carolina Ogawa
   Ogata, Haruhiko
   Tajiri, Hisao
   Pausawasdi, Nonthalee
   Dekker, Evelien
   Ahmad, Omer F.
   Sharma, Prateek
   Rex, Douglas K.
TI Benefits and challenges in implementation of artificial intelligence in
   colonoscopy: World Endoscopy Organization position statement
SO DIGESTIVE ENDOSCOPY
LA English
DT Review; Early Access
DE colon polyp; colonoscopy
ID COMPUTER-AIDED DETECTION; DELPHI METHOD
AB The number of artificial intelligence (AI) tools for colonoscopy on the market is increasing with supporting clinical evidence. Nevertheless, their implementation is not going smoothly for a variety of reasons, including lack of data on clinical benefits and cost-effectiveness, lack of trustworthy guidelines, uncertain indications, and cost for implementation. To address this issue and better guide practitioners, the World Endoscopy Organization (WEO) has provided its perspective about the status of AI in colonoscopy as the position statement. WEO Position Statement: Statement 1.1: Computer-aided detection (CADe) for colorectal polyps is likely to improve colonoscopy effectiveness by reducing adenoma miss rates and thus increase adenoma detection; Statement 1.2: In the short term, use of CADe is likely to increase health-care costs by detecting more adenomas; Statement 1.3: In the long term, the increased cost by CADe could be balanced by savings in costs related to cancer treatment (surgery, chemotherapy, palliative care) due to CADe-related cancer prevention; Statement 1.4: Health-care delivery systems and authorities should evaluate the cost-effectiveness of CADe to support its use in clinical practice; Statement 2.1: Computer-aided diagnosis (CADx) for diminutive polyps (<= 5 mm), when it has sufficient accuracy, is expected to reduce health-care costs by reducing polypectomies, pathological examinations, or both; Statement 2.2: Health-care delivery systems and authorities should evaluate the cost-effectiveness of CADx to support its use in clinical practice; Statement 3: We recommend that a broad range of high-quality cost-effectiveness research should be undertaken to understand whether AI implementation benefits populations and societies in different health-care systems.
C1 [Mori, Yuichi; Halvorsen, Natalie] Univ Oslo, Clin Effectiveness Res Grp, Oslo, Norway.
   [Mori, Yuichi] Oslo Univ Hosp, Dept Transplantat Med, Oslo, Norway.
   [Mori, Yuichi; Kudo, Shin-ei; Misawa, Masashi] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Tokyo, Japan.
   [Ogata, Haruhiko] Keio Univ, Ctr Diagnost & Therapeut Endoscopy, Sch Med, Tokyo, Japan.
   [Tajiri, Hisao] Jikei Univ, Sch Med, Tokyo, Japan.
   [East, James E.] Univ Oxford, John Radcliffe Hosp, Translat Gastroenterol Unit, Oxford, England.
   [East, James E.] NIHR Oxford Biomed Res Ctr, Oxford, England.
   [East, James E.] Mayo Clin Healthcare, Div Gastroenterol & Hepatol, London, England.
   [Ahmad, Omer F.] UCL, London, England.
   [Hassan, Cesare; Repici, Alessandro] Humanitas Univ, Dept Biomed Sci, Pieve Emanuele, Italy.
   [Hassan, Cesare; Repici, Alessandro] IRCCS, Endoscopy Unit, Humanitas Clin & Res Ctr, Rozzano, Italy.
   [Berzin, Tyler M.] Beth Israel Deaconess Med Ctr, Div Gastroenterol, Boston, MA USA.
   [Berzin, Tyler M.] Harvard Med Sch, Boston, MA USA.
   [Parasa, Sravanthi] Swedish Med Ctr, Seattle, WA USA.
   [Sharma, Prateek] Univ Kansas, Sch Med, Div Gastroenterol & Hepatol, Kansas City, MO USA.
   [Sharma, Prateek] VA Med Ctr, Kansas City, MO USA.
   [Rex, Douglas K.] Indiana Univ Sch Med, Div Gastroenterol, Indianapolis, IN USA.
   [Byrne, Michael] Univ British Columbia, Dept Med, Vancouver, BC, Canada.
   [von Renteln, Daniel] Univ Montreal, Med Ctr CHUM, Div Gastroenterol, Montreal, PQ, Canada.
   [von Renteln, Daniel] Res Ctr CRCHUM, Montreal, PQ, Canada.
   [Hewett, David G.] Univ Queensland, Sch Med, Brisbane, Qld, Australia.
   [Ramchandani, Mohan] Asian Inst Gastroenterol, Hyderabad, India.
   [Al Khatry, Maryam] Obaidulla Hosp, Dept Gastroenterol, Ras Al Khaymah, U Arab Emirates.
   [Wang, Pu] Sichuan Acad Med Sci, Chengdu, Peoples R China.
   [Wang, Pu] Sichuan Prov Peoples Hosp, Chengdu, Peoples R China.
   [Yu, Honggang] Wuhan Univ, Dept Gastroenterol, Renmin Hosp, Wuhan, Peoples R China.
   [Matsubayashi, Carolina Ogawa] Univ Sao Paulo, Dept Gastroenterol, Gastrointestinal Endoscopy Unit, Sch Med, Sao Paulo, Brazil.
   [Pausawasdi, Nonthalee] Vikit Viranuvatti Siriraj GI Endoscopy Ctr, Bangkok, Thailand.
   [Pausawasdi, Nonthalee] Mahidol Univ, Siriraj Hosp, Div Gastroenterol, Dept Med,Fac Med, Bangkok, Thailand.
   [Dekker, Evelien] Univ Amsterdam, Dept Gastroenterol & Hepatol, Med Ctr, Amsterdam, Netherlands.
C3 University of Oslo; University of Oslo; Showa University; National
   Cancer Center - Japan; Keio University; Jikei University; University of
   Oxford; University of Oxford; University of London; University College
   London; Humanitas University; IRCCS Humanitas Research Hospital; Harvard
   University; Beth Israel Deaconess Medical Center; Harvard University;
   Harvard Medical School; Swedish Medical Center; University of Kansas;
   Indiana University System; Indiana University Bloomington; University of
   British Columbia; Universite de Montreal; University of Queensland;
   Sichuan Provincial People's Hospital; Sichuan Provincial People's
   Hospital; Wuhan University; Universidade de Sao Paulo; Mahidol
   University; University of Amsterdam
RP Mori, Y (通讯作者)，Univ Oslo, Inst Hlth & Soc, Clin Effectiveness Res Grp, Fac Med, Gaustad Sykehus,Bygg 20,Sognsvannsveien 21, N-0372 Oslo, Norway.; Mori, Y (通讯作者)，Showa Univ, Ctr Digest Dis, Northern Yokohama Hosp, 35-1 Chigasaki Chuo, Tsuzuki, Kanagawa 2248503, Japan.
EM yuichi.mori@medisin.uio.no
RI Sharma, Prateek/IZE-3910-2023; Hewett, David/B-4197-2011
OI Berzin, Tyler/0000-0002-4364-6210; Halvorsen,
   Natalie/0009-0009-3062-036X; Hewett, David/0000-0002-4529-3543
FU European Commission (Horizon Europe) [101057099]; Japan Society for
   Promotion of Science [22H03357]; National Institute for Health Research
   (NIHR) Oxford Biomedical Research Centre
FX AUTHOR Y.M. IS funded by the European Commission (Horizon Europe
   101057099) and Japan Society for Promotion of Science (22H03357); J.E.E.
   is funded by the National Institute for Health Research (NIHR) Oxford
   Biomedical Research Centre. The views expressed are those of the authors
   and not necessarily those of the National Health Service, the NIHR, or
   the Department of Health.
CR Aniwan S, 2023, GASTROINTEST ENDOSC, V97, P507, DOI 10.1016/j.gie.2022.09.023
   [Anonymous], 2007, PRACTICAL ASSESSMENT, DOI [10.7275/pdz9-th90, DOI 10.7275/PDZ9-TH90]
   Areia M, 2022, LANCET DIGIT HEALTH, V4, pE436, DOI 10.1016/S2589-7500(22)00042-5
   BARDECKI MJ, 1984, TECHNOL FORECAST SOC, V25, P281, DOI 10.1016/0040-1625(84)90006-4
   Barua I., 2022, NEJM EVID, V1
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   East JE, 2007, AM J GASTROENTEROL, V102, P2529, DOI 10.1111/j.1572-0241.2007.01429.x
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hasson F, 2000, J ADV NURS, V32, P1008, DOI 10.1046/j.1365-2648.2000.01567.x
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Houwen BBSL, 2022, ENDOSCOPY, V54, P88, DOI 10.1055/a-1689-5130
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Lehman CD, 2015, JAMA INTERN MED, V175, P1828, DOI 10.1001/jamainternmed.2015.5231
   Mori Y, 2022, LANCET GASTROENTEROL, V7, P785, DOI 10.1016/S2468-1253(22)00232-1
   Mori Y, 2022, GASTROINTEST ENDOSC, V95, pAB241, DOI 10.1016/j.cgh.2022.08.022
   Mori Y, 2021, J GASTROEN HEPATOL, V36, P7, DOI 10.1111/jgh.15339
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Okoli C, 2004, INFORM MANAGE-AMSTER, V42, P15, DOI 10.1016/j.im.2003.11.002
   Parikh RB, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00609-6
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rondonotti E, 2023, ENDOSCOPY, V55, P14, DOI 10.1055/a-1852-0330
   Tokunaga M, 2021, GASTROINTEST ENDOSC, V93, P647, DOI 10.1016/j.gie.2020.07.053
   Voets MM, 2022, VALUE HEALTH, V25, P340, DOI 10.1016/j.jval.2021.11.1362
   Wadhwa V, 2020, ENDOSC INT OPEN, V08, pE1379, DOI 10.1055/a-1223-1926
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 32
TC 3
Z9 3
U1 8
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD 2023 MAR 13
PY 2023
DI 10.1111/den.14531
EA MAR 2023
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 9V6GT
UT WOS:000948489600001
PM 36749036
OA Bronze
DA 2023-08-21
ER

PT J
AU Yin, ZG
   Yao, CH
   Zhang, LM
   Qi, SH
AF Yin, Zugang
   Yao, Chenhui
   Zhang, Limin
   Qi, Shaohua
TI Application of artificial intelligence in diagnosis and treatment of
   colorectal cancer: A novel Prospect
SO FRONTIERS IN MEDICINE
LA English
DT Review
DE artificial intelligence; colorectal cancer; machine learning; deep
   learning; bioinformatics analysis; screening; diagnosis; therapy
ID COMPUTER-AIDED DETECTION; CT COLONOGRAPHY; NEURAL-NETWORK; COLONOSCOPY;
   TECHNOLOGY; STATISTICS; PREDICTION; PROGNOSIS; SURGERY; LIGHT
AB In the past few decades, according to the rapid development of information technology, artificial intelligence (AI) has also made significant progress in the medical field. Colorectal cancer (CRC) is the third most diagnosed cancer worldwide, and its incidence and mortality rates are increasing yearly, especially in developing countries. This article reviews the latest progress in AI in diagnosing and treating CRC based on a systematic collection of previous literature. Most CRCs transform from polyp mutations. The computer-aided detection systems can significantly improve the polyp and adenoma detection rate by early colonoscopy screening, thereby lowering the possibility of mutating into CRC. Machine learning and bioinformatics analysis can help screen and identify more CRC biomarkers to provide the basis for non-invasive screening. The Convolutional neural networks can assist in reading histopathologic tissue images, reducing the experience difference among doctors. Various studies have shown that AI-based high-level auxiliary diagnostic systems can significantly improve the readability of medical images and help clinicians make more accurate diagnostic and therapeutic decisions. Moreover, Robotic surgery systems such as da Vinci have been more and more commonly used to treat CRC patients, according to their precise operating performance. The application of AI in neoadjuvant chemoradiotherapy has further improved the treatment and efficacy evaluation of CRC. In addition, AI represented by deep learning in gene sequencing research offers a new treatment option. All of these things have seen that AI has a promising prospect in the era of precision medicine.
C1 [Yin, Zugang; Yao, Chenhui] Dalian Med Univ, Affiliated Hosp 1, Dept Gen Surg, Dalian, Peoples R China.
   [Zhang, Limin] Dalian Med Univ, Affiliated Hosp 1, Dept Resp, Dalian, Peoples R China.
   [Qi, Shaohua] Chinese Acad Med Sci, Inst Lab Anim Sci, Beijing, Peoples R China.
   [Qi, Shaohua] Peking Union Med Coll, Comparat Med Ctr, Beijing, Peoples R China.
C3 Dalian Medical University; Dalian Medical University; Chinese Academy of
   Medical Sciences - Peking Union Medical College; Institute of Laboratory
   Animal Science - CAMS; Chinese Academy of Medical Sciences - Peking
   Union Medical College; Peking Union Medical College
RP Yao, CH (通讯作者)，Dalian Med Univ, Affiliated Hosp 1, Dept Gen Surg, Dalian, Peoples R China.
EM gavinyaoch@126.com
FU First Affiliated Hospital of Dalian Medical University [20Z12020]
FX We would acknowledge the support of the First Affiliated Hospital of
   Dalian Medical University (grant no. 20Z12020).
CR Abdallah M, 2020, WASTE MANAGE, V109, P231, DOI 10.1016/j.wasman.2020.04.057
   Abduljabbar R, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11010189
   Acs B, 2020, J INTERN MED, V288, P62, DOI 10.1111/joim.13030
   [Anonymous], 2020, NAT CANCER, V1, P137, DOI 10.1038/s43018-020-0041-7
   Baek SJ, 2021, SURG ONCOL, V37, DOI 10.1016/j.suronc.2021.101559
   Beltramin D, 2022, STUD HLTH TECHNOL IN, V295, P249
   Bibault JE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30657-6
   Bresalier RS, 2022, GASTROENTEROL CLIN N, V51, P577, DOI 10.1016/j.gtc.2022.05.002
   Buccafusca G, 2019, CRIT REV ONCOL HEMAT, V136, P20, DOI 10.1016/j.critrevonc.2019.01.023
   Byeon SJ, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16885-x
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Ciardiello F, 2022, CA-CANCER J CLIN, V72, P372, DOI 10.3322/caac.21728
   D'Orazio M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-12364-5
   Dabass M, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105680
   Daye D, 2021, EUR RADIOL, V31, P5759, DOI 10.1007/s00330-020-07673-0
   Dekker E, 2019, LANCET, V394, P1467, DOI 10.1016/S0140-6736(19)32319-0
   Delli Pizzi A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84816-3
   Echle A, 2020, GASTROENTEROLOGY, V159, P1406, DOI 10.1053/j.gastro.2020.06.021
   Feng LL, 2022, LANCET DIGIT HEALTH, V4, pE8, DOI 10.1016/S2589-7500(21)00215-6
   Ferrando L, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0226595
   Ferrari A, 2021, CANCERS, V13, DOI 10.3390/cancers13081820
   Ferrari R, 2019, EUR J RADIOL, V118, P1, DOI 10.1016/j.ejrad.2019.06.013
   Flynn J, 2020, ANZ J SURG, V90, P1230, DOI 10.1111/ans.16067
   Ganesh K, 2019, NAT REV GASTRO HEPAT, V16, P361, DOI 10.1038/s41575-019-0126-x
   Gonai T, 2020, INTEST RES, V18, P107, DOI 10.5217/ir.2019.00061
   Grosek J, 2021, RADIOL ONCOL, V55, P433, DOI 10.2478/raon-2021-0026
   Grosu S, 2021, RADIOLOGY, V299, P326, DOI 10.1148/radiol.2021202363
   Haak HE, 2022, SURG ENDOSC, V36, P3592, DOI 10.1007/s00464-021-08685-7
   Hamabe A, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0269931
   Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011
   Hammad A, 2021, MATH BIOSCI ENG, V18, P8997, DOI 10.3934/mbe.2021443
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   He K, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00457-4
   Ho CW, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06264-x
   Horvat N, 2022, ABDOM RADIOL, V47, P2770, DOI 10.1007/s00261-022-03572-8
   Howard J, 2019, AM J IND MED, V62, P917, DOI 10.1002/ajim.23037
   Hu DJ, 2020, MOL MED REP, V22, P620, DOI 10.3892/mmr.2020.11171
   Huang CM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69345-9
   Huang X, 2020, INT J CLIN EXP PATHO, V13, P675
   Iavazzo C., 2014, ACTA MED-HIST ADRIAT, P247
   Igaki T, 2022, DIS COLON RECTUM, V65, pE329, DOI 10.1097/DCR.0000000000002393
   Iizuka O, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58467-9
   Iwatate M, 2018, DIGEST ENDOSC, V30, P642, DOI 10.1111/den.13065
   JB WEISS., 2019, LETT EDITOR, V110, P774, DOI [10.1038/ajg.2015.365, DOI 10.1038/AJG.2015.365]
   Jiang W, 2021, ANN SURG ONCOL, V28, P6408, DOI 10.1245/s10434-021-10218-4
   Jiao YP, 2021, COMPUT METH PROG BIO, V212, DOI 10.1016/j.cmpb.2021.106464
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kanth P, 2021, BMJ-BRIT MED J, V374, DOI 10.1136/bmj.n1855
   Kasahara K, 2022, INT J CLIN ONCOL, V27, P1570, DOI 10.1007/s10147-022-02209-6
   Kassani SH, 2022, INT J MED INFORM, V159, DOI 10.1016/j.ijmedinf.2021.104669
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Kaul V, 2020, GASTROINTEST ENDOSC, V92, P807, DOI 10.1016/j.gie.2020.06.040
   Kel A, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2687-7
   Kijima S, 2014, WORLD J GASTROENTERO, V20, P16964, DOI 10.3748/wjg.v20.i45.16964
   Kim H, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01905-z
   Kim K, 2021, KOREAN J RADIOL, V22, P912, DOI 10.3348/kjr.2020.0447
   Kim MJ, 2018, ANN SURG, V267, P243, DOI 10.1097/SLA.0000000000002321
   Kitaguchi D, 2020, INT J SURG, V79, P88, DOI 10.1016/j.ijsu.2020.05.015
   Kitaguchi D, 2020, SURG ENDOSC, V34, P4924, DOI 10.1007/s00464-019-07281-0
   Kleppe A, 2022, LANCET ONCOL, V23, P1221, DOI 10.1016/S1470-2045(22)00391-6
   Koh DM, 2020, RADIOLOGY, V296, P65, DOI 10.1148/radiol.2020200417
   Krause J, 2021, J PATHOL, V254, P70, DOI 10.1002/path.5638
   Kron T, 2019, AUSTRALAS PHYS ENG S, V42, P403, DOI 10.1007/s13246-019-00757-2
   Kuipers EJ, 2015, NAT REV DIS PRIMERS, V1, DOI 10.1038/nrdp.2015.65
   Li H, 2021, TECHNOL CANCER RES T, V20, DOI 10.1177/15330338211058352
   Li JW, 2021, J GASTROEN HEPATOL, V36, P3298, DOI 10.1111/jgh.15642
   Li JN, 2019, J DIGEST DIS, V20, P62, DOI 10.1111/1751-2980.12712
   Li PP, 2021, MAGN RESON MATER PHY, V34, P707, DOI 10.1007/s10334-021-00915-2
   Liang F, 2022, WORLD J GASTRO ONCOL, V14, P124, DOI 10.4251/wjgo.v14.i1.124
   Lichtblau D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209274
   Liu XY, 2021, EBIOMEDICINE, V69, DOI 10.1016/j.ebiom.2021.103442
   Liu XM, 2019, MED PHYS, V46, P3532, DOI 10.1002/mp.13584
   Liu ZQ, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-28421-6
   Lu YB, 2022, AM J GASTROENTEROL, V117, P1437, DOI 10.14309/ajg.0000000000001900
   Luo HB, 2022, J BIOPHOTONICS, V15, DOI 10.1002/jbio.202100349
   Luo R, 2021, TRIALS, V22, DOI 10.1186/s13063-021-05077-z
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Ma XL, 2019, BMC MED IMAGING, V19, DOI 10.1186/s12880-019-0392-7
   Machado MAC, 2021, J GASTROINTEST SURG, V25, P574, DOI 10.1007/s11605-020-04799-w
   Malycha J, 2022, CURR OPIN CRIT CARE, V28, P315, DOI 10.1097/MCC.0000000000000945
   Men K, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aada6c
   Mikeska T, 2014, GENES-BASEL, V5, P821, DOI 10.3390/genes5030821
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mitsala A, 2021, CURR ONCOL, V28, P1581, DOI 10.3390/curroncol28030149
   Muehlematter UJ, 2021, LANCET DIGIT HEALTH, V3, pE195, DOI 10.1016/S2589-7500(20)30292-2
   Muthukrishnan N, 2020, NEUROIMAG CLIN N AM, V30, P393, DOI 10.1016/j.nic.2020.07.004
   Ngu JCY, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1798
   Nussinov R, 2021, DRUG RESIST UPDATE, V59, DOI 10.1016/j.drup.2021.100796
   Nwaokorie A, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22189970
   Onyoh Elias F, 2019, Curr Gastroenterol Rep, V21, P36, DOI 10.1007/s11894-019-0703-8
   Pang YF, 2020, CONF TECHNOL APPL, P35, DOI 10.1109/TAAI51410.2020.00015
   Park JH, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01265-0
   Park SH, 2020, WORLD J GASTROENTERO, V26, DOI 10.3748/wjg.v26.i44.6945
   Patricio RPS, 2022, BIOORGAN MED CHEM, V53, DOI 10.1016/j.bmc.2021.116530
   Pinar I, 2018, ANN SURG ONCOL, V25, P3906, DOI 10.1245/s10434-018-6862-2
   Polat F, 2019, SURG ENDOSC, V33, P3644, DOI 10.1007/s00464-018-06653-2
   Qiu H, 2022, CURR ONCOL, V29, P1773, DOI 10.3390/curroncol29030146
   Quero G, 2022, CANCERS, V14, DOI 10.3390/cancers14153803
   Ramesh AN, 2004, ANN ROY COLL SURG, V86, P334, DOI 10.1308/147870804290
   Ranka S, 2021, CURR OPIN CARDIOL, V36, P26, DOI 10.1097/HCO.0000000000000812
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Ribero D, 2021, UPDATES SURG, V73, P1125, DOI 10.1007/s13304-021-01002-w
   Rocca A, 2022, J CLIN MED, V11, DOI 10.3390/jcm11010031
   Russo V, 2022, CANCERS, V14, DOI 10.3390/cancers14164012
   Sadek AW, 2007, EC113 TRANSP RES
   Sanchez-Ibarra HE, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235490
   Sasaki M, 2022, ASIAN J ENDOSC SURG, V15, P613, DOI 10.1111/ases.13064
   Shaish H, 2020, EUR RADIOL, V30, P6263, DOI 10.1007/s00330-020-06968-6
   Shao YJ, 2021, J MED SYST, V45, DOI 10.1007/s10916-020-01701-8
   Sharifi-Azad M, 2022, CANCER CELL INT, V22, DOI 10.1186/s12935-022-02605-y
   Sharma Abhilasha, 2022, Comput Biol Med, V146, P105688, DOI 10.1016/j.compbiomed.2022.105688
   Sheikh A, 2021, LANCET DIGIT HEALTH, V3, pE383, DOI 10.1016/S2589-7500(21)00005-4
   Sheng SH, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000011817
   Shi LM, 2019, MAGN RESON IMAGING, V61, P33, DOI 10.1016/j.mri.2019.05.003
   Shu ZY, 2019, ABDOM RADIOL, V44, P3775, DOI 10.1007/s00261-019-01971-y
   Song D, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2022.106634
   Starmans MPA, 2021, CLIN EXP METASTAS, V38, P483, DOI 10.1007/s10585-021-10119-6
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Su Y, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105409
   Sultan AS, 2020, J ORAL PATHOL MED, V49, P849, DOI 10.1111/jop.13042
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Tanos R, 2020, ADV SCI, V7, DOI 10.1002/advs.202000486
   Taunk P, 2019, INT J COLORECTAL DIS, V34, P2043, DOI 10.1007/s00384-019-03406-y
   Tepus M, 2020, GASTROINTEST TUMORS, V7, P62, DOI 10.1159/000507701
   Thanikachalam K, 2019, NUTRIENTS, V11, DOI 10.3390/nu11010164
   Thomas DS, 2015, BRIT J CANCER, V113, P268, DOI 10.1038/bjc.2015.202
   Trivizakis E, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94781-6
   Tsigelny IF, 2019, BRIEF BIOINFORM, V20, P1434, DOI 10.1093/bib/bby004
   Vaishya R, 2020, DIABETES METAB SYND, V14, P337, DOI 10.1016/j.dsx.2020.04.012
   Viscaino M, 2021, WORLD J GASTROENTERO, V27, P6399, DOI 10.3748/wjg.v27.i38.6399
   Wallace MB, 2022, GASTROENTEROLOGY, V163, P295, DOI 10.1053/j.gastro.2022.03.007
   Wan N, 2019, BMC CANCER, V19, DOI 10.1186/s12885-019-6003-8
   Wang DS, 2020, DIS COLON RECTUM, V63, P143, DOI 10.1097/DCR.0000000000001519
   Wang JY, 2018, MOL MED REP, V17, P5013, DOI 10.3892/mmr.2018.8532
   Wang KS, 2021, BMC MED, V19, DOI 10.1186/s12916-021-01942-5
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang RJ, 2022, J HEMATOL ONCOL, V15, DOI 10.1186/s13045-022-01225-3
   Wei JW, 2021, MED PHYS, V48, P513, DOI 10.1002/mp.14563
   Wong CT, 2023, J MAGN RESON IMAGING, V57, P45, DOI 10.1002/jmri.28381
   Xia CF, 2022, CHINESE MED J-PEKING, V135, P584, DOI 10.1097/CM9.0000000000002108
   Xu L, 2021, CANCER MED-US, V10, P7184, DOI 10.1002/cam4.4261
   Yao LW, 2022, ENDOSCOPY, V54, P757, DOI 10.1055/a-1706-6174
   Yates DR., 2011, BJU INT, P108, DOI [10.1111/j.1464-410X.2011.10576,10600.x, DOI 10.1111/J.1464-410X.2011.10576,10600.X]
   Yin Z, 2021, EMERG TOP LIFE SCI, DOI 10.1042/ETLS20210223
   Yu G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26643-8
   Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0
   Zeng YF, 2020, THERANOSTICS, V10, P2587, DOI 10.7150/thno.40099
   Zhang DH, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2022.3156851
   Zhang WW, 2019, ANAL CELL PATHOL, V2019, DOI 10.1155/2019/9740475
   Zhang XY, 2020, RADIOLOGY, V296, P56, DOI 10.1148/radiol.2020190936
   Zhang X, 2019, MOLECULES, V24, DOI 10.3390/molecules24122238
   Zhang YM, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000008242
   Zhou HR, 2020, MOL CARCINOGEN, V59, P425, DOI 10.1002/mc.23165
   Zhou PY, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18879-1
   Zhu HT, 2021, J APPL CLIN MED PHYS, V22, P324, DOI 10.1002/acm2.13381
NR 157
TC 5
Z9 5
U1 4
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-858X
J9 FRONT MED-LAUSANNE
JI Front. Med.
PD MAR 8
PY 2023
VL 10
AR 1128084
DI 10.3389/fmed.2023.1128084
PG 14
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 9Z2JV
UT WOS:000950973100001
PM 36968824
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Karaman, A
   Pacal, I
   Basturk, A
   Akay, B
   Nalbantoglu, U
   Coskun, S
   Sahin, O
   Karaboga, D
AF Karaman, Ahmet
   Pacal, Ishak
   Basturk, Alper
   Akay, Bahriye
   Nalbantoglu, Ufuk
   Coskun, Seymanur
   Sahin, Omur
   Karaboga, Dervis
TI Robust real-time polyp detection system design based on YOLO algorithms
   by optimizing activation functions and hyper-parameters with artificial
   bee colony (ABC)
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Colorectal cancer; Polyp detection; Hyper -parameter optimization;
   Artificial bee colony (ABC); Activation functions; YOLOv5
ID CANCER
AB Colorectal cancer (CRC) is one of the most common cancer types with a high mortality rate. Colonoscopy is considered the gold standard in CRC screening, it also provides immediate removal of polyps, which are the precursors of CRC, significantly reducing CRC mortality. Polyps can be overlooked due to many factors and can progress to a fatal stage. Increasing the detection rate of missed polyps can be a turning point for CRC. Therefore, many traditional computer-aided detection (CAD) systems have been proposed, but the desired efficiency could not be obtained due to real-time detection or the limited sensitivity and specificity of the systems. In this article, we present a deep learning-based approach unlike traditional systems. This approach is basically based on 5th version of you only look once (YOLOv5) object detection algorithm and artificial bee colony (ABC) optimization algorithm. While models belonging to the YOLOv5 algorithm are used for polyp detection, the ABC algorithm is used to improve the performance of the models. The ABC algorithm is positioned to find the optimal activation functions and hyper-parameters for the YOLOv5 algorithm. The proposed method was performed on the novel Showa University and Nagoya University polyp database (SUN) dataset and PICCOLO white-light and narrowband imaging colonoscopic dataset (PICCOLO). Experimental studies showed that the ABC algorithm successfully optimizes the YOLOv5 algorithm and offers much higher accuracy than the original YOLOv5 algorithm. The proposed method is far ahead of the existing methods in the literature in terms of speed and accuracy, with high performance in real-time polyp detection. This study is the first proposed method for optimization of activation functions and hyper-parameters for object detection algorithms.
C1 [Karaman, Ahmet; Coskun, Seymanur] Acibadem Hosp, Dept Gastroenterol, TR-38030 Kayseri, Turkiye.
   [Basturk, Alper; Akay, Bahriye; Nalbantoglu, Ufuk; Sahin, Omur; Karaboga, Dervis] Erciyes Univ, Engn Fac, Dept Comp Engn, TR-38030 Kayseri, Turkiye.
   [Pacal, Ishak] Igdir Univ, Engn Fac, Dept Comp Engn, TR-76000 Igdir, Turkiye.
   [Pacal, Ishak; Basturk, Alper; Akay, Bahriye; Nalbantoglu, Ufuk; Sahin, Omur; Karaboga, Dervis] Erciyes Univ, Artificial Intelligence & Big Data Applicat & Res, TR-38030 Kayseri, Turkiye.
C3 Acibadem Hastaneleri; Erciyes University; Igdir University; Erciyes
   University
RP Pacal, I (通讯作者)，Igdir Univ, Engn Fac, Dept Comp Engn, TR-76000 Igdir, Turkiye.
EM ahmet.karaman@acibadem.com; ishak.pacal@igdir.edu.tr; ab@erciyes.edu.tr;
   bahriye@erciyes.edu.tr; nalbantoglu@erciyes.edu.tr; omur@erciyes.edu.tr;
   karaboga@erciyes.edu.tr
RI Sahin, Omur/AAO-3107-2020
OI Sahin, Omur/0000-0003-1213-7445
FU Big Data Application and Research Center at Erciyes University in Turkey
   [2021-02/15]
FX Acknowledgements Computational experiments were performed using the
   resources at the Artificial Intelligence and Big Data Application and
   Research Center at Erciyes University in Turkey. Ethical clearance was
   obtained from Acibadem University in Turkey, with the permission number
   ATADEK-2021/02 and the decision number 2021-02/15.
CR A. F. Agarap, 2018, DEEP LEARNING USING
   Akay B, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107351
   Akay B, 2022, ARTIF INTELL REV, V55, P829, DOI 10.1007/s10462-021-09992-0
   Alici-Karaca D, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103463
   Baykara O., 2016, BALIKESIR HLTH SCI J, V5, P154, DOI [10.5505/bsbd.2016.93823, DOI 10.5505/BSBD.2016.93823]
   Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED, DOI DOI 10.48550/ARXIV.2004.10934
   Chou YC, 2023, MULTIMED TOOLS APPL, V82, P16817, DOI 10.1007/s11042-022-13995-6
   Clevert D.-A., 2016, P INT C LEARN REPR, P1
   Cuong-Le T, 2022, ENG COMPUT-GERMANY, V38, P3069, DOI 10.1007/s00366-021-01299-6
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Elfwing S, 2018, NEURAL NETWORKS, V107, P3, DOI 10.1016/j.neunet.2017.12.012
   ELKarazle K, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031225
   Erkan U, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03631-w
   Ferrari A, 2021, CANCERS, V13, DOI 10.3390/cancers13081820
   Ghambari S, 2018, APPL SOFT COMPUT, V62, P736, DOI 10.1016/j.asoc.2017.10.040
   Hendrycks D., 2016, GAUSSIAN ERROR LINEA, P1
   Jass JR, 2004, CLIN GASTROENTEROL H, V2, P1, DOI 10.1016/S1542-3565(03)00284-2
   Jocher Glenn, 2022, Zenodo
   Karaboga D., 2005, TR06 ERC U ENG FAC C
   Karaboga D, 2020, COGENT ENG, V7, DOI 10.1080/23311916.2020.1855741
   Karagoz MA, 2023, NEURAL COMPUT APPL, V35, P10605, DOI 10.1007/s00521-023-08252-2
   Karakecili A, 2022, APPL BIOCHEM BIOTECH, DOI [10.1007/s12010-022-03962-0, 10.1007/s10489-022-04299-1]
   Kaya E, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105311
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Klambauer G., 2017, PROC NEURIPS, P971
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JN, 2022, J ELECTR ENG TECHNOL, V17, P3057, DOI 10.1007/s42835-022-01191-3
   Li HL, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3397161
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mai H. T., 2022, ENG COMPUT-GERMANY, V1, P1, DOI [10.1007/S00366-022-01636-3/TABLES/11, DOI 10.1007/S00366-022-01636-3/TABLES/11]
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misra D., 2019, ARXIV PREPRINT
   Morgan E, 2022, GUT, DOI 10.1136/gutjnl-2022-327736
   Nogueira-Rodriguez A, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12040898
   Pacal I., 2022, J I SCI TECHNOL, DOI [10.21597/jist.1183679, DOI 10.21597/JIST.1183679]
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pacal I, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104003
   Park HC, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17843-3
   Qiu H, 2022, CURR ONCOL, V29, P1773, DOI 10.3390/curroncol29030146
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sanchez-Peralta L. F., 2020, APPL SCI SWITZERLAND, P10
   Sawicki T, 2021, CANCERS, V13, DOI 10.3390/cancers13092025
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI [DOI 10.3322/CAAC.21442, 10.3322/caac.21332]
   Souaidi M., 2022, MULTISCALE HYBRID NE, DOI [10.3390/diagnostics12082030, DOI 10.3390/DIAGNOSTICS12082030]
   Souaidi M, 2022, IEEE ACCESS, V10, P47124, DOI 10.1109/ACCESS.2022.3171238
   Wang C.-Y., 2021, YOU ONLY LEARN ONE R, P1
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Xi Y, 2021, TRANSL ONCOL, V14, DOI 10.1016/j.tranon.2021.101174
   Xu B, 2015, Arxiv, DOI arXiv:1505.00853
   Younas F, 2023, APPL INTELL, V53, P2410, DOI 10.1007/s10489-022-03689-9
   Zeng T, 2022, EXPERT SYST APPL, V192, DOI 10.1016/j.eswa.2021.116332
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zoph, 2018, ARXIV, P1, DOI DOI 10.48550/ARXIV.1710.05941
NR 56
TC 5
Z9 5
U1 4
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JUL 1
PY 2023
VL 221
AR 119741
DI 10.1016/j.eswa.2023.119741
EA MAR 2023
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA G7NP8
UT WOS:000990985200001
DA 2023-08-21
ER

PT J
AU Lafraxo, S
   Souaidi, M
   El Ansari, M
   Koutti, L
AF Lafraxo, Samira
   Souaidi, Meryem
   El Ansari, Mohamed
   Koutti, Lahcen
TI Semantic Segmentation of Digestive Abnormalities from WCE Images by
   Using AttResU-Net Architecture
SO LIFE-BASEL
LA English
DT Article
DE gastrointestinal tract; segmentation; deep learning; U-Net; WCE;
   colonoscopy; attention mechanism; residual block
ID BLEEDING DETECTION; SYSTEM
AB Colorectal cancer is one of the most common malignancies and the leading cause of cancer death worldwide. Wireless capsule endoscopy is currently the most frequent method for detecting precancerous digestive diseases. Thus, precise and early polyps segmentation has significant clinical value in reducing the probability of cancer development. However, the manual examination is a time-consuming and tedious task for doctors. Therefore, scientists have proposed many computational techniques to automatically segment the anomalies from endoscopic images. In this paper, we present an end-to-end 2D attention residual U-Net architecture (AttResU-Net), which concurrently integrates the attention mechanism and residual units into U-Net for further polyp and bleeding segmentation performance enhancement. To reduce outside areas in an input image while emphasizing salient features, AttResU-Net inserts a sequence of attention units among related downsampling and upsampling steps. On the other hand, the residual block propagates information across layers, allowing for the construction of a deeper neural network capable of solving the vanishing gradient issue in each encoder. This improves the channel interdependencies while lowering the computational cost. Multiple publicly available datasets were employed in this work, to evaluate and verify the proposed method. Our highest-performing model was AttResU-Net, on the MICCAI 2017 WCE dataset, which achieved an accuracy of 99.16%, a Dice coefficient of 94.91%, and a Jaccard index of 90.32%. The experiment findings show that the proposed AttResU-Net overcomes its baselines and provides performance comparable to existing polyp segmentation approaches.
C1 [Lafraxo, Samira; Souaidi, Meryem; El Ansari, Mohamed; Koutti, Lahcen] Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, Agadir 80000, Morocco.
   [El Ansari, Mohamed] Moulay Ismail Univ, Fac Sci, Dept Comp Sci, Informat & Applicat Lab, Meknes 52000, Morocco.
C3 Ibn Zohr University of Agadir; Moulay Ismail University of Meknes
RP Lafraxo, S (通讯作者)，Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, Agadir 80000, Morocco.
EM samira.lafraxo@edu.uiz.ac.ma
RI LAFRAXO, Samira/GXH-8925-2022; El Ansari, Mohamed/L-9738-2016
OI LAFRAXO, Samira/0000-0002-8876-3357; El Ansari,
   Mohamed/0000-0001-5394-9066
FU Ministry of National Education, Vocational Training, Higher Education
   and Scientific Research; Ministry of Industry, Trade and Green and
   Digital Economy, the Digital Development Agency (ADD); National Center
   for Scientific and Technical Research (CNRST) [ALKHAWARIZMI/2020/20]
FX This work was partially supported by the Ministry of National Education,
   Vocational Training, Higher Education and Scientific Research, the
   Ministry of Industry, Trade and Green and Digital Economy, the Digital
   Development Agency (ADD), and the National Center for Scientific and
   Technical Research (CNRST). Project number: ALKHAWARIZMI/2020/20.
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Coelho P, 2018, LECT NOTES COMPUT SC, V10882, P553, DOI 10.1007/978-3-319-93000-8_63
   Feng RW, 2020, I S BIOMED IMAGING, P225, DOI 10.1109/ISBI45749.2020.9098492
   Figueiredo IN, 2013, COMP M BIO BIO E-IV, V1, P198, DOI 10.1080/21681163.2013.796164
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Garbaz A, 2022, 2022 IEEE C COMPUTAT, P1
   Ghosh T, 2018, IEEE IMAGE PROC, P3034, DOI 10.1109/ICIP.2018.8451300
   Gross S., 2009, BILDVERARBEITUNG F R, P252
   Hajabdollahi M, 2018, Arxiv, DOI arXiv:1802.07788
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong TC, 2020, J FORMOS MED ASSOC, V119, P1750, DOI 10.1016/j.jfma.2020.08.027
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jin QG, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.605132
   Lafraxo S, 2020, 2020 8TH INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND MOBILE COMMUNICATIONS (WINCOM 2020), P130, DOI 10.1109/wincom50532.2020.9272456
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Liu M, 2022, IEEE J BIOMED HEALTH, V26, P5025, DOI 10.1109/JBHI.2022.3187765
   Liu YC, 2019, IEEE IMAGE PROC, P3322, DOI 10.1109/ICIP.2019.8803471
   Long J., 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298965
   Mahmood S, 2022, BIOMEDICINES, V10, DOI 10.3390/biomedicines10092195
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Oukdach Yassine, 2022, 2022 9th International Conference on Wireless Networks and Mobile Communications (WINCOM), P1, DOI 10.1109/WINCOM55661.2022.9966474
   Ozyoruk KB, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102058
   Poorneshwaran JM, 2019, IEEE ENG MED BIO, P7201, DOI 10.1109/EMBC.2019.8857958
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Ramamurthy K, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102316
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Souaidi M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12082030
   Souaidi M, 2019, IET IMAGE PROCESS, V13, P2233, DOI 10.1049/iet-ipr.2019.0415
   Sriker D, 2021, PROC SPIE, V11597, DOI 10.1117/12.2582130
   Stewart BJ, 2020, NAT REV NEPHROL, V16, P112, DOI 10.1038/s41581-019-0227-3
   Vaswani A, 2017, ADV NEUR IN, V30
   Wu HS, 2021, AAAI CONF ARTIF INTE, V35, P2916
   Xie LS, 2022, IEEE J BIOMED HEALTH, V26, P5013, DOI 10.1109/JBHI.2022.3192277
   Yu ZC, 2022, IEEE J BIOMED HEALTH, V26, P4987, DOI 10.1109/JBHI.2022.3191754
   Zhu ML, 2021, IEEE T MED IMAGING, V40, P3315, DOI 10.1109/TMI.2021.3083586
NR 46
TC 1
Z9 1
U1 3
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-1729
J9 LIFE-BASEL
JI Life-Basel
PD MAR
PY 2023
VL 13
IS 3
AR 719
DI 10.3390/life13030719
PG 18
WC Biology; Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Microbiology
GA C0UH5
UT WOS:000959169000001
PM 36983874
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Ma, HC
   Xu, C
   Nie, C
   Han, JB
   Li, YJ
   Liu, CX
AF Ma, Haichao
   Xu, Chao
   Nie, Chao
   Han, Jubao
   Li, Yingjie
   Liu, Chuanxu
TI DBE-Net: Dual Boundary-Guided Attention Exploration Network for Polyp
   Segmentation
SO DIAGNOSTICS
LA English
DT Article
DE polyp segmentation; colorectal cancer; boundary exploration; medical
   image analysis; deep learning; colonoscopy
ID IMAGES
AB Automatic segmentation of polyps during colonoscopy can help doctors accurately find the polyp area and remove abnormal tissues in time to reduce the possibility of polyps transforming into cancer. However, the current polyp segmentation research still has the following problems: blurry polyp boundaries, multi-scale adaptability of polyps, and close resemblances between polyps and nearby normal tissues. To tackle these issues, this paper proposes a dual boundary-guided attention exploration network (DBE-Net) for polyp segmentation. Firstly, we propose a dual boundary-guided attention exploration module to solve the boundary-blurring problem. This module uses a coarse-to-fine strategy to progressively approximate the real polyp boundary. Secondly, a multi-scale context aggregation enhancement module is introduced to accommodate the multi-scale variation of polyps. Finally, we propose a low-level detail enhancement module, which can extract more low-level details and promote the performance of the overall network. Extensive experiments on five polyp segmentation benchmark datasets show that our method achieves superior performance and stronger generalization ability than state-of-the-art methods. Especially for CVC-ColonDB and ETIS, two challenging datasets among the five datasets, our method achieves excellent results of 82.4% and 80.6% in terms of mDice (mean dice similarity coefficient) and improves by 5.1% and 5.9% compared to the state-of-the-art methods.
C1 [Ma, Haichao; Xu, Chao; Nie, Chao; Han, Jubao; Li, Yingjie; Liu, Chuanxu] Anhui Univ, Sch Integrated Circuits, Hefei 230601, Peoples R China.
   [Ma, Haichao; Xu, Chao; Nie, Chao; Han, Jubao; Li, Yingjie; Liu, Chuanxu] Anhui Engn Lab Agroecol Big Data, Hefei 230601, Peoples R China.
C3 Anhui University
RP Xu, C (通讯作者)，Anhui Univ, Sch Integrated Circuits, Hefei 230601, Peoples R China.; Xu, C (通讯作者)，Anhui Engn Lab Agroecol Big Data, Hefei 230601, Peoples R China.
EM xchao@ahu.edu.cn
FU National Key Research and Development Program of China [2019YFC0117800]
FX This research was funded by the National Key Research and Development
   Program of China (No. 2019YFC0117800).
CR Alam S., 2020, ARXIV
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B., 2021, ARXIV
   Dosovitskiy A., 2020, PROC INT C LEARN REP
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Fiori M, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414600143
   Guo QQ, 2022, IEEE ACCESS, V10, P52971, DOI 10.1109/ACCESS.2022.3175858
   Guo Xiaoqing, 2022, Med Image Anal, V78, P102394, DOI 10.1016/j.media.2022.102394
   Guo XQ, 2021, IEEE T MED IMAGING, V40, P1134, DOI 10.1109/TMI.2020.3046843
   Iwahori Y., 2013, AUTOMATIC POLYP DETE, P21
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Lai HL, 2023, VISUAL COMPUT, V39, P1453, DOI 10.1007/s00371-022-02422-4
   Li S., 2021, ARXIV
   Lin H., 2006, IEEE, V10, P9988
   Lou A., 2021, ARXIV
   Lou A, 2021, IEEE IMAGE PROC, P1894, DOI 10.1109/ICIP42928.2021.9506485
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Nguyen NQ, 2019, IEEE ACCESS, V7, P33795, DOI 10.1109/ACCESS.2019.2904094
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Ta N, 2022, MULTIMEDIA SYST, DOI 10.1007/s00530-022-00900-2
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Vaswani A., 2017, PROC 31 INT C NEURAL, V30, DOI DOI 10.5555/3295222.3295349
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang J., 2022, ARXIV
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wu H., 2022, NEW ENGL J MED, P1, DOI [10.1109/TCYB.2022.3162873, DOI 10.1109/TCYB.2022.3162873]
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 40
TC 0
Z9 0
U1 15
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD MAR
PY 2023
VL 13
IS 5
AR 896
DI 10.3390/diagnostics13050896
PG 19
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 9T3DL
UT WOS:000946910600001
PM 36900040
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Nogueira-Rodriguez, A
   Glez-Pena, D
   Reboiro-Jato, M
   Lopez-Fernandez, H
AF Nogueira-Rodriguez, Alba
   Glez-Pena, Daniel
   Reboiro-Jato, Miguel
   Lopez-Fernandez, Hugo
TI Negative Samples for Improving Object Detection-A Case Study in
   AI-Assisted Colonoscopy for Polyp Detection
SO DIAGNOSTICS
LA English
DT Article
DE colorectal cancer; deep learning; convolutional neural network (CNN);
   polyp detection; polyp localization
ID COMPUTER-AIDED DETECTION; SYSTEM
AB Deep learning object-detection models are being successfully applied to develop computer-aided diagnosis systems for aiding polyp detection during colonoscopies. Here, we evidence the need to include negative samples for both (i) reducing false positives during the polyp-finding phase, by including images with artifacts that may confuse the detection models (e.g., medical instruments, water jets, feces, blood, excessive proximity of the camera to the colon wall, blurred images, etc.) that are usually not included in model development datasets, and (ii) correctly estimating a more realistic performance of the models. By retraining our previously developed YOLOv3-based detection model with a dataset that includes 15% of additional not-polyp images with a variety of artifacts, we were able to generally improve its F1 performance in our internal test datasets (from an average F1 of 0.869 to 0.893), which now include such type of images, as well as in four public datasets that include not-polyp images (from an average F1 of 0.695 to 0.722).
C1 [Nogueira-Rodriguez, Alba; Glez-Pena, Daniel; Reboiro-Jato, Miguel; Lopez-Fernandez, Hugo] Univ Vigo, ESEI Escuela Super Ingn Informat, Dept Comp Sci, CINBIO, Orense 32004, Spain.
   [Nogueira-Rodriguez, Alba; Glez-Pena, Daniel; Reboiro-Jato, Miguel; Lopez-Fernandez, Hugo] UVIGO, Galicia Hlth Res Inst IIS Galicia Sur, SING Res Grp, SERGAS, Vigo 36213, Spain.
C3 Universidade de Vigo; Universidade de Vigo
RP Nogueira-Rodriguez, A (通讯作者)，Univ Vigo, ESEI Escuela Super Ingn Informat, Dept Comp Sci, CINBIO, Orense 32004, Spain.; Nogueira-Rodriguez, A (通讯作者)，UVIGO, Galicia Hlth Res Inst IIS Galicia Sur, SING Res Grp, SERGAS, Vigo 36213, Spain.
EM alnogueira@uvigo.es
RI Reboiro-Jato, Miguel/G-1102-2011; Lopez-Fernandez, Hugo/H-7558-2017
OI Reboiro-Jato, Miguel/0000-0001-8749-2703; Lopez-Fernandez,
   Hugo/0000-0002-6476-7206; Nogueira Rodriguez, Alba/0000-0001-5991-7698
FU Ministerio de Ciencia y Competitividad and Ministerio de Ciencia e
   Innovacion, Gobierno de Espana under the scope of the PolyDeep and
   PolyDeepAdvance projects [DPI2017-87494-R, PDC2021-121644-I00];
   Conselleria de Educacion, Universidades e Formacion Profesional
   [ED431C2018/55-GRC, ED431C 2022/03-GRC]
FX This work was partially supported by: (i) Ministerio de Ciencia y
   Competitividad and Ministerio de Ciencia e Innovacion, Gobierno de
   Espana under the scope of the PolyDeep and PolyDeepAdvance projects
   (DPI2017-87494-R, PDC2021-121644-I00); (ii) by Conselleria de Educacion,
   Universidades e Formacion Profesional (Xunta de Galicia) under the scope
   of the strategic funding ED431C2018/55-GRC and ED431C 2022/03-GRC
   Competitive Reference Group.
CR Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], INT J COMPUT VISION, DOI DOI 10.1007/s11263-009-0275-4
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2018, P 32 CARS C, V13, pS166
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hann A, 2021, UNITED EUR GASTROENT, V9, P527, DOI 10.1002/ueg2.12108
   Houwen Britt B S L, 2023, Gastrointest Endosc, V97, P184, DOI 10.1016/j.gie.2022.08.043
   Li KD, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255809
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lopez-Fernandez H, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.593
   Ma YT, 2021, LECT NOTES COMPUT SC, V12905, P387, DOI 10.1007/978-3-030-87240-3_37
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Nogueira-Rodriguez A., 2020, P PRACTICAL APPL COM, P51
   Nogueira-Rodriguez A, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12040898
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Viscaino M, 2021, WORLD J GASTROENTERO, V27, P6399, DOI 10.3748/wjg.v27.i38.6399
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
NR 26
TC 0
Z9 0
U1 3
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD MAR
PY 2023
VL 13
IS 5
AR 966
DI 10.3390/diagnostics13050966
PG 15
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 9U8WG
UT WOS:000947985000001
PM 36900110
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Khan, TM
   Arsalan, M
   Razzak, I
   Meijering, E
AF Khan, Tariq M.
   Arsalan, Muhammad
   Razzak, Imran
   Meijering, Erik
TI Simple and robust depth-wise cascaded network for polyp segmentation
SO ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Polyp segmentation; Medical image segmentation; Convolutional neural
   networks; Colorectal; colon cancer
AB The segmentation of the polyp region in colonoscopy images is considered difficult due to size, texture, and color variation. To segment polyps successfully, models based on convolutional neural networks (CNN), transformers, and their combinations have been developed. However, these methods are limited in that they can only model the local appearance of polyps or lack multi-level feature representation for spatial dependency in the decoding process. In this paper, we propose a simple, efficient yet powerful polyp segmentation framework that unifies the network with a multiscale cascaded path. The proposed MMS-Net utilizes multiscale and multipath convolutional operations in conjunction with multiple deep feature aggregation. The overall dense empowered features are sufficient for pixel-by-pixel detection of the polyp region. Extensive experiments on two popular benchmark datasets for polyp segmentation (Kvasir and CVC-Clinic DB) and two datasets of other medical applications (DRIVE and MC) are presented. The results show that our MMS-Net performs comparably to or better than other state-of-the-art methods despite having two or even three orders of magnitude fewer trainable parameters.
C1 [Khan, Tariq M.; Razzak, Imran; Meijering, Erik] Kensington, UNSW, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.
   [Arsalan, Muhammad] Dongguk Univ, Div Elect & Elect Engn, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.
C3 University of New South Wales Sydney; Dongguk University
RP Khan, TM (通讯作者)，Kensington, UNSW, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.
EM tariq045@gmail.com
OI Khan, Tariq Mahmood/0000-0002-7477-1591; Razzak,
   Imran/0000-0002-3930-6600
CR Arsalan M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030871
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen J., 2021, ARXIV
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Guo S, 2021, Arxiv, DOI arXiv:2009.12053
   Guo S, 2019, INT J MED INFORM, V126, P105, DOI 10.1016/j.ijmedinf.2019.03.015
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C.-H., 2021, ARXIV
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Iqbal S, 2022, PHOTONICS-BASEL, V9, DOI 10.3390/photonics9120923
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji GP, 2021, LECT NOTES COMPUT SC, V12901, P142, DOI 10.1007/978-3-030-87193-2_14
   Kingma D., 2015, ARXIV
   Loshchilov I, 2016, ARXIV, DOI [DOI 10.48550/ARXIV.1608.03983, 10.48550/arXiv.1608.03983]
   Lou A., 2022, PROC SPIE
   Maninis Kevis-Kokitsi, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P140, DOI 10.1007/978-3-319-46723-8_17
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Muhammad A., 2019, J CLIN MED, V8
   Duc NT, 2022, IEEE ACCESS, V10, P80575, DOI 10.1109/ACCESS.2022.3195241
   Oliveira A, 2018, EXPERT SYST APPL, V112, P229, DOI 10.1016/j.eswa.2018.06.034
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santosh KC, 2018, IEEE T MED IMAGING, V37, P1168, DOI 10.1109/TMI.2017.2775636
   Souza JC, 2019, COMPUT METH PROG BIO, V177, P285, DOI 10.1016/j.cmpb.2019.06.005
   Tomar N.K., 2020, INT C PATTERN RECOGN
   Wu YC, 2019, LECT NOTES COMPUT SC, V11764, P264, DOI 10.1007/978-3-030-32239-7_30
   Wu YC, 2018, LECT NOTES COMPUT SC, V11071, P119, DOI 10.1007/978-3-030-00934-2_14
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 36
TC 1
Z9 1
U1 12
U2 12
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0952-1976
EI 1873-6769
J9 ENG APPL ARTIF INTEL
JI Eng. Appl. Artif. Intell.
PD MAY
PY 2023
VL 121
AR 106023
DI 10.1016/j.engappai.2023.106023
EA FEB 2023
PG 10
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Multidisciplinary; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Engineering
GA 9X1CL
UT WOS:000949511400001
DA 2023-08-21
ER

PT J
AU Wang, Z
   Yao, ZL
   Wang, SS
   Zhang, XH
AF Wang, Zheng
   Yao, Zhilin
   Wang, Shengsheng
   Zhang, Xiaohui
TI Deep learning coordinated with level set-based auxiliary refinement for
   polyps segmentation
SO SIGNAL IMAGE AND VIDEO PROCESSING
LA English
DT Article
DE Colorectal cancer; Polyps segmentation; Convolutional neural networks;
   Level set method
AB Colorectal cancer has become the third reason for new cancer cases and death nowadays. Therefore, the early examination and detection of colorectal polyps in colonoscopy images are of great significance, and polyps may be highly correlated to colorectal cancer. However, accurate automatic segmentation for polyps is still a challenge currently due to their multifarious shapes and sizes, low contrast with background. To handle this problem, a new method, deep learning coordinated with level set-based auxiliary refinement (DL-LSAR), is proposed in this paper, which utilizes the advantages of convolutional neural networks and level set method to achieve perfect segmentation. We first apply the convolutional neural networks to obtain a preliminary segmentation result in which the high-level semantic information can be effectively collected. The feature map produced from the former will be applied to initialize the level set method and parameter maps to make per pixel on the evolution contour have dynamic parameters. And this process will benefit the minimization of the associated energy function. Quantitative and qualitative comparison on five commonly used datasets with several state-of-the-art methods corroborate that the proposed DL-LSAR framework can acquire satisfactory segmentation results.
C1 [Wang, Zheng; Yao, Zhilin; Wang, Shengsheng] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
   [Wang, Zheng; Yao, Zhilin; Wang, Shengsheng] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Yao, Zhilin; Wang, Shengsheng] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Xiaohui] Beijing Res Inst Huawei Technol Co Ltd, Beijing 100095, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Wang, SS (通讯作者)，Jilin Univ, Coll Software, Changchun 130012, Peoples R China.; Wang, SS (通讯作者)，Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.; Wang, SS (通讯作者)，Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM wss@jlu.edu.cn
FU Innovation Capacity Construction Project of Jilin Province Development
   and Reform Commission [2021FGWCXNLJSSZ10, 2019C053-3]; National Key
   Research and Development Program of China [2020YFA0714103]; Fundamental
   Research Funds for the Central Universities; JLU
FX This work is supported by the Innovation Capacity Construction Project
   of Jilin Province Development and Reform Commission(2021FGWCXNLJSSZ10,
   2019C053-3), the National Key Research and Development Program of China
   (No. 2020YFA0714103), and the Fundamental Research Funds for the Central
   Universities, JLU.
CR Ahmed A.M A., 2020, MEDIAEVALW
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bertasius G, 2016, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2016.392
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen LC, 2016, PROC CVPR IEEE, P4545, DOI 10.1109/CVPR.2016.492
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Diagnostic Science, 2021, ENC DIS COL CANC
   Dong B., 2021, ARXIV
   Dosovitskiy A., 2020, PROC INT C LEARN REP
   Fan Deng-Ping, 2018, ARXIV
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Han YM, 2020, IET IMAGE PROCESS, V14, P183, DOI 10.1049/iet-ipr.2018.6622
   Hatamizadeh A, 2019, LECT NOTES COMPUT SC, V11861, P98, DOI 10.1007/978-3-030-32692-0_12
   Hoogi A, 2017, IEEE T MED IMAGING, V36, P781, DOI 10.1109/TMI.2016.2628084
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Kingma D., 2015, ARXIV
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy R, 2019, PATTERN RECOGN LETT, V123, P31, DOI 10.1016/j.patrec.2019.03.004
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Vaswani A, 2017, ADV NEUR IN, V30
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   wikipedia, COLORECTAL CANC
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P28525, DOI 10.1007/s11042-020-09311-9
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
NR 33
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1863-1703
EI 1863-1711
J9 SIGNAL IMAGE VIDEO P
JI Signal Image Video Process.
PD SEP
PY 2023
VL 17
IS 6
BP 2943
EP 2951
DI 10.1007/s11760-023-02515-0
EA FEB 2023
PG 9
WC Engineering, Electrical & Electronic; Imaging Science & Photographic
   Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Imaging Science & Photographic Technology
GA I9CI0
UT WOS:000988295600001
DA 2023-08-21
ER

PT J
AU Gimeno-Garcia, AZ
   Negrin, DH
   Hernandez, A
   Nicolas-Perez, D
   Rodriguez, E
   Montesdeoca, C
   Alarcon, O
   Romero, R
   Dorta, JLB
   Cedres, Y
   del Castillo, R
   Jimenez, A
   Felipe, V
   Morales, D
   Ortega, J
   Reygosa, C
   Quintero, E
   Hernandez-Guerra, M
AF Gimeno-Garcia, Antonio Z.
   Negrin, Domingo Hernandez
   Hernandez, Anjara
   Nicolas-Perez, David
   Rodriguez, Eduardo
   Montesdeoca, Carlota
   Alarcon, Onofre
   Romero, Rafael
   Dorta, Jose Luis Baute
   Cedres, Yaiza
   del Castillo, Rocio
   Jimenez, Alejandro
   Felipe, Vanessa
   Morales, Dalia
   Ortega, Juan
   Reygosa, Cristina
   Quintero, Enrique
   Hernandez-Guerra, Manuel
TI Usefulness of a novel computer-aided detection system for colorectal
   neoplasia: a randomized controlled trial
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID DETECTION-ASSISTED COLONOSCOPY; ADENOMA DETECTION;
   ARTIFICIAL-INTELLIGENCE; ENDOSCOPY; CLASSIFICATION; STATEMENT; SOCIETY
AB Background and Aims: Artificial intelligence-based computer-aid detection (CADe) devices have been recently tested in colonoscopies, increasing the adenoma detection rate (ADR), mainly in Asian populations. However, ev-idence for the benefit of these devices in the occidental population is still low. We tested a new CADe device, namely, ENDO-AID (OIP-1) (Olympus, Tokyo, Japan), in clinical practice. Methods: This randomized controlled trial included 370 consecutive patients who were randomized 1:1 to CADe (n = 185) versus standard exploration (n = 185) from November 2021 to January 2022. The primary endpoint was the ADR. Advanced adenoma was defined as >10 mm, harboring high-grade dysplasia, or with a villous pattern. Otherwise, the adenoma was nonadvanced. ADR was assessed in both groups stratified by endoscopist ADR and colon cleansing. Results: In the intention-to-treat analysis, the ADR was 55.1% (102/185) in the CADe group and 43.8% (81/185) in the control group (P = .029). Nonadvanced ADRs (54.8% vs 40.8%, P = .01) and flat ADRs (39.4 vs 24.8, P = .006), polyp detection rate (67.1% vs 51%; P = .004), and number of adenomas per colonoscopy were signifi- cantly higher in the CADe group than in the control group (median [25th-75th percentile], 1 [0-2] vs 0 [0-1.5], respectively; P Z .014). No significant differences were found in serrated ADR. After stratification by endoscopist and bowel cleansing, no statistically significant differences in ADR were found. Conclusions: Colonoscopy assisted by ENDO-AID (OIP-1) increases ADR and number of adenomas per colonoscopy, suggesting it may aid in the detection of colorectal neoplastic lesions, especially because of its detection of diminutive and flat adenomas. (Clinical trial registration number: NCT04945044.) (Gastrointest Endosc 2023;97:528-36.)
C1 [Gimeno-Garcia, Antonio Z.; Negrin, Domingo Hernandez; Hernandez, Anjara; Nicolas-Perez, David; Rodriguez, Eduardo; Montesdeoca, Carlota; Alarcon, Onofre; Romero, Rafael; Dorta, Jose Luis Baute; Cedres, Yaiza; del Castillo, Rocio; Felipe, Vanessa; Morales, Dalia; Ortega, Juan; Reygosa, Cristina; Quintero, Enrique; Hernandez-Guerra, Manuel] Univ La Laguna, Hosp Univ Canarias, Inst Univ Tecnol Biomed ITB, Serv Gastroenterol, Tenerife, Spain.
   [Gimeno-Garcia, Antonio Z.; Negrin, Domingo Hernandez; Hernandez, Anjara; Nicolas-Perez, David; Rodriguez, Eduardo; Montesdeoca, Carlota; Alarcon, Onofre; Romero, Rafael; Dorta, Jose Luis Baute; Cedres, Yaiza; del Castillo, Rocio; Felipe, Vanessa; Morales, Dalia; Ortega, Juan; Reygosa, Cristina; Quintero, Enrique; Hernandez-Guerra, Manuel] Univ La Laguna, Ctr Invest Biomed Canarias CIBICAN, Dept Med Interna, Tenerife, Spain.
   [Jimenez, Alejandro] Hosp Univ Canarias, Unidad Invest, Tenerife, Spain.
C3 Universidad de la Laguna; Universidad de la Laguna; Universidad de la
   Laguna
RP Gimeno-Garcia, AZ (通讯作者)，Hosp Univ Canarias, Unidad Endoscopia 10a Planta, Ofra Sn 38320, San Cristobal la Laguna, Spain.
OI Hdez Perez, M. Anjara/0000-0003-2548-6767
CR Anderson R, 2020, GASTROENTEROLOGY, V158, P1287, DOI 10.1053/j.gastro.2019.12.031
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Berzin TM, 2020, GASTROINTEST ENDOSC, V92, P951, DOI 10.1016/j.gie.2020.06.035
   Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deliwala SS, 2021, INT J COLORECTAL DIS, V36, P2291, DOI 10.1007/s00384-021-03929-3
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, DIGEST ENDOSC, V33, P285, DOI 10.1111/den.13807
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hsieh YH, 2018, TZU CHI MED J, V30, P127, DOI 10.4103/tcmj.tcmj_86_18
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Mori Y, 2021, J GASTROEN HEPATOL, V36, P7, DOI 10.1111/jgh.15339
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Robertson DJ, 2017, GASTROINTEST ENDOSC, V85, P2, DOI 10.1016/j.gie.2016.09.025
   Rondonotti E, 2022, ENDOSCOPY, DOI 10.1055/a-1849-6878
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Spadaccini M, 2021, LANCET GASTROENTEROL, V6, P793, DOI 10.1016/S2468-1253(21)00215-6
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Vleugels JLA, 2017, GASTROINTEST ENDOSC, V85, P1169, DOI 10.1016/j.gie.2016.12.014
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Yamada M, 2021, BEST PRACT RES CL GA, V52-53, DOI 10.1016/j.bpg.2021.101745
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 33
TC 2
Z9 2
U1 0
U2 1
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD MAR
PY 2023
VL 97
IS 3
BP 528
EP +
DI 10.1016/j.gie.2022.09.029
EA FEB 2023
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 9S8ZB
UT WOS:000946623700001
PM 36228695
DA 2023-08-21
ER

PT J
AU Lui, KLT
   Liu, SHK
   Leung, K
   Wu, JT
   Zauber, AG
   Leung, WK
AF Lui, Ka Luen Thomas
   Liu, Sze Hang Kevin
   Leung, Kathy
   Wu, Joseph T.
   Zauber, Ann G.
   Leung, Wai Keung
TI The Impacts of Computer-Aided Detection of Colorectal Polyps on
   Subsequent Colonoscopy Surveillance Intervals: Simulation Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Article
DE artificial intelligence; surveillance colonoscopy; colonic polyp; polyp;
   colonoscopy; computer-aided; detect; adenoma; endoscopic; endoscopy;
   simulation; simulated; surveillance
ID INTELLIGENCE-ASSISTED COLONOSCOPY; ARTIFICIAL-INTELLIGENCE; TIME;
   CANCERS
AB Background: Computer-aided detection (CADe) of colorectal polyps has been shown to increase adenoma detection rates, which would potentially shorten subsequent surveillance intervals.
   Objective: The purpose of this study is to simulate the potential changes in subsequent colonoscopy surveillance intervals after the application of CADe in a large cohort of patients.
   Methods: We simulated the projected increase in polyp and adenoma detection by universal CADe application in our patients who had undergone colonoscopy with complete endoscopic and histological findings between 2016 and 2020. The simulation was based on bootstrapping the published performance of CADe. The corresponding changes in surveillance intervals for each patient, as recommended by the US Multi-Society Task Force on Colorectal Cancer (USMSTF) or the European Society of Gastrointestinal Endoscopy (ESGE), were determined after the CADe was determined.
   Results: A total of 3735 patients who had undergone colonoscopy were included. Based on the simulated CADe effect, the application of CADe would result in 19.1% (n=714) and 1.9% (n=71) of patients having shorter surveillance intervals, according to the USMSTF and ESGE guidelines, respectively. In particular, all (or 2.7% (n=101) of the total) patients who were originally scheduled to have 3-5 years of surveillance would have their surveillance intervals shortened to 3 years, following the USMSTF guidelines. The changes in this group of patients were largely attributed to an increase in the number of adenomas (n=75, 74%) rather than serrated lesions being detected.
   Conclusions: Widespread adoption of CADe would inevitably increase the demand for surveillance colonoscopies with the shortening of original surveillance intervals, particularly following the current USMSTF guideline.
C1 [Lui, Ka Luen Thomas; Liu, Sze Hang Kevin; Leung, Wai Keung] Univ Hong Kong, Li Ka Shing Fac Med, Sch Clin Med, Dept Med, 102 Pokfulam Rd, Hong Kong, Peoples R China.
   [Leung, Kathy; Wu, Joseph T.] Univ Hong Kong, Li Ka Shing Fac Med, WHO Collaborating Ctr Infect Dis Epidemiol & Contr, Sch Publ Hlth, Hong Kong, Peoples R China.
   [Zauber, Ann G.] Mem Sloan Kettering Canc Ctr, Dept Epidemiol & Biostat, New York, NY USA.
C3 University of Hong Kong; University of Hong Kong; Memorial Sloan
   Kettering Cancer Center
RP Leung, WK (通讯作者)，Univ Hong Kong, Li Ka Shing Fac Med, Sch Clin Med, Dept Med, 102 Pokfulam Rd, Hong Kong, Peoples R China.
EM waikleung@hku.hk
RI Leung, Kathy/D-5605-2017; Leung, Wai Keung/B-8140-2011; Wu, Joseph Tsz
   Kei/C-4450-2009
OI Leung, Kathy/0000-0003-4777-388X; Zauber, Ann
   Graham/0000-0002-1764-5994; Leung, Wai Keung/0000-0002-5993-1059; Wu,
   Joseph Tsz Kei/0000-0002-3155-5987
CR Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Ahuja A, 2022, GASTROENTEROLOGY, V163, P582, DOI 10.1053/j.gastro.2022.06.074
   Antonelli G, 2020, WORLD J GASTROENTERO, V26, P7436, DOI 10.3748/wjg.v26.i47.7436
   Areia M, 2022, LANCET DIGIT HEALTH, V4, pE436, DOI 10.1016/S2589-7500(22)00042-5
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bilal M, 2020, AM J GASTROENTEROL, V115, P963, DOI 10.14309/ajg.0000000000000646
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Burgess NG, 2021, ENDOSCOPY, V53, P902, DOI 10.1055/a-1384-0485
   Cao Y, 2007, IEEE T BIO-MED ENG, V54, P1268, DOI 10.1109/TBME.2007.890734
   Cheung KS, 2019, J GASTROEN HEPATOL, V34, P1545, DOI 10.1111/jgh.14674
   Deliwala SS, 2021, INT J COLORECTAL DIS, V36, P2291, DOI 10.1007/s00384-021-03929-3
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gupta S, 2020, GASTROINTEST ENDOSC, V91, P463, DOI 10.1016/j.gie.2020.01.014
   Hann A, 2021, UNITED EUR GASTROENT, V9, P527, DOI 10.1002/ueg2.12108
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Huang D, 2022, INT J COLORECTAL DIS, V37, P495, DOI 10.1007/s00384-021-04062-x
   Imperiale TF, 2011, INT J MED INFORM, V80, P726, DOI 10.1016/j.ijmedinf.2011.07.001
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Kamitani Y, 2022, J CLIN MED, V11, DOI 10.3390/jcm11102923
   Kudo SE, 2021, TRANSL GASTROENT HEP, V6, DOI 10.21037/tgh.2019.12.14
   Larsen Solveig Linnea Veen, 2022, DEN open, V2, pe109, DOI 10.1002/deo2.109
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lee J, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000007468
   Li JW, 2022, SINGAP MED J, V63, P118, DOI 10.11622/smedj.2022044
   Limdi JK, 2022, GASTROINTEST ENDOSC, V95, P757, DOI 10.1016/j.gie.2021.12.048
   Lui TKL, 2021, GASTROINTEST ENDOSC, V93, P193, DOI 10.1016/j.gie.2020.04.066
   Lui TKL, 2020, WORLD J GASTROENTERO, V26, P5248, DOI 10.3748/wjg.v26.i35.5248
   McGill SK, 2021, ENDOSCOPY, V53, P1284, DOI 10.1055/a-1346-7455
   Misawa M, 2022, ENDOSCOPY, DOI 10.1055/a-1890-5043
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2019, ENDOSCOPY, V51, P219, DOI 10.1055/a-0754-5556
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2018, DIGEST ENDOSC, V30, P52, DOI 10.1111/den.13005
   Murakami D, 2021, LANCET GASTROENTEROL, V6, P984, DOI 10.1016/S2468-1253(21)00379-4
   Pan H, 2022, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.775604
   Rath T, 2022, ENDOSCOPY, V54, P473, DOI 10.1055/a-1669-8814
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2021, ENDOSCOPY, V53, P285, DOI 10.1055/a-1367-1979
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2022, GASTROENTEROLOGY, V163, P35, DOI 10.1053/j.gastro.2022.04.042
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sanduleanu S, 2015, GUT, V64, P1257, DOI 10.1136/gutjnl-2014-307992
   Seager A, 2022, COLORECTAL DIS, V24, P1227, DOI 10.1111/codi.16219
   Shung Dennis L, 2020, Gastrointest Endosc Clin N Am, V30, P585, DOI 10.1016/j.giec.2020.02.010
   Soffer S, 2021, LANCET GASTROENTEROL, V6, P984, DOI 10.1016/S2468-1253(21)00349-6
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Taghiakbari M, 2021, WORLD J GASTROENTERO, V27, P8103, DOI 10.3748/wjg.v27.i47.8103
   Tavanapong W, 2022, IEEE J BIOMED HEALTH, V26, P3950, DOI 10.1109/JBHI.2022.3160098
   Wallace MB, 2022, GASTROENTEROLOGY, V163, P295, DOI 10.1053/j.gastro.2022.03.007
   Wang AL, 2021, ANN TRANSL MED, V9, DOI 10.21037/atm-21-5081
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Xu H, 2023, CLIN GASTROENTEROL H, V21, DOI 10.1016/j.cgh.2022.07.006
   Yao LW, 2022, ENDOSCOPY, V54, P757, DOI 10.1055/a-1706-6174
   Zhang YC, 2021, J LAPAROENDOSC ADV S, V31, P1143, DOI 10.1089/lap.2020.0777
NR 58
TC 0
Z9 0
U1 0
U2 0
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD FEB 10
PY 2023
VL 25
AR e42665
DI 10.2196/42665
PG 12
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA J1QT3
UT WOS:001007429500005
PM 36763451
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Ahmad, OF
   Mazomenos, E
   Chadebecq, F
   Kader, R
   Hussein, M
   Haidry, RJ
   Puyal, JGB
   Brandao, P
   Toth, D
   Mountney, P
   Seward, E
   Vega, R
   Stoyanov, D
   Lovat, LB
AF Ahmad, Omer F.
   Mazomenos, Evangelos
   Chadebecq, Francois
   Kader, Rawen
   Hussein, Mohamed
   Haidry, Rehan J.
   Puyal, Juana Gonzalez-Bueno
   Brandao, Patrick
   Toth, Daniel
   Mountney, Peter
   Seward, Ed
   Vega, Roser
   Stoyanov, Danail
   Lovat, Laurence B.
TI Identifying key mechanisms leading to visual recognition errors for
   missed colorectal polyps using eye-tracking technology
SO JOURNAL OF GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article; Early Access
DE artificial intelligence; colonic polyps; colonoscopy; colorectal cancer
ID GAZE PATTERNS; COLONOSCOPY; ENDOSCOPY
AB Background and AimLack of visual recognition of colorectal polyps may lead to interval cancers. The mechanisms contributing to perceptual variation, particularly for subtle and advanced colorectal neoplasia, have scarcely been investigated. We aimed to evaluate visual recognition errors and provide novel mechanistic insights. MethodsEleven participants (seven trainees and four medical students) evaluated images from the UCL polyp perception dataset, containing 25 polyps, using eye-tracking equipment. Gaze errors were defined as those where the lesion was not observed according to eye-tracking technology. Cognitive errors occurred when lesions were observed but not recognized as polyps by participants. A video study was also performed including 39 subtle polyps, where polyp recognition performance was compared with a convolutional neural network. ResultsCognitive errors occurred more frequently than gaze errors overall (65.6%), with a significantly higher proportion in trainees (P = 0.0264). In the video validation, the convolutional neural network detected significantly more polyps than trainees and medical students, with per-polyp sensitivities of 79.5%, 30.0%, and 15.4%, respectively. ConclusionsCognitive errors were the most common reason for visual recognition errors. The impact of interventions such as artificial intelligence, particularly on different types of perceptual errors, needs further investigation including potential effects on learning curves. To facilitate future research, a publicly accessible visual perception colonoscopy polyp database was created.
C1 [Ahmad, Omer F.; Mazomenos, Evangelos; Chadebecq, Francois; Kader, Rawen; Hussein, Mohamed; Puyal, Juana Gonzalez-Bueno; Brandao, Patrick; Stoyanov, Danail; Lovat, Laurence B.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, London, England.
   [Ahmad, Omer F.; Kader, Rawen; Hussein, Mohamed; Haidry, Rehan J.; Lovat, Laurence B.] UCL, Div Surg & Intervent Sci, London, England.
   [Ahmad, Omer F.; Haidry, Rehan J.; Seward, Ed; Vega, Roser; Lovat, Laurence B.] Univ Coll London Hosp, Gastrointestinal Serv, London, England.
   [Puyal, Juana Gonzalez-Bueno; Brandao, Patrick; Toth, Daniel; Mountney, Peter] Odin Vis Ltd, London, England.
   [Ahmad, Omer F.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, Charles Bell House,43-45 Foley St, London W1W 7TS, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London; University of London; University College London; University
   College London Hospitals NHS Foundation Trust; UK Research & Innovation
   (UKRI); Engineering & Physical Sciences Research Council (EPSRC);
   University of London; University College London
RP Ahmad, OF (通讯作者)，UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, Charles Bell House,43-45 Foley St, London W1W 7TS, England.
EM ofahmad123@gmail.com
RI Lovat, Laurence/C-1986-2009; Kader, Rawen/ABI-2203-2020
OI Lovat, Laurence/0000-0003-4542-3915; Kader, Rawen/0000-0001-9133-0838
CR Ahmad OF., 2021, ENDOSCOPY, V53, P277
   Ahmad OF, 2022, DIGEST ENDOSC, V34, P862, DOI 10.1111/den.14187
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Almansa C, 2011, AM J GASTROENTEROL, V106, P1070, DOI 10.1038/ajg.2011.26
   Anderson R, 2020, GASTROENTEROLOGY, V158, P1287, DOI 10.1053/j.gastro.2019.12.031
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Coe SG, 2013, AM J GASTROENTEROL, V108, P219, DOI 10.1038/ajg.2012.417
   Dik VK, 2016, EUR J GASTROEN HEPAT, V28, P1400, DOI 10.1097/MEG.0000000000000717
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kumahara K, 2019, DIGEST ENDOSC, V31, P552, DOI 10.1111/den.13397
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   McGill SK, 2015, GUT, V64, P184, DOI 10.1136/gutjnl-2013-305743
   Meining A, 2010, ENDOSCOPY, V42, P652, DOI 10.1055/s-0029-1244233
   Rutter MD, 2020, GUT, V69, P201, DOI 10.1136/gutjnl-2019-319858
   Troya J, 2022, ENDOSCOPY, V54, P1009, DOI 10.1055/a-1770-7353
NR 16
TC 0
Z9 0
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0815-9319
EI 1440-1746
J9 J GASTROEN HEPATOL
JI J. Gastroenterol. Hepatol.
PD 2023 FEB 1
PY 2023
DI 10.1111/jgh.16127
EA FEB 2023
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 8G0EH
UT WOS:000920025000001
PM 36652526
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Aslam, MF
   Bano, S
   Khalid, M
   Sarfraz, Z
   Sarfraz, A
   Sarfraz, M
   Robles-Velasco, K
   Felix, M
   Deane, K
   Cherrez-Ojeda, I
AF Aslam, Muhammad Fawad
   Bano, Shehar
   Khalid, Mariam
   Sarfraz, Zouina
   Sarfraz, Azza
   Sarfraz, Muzna
   Robles-Velasco, Karla
   Felix, Miguel
   Deane, Kitson
   Cherrez-Ojeda, Ivan
TI The effectiveness of real-time computer-aided and quality control
   systems in colorectal adenoma and polyp detection during colonoscopies:
   a meta-analysis
SO ANNALS OF MEDICINE AND SURGERY
LA English
DT Review
DE adenoma; colorectal; meta-analysis; polyps; trials; withdrawal time
ID ARTIFICIAL-INTELLIGENCE; EFFICACY
AB Aims:This meta-analysis aims to quantify the effectiveness of artificial intelligence (AI)-supported colonoscopy compared to standard colonoscopy in adenoma detection rate (ADR) differences with the use of computer-aided detection and quality control systems. Moreover, the polyp detection rate (PDR) intergroup differences and withdrawal times will be analyzed. Methods:This study was conducted adhering to PRISMA guidelines. Studies were searched across PubMed, CINAHL, EMBASE, Scopus, Cochrane, and Web of Science. Keywords including the following 'Artificial Intelligence, Polyp, Adenoma, Detection, Rate, Colonoscopy, Colorectal, Colon, Rectal' were used. Odds ratio (OR) applying 95% CI for PDR and ADR were computed. SMD with 95% CI for withdrawal times were computed using RevMan 5.4.1 (Cochrane). The risk of bias was assessed using the RoB 2 tool. Results:Of 2562 studies identified, 11 trials were included comprising 6856 participants. Of these, 57.4% participants were in the AI group and 42.6% individuals were in in the standard group. ADR was higher in the AI group compared to the standard of care group (OR=1.51, P=0.003). PDR favored the intervened group compared to the standard group (OR=1.89, P<0.0001). A medium measure of effect was found for withdrawal times (SMD=0.25, P<0.0001), therefore with limited practical applications. Conclusion:AI-supported colonoscopies improve PDR and ADR; however, no noticeable worsening of withdrawal times is noted. Colorectal cancers are highly preventable if diagnosed early-on. With AI-assisted tools in clinical practice, there is a strong potential to reduce the incidence rates of cancers in the near future.
C1 [Aslam, Muhammad Fawad] Rai Med Coll, Dept Amed, Sargodha, Pakistan.
   [Khalid, Mariam] Rai Med Coll, Dept Med Educ, Sargodha, Pakistan.
   [Sarfraz, Azza] Aga Khan Univ, Dept Pediat, Karachi, Pakistan.
   [Bano, Shehar; Sarfraz, Zouina] Fatima Jinnah Med Univ, Dept Res & Publicat, Lahore, Pakistan.
   [Sarfraz, Muzna; Cherrez-Ojeda, Ivan] King Edward Med Univ, Dept Med, Lahore, Pakistan.
   [Robles-Velasco, Karla; Felix, Miguel] Univ Espiritu Santo, Samborondon, Ecuador.
   [Felix, Miguel] Lincoln, NYC HealthHospitals, Dept Med, Bronx, NY USA.
   [Deane, Kitson] Woodhull Med & Mental Hlth Ctr, New York, NY USA.
   [Sarfraz, Zouina] Fatima Jinnah Med Univ, Dept Res & Publicat, Lahore 54000, Pakistan.
C3 Aga Khan University; Universidad de Especialidades Espiritu Santo
RP Sarfraz, Z (通讯作者)，Fatima Jinnah Med Univ, Dept Res & Publicat, Lahore 54000, Pakistan.
EM drfawadrai@gmail.com; sheharbano1196@gmail.com;
   mariamkhalid1503@gmail.com; zouinasarfraz@gmail.com;
   azza.sarfraz@aku.edu; sarfrazmuzna@gmail.com;
   karlaroblesvelasco@gmail.com; miguel.felixromero@gmail.com;
   kitsondeane@gmail.com; ivancherrez@gmail.com
RI Sarfraz, Zouina/AAS-5093-2021
OI Sarfraz, Zouina/0000-0002-5132-7455; Robles-Velasco,
   Karla/0000-0001-7780-1015
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Alberti LR, 2015, WORLD J GASTRO ONCOL, V7, P484, DOI 10.4251/wjgo.v7.i12.484
   Ameen S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073341
   [Anonymous], 2022, PREV COL CANC MULT B
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   crd, EFF REAL TIM COMP AI
   Deliwala SS, 2021, INT J COLORECTAL DIS, V36, P2291, DOI 10.1007/s00384-021-03929-3
   Facciorusso A, 2018, CLIN GASTROENTEROL H, V16, P1209, DOI 10.1016/j.cgh.2017.11.007
   Facciorusso A, 2016, CLIN GASTROENTEROL H, V14, P1148, DOI 10.1016/j.cgh.2016.03.017
   Fleming M, 2012, J GASTROINTEST ONCOL, V3, P153, DOI 10.3978/j.issn.2078-6891.2012.030
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Harkey K, 2021, JAMA SURG, V156, P221, DOI [10.1001/jamasurg.2020.6265, 10.1186/s13643-021-01626-4, 10.1016/j.jclinepi.2021.03.001, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n71, 10.1016/j.rec.2021.07.010]
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Li JL, 2021, EUR J GASTROEN HEPAT, V33, P1041, DOI 10.1097/MEG.0000000000001906
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2020, WORLD J GASTROENTERO, V26, P5248, DOI 10.3748/wjg.v26.i35.5248
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mitsala A, 2021, CURR ONCOL, V28, P1581, DOI 10.3390/curroncol28030149
   Mohan BP, 2020, ECLINICALMEDICINE, V29-30, DOI 10.1016/j.eclinm.2020.100622
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2020, TECH INNOVAT GASTROI, V22, P52, DOI 10.1016/j.tgie.2019.150638
   Shea BJ, 2017, BMJ-BRIT MED J, V358, DOI 10.1136/bmj.j4008
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Taghiakbari M, 2021, WORLD J GASTROENTERO, V27, P8103, DOI 10.3748/wjg.v27.i47.8103
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Willems P, 2020, ENDOSC INT OPEN, V8, pE684, DOI 10.1055/a-1132-5371
   Wong WJ, 2020, ANZ J SURG, V90, P314, DOI 10.1111/ans.15652
   Xi Y, 2021, TRANSL ONCOL, V14, DOI 10.1016/j.tranon.2021.101174
   Yao LW, 2022, ENDOSCOPY, V54, P757, DOI 10.1055/a-1706-6174
   Zhang YC, 2021, J LAPAROENDOSC ADV S, V31, P1143, DOI 10.1089/lap.2020.0777
   Zippelius C, 2022, ENDOSCOPY, V54, P465, DOI 10.1055/a-1556-5984
NR 37
TC 0
Z9 0
U1 0
U2 0
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 2049-0801
J9 ANN MED SURG
JI Ann. Med. Surg.
PD FEB
PY 2023
VL 85
IS 2
BP 80
EP 91
DI 10.1097/MS9.0000000000000079
PG 12
WC Medicine, General & Internal
WE Emerging Sources Citation Index (ESCI)
SC General & Internal Medicine
GA G1EG8
UT WOS:000986667400005
PM 36845807
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU ELKarazle, K
   Raman, V
   Then, P
   Chua, C
AF ELKarazle, Khaled
   Raman, Valliappan
   Then, Patrick
   Chua, Caslon
TI Detection of Colorectal Polyps from Colonoscopy Using Machine Learning:
   A Survey on Modern Techniques
SO SENSORS
LA English
DT Review
DE automatic polyp detection; colorectal cancer; colorectal polyps; deep
   learning; computer vision
ID SEGMENTATION; DIAGNOSIS; IMAGES; VIDEOS; RISK
AB Given the increased interest in utilizing artificial intelligence as an assistive tool in the medical sector, colorectal polyp detection and classification using deep learning techniques has been an active area of research in recent years. The motivation for researching this topic is that physicians miss polyps from time to time due to fatigue and lack of experience carrying out the procedure. Unidentified polyps can cause further complications and ultimately lead to colorectal cancer (CRC), one of the leading causes of cancer mortality. Although various techniques have been presented recently, several key issues, such as the lack of enough training data, white light reflection, and blur affect the performance of such methods. This paper presents a survey on recently proposed methods for detecting polyps from colonoscopy. The survey covers benchmark dataset analysis, evaluation metrics, common challenges, standard methods of building polyp detectors and a review of the latest work in the literature. We conclude this paper by providing a precise analysis of the gaps and trends discovered in the reviewed literature for future work.
C1 [ELKarazle, Khaled; Then, Patrick] Swinburne Univ Technol, Sch Informat & Commun Technol, Sarawak Campus, Kuching 93350, Malaysia.
   [Raman, Valliappan] Coimbatore Inst Technol, Dept Artificial Intelligence & Data Sci, Coimbatore 641014, India.
   [Chua, Caslon] Swinburne Univ Technol, Dept Comp Sci & Software Engn, Melbourne 3122, Australia.
C3 Swinburne University of Technology; Swinburne University of Technology
   Sarawak; Coimbatore Institute of Technology; Swinburne University of
   Technology
RP ELKarazle, K (通讯作者)，Swinburne Univ Technol, Sch Informat & Commun Technol, Sarawak Campus, Kuching 93350, Malaysia.
EM kelkaeazle@swinburne.edu.my
RI raman, Valliappan/E-6393-2018
OI raman, Valliappan/0000-0002-9363-2319; ELKarazle, Khaled Yahya Mohamed
   Mahmoud/0000-0001-7545-1605
FU Swinburne University of Technology (Sarawak Campus); Swinburne
   University of Technology, Melbourne
FX The authors would like to thank Swinburne University of Technology
   (Sarawak Campus) and Swinburne University of Technology, Melbourne for
   providing the necessary resources to out this
CR Afify HM, 2021, INT J IMAG SYST TECH, V31, P1741, DOI 10.1002/ima.22568
   Albuquerque C, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21574-w
   Ali S.N., 2022, ARXIV
   Ali S, 2021, Arxiv, DOI arXiv:2106.04463
   Ali S, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102002
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], 2020, INT C PATTERN RECOGN
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Biffi C, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00633-6
   Bond JH, 2000, AM J GASTROENTEROL, V95, P3053
   Bora K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83788-8
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Carrinho P., 2022, SSRN ELECT J, DOI [10.2139/ssrn.4227573, DOI 10.2139/SSRN.4227573]
   Chen BL, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103019
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doniyorjon M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122110856
   Eixelberger Thomas, 2022, Current Directions in Biomedical Engineering, P277, DOI 10.1515/cdbme-2022-1071
   Ellahyani A., 2023, PERS UBIQUIT COMPUT, V27, P235, DOI [10.1007/s00779-021-01660-y, DOI 10.1007/S00779-021-01660-Y]
   Eu C. Y., 2022, P INT C ART INT SMAR, DOI [10.1007/978-981-16-2183-3_69, DOI 10.1007/978-981-16-2183-3_69]
   Fitting D, 2022, SCAND J GASTROENTERO, V57, P1397, DOI 10.1080/00365521.2022.2085059
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong EJ, 2022, J PERS MED, V12, DOI 10.3390/jpm12060963
   Grosu S, 2021, RADIOLOGY, V299, P326, DOI 10.1148/radiol.2021202363
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Hao YZ, 2020, GUT LIVER, V14, P399, DOI 10.5009/gnl19097
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ho CW, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06264-x
   Hu KL, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105760
   Jain Samir, 2022, Computer Vision and Image Processing: 6th International Conference, CVIP 2021, Revised Selected Papers. Communications in Computer and Information Science (1567), P538, DOI 10.1007/978-3-031-11346-8_46
   Jeong YH, 2016, J KOREAN MED SCI, V31, P1426, DOI 10.3346/jkms.2016.31.9.1426
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jinsakul N, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7121170
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeMarchand L, 1997, CANCER RES, V57, P4787
   Li JY, 2019, CHINESE J ELECTRON, V28, P718, DOI 10.1049/cje.2019.03.005
   Liew Win Sheng, 2022, International Conference on Artificial Intelligence for Smart Community: AISC 2020. Lecture Notes in Electrical Engineering (758), P735, DOI 10.1007/978-981-16-2183-3_71
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z., SWIN TRANSFORMER HIE
   Lo CM, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10081494
   Ma C., 2022, REAL TIME POLYP DETE, DOI [10.1007/978-3-031-18907-4_21, DOI 10.1007/978-3-031-18907-4_21]
   medtronic, GI GENIUSTM INTELLIG
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Nadimi ES, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106531
   An NS, 2022, IEEE ACCESS, V10, P43669, DOI 10.1109/ACCESS.2022.3168693
   Nisha JS, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103465
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Park KB, 2022, J COMPUT DES ENG, V9, P616, DOI 10.1093/jcde/qwac018
   Lan PN, 2021, LECT NOTES COMPUT SC, V13018, P15, DOI 10.1007/978-3-030-90436-4_2
   Puyal JGB, 2022, MED IMAGE ANAL, V82, DOI 10.1016/j.media.2022.102625
   Qadir H. A., 2019, 2019 13 INT S MEDICA, P1, DOI [10.1109/ISMICT.2019.8743694, DOI 10.1109/ISMICT.2019.8743694]
   Qian ZQ, 2021, IEEE SENS J, V21, P11374, DOI 10.1109/JSEN.2020.3036005
   Rani N., 2022, HDB INTELLIGENT COMP, P801, DOI [10.1002/9781119792642.CH37, DOI 10.1002/9781119792642.CH37]
   Reddy Jillella Sai Charan, 2022, 2022 1st International Conference on the Paradigm Shifts in Communication, Embedded Systems, Machine Learning and Signal Processing (PCEMS)., P104, DOI 10.1109/PCEMS55161.2022.9807988
   Redmon J., YOU ONLY LOOK ONCE U
   Ren S., FASTER R CNN REAL TI
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ronneberger O., U NET CONVOLUTIONAL
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Sharma P, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.844391
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shussman N, 2014, GASTROENTEROL REP, V2, P1, DOI 10.1093/gastro/got041
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sun XZ, 2020, PROC INT C TOOLS ART, P706, DOI 10.1109/ICTAI50040.2020.00113
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tanwar S, 2022, BIOMED RES INT-UK, V2022, DOI 10.1155/2022/2805607
   Tashk A., 2022, P 2022 IEEE 5 INT C
   Tashk A, 2020, IEEE C EVOL COMPUTAT
   Umehara K., 2017, PROC SPIE, V10134, P108
   Usami Hiroyasu, 2020, Procedia Computer Science, V176, P2507, DOI 10.1016/j.procs.2020.09.325
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Venkatayogil N, 2022, IEEE SENSOR, DOI 10.1109/SENSORS52175.2022.9967308
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang Y, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/2485934
   Wesp P, 2022, EUR RADIOL, V32, P4749, DOI 10.1007/s00330-021-08532-2
   WILLIAMS C, 1973, GUT, V14, P990, DOI 10.1136/gut.14.12.990
   World Health Organization, 2022, COLORECTAL CANCER
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yadav Nikhil, 2017, INT RES J ENG TECHNO, V4, P586
   Yang K, 2022, ALEX ENG J, V61, P917, DOI 10.1016/j.aej.2021.04.072
   Younas F, 2023, APPL INTELL, V53, P2410, DOI 10.1007/s10489-022-03689-9
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yu T, 2022, ARTIF INTELL MED, V131, DOI 10.1016/j.artmed.2022.102363
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 98
TC 3
Z9 3
U1 13
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD FEB
PY 2023
VL 23
IS 3
AR 1225
DI 10.3390/s23031225
PG 23
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA 9X6OE
UT WOS:000949885900001
PM 36772263
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Houwen, BBSL
   Nass, KJ
   Vleugels, JLA
   Fockens, P
   Hazewinkel, Y
   Dekker, E
AF Houwen, Britt B. S. L.
   Nass, Karlijn J.
   Vleugels, Jasper L. A.
   Fockens, Paul
   Hazewinkel, Yark
   Dekker, Evelien
TI Comprehensive review of publicly available colonoscopic imaging
   databases for artificial intelligence research: availability,
   accessibility, and usability
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
ID AUTOMATIC POLYP DETECTION; COMPUTER-AIDED DETECTION; COLORECTAL POLYPS;
   NETWORK; CLASSIFICATION; SEGMENTATION; VALIDATION; LOCALIZATION; SYSTEM;
   IMAGES
AB Background and Aims: Publicly available databases containing colonoscopic imaging data are valuable resources for artificial intelligence (AI) research. Currently, little is known regarding the available number and content of these databases. This review aimed to describe the availability, accessibility, and usability of publicly available colonoscopic imaging databases, focusing on polyp detection, polyp characterization, and quality of colonoscopy.
   Methods: A systematic literature search was performed in MEDLINE and Embase to identify AI studies describing publicly available colonoscopic imaging databases published after 2010. Second, a targeted search using Google's Dataset Search, Google Search, GitHub, and Figshare was done to identify databases directly. Databases were included if they contained data about polyp detection, polyp characterization, or quality of colonoscopy. To assess accessibility of databases, the following categories were defined: open access, open access with barriers, and regulated access. To assess the potential usability of the included databases, essential details of each database were extracted using a checklist derived from the Checklist for Artificial Intelligence in Medical Imaging.
   Results: We identified 22 databases with open access, 3 databases with open access with barriers, and 15 databases with regulated access. The 22 open access databases contained 19,463 images and 952 videos. Nineteen of these databases focused on polyp detection, localization, and/or segmentation; 6 on polyp characterization, and 3 on quality of colonoscopy. Only half of these databases have been used by other researcher to develop, train, or benchmark their AI system. Although technical details were in general well reported, important details such as polyp and patient demographics and the annotation process were under-reported in almost all databases.
   Conclusions: This review provides greater insight on public availability of colonoscopic imaging databases for AI research. Incomplete reporting of important details limits the ability of researchers to assess the usability of current databases.
C1 [Houwen, Britt B. S. L.; Nass, Karlijn J.; Vleugels, Jasper L. A.; Fockens, Paul; Dekker, Evelien] Univ Amsterdam, Locat Acad Med Ctr, Dept Gastroenterol & Hepatol, Amsterdam Gastroenterol Endocrinol Metab,Med Ctr, Amsterdam, Netherlands.
   [Hazewinkel, Yark] Radboud Univ Nijmegen, Med Ctr, Dept Gastroenterol & Hepatol, Nijmegen, Netherlands.
   [Dekker, Evelien] Univ Amsterdam, Locat Acad Med Ctr, Dept Gastroenterol & Hepatol, Med Ctr, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.
C3 University of Amsterdam; Radboud University Nijmegen; University of
   Amsterdam
RP Dekker, E (通讯作者)，Univ Amsterdam, Locat Acad Med Ctr, Dept Gastroenterol & Hepatol, Med Ctr, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.
RI Houwen, Britt/IVH-6320-2023; Vleugels, Jasper/AAX-4659-2021; Hazewinkel,
   Yark/AAD-6593-2019
CR Afify HM, 2021, INT J IMAG SYST TECH, V31, P1741, DOI 10.1002/ima.22568
   Ahmad OF, 2022, DIGEST ENDOSC, V34, P862, DOI 10.1111/den.14187
   Ahmed A, ARXIV
   Ahmed A, 2022, P INT C DATA SCI APP
   Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Alam S, ARXIV
   Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Ali S, 2021, MED IMAGE ANAL
   Ali S, 2021, ARXIV
   Ali S, 2021, NORD MACH INTELL, V1, P38
   Ali S, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102002
   Ali SMF, 2020, DEPTH WISE SEPARABLE
   Angermann, 2017 EUROMICRO C DIG
   Angermann Q, 2017, INT J COMPUT ASSIST, V12, pS20
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Angermann Q, 2016, PROCEDIA COMPUT SCI, V90, P182, DOI 10.1016/j.procs.2016.07.017
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Armin MA, 2018, LECT NOTES COMPUT SC, V11041, P108, DOI 10.1007/978-3-030-01201-4_13
   Attallah O, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.423
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Banik D, 2020, DEEP CONDITIONAL ADV
   Bardhi O, 2017 IEEE INT S SIGN
   Bardhi O, 2021, INFORMATION, V12, DOI 10.3390/info12060245
   Batchkala G, 2020, REAL TIME POLYP SEGM
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2018, P 32 CARS C, V13, pS166
   Bernal J, 2013 35 ANN INT C IE
   Bernal J, 2019, INT J COMPUT ASS RAD, V14, P191, DOI 10.1007/s11548-018-1864-x
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bhattacharya D, 2021, ARXIV
   Billah M, 2020, MULTIMED TOOLS APPL, V79, P23633, DOI 10.1007/s11042-020-09151-7
   Billah M, 2018, BIOMED ENG LETT, V8, P69, DOI 10.1007/s13534-017-0048-x
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bora K, 2021, SCI REP-UK, V11, P1
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Branch MV, ARXIV
   Brandao P, 2018, PEER PEER NETW APPL, V3
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Bravo D, 2020, 15 INT S MEDICAL INF, P360
   BravoD RuanoJ, 2020, MEDICAL IMAGING 2020, P775
   Cai L, 2021 IEEE EMBS INT C
   Calderwood AH, 2010, GASTROINTEST ENDOSC, V72, P686, DOI 10.1016/j.gie.2010.06.068
   Celik N, 2021, INT C MED IM COMP CO
   Chan XY, 2022, SAGE OPEN, V12, DOI 10.1177/21582440221095012
   Chen C -W, DEEP LEARNING POLYP
   Chen Y, 2021, 6 INT WORKSHOP PATTE
   Cheng M, 2021, INT C MEDICAL IMAGE
   Cho M, 2019, PEERJ, V7, DOI 10.7717/peerj.7256
   Cho YJ, 2016, J MED BIOL ENG, V36, P871, DOI 10.1007/s40846-016-0190-4
   Chou Y, 2021, NORD MACH INTELL, V1, P17
   Cincar, 2020, 2020 INT C INNOVATIO
   Cychnerski J, 2022, ARXIV
   Dalju HB, 2021 IEEE BIOMEDICAL
   Dang T., 2021, ARXIV
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Deng J., 2009, P IEEE C COMP VIS PA, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dijkstra, 2019, VISIGRAPP 4 VISAPP
   Dogan RS, 2021, EUROBIOTECH J, V5, P34, DOI 10.2478/ebtj-2021-0006
   Dong B., 2021, ARXIV
   Du N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155371
   Dulf E-H, 2021 25 INT C SYSTEM
   Dulf EH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175704
   Ellahyani A., 2023, PERS UBIQUIT COMPUT, V27, P235, DOI [10.1007/s00779-021-01660-y, DOI 10.1007/S00779-021-01660-Y]
   Eriyanti, 2021 INT ELECT S
   Erol T, 2022, ARXIV
   Eu CY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165630
   Fang YQ, 2021, IEEE SENS J, V21, P11799, DOI 10.1109/JSEN.2020.3015831
   Fathan MI, 2019, COMP STUDY POLYP CLA
   Feng RW, 2020, I S BIOMED IMAGING, P225, DOI 10.1109/ISBI45749.2020.9098492
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Figueiredo IN, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101577
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Galdran A, 2021, MULTICENTER POLYP SE
   Galdran A, 2021, PATTERN RECOGN
   Gil D, 2015, COMPUTER ASSISTED RO, P140
   Gjestang HL, 2021 IEEE 34 INT S C
   Gómez-Zuleta Martín Alonso, 2021, Rev. colomb. Gastroenterol., V36, P7, DOI 10.22516/25007440.471
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Guo XQ, 2021, IEEE T MED IMAGING, V40, P1134, DOI 10.1109/TMI.2020.3046843
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   Guo Y, 2019, ANN C MEDICAL IMAGE, P377
   Guo YB, 2020, J IMAGING, V6, DOI 10.3390/jimaging6070069
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Harkey K, 2021, JAMA SURG, V156, P221, DOI [10.1001/jamasurg.2020.6265, 10.1186/s13643-021-01626-4, 10.1016/j.jclinepi.2021.03.001, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n71, 10.1016/j.rec.2021.07.010]
   Hasan MM, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-12250-2
   Hasnat R, 2021 3 INT C ELECT E
   He F, 2021 IEEE 18 INT S B
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hicks S, 2021, NORDIC MACHINE INTEL, V1, P1
   Hong LTT, 2021, IEEE ACCESS, V9, P156987, DOI 10.1109/ACCESS.2021.3129480
   Houwen BBSL, 2022, ENDOSCOPY, V54, peP133
   Houwen BBSL, 2022, DEV VAL COMP AID DIA
   Hrynaszkiewicz I, 2010, BRIT MED J, V340, DOI 10.1136/bmj.c181
   Hsu CM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21185995
   Huang C., 2018, 2017 IEEE 28 ANN INT, P1
   Huang C. -H., 2021, ARXIV
   Huang D, 2021, INT C NEURAL INFORM
   Huang JD, 2023, ROAD MATER PAVEMENT, V24, P1939, DOI 10.1080/14680629.2022.2112061
   Hung NB, 2021 RIVF INT C COMP
   Hwang M, 2020, COMPUT MED IMAG GRAP, V84, DOI 10.1016/j.compmedimag.2020.101763
   Isidro AE, 2022, ARXIV
   Itoh H, 2021, INT J COMPUT ASS RAD, V16, P1817, DOI 10.1007/s11548-021-02477-z
   Jha D., ARXIV
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji G-P, 2021, INT C MEDICAL IMAGE
   Ji G-P, AUTOMATIC POLYP SEGM
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kang J., 2020, KD RESUNET AUTOMATIC
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Karmakar R, 2022, MOBILE POLYPNET LIGH, V8, P1
   Kassani S. H., 2020, ARXIV
   Kayser M, ARXIV
   Keerie C, 2018, TRIALS, V19, DOI 10.1186/s13063-017-2382-9
   Khadka R, 2020, TRANSFER KNOWLEDGE F
   Khadka R, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105227
   Khan SM, 2021, LANCET DIGIT HEALTH, V3, pE51, DOI 10.1016/S2589-7500(20)30240-5
   Krenzer A, 2022, REAL TIME POLYP DETE
   Kwon J, 2021, IEEE ENG MED BIO, P3725, DOI 10.1109/EMBC46164.2021.9629608
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Lai H, 2022, VISUAL COMPUT, P1
   Lan PN, 2021, ARXIV
   Lee JY, 2022, GASTROINTEST ENDOSC, V95, P512, DOI 10.1016/j.gie.2021.11.041
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Li JW, 2021, J GASTROEN HEPATOL, V36, P3298, DOI 10.1111/jgh.15642
   Li KD, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255809
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Li X, 2020 IEEE 32 INT C T
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu XY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102052
   Low DJ, 2021, ENDOSC INT OPEN, V09, pE1778, DOI 10.1055/a-1546-8266
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Lumini A, ARXIV
   Ma, 2020 IEEE 17 INT S B
   Ma YT, 2021, LECT NOTES COMPUT SC, V12905, P387, DOI 10.1007/978-3-030-87240-3_37
   Mahanty Mohan, 2021, Revue d'Intelligence Artificielle, V35, P395, DOI 10.18280/ria.350505
   Mahato SJ, 2021, INT C COMPUTATIONAL
   Mahmood F, 2019, MEDICAL IMAGING 2019, P268, DOI 10.1117
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2021, DIGEST ENDOSC, V33, P273, DOI 10.1111/den.13847
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Mohan Mahanty, 2021, Natural Volatiles & Essential Oils, V8, P649
   Mohapatra S, 2022, 2022 IEEE 4 INT C AD
   Mohapatra S, 2021, INTERDISCIP SCI, V13, P212, DOI 10.1007/s12539-021-00417-8
   Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mostafiz R, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2944-4
   Mostafiz R, 2020, INT J IMAG SYST TECH, V30, P224, DOI 10.1002/ima.22350
   Nagesh B, 2021 3 INT C INTELLI
   Nagy S, 2017, AFRICON, P78, DOI 10.1109/AFRCON.2017.8095459
   Nasrin S, 2021, SEGMENTATION POLYPS
   Nathan S, 2020, EFFICIENT SUPERVISIO
   Nezhad SA, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/8151177
   Nguyen NQ, 2020, IEEE ACCESS, V8, P99495, DOI 10.1109/ACCESS.2020.2995630
   Nguyen DT, 2020, SENSORS-BASEL, V20
   Nguyen Q, 2018 IEEE 1 INT C AR
   Nguyen T-C, 2021, INT C MEDICAL IMAGE
   Nguyen T-P, 2020, HCMUS MED AUTOMATIC
   Nisha J, 2021, BIOMED ENG-APP BAS C
   Nisha JS, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103465
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Obukhova NA, 2020, COMPUTER VISION CONT, V6, P93
   Ou S, 2021 IEEE 2 INT C IN
   Ozturk S, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103638
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pappalardo, 2020 IEEE INT S MEDI
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/crv52889.2021.00032, 10.1109/CRV52889.2021.00032]
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Podlasek J, 2021, ENDOSC INT OPEN, V09, pE741, DOI 10.1055/a-1388-6735
   Pogorelov K, 2018, P 9 ACM MULTIMEDIA S
   Pogorelov K, P 8 ACM MULTIMEDIA S
   Pogorelov K, 2018 IEEE 31 INT S C
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P170, DOI 10.1145/3083187.3083216
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Polat G, 2021, POLYP DETECTION COLO
   Poon CCY, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0281-z
   Poorneshwaran J, 2019, 2019 41 ANN INT C IE
   Poudel, 2020, AUTOMATIC POLYP SEGM
   Puyal JG-B, 2020, INT C MED IMAGE COMP
   Qadir HA, 2019, IEEE ACCESS, V7, P169537, DOI 10.1109/ACCESS.2019.2954675
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Qian ZQ, 2021, IEEE SENS J, V21, P11374, DOI 10.1109/JSEN.2020.3036005
   Qiu Z, 2022, ARXIV
   Rahim T, 2021, DEEP LEARNING BASED, P522
   Rahman MM, 2021, INFORM MED UNLOCKED, V24
   Rajinikanth V, 2022, CMC-COMPUT MATER CON, V70, P4087, DOI 10.32604/cmc.2022.019786
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Ribeiro Jose, 2022, Procedia Computer Science, P477, DOI 10.1016/j.procs.2021.12.039
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Saito H, 2021, GASTROENTEROL REP, V9, P226, DOI 10.1093/gastro/goaa078
   Sanchez-Gonzalez A, 2018, 2018 IEEE INT S SIGN
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Sanchez-Peralta LF, 2020, INT J COMPUT ASS RAD, V15, P1975, DOI 10.1007/s11548-020-02262-4
   Sanchez-Peralta LF, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8081316
   Sang DV, 2021, ARXIV
   Sasmal, 2020 IEEE APPL SIGNA
   Sasmal P, 2021, AUTOMATED FRAMEWORK
   Sasmal P, 2022, PATTERN RECOGN LETT, V154, P7, DOI 10.1016/j.patrec.2021.12.014
   Sasmal P, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3082315
   Sasmal P, 2021, IEEE ACCESS, V9, P92629, DOI 10.1109/ACCESS.2021.3092263
   Shafi A., 2020, INT J ELECT COMPUT E, V10, P2986
   Shen Y, 2021, INT C MEDICAL IMAGE
   Shen YT, 2021, IEEE ENG MED BIO, P3114, DOI 10.1109/EMBC46164.2021.9630525
   Shen Z, 2021 7 INT C COMP CO
   Shin W, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12042114
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Sierra F, 2020, IEEE ENG MED BIO, P2412, DOI 10.1109/EMBC44109.2020.9176534
   Sierra-Jerez, 2022, HLTH TECHNOL, P1
   Sima I, 2021 IEEE 21 INT C B
   Singh D, 2021, J AMB INTEL HUM COMP, V12, P8683, DOI 10.1007/s12652-020-02629-0
   Sinonquel P, 2021, GUT, V70, P641, DOI 10.1136/gutjnl-2020-322491
   Somani A, 2021, NORD MACH INTELL, V1, P11
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Srivastava A, 2021, ARXIV
   Su H, 2021, FRONT BIOENG BIOTECH, V9, P1
   Sun X, 2019 18 IEEE INT C M
   Sun X, 2020 IEEE 32 INT C T
   Sushma B, 2021 5 INT C COMP ME
   Sutton R. T., 2022, SCI REP-UK, V12, P1
   Sziova B, 2021, RECENT DEV NEW DIREC, P347
   Ta N, 2022, MULTIMEDIA SYST, DOI 10.1007/s00530-022-00900-2
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Taha B, 2017, IEEE IMAGE PROC, P2060, DOI 10.1109/ICIP.2017.8296644
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Tajbakhsh Nima, 2014, 2014 IEEE 11 INT S B
   Takamatsu M., 2020 19 IEEE INT C M
   Tas M, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2020.106959
   Tashk A, 2019, 2019 INT C CONTROL A
   Thambawita Vajira, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3386295
   Thambawita V, 2021, ARXIV
   Thambawita V, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122183
   Thanh, 2020 RIVF INT C COMP
   Thanh, 2021, J MILIT SCI TECHNOL, P3, DOI DOI 10.54939/1859-1043.J.MST.CSCE5.2021.3-13
   Thanh NC, 2021 8 NAFOSTED C IN
   Thomaz VD, 2019, COMP MED SY, P192, DOI 10.1109/CBMS.2019.00047
   Thomaz VD, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101988
   Tomar NK, ARXIV
   Tomar NK, 2021, INT C PATTERN RECOGN
   Tomara NK, 2021, IMPROVING GEN POLYP
   Trinh QH., 2021, ARXIV
   Tzavara NP, 2021, NORD MACH INTELL, V1, P32
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Viscaino M, 2019, IEEE ENG MED BIO, P961, DOI 10.1109/EMBC.2019.8857831
   Vispute, 2018 5 INT C SIGNAL
   Vleugels JLA, 2020, GUT, V69, P977, DOI 10.1136/gutjnl-2018-316882
   Wan JJ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122264
   Wang, 2019 IEEE INT C SIGN
   Wang D, 2022, IEEE J BIOMED HEALTH
   Wang D, 2021 IEEE 10 DATA DR
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang M, 2021, IEEE ENG MED BIO, P2936, DOI 10.1109/EMBC46164.2021.9630787
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Q, 2021, INT C MEDICAL IMAGE
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Wang ST, 2021, KNOWL-BASED SYST, V234, DOI 10.1016/j.knosys.2021.107568
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Wang WL, 2020, BMC PSYCHIATRY, V20, DOI 10.1186/s12888-020-02566-4
   Wang Y, 2019, MEDICAL IMAGING 2019
   Wang Y, 2021, COMPUT MATH METHOD M
   Wang Y, 2019, MEDICAL IMAGING 2019, DOI [10.1117/12.2512756.short, DOI 10.1117/12.2512756.SHORT]
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wichakam I, 2018, INT C MULTIMEDIA MOD
   Wickstrom K, 2018 IEEE 28 INT WOR
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   Wu HS, 2021, AAAI CONF ARTIF INTE, V35, P2916
   Wu LY, 2021, LECT NOTES COMPUT SC, V12905, P302, DOI 10.1007/978-3-030-87240-3_29
   Xu JW, 2022, COMPUT METH PROG BIO, V214, DOI 10.1016/j.cmpb.2021.106576
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yang C, 2021, IEEE J BIOMED HEALTH, V25, P3886, DOI 10.1109/JBHI.2021.3077271
   Yang K, 2022, ALEX ENG J, V61, P917, DOI 10.1016/j.aej.2021.04.072
   Ye ML, 2017, INT J COMPUT ASS RAD, V12, P1281, DOI 10.1007/s11548-017-1620-7
   Ye ML, 2016, MED IMAGE ANAL, V30, P144, DOI 10.1016/j.media.2015.10.003
   Yeung M, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104815
   Yin Z., 2021, ARXIV
   Yu J, 2019 IEEE 35 INT C D
   Yua, 2021, PARALLEL RES2NET BAS
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang P, 2019 IEEE 31 INT C T
   Zhang R, 2020, INT C MED IM COMP CO
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang Z, 2021, 2021 14 INT C IMAGE
   Zhang Z, 2021, CHINESE C PATTERN RE
   Zhao X, 2021, INT C MEDICAL IMAGE
   Zhao X, 2021, ARTIF INTELL
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
   Zhou X, 2021 CHINA AUTOMATIO
   Zhu Y, 2019, 2019 12 INT C IMAGE
   Zizhao, 2021 IEEE INT C EMER
NR 310
TC 0
Z9 0
U1 1
U2 1
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD FEB
PY 2023
VL 97
IS 2
PG 32
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 8O1KL
UT WOS:000925601000001
DA 2023-08-21
ER

PT J
AU Hsu, CM
   Hsu, CC
   Hsu, ZM
   Chen, TH
   Kuo, TY
AF Hsu, Chen-Ming
   Hsu, Chien-Chang
   Hsu, Zhe-Ming
   Chen, Tsung-Hsing
   Kuo, Tony
TI Intraprocedure Artificial Intelligence Alert System for Colonoscopy
   Examination
SO SENSORS
LA English
DT Article
DE colonoscopy; intra-procedure alert system; dynamic colon polyp image;
   blurred image detection; foreign body detection; polyp detection; deep
   learning
ID COLORECTAL-CANCER; QUALITY INDICATORS; INTERVAL CANCER; PREVENTION;
   VALIDATION; ADENOMAS; TIME
AB Colonoscopy is a valuable tool for preventing and reducing the incidence and mortality of colorectal cancer. Although several computer-aided colorectal polyp detection and diagnosis systems have been proposed for clinical application, many remain susceptible to interference problems, including low image clarity, unevenness, and low accuracy for the analysis of dynamic images; these drawbacks affect the robustness and practicality of these systems. This study proposed an intraprocedure alert system for colonoscopy examination developed on the basis of deep learning. The proposed system features blurred image detection, foreign body detection, and polyp detection modules facilitated by convolutional neural networks. The training and validation datasets included high-quality images and low-quality images, including blurred images and those containing folds, fecal matter, and opaque water. For the detection of blurred images and images containing folds, fecal matter, and opaque water, the accuracy rate was 96.2%. Furthermore, the study results indicated a per-polyp detection accuracy of 100% when the system was applied to video images. The recall rates for high-quality image frames and polyp image frames were 95.7% and 92%, respectively. The overall alert accuracy rate and the false-positive rate of low quality for video images obtained through per-frame analysis were 95.3% and 0.18%, respectively. The proposed system can be used to alert colonoscopists to the need to slow their procedural speed or to perform flush or lumen inflation in cases where the colonoscope is being moved too rapidly, where fecal residue is present in the intestinal tract, or where the colon has been inadequately distended.
C1 [Hsu, Chen-Ming] Taoyuan Chang Gung Mem Hosp, Dept Gastroenterol & Hepatol, Taoyuan 333, Taiwan.
   [Hsu, Chen-Ming; Chen, Tsung-Hsing; Kuo, Tony] Linkou Chang Gung Mem Hosp, Dept Gastroenterol & Hepatol, Taoyuan 333, Taiwan.
   [Hsu, Chen-Ming; Chen, Tsung-Hsing] Chang Gung Univ, Coll Med, Taoyuan 333, Taiwan.
   [Hsu, Chien-Chang; Hsu, Zhe-Ming] Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, New Taipei 242, Taiwan.
C3 Chang Gung Memorial Hospital; Chang Gung Memorial Hospital; Chang Gung
   University; Fu Jen Catholic University
RP Hsu, CC (通讯作者)，Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, New Taipei 242, Taiwan.
EM cch@csie.fju.edu.tw
CR Aronchick CA, 2000, GASTROINTEST ENDOSC, V52, P346, DOI 10.1067/mge.2000.108480
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Chen C.-W., 2021, THESIS ATL TAIWAN U, DOI [10.6342/NTU202104216, DOI 10.6342/NTU202104216]
   Galloro G, 2015, COLORECTAL DIS, V17, P25, DOI 10.1111/codi.12818
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Haug U, 2014, GUT, V63, P865, DOI 10.1136/gutjnl-2013-305686
   Hisabe T, 2014, DIGEST ENDOSC, V26, P73, DOI 10.1111/den.12276
   Hsu CM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21185995
   Jin P, 2020, J CANCER RES CLIN, V146, P2339, DOI 10.1007/s00432-020-03304-9
   Johnson DA, 2014, GASTROENTEROLOGY, V147, P903, DOI 10.1053/j.gastro.2014.07.002
   Kaltenbach T, 2008, GASTROENTEROLOGY, V134, P327, DOI 10.1053/j.gastro.2007.10.062
   Korbar B, 2017, IEEE COMPUT SOC CONF, P821, DOI 10.1109/CVPRW.2017.114
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Li KD, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255809
   Liu Q., 2017, THESIS U COLL SE NOR
   Liu YK, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P547, DOI 10.1109/SSCI.2018.8628648
   May FP, 2020, AM J GASTROENTEROL, V115, P1183, DOI 10.14309/ajg.0000000000000622
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Parmar R, 2016, AM J GASTROENTEROL, V111, P197, DOI 10.1038/ajg.2015.417
   Pickhardt PJ, 2004, ANN INTERN MED, V141, P352, DOI 10.7326/0003-4819-141-5-200409070-00009
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rex DK, 2000, GASTROINTEST ENDOSC, V51, P33, DOI 10.1016/S0016-5107(00)70383-X
   Rex DK, 2015, AM J GASTROENTEROL, V110, P72, DOI 10.1038/ajg.2014.385
   Rostom A, 2004, GASTROINTEST ENDOSC, V59, P482, DOI 10.1016/S0016-5107(03)02875-X
   Rutter MD, 2018, GASTROENTEROLOGY, V155, P909, DOI 10.1053/j.gastro.2018.05.038
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Shaukat A, 2015, GASTROENTEROLOGY, V149, P952, DOI 10.1053/j.gastro.2015.06.044
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Snover DC, 2011, HUM PATHOL, V42, P1, DOI 10.1016/j.humpath.2010.06.002
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Suzuki H, 2020, DIGESTION, V101, P339, DOI 10.1159/000499856
   Viscaino M, 2021, WORLD J GASTROENTERO, V27, P6399, DOI 10.3748/wjg.v27.i38.6399
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Xu HY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0261-2
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 42
TC 1
Z9 1
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD FEB
PY 2023
VL 23
IS 3
AR 1211
DI 10.3390/s23031211
PG 13
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA 8U6NK
UT WOS:000930066200001
PM 36772251
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Krenzer, A
   Banck, M
   Makowski, K
   Hekalo, A
   Fitting, D
   Troya, J
   Sudarevic, B
   Zoller, WG
   Hann, A
   Puppe, F
AF Krenzer, Adrian
   Banck, Michael
   Makowski, Kevin
   Hekalo, Amar
   Fitting, Daniel
   Troya, Joel
   Sudarevic, Boban
   Zoller, Wolfgang G.
   Hann, Alexander
   Puppe, Frank
TI A Real-Time Polyp-Detection System with Clinical Application in
   Colonoscopy Using Deep Convolutional Neural Networks
SO JOURNAL OF IMAGING
LA English
DT Article
DE machine learning; deep learning; endoscopy; gastroenterology;
   automation; object detection; video object detection; real-time
ID COLORECTAL NEOPLASTIC POLYPS; MISS RATE; CLASSIFICATION; CNN
AB Colorectal cancer (CRC) is a leading cause of cancer-related deaths worldwide. The best method to prevent CRC is with a colonoscopy. During this procedure, the gastroenterologist searches for polyps. However, there is a potential risk of polyps being missed by the gastroenterologist. Automated detection of polyps helps to assist the gastroenterologist during a colonoscopy. There are already publications examining the problem of polyp detection in the literature. Nevertheless, most of these systems are only used in the research context and are not implemented for clinical application. Therefore, we introduce the first fully open-source automated polyp-detection system scoring best on current benchmark data and implementing it ready for clinical application. To create the polyp-detection system (ENDOMIND-Advanced), we combined our own collected data from different hospitals and practices in Germany with open-source datasets to create a dataset with over 500,000 annotated images. ENDOMIND-Advanced leverages a post-processing technique based on video detection to work in real-time with a stream of images. It is integrated into a prototype ready for application in clinical interventions. We achieve better performance compared to the best system in the literature and score a F1-score of 90.24% on the open-source CVC-VideoClinicDB benchmark.
C1 [Krenzer, Adrian; Banck, Michael; Makowski, Kevin; Hekalo, Amar; Puppe, Frank] Julius Maximilians Univ Wurzburg, Dept Artificial Intelligence & Knowledge Syst, Sanderring 2, D-97070 Wurzburg, Germany.
   [Krenzer, Adrian; Banck, Michael; Fitting, Daniel; Troya, Joel; Sudarevic, Boban; Zoller, Wolfgang G.; Hann, Alexander] Univ Hosp Wurzburg, Dept Internal Medicine 2, Intervent & Expt Endoscopy InExEn, Oberdurrbacher Str 6, D-97080 Wurzburg, Germany.
   [Sudarevic, Boban; Zoller, Wolfgang G.] Katharinen hosp, Dept Internal Med & Gastroenterol, Kriegsbergstr 60, D-70174 Stuttgart, Germany.
C3 University of Wurzburg; University of Wurzburg; Klinikum Stuttgart
RP Krenzer, A (通讯作者)，Julius Maximilians Univ Wurzburg, Dept Artificial Intelligence & Knowledge Syst, Sanderring 2, D-97070 Wurzburg, Germany.; Krenzer, A (通讯作者)，Univ Hosp Wurzburg, Dept Internal Medicine 2, Intervent & Expt Endoscopy InExEn, Oberdurrbacher Str 6, D-97080 Wurzburg, Germany.
EM adrian.krenzer@uni-wuerzburg.de
OI Hann, Alexander/0000-0001-8035-3559; Krenzer, Adrian/0000-0002-1593-3300
FU state government of Baden-Wurttemberg, Germany; Interdisziplinaeres
   Zentrum fuer Klinische Forschung (IZKF); University of Wuerzburg;
   cluster Forum Gesundheitsstandort Baden-Wuerttemberg
FX A.H. and W.Z. receive public funding from the state government of
   Baden-Wurttemberg, Germany (Funding cluster Forum Gesundheitsstandort
   Baden-Wuerttemberg) to research and develop artificial intelligence
   applications for polyp detection in screening colonoscopy. F.P. receives
   funding from Interdisziplinaeres Zentrum fuer Klinische Forschung (IZKF)
   from the University of Wuerzburg.
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Ali S, 2019, Arxiv, DOI arXiv:1905.03209
   Ali Sharib, 2020, IEEE DataPort, DOI 10.21227/F8XG-WB80
   Andrew N., 2011, DOCUMENT CS294A LECT, V72, P1
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Bagheri M, 2019, IEEE ENG MED BIO, P6742, DOI 10.1109/EMBC.2019.8856793
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED, DOI DOI 10.48550/ARXIV.2004.10934
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Fitting D, 2022, SCAND J GASTROENTERO, V57, P1397, DOI 10.1080/00365521.2022.2085059
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   Hazewinkel Y, 2011, NAT REV GASTRO HEPAT, V8, P554, DOI 10.1038/nrgastro.2011.141
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Ishiyama M, 2022, GASTROINTEST ENDOSC, V95, P155, DOI 10.1016/j.gie.2021.07.022
   Itoh H, 2022, INT J COMPUT ASS RAD, V17, P2051, DOI 10.1007/s11548-022-02696-y
   Itoh H, 2019, HEALTHC TECHNOL LETT, V6, P237, DOI 10.1049/htl.2019.0079
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kayser M., 2020, ARXIV
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Krenzer A, 2022, BIOMED ENG ONLINE, V21, DOI 10.1186/s12938-022-01001-x
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin T.-Y., 2014, EUR C COMP VIS, P740
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YY, 2020, I S BIOMED IMAGING, P1642, DOI 10.1109/ISBI45749.2020.9098406
   Livovsky DM, 2021, GASTROINTEST ENDOSC, V94, P1099, DOI 10.1016/j.gie.2021.06.021
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misawa M, 2019, GASTROINTEST ENDOSC, V89, pAB646, DOI 10.1016/j.gie.2019.03.1134
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Puyal JGB, 2022, MED IMAGE ANAL, V82, DOI 10.1016/j.media.2022.102625
   Qadir HA, 2019, IEEE ACCESS, V7, P169537, DOI 10.1109/ACCESS.2019.2954675
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Ratheesh A, 2016, INT CONF COMMUN SYST, P179, DOI 10.1109/CSN.2016.7824010
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Sabater A., 2020, P INT C INTELLIGENT
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sharma P, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.844391
   Sharma P, 2020, ONCOLOGIE, V22, P129, DOI 10.32604/oncologie.2020.013870
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Szegedy C., 2016, ARXIV, DOI [10.1609/aaai.v31i1.11231, DOI 10.1609/AAAI.V31I1.11231]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Thomaz VD, 2019, COMP MED SY, P192, DOI 10.1109/CBMS.2019.00047
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wu Y., 2019, DETECTRON2
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Xu RJ, 2021, FORESTS, V12, DOI 10.3390/f12020217
   Yuan YX, 2020, IEEE T AUTOM SCI ENG, V17, P574, DOI 10.1109/TASE.2019.2936645
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan ZJ, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254671
   Zhang PF, 2019, PROC INT C TOOLS ART, P1252, DOI 10.1109/ICTAI.2019.00-93
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhang Y, 2021, ARXIV
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
NR 84
TC 2
Z9 2
U1 5
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2313-433X
J9 J IMAGING
JI J. Imaging
PD FEB
PY 2023
VL 9
IS 2
AR 26
DI 10.3390/jimaging9020026
PG 38
WC Imaging Science & Photographic Technology
WE Emerging Sources Citation Index (ESCI)
SC Imaging Science & Photographic Technology
GA 9I0DC
UT WOS:000939190800001
PM 36826945
OA gold, Green Published, Green Submitted
DA 2023-08-21
ER

PT J
AU Kutlu, H
   Ozyurt, F
   Avci, E
AF Kutlu, Huseyin
   Ozyurt, Fatih
   Avci, Engin
TI A New Method Based on Convolutional Neural Networks and Discrete Wavelet
   Transform for Detection, Classification and Tracking of Colon Polyps in
   Colonoscopy Videos
SO TRAITEMENT DU SIGNAL
LA English
DT Article
DE CNN; DWT; SVM; faster R-CNN; colonoscopy; deep learning; polyp tracking;
   polyp detection; polyp classification
ID FEATURE-SELECTION
AB In this study, a new method based on Convolutional Neural Network (CNN), Discrete Wavelet Transform (DWT) and Support Vector Machine (SVM) is presented for polyp detection, classification and tracking during colonoscopy. The proposed method is constructed in 3 parts. 1) Detection of polyps with deep learning based Faster R-CNN for detection of polyps 2) Classification of detected polyps by CNN-DWT-SVM. 3) Tracking for polyps counting. The proposed method was trained and tested with the Colonoscopy Dataset, a public data set. In the first step of the method, polyp detection was carried out with pre-trained ResNet 50 CNN architecture with 92.6% precision. The regions identified in the second step of the method were classified for four classes adenoma, hyperplastic, lumen, serrated and 94.7% classification accuracy was obtained. With the proposed method, the detection sensitivity of Faster R-CNN was increased from 92.6% to 99.2%, and the accuracy of 95.4% was achieved by using DWT in the classification of polyp classes. In the classification process, 98% correct adenoma, 95% hyperplastic, 90% luminal intestine, 96% serrated polyp were reached. The proposed method reached an average of 94% MOTA in polyp tracking and was able to detect polyp frames with their classes with 99.2% precision.
C1 [Kutlu, Huseyin] Adiyaman Univ, Besni AE Voc Sch, Comp Tech Dept, TR-02300 Adiyaman, Turkiye.
   [Ozyurt, Fatih; Avci, Engin] Firat Univ, Software Engn Dept, TR-23119 Elazig, Turkiye.
C3 Adiyaman University; Firat University
RP Kutlu, H (通讯作者)，Adiyaman Univ, Besni AE Voc Sch, Comp Tech Dept, TR-02300 Adiyaman, Turkiye.
EM hkutlu@adiyaman.edu.tr
RI Özyurt, Fatih/W-4385-2018
OI Özyurt, Fatih/0000-0002-8154-6691
CR [Anonymous], 2008, EURASIP J IMAGE VIDE, P1, DOI [10.1155/2008/246309, DOI 10.1155/2008/246309]
   Azer SA, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55080473
   Bennet Jaison, 2014, ScientificWorldJournal, V2014, P195470, DOI 10.1155/2014/195470
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bishop Christopher M., 1996, NEURAL NETWORKS PATT
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Ferreira CA, 2018, LECT NOTES COMPUT SC, V10882, P763, DOI 10.1007/978-3-319-93000-8_86
   Girshick R., 2013, ARXIV, DOI 10.48550/arXiv.1311.2524
   Girshick R, 2015, Arxiv, DOI [arXiv:1504.08083, DOI 10.48550/ARXIV.1504.08083, 10.48550/arXiv.1504.08083]
   GROSSMANN A, 1984, SIAM J MATH ANAL, V15, P723, DOI 10.1137/0515056
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Huang G., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243
   IJspeert JEG, 2016, GUT, V65, P963, DOI 10.1136/gutjnl-2014-308411
   Julka M, 2011, PRIMARY CARE, V38, P449, DOI 10.1016/j.pop.2011.05.009
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kuhn H. W., 1955, NAV RES LOGISTICS, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]
   Kutlu H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091992
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Iandola FN, 2016, Arxiv, DOI [arXiv:1602.07360, 10.7717/peerj-cs.528/fig-8]
   Ozyurt F, 2020, J SUPERCOMPUT, V76, P8413, DOI 10.1007/s11227-019-03106-y
   Ozyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Ozyurt F, 2019, ARAB J SCI ENG, V44, P3173, DOI 10.1007/s13369-018-3454-1
   Phinyomark A, 2012, ELEKTRON ELEKTROTECH, V122, P27, DOI 10.5755/j01.eee.122.6.1816
   Qadir H. A., 2019, 2019 13 INT S MEDICA, P1, DOI [10.1109/ISMICT.2019.8743694, DOI 10.1109/ISMICT.2019.8743694]
   Raghu M., 2019, ADV NEUR IN
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Song QJ, 2017, EXPERT SYST APPL, V81, P22, DOI 10.1016/j.eswa.2017.02.049
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Sun GM, 2006, NEUROCOMPUTING, V69, P387, DOI 10.1016/j.neucom.2005.04.005
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Theckedath D., 2020, SOCIAL NETW COMPUT S, V1, P1, DOI [10.1007/S42979-020-0114-9/TABLES/5, DOI 10.1007/S42979-020-0114-9, 10.1007/s42979-020-0114-9]
   Too J, 2019, COMPUTATION, V7, DOI 10.3390/computation7010012
   Tuncer T, 2020, CHEMOMETR INTELL LAB, V203, DOI 10.1016/j.chemolab.2020.104054
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   VAPNIK V, 1994, NEURAL COMPUT, V6, P851, DOI 10.1162/neco.1994.6.5.851
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang J, 2004, COMB CHEM HIGH T SCR, V7, P783, DOI 10.2174/1386207043328274
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang XH, 2003, IEEE T NANOBIOSCI, V2, P190, DOI 10.1109/TNB.2003.816230
   Weston J, 2001, ADV NEUR IN, V13, P668
   Wosiak A, 2018, COMPLEXITY, DOI 10.1155/2018/2520706
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 52
TC 0
Z9 0
U1 1
U2 1
PU INT INFORMATION & ENGINEERING TECHNOLOGY ASSOC
PI EDMONTON
PA #2020, SCOTIA PLACE TOWER ONE, 10060 JASPER AVE, EDMONTON, AB T5J 3R8,
   CANADA
SN 0765-0019
EI 1958-5608
J9 TRAIT SIGNAL
JI Trait. Signal
PD FEB
PY 2023
VL 40
IS 1
BP 175
EP 186
DI 10.18280/ts.400116
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A8MV0
UT WOS:000957612200016
OA Bronze
DA 2023-08-21
ER

PT J
AU Lafraxo, S
   Souaidi, M
   Kerkaou, Z
   El Ansari, M
   Koutti, L
AF Lafraxo, Samira
   Souaidi, Meryem
   Kerkaou, Zakaria
   El Ansari, Mohamed
   Koutti, Lahcen
TI A Multiscale Polyp Detection Approach for GI Tract Images Based on
   Improved DenseNet and Single-Shot Multibox Detector
SO DIAGNOSTICS
LA English
DT Article
DE polyp; wireless capsule endoscopy images (WCE); single-shot multibox
   detector (SSD); image augmentation; multiscale DenseNet
ID WCE
AB Small bowel polyps exhibit variations related to color, shape, morphology, texture, and size, as well as to the presence of artifacts, irregular polyp borders, and the low illumination condition inside the gastrointestinal GI tract. Recently, researchers developed many highly accurate polyp detection models based on one-stage or two-stage object detector algorithms for wireless capsule endoscopy (WCE) and colonoscopy images. However, their implementation requires a high computational power and memory resources, thus sacrificing speed for an improvement in precision. Although the single-shot multibox detector (SSD) proves its effectiveness in many medical imaging applications, its weak detection ability for small polyp regions persists due to the lack of information complementary between features of low- and high-level layers. The aim is to consecutively reuse feature maps between layers of the original SSD network. In this paper, we propose an innovative SSD model based on a redesigned version of a dense convolutional network (DenseNet) which emphasizes multiscale pyramidal feature maps interdependence called DC-SSDNet (densely connected single-shot multibox detector). The original backbone network VGG-16 of the SSD is replaced with a modified version of DenseNet. The DenseNet-46 front stem is improved to extract highly typical characteristics and contextual information, which improves the model's feature extraction ability. The DC-SSDNet architecture compresses unnecessary convolution layers of each dense block to reduce the CNN model complexity. Experimental results showed a remarkable improvement in the proposed DC-SSDNet to detect small polyp regions achieving an mAP of 93.96%, F1-score of 90.7%, and requiring less computational time.
C1 [Lafraxo, Samira; Souaidi, Meryem; Kerkaou, Zakaria; El Ansari, Mohamed; Koutti, Lahcen] Univ Ibn Zohr, Fac Sci, LABSIV, Comp Sci, Agadir 80000, Morocco.
   [El Ansari, Mohamed] Univ Moulay Ismail, Fac Sci, Comp Sci Dept, Informat & Applicat Lab, Meknes 50070, Morocco.
C3 Ibn Zohr University of Agadir; Moulay Ismail University of Meknes
RP Souaidi, M (通讯作者)，Univ Ibn Zohr, Fac Sci, LABSIV, Comp Sci, Agadir 80000, Morocco.
EM souaidi.meryem@gmail.com
RI El Ansari, Mohamed/L-9738-2016; LAFRAXO, Samira/GXH-8925-2022
OI El Ansari, Mohamed/0000-0001-5394-9066; LAFRAXO,
   Samira/0000-0002-8876-3357
FU Ministry of National Education, Vocational Training, Higher Education
   and Scientific Research; Ministry of Industry, Trade and Green and
   Digital Economy, the Digital Development Agency (ADD); National Center
   for Scientific and Technical Research (CNRST) [ALKHAWARIZMI/2020/20]
FX This work was partially supported by the Ministry of National Education,
   Vocational Training, Higher Education and Scientific Research, the
   Ministry of Industry, Trade and Green and Digital Economy, the Digital
   Development Agency (ADD), and the National Center for Scientific and
   Technical Research (CNRST). Project number: ALKHAWARIZMI/2020/20.
CR Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Benhida Hamza, 2022, 2022 9th International Conference on Wireless Networks and Mobile Communications (WINCOM), P1, DOI 10.1109/WINCOM55661.2022.9966447
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen BL, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103019
   Chen XL, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/2144472
   Choi HT, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082842
   Dai JF, 2016, Arxiv, DOI arXiv:1605.06409
   Dai JF, 2016, ADV NEUR IN, V29
   Dulf EH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175704
   Fu C.-Y., 2017, ARXIV
   Girshick R., 2014, P IEEE C COMP VIS PA, P580, DOI DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jeong J, 2017, Arxiv, DOI [arXiv:1705.09587, DOI 10.5244/C.31.76]
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Krenzer A, 2023, J IMAGING, V9, DOI 10.3390/jimaging9020026
   Lafraxo S, 2020, INT C ADV INTELLIGEN, P887
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102052
   Ma W, 2020, IEEE ACCESS, V8, P188577, DOI 10.1109/ACCESS.2020.3031990
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Souaidi M., 2020, ADV INTELLIGENT SYST, P870
   Souaidi M., 2017, P 2017 INT C ADV TEC, P1
   Souaidi M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12082030
   Souaidi M, 2022, IEEE ACCESS, V10, P47124, DOI 10.1109/ACCESS.2022.3171238
   Souaidi M, 2019, IET IMAGE PROCESS, V13, P2233, DOI 10.1049/iet-ipr.2019.0415
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tashk A, 2020, IEEE C EVOL COMPUTAT
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang TC, 2022, ANAL METHODS-UK, V14, P508, DOI [10.1039/D1AY01726H, 10.1039/d1ay01726h]
   Wang YT, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235270
   We O., 2015, ETIS LARIB POLYP DB
   Zhai SP, 2020, IEEE ACCESS, V8, P24344, DOI 10.1109/ACCESS.2020.2971026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 45
TC 2
Z9 2
U1 6
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD FEB
PY 2023
VL 13
IS 4
AR 733
DI 10.3390/diagnostics13040733
PG 21
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 9I1UF
UT WOS:000939303200001
PM 36832221
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Puyal, JGB
   Brandao, P
   Ahmad, OF
   Bhatia, KAK
   Toth, D
   Kader, R
   Lovat, L
   Mountney, P
   Stoyanov, D
AF Puyal, Juana Gonzalez-Bueno
   Brandao, Patrick
   Ahmad, Omer F.
   Bhatia, K. anwal K.
   Toth, Daniel
   Kader, Rawen
   Lovat, Laurence
   Mountney, Peter
   Stoyanov, Danail
TI Spatio-temporal classification for polyp diagnosis
SO BIOMEDICAL OPTICS EXPRESS
LA English
DT Article
ID RECOGNITION; VALIDATION; SYSTEM
AB Colonoscopy remains the gold standard investigation for colorectal cancer screening as it offers the opportunity to both detect and resect pre-cancerous polyps. Computer-aided polyp characterisation can determine which polyps need polypectomy and recent deep learning-based approaches have shown promising results as clinical decision support tools. Yet polyp appearance during a procedure can vary, making automatic predictions unstable. In this paper, we investigate the use of spatio-temporal information to improve the performance of lesions classification as adenoma or non-adenoma. Two methods are implemented showing an increase in performance and robustness during extensive experiments both on internal and openly available benchmark datasets.
C1 [Puyal, Juana Gonzalez-Bueno; Ahmad, Omer F.; Kader, Rawen; Lovat, Laurence; Stoyanov, Danail] UCL, Wellcome EPSRC, Ctr Intervent & Surg Sci WEISS, London W1W 7TY, England.
   [Puyal, Juana Gonzalez-Bueno; Brandao, Patrick; Bhatia, K. anwal K.; Toth, Daniel; Mountney, Peter] Odin Vis, London W1W 7TY, England.
C3 University of London; University College London
RP Puyal, JGB (通讯作者)，UCL, Wellcome EPSRC, Ctr Intervent & Surg Sci WEISS, London W1W 7TY, England.; Puyal, JGB (通讯作者)，Odin Vis, London W1W 7TY, England.
EM j.puyal@ucl.ac.uk
RI Kader, Rawen/ABI-2203-2020; Lovat, Laurence/C-1986-2009
OI Kader, Rawen/0000-0001-9133-0838; Lovat, Laurence/0000-0003-4542-3915
FU Horizon 2020 Framework Programme [863146]; Royal Academy of Engineering
   [CiET1819\2\36]; Engineering and Physical Sciences Research Council
   [EP/P012841/1, EP/P027938/1, EP/R004080/1]; Wellcome/EPSRC Centre for
   Interventional and Surgical Sciences [203145Z/16/Z]
FX Horizon 2020 Framework Programme (863146) ; Royal Academy of Engineering
   (CiET1819\2\36) ; Engineering and Physical Sciences Research Council
   (EP/P012841/1, EP/P027938/1, EP/R004080/1) ; Wellcome/EPSRC Centre for
   Interventional and Surgical Sciences (203145Z/16/Z) .
CR Bano S, 2020, INT J COMPUT ASS RAD, V15, P791, DOI 10.1007/s11548-020-02169-0
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Czempiel Tobias, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P343, DOI 10.1007/978-3-030-59716-0_33
   Dayyeh B. K. A., 2015, GASTROINTEST ENDOSC, V81, P455
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fonolla R, 2019, I S BIOMED IMAGING, P74, DOI 10.1109/ISBI.2019.8759320
   Gao XJ, 2021, LECT NOTES COMPUT SC, V12904, P593, DOI 10.1007/978-3-030-87202-1_57
   Golhar M, 2021, IEEE ACCESS, V9, P631, DOI [10.1109/ACCESS.2020.3047544, 10.1109/access.2020.3047544]
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hamada Y, 2021, BMC GASTROENTEROL, V21, DOI 10.1186/s12876-021-01898-z
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Komeda Y., ONCOLOGY-BASEL, V93
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Livovsky DM, 2021, GASTROINTEST ENDOSC, V94, P1099, DOI 10.1016/j.gie.2021.06.021
   Mahmood F, 2018, Arxiv, DOI arXiv:1811.07407
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M., GASTROINTEST ENDOSC, V93, P3
   Mori Y., GASTROINTEST ENDOSC
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Patrun J, 2018, GASTROENT RES PRACT, V2018, DOI 10.1155/2018/7531368
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Puyal Juana Gonzalez-Bueno, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P295, DOI 10.1007/978-3-030-59725-2_29
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2009, AM J GASTROENTEROL, V104, P739, DOI 10.1038/ajg.2009.104
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Shafi A., 2020, INT J ELECT COMPUT E, V10, P2986
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Singh D., 2020, J AMBIENT INTELL HUM, V2, P8683
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Torch, 2019, PYTORCH RAND SAMPL
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Yengera G., 2018, ARXIV
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhang PF, 2019, PROC INT C TOOLS ART, P1252, DOI 10.1109/ICTAI.2019.00-93
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 42
TC 0
Z9 0
U1 0
U2 0
PU Optica Publishing Group
PI WASHINGTON
PA 2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA
SN 2156-7085
J9 BIOMED OPT EXPRESS
JI Biomed. Opt. Express
PD FEB 1
PY 2023
VL 14
IS 2
BP 593
EP 607
DI 10.1364/BOE.473446
PG 15
WC Biochemical Research Methods; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
GA L4SE5
UT WOS:001023172500001
PM 36874484
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Zhu, JB
   Ge, MF
   Chang, ZM
   Dong, WF
AF Zhu, Jianbo
   Ge, Mingfeng
   Chang, Zhimin
   Dong, Wenfei
TI CRCNet: Global-local context and multi-modality cross attention for
   polyp segmentation
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Deep learning; Colorectal cancer; Colonoscopy images; Convolutional
   neural network; Medical image segmentation
AB Accurate polyp segmentation is important for the diagnosis and treatment of colon cancer. In recent years, efforts have been made to improve the encoder-decoder framework by using global features and attention mechanisms to enhance feature extraction and help improve the segmentation of diverse polyps. However, few studies have considered the impacts of the polyp size, texture, and complex pathological environments on the segmentation performance. Considering the above challenges, this paper proposes a global-local feature-based encoder -decoder framework, named CRCNet comprising two components: a global-local context module (GLCM) and multi-modality cross attention (MMCA). The GLCM is responsible for capturing global and local information from all deep encoders, enabling accurate weighting of the context feature information for each region in the path-ological image. The MMCA is in charge of adding background, boundary, and foreground factors for judgment when merging shallow features while paying more attention to doubtful and complicated regions. We conducted extensive experiments on the Kvasir-SEG and CVC-ClinicDB datasets, CRCNet achieved state-of-the-art results in terms of segmentation accuracy and computational efficiency, with Dice and MIoU of 91.59 % and 90.57 % for Kvasir-SEG, respectively, and 95.02 % and 94.48 % for CVC-ClinicDB, respectively. Thus, CRCNet shows a significant improvement over the state-of-the-art method. The corresponding code is available at: https://github. com/1152067715/CRCNet.
C1 [Zhu, Jianbo; Dong, Wenfei] Shandong Univ Tradit Chinese Med, Sch Intelligence & Informat Engn, Jinan, Peoples R China.
   [Zhu, Jianbo; Ge, Mingfeng; Chang, Zhimin; Dong, Wenfei] Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Suzhou 215163, Peoples R China.
C3 Shandong University of Traditional Chinese Medicine; Chinese Academy of
   Sciences; Suzhou Institute of Biomedical Engineering & Technology, CAS
RP Ge, MF (通讯作者)，Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Suzhou 215163, Peoples R China.
EM gemf@sibet.ac.cn
RI zhu, jianbo/GQR-1845-2022
OI Zhu, Jianbo/0009-0008-3212-9737
FU National Key R & D Program of China [2021YFB3602200]
FX Acknowledgements This study was funded by the National Key R & D Program
   of China (No. 2021YFB3602200) .
CR Ali S., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2202.12031
   Ali S, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101900
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Biller LH, 2021, JAMA-J AM MED ASSOC, V325, P669, DOI 10.1001/jama.2021.0106
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Chen L., 2018, P EUROPEAN C COMPUTE
   Chen LC, 2017, Arxiv, DOI arXiv:1706.05587
   Cheng R, 2021, PROC CVPR IEEE, P12542, DOI 10.1109/CVPR46437.2021.01236
   Ciardiello F., 2022, CLIN MANAGEMENT META
   Du N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155371
   Fan D.-P., 2020, INT C MEDICAL IMAGE
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gross S., 2009, BILDVERARBEITUNG F R, P252
   He K., 2015, ABS151203385 CORR
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heidenreich JF, 2021, EUR J RADIOL, V141, DOI 10.1016/j.ejrad.2021.109817
   Hoerter Nicholas, 2020, Curr Treat Options Gastroenterol, DOI 10.1007/s11938-020-00274-2
   Hu J, 2018, 2018 IEEECVF C COMPU
   Hung TNK, 2022, MOL INFORM, V41, DOI 10.1002/minf.202100264
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Keshtkar K., 2021, CONVOLUTIONAL NEURAL
   Le A., 2021, INT J CLIN RES TRIAL, V6
   Le NQK, 2022, COMPUT BIOL CHEM, V99, DOI 10.1016/j.compbiolchem.2022.107732
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Pamudurthy Vijeta, 2020, Proc (Bayl Univ Med Cent), V33, P28, DOI 10.1080/08998280.2019.1686327
   Ronneberger O., 2015, P INT C MED IM COMP, P234, DOI [10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Sanchez-Peralta LF, 2022, ARTIF INTELL MED, P967
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P145, DOI 10.3322/caac.21601
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Tian Y, 2021, Arxiv, DOI arXiv:2101.03285
   Tomar NK, 2022, Arxiv, DOI [arXiv:2205.04280, 10.48550/arXiv.2205.04280, DOI 10.48550/ARXIV.2205.04280]
   Turner JK, 2013, EUR J GASTROEN HEPAT, V25, P562, DOI 10.1097/MEG.0b013e32835d1f2d
   Vosko S, 2021, CLIN GASTROENTEROL H, V19, P2425, DOI 10.1016/j.cgh.2021.05.017
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei J., 2021, SHALLOW ATTENTION NE
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao H., 2017, P IEEE C COMP VIS PA
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 45
TC 2
Z9 2
U1 27
U2 27
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD MAY
PY 2023
VL 83
AR 104593
DI 10.1016/j.bspc.2023.104593
EA JAN 2023
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 8N9DA
UT WOS:000925444400001
DA 2023-08-21
ER

PT J
AU Tavanapong, W
   Pratt, J
   Oh, J
   Khaleel, M
   Wong, JS
   de Groen, PC
AF Tavanapong, Wallapak
   Pratt, Jacob
   Oh, JungHwan
   Khaleel, Mohammed
   Wong, Johnny S.
   de Groen, Piet C.
TI Development and deployment of Computer-aided Real-Time feedback for
   improving quality of colonoscopy in a Multi-Center clinical trial
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Computer -aided analysis; Colonoscopy; Quality; Real-time feedback;
   Polyp detection rate
ID COLORECTAL-CANCER; ADENOMA DETECTION; RETROFLEXION; PREVENTION; VIDEOS;
   SYSTEM
AB Background and Objective: The quality of colonoscopy has been a subject of interest in the gastroenterology community for over two decades. High-quality colonoscopy leads to high polyp detection rates, reducing mor-tality associated with colorectal cancer. Methods: This paper describes the development and deployment of Endoscopic Multimedia Information System (EMIS), computer-aided software that provides real-time feedback on colonoscopy quality such as the endoscopist's techniques in inspecting the colon. On the contrary, most other software in this field aims to recognize polyps. The deployed version of EMIS includes new analysis components using Convolutional Neural Networks and new types of visual feedback. EMIS gives feedback only when an important change in the quality of the examination occurs. We present first-hand technical and operational challenges faced during our three-center trial and current solutions. Results: This work provides valuable in-formation for others attempting to implement real-time feedback in routine colonoscopy screening.
C1 [Tavanapong, Wallapak; Pratt, Jacob; Khaleel, Mohammed; Wong, Johnny S.] Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
   [Oh, JungHwan] Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76203 USA.
   [de Groen, Piet C.] Univ Minnesota, Div Gastroenterol Hepatol & Nutr, Minneapolis, MN 55455 USA.
C3 Iowa State University; University of North Texas System; University of
   North Texas Denton; University of Minnesota System; University of
   Minnesota Twin Cities
RP Pratt, J (通讯作者)，Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
EM tavanapo@iastate.edu; jrpratt@iastate.edu; junghwan.oh@unt.edu;
   mkhaleel@iastate.edu; wong@iastate.edu; degroen@umn.edu
FU National Institutes of Health (NIH) [1R01DK106130-01A1]
FX Funding This work was supported in part by the National Institutes of
   Health (NIH) [Grant No 1R01DK106130-01A1] . Data Statement Data used in
   this study is confidential.
CR Abadi M., 2015, P 12 USENIX C OPERAT, DOI [DOI 10.5555/3026877.3026899, DOI 10.1038/NN.3331]
   American Cancer Society, 2022, COL CANC STAT
   [Anonymous], 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   [Anonymous], MULTICENTRE OPEN LAB
   [Anonymous], KERAS PYTHON DEEP LE
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barua I., 2022, NEJM EVID, V1, pEVIDoa2200003, DOI [10.1056/EVIDoa2200003, DOI 10.1056/EVIDOA2200003]
   Cohen J, 2017, J CLIN GASTROENTEROL, V51, P818, DOI 10.1097/MCG.0000000000000695
   Enders F., 2014, RSF-RUS SAGE J SOC S, V146, pS, DOI 10.1016/S0016-5085(14)62641-X
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hanson JM, 2001, DIS COLON RECTUM, V44, P1706, DOI 10.1007/BF02234394
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Lee HS, 2017, ENDOSCOPY, V49, P334, DOI 10.1055/s-0042-119401
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Matei A, 2020, LECT NOTES ARTIF INT, V12344, P763, DOI 10.1007/978-3-030-61705-9_64
   Munzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   PyInstaller Development Team, PYINST DEV TEAM
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Srinivasan N, 2012, AM J GASTROENTEROL, V107, pS596, DOI 10.14309/00000434-201210001-01492
   Stanek SR, 2013, COMPUT METH PROG BIO, V112, P407, DOI 10.1016/j.cmpb.2013.07.028
   Stanek SR, 2012, COMPUT METH PROG BIO, V108, P524, DOI 10.1016/j.cmpb.2011.04.003
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tavanapong W, 2022, IEEE J BIOMED HEALTH, V26, P3950, DOI 10.1109/JBHI.2022.3160098
   Tavanapong W, 2020, COMP MED SY, P13, DOI 10.1109/CBMS49503.2020.00010
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang Y, 2013, IEEE J BIOMED HEALTH, V17, P143, DOI 10.1109/TITB.2012.2226595
   Wang Y, 2010, IEEE T BIO-MED ENG, V57, P685, DOI 10.1109/TBME.2009.2034466
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Xirasagar S, 2020, GASTROINTEST ENDOSC, V91, P905, DOI 10.1016/j.gie.2019.11.043
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang C., 2015, WORLDCOMP INT C IMAG, P308
NR 39
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD MAY
PY 2023
VL 83
AR 104609
DI 10.1016/j.bspc.2023.104609
EA JAN 2023
PG 13
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 8W7XB
UT WOS:000931539500001
DA 2023-08-21
ER

PT J
AU Sadagopan, R
   Ravi, S
   Adithya, SV
   Vivekanandhan, S
AF Sadagopan, Rajkumar
   Ravi, Saravanan
   Adithya, Sairam Vuppala
   Vivekanandhan, Sapthagirivasan
TI PolyEffNetV1: A CNN based colorectal polyp detection in colonoscopy
   images
SO PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART H-JOURNAL OF
   ENGINEERING IN MEDICINE
LA English
DT Article
DE Colonoscopy images; colon disorder; polyp; deep learning; artificial
   intelligence; GI tract
ID DIAGNOSIS; VALIDATION
AB Presence of polyps is the root cause of colorectal cancer, hence identification of such polyps at an early stage can help in advance treatments to avoid complications to the patient. Since there are variations in the size and shape of polyps, the task of detecting them in colonoscopy images becomes challenging. Hence our work is to leverage an algorithm for segmentation and classification of the polyp of colonoscopy images using Deep learning algorithms. In this work, we propose PolypEffNetV1, a U-Net to segment the different pathologies present in the colonoscopy frame and EfficientNetB5 to classify the detected pathologies. The colonoscopy images for the segmentation process are taken from the open-source dataset KVASIR, it consists of 1000 images with "ground truth" labeling. For classification, combination of KVASIR and CVC datasets are incorporated, which consists of 1612 images with 1696 polyp regions and 760 non-polyp inflamed regions. The proposed PolypEffNetV1 produced testing accuracy of 97.1%, Jaccard index of 0.84, dice coefficient of 0.91, and F1-score of 0.89. Subsequently, for classification to evidence whether the segmented region is polyp or non-polyp inflammation, the developed classifier produced validation accuracy of 99%, specificity of 98%, and sensitivity of 99%. Hence the proposed system could be used by gastroenterologists to identify the presence of polyp in the colonoscopy images/videos which will in turn increase healthcare quality. These developed models can be either deployed on the edge of the device to enable real-time aidance or can be integrated with existing software-application for offline review and treatment planning.
C1 [Sadagopan, Rajkumar; Ravi, Saravanan; Adithya, Sairam Vuppala; Vivekanandhan, Sapthagirivasan] Rajalakshmi Engn Coll, Dept Biomed Engn, Chennai, India.
   [Sadagopan, Rajkumar; Ravi, Saravanan; Adithya, Sairam Vuppala] Rajalakshmi Engn Coll, Ctr Excellence Med Imaging, Chennai, India.
   [Vivekanandhan, Sapthagirivasan] IT Serv Co, Med & Life Sci Dept, Engn R&D Div, Bengaluru, India.
   [Sadagopan, Rajkumar] Rajalakshmi Engn Coll Autonomous, Dept Biomed Engn, Chennai 602105, India.
C3 Rajalakshmi Engineering College; Rajalakshmi Engineering College;
   Rajalakshmi Engineering College
RP Sadagopan, R (通讯作者)，Rajalakshmi Engn Coll Autonomous, Dept Biomed Engn, Chennai 602105, India.
EM srk1670@gmail.com
OI V A, Sairam/0000-0003-0550-8244
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   American Cancer Society, 2022, KEY STAT COL CANC
   Bagheri M, 2019, IEEE ENG MED BIO, P6742, DOI 10.1109/EMBC.2019.8856793
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Fonolla R, 2019, I S BIOMED IMAGING, P74, DOI 10.1109/ISBI.2019.8759320
   Gross S., 2009, BILDVERARBEITUNG F R, P252
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   Guo YB, 2020, J IMAGING, V6, DOI 10.3390/jimaging6070069
   Hosseinzadeh Kassani Sara, 2020, Advances in Artificial Intelligence. 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12109), P290, DOI 10.1007/978-3-030-47358-7_29
   Hsu CM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21185995
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kim YJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83199-9
   Kingma D., 2015, ARXIV
   Kurniawan N, 2017, COMPUT STRUCT BIOTEC, V15, P168, DOI 10.1016/j.csbj.2017.01.004
   Lee H, 2022, PUBLIC MANAG REV, V24, P512, DOI 10.1080/14719037.2020.1846368
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Murata M, 2017, NINTH INTERNATIONAL CONFERENCES ON PERVASIVE PATTERNS AND APPLICATIONS (PATTERNS 2017), P109
   Nadeem S., 2016, ARXIV
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P112, DOI 10.1145/3083187.3083189
   Ratheesh A, 2016, INT CONF COMMUN SYST, P179, DOI 10.1109/CSN.2016.7824010
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sapthagirivasan V, 2013, COMPUT BIOL MED, V43, P1910, DOI 10.1016/j.compbiomed.2013.09.002
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [DOI 10.3322/caac.20073, 10.3322/caac.21442]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Viet SD., 2021, ARXIV
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
NR 39
TC 0
Z9 0
U1 5
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0954-4119
EI 2041-3033
J9 P I MECH ENG H
JI Proc. Inst. Mech. Eng. Part H-J. Eng. Med.
PD MAR
PY 2023
VL 237
IS 3
BP 406
EP 418
DI 10.1177/09544119221149233
EA JAN 2023
PG 13
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA A1BB4
UT WOS:000919998300001
PM 36683465
DA 2023-08-21
ER

PT J
AU Wei, X
   Ye, FH
   Wan, H
   Xu, JF
   Min, WD
AF Wei, Xin
   Ye, Fanghua
   Wan, Huan
   Xu, Jianfeng
   Min, Weidong
TI TANet: Triple Attention Network for medical image segmentation
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Attention mechanism; Deep learning; Medical image processing; Image
   segmentation
ID CLASSIFICATION; CONTEXT
AB In recent years, deep learning-based methods have achieved remarkable progress in medical image processing, like polyp segmentation in colonoscopy images and skin lesion segmentation in dermoscopy images. However, the current state-of-the-art medical segmentation methods still suffer from the problem of low accuracy in segmenting the small-scale and variable-scale objects. To solve this problem, we propose Triple Attention Network (TANet). In TANet, a novel Triple Attention Module (TAM) is presented. TAM has two sub-modules: Multi-scale Feature Selection Module (MFSM) and Contextual Feature Extraction Module (CFEM). MFSM is used to extract more adaptable multi-scale features for capturing variable-scale objects, while CFEM is for capturing small-scale objects by extracting contextual features. TAM aims to combine MFSM and CFEM to finally enhance the segmentation performance of the medical images with the small-scale and variable-scale lesions. Extensive experiments are conducted on five polyp datasets and one skin lesion dataset. Results show that the proposed models outperform the previous state-of-the-art models on most evaluation metrics and improve the Dice score by up to 7.1%. All results consistently confirm the effectiveness of the proposed TANet and show that the TANet achieves state-of-the-art performance on the above datasets.
C1 [Wei, Xin; Ye, Fanghua; Xu, Jianfeng] Nanchang Univ, Sch Software, 235 East Nanjing Rd, Nanchang 330047, Peoples R China.
   [Wan, Huan] Jiangxi Normal Univ, Sch Comp Informat Engn, 99 Ziyang Ave, Nanchang 330022, Peoples R China.
   [Xu, Jianfeng] Nanchang Kindly KDL Med Technol Co Ltd, 77 North Aixihu Rd, Nanchang 330096, Peoples R China.
   [Min, Weidong] Nanchang Univ, Inst Metaverse, Sch Math & Comp Sci, Jiangxi Key Lab Smart City, 999 Xuefu Ave, Nanchang 330047, Peoples R China.
C3 Nanchang University; Jiangxi Normal University; Nanchang University
RP Min, WD (通讯作者)，Nanchang Univ, Inst Metaverse, Sch Math & Comp Sci, Jiangxi Key Lab Smart City, 999 Xuefu Ave, Nanchang 330047, Peoples R China.
EM minweidong@ncu.edu.cn
RI Min, Weidong/D-4585-2017
OI Min, Weidong/0000-0003-2526-2181; Wei, Xin/0000-0003-0976-3381
FU National Natural Science Foundation of China [62106093, 62076117,
   62106090]; Jiangxi Key Laboratory of Smart City [20192BCD40002];
   Technical Leaders in Major Disciplines-Leading Talents Project
   [20223BCJ25026]; Urgent Need for Overseas Talent and Jiangxi Training
   Program for Academic;  [20225BCJ22016];  [20223BCJ25040]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 62106093, 62076117, 62106090) , Jiangxi Key Laboratory
   of Smart City (Grant No. 20192BCD40002) , the Urgent Need for Overseas
   Talent project (Grant No. 20223BCJ25040, 20223BCJ25026) and Jiangxi
   Training Program for Academic and the Technical Leaders in Major
   Disciplines-Leading Talents Project (Grant No. 20225BCJ22016) .
CR Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   Azad R, 2019, IEEE INT CONF COMP V, P406, DOI 10.1109/ICCVW.2019.00052
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen J., 2021, ARXIV
   Chen LC, 2017, Arxiv, DOI arXiv:1706.05587
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843, DOI DOI 10.5555/2999325.2999452
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Ding L, 2020, IEEE T IMAGE PROCESS, V29, P6561, DOI 10.1109/TIP.2020.2991530
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Hu J., 2017, PROC IEEE C COMPUT V, P7132, DOI DOI 10.1109/CVPR.2018.00745
   Huang C.-H., 2021, ARXIV
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jin QG, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106881
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Long ZL, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106765
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Nardelli P, 2018, IEEE T MED IMAGING, V37, P2428, DOI 10.1109/TMI.2018.2833385
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Poudel S, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107445
   Poudel S, 2020, IEEE ACCESS, V8, P99227, DOI 10.1109/ACCESS.2020.2996770
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Qin Y, 2018, LECT NOTES COMPUT SC, V11072, P603, DOI 10.1007/978-3-030-00931-1_69
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saha M, 2018, IEEE T IMAGE PROCESS, V27, P2189, DOI 10.1109/TIP.2018.2795742
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Shen T, 2018, AAAI CONF ARTIF INTE, P5446
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sun W, 2019, Arxiv, DOI arXiv:1901.06322
   Ta N, 2022, MULTIMEDIA SYST, DOI 10.1007/s00530-022-00900-2
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tong XZ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11030501
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wang JB, 2018, INT C PATT RECOG, P2337, DOI 10.1109/ICPR.2018.8545891
   Wang Y, 2018, LECT NOTES COMPUT SC, V11073, P523, DOI 10.1007/978-3-030-00937-3_60
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wu HS, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102327
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Zhang JW, 2018, Arxiv, DOI [arXiv:1812.00352, 10.1007/s13755-022-00204-9, DOI 10.48550/ARXIV.1812.00352]
   Zhang J, 2017, IEEE T IMAGE PROCESS, V26, P4753, DOI 10.1109/TIP.2017.2721106
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang LH, 2017, IEEE T PATTERN ANAL, V39, P1892, DOI 10.1109/TPAMI.2016.2609426
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou SH, 2020, IEEE T IMAGE PROCESS, V29, P461, DOI 10.1109/TIP.2019.2919937
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 71
TC 0
Z9 0
U1 33
U2 33
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD APR
PY 2023
VL 82
AR 104608
DI 10.1016/j.bspc.2023.104608
EA JAN 2023
PG 12
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 8P1CG
UT WOS:000926267100001
DA 2023-08-21
ER

PT J
AU Xu, H
   Tang, RSY
   Lam, TYT
   Zhao, GJ
   Lau, JYW
   Liu, YP
   Wu, Q
   Rong, L
   Xu, WR
   Li, X
   Wong, SH
   Cai, ST
   Wang, J
   Liu, GY
   Ma, TT
   Liang, X
   Mak, JWY
   Xu, HZ
   Yuan, P
   Cao, TT
   Li, FD
   Ye, ZS
   Shutian, Z
   Sung, JJY
AF Xu, Hong
   Tang, Raymond S. Y.
   Lam, Thomas Y. T.
   Zhao, Guijun
   Lau, James Y. W.
   Liu, Yunpeng
   Wu, Qi
   Rong, Long
   Xu, Weiran
   Li, Xue
   Wong, Sunny H.
   Cai, Shuntian
   Wang, Jing
   Liu, Guanyi
   Ma, Tantan
   Liang, Xiong
   Mak, Joyce W. Y.
   Xu, Hongzhi
   Yuan, Peng
   Cao, Tingting
   Li, Fudong
   Ye, Zhenshi
   Shutian, Zhang
   Sung, Joseph J. Y.
TI Artificial Intelligence-Assisted Colonoscopy for Colorectal Cancer
   Screening: A Multicenter Randomized Controlled Trial
SO CLINICAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE Artificial Intelligence; Colonoscopy; Colorectal Cancer Screening
ID ADENOMA DETECTION; RISK; POLYPECTOMY; SYSTEM
AB BACKGROUND AND AIMS: Artificial intelligence (AI)-assisted colonoscopy improves polyp detection and characterization in colonoscopy. However, data from large-scale multicenter randomized controlled trials (RCT) in an asymptomatic population are lacking.METHODS: This multicenter RCT aimed to compare AI-assisted colonoscopy with conventional colonoscopy for adenoma detection in an asymptomatic population. Asymptomatic subjects 45-75 years of age undergoing colorectal cancer screening by direct colonoscopy or fecal immunochemical test were recruited in 6 referral centers in Hong Kong, Jilin, Inner Mongolia, Xiamen, and Beijing. In the AI-assisted colonoscopy, an AI polyp detection system (Eagle-Eye) with real-time notifica-tion on the same monitor of the endoscopy system was used. The primary outcome was overall adenoma detection rate (ADR). Secondary outcomes were mean number of adenomas per co-lonoscopy, ADR according to endoscopist's experience, and colonoscopy withdrawal time. This study received Institutional Review Board approval (CRE-2019.393).RESULTS: From November 2019 to August 2021, 3059 subjects were randomized to AI-assisted colo-noscopy (n = 1519) and conventional colonoscopy (n = 1540). Baseline characteristics and bowel preparation quality between the 2 groups were similar. The overall ADR (39.9% vs 32.4%; P < .001), advanced ADR (6.6% vs 4.9%; P = .041), ADR of expert (42.3% vs 32.8%; P < .001) and nonexpert endoscopists (37.5% vs 32.1%; P = .023), and adenomas per colonoscopy (0.59 +/- 0.97 vs 0.45 +/- 0.81; P < .001) were all significantly higher in the AI-assisted colonos-copy. The median withdrawal time (8.3 minutes vs 7.8 minutes; P = .004) was slightly longer in the AI-assisted colonoscopy group.CONCLUSIONS: In this multicenter RCT in asymptomatic patients, AI-assisted colonoscopy improved overall ADR, advanced ADR, and ADR of both expert and nonexpert attending endoscopists. (ClinicalTrials.gov, Number: NCT04422548).
C1 [Xu, Hong; Xu, Weiran; Ma, Tantan; Cao, Tingting; Li, Fudong] First Hosp Jilin Univ, Dept Gastroenterol, Changchun, Jilin, Peoples R China.
   [Xu, Hong; Xu, Weiran; Ma, Tantan; Cao, Tingting; Li, Fudong] First Hosp Jilin Univ, Endoscopy Ctr, Changchun, Jilin, Peoples R China.
   [Tang, Raymond S. Y.; Wong, Sunny H.; Mak, Joyce W. Y.; Sung, Joseph J. Y.] Chinese Univ Hong Kong, Dept Med & Therapeut, Hong Kong, Peoples R China.
   [Tang, Raymond S. Y.; Lam, Thomas Y. T.; Lau, James Y. W.; Wong, Sunny H.; Mak, Joyce W. Y.; Sung, Joseph J. Y.] Chinese Univ Hong Kong, Inst Digest Dis, Hong Kong, Peoples R China.
   [Lam, Thomas Y. T.] Chinese Univ Hong Kong, JC Sch Publ Hlth & Primary Care, Hong Kong, Peoples R China.
   [Lam, Thomas Y. T.; Sung, Joseph J. Y.] Chinese Univ Hong Kong, Stanley Ho Big Data Decis Analyt Res Ctr, Hong Kong, Peoples R China.
   [Zhao, Guijun; Li, Xue; Liang, Xiong] Inner Mongolia Peoples Hosp, Dept Endoscopy Ctr, Inner Mongolia Key Lab Endoscop Digest Dis, Hohhot, Peoples R China.
   [Lau, James Y. W.] Chinese Univ Hong Kong, Dept Surg, Hong Kong, Peoples R China.
   [Liu, Yunpeng; Cai, Shuntian; Xu, Hongzhi; Ye, Zhenshi] Xiamen Univ, Zhongshan Hosp, Dept Gastroenterol, Xiamen, Peoples R China.
   [Wu, Qi; Wang, Jing; Yuan, Peng] Peking Univ Canc Hosp & Inst, Endoscopy Ctr, Key Lab Carcinogenesis & Translat Res, Minist Educ Beijing, Beijing, Peoples R China.
   [Rong, Long; Liu, Guanyi] Peking Univ First Hosp, Endoscopy Ctr, Beijing, Peoples R China.
   [Shutian, Zhang] Capital Med Univ, Beijing Friendship Hosp, Natl Clin Res Ctr Digest Dis, Dept Gastroenterol & Hepatol, Beijing, Peoples R China.
   [Wong, Sunny H.; Sung, Joseph J. Y.] Nanyang Technol Univ, Lee Kong Chian Sch Med, Nanyang, Singapore.
C3 Jilin University; Jilin University; Chinese University of Hong Kong;
   Chinese University of Hong Kong; Chinese University of Hong Kong;
   Chinese University of Hong Kong; Chinese University of Hong Kong; Xiamen
   University; Capital Medical University; Nanyang Technological University
   & National Institute of Education (NIE) Singapore; Nanyang Technological
   University
RP Sung, JJY (通讯作者)，Nanyang Technol Univ, Lee Kong Chian Sch Med, Nanyang, Singapore.
EM josephsung@ntu.edu.sg
RI Lam, Thomas Yuen Tung/ACR-1816-2022; Tang, Raymond/AED-4572-2022
OI Lam, Thomas Yuen Tung/0000-0002-4306-4990; 
CR Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2017, GUT, V66, P1949, DOI 10.1136/gutjnl-2016-311906
   Kamba S, 2021, GASTROINTEST ENDOSC, V93, pAB195
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lui RN, 2021, J GASTROEN HEPATOL, V36, P1656, DOI 10.1111/jgh.15368
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Meester RGS, 2020, GASTROENTEROLOGY, V159, P105, DOI 10.1053/j.gastro.2020.03.025
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Morris EJA, 2015, GUT, V64, P1248, DOI 10.1136/gutjnl-2014-308362
   Ng SC, 2012, AM J GASTROENTEROL, V107, P1165, DOI 10.1038/ajg.2012.135
   Pohl H, 2021, ANN INTERN MED, V174, P1377, DOI 10.7326/M20-6689
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Rodriguez-Ruiz A, 2019, JNCI-J NATL CANCER I, V111, P916, DOI 10.1093/jnci/djy222
   Singh H, 2006, JAMA-J AM MED ASSOC, V295, P2366, DOI 10.1001/jama.295.20.2366
   Song MY, 2020, LANCET GASTROENTEROL, V5, P537, DOI 10.1016/S2468-1253(20)30009-1
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tang RSY, 2022, CLIN GASTROENTEROL H, V20, P372, DOI 10.1016/j.cgh.2020.10.014
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wieszczy P, 2021, GASTROENTEROLOGY, V160, P1067, DOI 10.1053/j.gastro.2020.10.009
   Wong JCT, 2019, GASTROINTEST ENDOSC, V89, P607, DOI 10.1016/j.gie.2018.11.014
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 27
TC 8
Z9 8
U1 3
U2 9
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1542-3565
EI 1542-7714
J9 CLIN GASTROENTEROL H
JI Clin. Gastroenterol. Hepatol.
PD FEB
PY 2023
VL 21
IS 2
DI 10.1016/j.cgh.2022.07.006
EA JAN 2023
PG 13
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 8P2CP
UT WOS:000926335700001
PM 35863686
OA hybrid
DA 2023-08-21
ER

PT J
AU Lewis, J
   Cha, YJ
   Kim, J
AF Lewis, John
   Cha, Young-Jin
   Kim, Jongho
TI Dual encoder-decoder-based deep polyp segmentation network for
   colonoscopy images
SO SCIENTIFIC REPORTS
LA English
DT Article
ID OUTCOMES
AB Detection of colorectal polyps through colonoscopy is an essential practice in prevention of colorectal cancers. However, the method itself is labor intensive and is subject to human error. With the advent of deep learning-based methodologies, and specifically convolutional neural networks, an opportunity to improve upon the prognosis of potential patients suffering with colorectal cancer has appeared with automated detection and segmentation of polyps. Polyp segmentation is subject to a number of problems such as model overfitting and generalization, poor definition of boundary pixels, as well as the model's ability to capture the practical range in textures, sizes, and colors. In an effort to address these challenges, we propose a dual encoder-decoder solution named Polyp Segmentation Network (PSNet). Both the dual encoder and decoder were developed by the comprehensive combination of a variety of deep learning modules, including the PS encoder, transformer encoder, PS decoder, enhanced dilated transformer decoder, partial decoder, and merge module. PSNet outperforms state-of-the-art results through an extensive comparative study against 5 existing polyp datasets with respect to both mDice and mIoU at 0.863 and 0.797, respectively. With our new modified polyp dataset we obtain an mDice and mIoU of 0.941 and 0.897 respectively.
C1 [Lewis, John; Cha, Young-Jin] Univ Manitoba, Dept Civil Engn, Winnipeg, MB R3M 0N2, Canada.
   [Kim, Jongho] Univ Manitoba, Max Rady Coll Med, Dept Radiol, Winnipeg, MB R3A 1R9, Canada.
C3 University of Manitoba; University of Manitoba
RP Cha, YJ (通讯作者)，Univ Manitoba, Dept Civil Engn, Winnipeg, MB R3M 0N2, Canada.
EM young.cha@umanitoba.ca
OI Kim, Jongho/0000-0002-8749-0932
FU Research Manitoba Innovation Proof-of-Concept Grant [4914]; CFI JELF
   Grant [37394]
FX AcknowledgementsThis research was partially supported by a Research
   Manitoba Innovation Proof-of-Concept Grant (4914), and a CFI JELF Grant
   (37394).
CR Ali R, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104412
   Ali S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59413-5
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Choi W, 2020, IEEE T IND ELECTRON, V67, P8016, DOI 10.1109/TIE.2019.2945265
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong X., 2022, PROC IEEECVF C COMPU, P12124
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Galdran Adrian, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P293, DOI 10.1007/978-3-030-68763-2_22
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Jaccard P., 1912, NEW PHYTOL, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Kang D., 2021, DATA SCI ENG, V9, P123
   Kang D, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103291
   Kang DH, 2018, COMPUT-AIDED CIV INF, V33, P885, DOI 10.1111/mice.12375
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Matsuda T, 2015, JPN J CLIN ONCOL, V45, P900, DOI 10.1093/jjco/hyv117
   Morris M, 2007, MED J AUSTRALIA, V186, P296, DOI 10.5694/j.1326-5377.2007.tb00904.x
   Pozdeev A.A., 2020, 2019 IEEE EIC
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song PF, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105476
   Srivastava A., 2022, ICPR 2022
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Tomar NK, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3159394
   Vaswani A., 2017, ARXIV
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang Y, 2020, IEEE T MED IMAGING, V39, P866, DOI 10.1109/TMI.2019.2936500
   Wei J., 2021, MICCAI 2021
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YH, 2021, Arxiv, DOI arXiv:2110.09408
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang Y., 2021, MICCAI 2021
   Zhao X., 2021, MICCAI 2021
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 43
TC 5
Z9 5
U1 8
U2 9
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JAN 21
PY 2023
VL 13
IS 1
DI 10.1038/s41598-023-28530-2
PG 12
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA A5UQ9
UT WOS:000955774100024
PM 36681776
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Lui, TKL
   Hang, DV
   Tsao, SKK
   Hui, CKY
   Mak, LLY
   Ko, MKL
   Cheung, KS
   Thian, MY
   Liang, R
   Tsui, VWM
   Yeung, CK
   Dao, LV
   Leung, WK
AF Lui, Thomas K. L.
   Hang, Dao Viet
   Tsao, Stephen K. K.
   Hui, Cynthia K. Y.
   Mak, Loey Lung Yi
   Ko, Michael K. L.
   Cheung, Ka Shing
   Thian, M. Y.
   Liang, R.
   Tsui, Vivien W. M.
   Yeung, Chung Kwong
   Dao, L. V.
   Leung, Wai K.
TI Computer-assisted detection versus conventional colonoscopy for proximal
   colonic lesions: a multicenter, randomized, tandem-colonoscopy study
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID ARTIFICIAL-INTELLIGENCE; SCREENING COLONOSCOPY; ADENOMA DETECTION; AIDED
   DETECTION; NARROW-BAND; YOUNG-ADULTS; POLYPS; SYSTEM
AB Background and Aims: Computer-assisted detection (CADe) is a promising technologic advance that enhances adenoma detection during colonoscopy. However, the role of CADe in reducing missed colonic lesions is uncertain. The aim of this study was to determine the miss rates of proximal colonic lesions by CADe and conventional colonoscopy.
   Methods: This was a prospective, multicenter, randomized, tandem-colonoscopy study conducted in 3 Asian centers. Patients were randomized to receive CADe or conventional white-light colonoscopy during the first withdrawal of the proximal colon (cecum to splenic flexure), immediately followed by tandem examination of the proximal colon with white light in both groups. The primary outcome was adenoma/polyp miss rate, which was defined as any adenoma/polyp detected during the second examination.
   Results: Of 223 patients (48.6% men; median age, 63 years) enrolled, 7 patients did not have tandem examination, leaving 108 patients in each group. There was no difference in the miss rate for proximal adenomas (CADe vs conventional: 20.0% vs 14.0%, P = .07) and polyps (26.7% vs 19.6%, P = .06). The CADe group, however, had significantly higher proximal polyp (58.0% vs 46.7%, P = .03) and adenoma (44.7% vs 34.6%, P = .04) detection rates than the conventional group. The mean number of proximal polyps and adenomas detected per patient during the first examination was also significantly higher in the CADe group (polyp: 1.20 vs .86, P = .03; adenoma, .91 vs .61, P = .03). Subgroup analysis showed that CADe enhanced proximal adenoma detection in patients with fair bowel preparation, shorter withdrawal time, and endoscopists with lower adenoma detection rate.
   Conclusions: This multicenter trial from Asia confirmed that CADe can further enhance proximal adenoma and polyp detection but may not be able to reduce the number of missed proximal colonic lesions.
C1 [Lui, Thomas K. L.; Hui, Cynthia K. Y.; Mak, Loey Lung Yi; Ko, Michael K. L.; Cheung, Ka Shing; Tsui, Vivien W. M.; Leung, Wai K.] Univ Hong Kong, Queen Mary Hosp, Dept Med, Hong Kong, Peoples R China.
   [Yeung, Chung Kwong] Univ Hong Kong, Dept Surg, Hong Kong, Peoples R China.
   [Hang, Dao Viet] Hanoi Med Univ, Internal Med Fac, Hanoi, Vietnam.
   [Tsao, Stephen K. K.; Thian, M. Y.; Liang, R.] Tan Tock Seng Hosp, Dept Gastroenterol & Hepatol, Singapore, Singapore.
   [Dao, L. V.] Inst Gastroenterol & Hepatol, Hanoi, Vietnam.
   [Leung, Wai K.] Queen Mary Hosp, Dept Med, 4-F Professorial Block,102 Pokfulam Rd, Hong Kong, Peoples R China.
C3 University of Hong Kong; University of Hong Kong; Hanoi Medical
   University; Tan Tock Seng Hospital; University of Hong Kong
RP Leung, WK (通讯作者)，Queen Mary Hosp, Dept Med, 4-F Professorial Block,102 Pokfulam Rd, Hong Kong, Peoples R China.
OI Liang, Raymond/0000-0002-2280-5278; Lui, Ka Luen,
   Thomas/0000-0002-2986-3681; Dao Viet, Hang/0000-0002-3685-9496
CR Adler A, 2008, GUT, V57, P59, DOI 10.1136/gut.2007.123539
   Adler A, 2009, GASTROENTEROLOGY, V136, P410, DOI 10.1053/j.gastro.2008.10.022
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Cha JM, 2015, GASTROINTEST ENDOSC, V82, P138, DOI 10.1016/j.gie.2014.12.050
   Deliwala SS, 2021, INT J COLORECTAL DIS, V36, P2291, DOI 10.1007/s00384-021-03929-3
   Fitzmaurice C, 2018, J CLIN ONCOL, V36, DOI 10.1200/JCO.2018.36.15_suppl.1568
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Hong SN, 2012, CLIN ENDOSC, V45, P404, DOI 10.5946/ce.2012.45.4.404
   Huang D, 2022, INT J COLORECTAL DIS, V37, P495, DOI 10.1007/s00384-021-04062-x
   Ikematsu H, 2012, J GASTROENTEROL, V47, P1099, DOI 10.1007/s00535-012-0575-2
   Inoue T, 2008, J GASTROENTEROL, V43, P45, DOI 10.1007/s00535-007-2125-x
   Jellema P, 2010, BMJ-BRIT MED J, V340, DOI 10.1136/bmj.c1269
   Jung Y, 2019, GASTROINTEST ENDOSC, V89, P523, DOI 10.1016/j.gie.2018.09.016
   Lin T.-Y., 2014, EUR C COMP VIS, P740
   Lu R, 2020, DIGEST DIS, V38, P484, DOI 10.1159/000506073
   Lui TKL, 2021, GASTROINTEST ENDOSC, V93, P193, DOI 10.1016/j.gie.2020.04.066
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Nagtegaal ID, 2020, HISTOPATHOLOGY, V76, P182, DOI 10.1111/his.13975
   Ngan R, 2016, OVERVIEW HONG KONG C
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Singh B, 2018, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2018.00119
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Wallace MB, 2022, GASTROENTEROLOGY, V163, P295, DOI 10.1053/j.gastro.2022.03.007
   Wang AL, 2021, ANN TRANSL MED, V9, DOI 10.21037/atm-21-5081
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 33
TC 1
Z9 1
U1 1
U2 1
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD FEB
PY 2023
VL 97
IS 2
DI 10.1016/j.gie.2022.09.020
EA JAN 2023
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 8O6MI
UT WOS:000925948700001
PM 36208795
DA 2023-08-21
ER

PT J
AU Kader, R
   Cid-Mejias, A
   Brandao, P
   Islam, S
   Hebbar, S
   Puyal, JGB
   Ahmad, OF
   Hussein, M
   Toth, D
   Mountney, P
   Seward, E
   Vega, R
   Stoyanov, D
   Lovat, LB
AF Kader, Rawen
   Cid-Mejias, Anton
   Brandao, Patrick
   Islam, Shahraz
   Hebbar, Sanjith
   Puyal, Juana Gonzalez-Bueno
   Ahmad, Omer F.
   Hussein, Mohamed
   Toth, Daniel
   Mountney, Peter
   Seward, Ed
   Vega, Roser
   Stoyanov, Danail
   Lovat, Laurence B.
TI Polyp characterization using deep learning and a publicly accessible
   polyp video database
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE artificial intelligence; colonic polyp; colonoscopy; colorectal
   neoplasm; deep learning
ID ARTIFICIAL-INTELLIGENCE; COLORECTAL POLYPS; CLASSIFICATION; SOCIETY;
   CANCER; POLYPECTOMY
AB ObjectivesConvolutional neural networks (CNN) for computer-aided diagnosis of polyps are often trained using high-quality still images in a single chromoendoscopy imaging modality with sessile serrated lesions (SSLs) often excluded. This study developed a CNN from videos to classify polyps as adenomatous or nonadenomatous using standard narrow-band imaging (NBI) and NBI-near focus (NBI-NF) and created a publicly accessible polyp video database. MethodsWe trained a CNN with 16,832 high and moderate quality frames from 229 polyp videos (56 SSLs). It was evaluated with 222 polyp videos (36 SSLs) across two test-sets. Test-set I consists of 14,320 frames (157 polyps, 111 diminutive). Test-set II, which is publicly accessible, 3317 video frames (65 polyps, 41 diminutive), which was benchmarked with three expert and three nonexpert endoscopists. ResultsSensitivity for adenoma characterization was 91.6% in test-set I and 89.7% in test-set II. Specificity was 91.9% and 88.5%. Sensitivity for diminutive polyps was 89.9% and 87.5%; specificity 90.5% and 88.2%. In NBI-NF, sensitivity was 89.4% and 89.5%, with a specificity of 94.7% and 83.3%. In NBI, sensitivity was 85.3% and 91.7%, with a specificity of 87.5% and 90.0%, respectively. The CNN achieved preservation and incorporation of valuable endoscopic innovations (PIVI)-1 and PIVI-2 thresholds for each test-set. In the benchmarking of test-set II, the CNN was significantly more accurate than nonexperts (13.8% difference [95% confidence interval 3.2-23.6], P = 0.01) with no significant difference with experts. ConclusionsA single CNN can differentiate adenomas from SSLs and hyperplastic polyps in both NBI and NBI-NF. A publicly accessible NBI polyp video database was created and benchmarked.
C1 [Kader, Rawen; Islam, Shahraz; Puyal, Juana Gonzalez-Bueno; Ahmad, Omer F.; Hussein, Mohamed; Stoyanov, Danail; Lovat, Laurence B.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, London, England.
   [Kader, Rawen; Islam, Shahraz; Ahmad, Omer F.; Hussein, Mohamed; Seward, Ed; Vega, Roser; Lovat, Laurence B.] UCL, Div Surg & Intervent Sci, London, England.
   [Kader, Rawen; Ahmad, Omer F.; Hussein, Mohamed; Seward, Ed; Vega, Roser; Lovat, Laurence B.] Univ Coll London Hosp, Gastrointestinal Serv, London, England.
   [Cid-Mejias, Anton; Brandao, Patrick; Hebbar, Sanjith; Puyal, Juana Gonzalez-Bueno; Toth, Daniel; Mountney, Peter] Odin Vis Ltd, London, England.
   [Kader, Rawen] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, Charles Bell House,43-45 Foley St, London W1W 7TS, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London; University of London; University College London; University
   College London Hospitals NHS Foundation Trust; UK Research & Innovation
   (UKRI); Engineering & Physical Sciences Research Council (EPSRC);
   University of London; University College London
RP Kader, R (通讯作者)，UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, Charles Bell House,43-45 Foley St, London W1W 7TS, England.
EM rawen.kader.17@ucl.ac.uk
RI Kader, Rawen/ABI-2203-2020; Lovat, Laurence/C-1986-2009
OI Kader, Rawen/0000-0001-9133-0838; Lovat, Laurence/0000-0003-4542-3915
FU Wellcome/EPSRC Centre for Interventional and Surgical Sciences at UCL
   [203145Z/16/Z]; Innovate UK [26673]; National Institute for Health
   Research University College London Hospitals Biomedical Research Centre;
   CRUK Experimental Cancer Medicine Centre at UCL
FX THIS STUDY WAS supported by the Wellcome/EPSRC Centre for Interventional
   and Surgical Sciences at UCL(203145Z/16/Z) and Innovate UK (26673).
   Author L.B.L. is supported by the National Institute for Health Research
   University College London Hospitals Biomedical Research Centre and the
   CRUK Experimental Cancer Medicine Centre at UCL
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Biffi C, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00633-6
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Gupta S, 2020, GASTROENTEROLOGY, V158, P1131, DOI 10.1053/j.gastro.2019.10.026
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kader R, 2021, WORLD J GASTROENTERO, V27, DOI [10.3748/wjg.v27.i35.5908ISSN, 10.3748/wjg.v27.i35.5908]
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lagendijk RL, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P323, DOI 10.1016/B978-0-12-374457-9.00014-7
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Minegishi Y, 2022, GASTROENTEROLOGY, V163, P323, DOI 10.1053/j.gastro.2022.03.053
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Mori Y, 2019, GASTROINTEST ENDOSC, V89, P816, DOI 10.1016/j.gie.2018.12.019
   Nagtegaal ID, 2020, HISTOPATHOLOGY, V76, P182, DOI 10.1111/his.13975
   Podlasek J, 2021, ENDOSC INT OPEN, V09, pE741, DOI 10.1055/a-1388-6735
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Rex DK, 2020, TECH INNOVAT GASTROI, V22, P52, DOI 10.1016/j.tgie.2019.150638
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Rutter MD, 2020, GUT, V69, P201, DOI 10.1136/gutjnl-2019-319858
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   van der Zander QEW, 2021, ENDOSCOPY, V53, P1219, DOI 10.1055/a-1343-1597
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
NR 26
TC 4
Z9 4
U1 2
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JUL
PY 2023
VL 35
IS 5
BP 645
EP 655
DI 10.1111/den.14500
EA JAN 2023
PG 11
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA L1BP0
UT WOS:000914939300001
PM 36527309
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Teramoto, A
   Hamada, S
   Ogino, B
   Yasuda, I
   Sano, Y
AF Teramoto, Akira
   Hamada, Seiji
   Ogino, Banri
   Yasuda, Ichiro
   Sano, Yasushi
TI Updates in narrow-band imaging for colorectal polyps: Narrow-band
   imaging generations, detection, diagnosis, and artificial intelligence
SO DIGESTIVE ENDOSCOPY
LA English
DT Review; Early Access
DE adenoma detection rate; blue laser imaging; colonoscopy; image enhanced
   endoscopy; narrow band imaging
ID SESSILE SERRATED ADENOMA/POLYPS; DEFINITION WHITE-LIGHT; COMPUTER-AIDED
   DIAGNOSIS; REAL-TIME; CONVENTIONAL COLONOSCOPY; MAGNIFYING ENDOSCOPY;
   ENHANCED ENDOSCOPY; CONTROLLED-TRIAL; INVASION DEPTH; COLONIC POLYPS
AB Narrow-band imaging (NBI) is an optical digital enhancement method that allows the observation of vascular and surface structures of colorectal lesions. Its usefulness in the detection and diagnosis of colorectal polyps has been demonstrated in several clinical trials and the diagnostic algorithms have been simplified after the establishment of endoscopic classifications such as the Japan NBI Expert Team classification. However, there were issues including lack of brightness in the earlier models, poor visibility under insufficient bowel preparation, and the incompatibility of magnifying endoscopes in certain endoscopic platforms, which had impeded NBI from becoming standardized globally. Nonetheless, NBI continued its evolution and the newest endoscopic platform launched in 2020 offers significantly brighter and detailed images. Enhanced visualization is expected to improve the detection of polyps while universal compatibility across all scopes including magnifying endoscopy will promote the global standardization of magnifying diagnosis. Therefore, knowledge related to magnifying colonoscopy will become essential as magnification becomes standardly equipped in future models, although the advent of computer-aided diagnosis and detection may greatly assist endoscopists to ensure quality of practice. Given that most endoscopic departments will be using both old and new models, it is important to understand how each generation of endoscopic platforms differ from each other. We reviewed the advances in the endoscopic platforms, artificial intelligence, and evidence related to NBI essential for the next generation of endoscopic practice.
C1 [Teramoto, Akira; Ogino, Banri; Yasuda, Ichiro] Toyama Univ Hosp, Dept Internal Med 3, Toyama, Japan.
   [Hamada, Seiji] Urasoe Gen Hosp, Gastrointestinal Ctr, Urasoe, Okinawa, Japan.
   [Sano, Yasushi] Sano Hosp, Gastrointestinal Ctr, Kobe, Hyogo, Japan.
   [Teramoto, Akira] Toyama Univ Hosp, Dept Internal Med 3, 2630 Sugitani, Toyama, Toyama 9300194, Japan.
C3 University of Toyama; University of Toyama
RP Teramoto, A (通讯作者)，Toyama Univ Hosp, Dept Internal Med 3, 2630 Sugitani, Toyama, Toyama 9300194, Japan.
EM akira_teramoto@hotmail.com
RI Yasuda, Ichiro/IUP-0131-2023
OI Yasuda, Ichiro/0000-0002-6888-0310; Sano, Yasushi/0000-0002-3352-5757;
   ogino, banri/0000-0002-2422-8961; Hamada, Seiji/0000-0002-8993-8622
CR Adler A, 2008, GUT, V57, P59, DOI 10.1136/gut.2007.123539
   Adler A, 2009, GASTROENTEROLOGY, V136, P410, DOI 10.1053/j.gastro.2008.10.022
   Ang TL, 2019, ENDOSC INT OPEN, V7, pE1207, DOI 10.1055/a-0982-3111
   [Anonymous], 2022, Dig Endosc, V34 Suppl 2, P138, DOI 10.1111/den.14303
   [Anonymous], 2022, Dig Endosc, V34 Suppl 2, P143, DOI 10.1111/den.14304
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Atkinson NSS, 2019, GASTROENTEROLOGY, V157, P462, DOI 10.1053/j.gastro.2019.04.014
   Barua I., NEJM EVID, DOI [10.1056/EVIDoa2200003, DOI 10.1056/EVIDOA2200003]
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bhat YM, 2014, GASTROINTEST ENDOSC, V80, P919, DOI 10.1016/j.gie.2014.06.019
   Bond A, 2017, CLIN COLORECTAL CANC, V16, P44, DOI 10.1016/j.clcc.2016.07.006
   Bruno C, 2021, CLIN OTOLARYNGOL, V46, P1315, DOI 10.1111/coa.13837
   Bruno C, 2021, RHINOLOGY, V59, DOI 10.4193/Rhin20.032
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chino A, 2016, INT J COLORECTAL DIS, V31, P343, DOI 10.1007/s00384-015-2416-2
   Chung SJ, 2014, GUT, V63, P785, DOI 10.1136/gutjnl-2013-304578
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   De Luca L, 2013, Diagn Ther Endosc, V2013, P580526, DOI 10.1155/2013/580526
   Dinesen L, 2012, GASTROINTEST ENDOSC, V75, P604, DOI 10.1016/j.gie.2011.10.017
   East JE, 2012, COLORECTAL DIS, V14, pE771, DOI 10.1111/codi.12014
   East JE, 2007, AM J GASTROENTEROL, V102, P2529, DOI 10.1111/j.1572-0241.2007.01429.x
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Fujimoto A, 2022, DIGEST ENDOSC, V34, P379, DOI 10.1111/den.14191
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Gono K, 2015, CLIN ENDOSC, V48, P476, DOI 10.5946/ce.2015.48.6.476
   Gourevitch RA, 2018, AM J GASTROENTEROL, V113, P431, DOI 10.1038/ajg.2017.496
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hann A, 2021, UNITED EUR GASTROENT, V9, P527, DOI 10.1002/ueg2.12108
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Hazewinkel Y, 2015, GASTROINTEST ENDOSC, V81, P531, DOI 10.1016/j.gie.2014.06.043
   Hazewinkel Y, 2013, GASTROINTEST ENDOSC, V77, P916, DOI 10.1016/j.gie.2012.12.018
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Higurashi T, 2022, SURG ENDOSC, V36, P7577, DOI 10.1007/s00464-022-09197-8
   Hirata M, 2007, GASTROINTEST ENDOSC, V65, P988, DOI 10.1016/j.gie.2006.07.046
   Ignjatovic A, 2011, ENDOSCOPY, V43, P94, DOI 10.1055/s-0030-1256074
   IJspeert JEG, 2016, GUT, V65, P963, DOI 10.1136/gutjnl-2014-308411
   Ikematsu H, 2017, GASTROINTEST ENDOSC, V86, P386, DOI 10.1016/j.gie.2017.01.017
   Ikematsu H, 2012, J GASTROENTEROL, V47, P1099, DOI 10.1007/s00535-012-0575-2
   Inoue T, 2008, J GASTROENTEROL, V43, P45, DOI 10.1007/s00535-007-2125-x
   Iwatate M, 2018, DIGEST ENDOSC, V30, P642, DOI 10.1111/den.13065
   Jin XF, 2012, J GASTROEN HEPATOL, V27, P882, DOI 10.1111/j.1440-1746.2011.06987.x
   Kaltenbach T, 2008, GUT, V57, P1406, DOI 10.1136/gut.2007.137984
   Kanao H, 2009, GASTROINTEST ENDOSC, V69, P631, DOI 10.1016/j.gie.2008.08.028
   Kashida H, 2019, DIGEST ENDOSC, V31, P16, DOI 10.1111/den.13263
   Kim H, 2019, SCAND J GASTROENTERO, V54, P1058, DOI 10.1080/00365521.2019.1650953
   Kimura T, 2012, AM J GASTROENTEROL, V107, P460, DOI 10.1038/ajg.2011.457
   Kobara H, 2021, J CLIN MED, V10, DOI 10.3390/jcm10204753
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Koyama Y, 2022, SURG ENDOSC, V36, P5032, DOI 10.1007/s00464-021-08863-7
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lash RH, 2010, J CLIN PATHOL, V63, P681, DOI 10.1136/jcp.2010.075507
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P603, DOI 10.1016/j.gie.2011.04.049
   Leung WK, 2020, GASTROINTEST ENDOSC, V91, P104, DOI 10.1016/j.gie.2019.06.031
   Leung WK, 2014, AM J GASTROENTEROL, V109, P855, DOI 10.1038/ajg.2014.83
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Mani S, 2016, REV ENVIRON CONTAM T, V237, P71, DOI 10.1007/978-3-319-23573-8_4
   Mason SE, 2019, AM J GASTROENTEROL, V114, P1219, DOI 10.14309/ajg.0000000000000156
   McGill SK, 2013, GUT, V62, P1704, DOI 10.1136/gutjnl-2012-303965
   Minamide T, 2021, J GASTROEN HEPATOL, V36, P3084, DOI 10.1111/jgh.15621
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Murakami T, 2021, SURG ENDOSC, V35, P4528, DOI 10.1007/s00464-020-07967-w
   Muto M, 2010, J CLIN ONCOL, V28, P1566, DOI 10.1200/JCO.2009.25.4680
   Nakano A, 2017, ENDOSC INT OPEN, V5, pE224, DOI 10.1055/s-0043-102400
   Nakao Y, 2013, EUR J GASTROEN HEPAT, V25, P981, DOI 10.1097/MEG.0b013e3283614b2b
   Niv Y, 2017, EUR J GASTROEN HEPAT, V29, P1327, DOI 10.1097/MEG.0000000000000994
   Okamoto Y, 2022, J GASTROEN HEPATOL, V37, P104, DOI 10.1111/jgh.15682
   Paggi S, 2009, CLIN GASTROENTEROL H, V7, P1049, DOI 10.1016/j.cgh.2009.06.028
   Pai RK., 2019, WHO CLASSIFICATION T, P163
   Parikh ND, 2016, ENDOSCOPY, V48, P731, DOI 10.1055/s-0042-107592
   Pasha SF, 2012, AM J GASTROENTEROL, V107, P363, DOI 10.1038/ajg.2011.436
   Pons FR, 2020, BMC GASTROENTEROL, V20, DOI 10.1186/s12876-020-01257-4
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Puig I, 2019, GASTROENTEROLOGY, V156, P75, DOI 10.1053/j.gastro.2018.10.004
   Rastogi A, 2011, GASTROINTEST ENDOSC, V74, P593, DOI 10.1016/j.gie.2011.04.050
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2007, GASTROENTEROLOGY, V133, P42, DOI 10.1053/j.gastro.2007.04.029
   Rex DK, 2016, GASTROINTEST ENDOSC, V83, P166, DOI 10.1016/j.gie.2015.03.1915
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Russo GI, 2021, CANCERS, V13, DOI 10.3390/cancers13174378
   Sabbagh LC, 2011, BMC GASTROENTEROL, V11, DOI 10.1186/1471-230X-11-100
   Saiki H, 2016, ENDOSC INT OPEN, V4, pE451, DOI 10.1055/s-0042-103239
   Saito S, 2011, DIGEST ENDOSC, V23, P120, DOI 10.1111/j.1443-1661.2011.01122.x
   Sano W, 2020, WORLD J GASTROENTERO, V26, P2276, DOI 10.3748/wjg.v26.i19.2276
   Sano W, 2015, ENDOSC INT OPEN, V3, pE354, DOI 10.1055/s-0034-1391948
   Sano Y, 2005, DIGEST ENDOSC, V17, P105, DOI DOI 10.1111/J.1443-1661.2005.00483.X
   Sano Y., 2001, STOMACH INTEST, V36, P1283
   Sano Y, 2009, GASTROINTEST ENDOSC, V69, P278, DOI 10.1016/j.gie.2008.04.066
   Sato T, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5518948
   Senore C, 2014, DIGEST LIVER DIS, V46, P803, DOI 10.1016/j.dld.2014.05.007
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Staudenmann Dominic, 2022, DEN open, V2, pe44, DOI 10.1002/deo2.44
   Subramaniam S, 2019, UNITED EUR GASTROENT, V7, P316, DOI 10.1177/2050640618822402
   Sumimoto K, 2017, GASTROINTEST ENDOSC, V86, P700, DOI 10.1016/j.gie.2017.02.018
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Tate DJ, 2018, GASTROINTEST ENDOSC, V87, P222, DOI 10.1016/j.gie.2017.06.031
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Uchita K, 2018, INT J CLIN ONCOL, V23, P707, DOI 10.1007/s10147-018-1247-x
   Uraoka T, 2015, J GASTROENTEROL, V50, P555, DOI 10.1007/s00535-014-0999-y
   Wada Y, 2009, GASTROINTEST ENDOSC, V70, P522, DOI 10.1016/j.gie.2009.01.040
   Yamashina T, 2015, J GASTROEN HEPATOL, V30, P117, DOI 10.1111/jgh.12688
   Yao K, 2009, ENDOSCOPY, V41, P462, DOI 10.1055/s-0029-1214594
   Yoshida N, 2022, DIGEST ENDOSC, V34, P86, DOI 10.1111/den.14228
   Yoshida N, 2014, DIGEST ENDOSC, V26, P250, DOI 10.1111/den.12127
   Yoshida N, 2014, J GASTROENTEROL, V49, P73, DOI 10.1007/s00535-013-0772-7
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang Y, 2020, WORLD J GASTROENTERO, V26, P6279, DOI 10.3748/wjg.v26.i40.6279
   Zhou QJ, 2011, WORLD J GASTROENTERO, V17, P666, DOI 10.3748/wjg.v17.i5.666
NR 118
TC 0
Z9 0
U1 3
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD 2023 JAN 18
PY 2023
DI 10.1111/den.14489
EA JAN 2023
PG 18
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 7X2QJ
UT WOS:000914047500001
PM 36480465
DA 2023-08-21
ER

PT J
AU Yao, LW
   Lu, ZH
   Yang, GH
   Zhou, W
   Xu, YM
   Guo, MW
   Huang, X
   He, CP
   Zhou, R
   Deng, YC
   Wu, HL
   Chen, BR
   Gong, RR
   Zhang, LH
   Zhang, MJ
   Gong, W
   Yu, HG
AF Yao, Liwen
   Lu, Zihua
   Yang, Genhua
   Zhou, Wei
   Xu, Youming
   Guo, Mingwen
   Huang, Xu
   He, Chunping
   Zhou, Rui
   Deng, Yunchao
   Wu, Huiling
   Chen, Boru
   Gong, Rongrong
   Zhang, Lihui
   Zhang, Mengjiao
   Gong, Wei
   Yu, Honggang
TI Development and validation of an artificial intelligence-based system
   for predicting colorectal cancer invasion depth using multi-modal data
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE artificial intelligence; colonoscopy; colorectal cancer; invasion depth
ID ENDOSCOPIC MUCOSAL RESECTION; SOCIETY TASK-FORCE; MULTICENTER;
   COLONOSCOPY; DIAGNOSIS; LESIONS; RECOMMENDATIONS; MANAGEMENT; NEOPLASMS;
   OUTCOMES
AB ObjectivesAccurate endoscopic optical prediction of the depth of cancer invasion is critical for guiding an optimal treatment approach of large sessile colorectal polyps but was hindered by insufficient endoscopists expertise and inter-observer variability. We aimed to construct a clinically applicable artificial intelligence (AI) system for the identification of presence of cancer invasion in large sessile colorectal polyps. MethodsA deep learning-based colorectal cancer invasion calculation (CCIC) system was constructed. Multi-modal data including clinical information, white light (WL) and image-enhanced endoscopy (IEE) were included for training. The system was trained using 339 lesions and tested on 198 lesions across three hospitals. Man-machine contest, reader study and video validation were further conducted to evaluate the performance of CCIC. ResultsThe overall accuracy of CCIC system using image and video validation was 90.4% and 89.7%, respectively. In comparison with 14 endoscopists, the accuracy of CCIC was comparable with expert endoscopists but superior to all the participating senior and junior endoscopists in both image and video validation set. With CCIC augmentation, the average accuracy of junior endoscopists improved significantly from 75.4% to 85.3% (P = 0.002). ConclusionsThis deep learning-based CCIC system may play an important role in predicting the depth of cancer invasion in colorectal polyps, thus determining treatment strategies for these large sessile colorectal polyps.
C1 [Yao, Liwen; Lu, Zihua; Zhou, Wei; Xu, Youming; Huang, Xu; He, Chunping; Zhou, Rui; Deng, Yunchao; Wu, Huiling; Chen, Boru; Gong, Rongrong; Zhang, Lihui; Zhang, Mengjiao; Gong, Wei; Yu, Honggang] Wuhan Univ, Renmin Hosp, Dept Gastroenterol, Wuhan, Peoples R China.
   [Yao, Liwen; Lu, Zihua; Zhou, Wei; Xu, Youming; Huang, Xu; He, Chunping; Zhou, Rui; Deng, Yunchao; Wu, Huiling; Chen, Boru; Gong, Rongrong; Zhang, Lihui; Zhang, Mengjiao; Gong, Wei; Yu, Honggang] Wuhan Univ, Renmin Hosp, Hubei Prov Clin Res Ctr Digest Dis Minimally Invas, Wuhan, Peoples R China.
   [Yao, Liwen; Lu, Zihua; Zhou, Wei; Xu, Youming; Huang, Xu; He, Chunping; Zhou, Rui; Deng, Yunchao; Wu, Huiling; Chen, Boru; Gong, Rongrong; Zhang, Lihui; Zhang, Mengjiao; Gong, Wei; Yu, Honggang] Wuhan Univ, Renmin Hosp, Key Lab Hubei Prov Digest Syst Dis, Wuhan, Peoples R China.
   [Yang, Genhua] Southern Med Univ, Shenzhen Hosp, Dept Gastroenterol, Shenzhen, Peoples R China.
   [Guo, Mingwen] First Hosp Yichang, Dept Gastroenterol, Yichang, Peoples R China.
   [Yu, Honggang] Wuhan Univ, Renmin Hosp, Dept Gastroenterol, Wuhan 430064, Hubei, Peoples R China.
   [Gong, Wei] Southern Med Univ, Nanfang Hosp, Dept Gastroenterol, Guangzhou, Guangdong, Peoples R China.
C3 Wuhan University; Wuhan University; Wuhan University; Southern Medical
   University - China; Wuhan University; Southern Medical University -
   China
RP Yu, HG (通讯作者)，Wuhan Univ, Renmin Hosp, Dept Gastroenterol, Wuhan 430064, Hubei, Peoples R China.; Gong, W (通讯作者)，Southern Med Univ, Nanfang Hosp, Dept Gastroenterol, Guangzhou, Guangdong, Peoples R China.
EM drgwei@foxmail.com; yuhonggang1968@163.com
OI Yao, Liwen/0000-0001-5412-9991
CR Backes Y, 2017, AM J GASTROENTEROL, V112, P54, DOI 10.1038/ajg.2016.403
   Backes Y, 2019, GUT, V68, P271, DOI 10.1136/gutjnl-2017-314723
   Bahin FF, 2018, GUT, V67, P1965, DOI 10.1136/gutjnl-2017-313823
   Bokemeyer B, 2009, EUR J GASTROEN HEPAT, V21, P650, DOI 10.1097/MEG.0b013e32830b8acf
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Burgess NG, 2017, GASTROENTEROLOGY, V153, P732, DOI 10.1053/j.gastro.2017.05.047
   Castelvecchi D, 2016, NATURE, V537, P20, DOI [10.1038/nature.2016.20491, 10.1038/538020a]
   Cohen JF, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2016-012799
   Diebold MD, 2004, AM J GASTROENTEROL, V99, P1795, DOI 10.1111/j.1572-0241.2004.40236.x
   Hashiguchi Y, 2020, INT J CLIN ONCOL, V25, P1, DOI 10.1007/s10147-019-01485-z
   Ichimasa K, 2021, GUT LIVER, V15, P818, DOI 10.5009/gnl20224
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Kaltenbach T, 2020, GASTROENTEROLOGY, V158, P1095, DOI 10.1053/j.gastro.2019.12.018
   Kudo SE, 2008, GASTROINTEST ENDOSC, V68, pS3, DOI 10.1016/j.gie.2008.07.052
   Lee H, 2019, NAT BIOMED ENG, V3, P173, DOI 10.1038/s41551-018-0324-9
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Luo XB, 2021, GASTROINTEST ENDOSC, V94, P627, DOI 10.1016/j.gie.2021.03.936
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Moss A, 2011, GASTROENTEROLOGY, V140, P1909, DOI 10.1053/j.gastro.2011.02.062
   dos Santos CEO, 2015, DIGEST ENDOSC, V27, P361, DOI 10.1111/den.12346
   Ouali Y., 2020, OVERVIEW DEEP SEMI S, DOI DOI 10.48550/ARXIV.2006.05278
   Pimentel-Nunes P, 2022, ENDOSCOPY, V54, P591, DOI 10.1055/a-1811-7025
   Puig I, 2019, GASTROENTEROLOGY, V156, P75, DOI 10.1053/j.gastro.2018.10.004
   Regula J, 2006, NEW ENGL J MED, V355, P1863, DOI 10.1056/NEJMoa054967
   Rembacken BJ, 2000, LANCET, V355, P1211, DOI 10.1016/S0140-6736(00)02086-9
   Saito Y, 2009, DIGEST ENDOSC, V21, pS7, DOI 10.1111/j.1443-1661.2009.00870.x
   Shaukat A, 2020, GASTROENTEROLOGY, V159, P1916, DOI [10.1053/gastro.2020.08.050, 10.1053/j.gastro.2020.08.050]
   Suzuki N, 2004, Colorectal Dis, V6, P15, DOI 10.1111/j.1463-1318.2004.00533.x
   Takamatsu M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-07038-1
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   U.S. Food and Drug Administration, 2020, CLIN PAT DEC SUPP SO
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Williams JG, 2013, COLORECTAL DIS, V15, P1, DOI 10.1111/codi.12262
   Yoda Y, 2013, ENDOSCOPY, V45, P718, DOI 10.1055/s-0033-1344234
NR 34
TC 2
Z9 2
U1 3
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JUL
PY 2023
VL 35
IS 5
BP 625
EP 635
DI 10.1111/den.14493
EA JAN 2023
PG 11
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA L1BP0
UT WOS:000914188000001
PM 36478234
DA 2023-08-21
ER

PT J
AU Mushtaq, D
   Madni, TM
   Janjua, UI
   Anwar, F
   Kakakhail, A
AF Mushtaq, Dania
   Madni, Tahir Mustafa
   Janjua, Uzair Iqbal
   Anwar, Fozia
   Kakakhail, Ahmad
TI An automatic gastric polyp detection technique using deep learning
SO INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY
LA English
DT Article; Early Access
DE attention mechanism; convolution neural network; feature map
   concatenation; gastric polyp; gastroscopy; polyp detection; SSD
ID ARTIFICIAL-INTELLIGENCE; NEURAL-NETWORKS
AB Over the last few years, researchers have focused on computer-aided polyp detection in gastroscopy. Deep learning (DL) has shown great promise for polyps' identification. The most exceptional contribution of DL methods in gastroenterology is their ability to identify polyps quickly and accurately using convolution neural network. Nonetheless, despite significant advancements, automatic detection of small polyps remains a challenging and complex task. Furthermore, due to multiple pooling operations, the features of small polyps are lost, resulting in low detection accuracy. This paper proposes an efficient object detection method for polyp detection using gastric images to address this issue. A single-shot multi-box detector (SSD) was combined with the feature extractor VGG-16, and the Refined Map Block (RMB) was integrated into SSD's high-resolution feature maps to get more semantic information. The RMB output was used as the input to the successive layers. The RMB comprises of attention cascade and feature map concatenation cascade. The attention cascade improved the localization accuracy, while the feature map concatenation cascade improved the classification accuracy. Using the former, the proposed attention-based SSD for gastric polyps (ASSD-GPNet) model focused on the specific information, a polyp, rather than the background. Furthermore, the feature map concatenation cascade adds semantic information while reducing computational complexity. The output of these two cascades was combined to produce a refined feature map that enhances the detection of small polyps. The model was trained and tested on 1970 gastric images and Pascal VOC07 + 12. Image augmentation was applied to increase the training data of gastric images to reduce overfitting and skip connections were used to overcome the vanishing gradient problem. Overall, the experimental results demonstrated that the proposed model outperformed than compared models in both medical and natural images. The ASSD-GPNet obtained mean average precision (mAP) of 94.2% on gastric images and 76.9% on Pascal VOC.
C1 [Mushtaq, Dania; Madni, Tahir Mustafa; Janjua, Uzair Iqbal; Anwar, Fozia] COMSATS Univ Islamabad, Islamabad, Pakistan.
   [Kakakhail, Ahmad] Natl Univ Modern Languages, Islamabad, Islamabad Capit, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Janjua, UI (通讯作者)，COMSATS Univ Islamabad, Islamabad, Pakistan.
EM uzair_iqbal@comsats.edu.pk
OI , Ahmad/0000-0001-7921-7701; Iqbal Janjua, Uzair/0000-0003-4515-0742
FU Pakistan's National Center of Artificial Intelligence
FX This study was conducted at the Medical Imaging and Diagnostics Lab at
   COMSATS University Islamabad and was funded by Pakistan's National
   Center of Artificial Intelligence.
CR Ang TL, 2021, J GASTROEN HEPATOL, V36, P5, DOI 10.1111/jgh.15344
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], INT J COMPUT VISION, DOI DOI 10.1007/s11263-009-0275-4
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Cao CT, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250632
   Casado-Garcia A, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2931-1
   Choi HT, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082842
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Dubois H, 2020, HEALTH EXPECT, V23, P893, DOI 10.1111/hex.13066
   Durak S, 2021, MED BIOL ENG COMPUT, V59, P1563, DOI 10.1007/s11517-021-02398-8
   Girshick R., 2014, P IEEE C COMP VIS PA, P580, DOI DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hu H., 2020, INT J IMAG SYST TECH, V31, P1
   Huang ZX, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000019157
   Ikenoyama Y, 2021, DIGEST ENDOSC, V33, P141, DOI 10.1111/den.13688
   Krizhevsky A., IMAGENET CLASSIFICAT
   Laddha M., 2019, P 2019 4 INT C BIOME, P55, DOI [10.1145/3366174.3366185, DOI 10.1145/3366174.3366185, 10.1145/3366174.3366185.]
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ro TH, 2015, WORLD J GASTROENTERO, V21, P9693, DOI 10.3748/wjg.v21.i33.9693
   Sakai Y, 2018, IEEE ENG MED BIO, P4138, DOI 10.1109/EMBC.2018.8513274
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang R., 2019, P 2019 8 INT C COMPU, P128, DOI [10.1145/3373509.3373524, DOI 10.1145/3373509.3373524]
   Wang W, 2023, BIOCELL, V47, P373, DOI [10.32604/biocell.2023.025905, 10.32604/biocell.2021.0xxx]
   Wang W, 2022, SYST SCI CONTROL ENG, V10, P325, DOI 10.1080/21642583.2022.2045645
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Yang K, 2022, ALEX ENG J, V61, P917, DOI 10.1016/j.aej.2021.04.072
   Yu CR, 2022, ARTIF INTELL REV, V55, P323, DOI [10.1007/s10462-021-10034-y, 10.17660/ActaHortic.2021.1313.1]
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang XX, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0200174
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
   Zhuang HM, 2023, VISUAL COMPUT, V39, P2207, DOI 10.1007/s00371-021-02322-z
NR 42
TC 0
Z9 0
U1 4
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-9457
EI 1098-1098
J9 INT J IMAG SYST TECH
JI Int. J. Imaging Syst. Technol.
PD 2023 JAN 14
PY 2023
DI 10.1002/ima.22850
EA JAN 2023
PG 15
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA 7Z3YI
UT WOS:000915498100001
DA 2023-08-21
ER

PT J
AU Nakashima, H
   Kitazawa, N
   Fukuyama, C
   Kawachi, H
   Kawahira, H
   Momma, K
   Sakaki, N
AF Nakashima, Hirotaka
   Kitazawa, Naoko
   Fukuyama, Chika
   Kawachi, Hiroshi
   Kawahira, Hiroshi
   Momma, Kumiko
   Sakaki, Nobuhiro
TI Clinical Evaluation of Computer-Aided Colorectal Neoplasia Detection
   Using a Novel Endoscopic Artificial Intelligence: A Single-Center
   Randomized Controlled Trial
SO DIGESTION
LA English
DT Article
DE Artificial intelligence; Computer-aided detection; Colon polyps; Adenoma
   detection rate; Adenoma miss rate
ID SESSILE SERRATED ADENOMA/POLYPS; QUALITY INDICATORS; COLONOSCOPY;
   CLASSIFICATION; CANCER; CARCINOMA; FREQUENCY; POLYPS; RISK
AB Introduction: Computer-aided diagnostic systems are emerging in the field of gastrointestinal endoscopy. In this study, we assessed the clinical performance of the computer-aided detection (CADe) of colonic adenomas using a new endoscopic artificial intelligence system. Methods: This was a single-center prospective randomized study including 415 participants allocated into the CADe group (n = 207) and control group (n = 208). All endoscopic examinations were performed by experienced endoscopists. The performance of the CADe was assessed based on the adenoma detection rate (ADR). Additionally, we compared the adenoma miss rate for the rectosigmoid colon (AMRrs) between the groups. Results: The basic demographic and procedural characteristics of the CADe and control groups were as follows: mean age, 54.9 and 55.9 years; male sex, 73.9% and 69.7% of participants; and mean withdrawal time, 411.8 and 399.0 s, respectively. The ADR was 59.4% in the CADe group and 47.6% in the control group (p = 0.018). The AMRrs was 11.9% in the CADe group and 26.0% in the control group (p = 0.037). Conclusion: The colonoscopy with the CADe system yielded an 11.8% higher ADR than that performed by experienced endoscopists alone. Moreover, there was no need to extend the examination time or request the assistance of additional medical staff to achieve this improved effectiveness. We believe that the novel CADe system can lead to considerable advances in colorectal cancer diagnosis.
C1 [Nakashima, Hirotaka; Kitazawa, Naoko; Momma, Kumiko; Sakaki, Nobuhiro] Fdn Detect Early Gastr Carcinoma, Dept Gastroenterol, Tokyo, Japan.
   [Fukuyama, Chika] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Gastroenterol, Tokyo, Japan.
   [Kawachi, Hiroshi] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Pathol, Tokyo, Japan.
   [Kawahira, Hiroshi] Jichi Med Univ, Med Simulat Ctr, Tochigi, Japan.
C3 Japanese Foundation for Cancer Research; Japanese Foundation for Cancer
   Research; Jichi Medical University
RP Nakashima, H (通讯作者)，Fdn Detect Early Gastr Carcinoma, Dept Gastroenterol, Tokyo, Japan.
EM nakashima@soiken.or.jp
OI Nakashima, Hirotaka/0000-0002-2386-1933; Kawachi,
   Hiroshi/0000-0002-8270-791X
CR Chino A, 2016, INT J COLORECTAL DIS, V31, P343, DOI 10.1007/s00384-015-2416-2
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Floer M, 2016, DIGESTION, V93, P202, DOI 10.1159/000442464
   FUJIFILM Europe GmbH, ELUXEO LITE BROCH
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Higurashi T, 2022, SURG ENDOSC, V36, P7577, DOI 10.1007/s00464-022-09197-8
   Ito R, 2021, ENDOSC INT OPEN, V09, pE271, DOI 10.1055/a-1324-3083
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kanda Y, 2013, BONE MARROW TRANSPL, V48, P452, DOI 10.1038/bmt.2012.244
   Kawamura T., 2017, J GASTROEN HEPATOL, V6, P2273, DOI [10.17554/j.issn.2224-3992.2017.06.672, DOI 10.17554/J.ISSN.2224-3992.2017.06.672]
   Kotake K, 2019, J ANUS RECTUM COLON, V3, P175, DOI 10.23922/jarc.2019-018
   Kudo S, 2020, CLIN TRANSL GASTROEN, V11, DOI 10.14309/ctg.0000000000000269
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kumar S, 2017, GASTROINTEST ENDOSC, V85, P1273, DOI 10.1016/j.gie.2016.11.030
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Liu AH, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000021278
   Misawa M, 2021, DIGEST ENDOSC, V33, P273, DOI 10.1111/den.13847
   Moher David, 2012, Int J Surg, V10, P28, DOI 10.1016/j.ijsu.2011.10.001
   Pohl H, 2015, ENDOSCOPY, V47, P891, DOI 10.1055/s-0034-1392261
   Rex DK, 2000, GASTROINTEST ENDOSC, V51, P33, DOI 10.1016/S0016-5107(00)70383-X
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Saiki H, 2016, ENDOSC INT OPEN, V4, pE451, DOI 10.1055/s-0042-103239
   Saito Y, 2021, DIGEST ENDOSC, V33, P486, DOI 10.1111/den.13972
   Sakamoto T, 2022, DIGEST DIS SCI, V67, P3976, DOI 10.1007/s10620-021-07217-6
   Saltzman JR, 2015, GASTROINTEST ENDOSC, V81, P781, DOI 10.1016/j.gie.2014.09.048
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Tanaka S, 2021, J GASTROENTEROL, V56, P323, DOI 10.1007/s00535-021-01776-1
   Wallace MB, 2022, GASTROENTEROLOGY, V163, P295, DOI 10.1053/j.gastro.2022.03.007
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   WHO Classification of Tumours Editorial Board, 2019, DIG SYST TUM, V8, P163
   Winawer Sidney J, 2002, Gastrointest Endosc Clin N Am, V12, P1, DOI 10.1016/S1052-5157(03)00053-9
   Wu J, 2012, ENDOSCOPY, V44, P128, DOI 10.1055/s-0031-1291487
   Yoshida N, 2021, INT J COLORECTAL DIS, V36, P2237, DOI 10.1007/s00384-021-04006-5
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 37
TC 1
Z9 1
U1 1
U2 3
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0012-2823
EI 1421-9867
J9 DIGESTION
JI Digestion
PD JUN
PY 2023
VL 104
IS 3
BP 193
EP 201
DI 10.1159/000528085
EA JAN 2023
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA J2OQ6
UT WOS:000909400900001
PM 36599306
DA 2023-08-21
ER

PT J
AU Alhajlah, M
   Noor, MN
   Nazir, M
   Mahmood, A
   Ashraf, I
   Karamat, T
AF Alhajlah, Mousa
   Noor, Muhammad Nouman
   Nazir, Muhammad
   Mahmood, Awais
   Ashraf, Imran
   Karamat, Tehmina
TI Gastrointestinal Diseases Classification Using Deep Transfer Learning
   and Features Optimization
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Diseases; deep learning; endoscopy; gastrointestinal tract; transfer
   learning
ID HELICOBACTER-PYLORI; RECOGNITION; STOMACH
AB Gastrointestinal diseases like ulcers, polyps', and bleeding are increasing rapidly in the world over the last decade. On average 0.7 million cases are reported worldwide every year. The main cause of gastrointestinal diseases is a Helicobacter Pylori (H. Pylori) bacterium that presents in more than 50% of people around the globe. Many researchers have proposed different methods for gastrointestinal disease using computer vision tech-niques. Few of them focused on the detection process and the rest of them performed classification. The major challenges that they faced are the simi-larity of infected and healthy regions that misleads the correct classification accuracy. In this work, we proposed a technique based on Mask Recurrent -Convolutional Neural Network (R-CNN) and fine-tuned pre-trained ResNet-50 and ResNet-152 networks for feature extraction. Initially, the region of interest is detected using Mask R-CNN which is later utilized for the training of fine-tuned models through transfer learning. Features are extracted from fine-tuned models that are later fused using a serial approach. Moreover, an Improved Ant Colony Optimization (ACO) algorithm has also opted for the best feature selection from the fused feature vector. The best-selected features are finally classified using machine learning techniques. The experimental process was conducted on the publicly available dataset and obtained an improved accuracy of 96.43%. In comparison with state-of-the-art techniques, it is observed that the proposed accuracy is improved.
C1 [Alhajlah, Mousa; Mahmood, Awais] King Saud Univ, Coll Appl Comp Sci, Almuzahmiyah Campus, Riyadh 11543, Saudi Arabia.
   [Noor, Muhammad Nouman; Nazir, Muhammad] HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.
   [Ashraf, Imran] HITEC Univ, Dept Comp Engn, Taxila 47080, Pakistan.
   [Karamat, Tehmina] Fdn Univ Islamabad, Dept Software Engn, Islamabad 44000, Pakistan.
RP Mahmood, A (通讯作者)，King Saud Univ, Coll Appl Comp Sci, Almuzahmiyah Campus, Riyadh 11543, Saudi Arabia.
EM mawais@ksu.edu.sa
RI Alhajlah, Mousa/HJY-0752-2023; Noor, Muhammad Nouman/HWQ-5109-2023;
   Ashraf, Imran/T-3635-2019
OI Alhajlah, Mousa/0000-0003-4799-6004; Ashraf, Imran/0000-0002-8271-6496
FU King Saud University, Riyadh, Saudi Arabia [RSP2022R458]
FX Funding Statement: Researchers Supporting Project number (RSP2022R458) ,
   King Saud University, Riyadh, Saudi Arabia.
CR Al-Adhaileh M. H., 2021, COMPUT MATH METHOD M, P29434
   Algood HMS, 2006, CLIN MICROBIOL REV, V19, P597, DOI 10.1128/CMR.00006-06
   Amjad M, 2001, IRISH J MED SCI, V170, P112, DOI 10.1007/BF03168822
   [Anonymous], CA CANCER J CLIN, DOI [10.3322/CAAC.21254, DOI 10.3322/caac.21254]
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Azhari H, 2018, AM J GASTROENTEROL, V113, pS682
   Aziz F., 2020, INT J MICROBIOLOGY A, V1, P24
   Bengio Y, 2013, INT CONF ACOUST SPEE, P8624, DOI 10.1109/ICASSP.2013.6639349
   Buhling F, 2004, CLIN DIAGN LAB IMMUN, V11, P131, DOI 10.1128/CDLI.11.1.131-136.2004
   Carpi F, 2011, IEEE T BIO-MED ENG, V58, P231, DOI 10.1109/TBME.2010.2087332
   Dheir I. M., 2022, INT J ACAD ENG RES, V6, P417
   Dwivedi P., 2019, DATA SCI
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Ghose C, 2007, CLIN VACCINE IMMUNOL, V14, P442, DOI 10.1128/CVI.00434-06
   Ho Y, 2020, IEEE ACCESS, V8, P4806, DOI 10.1109/ACCESS.2019.2962617
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jung Hwejin, 2019, BMC Biomed Eng, V1, P24, DOI 10.1186/s42490-019-0026-8
   Khan MA, 2020, IEEE ACCESS, V8, P197969, DOI 10.1109/ACCESS.2020.3034217
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, MULTIMED TOOLS APPL, V78, P27743, DOI 10.1007/s11042-019-07875-9
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   Khan SA, 2018, MULTIMED TOOLS APPL, V77, P1133, DOI 10.1007/s11042-016-4324-z
   Kingma D., 2015, ARXIV
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Masmoudi Y, 2022, SOFT COMPUT, V26, P7979, DOI 10.1007/s00500-022-06900-8
   Noor M.N., 2021, P NAT C ENG COMP TEC
   Noor M. N., 2020, RESEARCHPEDIA J COMP, V1, P39
   Ozturk S, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103638
   Peng J, 2020, EUR RADIOL, V30, P413, DOI 10.1007/s00330-019-06318-1
   Plonka M, 2006, DIGEST LIVER DIS, V38, P91, DOI 10.1016/j.dld.2005.10.013
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Ramzan M, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100717
   Ruder S., 2016, ARXIV160904747, V2016, p1609.04747, DOI DOI 10.48550/ARXIV.1609.04747
   Sadad T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061900
   Sun JY, 2018, COMP MED SY, P351, DOI 10.1109/CBMS.2018.00068
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Yeh J-Y, 2014, J SOFTWARE ENG APPL, V7, P422, DOI DOI 10.4236/JSEA.2014.75039
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
NR 41
TC 2
Z9 2
U1 1
U2 1
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2023
VL 75
IS 1
BP 2227
EP 2245
DI 10.32604/cmc.2023.031890
PG 19
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA 9K7HD
UT WOS:000941033600004
OA gold
DA 2023-08-21
ER

PT J
AU Lima, ACD
   de Paiva, LF
   Braz, G
   de Almeida, JDS
   Silva, AC
   Coimbra, MT
   de Paiva, AC
AF de Moura Lima, Alan Carlos
   de Paiva, Lisle Faray
   Braz Jr, Geraldo
   de Almeida, Joao Dallyson S.
   Silva, Aristofanes Correa
   Coimbra, Miguel Tavares
   de Paiva, Anselmo Cardoso
TI A Two-Stage Method for Polyp Detection in Colonoscopy Images Based on
   Saliency Object Extraction and Transformers
SO IEEE ACCESS
LA English
DT Article
DE Colonoscopy images; deep learning; depth maps; polyp detection; saliency
   objects; transformers
ID VALIDATION
AB The gastrointestinal tract is responsible for the entire digestive process. Several diseases, including colorectal cancer, can affect this pathway. Among the deadliest cancers, colorectal cancer is the second most common. It arises from benign tumors in the colon, rectum, and anus. These benign tumors, known as colorectal polyps, can be diagnosed and removed during colonoscopy. Early detection is essential to reduce the risk of cancer. However, approximately 28% of polyps are lost during this examination, mainly because of limitations in diagnostic techniques and image analysis methods. In recent years, computer-aided detection techniques for these lesions have been developed to improve detection quality during periodic examinations. We proposed an automatic method for polyp detection using colonoscopy images. This study presents a two-stage polyp detection method for colonoscopy images using transformers. In the first stage, a saliency map extraction model is supported by the extracted depth maps to identify possible polyp areas. The second stage of the method consists of detecting polyps in the extracted images resulting from the first stage, combined with the green and blue channels. Several experiments were performed using four public colonoscopy datasets. The best results obtained for the polyp detection task were satisfactory, reaching 91% Average Precision in the CVC-ClinicDB dataset, 92% Average Precision in the Kvasir-SEG dataset, and 84% Average Precision in the CVC-ColonDB dataset. This study demonstrates that polyp detection in colonoscopy images can be efficiently performed using a combination of depth maps, salient object-extracted maps, and transformers.
C1 [de Moura Lima, Alan Carlos; Braz Jr, Geraldo; de Almeida, Joao Dallyson S.; Silva, Aristofanes Correa; de Paiva, Anselmo Cardoso] Univ Fed Maranhao, NCA, BR-65085580 Sao Luis, Brazil.
   [de Paiva, Lisle Faray] Univ Burgundy, UFR SC, F-71200 Le Creusot, France.
   [Coimbra, Miguel Tavares] Univ Porto, Fac Sci, INESC TEC, P-4200465 Porto, Portugal.
C3 Universidade Federal do Maranhao; INESC TEC; Universidade do Porto
RP Lima, ACD (通讯作者)，Univ Fed Maranhao, NCA, BR-65085580 Sao Luis, Brazil.
EM alanlima@nca.ufma.br
RI Braz Junior, Geraldo/P-3851-2014
OI Braz Junior, Geraldo/0000-0003-3731-6431
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES),
   Brazil [001]; Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPq), Brazil; Fundacao de Amparo a Pesquisa e ao
   Desenvolvimento Cientifico e Tecnologico do Maranhao (FAPEMA), Brazil;
   Portuguese funding agency, FCT-Fundacao para a Ciencia e a Tecnologia
   [PTDC/EEI-EEE/5557/2020]
FX & nbsp;This work was supported in part by Coordenacao de Aperfeicoamento
   de Pessoal de Nivel Superior (CAPES), Brazil, under Grant 001; in part
   by Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq),
   Brazil; in part by Fundacao de Amparo a Pesquisa e ao Desenvolvimento
   Cientifico e Tecnologico do Maranhao (FAPEMA), Brazil; and in part by
   National Funds through the Portuguese funding agency, FCT-Fundacao para
   a Ciencia e a Tecnologia, within project PTDC/EEI-EEE/5557/2020.
CR Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Badrinarayanan V, 2015, Arxiv, DOI [arXiv:1505.07293, DOI 10.1109/TPAMI.2016.2644615, DOI 10.48550/ARXIV.1505.07293]
   Bagheri M, 2019, IEEE ENG MED BIO, P6742, DOI 10.1109/EMBC.2019.8856793
   Bai Y., 2021, P ADV NEUR INF PROC, V34, P1
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bochkovskiy A., 2020, P IEEE CVF C COMP VI, P722
   Branch M. V. L., 2021, ARXIV
   Cai L, 2023, PREV SCI, V24, P455, DOI 10.1007/s11121-021-01253-4
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Cheng DC, 2011, BIOMED ENG-APP BAS C, V23, P357, DOI 10.4015/S1016237211002761
   COX DR, 1982, BRIT J CLIN PHARMACO, V14, P325, DOI 10.1111/j.1365-2125.1982.tb01987.x
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Dong B, 2022, Arxiv, DOI arXiv:2108.06932
   Fang YQ, 2021, IEEE SENS J, V21, P11799, DOI 10.1109/JSEN.2020.3015831
   He K., 2023, INTELL MED, V3, P59, DOI [10.1016/j.imed.2022.07.002, DOI 10.1016/J.IMED.2022.07.002]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu H., 2014, WILEY STATSREF STAT, V1, P1
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Lafraxo S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13040733
   Lee H, 2022, PUBLIC MANAG REV, V24, P512, DOI 10.1080/14719037.2020.1846368
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Lin MTU, 2021, Arxiv, DOI arXiv:2012.06785
   Liu N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4702, DOI 10.1109/ICCV48922.2021.00468
   Loshchilov Ilya, 2019, Arxiv, DOI [arXiv:1711.05101, DOI 10.48550/ARXIV.1711.05101]
   Lou A., 2023, J MED IMAG, V10, P81
   Neri E., 2015, INFORM PROCESSING ME, P327
   Organizacao Mundial da Saude, 2020, COLORECTAL CANCER
   Qian ZQ, 2021, IEEE SENS J, V21, P11374, DOI 10.1109/JSEN.2020.3036005
   Rahman MM, 2023, IEEE WINT CONF APPL, P6211, DOI 10.1109/WACV56688.2023.00616
   Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196
   Ratuapli Shiva K, 2014, Clin Liver Dis (Hoboken), V4, P109, DOI 10.1002/cld.433
   Redmon J., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ronneberger O, 2015, 161207003 ARXIV
   Sanchez-Peralta LF, 2020, INT J COMPUT ASS RAD, V15, P1975, DOI 10.1007/s11548-020-02262-4
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Taud H., 2018, GEOMATIC APPROACHES, P451, DOI [10.1007/978-3-319-60801-3_27, DOI 10.1007/978-3-319-60801-3_27]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan JJ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122264
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yuan L, 2021, Arxiv, DOI [arXiv:2101.11986, DOI 10.48550/ARXIV.2101.11986]
   Zhiqiang Shen, 2021, 2021 7th International Conference on Computer and Communications (ICCC), P1757, DOI 10.1109/ICCC54389.2021.9674267
NR 51
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2023
VL 11
BP 76108
EP 76119
DI 10.1109/ACCESS.2023.3297097
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA O0GD5
UT WOS:001040682200001
OA gold
DA 2023-08-21
ER

PT J
AU Elkarazle, K
   Raman, V
   Then, P
   Chua, C
AF Elkarazle, Khaled
   Raman, Valliappan
   Then, Patrick
   Chua, Caslon
TI Improved Colorectal Polyp Segmentation Using Enhanced MA-NET and
   Modified Mix-ViT Transformer
SO IEEE ACCESS
LA English
DT Article
DE ~Colorectal polyps; colorectal polyps detection; colorectal polyps
   segmentation; color space; colonoscopy images
ID MISSED POLYPS; RISK-FACTORS; DIAGNOSIS; ADENOMA; NETWORK
AB Colorectal polyps is a prevalent medical condition that could lead to colorectal cancer, a leading cause of cancer-related mortality globally, if left undiagnosed. Colonoscopy remains the gold standard for detection and diagnosis of colorectal neoplasia; however, a significant proportion of neoplastic lesions are missed during routine examinations, particularly diminutive and flat lesions. Deep learning techniques have been employed to improve polyp detection rates in colonoscopy images and have proven successful in reducing the miss rate. However, accurate segmentation of small and flat polyps remains a major challenge to existing models as they struggle to differentiate polypoid and non-polypoid regions apart. To address this issue, we present an enhanced version of the Multi-Scale Attention Network (MA-NET) that incorporates a modified Mix-ViT transformer as the feature extractor. The modified Mix-ViT facilitates ultra-finegrained visual categorization to improve the segmentation accuracy of polypoid and non-polypoid regions. Additionally, we introduce a pre-processing layer that performs histogram equalization on input images in the CIEL*A* B* color space to enhance their features. Our model was trained on a combined dataset comprising Kvasir-SEG and CVC-ClinicDB and cross-validated on CVC-ColonDB and ETIS-LaribDB. The proposed method demonstrates superior performance compared to existing methods, particularly in the detection of small and flat polyps.
C1 [Elkarazle, Khaled; Then, Patrick] Swinburne Univ Technol, Fac Engn Comp & Sci, Sarawak Campus, Kuching 93350, Sarawak, Malaysia.
   [Raman, Valliappan] Coimbatore Inst Technol, Dept Artificial Intelligence & Data Sci, Coimbatore 641014, Tamil Nadu, India.
   [Elkarazle, Khaled; Chua, Caslon] Swinburne Univ Technol, Fac Sci Engn & Technol, Melbourne, Vic 3122, Australia.
C3 Swinburne University of Technology; Swinburne University of Technology
   Sarawak; Coimbatore Institute of Technology; Swinburne University of
   Technology
RP Elkarazle, K (通讯作者)，Swinburne Univ Technol, Fac Engn Comp & Sci, Sarawak Campus, Kuching 93350, Sarawak, Malaysia.
EM kelkaeazle@swinburne.edu.my
FU Swinburne University of Technology Sarawak Higher Degree by Research
   (HDR) Support Fund
FX This work was supported in part by the Swinburne University of
   Technology Sarawak Higher Degree by Research (HDR) Support Fund.
CR Ahmad M, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2665283
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bazi Y, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030516
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bond JH, 2000, AM J GASTROENTEROL, V95, P3053
   Chang Q., 2022, ESF PNET EFFICIENT D
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SJ, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.852553
   cie co at, D65 CIE
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong B, 2022, Arxiv, DOI arXiv:2108.06932
   Dosovitskiy A., 2021, PROC INT C LEARN REP, P1, DOI 10.48550/arXiv.2010.11929
   ELKarazle K, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031225
   Ellahyani A., 2023, PERS UBIQUIT COMPUT, V27, P235, DOI [10.1007/s00779-021-01660-y, DOI 10.1007/S00779-021-01660-Y]
   Eu C. Y., 2022, P INT C ART INT SMAR, DOI [10.1007/978-981-16-2183-3_69, DOI 10.1007/978-981-16-2183-3_69]
   Fan TL, 2020, IEEE ACCESS, V8, P179656, DOI 10.1109/ACCESS.2020.3025372
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Hao YZ, 2020, GUT LIVER, V14, P399, DOI 10.5009/gnl19097
   Hassan MF, 2022, MULTIMED TOOLS APPL, V81, P26331, DOI 10.1007/s11042-022-12429-7
   Helsingen L.M., 2022, NEJM EVIDENCE, P1, DOI [10.1056/EVIDra2100035, DOI 10.1056/EVIDRA2100035]
   Hu KL, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105760
   Issa IA, 2017, WORLD J GASTROENTERO, V23, P5086, DOI 10.3748/wjg.v23.i28.5086
   Jeong YH, 2016, J KOREAN MED SCI, V31, P1426, DOI 10.3346/jkms.2016.31.9.1426
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Khan MU, 2018, LECT NOTES ELECTR EN, V477, P39, DOI 10.1007/978-981-10-7629-9_5
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Lee J, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000007468
   Li YH, 2022, PROC CVPR IEEE, P4794, DOI 10.1109/CVPR52688.2022.00476
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lui TKL, 2020, WORLD J GASTROENTERO, V26, P5248, DOI 10.3748/wjg.v26.i35.5248
   Macari M, 2004, AM J ROENTGENOL, V183, P127, DOI 10.2214/ajr.183.1.1830127
   Mennigen R, 1988, Surg Endosc, V2, P84, DOI 10.1007/BF00704360
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Duc NT, 2022, IEEE ACCESS, V10, P80575, DOI 10.1109/ACCESS.2022.3195241
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Palmier R, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-04786-y
   Park KB, 2022, J COMPUT DES ENG, V9, P616, DOI 10.1093/jcde/qwac018
   Puyal JGB, 2022, MED IMAGE ANAL, V82, DOI 10.1016/j.media.2022.102625
   Qadri SF, 2023, INT J INTELL SYST, V2023, DOI 10.1155/2023/2345835
   Rasouli Pezhman, 2020, Gastroenterol Hepatol Bed Bench, V13, P191
   Rawla P, 2019, GASTROENTEROL REV, V14, P89, DOI 10.5114/pg.2018.81072
   Ribeiro Jose, 2022, Procedia Computer Science, P477, DOI 10.1016/j.procs.2021.12.039
   Ronneberger O., U NET CONVOLUTIONAL
   Saberi Z., 2023, IAENG INT J APPL MAT, V53, P1
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Sanderson E, 2022, LECT NOTES COMPUT SC, V13413, P892, DOI 10.1007/978-3-031-12053-4_65
   Senore C, 2017, BEST PRACT RES CL GA, V31, P481, DOI 10.1016/j.bpg.2017.04.008
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Susstrunk S, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P127
   Suzuki K, 2010, MED PHYS, V37, P12, DOI 10.1118/1.3263615
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang FL, 2022, Arxiv, DOI arXiv:2212.11677
   Wang JF, 2022, LECT NOTES COMPUT SC, V13433, P110, DOI 10.1007/978-3-031-16437-8_11
   WILLIAMS C, 1973, GUT, V14, P990, DOI 10.1136/gut.14.12.990
   World Health Organization, 2022, COLORECTAL CANCER
   Yang K, 2022, ALEX ENG J, V61, P917, DOI 10.1016/j.aej.2021.04.072
   Yu XH, 2023, PATTERN RECOGN, V135, DOI 10.1016/j.patcog.2022.109131
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 65
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2023
VL 11
BP 69295
EP 69309
DI 10.1109/ACCESS.2023.3291783
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA M5JU4
UT WOS:001030586100001
OA gold
DA 2023-08-21
ER

PT J
AU He, XX
AF He, Xiaoxu
TI A multi-resolution unet algorithm based on data augmentation and
   multi-center training for polyp automatic segmentation
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Image segmentation; colon cancer; U-Net; polyp segmentation; data
   augmentation
ID DIAGNOSIS
AB In clinical practice, segmenting polyps from colonoscopy images plays an important role in the diagnosis and treatment of colorectal cancer since it provides valuable information. However, accurate polyp segmentation is full of changes due to the following reasons: (1) the small training datasets with a limited number of samples and the lack of data variability; (2) the same type of polyps with a variation in texture, size, and color; (3) the weak boundary between a polyp and its surrounding mucosa. To address these challenges, we propose a novel robust deep neural network based on data augmentation, called Robust Multi-center Multi-resolution Unet (RMMSUNet), for the polyp segmentation task. Data augmentation and Multi-center training are both utilized to increase the amount and diversity of training dataset. The new multi-resolution blocks make up for the lack of fine-grained information in U-Net, and ensures the generation of more accurate pixel-level segmentation prediction graphs. Region-based refinement is added as the post-processing for the network output, to correct some wrongly predicted pixels and further refine the segmentation results. Quantitative and qualitative evaluations on the challenging polyp dataset show that our RMMSUNet improves the segmentation accuracy significantly, when comparing to other SOTA algorithms.
C1 [He, Xiaoxu] Foshan Univ, Sch Guangdong & Taiwan Artificial Intelligence, Foshan 528000, Peoples R China.
C3 Foshan University
RP He, XX (通讯作者)，Foshan Univ, Sch Guangdong & Taiwan Artificial Intelligence, Foshan 528000, Peoples R China.
EM xiaoxuhe@outlook.com
FU Foshan University High-level Talent Research Start-up Fund
FX This work is supported by the Foshan University High-level Talent
   Research Start-up Fund.
CR [Anonymous], 2019, 2019 IEEE INT S MULT, P225
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Biller LH, 2021, JAMA-J AM MED ASSOC, V325, P669, DOI 10.1001/jama.2021.0106
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Ciuti G, 2016, J MICRO-BIO ROBOT, V11, P1, DOI 10.1007/s12213-016-0087-x
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Fan D.-P., 2020, MICCA
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Huang C.-H., 2021, ARXIV
   Jha D., RESUNET ADV ARCHITEC
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jones HJS, 2021, COLORECTAL DIS, V23, P868, DOI 10.1111/codi.15480
   Lou A., 2021, MED IMAGING
   Lou A., 2022, MED IMAGING
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sasmal P, 2018, INT CONF CIRC SYST S, P201, DOI 10.1109/ICSIGSYS.2018.8372666
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tomar N.K., 2021, ICPR
   Tomar NK, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3159394
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Zhou ZL, 2021, IEEE T BIG DATA, V7, P559, DOI 10.1109/TBDATA.2019.2919570
NR 24
TC 0
Z9 0
U1 3
U2 3
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2023
VL 44
IS 3
BP 4593
EP 4604
DI 10.3233/JIFS-223340
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9W4CZ
UT WOS:000949027400074
DA 2023-08-21
ER

PT J
AU Huang, QX
   Lin, GS
   Sun, HM
AF Huang, Qi-Xian
   Lin, Guo-Shiang
   Sun, Hung-Min
TI Classification of Polyps in Endoscopic Images Using Self-Supervised
   Structured Learning
SO IEEE ACCESS
LA English
DT Article
DE Solid modeling; Task analysis; Feature extraction; Computer aided
   diagnosis; Visualization; Medical diagnostic imaging; Computational
   modeling; Self-supervised learning; Computer-aided diagnosis;
   self-supervised learning; SimCLR; Polyp classification; look-into-object
AB This study uses a two-stage learning computer-aided diagnosis (CAD) scheme that has a convolutional neural network(CNN) with self-supervised learning(SSL) to classify polyps as either a hyperplastic polyp (HP) or a Tubular Adenoma (TA). The proposed model uses look-into-object (LIO) and contrastive learning in SimCLR to focus on the holistic polyp region and allows greater model performance. However, the LIO scheme relies on pretraining a model to provide basic representations so this model is modified using a warm-up scheme to improve the loss function. There are insufficient medical images to train efficient representation for polyp classification so another approach uses natural images, instead of polyp images, for the pretext task. The experimental results show that the proposed scheme which uses polyp object structure information and self-supervised learning produces a robust model that allows better classification as either HP or TA in the prediction head by transferring a backbone. The backbone model uses ResNet-18 effectively to concentrate on the holistic polyp using limited labeled polyp images. The proposed scheme outperforms an existing method with a 4% increase in accuracy and a 3% improvement in F1-score.
C1 [Huang, Qi-Xian] Natl Tsing Hua Univ, Inst Informat Syst & Applicat, Hsinchu 30013, Taiwan.
   [Lin, Guo-Shiang] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
   [Sun, Hung-Min] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30013, Taiwan.
C3 National Tsing Hua University; National Chin-Yi University of
   Technology; National Tsing Hua University
RP Sun, HM (通讯作者)，Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 30013, Taiwan.
EM gslin@ncut.edu.tw; hmsun@cs.nthu.edu.tw
OI Huang, Qi-Xian/0000-0002-5507-8337
FU Chang Bing Show-Chwan Memorial Hospital Institute; Ministry of Science
   and Technology, Taiwan [MOST 111-2221-E-007-078-MY3,
   110-2221-E-007-040-MY3]
FX The work of Guo-Shiang Lin was supported in part by the Chang Bing
   Show-Chwan Memorial Hospital Institute; and in part by the Ministry of
   Science and Technology, Taiwan, under Project MOST
   111-2221-E-007-078-MY3 and Project 110-2221-E-007-040-MY3.
CR Ayoub J, 2010, IEEE ENG MED BIO, P5585, DOI 10.1109/IEMBS.2010.5626790
   Azizi S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3458, DOI 10.1109/ICCV48922.2021.00346
   Chen LC, 2017, Arxiv, DOI arXiv:1706.05587
   Chen T, 2020, Arxiv, DOI [arXiv:2002.05709, DOI 10.48550/ARXIV.2002.05709]
   Chen T, 2020, Arxiv, DOI [arXiv:2006.10029, DOI 10.48550/ARXIV.2006.10029]
   Chen Xinlei, 2020, Arxiv, DOI arXiv:2003.04297
   Chen XL, 2020, Arxiv, DOI arXiv:2011.10566
   Chung C.-Y., 2022, SELF SUPERVISED OBJE
   Dai Y, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/9479563
   Hjelm RD, 2019, Arxiv, DOI [arXiv:1808.06670, DOI 10.48550/ARXIV.1808.06670]
   Golhar M, 2021, IEEE ACCESS, V9, P631, DOI [10.1109/ACCESS.2020.3047544, 10.1109/access.2020.3047544]
   Grill J.-B., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2006.07733
   Chang AH, 2020, Arxiv, DOI arXiv:2004.13263
   Hafidi H, 2020, Arxiv, DOI arXiv:2007.08025
   Hamoudah T, 2022, GASTROINTEST ENDOSC, V96, P95, DOI 10.1016/j.gie.2022.02.015
   He K., 2020, CVPR, P9729
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   H‚naff OJ, 2020, Arxiv, DOI arXiv:1905.09272
   Hsu KJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P748
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kader R, 2021, WORLD J GASTROENTERO, V27, DOI [10.3748/wjg.v27.i35.5908ISSN, 10.3748/wjg.v27.i35.5908]
   Kaneko K, 2014, ENDOSC INT OPEN, V2, pE212, DOI 10.1055/s-0034-1390707
   Kim JY, 2022, bioRxiv, DOI [10.1101/2022.06.15.496360, 10.1101/2022.06.15.496360, DOI 10.1101/2022.06.15.496360]
   Kim YJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83199-9
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Laskin M., 2020, INT C MACHINE LEARNI, V119, P5639
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Liu X, 2019, SPRINGER THESES-RECO, P1, DOI 10.1007/978-981-13-8703-6
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma Y., 2019, PROC 8 INT S NEXT GE, P1, DOI [10.1109/ISNE.2019.8896576, DOI 10.1109/ISNE.2019.8896576]
   Ming-Hsien Tsai, 2020, ICGSP 2020: Proceedings of the 2020 4th International Conference on Graphics and Signal Processing, P61, DOI 10.1145/3406971.3406977
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sima I, 2021, IEEE INT C BIOINF BI, DOI 10.1109/BIBE52308.2021.9635497
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Su YK, 2022, AAAI CONF ARTIF INTE, P2289
   Szegedy C., 2013, P ADV NEUR INF PROC, V26, P2553, DOI DOI 10.5555/2999792.2999897
   Thanh, 2021, J MILIT SCI TECHNOL, P3, DOI DOI 10.54939/1859-1043.J.MST.CSCE5.2021.3-13
   Tian YL, 2020, Arxiv, DOI arXiv:1906.05849
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   van den Oord Aaron, 2018, REPRESENTATION LEARN, DOI DOI 10.48550/ARXIV.1807.03748
   Wah C, 2011, CNSTR2011001 CALTECH
   Wang Y., 2019, P IEEE INT C SIGN IN, P1, DOI [10.1109/ICSIDP47821.2019.9173377, DOI 10.1109/ICSIDP47821.2019.9173377]
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   WOLFF WI, 1973, NEW ENGL J MED, V288, P329, DOI 10.1056/NEJM197302152880701
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Yoshida N., DIGEST ENDOSC
   Yude Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12272, DOI 10.1109/CVPR42600.2020.01229
   Zhang F., 2021, P IEEECVF INT C COMP, P7242
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou MH, 2020, PROC CVPR IEEE, P11771, DOI 10.1109/CVPR42600.2020.01179
NR 52
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2023
VL 11
BP 50025
EP 50037
DI 10.1109/ACCESS.2023.3277029
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA I8UU8
UT WOS:001005487900001
OA gold
DA 2023-08-21
ER

PT J
AU Ige, AO
   Tomar, NK
   Aranuwa, FO
   Oriola, O
   Akingbesote, AO
   Noor, MHM
   Mazzara, M
   Aribisala, BS
AF Ige, Ayokunle Olalekan
   Tomar, Nikhil Kumar
   Aranuwa, Felix Ola
   Oriola, Oluwafemi
   Akingbesote, Alaba O.
   Noor, Mohd Halim Mohd
   Mazzara, Manuel
   Aribisala, Benjamin Segun
TI ConvSegNet: Automated Polyp Segmentation From Colonoscopy Using Context
   Feature Refinement With Multiple Convolutional Kernel Sizes
SO IEEE ACCESS
LA English
DT Article
DE Biomedical; colonoscopy; image; kernel; polyp; segmentation
ID IMAGE SEGMENTATION; NETWORKS; ACCURATE
AB Colorectal cancer occurs in the rectal of humans, and early detection has been proved to reduce its mortality rate. Colonoscopy is the standard used in detecting the presence of polyps in the rectal, and accurate segmentation of the polyps from colonoscopy images often provides helpful information for early diagnosis and treatment. Although existing deep learning models often achieve high segmentation performance when tested on the same dataset used in model training; still, their performance often degrades when applied to out-of-distribution datasets, leading to low model generalization or overfitting. This challenge is often associated with the quality of the features learnt from the input images. In this work, a novel Context Feature Refinement (CFR) module is proposed to address the challenge of low model generalization and segmentation performance. The CFR module is built to extract contextual information from the incoming feature map by using multiple parallel convolutional layers with progressively increasing kernel sizes. Using multiple parallel convolutions with different kernel sizes helped to extract more efficient multi-scale contextual information and thus enabled the network to effectively identify and segment small and fine details, as well as larger and more complex structures in the input images. Extensive experiments on three public benchmark datasets in CVC-ClinicDB, Kvasir-SEG, and BKAI-NeoPolyp showed that the proposed ConvSegNet model achieved jaccard, dice and F2 scores of 0.8650, 0.9177, and 0.9328 on CVC-ClinicDB, 0.7936, 0.8618, and 0.8855 on Kvasir-SEG, and 0.8045, 0.8747 and 0.8909 on BKAI-NeoPolyp datasets respectively. Also, an improved generalization performance was achieved by the ConvSegNet model, compared to the benchmark polyp segmentation models. Code is available at https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/AOige/ConvSegNet.
C1 [Ige, Ayokunle Olalekan; Noor, Mohd Halim Mohd] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Tomar, Nikhil Kumar] Indira Gandhi Natl Open Univ, Sch Comp & Informat Sci SOCIS, New Delhi 110068, India.
   [Aranuwa, Felix Ola; Oriola, Oluwafemi; Akingbesote, Alaba O.] Adekunle Ajasin Univ, Dept Comp Sci, Akungba Akoko, Ondo, Nigeria.
   [Mazzara, Manuel] Innopolis Univ, Inst Software Dev & Engn, Innopolis 420500, Russia.
   [Aribisala, Benjamin Segun] Lagos State Univ, Dept Comp Sci, Lagos 102101, Nigeria.
   [Aribisala, Benjamin Segun] Univ Chicago, Dept Med, Chicago, IL 60637 USA.
C3 Universiti Sains Malaysia; Innopolis University; Lagos State University;
   University of Chicago
RP Ige, AO (通讯作者)，Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
EM ayo.ige@aaua.edu.ng
RI Mazzara, Manuel/R-1827-2019; Mohd Noor, Mohd Halim/J-9700-2013
OI Mazzara, Manuel/0000-0002-3860-4948; Mohd Noor, Mohd
   Halim/0000-0002-3300-3270; Ige, Ayokunle/0000-0001-5155-9304
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Ameling S., 2009, BILDVERARBEITUNG MED, DOI [10.1007/978-3-540-93860-6-70, DOI 10.1007/978-3-540-93860-6-70]
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bouget D, 2019, INT J COMPUT ASS RAD, V14, P977, DOI 10.1007/s11548-019-01948-8
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843, DOI DOI 10.5555/2999325.2999452
   Condessa F, 2012, LECT NOTES COMPUT SC, V7325, P188, DOI 10.1007/978-3-642-31298-4_23
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Huang C.-H., 2021, ARXIV
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Kassani S. H., 2020, ADV ARTIFICIAL INTEL, DOI [10.1007/978-3-030-47358-7_29, DOI 10.1007/978-3-030-47358-7_29]
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Nguyen NQ, 2020, IEEE ACCESS, V8, P99495, DOI 10.1109/ACCESS.2020.2995630
   Norouzi A, 2014, IETE TECH REV, V31, P199, DOI 10.1080/02564602.2014.906861
   Lan PN, 2021, LECT NOTES COMPUT SC, V13018, P15, DOI 10.1007/978-3-030-90436-4_2
   Pogorelov K, P 8 ACM MULTIMEDIA S
   Puyal Juana Gonzalez-Bueno, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P295, DOI 10.1007/978-3-030-59725-2_29
   Qadir H. A., 2019, 2019 13 INT S MEDICA, P1, DOI [10.1109/ISMICT.2019.8743694, DOI 10.1109/ISMICT.2019.8743694]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rundle AG, 2008, GASTROENTEROLOGY, V134, P1311, DOI 10.1053/j.gastro.2008.02.032
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Sharma P., 2022, IEEE T BIOMED ENG EA, DOI [10.1109/TBME.2022.3216269, DOI 10.1109/TBME.2022.3216269]
   Srivastava A, 2022, IEEE J BIOMED HEALTH, V26, P2252, DOI 10.1109/JBHI.2021.3138024
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Thakkar S, 2020, GASTROENTEROLOGY, V158, P1219, DOI 10.1053/j.gastro.2019.12.035
   Thomas SM, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101915
   Tomar NK, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3159394
   Torre LA, 2015, CA-CANCER J CLIN, V65, P87, DOI 10.3322/caac.21262
   Valanarasu JMJ, 2022, LECT NOTES COMPUT SC, V13435, P23, DOI 10.1007/978-3-031-16443-9_3
   van Opbroek A, 2015, IEEE T MED IMAGING, V34, P1018, DOI 10.1109/TMI.2014.2366792
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Weng WH, 2021, IEEE ACCESS, V9, P16591, DOI 10.1109/ACCESS.2021.3053408
   Yeung M, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104815
   You D, 2014, COMP MED SY, P539, DOI 10.1109/CBMS.2014.128
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
   Zhou LX, 2020, IEEE T MED IMAGING, V39, P2638, DOI 10.1109/TMI.2020.3001810
   Zhou XR, 2018, PROC SPIE, V10575, DOI 10.1117/12.2295178
   Zhou XY, 2018, THIN SOLID FILMS, V648, P83, DOI 10.1016/j.tsf.2018.01.007
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zunair H, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104699
NR 50
TC 0
Z9 0
U1 9
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2023
VL 11
BP 16142
EP 16155
DI 10.1109/ACCESS.2023.3244789
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 9E9FY
UT WOS:000937085000001
OA gold
DA 2023-08-21
ER

PT J
AU Jasim, MJM
   Hussan, BK
   Zeebaree, SRM
   Ageed, ZS
AF Jasim, Mohammed Jasim Mohammed
   Hussan, Bzar Khidir
   Zeebaree, Subhi R. M.
   Ageed, Zainab Salih
TI Automated Colonic Polyp Detection and Classification Enabled Northern
   Goshawk Optimization with Deep Learning
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Biomedical imaging; artificial intelligence; colonic polyp;
   classification; medical image classification; computer -aided diagnosis
ID IMAGES
AB The major mortality factor relevant to the intestinal tract is the growth of tumorous cells (polyps) in various parts. More specifically, colonic polyps have a high rate and are recognized as a precursor of colon cancer growth. Endoscopy is the conventional technique for detecting colon polyps, and considerable research has proved that automated diagnosis of image regions that might have polyps within the colon might be used to help experts for decreasing the polyp miss rate. The automated diagnosis of polyps in a computer-aided diagnosis (CAD) method is implemented using statistical networks (CNN), is broadly employed to allow the extraction of representative features. This manuscript devises a new Northern Goshawk Optimization with Transfer Learning Model for Colonic Polyp Detection and Classification (NGOTL-CPDC) model. The NGOTL-CPDC technique aims to investigate endoscopic images for automated colonic polyp detection. To accomplish this, the NGOTL-CPDC technique comprises of adaptive bilateral filtering (ABF) technique as a noise removal process and image pre-processing step. Besides, the NGOTL-CPDC model applies the Faster SqueezeNet model for feature extraction purposes in which the hyperparameter tuning process is performed using the NGO optimizer. Finally, the fuzzy Hopfield neural network (FHNN) method can be employed for colonic poly detection and classification. A widespread simulation analysis is carried out to ensure the improved outcomes of the NGOTL-CPDC model. The comparison study demonstrates the enhancements of the NGOTL-CPDC model on the colonic polyp classification process on medical test images.
C1 [Jasim, Mohammed Jasim Mohammed] Al Kitab Univ, Engn Coll, Kirkuk, Iraq.
   [Hussan, Bzar Khidir] Erbil Polytech Univ, Erbil Tech Engn Coll, Informat Syst Engn Dept, Erbil, Iraq.
   [Zeebaree, Subhi R. M.] Duhok Polytech Univ, Tech Coll Engn, Energy Eng Dept, Duhok, Iraq.
   [Ageed, Zainab Salih] Nawroz Univ, Coll Sci, Comp Sci Dept, Duhok, Iraq.
C3 Al-Kitab University; Erbil Polytechnic University
RP Zeebaree, SRM (通讯作者)，Duhok Polytech Univ, Tech Coll Engn, Energy Eng Dept, Duhok, Iraq.
EM subhi.rafeeq@dpu.edu.krd
RI Zeebaree, Subhi R. M./ADN-8057-2022
OI Zeebaree, Subhi R. M./0000-0002-3895-2619
CR Azer SA, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55080473
   Bora K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83788-8
   Dehghani M, 2021, IEEE ACCESS, V9, P162059, DOI 10.1109/ACCESS.2021.3133286
   Escorcia-Gutierrez J, 2022, COMPUT ELECTR ENG, V104, DOI 10.1016/j.compeleceng.2022.108462
   Gong EJ, 2022, J PERS MED, V12, DOI 10.3390/jpm12060963
   Ho CW, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06264-x
   Hsu CM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21185995
   Iizuka O, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58467-9
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Jangid M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020041
   Li JY, 2019, CHINESE J ELECTRON, V28, P718, DOI 10.1049/cje.2019.03.005
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Mahmood F, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aada93
   Ribeiro E, 2017, I S BIOMED IMAGING, P1044, DOI 10.1109/ISBI.2017.7950695
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Sudeep PV, 2016, COMPUT BIOL MED, V71, P97, DOI 10.1016/j.compbiomed.2016.02.003
   Tamang LD, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210982
   Tanwar S., 2020, J COMPUT THEOR NANOS, V17, P2354
   Wang J, 2019, INT J CONTROL AUTOM, V17, P1322, DOI 10.1007/s12555-017-0695-9
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Xu Y, 2020, MATH METHOD APPL SCI, DOI 10.1002/mma.6381
NR 21
TC 0
Z9 0
U1 3
U2 3
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2023
VL 75
IS 2
BP 3677
EP 3693
DI 10.32604/cmc.2023.037363
PG 17
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA E5FH1
UT WOS:000975791200024
OA gold
DA 2023-08-21
ER

PT J
AU Liu, S
   Liu, X
   Chang, SL
   Sun, YF
   Li, KY
   Hou, Y
   Wang, SW
   Meng, J
   Zhao, QL
   Wu, SB
   Yang, K
   Xue, LY
AF Liu, Shuang
   Liu, Xiao
   Chang, Shilong
   Sun, Yufeng
   Li, Kaiyuan
   Hou, Ya
   Wang, Shiwei
   Meng, Jie
   Zhao, Qingliang
   Wu, Sibei
   Yang, Kun
   Xue, Linyan
TI Multi-Classification of Polyps in Colonoscopy Images Based on an
   Improved Deep Convolutional Neural Network
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Colorectal polyps; four-and six-category classifications; convolutional
   neural network; dilated residual network
ID COLORECTAL-CANCER; TASK-FORCE
AB Achieving accurate classification of colorectal polyps during colonoscopy can avoid unnecessary endoscopic biopsy or resection. This study aimed to develop a deep learning model that can automatically classify colorectal polyps histologically on white-light and narrow-band imaging (NBI) colonoscopy images based on World Health Organization (WHO) and Workgroup serrAted polypS and Polyposis (WASP) classification criteria for colorectal polyps. White-light and NBI colonoscopy images of colorectal polyps exhibiting pathological results were firstly collected and classified into four categories: conventional adenoma, hyperplastic polyp, sessile serrated adenoma/polyp (SSAP) and normal, among which conventional adenoma could be further divided into three sub-categories of tubular adenoma, villous adenoma and villioustublar adenoma, subsequently the images were re-classified into six categories. In this paper, we proposed a novel convolutional neural network termed Polyp-DedNet for the four-and six-category classification tasks of colorectal polyps. Based on the existing classification network ResNet50, Polyp-DedNet adopted dilated convolution to retain more high-dimensional spatial information and an Efficient Channel Attention (ECA) module to improve the classification performance further. To eliminate gridding artifacts caused by dilated convolutions, traditional convolutional layers were used instead of the max pooling layer, and two convolutional layers with progressively decreasing dilation were added at the end of the network. Due to the inevitable imbalance of medical image data, a regularization method DropBlock and a Class-Balanced (CB) Loss were performed to prevent network overfitting. Furthermore, the 5-fold cross -validation was adopted to estimate the performance of Polyp-DedNet for the multi-classification task of colorectal polyps. Mean accuracies of the proposed Polyp-DedNet for the four-and six-category classifications of colorectal polyps were 89.91% +/- 0.92% and 85.13% +/- 1.10%, respectively. The metrics of precision, recall and F1-score were also improved by 1%similar to 2% compared to the baseline ResNet50. The proposed Polyp-DedNet presented state-of-the-art performance for colorectal polyp classifying on white-light and NBI colonoscopy images, highlighting its considerable potential as an AI-assistant system for accurate colorectal polyp diagnosis in colonoscopy.
C1 [Liu, Shuang; Liu, Xiao; Chang, Shilong; Li, Kaiyuan; Hou, Ya; Wang, Shiwei; Wu, Sibei; Yang, Kun; Xue, Linyan] Hebei Univ, Coll Qual & Tech Supervis, Baoding 071002, Peoples R China.
   [Liu, Shuang; Yang, Kun; Xue, Linyan] Hebei Technol Innovat Ctr Lightweight New Energy V, Baoding 071002, Peoples R China.
   [Liu, Shuang; Yang, Kun; Xue, Linyan] Hebei Univ, Natl & Local Joint Engn Res Ctr Metrol Instrument, Baoding 071002, Peoples R China.
   [Sun, Yufeng] Hebei Univ, Coll Elect Informat Engn, Baoding 071002, Peoples R China.
   [Meng, Jie] Hebei Univ, Affiliated Hosp, Dept Orthoped, Baoding 071002, Peoples R China.
   [Zhao, Qingliang] Xiamen Univ, Ctr Mol Imaging & Translat Med, State Key Lab Mol Vaccinol & Mol Diagnost, Dept Lab Med,Sch Publ Hlth, Xiamen 361102, Peoples R China.
C3 Hebei University; Hebei University; Hebei University; Hebei University;
   Xiamen University
RP Yang, K; Xue, LY (通讯作者)，Hebei Univ, Coll Qual & Tech Supervis, Baoding 071002, Peoples R China.; Yang, K; Xue, LY (通讯作者)，Hebei Technol Innovat Ctr Lightweight New Energy V, Baoding 071002, Peoples R China.; Yang, K; Xue, LY (通讯作者)，Hebei Univ, Natl & Local Joint Engn Res Ctr Metrol Instrument, Baoding 071002, Peoples R China.
EM yangkun@hbu.edu.cn; lyxue@hbu.edu.cn
FU Research Fund for Foundation of Hebei University [DXK201914]; President
   of Hebei University [XZJJ201914]; Post-graduate's Innovation Fund
   Project of Hebei University [HBU2022SS003]; Special Project for
   Cultivating College Students' Scientific and Technological Innovation
   Ability in Hebei Province [22E50041D]; Guangdong Basic and Applied Basic
   Research Foundation [2021A1515011654]; Fundamental Research Funds for
   the Central Universities of China [20720210117]
FX This work was funded by the Research Fund for Foundation of Hebei
   University (DXK201914), the President of Hebei University (XZJJ201914) ,
   the Post-graduate's Innovation Fund Project of Hebei University
   (HBU2022SS003) the Special Project for Cultivating College Students'
   Scientific and Technological Innovation Ability in Hebei Province
   (22E50041D), Guangdong Basic and Applied Basic Research Foundation
   (2021A1515011654), and the Fundamental Research Funds for the Central
   Universities of China (20720210117).
CR Almadi MA, 2015, CAN J GASTROENTEROL, V29, P304, DOI 10.1155/2015/789038
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cao W, 2021, CHINESE MED J-PEKING, V134, P783, DOI 10.1097/CM9.0000000000001474
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Ghiasi G, 2018, ADV NEUR IN, V31
   GIGER ML, 1988, MED PHYS, V15, P158, DOI 10.1118/1.596247
   Goret CC, 2018, MED SCI MONITOR, V24, P6809, DOI 10.12659/MSM.911012
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   IJspeert JEG, 2017, GUT, V66, P1225, DOI 10.1136/gutjnl-2015-310784
   Ijspeert JE, 2015, GASTROINTEST ENDOSC, V81, pAB260, DOI 10.1016/j.gie.2015.03.1348
   Khan MA, 2020, NEURAL COMPUT APPL, V32, P15929, DOI 10.1007/s00521-019-04514-0
   Lee BI, 2012, CLIN ENDOSC, V45, P25, DOI 10.5946/ce.2012.45.1.25
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Poudel S, 2020, IEEE ACCESS, V8, P99227, DOI 10.1109/ACCESS.2020.2996770
   Powers DM, 2011, EVALUATION PRECISION, V2, P37
   Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155
   Radosavovic Ilija, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10425, DOI 10.1109/CVPR42600.2020.01044
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Strum WB, 2016, NEW ENGL J MED, V374, P1065, DOI [10.1056/NEJMra1513581, 10.1056/NEJMc1604867]
   Tamaki T, 2011, LECT NOTES COMPUT SC, V6493, P452
   Tan M., 2021, INT C MACHINE LEARNI, V139, P10096, DOI DOI 10.48550/ARXIV.2104.00298
   Wang WL, 2020, BMC PSYCHIATRY, V20, DOI 10.1186/s12888-020-02566-4
   Wang YD, 2023, CRIT REV FOOD SCI, V63, P3081, DOI 10.1080/10408398.2021.1984199
   Yamada M, 2015, GASTROINTEST ENDOSC, V82, P108, DOI 10.1016/j.gie.2014.12.037
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 31
TC 0
Z9 0
U1 12
U2 12
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2023
VL 75
IS 3
BP 5837
EP 5852
DI 10.32604/cmc.2023.034720
PG 16
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA G7YJ8
UT WOS:000991265700020
OA gold
DA 2023-08-21
ER

PT J
AU Lou, AG
   Guan, SY
   Loew, M
AF Lou, Ange
   Guan, Shuyue
   Loew, Murray
TI CaraNet: context axial reverse attention network for segmentation of
   small medical objects
SO JOURNAL OF MEDICAL IMAGING
LA English
DT Article
DE small object segmentation; brain tumor; colonoscopy; attention; context
   axial reverse
AB Purpose: Segmenting medical images accurately and reliably is important for disease diagnosis and treatment. It is a challenging task because of the wide variety of objects' sizes, shapes, and scanning modalities. Recently, many convolutional neural networks have been designed for segmentation tasks and have achieved great success. Few studies, however, have fully considered the sizes of objects; thus, most demonstrate poor performance for small object segmentation. This can have a significant impact on the early detection of diseases.Approach: We propose a context axial reverse attention network (CaraNet) to improve the segmentation performance on small objects compared with several recent state-of-the-art models. CaraNet applies axial reserve attention and channel-wise feature pyramid modules to dig the feature information of small medical objects. We evaluate our model by six different measurement metrics.Results: We test our CaraNet on segmentation datasets for brain tumor (BraTS 2018) and polyp (Kvasir-SEG, CVC-ColonDB, CVC-ClinicDB, CVC-300, and ETIS-LaribPolypDB). Our CaraNet achieves the top-rank mean Dice segmentation accuracy, and results show a distinct advantage of CaraNet in the segmentation of small medical objects.Conclusions: We proposed CaraNet to segment small medical objects and outperform state-of-the-art methods.
C1 [Lou, Ange] Vanderbilt Univ, Nashville, TN 37235 USA.
   [Guan, Shuyue; Loew, Murray] George Washington Univ, Washington, DC USA.
C3 Vanderbilt University; George Washington University
RP Lou, AG (通讯作者)，Vanderbilt Univ, Nashville, TN 37235 USA.
EM ange.lou@vanderbilt.edu; frankshuyueguan@gwu.edu; loew@gwu.edu
RI Lou, Ange/ITU-3390-2023
CR An P., 2020, CANC IMAGING ARCH, DOI 10.7937/TCIA.2020.GQRY-NC81
   Taghanaki SA, 2021, ARTIF INTELL REV, V54, P137, DOI 10.1007/s10462-020-09854-1
   Bakas S, 2019, Arxiv, DOI [arXiv:1811.02629, DOI 10.48550/ARXIV.1811.02629]
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen C, 2018, IEEE T PATTERN ANAL, V5
   Chen J., 2021, ARXIV
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heller N, 2020, Arxiv, DOI [arXiv:1904.00445, DOI 10.48550/ARXIV.1904.00445]
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Huang G., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Lin A., 2022, ARXIV210606716, V71, P1
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lou AE, 2023, COMPUT BIOL MED, V154, DOI 10.1016/j.compbiomed.2023.106579
   Lou A, 2021, IEEE IMAGE PROC, P1894, DOI 10.1109/ICIP42928.2021.9506485
   Mehta S., 2018, P EUR C COMP VIS ECC, P552, DOI DOI 10.1007/978-3-030-01249-6_34
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Ngo DK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217790
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth Holger R, 2021, Res Sq, DOI 10.21203/rs.3.rs-571332/v1
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Szegedy C., 2015, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Nguyen TC, 2021, LECT NOTES COMPUT SC, V12901, P633, DOI 10.1007/978-3-030-87193-2_60
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A., 2017, ADV NEURAL INFORM PR
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie YT, 2021, LECT NOTES COMPUT SC, V12903, P171, DOI 10.1007/978-3-030-87199-4_16
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101840
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 47
TC 1
Z9 1
U1 7
U2 7
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 2329-4302
EI 2329-4310
J9 J MED IMAGING
JI J. Med. Imaging
PD JAN 1
PY 2023
VL 10
IS 1
DI 10.1117/1.JMI.10.1.014005
PG 16
WC Radiology, Nuclear Medicine & Medical Imaging
WE Emerging Sources Citation Index (ESCI)
SC Radiology, Nuclear Medicine & Medical Imaging
GA D9GN3
UT WOS:000971739000005
PM 36820234
OA Green Submitted
DA 2023-08-21
ER

PT J
AU Obayya, M
   Al-Wesabi, FN
   Maashi, M
   Mohamed, A
   Hamza, MA
   Drar, S
   Yaseen, I
   Alsaid, MI
AF Obayya, Marwa
   Al-Wesabi, Fahd N.
   Maashi, Mashael
   Mohamed, Abdullah
   Hamza, Manar Ahmed
   Drar, Suhanda
   Yaseen, Ishfaq
   Alsaid, Mohamed Ibrahim
TI Modified Salp Swarm Algorithm With Deep Learning Based Gastrointestinal
   Tract Disease Classification on Endoscopic Images
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Diseases; Convolutional neural networks;
   Gastrointestinal tract; Tuning; Deep learning; Classification
   algorithms; Biomedical imaging; Particle swarm optimization; Medical
   imaging; gastrointestinal tract diseases; deep learning; metaheursitics;
   fine-tuning; salp swarm algorithm
AB Nowadays, the analysis of gastrointestinal (GI) tract disease utilzing endoscopic image classification becomes an active research activity from the biomedical sector. The latest technology in medical imaging is Wireless Capsule Endoscopy (WCE) for diagnosing gastrointestinal diseases namely bleeding, ulcer, polyp, and so on. Manual diagnoses will be time taking and tough for the medical practitioner; thus, the authors have designed computerized approaches for classifying and detecting such diseases. Many research groups presented various machine learning (ML) and image processing methods for classifying GI tract diseases in recent times. Conventional data augmentation and image processing methods are integrated with adjusted pre-trained deep convolutional neural networks (CNNs) for classifying diseases in the GI tract from WCI images. This study presents a Modified Salp Swarm Algorithm with Deep Learning based Gastrointestinal Tract Disease Classification (MSSADL-GITDC) on Endoscopic Images. The presented MSSADL-GITDC technique mainly focuses on the examination of WCE images for GIT classification. To accomplish this, the presented MSSADL-GITDC technique applies median filtering (MF) technique for image smoothening. The presented MSSADL-GITDC technique designs improved capsule network (CapsNet) model for feature extraction where the CapsNet model is modified by the class attention layer (CAL). Moreover, MSSA based hyperparameter tuning process is performed to improve the efficiency of the improved CapsNet model. For GIT classification, deep belief network with extreme learning machine (DBN-ELM) was used. Finally, backpropagation is applied for supervised fine tuning of the DBN-ELM model. The experimental validation of the MSSADL-GITDC technique takes place on Kvasir-V2 database reported the betterment of the MSSADL-GITDC technique on GIT classification with maximum accuracy of 98.03%.
C1 [Obayya, Marwa] Princess Nourah bint Abdulrahman Univ, Coll Engn, Dept Biomed Engn, Riyadh 11671, Saudi Arabia.
   [Al-Wesabi, Fahd N.] King Khalid Univ, Coll Sci & Art Mahayil, Dept Comp Sci, Abha 62217, Saudi Arabia.
   [Maashi, Mashael] King Saud Univ, Coll Comp & Informat Sci, Dept Software Engn, Riyadh 11543, Saudi Arabia.
   [Mohamed, Abdullah] Future Univ Egypt, Res Ctr, New Cairo 11845, Egypt.
   [Hamza, Manar Ahmed; Drar, Suhanda; Yaseen, Ishfaq; Alsaid, Mohamed Ibrahim] Prince Sattam Bin Abdulaziz Univ, Dept Comp & Self Dev Preparatory Year Deanship, Al Kharj 16242, Saudi Arabia.
C3 Princess Nourah bint Abdulrahman University; King Khalid University;
   King Saud University; Egyptian Knowledge Bank (EKB); Future University
   in Egypt; Prince Sattam Bin Abdulaziz University
RP Al-Wesabi, FN (通讯作者)，King Khalid Univ, Coll Sci & Art Mahayil, Dept Comp Sci, Abha 62217, Saudi Arabia.
EM falwesabi@kku.edu.sa
RI Al-Wesabi, Fahd N./AAV-6279-2020; Maashi, Mashael S./AAJ-3501-2020
OI Al-Wesabi, Fahd N./0000-0002-4389-4927; Maashi, Mashael
   S./0000-0003-0446-5430
FU Deanship of Scientific Research at King Khalid University [10/44]; King
   Saud University, Riyadh, Saudi Arabia [PNURSP2023R203, RSP2023R787];
   Prince Sattam bin Abdulaziz University [PSAU/2023/R/1444]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Khalid University for funding this work through Large
   Groups Project under grant number (10/44). Princess Nourah bint
   Abdulrahman University Researchers Supporting Project number
   (PNURSP2023R203), Princess Nourah bint Abdulrahman University, Riyadh,
   Research Supporting Project number(RSP2023R787), King Saud University,
   Riyadh, Saudi Arabia. Saudi Arabia. This study is supported via funding
   from Prince Sattam bin Abdulaziz University project number
   (PSAU/2023/R/1444).
CR Afriyie Y, 2022, COGENT ENG, V9, DOI 10.1080/23311916.2022.2142072
   [Anonymous], 2022, INT J INTELL SYST, V37, P5796, DOI [10.1002/int.22815, DOI 10.1002/INT.22815]
   Auzine P., 2022, P 3 INT C NEXT GEN C, P1, DOI [10.1109/NextComp55567.2022.9932202.[6]F.J, DOI 10.1109/NEXTCOMP55567.2022.9932202.[6]F.J]
   Ayidzoe MA, 2023, J INTELL FUZZY SYST, V44, P3079, DOI 10.3233/JIFS-212168
   Biradher P., 2022, P IEEE DELH SECT C D, P1, DOI [10.1109/DELCON54057.2022.9753487, DOI 10.1109/DELCON54057.2022.9753487]
   Djenouri Y, 2023, IEEE SENS J, V23, P947, DOI 10.1109/JSEN.2022.3202437
   Fang H, 2021, IEEE ACCESS, V9, P141245, DOI 10.1109/ACCESS.2021.3119615
   Haile A. O., 2022, COGENT ENG, V9
   Hmoud al-adhaileh Mosleh, 2021, Complexity, DOI 10.1155/2021/6170416
   Igarashi S, 2020, COMPUT BIOL MED, V124, DOI 10.1016/j.compbiomed.2020.103950
   Iqbal I., 2022, INTELL SYST APPL, V16, P200149, DOI [10.1016/j.iswa.2022.200149, DOI 10.1016/J.ISWA.2022.200149]
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112718
   Khan MA, 2022, HUM-CENT COMPUT INFO, V12, DOI 10.22967/HCIS.2022.12.025
   Lonseko ZM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311136
   Luo XD, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103443
   Mohammad F, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072801
   Ozturk S, 2020, MULTIMED TOOLS APPL, V79, P28825, DOI 10.1007/s11042-020-09468-3
   Parasa S, 2020, GASTROINTEST ENDOSC, V92, P938, DOI 10.1016/j.gie.2020.04.044
   Qi HT, 2022, IEEE ACCESS, V10, P113397, DOI 10.1109/ACCESS.2022.3215706
   Ramamurthy K, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102316
   Raut V, 2023, COMP M BIO BIO E-IV, V11, P606, DOI 10.1080/21681163.2022.2099298
   Sharif M, 2021, J EXP THEOR ARTIF IN, V33, P577, DOI 10.1080/0952813X.2019.1572657
   Su QS, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106054
   Sutton R. T., 2022, SCI REP-UK, V12, P1
   Tightiz L, 2022, ENERGIES, V15, DOI 10.3390/en15218210
   Tubishat M, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113122
   Wang Wei, 2022, International Journal of Intelligent Systems, V37, P5796, DOI 10.1002/int.22815
   Yang SF, 2021, IEEE T MED IMAGING, V40, P38, DOI 10.1109/TMI.2020.3021560
   Yaxing Cao, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P1584, DOI 10.1109/CompComm.2018.8780859
   Yogapriya J, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/5940433
NR 31
TC 0
Z9 0
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2023
VL 11
BP 25959
EP 25967
DI 10.1109/ACCESS.2023.3256084
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA A8GJ6
UT WOS:000957444800001
OA gold
DA 2023-08-21
ER

PT J
AU Raymann, J
   Rajalakshmi, R
AF Raymann, Joel
   Rajalakshmi, Ratnavel
TI GAR-Net: Guided Attention Residual Network for Polyp Segmentation from
   Colonoscopy Video Frames
SO DIAGNOSTICS
LA English
DT Article
DE medical image analysis; polyp segmentation; colonoscopy; deep learning;
   attention mechanism; semantic segmentation; healthcare informatics
ID FEATURE-SELECTION; VALIDATION
AB Colorectal Cancer is one of the most common cancers found in human beings, and polyps are the predecessor of this cancer. Accurate Computer-Aided polyp detection and segmentation system can help endoscopists to detect abnormal tissues and polyps during colonoscopy examination, thereby reducing the chance of polyps growing into cancer. Many of the existing techniques fail to delineate the polyps accurately and produce a noisy/broken output map if the shape and size of the polyp are irregular or small. We propose an end-to-end pixel-wise polyp segmentation model named Guided Attention Residual Network (GAR-Net) by combining the power of both residual blocks and attention mechanisms to obtain a refined continuous segmentation map. An enhanced Residual Block is proposed that suppresses the noise and captures low-level feature maps, thereby facilitating information flow for a more accurate semantic segmentation. We propose a special learning technique with a novel attention mechanism called Guided Attention Learning that can capture the refined attention maps both in earlier and deeper layers regardless of the size and shape of the polyp. To study the effectiveness of the proposed GAR-Net, various experiments were carried out on two benchmark collections viz., CVC-ClinicDB (CVC-612) and Kvasir-SEG dataset. From the experimental evaluations, it is shown that GAR-Net outperforms other previously proposed models such as FCN8, SegNet, U-Net, U-Net with Gated Attention, ResUNet, and DeepLabv3. Our proposed model achieves 91% Dice co-efficient and 83.12% mean Intersection over Union (mIoU) on the benchmark CVC-ClinicDB (CVC-612) dataset and 89.15% dice co-efficient and 81.58% mean Intersection over Union (mIoU) on the Kvasir-SEG dataset. The proposed GAR-Net model provides a robust solution for polyp segmentation from colonoscopy video frames.
C1 [Raymann, Joel] Univ Waterloo, Fac Math, Waterloo, ON N2L 3G1, Canada.
   [Rajalakshmi, Ratnavel] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, India.
C3 University of Waterloo; Vellore Institute of Technology (VIT); VIT
   Chennai
RP Rajalakshmi, R (通讯作者)，Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, India.
EM rajalakshmi.r@vit.ac.in
OI , Ratnavel Rajalakshmi/0000-0002-6570-483X
CR Aina OE, 2019, INT CONF ELECT COMP, DOI 10.1109/ICECCO48375.2019.9043220
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Breier M, 2011, PROC SPIE, V7963, DOI 10.1117/12.877986
   Cao P, 2017, PATTERN RECOGN, V64, P327, DOI 10.1016/j.patcog.2016.11.007
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chung M, 2021, ARTIF INTELL MED, V113, DOI 10.1016/j.artmed.2021.102023
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Dong H, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1201, DOI 10.1145/3123266.3129391
   Gross S., 2009, BILDVERARBEITUNG F R, P252
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Hao DD, 2020, NEURAL NETWORKS, V128, P172, DOI 10.1016/j.neunet.2020.05.005
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Ioffe S., 2015, INT C MACHINE LEARNI
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lawton C., 2013, YEARB ONCOL, V2013, P128, DOI [10.1016/j.yonc.2013.04.004, DOI 10.1016/J.YONC.2013.04.004]
   Long J., 2015, IEEE C COMP VIS PATT, P3431, DOI 10.1109/CVPR.2015.7298965
   Manjunath KN, 2020, BIOMED J, V43, P74, DOI 10.1016/j.bj.2019.07.006
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029
   Thambawita V., 2018, CEUR WORKSHOP PROC, V2283
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vaswani A., 2017, ADV NEURAL INFORM PR
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Yao JH, 2009, PATTERN RECOGN, V42, P1029, DOI 10.1016/j.patcog.2008.09.034
NR 31
TC 0
Z9 0
U1 12
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD JAN
PY 2023
VL 13
IS 1
AR 123
DI 10.3390/diagnostics13010123
PG 18
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 7Q2OR
UT WOS:000909236600001
PM 36611415
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Semenov, S
   Costigan, C
   Ismail, MS
   McNamara, D
AF Semenov, Serhiy
   Costigan, Conor
   Ismail, Mohd Syafiq
   McNamara, Deirdre
TI Low Colon Capsule Endoscopy (CCE) False Negative Rate for Polyps
   Excluding Reader Error
SO DIAGNOSTICS
LA English
DT Article
DE colon capsule endoscopy; false negative rates; colonic polyp; capsule
   endoscopy
ID EUROPEAN-SOCIETY; ARTIFICIAL-INTELLIGENCE; COLORECTAL POLYPS; CT
   COLONOGRAPHY; COLONOSCOPY; ESGE; METAANALYSIS; DIAGNOSIS; ACCURACY;
   IMPACT
AB Background: CCE is a diagnostic tool lacking clinical data on false negative rates. We aimed to assess this rate and the reader/technical error breakdown. Methods: False negative CCEs were identified after comparing to a colonoscopy database. Missed pathology characteristics and study indications/quality were collated. Cases were re-read by experts and newly identified lesions/pathologies were verified by an expert panel and categorised as reader/technical errors. Results: Of 532 CCEs, 203 had an adequately reported comparative colonoscopy, 45 (22.2%) had missed polyps, and 26/45 (57.8%) reached the colonic section with missed pathology. Of the cases, 22 (84.6%) had adequate bowel preparation. Indications included 13 (50%) polyp surveillance, 12 (46%) GI symptoms, 1 (4%) polyp screening. CCE missed 18 (69.2%) diminutive polyps and 8 (30.8%) polyps >= 6 mm, 18/26 (69.2%) of these were adenomas. Excluding incomplete CCE correlates, colonoscopy total and significant polyp yield were 97/184 (52.7%) and 50/97 (51.5%), respectively. CCE total polyp and significant polyp false negative rate was 26.8% (26/97) and 16% (8/50), respectively. Following re-reading, reader and technical error was 20/26 (76.9%) and 6/26 (23.1%). Total and significant missed polyp rates were 20.6% (20/97) and 14% (7/50) for reader error, 6.2% (6/97) and 2% (1/50) for technical error. Conclusions: False negative CCE rate is not insubstantial and should be factored into clinical decision making.
C1 [Semenov, Serhiy; Costigan, Conor; Ismail, Mohd Syafiq; McNamara, Deirdre] Tallaght Hosp, Trinity Coll Dublin, Trinity Ctr, Trinity Acad Gastroenterol Grp, Dublin D02R590, Ireland.
   [Costigan, Conor; McNamara, Deirdre] Tallaght Univ Hosp, Dept Gastroenterol, Dublin D24NR0A, Ireland.
C3 CHARMEU; Trinity College Dublin
RP Semenov, S (通讯作者)，Tallaght Hosp, Trinity Coll Dublin, Trinity Ctr, Trinity Acad Gastroenterol Grp, Dublin D02R590, Ireland.
EM semenovs@tcd.ie
CR Ali H, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.17560
   Alihosseini Samira, 2020, Med J Islam Repub Iran, V34, P81, DOI 10.34171/mjiri.34.81
   Eliakim R, 2009, ENDOSCOPY, V41, P1026, DOI 10.1055/s-0029-1215360
   Facciorusso A, 2019, CLIN GASTROENTEROL H, V17, P2439, DOI 10.1016/j.cgh.2018.11.058
   Fatima H, 2008, CLIN GASTROENTEROL H, V6, P109, DOI 10.1016/j.cgh.2007.10.009
   Gonzalez-Suarez B, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01717-4
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Health Quality Ontario, 2015, Ont Health Technol Assess Ser, V15, P1
   Holleran G, 2014, ENDOSCOPY, V46, P473, DOI 10.1055/s-0034-1365402
   Ismail MS, 2021, ENDOSC INT OPEN, V09, pE965, DOI 10.1055/a-1401-9528
   Kjolhede T, 2021, ENDOSCOPY, V53, P713, DOI 10.1055/a-1249-3938
   Kobaek-Larsen M, 2018, COLORECTAL DIS, V20, P479, DOI 10.1111/codi.13965
   Koffas A, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12092093
   Mascarenhas M, 2021, ANN GASTROENTEROL, V34, P300, DOI 10.20524/aog.2021.0606
   Michopoulos S, 2021, ANN GASTROENTEROL, V34, P53, DOI 10.20524/aog.2020.0549
   Mollers T, 2021, ENDOSC INT OPEN, V09, pE562, DOI 10.1055/a-1353-4849
   Moen S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12081994
   Otani I, 2020, DIGESTION, V101, P262, DOI 10.1159/000499332
   Pecere S, 2020, GASTROINTEST ENDOSC, V91, P406, DOI 10.1016/j.gie.2019.09.041
   Rex DK, 2002, AM J GASTROENTEROL, V97, P1696
   Rex DK, 2015, GASTROENTEROLOGY, V148, P948, DOI 10.1053/j.gastro.2015.01.025
   Rokkas T, 2010, GASTROINTEST ENDOSC, V71, P792, DOI 10.1016/j.gie.2009.10.050
   Rondonotti E, 2018, ENDOSCOPY, V50, P423, DOI 10.1055/a-0576-0566
   Rutter MD, 2020, GUT, V69, P201, DOI 10.1136/gutjnl-2019-319858
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Spada C, 2021, EUR RADIOL, V31, P2967, DOI 10.1007/s00330-020-07413-4
   Spada C, 2011, GASTROINTEST ENDOSC, V74, P581, DOI 10.1016/j.gie.2011.03.1125
   Spada C, 2010, CLIN GASTROENTEROL H, V8, P516, DOI 10.1016/j.cgh.2010.02.018
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Jimenez BV, 2017, GASTROENT HEPAT-BARC, V40, P10, DOI 10.1016/j.gastrohep.2016.03.003
   Yamada K, 2020, DIGESTION, V101, P316, DOI 10.1159/000498942
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 32
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD JAN
PY 2023
VL 13
IS 1
AR 56
DI 10.3390/diagnostics13010056
PG 9
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 7P3WE
UT WOS:000908639100001
PM 36611348
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Shi, JH
   Zhang, Q
   Tang, YH
   Zhang, ZQ
AF Shi, Jing-Hui
   Zhang, Qing
   Tang, Yu-Hao
   Zhang, Zhong-Qun
TI Polyp-Mixer: An Efficient Context-Aware MLP-Based Paradigm for Polyp
   Segmentation
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
LA English
DT Article
DE MLP; colonoscopy; polyp segmentation
AB and efficient polyp segmentation plays a crucial role in colonoscopy, which is important for the prevention of colorectal cancer. Despite CNN-based methods have achieved great progress in the polyp segmentation task, they are incapable of modeling long-range dependencies. Transformer-based models utilize self-attention mechanism to overcome this problem while suffering from heavy computing cost. Benefiting from simple structures, MLP-based models seem to be an alternative. However, they struggle with dealing with flexible input scales and modeling long-term dependencies. Both of these two factors are important for image segmentation, which could explain why the MLP architecture performs poorly compared to the Transformer. To remedy this issue, we propose a novel Polyp Mixer, which utilizes MLP-based structures in both encoder and decoder. In particular, we use CycleMLP as the encoder to overcome the fixed input scale issue. Besides, we propose a Multi-head Mixer by converting the current CycleMLP into a Multi-head fashion, allowing our model to explore rich context information from various subspaces. In addition, we build a powerful Contextual Bridger Module between the encoder and decoder, which can capture semantics from larger receptive fields and combine them with various decoder layers. Experiments demonstrate the proposed method with fewer parameters (similar to 16M) achieves SOTA on 4 public benchmarks. Our code will be released at https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/shijinghuihub/Polyp-Mixer
C1 [Shi, Jing-Hui; Zhang, Qing] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
   [Tang, Yu-Hao] Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Technol, Nanjing 210016, Peoples R China.
   [Zhang, Zhong-Qun] Univ Birmingham, Dept Comp Sci, Birmingham B15, England.
C3 Shanghai Institute of Technology; Nanjing University of Aeronautics &
   Astronautics; University of Birmingham
RP Zhang, Q (通讯作者)，Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
EM 206141130@mail.sit.edu.cn; zhangqing0329@gmail.com;
   bx2016006@nuaa.edu.cn; zxz064@student.bham.ac.uk
RI Tang, Yuhao/IUN-8374-2023
FU Municipal Natural Science Foundation of Shanghai [19ZR1455300,
   21ZR1462600]
FX This work was supported by the Municipal Natural Science Foundation of
   Shanghai under Grant 19ZR1455300 and Grant 21ZR1462600.
CR Ba J. L., 2016, ARXIV
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chen J., 2021, ARXIV
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen SI, 2021, INTERACT LEARN ENVIR, DOI [10.1080/10494820.2021.1961159, 10.1109/ICMLC54886.2021.9737258]
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B, 2022, Arxiv, DOI arXiv:2108.06932
   Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI DOI 10.48550/ARXIV.2010.11929
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan H., 2021, ARXIV210411227, DOI DOI 10.48550/ARXIV.2104.11227
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Guo J., 2022, P IEEECVF C COMPUTER, P826
   Guo Xiaoqing, 2022, Med Image Anal, V78, P102394, DOI 10.1016/j.media.2022.102394
   He K., 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   Hou QB, 2023, IEEE T PATTERN ANAL, V45, P1328, DOI [10.1109/TPAMI.2022.3145427, 10.1109/IECON49645.2022.9968573]
   Hu XW, 2021, IEEE T CIRC SYST VID, V31, P1079, DOI 10.1109/TCSVT.2020.2995220
   Huang X., 2021, ARXIV
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji GP, 2021, LECT NOTES COMPUT SC, V12901, P142, DOI 10.1007/978-3-030-87193-2_14
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Li S, 2022, PLANT SOIL, V470, P35, DOI 10.1007/s11104-021-04913-0
   Li W., 2022, KNOWL-BASED SYST, V247
   Lin A., 2022, ARXIV210606716, V71, P1
   Liu Y, 2019, IEEE T CIRC SYST VID, V29, P1023, DOI 10.1109/TCSVT.2018.2823769
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI 10.1109/EMBC.2019.8857339
   Owais M, 2020, J MED INTERNET RES, V22, DOI 10.2196/18563
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8070986
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/crv52889.2021.00032, 10.1109/CRV52889.2021.00032]
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tang CX, 2022, AAAI CONF ARTIF INTE, P2344
   Tolstikhin I.O., 2021, P ADV NEUR INF PROC, V34, P24261, DOI DOI 10.48550/ARXIV.2105.01601
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Tu ZZ, 2021, IEEE T CIRC SYST VID, V31, P582, DOI 10.1109/TCSVT.2020.2980853
   Valanarasu JMJ, 2021, LECT NOTES COMPUT SC, V12901, P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A., 2017, PROC 31 INT C NEURAL, V30, DOI DOI 10.5555/3295222.3295349
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wu HS, 2021, AAAI CONF ARTIF INTE, V35, P2916
   Wu Z, 2019, IEEE T CIRC SYST VID, V29, P2960, DOI 10.1109/TCSVT.2018.2870954
   Xia J., 2022, ARXIV, DOI 10.48550/arXiv.220303990
   Yan JK, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09452-x
   Yin ZN, 2023, PUBLIC HEALTH NUTR, V26, P476, DOI 10.1017/S1368980022002439
   Yu T., 2022, P IEEE CVF WINT C AP, P297
   Zhang Q, 2022, IEEE T CIRC SYST VID, V32, P3644, DOI 10.1109/TCSVT.2021.3104932
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhuge MC, 2023, IEEE T PATTERN ANAL, V45, P3738, DOI 10.1109/TPAMI.2022.3179526
   Zhuge MC, 2022, PATTERN RECOGN, V127, DOI 10.1016/j.patcog.2022.108644
   Zhuge MC, 2021, PROC CVPR IEEE, P12642, DOI 10.1109/CVPR46437.2021.01246
NR 60
TC 0
Z9 0
U1 13
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1051-8215
EI 1558-2205
J9 IEEE T CIRC SYST VID
JI IEEE Trans. Circuits Syst. Video Technol.
PD JAN
PY 2023
VL 33
IS 1
BP 30
EP 42
DI 10.1109/TCSVT.2022.3197643
PG 13
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 7T9FP
UT WOS:000911746000003
DA 2023-08-21
ER

PT J
AU Shi, LT
   Li, ZG
   Li, JY
   Wang, YF
   Wang, HY
   Guo, YB
AF Shi, Liantao
   Li, Zhengguo
   Li, Jianyang
   Wang, Yufeng
   Wang, Hongyu
   Guo, Yubao
TI AGCNet: A Precise Adaptive Global Context Network for Real-Time
   Colonoscopy
SO IEEE ACCESS
LA English
DT Article
DE Colonoscopy; polyp segmentation; multi-scale semantic feature;
   context-guided pyramid aggregation module; feature aggregation
ID U-NET ARCHITECTURE; POLYP; DIAGNOSIS
AB Colonic endoscopy is the gold standard for detecting rectal polyps and rectal cancer. In which polyps are a major predisposing factor for colorectal cancer, the precise diagnosis of polyps within colorectal endoscopy is highly dependent on a physician of professional level. With the development of deep learning, some semantic segmentation methods have recently been applied to polyp detection, but there are problems with insufficient accuracy and segmentation speed. To this end, we propose a precision adaptive global context network (AGCNet) based on real-time colon endoscopy. Firstly, in order to adapt to the problem of large-scale variation of polyps, we designed a multi-scale semantic fusion module (MSFM), which enhances the representation capability by varieties of filters to collect contextual information at different scales, thus adapting to the problem of large variation of polyp size, especially smaller polyps. In addition, modelling long-range dependence by simply using complex spatial pixels tends to introduce more background noise and increase the computational effort. To this end, a context-aware pyramid aggregation module (CPAM) was designed, which internally includes a novel dual attention mechanism whereby the CPAM aggregates feature information across different regions to boost the network's ability to utilize global context and model long-range dependency through dual attention to further reinforce the features information of important regions and efficiently suppress features in non-important regions. Additionally, the CPAM performs multi-level pooling on the input features to extract multi-scale context information from the image and uses an attention mechanism to selectively highlight informative regions of the image that are most relevant to the segmentation task. The module fuses the multi-level pooled features with the attention map to produce enhanced feature representations that capture both global and local information. Thereby achieving precise polyp segmentation and taking real-time into account. Our proposed AGCNet performed extensive experimental studies on datasets Kvasir-SEG, CVC-ClinicDB, CVC-ColonDB and ETIS-LaribPolypDB. Specifically, AGCNet achieved an IoU of 87.40% and a Dice score of 92.63% on the Kvasir dataset, achieving accurate segmentation results faster than many current state-of-the-art models.
C1 [Shi, Liantao; Li, Zhengguo] Shenzhen Polytech, Inst Carbon Neutral Technol, Shenzhen 518055, Peoples R China.
   [Li, Jianyang; Wang, Yufeng; Guo, Yubao] Univ Sci & Technol Liaoning, Sch Elect & Informat Engn, Anshan 114000, Peoples R China.
   [Wang, Hongyu] Wuhan Univ Technol, Sch Automat, Wuhan 430000, Peoples R China.
C3 ShenZhen Polytechnic; University of Science & Technology Liaoning; Wuhan
   University of Technology
RP Li, ZG (通讯作者)，Shenzhen Polytech, Inst Carbon Neutral Technol, Shenzhen 518055, Peoples R China.
EM Lizhengguo@szpt.edu.cn
OI Shi, Liantao/0000-0002-5806-3405
CR Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Corley D. A., NEW ENGLAND J MED, V370
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang H, 2019, ISPRS J PHOTOGRAMM, V154, P246, DOI 10.1016/j.isprsjprs.2019.06.010
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Ho Y, 2020, IEEE ACCESS, V8, P4806, DOI 10.1109/ACCESS.2019.2962617
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Kaminski M. F., GASTROENTEROLOGY
   Kingma D., 2015, ARXIV
   Klare P., 2019, GASTROINTEST ENDOSC, V89, P1
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Lou GC, 2014, TURK J GASTROENTEROL, V25, P182, DOI 10.5152/tjg.2014.4664
   Rex DK, 2000, GASTROINTEST ENDOSC, V51, P33, DOI 10.1016/S0016-5107(00)70383-X
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rutter CM, 2012, CANCER CAUSE CONTROL, V23, P289, DOI 10.1007/s10552-011-9878-5
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang QY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM)
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang C., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1801.02254
   Zhang J, 2013, IEEE PHOTONICS J, V5, DOI 10.1109/JPHOT.2013.2247587
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 29
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2023
VL 11
BP 59002
EP 59015
DI 10.1109/ACCESS.2023.3278109
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA K5KB3
UT WOS:001016815400001
OA gold
DA 2023-08-21
ER

PT J
AU Tang, CP
   Chang, HY
   Wang, WC
   Hu, WX
AF Tang, Chia-Pei
   Chang, Hong-Yi
   Wang, Wei-Chun
   Hu, Wei-Xuan
TI A Novel Computer-Aided Detection/Diagnosis System for Detection and
   Classification of Polyps in Colonoscopy
SO DIAGNOSTICS
LA English
DT Article
DE colon polyp detection; generative adversarial network (GAN); object
   detection; data computer augmentation; image deblurring
ID COLORECTAL POLYPS; CNN
AB Using a deep learning algorithm in the development of a computer-aided system for colon polyp detection is effective in reducing the miss rate. This study aimed to develop a system for colon polyp detection and classification. We used a data augmentation technique and conditional GAN to generate polyp images for YOLO training to improve the polyp detection ability. After testing the model five times, a model with 300 GANs (GAN 300) achieved the highest average precision (AP) of 54.60% for SSA and 75.41% for TA. These results were better than those of the data augmentation method, which showed AP of 53.56% for SSA and 72.55% for TA. The AP, mAP, and IoU for the 300 GAN model for the HP were 80.97%, 70.07%, and 57.24%, and the data increased in comparison with the data augmentation technique by 76.98%, 67.70%, and 55.26%, respectively. We also used Gaussian blurring to simulate the blurred images during colonoscopy and then applied DeblurGAN-v2 to deblur the images. Further, we trained the dataset using YOLO to classify polyps. After using DeblurGAN-v2, the mAP increased from 25.64% to 30.74%. This method effectively improved the accuracy of polyp detection and classification.
C1 [Tang, Chia-Pei] Buddhist Tzu Chi Med Fdn, Dalin Tzu Chi Hosp, Dept Internal Med, Div Gastroenterol, Chiayi 622401, Taiwan.
   [Tang, Chia-Pei] Tzu Chi Univ, Sch Med, Hualien 970374, Taiwan.
   [Chang, Hong-Yi; Wang, Wei-Chun; Hu, Wei-Xuan] Natl Chiayi Univ, Dept Management Informat Syst, Chiayi 60054, Taiwan.
C3 Buddhist Tzu Chi General Hospital; Tzu Chi University; National Chiayi
   University
RP Chang, HY (通讯作者)，Natl Chiayi Univ, Dept Management Informat Syst, Chiayi 60054, Taiwan.
EM hychang@mail.ncyu.edu.tw
OI Chang, Hong-Yi/0000-0003-1249-1655
FU Ministry of Science and Technology (MOST) of Taiwan [110-2410-H-415-010,
   111-2410-H-415-008, 111-2314-B-303-024]; Dalin Tzu Chi Hospital,
   Buddhist Tzu Chi Medical Foundation [DTCRD 111-I-14]
FX The Ministry of Science and Technology (MOST) of Taiwan provided
   research funding and devices. The related project number of this work is
   110-2410-H-415-010, 111-2410-H-415-008, and 111-2314-B-303-024. This
   study was supported by a research fund from the Dalin Tzu Chi Hospital,
   Buddhist Tzu Chi Medical Foundation, DTCRD 111-I-14.
CR Ali S, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101900
   [Anonymous], COL CANC PREV
   [Anonymous], INTR COL CAN SCREEN
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chiu TW, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90599-4
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Duong A, 2022, ENDOSCOPY, V54, P128, DOI 10.1055/a-1386-7434
   Fanny, 2018, Procedia Computer Science, V135, P60, DOI 10.1016/j.procs.2018.08.150
   Fonolla R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155040
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Isola P., 2017, P 2017 IEEE C COMPUT
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jocher G., PYTORCH HUB INTEGRAT
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Kaul V, 2020, GASTROINTEST ENDOSC, V92, P807, DOI 10.1016/j.gie.2020.06.040
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kulkarni S, 2020, ACAD RADIOL, V27, P62, DOI 10.1016/j.acra.2019.10.001
   Li TB, 2020, ENDOSC INT OPEN, V08, pE1448, DOI 10.1055/a-1229-3927
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Park J, 2019, CLIN ENDOSC, V52, P328, DOI 10.5946/ce.2018.172
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Puyol-Anton E, 2021, LECT NOTES COMPUT SC, V12903, P413, DOI 10.1007/978-3-030-87199-4_39
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Queiroz F, 2019, DIGIT SIGNAL PROCESS, V88, P53, DOI 10.1016/j.dsp.2019.01.012
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Takamatsu Makoto, 2020, 2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA), P1087, DOI 10.1109/ICMLA51294.2020.00175
   Tang CP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165315
   Tang CP, 2021, TZU CHI MED J, V33, P108, DOI 10.4103/tcmj.tcmj_88_20
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 38
TC 0
Z9 0
U1 12
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD JAN
PY 2023
VL 13
IS 2
AR 170
DI 10.3390/diagnostics13020170
PG 20
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 8B5TZ
UT WOS:000916988300001
PM 36672980
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Wang, DY
   Xu, C
   An, ZH
   Han, JB
   Li, ZP
AF Wang, Deyu
   Xu, Chao
   An, Ziheng
   Han, Jubao
   Li, Zhengping
TI JudgeNet: Inverse Attention and Multiscale Fusion Networks With Boundary
   Determination in Polyp Segmentation
SO IEEE ACCESS
LA English
DT Article
DE Object segmentation; Feature extraction; Edge detection; Image
   segmentation; Neural networks; Medical services; Integrated circuits;
   Colonoscopy; polyp segmentation; small target segmentation
ID COLON
AB Colonoscopy is one of the most effective means of detecting intestinal polyps and colon cancer. With the development of machine vision, doctors often use automation to help diagnose intestinal polyps when using colonoscopy. The high rate of missed polyps during traditional intestinal polyp detection can lead to an increased recurrence rate and cancer of polyps. Therefore, we propose a multi-scale fusion network with boundary judgment function. The network can accurately segment smaller polyps and improve the blurred boundaries of segmented images. The network achieves the purpose of deepening the boundary information by using the attention mechanism by judging the global information generated by the encoder at different levels and the prediction mask map obtained by multi-scale fusion. Experimental results show that the network can accurately identify the boundaries of diminutive polyps and improve the overall accuracy of polyp segmentation. Compared with the latest network models, we achieved first place in several metrics in the mainstream datasets(e.t., Kvasir, CVC-ClinicDB, CVC-300, and ETIS LaribPolypDB). Codes available: https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/Wdy1997/J-Net.git
C1 [Wang, Deyu; Xu, Chao; An, Ziheng; Han, Jubao; Li, Zhengping] Univ Anhui, Integrated Circuit Dept, Hefei 230601, Peoples R China.
C3 Anhui University
RP Xu, C (通讯作者)，Univ Anhui, Integrated Circuit Dept, Hefei 230601, Peoples R China.
EM xchao@ahu.edu.cn
CR Bai L., 2017, ELECT J METABOLISM N
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   He XS, 2018, GASTROENTEROLOGY, V155, P355, DOI 10.1053/j.gastro.2018.04.019
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lan M, 2020, INFORM SCIENCES, V535, P156, DOI 10.1016/j.ins.2020.05.062
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lou AE, 2022, Arxiv, DOI arXiv:2108.07368
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Miah MBA, 2015, INT CONF ELECTR ENG
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102549
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JF, 2022, Arxiv, DOI [arXiv:2203.03635, 10.48550/ARXIV.2203.03635]
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   WILLETT W, 1989, NATURE, V338, P389, DOI 10.1038/338389a0
   Yu F., 2016, P 4 INT C LEARN REP, DOI 10.48550/arXiv.1511.07122Focustolearnmore
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang H, 2022, 2022 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION WORKSHOPS (CVPRW 2022), P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 33
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2023
VL 11
BP 58279
EP 58293
DI 10.1109/ACCESS.2023.3278373
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA J8VE5
UT WOS:001012339300001
OA gold
DA 2023-08-21
ER

PT J
AU Wen, Y
   Zhang, L
   Meng, XL
   Ye, XJ
AF Wen, Yan
   Zhang, Lei
   Meng, Xiangli
   Ye, Xujiong
TI Rethinking the Transfer Learning for FCN Based Polyp Segmentation in
   Colonoscopy
SO IEEE ACCESS
LA English
DT Article
DE Training; Task analysis; Image segmentation; Convolutional neural
   networks; Transfer learning; Colonoscopy; Cancer; real-time polyp
   segmentation; transfer learning; convolutional neural network
ID MISS RATE
AB Besides the complex nature of colonoscopy frames with intrinsic frame formation artefacts such as light reflections and the diversity of polyp types/shapes, the publicly available polyp segmentation training datasets are limited, small and imbalanced. In this case, the automated polyp segmentation using a deep neural network remains an open challenge due to the overfitting of training on small datasets. We proposed a simple yet effective polyp segmentation pipeline that couples the segmentation (FCN) and classification (CNN) tasks. We find the effectiveness of interactive weight transfer between dense and coarse vision tasks that mitigates the overfitting in learning. This motivates us to design a new training scheme within our segmentation pipeline. Our method is evaluated on CVC-EndoSceneStill and Kvasir-SEG datasets. It achieves 4.34% and 5.70% Polyp-IoU improvements compared to the state-of-the-art methods on the EndoSceneStill and Kvasir-SEG datasets, respectively and achieves real-time performance in inference.
C1 [Wen, Yan; Zhang, Lei; Ye, Xujiong] Univ Lincoln, Sch Comp Sci, Lab Vis Engn LoVE, Lincoln LN6 7DQ, England.
   [Meng, Xiangli] Lingnan Normal Univ, Sch Elect & Elect Engn, Zhanjiang 524048, Peoples R China.
C3 University of Lincoln; LingNan Normal University
RP Zhang, L (通讯作者)，Univ Lincoln, Sch Comp Sci, Lab Vis Engn LoVE, Lincoln LN6 7DQ, England.
EM lzhang@lincoln.ac.uk
OI ye, xujiong/0000-0003-0115-0724
FU British Council U.K. Glossary: Association of South East Asian Nations
   (ASEAN) Institutional Links Early Career Researchers (ECR) Scheme
   Project [913100317]; Guangdong Recruitment Program of Foreign Experts
FX This work was supported in part by the British Council U.K. Glossary:
   Association of South East Asian Nations (ASEAN) Institutional Links
   Early Career Researchers (ECR) Scheme Project under Grant 913100317, and
   in part by the Guangdong Recruitment Program of Foreign Experts.
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   [Anonymous], 2022, SCIKIT IMAGE IMAGE P
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI DOI 10.48550/ARXIV.2010.11929
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heresbach D., ENDOSCOPY
   Hu KL, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105760
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Jha D., LECT NOTES COMPUT SC, V11962
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jung DK, 2016, CLIN ENDOSC, V49, P61, DOI 10.5946/ce.2016.49.1.61
   Kingma D., 2015, ARXIV
   Lee JG, 2011, COMPUT BIOL MED, V41, P790, DOI 10.1016/j.compbiomed.2011.06.015
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Duc NT, 2022, IEEE ACCESS, V10, P80575, DOI 10.1109/ACCESS.2022.3195241
   Paszke A., 2017, NEURAL INF PROCESS S, DOI DOI 10.18653/V1/D18-1244
   Raghu M, 2019, ADV NEUR IN, V32
   Reddi S.J., 2019, ARXIV
   Sanchez-Peralta L. F., APPL SCI-BASEL, V10, P8501
   Sanchez-Peralta LF, 2020, INT J COMPUT ASS RAD, V15, P1975, DOI 10.1007/s11548-020-02262-4
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sun X., 2019, ARXIV
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Vemulapalli KC, 2022, ENDOSC INT OPEN, V10, pE659, DOI 10.1055/a-1784-0959
   Wicke Kai, 2018, 2018 AIAA Aerospace Sciences Meeting, P1
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wu H., 2022, NEW ENGL J MED, P1, DOI [10.1109/TCYB.2022.3162873, DOI 10.1109/TCYB.2022.3162873]
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhou X., 2021, PROC CHINA AUTOM C C, P6387, DOI [10.1109/CAC53003.2021.9728295, DOI 10.1109/CAC53003.2021.9728295]
NR 38
TC 0
Z9 0
U1 7
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2023
VL 11
BP 16183
EP 16193
DI 10.1109/ACCESS.2023.3245519
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 9Q3XJ
UT WOS:000944900900001
OA gold, Green Submitted, Green Accepted
DA 2023-08-21
ER

PT J
AU Yue, GH
   Wei, PS
   Liu, Y
   Luo, Y
   Du, JF
   Wang, TF
AF Yue, Guanghui
   Wei, Peishan
   Liu, Yun
   Luo, Yu
   Du, Jingfeng
   Wang, Tianfu
TI Automated Endoscopic Image Classification via Deep Neural Network With
   Class Imbalance Loss
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
LA English
DT Article
DE Feature extraction; Task analysis; Lesions; Neural networks; Image
   recognition; Image color analysis; Endoscopes; Deep neural network
   (DNN); endoscopic image classification; imbalanced learning; loss
   function
ID QUALITY ASSESSMENT; POLYP DETECTION; GASTRIC-CANCER; DIAGNOSIS
AB Recently, many computer-aided diagnosis (CAD) methods have been proposed to help physicians automatically classify endoscopic images. However, most existing methods often result in poor performance, especially for the minority classes, when the dataset is imbalanced. In this article, we propose a new CAD method for automated endoscopic image classification by introducing a novel class imbalance (CI) loss to the classical deep neural network (DNN). Specifically, we use the DNN to extract rich feature representations. Given that the majority class usually dominates the prediction error and influences the gradient of the network, the proposed CI loss considers both the class frequency and prediction probability of the ground-truth class to assign the weight of each sample and helps the minority classes contribute more to descending the gradient in the training process than the majority classes. Thanks to the CI loss, the network pays more attention to minority classes and hard samples. To verify the effectiveness of our proposed method, we conduct comprehensive experiments in the binary-class classification task on our collected polyp recognition dataset (22935 images) and in the multiclass classification task on the public Hyper-Kvasir dataset (10662 images). Experimental results show that our method is competent for the imbalanced endoscopic image classification task with good performance.
C1 [Yue, Guanghui; Wei, Peishan; Wang, Tianfu] Shenzhen Univ, Marshall Lab Biomed Engn, Shenzhen 518060, Peoples R China.
   [Yue, Guanghui; Wei, Peishan; Wang, Tianfu] Shenzhen Univ, Sch Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound, Guangdong Key Lab Biomed Measurements & Ultrasound, Shenzhen 518060, Peoples R China.
   [Liu, Yun] Liaoning Univ, Coll Informat, Shenyang 110036, Peoples R China.
   [Luo, Yu] Guangdong Univ Technol, Sch Comp Sci, Guangzhou 510006, Peoples R China.
   [Du, Jingfeng] Shenzhen Univ Gen Hosp, Dept Gastroenterol & Hepatol, Shenzhen 518071, Peoples R China.
C3 Shenzhen University; Shenzhen University; Liaoning University; Guangdong
   University of Technology
RP Liu, Y (通讯作者)，Liaoning Univ, Coll Informat, Shenyang 110036, Peoples R China.; Luo, Y (通讯作者)，Guangdong Univ Technol, Sch Comp Sci, Guangzhou 510006, Peoples R China.; Du, JF (通讯作者)，Shenzhen Univ Gen Hosp, Dept Gastroenterol & Hepatol, Shenzhen 518071, Peoples R China.
EM yueguanghui@szu.edu.cn; weipeishan2021@email.szu.edu.cn;
   yunliu@lnu.edu.cn; yuluo@gdut.edu.cn; djfjms1231@qq.com;
   tfwang@szu.edu.cn
OI luo, yu/0000-0003-3968-9725; Liu, Yun/0000-0003-4115-1617
FU Shenzhen Science and Technology Program [RCBS20200714114920379];
   Guangdong Basic and Applied Basic Research Foundation [2021A1515011348,
   2019A1515111205, 2019A1515110401]; National Natural Science Foundation
   of China [62001302, 62103286, 61901205]; Natural Science Foundation of
   Shenzhen [JCYJ20190808145011259]; Tencent "Rhinoceros Birds"-Scientific
   Research Foundation for Young Teachers of Shenzhen University; Social
   Science Youth Foundation of Ministry of Education of China
   [21YJC630181]; Liaoning Province Natural Science Foundation
   [2023-MS-139]
FX This work was supported in part by the Shenzhen Science and Technology
   Program under Grant RCBS20200714114920379; in part by the Guangdong
   Basic and Applied Basic Research Foundation under Grant 2021A1515011348,
   Grant 2019A1515111205, and Grant 2019A1515110401; in part by the
   National Natural Science Foundation of China under Grant 62001302, Grant
   62103286, and Grant 61901205; in part by the Natural Science Foundation
   of Shenzhen under Grant JCYJ20190808145011259; in part by the Tencent
   "Rhinoceros Birds"-Scientific Research Foundation for Young Teachers of
   Shenzhen University; in part by the Social Science Youth Foundation of
   Ministry of Education of China under Grant 21YJC630181; and in part by
   the Liaoning Province Natural Science Foundation under Grant
   2023-MS-139.
CR Agrawal V, 2015, INT CONF CONTEMP, P171, DOI 10.1109/IC3.2015.7346674
   ALBREGTSEN F, 2008, STAT TEXTURE MEASURE
   Andria G, 2017, IEEE T INSTRUM MEAS, V66, P2535, DOI 10.1109/TIM.2017.2692318
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Chang Y, 2020, IEEE T INSTRUM MEAS, V69, P2707, DOI 10.1109/TIM.2019.2925881
   Chen HY, 2019, Arxiv, DOI arXiv:1903.01182
   Chen TR, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3192862
   Cheng JL, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102313
   Du WJ, 2019, IEEE ACCESS, V7, P142053, DOI 10.1109/ACCESS.2019.2944676
   Fernando KRM, 2022, IEEE T NEUR NET LEAR, V33, P2940, DOI 10.1109/TNNLS.2020.3047335
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Gessert N, 2020, IEEE T BIO-MED ENG, V67, P495, DOI 10.1109/TBME.2019.2915839
   Guo XQ, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101733
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kim Y, 2021, PATTERN RECOGN LETT, V151, P33, DOI 10.1016/j.patrec.2021.07.017
   Lai ZF, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/2061516
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Lin A., 2022, ARXIV210606716, V71, P1
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Ling C. X., 2008, ENCY MACH LEARN, V2011, P231
   Liu D, 2016, COMPUT BIOL MED, V72, P185, DOI 10.1016/j.compbiomed.2016.03.010
   Liu Y, 2022, IEEE ACM T COMPUT BI, V19, P2523, DOI 10.1109/TCBB.2021.3080295
   Liu Y, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3184360
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Meng M. Q. -H., 2004, PROC 5 WORLD C INTEL, P555
   Murthy VN, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254333
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sasmal P, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3082315
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song Y, 2015, IEEE T MED IMAGING, V34, P1362, DOI 10.1109/TMI.2015.2393954
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   Tollivoro TA, 2019, GASTROINTEST ENDOSC, V89, P168, DOI 10.1016/j.gie.2018.08.023
   van der Post RS, 2018, GASTROINTEST ENDOSC, V87, P397, DOI 10.1016/j.gie.2017.04.016
   Wang GF, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3170983
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Xu JW, 2022, COMPUT METH PROG BIO, V214, DOI 10.1016/j.cmpb.2021.106576
   Yang JJ, 2020, INT J COMPUT ASS RAD, V15, P1291, DOI 10.1007/s11548-020-02190-3
   Yang XY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038011
   Yao K, 2007, CLIN GASTROENTEROL H, V5, P869, DOI 10.1016/j.cgh.2007.02.034
   Yuan YX, 2020, IEEE T AUTOM SCI ENG, V17, P574, DOI 10.1109/TASE.2019.2936645
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yue G., 2023, IEEE T INSTRUM MEAS, V72, P1
   Yue G., 2022, IEEE T MULTIMEDIA, DOI [10.1109/TMM.2022.3209889, DOI 10.1109/TMM.2022.3209889]
   Yue GH, 2023, IEEE TETCI, V7, P487, DOI 10.1109/TETCI.2022.3193677
   Yue GH, 2022, IEEE J BIOMED HEALTH, V26, P4090, DOI 10.1109/JBHI.2022.3173948
   Yue GH, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106235
   Yue GH, 2019, DIGIT SIGNAL PROCESS, V91, P21, DOI 10.1016/j.dsp.2018.12.007
   Zeng C., 2022, ARXIV
   Zhu ZH, 2020, IEEE T CYBERNETICS, V50, P1617, DOI 10.1109/TCYB.2018.2877663
NR 56
TC 0
Z9 0
U1 20
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9456
EI 1557-9662
J9 IEEE T INSTRUM MEAS
JI IEEE Trans. Instrum. Meas.
PY 2023
VL 72
AR 5010611
DI 10.1109/TIM.2023.3264047
PG 11
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA D7YA9
UT WOS:000970836300011
DA 2023-08-21
ER

PT J
AU Yue, GH
   Li, SY
   Cong, RM
   Zhou, TW
   Lei, BY
   Wang, TF
AF Yue, Guanghui
   Li, Siying
   Cong, Runmin
   Zhou, Tianwei
   Lei, Baiying
   Wang, Tianfu
TI Attention-Guided Pyramid Context Network for Polyp Segmentation in
   Colonoscopy Images
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
LA English
DT Article
DE Feature extraction; Task analysis; Image segmentation; Data mining;
   Transformers; Semantics; Colonoscopy; Attention; colonoscopy image; deep
   learning; polyp segmentation; pyramid context network
ID VALIDATION
AB Recently, deep convolutional neural networks (CNNs) have provided us an effective tool for automated polyp segmentation in colonoscopy images. However, most CNN-based methods do not fully consider the feature interaction among different layers and often cannot provide satisfactory segmentation performance. In this article, a novel attention-guided pyramid context network (APCNet) is proposed for accurate and robust polyp segmentation in colonoscopy images. Specifically, considering that different network layers represent the polyp in different aspects, APCNet first extracts multilayer features in a pyramid structure, and then uses an attention-guided multilayer aggregation strategy to refine the context features of each layer using the complementary information of different layers. To obtain abundant context features, APCNet uses a context extraction module (CEM) that explores the context information of each layer via local information retainment and global information compaction. Through the top-down deep supervision, our APCNet implements a coarse-to-fine polyp segmentation and finally localizes the polyp region precisely. Extensive experiments on two in-domain and four out-of-domain experiments show that APCNet is comparable to 19 state-of-the-art methods. Moreover, it holds a more appropriate tradeoff between effectiveness and computational complexity than these competing methods.
C1 [Yue, Guanghui; Li, Siying; Lei, Baiying; Wang, Tianfu] Shenzhen Univ, Shenzhen Univ Med Sch, Sch Biomed Engn, Shenzhen 518060, Peoples R China.
   [Cong, Runmin] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100091, Peoples R China.
   [Zhou, Tianwei] Shenzhen Univ, Coll Management, Shenzhen 518060, Peoples R China.
C3 Shenzhen University; Beijing Jiaotong University; Shenzhen University
RP Zhou, TW (通讯作者)，Shenzhen Univ, Coll Management, Shenzhen 518060, Peoples R China.
EM yueguanghui@szu.edu.cn; 2070246077@email.szu.edu.cn; rmcong@bjtu.edu.cn;
   tianwei@szu.edu.cn; leiby@szu.edu.cn; tfwang@szu.edu.cn
RI Lei, Baiying/GQO-8422-2022
OI Lei, Baiying/0000-0002-3087-2550
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ali S, 2021, ARXIV
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chang Q., 2022, ARXIV
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C. -H., 2021, ARXIV
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liang-Chieh Chen, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11211), P833, DOI 10.1007/978-3-030-01234-2_49
   Lin AL, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3178991
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahapatra D, 2022, MED IMAGE ANAL, V81, DOI 10.1016/j.media.2022.102551
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Duc NT, 2022, IEEE ACCESS, V10, P80575, DOI 10.1109/ACCESS.2022.3195241
   Paszke A, 2019, ADV NEUR IN, V32
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/crv52889.2021.00032, 10.1109/CRV52889.2021.00032]
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy K, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3161690
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sanderson E, 2022, LECT NOTES COMPUT SC, V13413, P892, DOI 10.1007/978-3-031-12053-4_65
   Sasmal P, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3082315
   Shen YT, 2021, LECT NOTES COMPUT SC, V12901, P559, DOI 10.1007/978-3-030-87193-2_53
   Shu YC, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106950
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song JH, 2022, IEEE T MED IMAGING, V41, P2273, DOI 10.1109/TMI.2022.3162111
   Srivastava A, 2022, INT C PATT RECOG, P4321, DOI 10.1109/ICPR56361.2022.9956726
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Nguyen TC, 2021, LECT NOTES COMPUT SC, V12901, P633, DOI 10.1007/978-3-030-87193-2_60
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Tomar N.K., 2022, ARXIV
   Tran VL, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3184341
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang GF, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3170983
   Wang J., 2022, ARXIV
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Wang ST, 2022, IEEE T CYBERNETICS, V52, P12623, DOI 10.1109/TCYB.2021.3069920
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wen Y, 2022, KNOWL-BASED SYST, V243, DOI 10.1016/j.knosys.2022.108424
   Wu HS, 2021, AAAI CONF ARTIF INTE, V35, P2916
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yang XY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038011
   Yin Zenong, 2022, Public Health Nutr, P1, DOI [10.1017/S1368980022002439, 10.1109/ICIT48603.2022.10002826]
   Yue GH, 2023, IEEE TETCI, V7, P487, DOI 10.1109/TETCI.2022.3193677
   Yue GH, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103846
   Yue GH, 2022, IEEE J BIOMED HEALTH, V26, P4090, DOI 10.1109/JBHI.2022.3173948
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
   Zhou ZL, 2021, IEEE T BIG DATA, V7, P559, DOI 10.1109/TBDATA.2019.2919570
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 74
TC 0
Z9 0
U1 23
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9456
EI 1557-9662
J9 IEEE T INSTRUM MEAS
JI IEEE Trans. Instrum. Meas.
PY 2023
VL 72
AR 5008213
DI 10.1109/TIM.2023.3244219
PG 13
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA A6CC5
UT WOS:000955971400022
DA 2023-08-21
ER

PT J
AU Wang, P
   Liu, XG
   Kang, M
   Peng, X
   Shu, ML
   Zhou, GY
   Liu, PX
   Xiong, F
   Deng, MM
   Xia, HF
   Li, JJ
   Long, XQ
   Song, Y
   Li, LP
AF Wang, Pu
   Liu, Xiao-Gang
   Kang, Min
   Peng, Xue
   Shu, Mei-Ling
   Zhou, Guan-Yu
   Liu, Pei-Xi
   Xiong, Fei
   Deng, Ming-Ming
   Xia, Hong-Fen
   Li, Jian-Jun
   Long, Xiao-Qi
   Song, Yan
   Li, Liang-Ping
TI Artificial intelligence empowers the second-observer strategy for
   colonoscopy: a randomized clinical trial
SO GASTROENTEROLOGY REPORT
LA English
DT Article
DE artificial intelligence; colon cancer screening; adenoma; early
   detection; computer-aided detection
ID COMPUTER-AIDED DETECTION; ADENOMA DETECTION RATE; INATTENTIONAL
   BLINDNESS; COLORECTAL-CANCER; ENDOSCOPY; PARTICIPATION; SURVEILLANCE;
   POLYPECTOMY; MULTICENTER; VALIDATION
AB Background In colonoscopy screening for colorectal cancer, human vision limitations may lead to higher miss rate of lesions; artificial intelligence (AI) assistance has been demonstrated to improve polyp detection. However, there still lacks direct evidence to demonstrate whether AI is superior to trainees or experienced nurses as a second observer to increase adenoma detection during colonoscopy. In this study, we aimed to compare the effectiveness of assistance from AI and human observer during colonoscopy. Methods A prospective multicenter randomized study was conducted from 2 September 2019 to 29 May 2020 at four endoscopy centers in China. Eligible patients were randomized to either computer-aided detection (CADe)-assisted group or observer-assisted group. The primary outcome was adenoma per colonoscopy (APC). Secondary outcomes included polyp per colonoscopy (PPC), adenoma detection rate (ADR), and polyp detection rate (PDR). We compared continuous variables and categorical variables by using R studio (version 3.4.4). Results A total of 1,261 (636 in the CADe-assisted group and 625 in the observer-assisted group) eligible patients were analysed. APC (0.42 vs 0.35, P = 0.034), PPC (1.13 vs 0.81, P < 0.001), PDR (47.5% vs 37.4%, P < 0.001), ADR (25.8% vs 24.0%, P = 0.464), the number of detected sessile polyps (683 vs 464, P < 0.001), and sessile adenomas (244 vs 182, P = 0.005) were significantly higher in the CADe-assisted group than in the observer-assisted group. False detections of the CADe system were lower than those of the human observer (122 vs 191, P < 0.001). Conclusions Compared with the human observer, the CADe system may improve the clinical outcome of colonoscopy and reduce disturbance to routine practice (Chictr.org.cn No.: ChiCTR1900025235).
C1 [Wang, Pu; Liu, Xiao-Gang; Zhou, Guan-Yu; Liu, Pei-Xi; Xiong, Fei; Song, Yan; Li, Liang-Ping] Univ Elect Sci & Technol China, Sichuan Prov Peoples Hosp, Dept Gastroenterol, 32 West Second Sect,First Ring Rd, Chengdu 610072, Sichuan, Peoples R China.
   [Kang, Min; Deng, Ming-Ming; Xia, Hong-Fen] Southwest Med Univ, Affiliated Hosp, Dept Gastroenterol, Luzhou, Sichuan, Peoples R China.
   [Peng, Xue; Li, Jian-Jun] Third Mil Med Univ, Xinqiao Hosp, Dept Gastroenterol, Chongqing, Peoples R China.
   [Shu, Mei-Ling; Long, Xiao-Qi] Suining Cent Hosp, Dept Gastroenterol, Suining, Sichuan, Peoples R China.
C3 Sichuan Provincial People's Hospital; University of Electronic Science &
   Technology of China; Southwest Medical University; Army Medical
   University
RP Li, LP (通讯作者)，Univ Elect Sci & Technol China, Sichuan Prov Peoples Hosp, Dept Gastroenterol, 32 West Second Sect,First Ring Rd, Chengdu 610072, Sichuan, Peoples R China.
EM llpsamsph001@outlook.com
RI li, jian/IAQ-2794-2023; li, wei/IUQ-2973-2023; Tang, Wei/IZQ-1283-2023;
   LI, WEI/ISS-1208-2023; wang, yu/IUQ-6654-2023; Wang, Jing/IQW-3496-2023;
   li, yan/ITU-9719-2023
OI Wang, Jing/0000-0002-8296-2961; Wang, Pu/0000-0002-1234-309X
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   American Cancer Society, 2017, CANC FACTS FIGURES 2
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Berzin TM, 2020, LANCET, V395, P485, DOI 10.1016/S0140-6736(20)30294-4
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Glissen Brown Jeremy R, 2020, VideoGIE, V5, P135, DOI 10.1016/j.vgie.2020.01.002
   Gralnek IM, 2014, LANCET ONCOL, V15, P353, DOI 10.1016/S1470-2045(14)70020-8
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Holzwanger EA, 2021, ENDOSCOPY, V53, P937, DOI 10.1055/a-1302-2942
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kudo T, 2018, GASTROINTEST ENDOSC, V88, P854, DOI 10.1016/j.gie.2018.06.011
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lei S, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000023685
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Memmert D, 2010, J GEN PSYCHOL, V137, P129, DOI 10.1080/00221301003645061
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Park SK, 2016, SCAND J GASTROENTERO, V51, P886, DOI 10.3109/00365521.2016.1157892
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2018, GASTROINTEST ENDOSC, V88, P335, DOI 10.1016/j.gie.2018.02.043
   Robertson DJ, 2015, GUT, V64, P982, DOI 10.1136/gutjnl-2014-308076
   Rutter MD, 2020, GUT, V69, P201, DOI 10.1136/gutjnl-2019-319858
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Tziatzios G, 2019, DIGEST LIVER DIS, V51, P1079, DOI 10.1016/j.dld.2019.05.012
   Uraoka T, 2021, ENDOSCOPY, V53, pE102, DOI 10.1055/a-1202-1277
   Wang HS, 2013, GASTROINTEST ENDOSC, V77, P71, DOI 10.1016/j.gie.2012.08.038
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
NR 39
TC 0
Z9 0
U1 1
U2 1
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 2052-0034
J9 GASTROENTEROL REP
JI Gastroenterol. Rep.
PD DEC 30
PY 2022
VL 11
AR goac081
DI 10.1093/gastro/goac081
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 7Z3CV
UT WOS:000915441800001
PM 36686571
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Mohapatra, S
   Pati, GK
   Mishra, M
   Swarnkar, T
AF Mohapatra, Subhashree
   Pati, Girish Kumar
   Mishra, Manohar
   Swarnkar, Tripti
TI Gastrointestinal abnormality detection and classification using
   empirical wavelet transform and deep convolutional neural network from
   endoscopic images
SO AIN SHAMS ENGINEERING JOURNAL
LA English
DT Article
DE Artificial intelligence; Discrete wavelet transform; Empirical wavelet
   transform; Convolutional neural network; Gastrointestinal tract
ID WIRELESS CAPSULE ENDOSCOPY; HELICOBACTER-PYLORI INFECTION;
   ARTIFICIAL-INTELLIGENCE; DIAGNOSIS; FRAMEWORK; FEATURES; DISEASES;
   CANCER
AB With an intention to assist gastroenterologists, this work proposes an intelligent method to classify ali-mentary canal diseases such as Barrett's, Esophagitis, Hemorrhoids, Polyps, and Ulcerative colitis by using empirical wavelet transform (EWT) and convolutional neural network (CNN). Here, a publicly available HyperKvasir dataset is used for the experimental work. The framework starts with several image pre-processing steps followed by the implementation of EWT. EWT helps to decompose the image into sev-eral modes and extract specific patterns in the images. These decomposed images are then fed into the proposed deep CNN for disease classification in two-levels. Finally, the proposed model is evaluated based on several performance metrics. The result shows 96.65% accuracy, 0.9298 Matthews correlation coefficient (MCC) in the first level, and 94.25% accuracy, 0.8108 MCC in the second level of classification. Lastly, to justify the efficacy of the proposed method, a comparative study is carried out with other con-temporary techniques.(c) 2022 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Engineering, Ain Shams Uni-versity. This is an open access article under the CC BY-NC-ND license (https://hfbic2b72e0689ad14138h0qkw69uxxc656nn5fiac.eds.tju.edu.cn/licenses/ by-nc-nd/4.0/).
C1 [Mohapatra, Subhashree] Siksha O Anusandhan Deemed Be Univ, Dept Comp Sci & Engn, ITER, Bhubaneswar 751030, Odisha, India.
   [Pati, Girish Kumar] Siksha O Anusandhan Deemed Be Univ, Inst Med Sci & SUM Hosp, Dept Gastroenterol & Hepatobiliary Sci, Bhubaneswar 751003, India.
   [Mishra, Manohar] Siksha O Anusandhan Deemed Be Univ, Dept Elect & Elect Engn, ITER, Bhubaneswar 751030, India.
   [Swarnkar, Tripti] Siksha O Anusandhan Deemed be Univ, Dept Comp Applicat, ITER, Bhubaneswar 751030, India.
C3 Siksha 'O' Anusandhan University; Siksha 'O' Anusandhan University;
   Siksha 'O' Anusandhan University; Siksha 'O' Anusandhan University
RP Mishra, M (通讯作者)，Siksha O Anusandhan Deemed Be Univ, Dept Elect & Elect Engn, ITER, Bhubaneswar 751030, India.
EM manohar2006mishra@gmail.com
RI Mishra, Manohar/ADD-8409-2022
OI Mishra, Manohar/0000-0003-2160-4703
CR Abdel-Hamid L, 2021, AIN SHAMS ENG J, V12, P2799, DOI 10.1016/j.asej.2021.02.010
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   [Anonymous], ENDOSCOPY EQUIPMENT
   Attallah O, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.423
   Bernal J., MICCAI ENDOSCOPIC VI
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Cogan T, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103351
   Dutta Amartya, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P315, DOI 10.1007/978-3-030-68793-9_24
   Gilles J, 2014, SIAM J IMAGING SCI, V7, P157, DOI 10.1137/130923774
   Gilles J, 2013, IEEE T SIGNAL PROCES, V61, P3999, DOI 10.1109/TSP.2013.2265222
   Grandini M, 2020, Arxiv, DOI [arXiv:2008.05756, DOI 10.48550/ARXIV.2008.05756]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Huynh-The T, 2020, IEEE COMMUN LETT, V24, P811, DOI 10.1109/LCOMM.2020.2968030
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jain S, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1467-3
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Kirar BS, 2019, IET IMAGE PROCESS, V13, P73, DOI 10.1049/iet-ipr.2018.5297
   Krizhevsky A., 2012, P ADV NEUR INF PROC, P1097
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li H, 2019, QUANT IMAG MED SURG, V9, P905, DOI 10.21037/qims.2019.05.16
   Marz T, 2015, FOUND COMPUT MATH, V15, P973, DOI 10.1007/s10208-014-9199-7
   Maheshwari S, 2017, IEEE J BIOMED HEALTH, V21, P803, DOI 10.1109/JBHI.2016.2544961
   Miller KD, 2018, CA-CANCER J CLIN, V68, P425, DOI 10.3322/caac.21494
   Mohapatra Subhashree, 2021, Advances in Intelligent Computing and Communication. Proceedings of ICAC 2020. Lecture Notes in Networks and Systems (LNNS 202), P611, DOI 10.1007/978-981-16-0695-3_57
   Mohapatra Subhashree, 2021, Intelligent and Cloud Computing. Proceedings of ICICC 2019. Smart Innovation, Systems and Technologies (SIST 153), P365, DOI 10.1007/978-981-15-6202-0_37
   Mohapatra S., 2021, HDB COMPUTATIONAL IN, P121
   Mohapatra S., 2021, HDB DEEP LEARNING BI, P25, DOI [10.1016/B978-0-12-823014-5.00006-5, DOI 10.1016/B978-0-12-823014-5.00006-5]
   Mohapatra S, 2021, INTERDISCIP SCI, V13, P212, DOI 10.1007/s12539-021-00417-8
   Nasir M, 2020, CURR MED IMAGING, V16, P794, DOI 10.2174/1573405615666191223122401
   Pogorelov K, 2018, COMP MED SY, P381, DOI 10.1109/CBMS.2018.00073
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P170, DOI 10.1145/3083187.3083216
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Sandhya M., 2022, ARAB J SCI ENG, V47, P9899
   Sharif M, 2021, J EXP THEOR ARTIF IN, V33, P577, DOI 10.1080/0952813X.2019.1572657
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Tandon Rakesh, 2007, Indian J Gastroenterol, V26 Suppl 1, pS31
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Xue Y, 2020, IEEE ACCESS, V8, P123765, DOI 10.1109/ACCESS.2020.3006106
   Zhang D, 2019, WAVELET TRANSFORM FU, P35
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 46
TC 6
Z9 6
U1 6
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2090-4479
EI 2090-4495
J9 AIN SHAMS ENG J
JI Ain Shams Eng. J.
PD APR 5
PY 2023
VL 14
IS 4
AR 101942
DI 10.1016/j.asej.2022.101942
EA DEC 2022
PG 14
WC Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 8H0XG
UT WOS:000920761300001
OA gold
DA 2023-08-21
ER

PT J
AU Huneburg, R
   Bucksch, K
   Schmeisser, F
   Heling, D
   Marwitz, T
   Aretz, S
   Kaczmarek, DJ
   Kristiansen, G
   Hommerding, O
   Strassburg, CP
   Engel, C
   Nattermann, J
AF Hueneburg, Robert
   Bucksch, Karolin
   Schmeisser, Friederike
   Heling, Dominik
   Marwitz, Tim
   Aretz, Stefan
   Kaczmarek, Dominik J.
   Kristiansen, Glen
   Hommerding, Oliver
   Strassburg, Christian P.
   Engel, Christoph
   Nattermann, Jacob
TI Real-time use of artificial intelligence (CADEYE) in colorectal cancer
   surveillance of patients with Lynch syndrome-A randomized controlled
   pilot trial (CADLY)
SO UNITED EUROPEAN GASTROENTEROLOGY JOURNAL
LA English
DT Article
DE endoscopy
ID ADENOMAS; COLONOSCOPY; PREVALENCE; POLYPS; SYSTEM
AB BackgroundLynch syndrome (LS), an autosomal dominant disorder caused by pathogenic germline variants in DNA mismatch repair (MMR) genes, represents the most common hereditary colorectal cancer (CRC) syndrome. Lynch syndrome patients are at high risk of CRC despite regular endoscopic surveillance.
   ObjectiveOur aim was to investigate the diagnostic performance of artificial intelligence (AI)-assisted colonoscopy in comparison to High-Definition white-light endoscopy (HD-WLE) for the first time.
   MethodsPatients >= 18 years with LS, with a pathogenic germline variant (MLH1, MHS2, MSH6), and at least one previous colonoscopy (interval 10-36 months) were eligible. Patients were stratified by previous CRC and affected MMR gene with a 1:1 allocation ratio (AI-assisted vs. HD white-light endoscopy) in this exploratory pilot trial.
   ResultsBetween Dec-2021 and Dec-2022, 101 LS patients were randomised and 96 patients were finally analyzed after exclusion of 5 patients due to insufficient bowel preparation. In the HD-WLE arm, adenomas were detected in 12/46 patients compared to 18/50 in the AI arm (26.1% [95% CI 14.3-41.1] vs. 36.0% [22.9-50.8]; p = 0.379). The use of AI-assisted colonoscopy especially increased detection of flat adenomas (Paris classification 0-IIb) (examinations with detected flat adenomas: 3/46 [6.5%] vs. 10/50 [20%]; p = 0.07; numbers of detected flat adenomas: 4/20 vs. 17/30, p = 0.018). The median withdrawal time did not differ significantly between HD-WLE and AI (14 vs. 15 min; p = 0.170).
   ConclusionWe here present first data suggesting that real-time AI-assisted colonoscopy is a promising approach to optimize endoscopic surveillance in LS patients, in particular to improve the detection of flat adenomas.
C1 [Hueneburg, Robert; Schmeisser, Friederike; Heling, Dominik; Marwitz, Tim; Aretz, Stefan; Kaczmarek, Dominik J.; Kristiansen, Glen; Hommerding, Oliver; Strassburg, Christian P.; Nattermann, Jacob] Univ Hosp Bonn, Natl Ctr Hereditary Tumor Syndromes, Bonn, Germany.
   [Hueneburg, Robert; Schmeisser, Friederike; Heling, Dominik; Marwitz, Tim; Kaczmarek, Dominik J.; Strassburg, Christian P.; Nattermann, Jacob] Univ Hosp Bonn, Dept Internal Med 1, Bonn, Germany.
   [Bucksch, Karolin; Engel, Christoph] Univ Leipzig, Inst Med Informat Stat & Epidemiol, Leipzig, Germany.
   [Aretz, Stefan] Univ Bonn, Inst Human Genet, Bonn, Germany.
   [Kristiansen, Glen; Hommerding, Oliver] Univ Hosp Bonn, Inst Pathol, Bonn, Germany.
C3 University of Bonn; University of Bonn; Leipzig University; University
   of Bonn; University of Bonn
RP Huneburg, R (通讯作者)，Univ Hosp Bonn, Natl Ctr Hereditary Tumor Syndromes, Dept Internal Med 1, Venusberg Campus 1, D-53127 Bonn, Germany.
EM robert.hueneburg@ukbonn.de
OI Engel, Christoph/0000-0002-7247-282X; Kaczmarek,
   Dominik/0000-0003-0093-7832
CR Ahadova A, 2021, INT J CANCER, V148, P800, DOI 10.1002/ijc.33224
   Bhurwal A, 2021, J GASTROEN HEPATOL, V36, P3260, DOI 10.1111/jgh.15701
   De Jong AE, 2006, GASTROENTEROLOGY, V130, P665, DOI 10.1053/j.gastro.2005.11.032
   de la Chapelle A, 2005, FAM CANCER, V4, P233, DOI 10.1007/s10689-004-5811-3
   Dominguez-Valentin M, 2020, GENET MED, V22, P15, DOI 10.1038/s41436-019-0596-9
   Edelstein DL, 2011, CLIN GASTROENTEROL H, V9, P340, DOI 10.1016/j.cgh.2010.10.033
   Engel C, 2018, GASTROENTEROLOGY, V155, P1400, DOI 10.1053/j.gastro.2018.07.030
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Goverde A, 2020, CLIN GASTROENTEROL H, V18, P1112, DOI 10.1016/j.cgh.2019.08.043
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Huneburg R, 2009, ENDOSCOPY, V41, P316, DOI 10.1055/s-0028-1119628
   Iino H, 2000, GUT, V47, P37, DOI 10.1136/gut.47.1.37
   Ladabaum U, 2015, GASTROENTEROLOGY, V149, P783, DOI 10.1053/j.gastro.2015.07.037
   Liljegren A, 2008, J CLIN ONCOL, V26, P3434, DOI 10.1200/JCO.2007.13.2795
   Moher D, 2001, JAMA-J AM MED ASSOC, V285, P1992, DOI 10.1001/jama.285.15.1992
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Rondagh EJA, 2013, ENDOSCOPY, V45, P257, DOI 10.1055/s-0032-1326195
   Sanchez A, 2022, CLIN GASTROENTEROL H, V20, P611, DOI 10.1016/j.cgh.2020.11.002
   Sealock RJ, 2022, GASTROINTEST ENDOSC, V95, P1276, DOI 10.1016/j.gie.2022.02.009
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   van Doorn SC, 2015, AM J GASTROENTEROL, V110, P180, DOI 10.1038/ajg.2014.326
   van Leerdam ME, 2019, ENDOSCOPY, V51, P1082, DOI 10.1055/a-1016-4977
   Vasen HFA, 2010, GASTROENTEROLOGY, V138, P2300, DOI 10.1053/j.gastro.2010.02.053
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Weiss JM, 2021, J NATL COMPR CANC NE, V19, P1122, DOI 10.1164/jnccn.2021.0048
   Win AK, 2017, CANCER EPIDEM BIOMAR, V26, P404, DOI [10.1158/1055-9965.epi-16-0693, 10.1158/1055-9965.EPI-16-0693]
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 28
TC 2
Z9 2
U1 2
U2 2
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 2050-6406
EI 2050-6414
J9 UNITED EUR GASTROENT
JI United European Gastroenterol. J.
PD FEB
PY 2023
VL 11
IS 1
BP 60
EP 68
DI 10.1002/ueg2.12354
EA DEC 2022
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 8L7UD
UT WOS:000903695900001
PM 36571259
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Katrevula, A
   Katukuri, GR
   Singh, AP
   Inavolu, P
   Rughwani, H
   Alla, SR
   Ramchandani, M
   Duvvur, NR
AF Katrevula, Anudeep
   Katukuri, Goutham Reddy
   Singh, Aniruddha Pratap
   Inavolu, Pradev
   Rughwani, Hardik
   Alla, Siddhartha Reddy
   Ramchandani, Mohan
   Duvvur, Nageshwar Reddy
TI Real-World Experience of AI-Assisted Endocytoscopy Using EndoBRAIN-An
   Observational Study from a Tertiary Care Center
SO JOURNAL OF DIGESTIVE ENDOSCOPY
LA English
DT Article
DE EndoBRAIN; endocytoscopy; polyp
ID AIDED DIAGNOSTIC SYSTEM; COLORECTAL LESIONS; ARTIFICIAL-INTELLIGENCE;
   CLASSIFICATION; CANCER
AB Background and Aims Precise optical diagnosis of colorectal polyps could improve the cost-effectiveness of colonoscopy and reduce polypectomy-related complications. We conducted this study to estimate the diagnostic performance of visual inspection alone (WLI + NBI) and of EndoBRAIN (endocytoscopy-computer-aided diagnosis [EC-CAD]) in identifying a lesion as neoplastic or nonneoplastic using EC in real-world scenario. Methods In this observational, prospective, pilot study, a total of 55 polyps were studied in the patients aged more than or equal to 18 years. EndoBRAIN is an artificial intelligence (AI)-based system that analyzes cell nuclei, crypt structure, and vessel pattern in differentiating neoplastic and nonneoplastic lesion in real-time. Endoscopist assessed polyps using white light imaging (WLI), narrow band imaging (NBI) initially followed by assessment using EC with NBI and EC with methylene blue staining. The sensitivity, specificity, positive predictive value, negative predictive value, and accuracy of endoscopist and EndoBRAIN in identifying the neoplastic from nonneoplastic polyp was compared using histopathology as gold-standard. Results A total of 55 polyps were studied, in which most of them were diminutive (36/55) and located in rectum (21/55). The image acquisition rate was 78% (43/55) and histopathology of the majority was identified to be hyperplastic (20/43) and low-grade adenoma (16/43). EndoBRAIN identified colonic polyps with 100% sensitivity, 81.82% specificity (95% confidence interval [CI], 59.7-94.8%), 90.7% accuracy (95% CI, 77.86-97.41%), 84% positive predictive value (95% CI, 68.4-92.72%), and 100% negative predictive value. The sensitivity and negative predictive value were significantly greater than visual inspection of endoscopist. The diagnostic accuracy seems to be superior; however, it did not reach statistical significance. Specificity and positive predictive value were similar in both groups. Conclusion Optical diagnosis using EC and EC-CAD has a potential role in predicting the histopathological diagnosis. The diagnostic performance of CAD seems to be better than endoscopist using EC for predicting neoplastic lesions.
C1 [Katrevula, Anudeep; Katukuri, Goutham Reddy; Singh, Aniruddha Pratap; Inavolu, Pradev; Rughwani, Hardik; Alla, Siddhartha Reddy; Ramchandani, Mohan; Duvvur, Nageshwar Reddy] AIG Hosp, Dept Gastroenterol, Hyderabad 500032, Telangana, India.
RP Ramchandani, M (通讯作者)，AIG Hosp, Dept Gastroenterol, Hyderabad 500032, Telangana, India.
EM ramchandanimohan@gmail.com
CR [Anonymous], 2009, 3 YEAR REP POP BAS C
   Choi SJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84299-2
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Ebigbo A, 2019, ENDOSC INT OPEN, V7, pE1616, DOI 10.1055/a-1010-5705
   Gao J, 2019, MATH BIOSCI ENG, V16, P6536, DOI 10.3934/mbe.2019326
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kudo SE, 2011, ENDOSCOPY, V43, P869, DOI 10.1055/s-0030-1256663
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kudo SE, 2015, GASTROINTEST ENDOSC, V82, P912, DOI 10.1016/j.gie.2015.04.039
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2021, ENDOSC INT OPEN, V09, pE1004, DOI 10.1055/a-1475-3624
   Mori Y, 2021, J GASTROEN HEPATOL, V36, P7, DOI 10.1111/jgh.15339
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nazarian S, 2021, J MED INTERNET RES, V23, DOI 10.2196/27370
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
NR 18
TC 0
Z9 0
U1 7
U2 7
PU THIEME MEDICAL PUBL INC
PI NEW YORK
PA 333 SEVENTH AVE, NEW YORK, NY 10001 USA
SN 0976-5042
EI 0976-5050
J9 J DIG ENDOSC
JI J. Dig. Endosc.
PD MAR
PY 2023
VL 14
IS 01
BP 3
EP 7
DI 10.1055/s-0042-1758535
EA DEC 2022
PG 5
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA C2XP1
UT WOS:000903410200003
OA gold
DA 2023-08-21
ER

PT J
AU Qiu, J
   Hayashi, Y
   Oda, M
   Kitasaka, T
   Mori, K
AF Qiu, Jie
   Hayashi, Yuichiro
   Oda, Masahiro
   Kitasaka, Takayuki
   Mori, Kensaku
TI Boundary-aware feature and prediction refinement for polyp segmentation
SO COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND
   VISUALIZATION
LA English
DT Article
DE Polyp segmentation; boundary-aware; consistency learning
AB Polyp segmentation from colonoscopy videos is an essential task in medical image processing for detecting early cancer. However, segmenting a precise boundary is still challenging, even with powerful deep neural networks. We consider the difficulty can be caused by: (1) the ambiguity boundary and (2) some complicated shape makes polyps hard to segment. To address these problems, we propose the Boundary-aware Feature and Prediction Refinement framework (BaFPR) for polyp segmentation. Specifically, we design a segmentation decoder for representation learning with boundary prior and propose a novel consistency loss to learn clues from the polar coordinate. The decoder mainly consists of a boundary prior module (BPM) and a bi-directional fusion module (BiFM). BPM is designed to learn the boundary prior, while BiFM learns to fuse representations of BPM and multi-scale representations from an encoder. To handle these complicated shapes of polyps, we maintain an extra segmentation network that learns with polar transformations of data to provide extra clues for the main segmentation network by our proposed consistency loss. We evaluated BaFPR with five challenging datasets for polyp segmentation and the results showed that our proposal consistently improves the segmentation performance of polyps. Code available at: .
C1 [Qiu, Jie; Hayashi, Yuichiro; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Japan.
   [Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Informat & Commun, Nagoya, Japan.
   [Kitasaka, Takayuki] Aichi Inst Technol, Dept Informat Sci, Toyota, Japan.
   [Mori, Kensaku] Natl Inst Informat, Res Ctr Med Bigdata, Tokyo, Japan.
C3 Nagoya University; Nagoya University; Research Organization of
   Information & Systems (ROIS); National Institute of Informatics (NII) -
   Japan
RP Qiu, J; Mori, K (通讯作者)，Nagoya Univ, Grad Sch Informat, Nagoya, Japan.
EM jieqiu@mori.m.is.nagoya-u.ac.jp; kensaku@is.nagoya-u.ac.jp
FU JST CREST, Japan [JPMJCR20D5]; MEXT/JSPS KAKENHI [17H00867, 21K19898]
FX Parts of this research were supported by the JST CREST Grant Number
   JPMJCR20D5, Japan and the MEXT/JSPS KAKENHI Grant Numbers 17H00867,
   21K19898.
CR Bencevic M, 2021, IEEE ACCESS, V9, P133365, DOI 10.1109/ACCESS.2021.3116265
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B., 2021, THIS IS TECHNICAL RE
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kervadec H., 2019, INT C MED IM DEEP LE, P285, DOI DOI 10.1016/J.MEDIA.2020.101851
   Lee HJ, 2020, PROC CVPR IEEE, P4816, DOI 10.1109/CVPR42600.2020.00487
   Loshchilov I., 2019, INT C LEARN REPR
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang JC, 2021, LECT NOTES COMPUT SC, V12901, P206, DOI 10.1007/978-3-030-87193-2_20
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wang Y, 2020, PROC CVPR IEEE, P3832, DOI 10.1109/CVPR42600.2020.00389
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Xu Xuanang, 2022, Med Image Anal, V78, P102418, DOI 10.1016/j.media.2022.102418
   Zhang H, 2020, NEUROCOMPUTING, V383, P212, DOI 10.1016/j.neucom.2019.12.036
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 35
TC 0
Z9 0
U1 4
U2 5
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2168-1163
EI 2168-1171
J9 COMP M BIO BIO E-IV
JI Comp. Meth. Biomech. Biomed. Eng.
PD JUL 4
PY 2023
VL 11
IS 4
BP 1187
EP 1196
DI 10.1080/21681163.2022.2155579
EA DEC 2022
PG 10
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA I0SJ7
UT WOS:000901947800001
DA 2023-08-21
ER

PT J
AU Li, MD
   Huang, ZR
   Shan, QY
   Chen, SL
   Zhang, N
   Hu, HT
   Wang, W
AF Li, Ming-De
   Huang, Ze-Rong
   Shan, Quan-Yuan
   Chen, Shu-Ling
   Zhang, Ning
   Hu, Hang-Tong
   Wang, Wei
TI Performance and comparison of artificial intelligence and human experts
   in the detection and classification of colonic polyps
SO BMC GASTROENTEROLOGY
LA English
DT Article
DE Colonic polyps; Endoscope; Artificial intelligence; Deep learning
ID COMPUTER-AIDED CLASSIFICATION; COLORECTAL POLYPS; CT COLONOGRAPHY; MISS
   RATE; ADENOMA; CANCER; VALIDATION; CARCINOMA; DIAGNOSIS; ACCURACY
AB Objective: The main aim of this study was to analyze the performance of different artificial intelligence (AI) models in endoscopic colonic polyp detection and classification and compare them with doctors with different experience. Methods: We searched the studies on Colonoscopy, Colonic Polyps, Artificial Intelligence, Machine Learning, and Deep Learning published before May 2020 in PubMed, EMBASE, Cochrane, and the citation index of the conference proceedings. The quality of studies was assessed using the QUADAS-2 table of diagnostic test quality evaluation criteria. The random-effects model was calculated using Meta-DISC 1.4 and RevMan 5.3. Results: A total of 16 studies were included for meta-analysis. Only one study (1/16) presented externally validated results. The area under the curve (AUC) of AI group, expert group and non-expert group for detection and classification of colonic polyps were 0.940, 0.918, and 0.871, respectively. AI group had slightly lower pooled specificity than the expert group (79% vs. 86%, P < 0.05), but the pooled sensitivity was higher than the expert group (88% vs. 80%, P < 0.05). While the non-experts had less pooled specificity in polyp recognition than the experts (81% vs. 86%, P < 0.05), and higher pooled sensitivity than the experts (85% vs. 80%, P < 0.05). Conclusion: The performance of AI in polyp detection and classification is similar to that of human experts, with high sensitivity and moderate specificity. Different tasks may have an impact on the performance of deep learning models and human experts, especially in terms of sensitivity and specificity.
C1 [Li, Ming-De; Huang, Ze-Rong; Shan, Quan-Yuan; Chen, Shu-Ling; Hu, Hang-Tong; Wang, Wei] Sun Yat Sen Univ, Affiliated Hosp 1, Inst Diagnost & Intervent Ultrasound, Ultras Artificial Intelligence X Lab,Dept Med Ultr, 58 Zhongshan Rd 2, Guangzhou 510080, Peoples R China.
   [Zhang, Ning] Sun Yat Sen Univ, Affiliated Hosp 1, Dept Gastroenterol, Guangzhou, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Hu, HT; Wang, W (通讯作者)，Sun Yat Sen Univ, Affiliated Hosp 1, Inst Diagnost & Intervent Ultrasound, Ultras Artificial Intelligence X Lab,Dept Med Ultr, 58 Zhongshan Rd 2, Guangzhou 510080, Peoples R China.
EM huht5@mail.sysu.edu.cn; wangw73@mail.sysu.edu.cn
OI Wang, Wei/0000-0002-9485-583X
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Eslam M, 2011, ALIMENT PHARM THER, V34, P297, DOI 10.1111/j.1365-2036.2011.04716.x
   grand-challenge, AUTOMATIC POLYP DETE
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Halligan S, 2006, GASTROENTEROLOGY, V131, P1690, DOI 10.1053/j.gastro.2006.09.051
   Ignjatovic A, 2011, GASTROINTEST ENDOSC, V73, P128, DOI 10.1016/j.gie.2010.09.021
   Jang JH, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/16113
   Jerebko AK, 2005, ACAD RADIOL, V12, P479, DOI 10.1016/j.acra.2004.04.024
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Mang T, 2012, EUR RADIOL, V22, P2768, DOI 10.1007/s00330-012-2522-2
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   nci.nih, VIRTUAL COLONOSCOPY
   Petrick N, 2008, RADIOLOGY, V246, P148, DOI 10.1148/radiol.2453062161
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P1186, DOI 10.1016/S0002-9270(03)00183-7
   Raghavendra M, 2010, GASTROINTEST ENDOSC, V72, P572, DOI 10.1016/j.gie.2010.03.1124
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Seely AJE, 2014, CRIT CARE, V18, DOI 10.1186/cc13822
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Sharma P, 2020, GASTROINTEST ENDOSC, V91, P925, DOI 10.1016/j.gie.2019.12.018
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI [DOI 10.3322/CAAC.21442, 10.3322/caac.21332]
   Simon K, 2016, CLIN INTERV AGING, V11, DOI 10.2147/CIA.S109285
   Tan LZ, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.6.23
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Whiting Penny F, 2006, BMC Med Res Methodol, V6, P9, DOI 10.1186/1471-2288-6-9
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Wu YK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195710
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhou HJ, 2016, J NUCL MED, V57, P342, DOI 10.2967/jnumed.115.165407
NR 47
TC 1
Z9 1
U1 2
U2 4
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
EI 1471-230X
J9 BMC GASTROENTEROL
JI BMC Gastroenterol.
PD DEC 13
PY 2022
VL 22
IS 1
AR 517
DI 10.1186/s12876-022-02605-2
PG 12
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 7K0TP
UT WOS:000904999500002
PM 36513975
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Zhou, HJ
   Liu, ZY
   Li, T
   Chen, YF
   Huang, W
   Zhang, ZJ
AF Zhou, Huijun
   Liu, Zhenyang
   Li, Ting
   Chen, Yifei
   Huang, Wei
   Zhang, Zijian
TI Classification of precancerous lesions based on fusion of multiple
   hierarchical features
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE Precancerous diseases; Feature fusion; Image recognition; Machine
   learning; Gastric cancer
ID CONVOLUTIONAL NEURAL-NETWORKS; WHOLE-SLIDE IMAGES; GASTRIC-CANCER;
   PREVENTION; DISEASES; PATTERN; CNN
AB Purpose: To investigate an identification method for precancerous gastric cancer based on the fusion of superficial features and deep features of gastroscopic images. The purpose of this study is to make most use of superficial features and deep features to provide clinicians with clinical decision support to assist the diagnosis of precancerous gastric diseases and reduce the workload of doctors. Methods: According to the nature of gastroscopic images, 75-dimensional shallow features were manually designed, including histogram features, texture features and high-order features of the image; then, based on the constructed convolutional neural networks such as ResNet and GoogLeNet, before the output layer. A fully connected layer is added as the deep feature of the image. In order to ensure consistent feature weights, the number of neurons in the fully connected layer is designed to be 75 dimensions. Therefore, the superficial and deep features of the image are concatenated, and a machine learning classifier is used to identify gastric polyps, there are three types of gastric precancerous diseases such as gastric polyps, gastric ulcers and gastric erosions. Results: A dataset with 420 images was collected for each disease, and divided into a training set and a test set with a ratio of 5:1, and then based on the dataset, three methods, such as traditional machine learning, deep learning, and feature fusion, were used respectively. For model training and testing of traditional machine learning and feature fusion, SVM, RF and BP neural network are used as the classification results of the classifier. For deep learning, the GoogLeNet, ResNet, and ResNeXt were implemented. The test results of the model on the test set show that the recognition accuracy of the proposed feature fusion method reaches (SVM: 85.18%; RF: 83.42%; BPNN: 85.18%), which is better than the traditional machine learning method (SVM: 80.17%; RF: 82.37%; BPNN: 84.12%) and the deep learning method (GoogLeNet: 82.54%; ResNet-18: 81.67%; ResNet-50: 81.67%; ResNeXt-50: 82.11%), which proves that this method has obvious advantages. Conclusion: This study provides a new strategy for the identification of precancerous gastric cancer, improving the efficiency and accuracy of precancerous gastric cancer identification, and hopes to provide substantial practical help for the identification of gastric precancerous diseases. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhou, Huijun; Liu, Zhenyang; Li, Ting] Cent South Univ, Hunan Canc Hosp, Affiliated Canc Hosp, Xiangya Sch Med,Dept Gastroenterol & Urol, Changsha 410013, Hunan, Peoples R China.
   [Chen, Yifei] Cent South Univ, Hunan Canc Hosp, Affiliated Canc Hosp, Xiangya Sch Med,Dept Endoscop Diag & Treatment Ctr, Changsha 410013, Hunan, Peoples R China.
   [Huang, Wei; Zhang, Zijian] Cent South Univ, Xiangya Hosp, Dept Radiat Oncol, Changsha 410008, Peoples R China.
   [Huang, Wei; Zhang, Zijian] Cent South Univ, Xiangya Hosp, Natl Clin Res Ctr Geriatr Disorders, Changsha 410008, Hunan, Peoples R China.
   [Huang, Wei] Cent South Univ, Xiangya Hosp, Res Ctr Carcinogenesis & Targeted Therapy, Changsha, Hunan, Peoples R China.
   [Huang, Wei; Zhang, Zijian] Cent South Univ, Xiangya Hosp, Res Ctr Carcinogenesis & Targeted Therapy, Natl Clin Res Ctr Geriatr Disorders,Dept Radiat On, Changsha 410008, Hunan, Peoples R China.
C3 Central South University; Central South University; Central South
   University; Central South University; Central South University; Central
   South University
RP Huang, W; Zhang, ZJ (通讯作者)，Cent South Univ, Xiangya Hosp, Res Ctr Carcinogenesis & Targeted Therapy, Natl Clin Res Ctr Geriatr Disorders,Dept Radiat On, Changsha 410008, Hunan, Peoples R China.
EM weihuang@csu.edu.cn; wanzzj@csu.edu.cn
RI Zhang, Zijian/AFR-0210-2022
OI Zhang, Zijian/0000-0002-2702-8025
FU 2020 Hunan Provincial clinical medical technology innovation guidance
   project [2020SK53706]; Changsha Municipal Natural Science Foundation
   [kq2202384]
FX The work was supported by 2020 Hunan Provincial clin-ical medical
   technology innovation guidance project (No. 2020SK53706) and Changsha
   Municipal Natural Science Foundation (No. kq2202384)
CR Aggarwal BB, 2009, CLIN CANCER RES, V15, P425, DOI 10.1158/1078-0432.CCR-08-0149
   [Anonymous], 2020, ARTIF INTELL
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Deb S, 2018, SOFT COMPUT, V22, P6035, DOI 10.1007/s00500-018-3076-2
   Fox JG, 2007, J CLIN INVEST, V117, P60, DOI 10.1172/JCI30111
   Galavis PE, 2010, ACTA ONCOL, V49, P1012, DOI 10.3109/0284186X.2010.498437
   Gao J, 2021, DIGEST DIS SCI, V66, P1212, DOI 10.1007/s10620-020-06289-0
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   GBD 2017 Gastrooesophageal, 2020, LANCET GASTROENTEROL, V5, P561, DOI 10.1016/S2468-1253(19)30408-X
   Gonzalez CA, 2012, INT J CANCER, V130, P745, DOI 10.1002/ijc.26430
   He K, 2016, DEEP RESIDUAL LEARNI
   Hegde N, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0131-z
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Isobe Y, 2011, GASTRIC CANCER, V14, P301, DOI 10.1007/s10120-011-0085-6
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Li JY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180830
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Lu Y, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101748
   Mochiki E, 2005, SURGERY, V137, P317, DOI 10.1016/j.surg.2004.10.012
   Sharma H, 2017, COMPUT MED IMAG GRAP, V61, P2, DOI 10.1016/j.compmedimag.2017.06.001
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang XX, 2018, ALLELOPATHY J, V45, P65, DOI 10.26651/allelo.j./2018-45-1-1176
   Wei LY, 2017, ARTIF INTELL MED, V83, P82, DOI 10.1016/j.artmed.2017.02.005
   Wong KKL, 2017, ORGANOGENESIS, V13, P39, DOI 10.1080/15476278.2017.1295904
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yoshida H, 2018, GASTRIC CANCER, V21, P249, DOI 10.1007/s10120-017-0731-8
   Yu J., 2017, J IMAGE GRAPH
   Zhang LJ, 2020, J MED IMAG HEALTH IN, V10, P2965, DOI 10.1166/jmihi.2020.3243
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zhao C, 2022, MEASUREMENT, V199, DOI 10.1016/j.measurement.2022.111569
   Zheng R., 2022, J NATL CANC CTR, V2, P1, DOI 10.1016/j.jncc.2022.02.002
   Zheng Z., 2021, CLIN MOL DIAGNOSTICS, P553
   Zulkurnain N F, 2022, CONTENT BASED IMAGE
NR 35
TC 2
Z9 2
U1 7
U2 13
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD FEB
PY 2023
VL 229
AR 107301
DI 10.1016/j.cmpb.2022.107301
EA DEC 2022
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 6Z3JU
UT WOS:000897677600005
PM 36516661
DA 2023-08-21
ER

PT J
AU Shah, S
   Park, N
   Chehade, NE
   Chahine, A
   Monachese, M
   Tiritilli, A
   Moosvi, Z
   Ortizo, R
   Samarasena, J
AF Shah, Sagar
   Park, Nathan
   Chehade, Nabil El Hage
   Chahine, Anastasia
   Monachese, Marc
   Tiritilli, Amelie
   Moosvi, Zain
   Ortizo, Ronald
   Samarasena, Jason
TI Effect of computer-aided colonoscopy on adenoma miss rates and polyp
   detection: A systematic review and meta-analysis
SO JOURNAL OF GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Review
DE adenoma detection rate; adenoma miss rate; artificial intelligence;
   colorectal cancer; computer-aided colonoscopy; computer-aided detection;
   polyp detection rate
ID COLORECTAL-CANCER; SERRATED POLYPS; RISK-FACTORS; TRIAL
AB Background and AimMultiple computer-aided techniques utilizing artificial intelligence (AI) have been created to improve the detection of polyps during colonoscopy and thereby reduce the incidence of colorectal cancer. While adenoma detection rates (ADR) and polyp detection rates (PDR) are important colonoscopy quality indicators, adenoma miss rates (AMR) may better quantify missed lesions, which can ultimately lead to interval colorectal cancer. The purpose of this systematic review and meta-analysis was to determine the efficacy of computer-aided colonoscopy (CAC) with respect to AMR, ADR, and PDR in randomized controlled trials. MethodsA comprehensive, systematic literature search was performed across multiple databases in September of 2022 to identify randomized, controlled trials that compared CAC with traditional colonoscopy. Primary outcomes were AMR, ADR, and PDR. ResultsFourteen studies totaling 10 928 patients were included in the final analysis. There was a 65% reduction in the adenoma miss rate with CAC (OR, 0.35; 95% CI, 0.25-0.49, P < 0.001, I-2 = 50%). There was a 78% reduction in the sessile serrated lesion miss rate with CAC (OR, 0.22; 95% CI, 0.08-0.65, P < 0.01, I-2 = 0%). There was a 52% increase in ADR in the CAC group compared with the control group (OR, 1.52; 95% CI, 1.39-1.67, P = 0.04, I-2 = 47%). There was 93% increase in the number of adenomas > 10 mm detected per colonoscopy with CAC (OR 1.93; 95% CI, 1.18-3.16, P < 0.01, I-2 = 0%). ConclusionsThe results of the present study demonstrate the promise of CAC in improving AMR, ADR, PDR across a spectrum of size and morphological lesion characteristics.
C1 [Shah, Sagar] Univ Calif Los Angeles, Ronald Reagan Med Ctr, Dept Internal Med, Los Angeles, CA USA.
   [Park, Nathan; Chahine, Anastasia; Monachese, Marc; Tiritilli, Amelie; Ortizo, Ronald; Samarasena, Jason] Univ Calif Irvine, Irvine Med Ctr, H H Chao Comprehens Digest Dis Ctr, Orange, CA USA.
   [Chehade, Nabil El Hage] Case Western Reserve Univ, Metrohlth Med Ctr, Div Internal Med, Cleveland, OH USA.
   [Moosvi, Zain] Univ Pittsburgh, Div Gastroenterol Hepatol & Nutr, Pittsburgh, PA USA.
   [Samarasena, Jason] Univ Calif Irvine, Irvine Med Ctr, Comprehens Digest Dis Ctr, 333 City Blvd West Suite 400, Orange, CA 92868 USA.
C3 University of California System; University of California Los Angeles;
   University of California Los Angeles Medical Center; Ronald Reagan UCLA
   Medical Center; University of California System; University of
   California Irvine; Case Western Reserve University; MetroHealth System;
   Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh; University of California System; University of California
   Irvine
RP Samarasena, J (通讯作者)，Univ Calif Irvine, Irvine Med Ctr, Comprehens Digest Dis Ctr, 333 City Blvd West Suite 400, Orange, CA 92868 USA.
EM jsamaras@hs.uci.edu
CR Adler J, 2015, AM J GASTROENTEROL, V110, P1657, DOI 10.1038/ajg.2015.365
   Aniwan S, 2016, AM J GASTROENTEROL, V111, P723, DOI 10.1038/ajg.2015.440
   [Anonymous], 2017, CANC FACTS FIG 2015
   Araghi M, 2019, INT J CANCER, V144, P2992, DOI 10.1002/ijc.32055
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Bensen S, 1999, AM J GASTROENTEROL, V94, P194
   Boparai KS, 2010, GUT, V59, P1094, DOI 10.1136/gut.2009.185884
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Brown JR., 2021, CLIN GASTROENTEROL H
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hiraoka S, 2010, GASTROENTEROLOGY, V139, P1503, DOI 10.1053/j.gastro.2010.07.011
   HIXSON LJ, 1991, GASTROINTEST ENDOSC, V37, P125, DOI 10.1016/S0016-5107(91)70668-8
   Jeong YH, 2016, J KOREAN MED SCI, V31, P1426, DOI 10.3346/jkms.2016.31.9.1426
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Kolb JM, 2020, AM J GASTROENTEROL, V115, P980, DOI 10.14309/ajg.0000000000000639
   Leggett B, 2010, GASTROENTEROLOGY, V138, P2088, DOI 10.1053/j.gastro.2009.12.066
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Pickhardt PJ, 2004, ANN INTERN MED, V141, P352, DOI 10.7326/0003-4819-141-5-200409070-00009
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rosch T, 2018, CLIN GASTROENTEROL H, V16, P1754, DOI 10.1016/j.cgh.2018.05.043
   Schoefl R, 2015, DIGEST DIS, V33, P38, DOI 10.1159/000366034
   Schreiner MA, 2010, GASTROENTEROLOGY, V139, P1497, DOI 10.1053/j.gastro.2010.06.074
   Shaukat A, 2022, GASTROENTEROLOGY, V163, P732, DOI 10.1053/j.gastro.2022.05.028
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI [DOI 10.3322/CAAC.21442, 10.3322/caac.21332]
   Snover DC, 2005, AM J CLIN PATHOL, V124, P380, DOI 10.1309/V2EPTPLJRB3FGHJL
   Spring KJ, 2006, GASTROENTEROLOGY, V131, P1400, DOI 10.1053/j.gastro.2006.08.038
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Wallace MB, 2022, GASTROENTEROLOGY, V163, P295, DOI 10.1053/j.gastro.2022.03.007
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Xu L, 2021, CANCER MED-US, V10, P7184, DOI 10.1002/cam4.4261
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 40
TC 7
Z9 7
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0815-9319
EI 1440-1746
J9 J GASTROEN HEPATOL
JI J. Gastroenterol. Hepatol.
PD FEB
PY 2023
VL 38
IS 2
BP 162
EP 176
DI 10.1111/jgh.16059
EA DEC 2022
PG 15
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 9A7KA
UT WOS:000897119800001
PM 36350048
DA 2023-08-21
ER

PT J
AU Houwen, BBSL
   Hartendorp, F
   Giotis, I
   Hazewinkel, Y
   Fockens, P
   Walstra, TR
   Dekker, E
AF Houwen, Britt B. S. L.
   Hartendorp, Fons
   Giotis, Ioanis
   Hazewinkel, Yark
   Fockens, Paul
   Walstra, Taco R.
   Dekker, Evelien
CA POLAR Study Grp
TI Computer-aided classification of colorectal segments during colonoscopy:
   a deep learning approach based on images of a magnetic endoscopic
   positioning device
SO SCANDINAVIAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Artificial intelligence; colorectal cancer; colorectal polyps;
   colonoscopy; optical diagnosis
ID TUMOR-LOCALIZATION; ACCURACY; CANCER
AB ObjectiveAssessment of the anatomical colorectal segment of polyps during colonoscopy is important for treatment and follow-up strategies, but is largely operator dependent. This feasibility study aimed to assess whether, using images of a magnetic endoscope imaging (MEI) positioning device, a deep learning approach can be useful to objectively divide the colorectum into anatomical segments.MethodsModels based on the VGG-16 based convolutional neural network architecture were developed to classify the colorectum into anatomical segments. These models were pre-trained on ImageNet data and further trained using prospectively collected data of the POLAR study in which endoscopists were using MEI (3930 still images and 90,151 video frames). Five-fold cross validation with multiple runs was used to evaluate the overall diagnostic accuracies of the models for colorectal segment classification (divided into a 5-class and 2-class colorectal segment division). The colorectal segment assignment by endoscopists was used as the reference standard.ResultsFor the 5-class colorectal segment division, the best performing model correctly classified the colorectal segment in 753 of the 1196 polyps, corresponding to an overall accuracy of 63%, sensitivity of 63%, specificity of 89% and kappa of 0.47. For the 2-class colorectal segment division, 1112 of the 1196 polyps were correctly classified, corresponding to an accuracy of 93%, sensitivity of 93%, specificity of 90% and kappa of 0.82.ConclusionThe diagnostic performance of a deep learning approach for colorectal segment classification based on images of a MEI device is yet suboptimal (clinicaltrials.gov: NCT03822390).
C1 [Houwen, Britt B. S. L.; Fockens, Paul; Dekker, Evelien] Univ Amsterdam, Amsterdam Univ Med Ctr, Locat Acad Med Ctr, Dept Gastroenterol & Hepatol, Amsterdam, Netherlands.
   [Hartendorp, Fons; Walstra, Taco R.] Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands.
   [Giotis, Ioanis] ZiuZ Visual Intelligence, Gorredijk, Netherlands.
   [Hazewinkel, Yark] Radboud Univ Nijmegen, Med Ctr, Dept Gastroenterol & Hepatol, Nijmegen, Netherlands.
   [Dekker, Evelien] Bergman Clin Maag & Darm Amsterdam, Amsterdam, Netherlands.
   [Dekker, Evelien] Univ Amsterdam, Locat Acad Med Ctr, Med Ctr, Dept Gastroenterol & Hepatol, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.
C3 University of Amsterdam; University of Amsterdam; Radboud University
   Nijmegen; University of Amsterdam
RP Dekker, E (通讯作者)，Univ Amsterdam, Locat Acad Med Ctr, Med Ctr, Dept Gastroenterol & Hepatol, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.
EM e.dekker@amsterdamumc.nl
RI Dekker, Evelien/HOH-9015-2023; Hazewinkel, Yark/AAD-6593-2019; Houwen,
   Britt/IVH-6320-2023
OI Daca-Alvarez, Maria/0000-0001-5636-8865
FU Dutch Digestive Disease Foundation [TKI 18-01]; European Regional
   Development Fund region Northern-Netherlands [UP-18-00565]; Province of
   Friesland; ZiuZ Medical B.V
FX The collaboration project is co-funded by the PPP Allowance made
   available by Health?~?Holland, Top Sector Life Sciences & Health, to the
   Dutch Digestive Disease Foundation to stimulate public-private
   partnerships [TKI 18-01]; the European Regional Development Fund region
   Northern-Netherlands [UP-18-00565]; and the province of Friesland. ZiuZ
   Medical B.V provided research equipment on loan for this study.
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Bodenstedt S., 2017, ARXIV
   Borda F, 2012, REV ESP ENFERM DIG, V104, P512, DOI 10.4321/s1130-01082012001000002
   Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1136/bmj.h5527, 10.1373/clinchem.2015.246280, 10.1148/radiol.2015151516]
   Cho YB, 2007, WORLD J SURG, V31, P1491, DOI 10.1007/s00268-007-9082-7
   Ellul P, 2011, EUR J GASTROEN HEPAT, V23, P488, DOI 10.1097/MEG.0b013e328346974b
   Feuerlein S, 2012, EUR J RADIOL, V81, P2538, DOI 10.1016/j.ejrad.2011.12.004
   Hassan C, 2013, ENDOSCOPY, V45, P842, DOI 10.1055/s-0033-1344548
   LISA, BEOWULF CLUSTER COMP
   Liu JF, 2013, COMPUT MED IMAG GRAP, V37, P207, DOI 10.1016/j.compmedimag.2013.01.010
   Louis MA, 2010, WORLD J SURG, V34, P1587, DOI 10.1007/s00268-009-0358-y
   Misawa M, 2021, DIGEST ENDOSC, V33, P273, DOI 10.1111/den.13847
   Moug SJ, 2017, SURG ENDOSC, V31, P2959, DOI 10.1007/s00464-016-5313-z
   Neri E, 2010, ABDOM IMAGING, V35, P589, DOI 10.1007/s00261-009-9570-3
   O'Connor SA, 2016, ENDOSC INT OPEN, V4, pE642, DOI 10.1055/s-0042-105864
   Piscatelli N, 2005, ARCH SURG-CHICAGO, V140, P932, DOI 10.1001/archsurg.140.10.932
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saito H, 2021, GASTROENTEROL REP, V9, P226, DOI 10.1093/gastro/goaa078
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Solon JG, 2010, COLORECTAL DIS, V12, pE267, DOI 10.1111/j.1463-1318.2009.02144.x
   Stanciu C, 2007, Rev Med Chir Soc Med Nat Iasi, V111, P39
   Vaziri K, 2010, SURG ENDOSC, V24, P2502, DOI 10.1007/s00464-010-0993-2
   Weyand T., 2016, EUROPEAN C COMPUTER
   Yao HM, 2021, MED IMAGE ANAL, V73, DOI 10.1016/j.media.2021.102180
NR 24
TC 2
Z9 2
U1 2
U2 3
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0036-5521
EI 1502-7708
J9 SCAND J GASTROENTERO
JI Scand. J. Gastroenterol.
PD JUN 3
PY 2023
VL 58
IS 6
BP 649
EP 655
DI 10.1080/00365521.2022.2151320
EA DEC 2022
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA G4YS6
UT WOS:000912246300001
PM 36458659
OA Green Submitted, hybrid
DA 2023-08-21
ER

PT J
AU Nisa, SQ
   Ismail, AR
AF Nisa, Syed Qamrun
   Ismail, Amelia Ritahani
TI Dual U-Net with Resnet Encoder for Segmentation of Medical Images
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Medical Images; Deep Convolutional Neural Network; FCN; U-net;
   Unet_Resnet; Dual U-net with Resnet Encoder
ID LEARNING TECHNIQUES
AB Segmentation of medical images has been the most demanding and growing area currently for analysis of medical images. Segmentation of polyp images is a huge challenge because of the variability of color depth and morphology in polyps throughout colonoscopy imaging. For segmentation, in this work, we have used a dataset of images of the gastrointestinal polyp. The algorithms used in this paper for segmentation of gastrointestinal polyp images depend on profound deep convolutional neural network architectures: FCN, Dual U-net with Resnet Encoder, U-net, and Unet_Resnet. To improve the performance, data augmentation is performed on the dataset. The efficiency of the algorithms is measured by using metrics such as Dice Similarity Coefficient (DSC) and Intersection Over Union (IOU). The algorithm Dual U-net with Resnet Encoder obtains a higher DSC of 0.87 and IOU of 0.80 and beats the other algorithms U-net, FCN, and Unet_Resnet in segmentation of gastrointestinal polyp images.
C1 [Nisa, Syed Qamrun; Ismail, Amelia Ritahani] Int Islamic Univ Malaysia, Dept Comp Sci, Kulliyyah Informat & Commun Technol, POB 10, Kuala Lumpur 50728, Malaysia.
C3 International Islamic University Malaysia
RP Ismail, AR (通讯作者)，Int Islamic Univ Malaysia, Dept Comp Sci, Kulliyyah Informat & Commun Technol, POB 10, Kuala Lumpur 50728, Malaysia.
RI Ismail, Amelia Ritahani/ABH-7150-2020
OI Ismail, Amelia Ritahani/0000-0002-7126-4287
FU Kulliyyah of Information and Communication Technology (KICT);
   International Islamic University Malaysia
FX The publication fees for this paper are funded by Kulliyyah of
   Information and Communication Technology (KICT), International Islamic
   University Malaysia.
CR Afify HM, 2021, INT J IMAG SYST TECH, V31, P1741, DOI 10.1002/ima.22568
   Ait Skourt B, 2018, PROCEDIA COMPUT SCI, V127, P109, DOI 10.1016/j.procs.2018.01.104
   Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   [Anonymous], 2014, INT J RECENT ADV ENG, DOI DOI 10.24128/IJRAER.2017.MN89CD
   Banerjee A, 2016, 2016 3rd International Conference on Recent Advances in Information Technology (RAIT), P429, DOI 10.1109/RAIT.2016.7507940
   Bi L, 2018, VISUAL COMPUT, V34, P1043, DOI 10.1007/s00371-018-1519-5
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Cao W, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P346, DOI 10.1109/CISP-BMEI.2016.7852734
   Ghosh S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329784
   Gupta K.K., 2018, 2018 4 INT C COMPUT, P1, DOI DOI 10.1109/CCAA.2018.8777561
   Habijan Marija, 2019, 2019 International Conference on Systems, Signals and Image Processing (IWSSIP). Proceedings, P121, DOI 10.1109/IWSSIP.2019.8787253
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Idris B., 2021, IMAGE PROCESSING TEC
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Khan W., 2014, J IMAGE GRAPH, P166, DOI [10.12720/joig.1.4.166-170, DOI 10.12720/JOIG.1.4.166-170]
   Lai JW, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/4625371
   Liu XB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031224
   Malhotra P, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/9580991
   Mehmood A, 2019, SIGGRAPH '19 - ACM SIGGRAPH 2019 POSTERS, DOI 10.1145/3306214.3338602
   Merjulah R, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P1055, DOI 10.1109/ICICI.2017.8365301
   Mittal M, 2020, ALGO INTELL SY, P41, DOI 10.1007/978-981-15-1100-4_3
   Mohamed Y., 2019, MEDICAL IMAGING PRIN, DOI 10.5772/intechopen.84360
   Nisa S. Q., 2020, 2020 IEEE 7 INT C EN, P1, DOI [10.1109/ICETAS51660.2020.9484287, DOI 10.1109/ICETAS51660.2020.9484287]
   Nisa S. Q., 2021, COMP PERFORMANCE ANA, V8, P149
   Ozturk S, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106799
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pashaei M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060959
   Phonsa G, 2019, ADV INTELL SYST, V741, P1123, DOI 10.1007/978-981-13-0761-4_105
   Prabhu P., 2017, DIGITAL IMAGE PROCES
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saarinen T., 2005, TRACK ENV CHANG USIN, V2, P23, DOI [10.1007/0-306-47670-3_3, DOI 10.1007/0-306-47670-3_3]
   Seo H, 2020, MED PHYS, V47, pE148, DOI 10.1002/mp.13649
   Sharma S, 2019, COMP M BIO BIO E-IV, V7, P286, DOI 10.1080/21681163.2018.1493619
   Siddique N, 2021, IEEE ACCESS, V9, P82031, DOI 10.1109/ACCESS.2021.3086020
   Tsuji T., 2021, AUTOMATIC MULTICLASS, V189, DOI [10.1007/978-981-15-5784-2_18, DOI 10.1007/978-981-15-5784-2_18]
   Vardhana M, 2018, COGN SYST RES, V50, P10, DOI 10.1016/j.cogsys.2018.03.005
   Wang B, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4886
   Alom MZ, 2018, Arxiv, DOI arXiv:1803.01164
   Zhang Z, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105395
NR 39
TC 0
Z9 0
U1 0
U2 0
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD DEC
PY 2022
VL 13
IS 12
BP 537
EP 542
PG 6
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 8K3XZ
UT WOS:000923040200065
DA 2023-08-21
ER

PT J
AU Ochiai, K
   Ozawa, T
   Shibata, J
   Ishihara, S
   Tada, T
AF Ochiai, Kentaro
   Ozawa, Tsuyoshi
   Shibata, Junichi
   Ishihara, Soichiro
   Tada, Tomohiro
TI Current Status of Artificial Intelligence-Based Computer-Assisted
   Diagnosis Systems for Gastric Cancer in Endoscopy
SO DIAGNOSTICS
LA English
DT Review
DE endoscopy; esophagogastroduodenoscopy; artificial intelligence (AI);
   gastric cancer; computer-assisted diagnosis (CAD)
ID HELICOBACTER-PYLORI INFECTION; UPPER GASTROINTESTINAL ENDOSCOPY;
   CONVOLUTIONAL NEURAL-NETWORK; CONVENTIONAL ENDOSCOPY; INVASION DEPTH;
   MAGNIFYING ENDOSCOPY; SINGLE-CENTER; MULTICENTER; COLONOSCOPY;
   PREDICTION
AB Artificial intelligence (AI) is gradually being utilized in various fields as its performance has been improving with the development of deep learning methods, availability of big data, and the progression of computer processing units. In the field of medicine, AI is mainly implemented in image recognition, such as in radiographic and pathologic diagnoses. In the realm of gastrointestinal endoscopy, although AI-based computer-assisted detection/diagnosis (CAD) systems have been applied in some areas, such as colorectal polyp detection and diagnosis, so far, their implementation in real-world clinical settings is limited. The accurate detection or diagnosis of gastric cancer (GC) is one of the challenges in which performance varies greatly depending on the endoscopist's skill. The diagnosis of early GC is especially challenging, partly because early GC mimics atrophic gastritis in the background mucosa. Therefore, several CAD systems for GC are being actively developed. The development of a CAD system for GC is considered challenging because it requires a large number of GC images. In particular, early stage GC images are rarely available, partly because it is difficult to diagnose gastric cancer during the early stages. Additionally, the training image data should be of a sufficiently high quality to conduct proper CAD training. Recently, several AI systems for GC that exhibit a robust performance, owing to being trained on a large number of high-quality images, have been reported. This review outlines the current status and prospects of AI use in esophagogastroduodenoscopy (EGDS), focusing on the diagnosis of GC.
C1 [Ochiai, Kentaro; Ozawa, Tsuyoshi; Ishihara, Soichiro; Tada, Tomohiro] Univ Tokyo, Fac Med, Dept Surg Oncol, Bunkyo ku, Tokyo 1130033, Japan.
   [Ozawa, Tsuyoshi; Shibata, Junichi; Tada, Tomohiro] Tomohiro Tada Inst Gastroenterol & Proctol, Musashi Urawa, Saitama 3360021, Japan.
   [Ozawa, Tsuyoshi; Shibata, Junichi; Tada, Tomohiro] AI Med Serv Inc, Toshima ku, Tokyo 1040061, Japan.
C3 University of Tokyo
RP Ochiai, K (通讯作者)，Univ Tokyo, Fac Med, Dept Surg Oncol, Bunkyo ku, Tokyo 1130033, Japan.
EM ochiaik-sur@h.u-tokyo.ac.jp
RI shibata, junichi/GLV-4981-2022
CR Abe S, 2011, GASTRIC CANCER, V14, P35, DOI 10.1007/s10120-011-0002-z
   Areia M, 2022, LANCET DIGIT HEALTH, V4, pE436, DOI 10.1016/S2589-7500(22)00042-5
   Barreto SG, 2016, SURG ENDOSC, V30, P24, DOI 10.1007/s00464-015-4184-z
   Chen XX, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102444
   Cho BJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061858
   Choi J, 2010, ENDOSCOPY, V42, P705, DOI 10.1055/s-0030-1255617
   Correa P, 2007, GASTROENTEROLOGY, V133, P659, DOI 10.1053/j.gastro.2007.06.026
   Dohi O, 2017, GASTRIC CANCER, V20, P297, DOI 10.1007/s10120-016-0620-6
   Doyama H, 2021, GUT LIVER, V15, P329, DOI 10.5009/gnl19392
   Guimaraes P, 2020, GUT, V69, P4, DOI 10.1136/gutjnl-2019-319347
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horiuchi Y, 2020, DIGEST DIS SCI, V65, P1355, DOI 10.1007/s10620-019-05862-6
   Horiuchi Y, 2020, GASTROINTEST ENDOSC, V92, P856, DOI 10.1016/j.gie.2020.04.079
   Hosokawa O, 2007, HEPATO-GASTROENTEROL, V54, P442
   Hu H, 2021, GASTROINTEST ENDOSC, V93, P1333, DOI 10.1016/j.gie.2020.11.014
   Ikenoyama Y, 2021, DIGEST ENDOSC, V33, P141, DOI 10.1111/den.13688
   Ishioka M, 2022, DIGEST ENDOSC, DOI 10.1111/den.14455
   Ishioka M, 2019, DIGEST ENDOSC, V31, pe34, DOI 10.1111/den.13306
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Januszewicz W, 2022, ENDOSCOPY, V54, P653, DOI 10.1055/a-1675-4136
   Japanese Gastr Canc Assoc, 2021, GASTRIC CANCER, V24, P1, DOI 10.1007/s10120-020-01042-y
   Katai H, 2018, GASTRIC CANCER, V21, P144, DOI 10.1007/s10120-017-0716-7
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kumar S, 2021, ANN GASTROENTEROL, V34, P669, DOI 10.20524/aog.2021.0640
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Li YD, 2022, GASTROINTEST ENDOSC, V95, P1138, DOI 10.1016/j.gie.2021.12.019
   Ling TS, 2021, ENDOSCOPY, V53, P469, DOI 10.1055/a-1229-0920
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Luo HY, 2019, LANCET ONCOL, V20, P1645, DOI 10.1016/S1470-2045(19)30637-0
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Miyaoka M, 2020, TRANSL GASTROENT HEP, V5, DOI 10.21037/tgh.2019.12.16
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Nagahama T, 2017, GASTRIC CANCER, V20, P304, DOI 10.1007/s10120-016-0612-6
   Nagao S, 2020, GASTROINTEST ENDOSC, V92, P866, DOI 10.1016/j.gie.2020.06.047
   Nakashima H, 2020, GASTRIC CANCER, V23, P1033, DOI 10.1007/s10120-020-01077-1
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Nakayoshi T, 2004, ENDOSCOPY, V36, P1080, DOI 10.1055/s-2004-825961
   Nam JY, 2022, GASTROINTEST ENDOSC, V95, P258, DOI 10.1016/j.gie.2021.08.022
   Namikawa K, 2020, ENDOSCOPY, V52, P1077, DOI 10.1055/a-1194-8771
   Niikura R, 2022, ENDOSCOPY, V54, P780, DOI 10.1055/a-1660-6500
   Ramamurthy K, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102316
   SANO T, 1990, DIGEST DIS SCI, V35, P1340, DOI 10.1007/BF01536738
   Shichijo S, 2019, SCAND J GASTROENTERO, V54, P158, DOI 10.1080/00365521.2019.1577486
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Sugano K, 2015, GUT, V64, P1353, DOI 10.1136/gutjnl-2015-309252
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tang DH, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.622827
   Tsujii Y, 2015, GASTROINTEST ENDOSC, V82, P452, DOI 10.1016/j.gie.2015.01.022
   Ueyama H, 2021, J GASTROEN HEPATOL, V36, P482, DOI 10.1111/jgh.15190
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
   Wu LL, 2022, GASTROINTEST ENDOSC, V95, P269, DOI 10.1016/j.gie.2021.09.017
   Wu LL, 2022, GASTROINTEST ENDOSC, V95, P92, DOI 10.1016/j.gie.2021.06.033
   Wu LL, 2021, LANCET GASTROENTEROL, V6, P700, DOI 10.1016/S2468-1253(21)00216-8
   Wu LL, 2021, ENDOSCOPY, V53, P1199, DOI 10.1055/a-1350-5583
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Xu M, 2021, GASTROINTEST ENDOSC, V94, P540, DOI 10.1016/j.gie.2021.03.013
   Yao K, 2009, ENDOSCOPY, V41, P462, DOI 10.1055/s-0029-1214594
   Yoon HJ, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091310
   Yuan XL, 2022, SURG ENDOSC, V36, P9444, DOI 10.1007/s00464-022-09420-6
   Zhang YQ, 2020, DIGEST LIVER DIS, V52, P566, DOI 10.1016/j.dld.2019.12.146
   Zheng WF, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000109
   Zhou Y, 2015, J DIGEST DIS, V16, P303, DOI 10.1111/1751-2980.12251
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 64
TC 2
Z9 2
U1 5
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD DEC
PY 2022
VL 12
IS 12
AR 3153
DI 10.3390/diagnostics12123153
PG 15
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 7D6PW
UT WOS:000900610800001
PM 36553160
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Liu, GW
   Zhao, J
   Tian, GY
   Li, S
   Lu, Y
AF Liu, Guangwei
   Zhao, Jun
   Tian, Guangye
   Li, Shuai
   Lu, Yun
TI Visualizing knowledge evolution trends and research hotspots of
   artificial intelligence in colorectal cancer: A bibliometric analysis
SO FRONTIERS IN ONCOLOGY
LA English
DT Article
DE bibliometric analysis; artificial intelligence; network visualization;
   colorectal cancer; deep learning
ID CLASSIFICATION; DIAGNOSIS
AB BackgroundIn recent years, the rapid development of artificial intelligence (AI) technology has created a new diagnostic and therapeutic opportunity for colorectal cancer (CRC). Numerous academic and clinical studies have demonstrated that high-level auxiliary diagnosis and treatment systems based on AI technology can significantly improve the readability of medical data, objectively provide a reliable and comprehensive reference for physicians, reduce the experience gap between physicians, and aid physicians in making more accurate diagnosis decisions. In this study, we used bibliometric techniques to visually analyze the literature about AI in the CRC field and summarize the current situation and research hotspots in this field.MethodsThe relevant literature on AI in the field of CRC research was obtained from the Web of Science Core Collection (WoSCC) database. The software CiteSpace was utilized to analyze the number of papers, countries, institutions, authors, journals, cited literature, and keywords of the included literature and generate a visual knowledge map. The present study aims to evaluate the origin, current hotspots, and research trends of AI in CRC using bibliometric analysis.ResultsAs of March 2022, 64 nations/regions, 230 institutions, 245 journals, and 300 authors had published 562 AI-related articles in the field of CRC. Since 2016, each year has seen an exponential increase. China and the United States were the largest contributors, with the largest number of beneficial research institutions and the closest collaboration relationship. The World Journal of Gastroenterology is this field's most widely published journal. Diagnosis and treatment research, gene and immunology research, intestinal polyp research, tumor grading research, gastrointestinal endoscopy research, and prognosis research comprised the six topics derived from high-frequency keyword cluster analysis.ConclusionIn recent years, field research has been a popular topic of discussion. The results of our bibliometric analysis allow us to comprehend better the current situation and trend of this research field, and the quantitative data indicators can serve as a guide for the research and application of global scholars.
C1 [Liu, Guangwei; Lu, Yun] Qingdao Univ, Affiliated Hosp, Dept Gastrointestinal Surg, Qingdao, Shandong, Peoples R China.
   [Zhao, Jun] Qingdao Univ, Affiliated Hosp, Dept Pharm, Qingdao, Shandong, Peoples R China.
   [Tian, Guangye] Shandong Univ, Sch Control Sci & Engn, Jinan, Shandong, Peoples R China.
   [Li, Shuai] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Liu, Guangwei; Lu, Yun] Qingdao Univ, Shandong Key Lab Digital Med & Comp Assisted Surg, Qingdao, Shandong, Peoples R China.
C3 Qingdao University; Qingdao University; Shandong University; Beihang
   University; Qingdao University
RP Lu, Y (通讯作者)，Qingdao Univ, Affiliated Hosp, Dept Gastrointestinal Surg, Qingdao, Shandong, Peoples R China.; Lu, Y (通讯作者)，Qingdao Univ, Shandong Key Lab Digital Med & Comp Assisted Surg, Qingdao, Shandong, Peoples R China.
EM luyun@qdu.edu.cn
FU Shandong Natural Science Foundation of China;  [ZR2019PF017]; 
   [ZR2020MF155]
FX Funding This work was supported by Shandong Natural Science Foundation
   of China (grant numbers: ZR2019PF017 and ZR2020MF155).
CR Anand SS, 1999, ARTIF INTELL MED, V15, P193, DOI 10.1016/S0933-3657(98)00052-9
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Chen CL, 2016, SCI REP-UK, V6, DOI 10.1038/srep21471
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Liu N, 2021, SCIENTOMETRICS, V126, P3153, DOI 10.1007/s11192-021-03868-4
   Liu ZY, 2019, THERANOSTICS, V9, P1303, DOI 10.7150/thno.30309
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Park S, 2021, MEDICINE, V100, DOI 10.1097/MD.0000000000025422
   Reichling C, 2020, GUT, V69, P681, DOI 10.1136/gutjnl-2019-319292
   Saheb T, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104660
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yu KH, 2019, BMJ QUAL SAF, V28, P238, DOI 10.1136/bmjqs-2018-008551
   Zeng YF, 2020, THERANOSTICS, V10, P2587, DOI 10.7150/thno.40099
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang XY, 2021, ANN PALLIAT MED, V10, P3750, DOI 10.21037/apm-20-2050
   Zhang X, 2019, MOLECULES, V24, DOI 10.3390/molecules24122238
   Zhang Y, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/7899929
NR 24
TC 0
Z9 0
U1 8
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2234-943X
J9 FRONT ONCOL
JI Front. Oncol.
PD NOV 28
PY 2022
VL 12
AR 925924
DI 10.3389/fonc.2022.925924
PG 12
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA 6Y3MU
UT WOS:000897002900001
PM 36518311
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Gan, PL
   Huang, S
   Pan, X
   Xia, HF
   Lue, MH
   Zhou, X
   Tang, XW
AF Gan, Pei-Ling
   Huang, Shu
   Pan, Xiao
   Xia, Hui-Fang
   Lue, Mu-Han
   Zhou, Xian
   Tang, Xiao-Wei
TI The scientific progress and prospects of artificial intelligence in
   digestive endoscopy: A comprehensive bibliometric analysis
SO MEDICINE
LA English
DT Review
DE artificial intelligence; digestive endoscope; visualization; VOSviewer;
   CiteSpace
ID CONVOLUTIONAL NEURAL-NETWORKS; CAPSULE ENDOSCOPY; REGENERATIVE MEDICINE;
   EMERGING TRENDS; GASTRIC-CANCER; CLASSIFICATION; DIAGNOSIS; IMAGES
AB Background:Artificial intelligence (AI) has been used for diagnosis and outcome prediction in clinical practice. Furthermore, AI in digestive endoscopy has attracted much attention and shown promising and stimulating results. This study aimed to determine the development trends and research hotspots of AI in digestive endoscopy by visualizing articles. Publications on AI in digestive endoscopy research were retrieved from the Web of Science Core Collection on April 25, 2022. VOSviewer and CiteSpace were used to assess and plot the research outputs. This analytical research was based on original articles and reviews. A total of 524 records of AI research in digestive endoscopy, published between 2005 and 2022, were retrieved. The number of articles has increased 27-fold from 2017 to 2021. Fifty-one countries and 994 institutions contributed to all publications. Asian countries had the highest number of publications. China, the USA, and Japan were consistently the leading driving forces and mainly contributed (26%, 21%, and 14.31%, respectively). With a solid academic reputation in this area, Japan has the highest number of citations per article. Tada Tomohiro published the most articles and received the most citations.. Gastrointestinal endoscopy published the largest number of publications, and 4 of the top 10 cited papers were published in this journal. "The Classification," "ulcerative colitis," "capsule endoscopy," "polyp detection," and "early gastric cancer" were the leading research hotspots. Our study provides systematic elaboration for researchers to better understand the development of AI in gastrointestinal endoscopy.
C1 [Gan, Pei-Ling; Pan, Xiao; Xia, Hui-Fang; Lue, Mu-Han; Zhou, Xian; Tang, Xiao-Wei] Southwest Med Univ, Affiliated Hosp, Dept Gastroenterol, Luzhou, Peoples R China.
   [Huang, Shu] Peoples Hosp Lianshui, Dept Gastroenterol, Huaian, Peoples R China.
   [Tang, Xiao-Wei] Southwest Med Univ, Affiliated Hosp, Dept Gastroenterol, St Taiping 25, Luzhou 646099, Sichuan, Peoples R China.
C3 Southwest Medical University; Southwest Medical University
RP Zhou, X; Tang, XW (通讯作者)，Southwest Med Univ, Affiliated Hosp, Dept Gastroenterol, Luzhou, Peoples R China.; Tang, XW (通讯作者)，Southwest Med Univ, Affiliated Hosp, Dept Gastroenterol, St Taiping 25, Luzhou 646099, Sichuan, Peoples R China.
EM ganpeilingspirit@163.com; 0826hxs@163.com; 1051902762@qq.com;
   2315768518@qq.com; 995155523@qq.com; solitude5834@hotmail.com;
   853023378@qq.com
CR Abiodun OI, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00938
   Ajani JA, 2013, J NATL COMPR CANC NE, V11, P531, DOI 10.6004/jnccn.2013.0070
   Akpunonu B, 2022, CLEV CLIN J MED, V89, P200, DOI 10.3949/ccjm.89a.20061
   [Anonymous], WHO CANC STAT
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Byrne MF, 2019, GASTROINTEST ENDOSC, V89, P195, DOI 10.1016/j.gie.2018.08.017
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen CM, 2017, J DATA INFO SCI, V2, P1, DOI 10.1515/jdis-2017-0006
   Chen CM, 2014, EXPERT OPIN BIOL TH, V14, P1295, DOI 10.1517/14712598.2014.920813
   Chen CM, 2012, EXPERT OPIN BIOL TH, V12, P593, DOI 10.1517/14712598.2012.674507
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cho BJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70490-4
   Arnal MJD, 2015, WORLD J GASTROENTERO, V21, P7933, DOI 10.3748/wjg.v21.i26.7933
   Goyal H, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103313
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hong JS, 2017, IEEE ENG MED BIO, P2892, DOI 10.1109/EMBC.2017.8037461
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Johnson KW, 2018, J AM COLL CARDIOL, V71, P2668, DOI 10.1016/j.jacc.2018.03.521
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Krizhevsky A., 2012, P ADV NEUR INF PROC, P1097
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   McCarthy J, 2006, AI MAG, V27, P12
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Niel O, 2019, AM J KIDNEY DIS, V74, P803, DOI 10.1053/j.ajkd.2019.05.020
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Roldan-Valadez E, 2019, IRISH J MED SCI, V188, P939, DOI 10.1007/s11845-018-1936-5
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Sato F, 2005, CANCER-AM CANCER SOC, V103, P1596, DOI 10.1002/cncr.20938
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Warnecke-Eberz U, 2010, PHARMACOGENOMICS, V11, P55, DOI [10.2217/pgs.09.137, 10.2217/PGS.09.137]
   Wong TY, 2020, OPHTHALMOLOGICA, V243, P9, DOI 10.1159/000502387
   Yang YJ, 2020, CLIN ENDOSC, V53, P387, DOI 10.5946/ce.2020.133
   Zahedi H., 2012, Journal of Medical Engineering & Technology, V36, P261, DOI 10.3109/03091902.2012.682112
   Zhou J, 2020, GASTROINTEST ENDOSC, V91, P428, DOI 10.1016/j.gie.2019.11.026
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 50
TC 0
Z9 0
U1 7
U2 10
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0025-7974
EI 1536-5964
J9 MEDICINE
JI Medicine (Baltimore)
PD NOV 25
PY 2022
VL 101
IS 47
DI 10.1097/MD.0000000000031931
PG 10
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 6W5AK
UT WOS:000895740900086
PM 36451438
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Hwang, M
   Qian, YC
   Wu, C
   Jiang, WC
   Wang, D
   Wei, JS
   Ding, KF
   Hwang, KS
AF Hwang, Maxwell
   Qian, Yucheng
   Wu, Cai
   Jiang, Wei-Cheng
   Wang, Da
   Wei, Jingsun
   Ding, Kefeng
   Hwang, Kao-Shing
TI A local region proposals approach to instance segmentation for
   intestinal polyp detection
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Image segmentation; Convolution neural network; Region proposal network;
   Polyps detection
AB This article designs a cascaded neural network to diagnose colonoscopic images automatically. With the limited number of labeled polyps masked in binary, the proposed detection network uses a hetero-encoder to map a colonoscopic image to an aggregated set of exemplified images as data argumentation to force the successive autoencoder to learn important features acting as a denoising autoencoder. In other words, the autoencoder denoises the transient images generated in the precedent hetero-encoder training process by auto-associating the ground truth and its variants. A hard attention model classifies the segmented image and applies a local region proposal network (RPN) to the generation and aggression of bounding boxes only on the segmented images to allow a more precise detection such that computations on bounding boxes with less information are avoided. The proposed system can outperform current complex state-of-art methods like faster-R-CNN from the experiments on endoscopic images.
C1 [Hwang, Maxwell] Northwestern Polytech Univ, Sch Microelect, Xian 710072, Peoples R China.
   [Qian, Yucheng; Wang, Da; Wei, Jingsun; Ding, Kefeng] Zhejiang Univ, Affiliated Hosp 2, Sch Med,Minist Educ, Dept Colorectal Surg & Oncol,Key Lab Canc Prevent, Hangzhou, Zhejiang, Peoples R China.
   [Wu, Cai] Zhejiang Univ, Affiliated Hosp 4, Sch Med, Dept Hematol, 1 Shangcheng Rd, Yiwu, Zhejiang, Peoples R China.
   [Jiang, Wei-Cheng] Tunghai Univ, Dept Elect Engn, Taichung, Taiwan.
   [Hwang, Kao-Shing] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
C3 Northwestern Polytechnical University; Zhejiang University; Zhejiang
   University; Tunghai University; National Sun Yat Sen University
RP Ding, KF (通讯作者)，Zhejiang Univ, Affiliated Hosp 2, Sch Med,Minist Educ, Dept Colorectal Surg & Oncol,Key Lab Canc Prevent, Hangzhou, Zhejiang, Peoples R China.
EM 11818090@zju.edu.cn; carl_hwang@msn.com
FU National Key R&D Program of China [2017YFC0908200]; Key Technology
   Research and Development Program of Zhejiang Province [2017C03017]; Key
   Project of Yiwu Science and Technology plan, China [20-3-067]
FX This study was funded by the National Key R&D Program of China
   (2017YFC0908200), the Key Technology Research and Development Program of
   Zhejiang Province (no. 2017C03017), and the Key Project of Yiwu Science
   and Technology plan, China. no. 20-3-067.
CR Al-Mnayyis A., 2020, INT J ELECT COMPUT E, V10, P4101
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   [Anonymous], 2017, ARXIV, Patent No. 171009829Cs
   Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bradski G., 2008, LEARNING OPENCV COMP
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Dai JF, 2016, ADV NEUR IN, V29
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hwang M, 2020, COMPUT MED IMAG GRAP, V84, DOI 10.1016/j.compmedimag.2020.101763
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mnih V, 2014, ADV NEUR IN, V27
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Phung VH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214500
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Zhao J., 2016, ARXIV
NR 26
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD MAY
PY 2023
VL 14
IS 5
BP 1591
EP 1603
DI 10.1007/s13042-022-01714-4
EA NOV 2022
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E4QJ0
UT WOS:000888679900001
DA 2023-08-21
ER

PT J
AU Karaman, A
   Karaboga, D
   Pacal, I
   Akay, B
   Basturk, A
   Nalbantoglu, U
   Coskun, S
   Sahin, O
AF Karaman, Ahmet
   Karaboga, Dervis
   Pacal, Ishak
   Akay, Bahriye
   Basturk, Alper
   Nalbantoglu, Ufuk
   Coskun, Seymanur
   Sahin, Omur
TI Hyper-parameter optimization of deep learning architectures using
   artificial bee colony (ABC) algorithm for high performance real-time
   automatic colorectal cancer (CRC) polyp detection
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Colorectal cancer; Deep learning; Hyper-parameter optimization;
   Artificial bee colony; Real-time polyp detection; YOLOv4
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Colorectal cancer (CRC) is one of the most common and malignant types of cancer worldwide. Colonoscopy, considered the gold standard for CRC screening, allows immediate removal of polyps, which are precursors to CRC. Many computer-aided diagnosis systems (CADs) have been proposed for automatic polyp detection. Most of these systems are based on traditional machine learning algorithms and their generalization ability, sensitivity and specificity are limited. On the other hand, with the widespread use of deep learning algorithms in medical image analysis and the successful results in the analysis of colonoscopy images, especially in the early and accurate detection of polyps, these problems are eliminated in recent years. In short, deep learning algorithms and applications have gained a critical role in CAD systems for real-time autonomous polyp detection. Here, we make significant improvements to object detection algorithms to improve the performance of CAD-based real-time polyp detection systems. We integrate the artificial bee colony algorithm (ABC) into the YOLO algorithm to optimize the hyper-parameters of YOLO-based algorithms. The proposed method can be easily integrated into all YOLO algorithms such as YOLOv3, YOLOv4, Scaled-YOLOv4, YOLOv5, YOLOR and YOLOv7. The proposed method improves the performance of the Scaled-YOLOv4 algorithm with an average of more than 3% increase in mAP and a more than 2% improvement in F1 value. In addition, the most comprehensive study is conducted by evaluating the performance of all existing models in the Scaled-YOLOv4 algorithm (YOLOv4s, YOLOv4m, YOLOV4-CSP, YOLOv4-P5, YOLOV4-P6 and YOLOv4-P7) on the novel SUN and PICCOLO polyp datasets. The proposed method is the first study for the optimization of YOLO-based algorithms in the literature and makes a significant contribution to the detection accuracy.
C1 [Karaman, Ahmet; Coskun, Seymanur] Acibadem Hosp, Dept Gastroenterol, Kayseri, Turkey.
   [Karaboga, Dervis; Akay, Bahriye; Basturk, Alper; Nalbantoglu, Ufuk; Sahin, Omur] Erciyes Univ, Engn Fac, Dept Comp Engn, Kayseri, Turkey.
   [Karaboga, Dervis; Pacal, Ishak; Akay, Bahriye; Basturk, Alper; Nalbantoglu, Ufuk; Sahin, Omur] Erciyes Univ, Artificial Intelligence & Big Data Applicat & Res, Kayseri, Turkey.
   [Pacal, Ishak] Igdir Univ, Engn Fac, Dept Comp Engn, Igdir, Turkey.
C3 Acibadem Hastaneleri; Erciyes University; Erciyes University; Igdir
   University
RP Pacal, I (通讯作者)，Erciyes Univ, Artificial Intelligence & Big Data Applicat & Res, Kayseri, Turkey.; Pacal, I (通讯作者)，Igdir Univ, Engn Fac, Dept Comp Engn, Igdir, Turkey.
EM Ishakpacal@gmail.com
RI Basturk, Alper/A-8953-2012; pacal, ishak/HJJ-1662-2023; Sahin,
   Omur/AAO-3107-2020
OI Basturk, Alper/0000-0001-5810-0643; Sahin, Omur/0000-0003-1213-7445;
   Orhan, Kaan/0000-0001-6768-0176
CR Akay B, 2022, ARTIF INTELL REV, V55, P829, DOI 10.1007/s10462-021-09992-0
   Ali M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081485
   [Anonymous], ALEXEYAB DARKNET YOL
   [Anonymous], WONGKINYIU SCALEDYOL
   Badem H, 2017, NEUROCOMPUTING, V266, P506, DOI 10.1016/j.neucom.2017.05.061
   Banharnsakun A, 2019, INT J MACH LEARN CYB, V10, P1301, DOI 10.1007/s13042-018-0811-z
   Bochkovskiy A., 2020, ARXIV E PRINTS, V2004, P10934, DOI 10.48550/arXiv.2004.10934
   Bora K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83788-8
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Durak S, 2021, MED BIOL ENG COMPUT, V59, P1563, DOI 10.1007/s11517-021-02398-8
   Erkan U, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03631-w
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hoang MC, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11101878
   Isik G, 2020, J FAC ENG ARCHIT GAZ, V35, P213, DOI 10.17341/gazimmfd.453677
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77
   Karaboga D, 2014, ARTIF INTELL REV, V42, P21, DOI 10.1007/s10462-012-9328-0
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kilicarslan S, 2022, NEURAL COMPUT APPL, V34, P13909, DOI 10.1007/s00521-022-07211-7
   Kilicarslan S, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102231
   Lee JN, 2022, J ELECTR ENG TECHNOL, V17, P3057, DOI 10.1007/s42835-022-01191-3
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Ozcan T, 2019, NEURAL COMPUT APPL, V31, P8955, DOI 10.1007/s00521-019-04427-y
   Ozkok FO, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103168
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pacal I, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104003
   Qian ZQ, 2022, IEEE SENS J, V22, P10841, DOI 10.1109/JSEN.2022.3170034
   Rawla P, 2019, GASTROENTEROL REV, V14, P89, DOI 10.5114/pg.2018.81072
   Reboiro-Jato A, 2022, CITATION NOGUEIRA RO, DOI [10.3390/diagnostics12040898, DOI 10.3390/DIAGNOSTICS12040898]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Garcia LS, 2021, AM J DANCE THER, V43, P3, DOI 10.1007/s10465-020-09339-2
   Schiele S, 2021, CANCERS, V13, DOI 10.3390/cancers13092074
   Souaidi M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12082030
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tamang LD, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210982
   Theodosi A, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01184-8
   Wan JJ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122264
   Wang C.-Y., 2021, YOU ONLY LEARN ONE R, P1
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang WCV, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133661
   Younas F, 2023, APPL INTELL, V53, P2410, DOI 10.1007/s10489-022-03689-9
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 53
TC 11
Z9 11
U1 16
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JUN
PY 2023
VL 53
IS 12
BP 15603
EP 15620
DI 10.1007/s10489-022-04299-1
EA NOV 2022
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I1FG3
UT WOS:000887886700001
PM 35543856
DA 2023-08-21
ER

PT J
AU Richter, R
   Bruns, J
   Obst, W
   Keitel-Anselmino, V
   Weigt, J
AF Richter, Rino
   Bruns, Johannes
   Obst, Wilfried
   Keitel-Anselmino, Verena
   Weigt, Jochen
TI Influence of artificial intelligence on the adenoma detection rate
   throughout the day
SO DIGESTIVE DISEASES
LA English
DT Article
ID COLONOSCOPY
AB Background: Artificial intelligence systems recently demonstrated an increase in polyp- and adenoma detection rate. Over the daytime the adenoma detection rate decreases as tiredness leads to a lack of attention. It is not clear if a polyp detection system with artificial intelligence leads to a constant adenoma detection over the day.Methods: We performed a database analysis of screening and surveillance colonoscopies with and without the use of AI. In both groups, patients were investigated with the same endoscopy equipment and by the same endoscopists. Only patients with good bowel preparation (BBPS > 6) were included. We correlated the daytime, the investigational time, day of the week and the adenoma and polyp detection. Results: A total of 303 colonoscopies were analyzed. In the AI+ group 163 endoscopies and in the AI- group 140 procedures were included. In both groups the total adenoma detection rate was equal (AI+ 0.39 vs AI- 0.43). The adenoma detection rate throughout the day had a significant decreasing trend in the group without the use of AI (p=0.015) whereas this trend was not present in the investigations that have been performed with AI (p=0.65). The duration of investigation did not show a significant difference between the groups (8.9 minutes in both groups). No relevant effect was noticed in adenoma detection between single days of the working week with or without the use of AI.Conclusion: AI helps to overcome the decay in adenoma detection over the daytime. This may be attributed to a constant awareness caused by the use of the AI system.
C1 [Richter, Rino; Bruns, Johannes; Obst, Wilfried; Keitel-Anselmino, Verena; Weigt, Jochen] Otto v Guericke Univ Magdeburg, Dept Gastroenterol Hepatol & Infect Dis, Magdeburg, Germany.
   [Weigt, Jochen] Otto v Guericke Univ Magdeburg, Dept Gastroenterol Hepatol & Infect Dis, Leipziger Str 44, D-39120 Magdeburg, Germany.
C3 Otto von Guericke University; Otto von Guericke University
RP Weigt, J (通讯作者)，Otto v Guericke Univ Magdeburg, Dept Gastroenterol Hepatol & Infect Dis, Leipziger Str 44, D-39120 Magdeburg, Germany.
EM Jochen.weigt@med.ovgu.de
OI Weigt, Jochen/0000-0002-3334-2168
CR [Anonymous], KREBS DARMKREBS
   Chan MY, 2009, CLIN GASTROENTEROL H, V7, P1217, DOI 10.1016/j.cgh.2009.07.013
   Gralnek IM, 2015, DIGEST ENDOSC, V27, P223, DOI 10.1111/den.12382
   Jaho F, 2021, ANN GASTROENTEROL, V34, P815, DOI 10.20524/aog.2021.0668
   Liu AH, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000021278
   Pan H, 2022, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.775604
   Pu LZCT, 2019, J GASTROEN HEPATOL, V34, P899, DOI 10.1111/jgh.14566
   Rebhun J, 2022, J CLIN GASTROENTEROL, V56, P764, DOI 10.1097/MCG.0000000000001599
   Sanaka MR, 2009, AM J GASTROENTEROL, V104, P1659, DOI 10.1038/ajg.2009.249
   Schmiegel W, 2008, Z GASTROENTEROL, V46, P799, DOI 10.1055/s-2008-1027726
   Teng TY, 2016, SURG ENDOSC, V30, P1796, DOI 10.1007/s00464-015-4448-7
   Tribonias G, 2010, COLORECTAL DIS, V12, pE260, DOI 10.1111/j.1463-1318.2009.02145.x
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   Wu JQ, 2018, DIGEST LIVER DIS, V50, P661, DOI 10.1016/j.dld.2018.03.035
NR 15
TC 0
Z9 0
U1 0
U2 0
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0257-2753
EI 1421-9875
J9 DIGEST DIS
JI Dig. Dis.
PD JUL
PY 2023
VL 41
IS 4
BP 615
EP 619
DI 10.1159/000528163
EA NOV 2022
PG 5
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA L1MF7
UT WOS:000890031900001
PM 36404713
OA hybrid
DA 2023-08-21
ER

PT J
AU Sharma, P
   Das, D
   Gautam, A
   Balabantaray, BK
AF Sharma, Pallabi
   Das, Dipankar
   Gautam, Anmol
   Balabantaray, Bunil Kumar
TI LPNet: A lightweight CNN with discrete wavelet pooling strategies for
   colon polyps classification
SO INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE deep learning; classification; CNN; polyps; colonoscopy
ID DIAGNOSIS
AB The traditional process of disease diagnosis from medical images follows a manual process, which is tedious and arduous. A computer-aided diagnosis (CADs) system can work as an assistive tool to improve the diagnosis process. In this pursuit, this article introduces a unique architecture LPNet for classifying colon polyps from the colonoscopy video frames. Colon polyps are abnormal growth of cells in the colon wall. Over time, untreated colon polyps may cause colorectal cancer. Different convolutional neural networks (CNNs) based systems have been developed in recent years. However, CNN uses pooling to reduce the number of parameters and expand the receptive field. On the other hand, pooling results in data loss and is deleterious to subsequent processes. Pooling strategies based on discrete wavelet operations have been proposed in our architecture as a solution to this problem, with the promise of achieving a better trade-off between receptive field size and computing efficiency. The overall performance of this model is superior to the others, according to experimental results on a colonoscopy dataset. LPNet with bio-orthogonal wavelet achieved the highest performance with an accuracy of 93.55%. It outperforms the other state-of-the-art (SOTA) CNN models for the polyps classification task, and it is lightweight in terms of the number of learnable parameters compared with them, making the model easily deployable in edge devices.
C1 [Sharma, Pallabi; Das, Dipankar; Gautam, Anmol; Balabantaray, Bunil Kumar] Natl Inst Technol Meghalaya, Dept Comp Sci & Engn, Shillong 793003, Meghalaya, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Meghalaya
RP Balabantaray, BK (通讯作者)，Natl Inst Technol Meghalaya, Dept Comp Sci & Engn, Shillong 793003, Meghalaya, India.
EM bunil@nitm.ac.in
RI ; Balabantaray, Bunil Kumar/M-9711-2013
OI SHARMA, PALLABI/0000-0003-3447-9251; Balabantaray, Bunil
   Kumar/0000-0002-2769-7122
FU NVIDIA Higher Education and Research Team; NVIDIA Academic Hardware
   Grant Program
FX The authors would like to thank NVIDIA Higher Education and Research
   Team for supporting the work. We utilized the resources supported by the
   NVIDIA Academic Hardware Grant Program. We thank all the members in
   Computer Vision and Machine learning Lab, NIT Meghalaya for the helpful
   suggestion.
CR Afify HM, 2021, INT J IMAG SYST TECH, V31, P1741, DOI 10.1002/ima.22568
   Agarap A.F., 2018, DEEP LEARNING USING, DOI [10.48550/arXiv.1803.08375, DOI 10.48550/ARXIV.1803.08375]
   Akbari M, 2018, IEEE ENG MED BIO, P65, DOI 10.1109/EMBC.2018.8512226
   Arora R., 2016, UNDERSTANDING DEEP N
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Daneshmand H., 2020, ARXIV200301652, V1050, P3
   Daneshmand H., 2020, ADV NEURAL INF PROCE, V33, P18387
   Gautam Anupam, 2022, 2022 2nd International Conference on Innovative Sustainable Computational Technologies (CISCT), P1, DOI 10.1109/CISCT55310.2022.10046570
   Geirhos Robert, 2018, ARXIV
   Ghosh SK, 2021, INT J IMAG SYST TECH, V31, P1486, DOI 10.1002/ima.22551
   Glorot X., 2010, PROC 13 INT C ARTIFI, V9, P249, DOI DOI 10.1177/1753193409103364.
   Graham S, 2019, MED IMAGE ANAL, V52, P199, DOI 10.1016/j.media.2018.12.001
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   Hermann K. L., 2020, ADV NEURAL INF PROCE, V33, P19000, DOI DOI 10.48550/ARXIV.1911.09071
   Howard A.G., 2017, ARXIV
   Huang G., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S., 2015, PROC INT C MACH LEAR, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Kingma D., 2015, ARXIV
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Liansheng Wang, 2020, Pattern Recognition Letters, V135, P244, DOI 10.1016/j.patrec.2020.04.008
   Lubana Ekdeep S., 2021, ADV NEURAL INF PROCE, V34, P4778
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Mostafiz R, 2020, INT J IMAG SYST TECH, V30, P224, DOI 10.1002/ima.22350
   Nair V., 2010, P 27 INT C MACHINE L, P807, DOI DOI 10.5555/3104322.3104425
   Paoletti ME., 2021, IEEE T GEOSCI ELECT, V60, P1
   Paoletti ME, 2020, IEEE ACCESS, V8, P179575, DOI 10.1109/ACCESS.2020.3027776
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Patrick MK, 2022, J KING SAUD UNIV-COM, V34, P1295, DOI 10.1016/j.jksuci.2019.09.014
   Romain O, 2013, IEEE 13 INT C BIOINF, P1
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sharma P, 2022, IEEE T BIO-MED ENG
   Sharma P, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.844391
   Sharma P, 2020, ONCOLOGIE, V22, P129, DOI 10.32604/oncologie.2020.013870
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sundaram PS, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1153-9
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vuong TLT, 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC)
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 50
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-9457
EI 1098-1098
J9 INT J IMAG SYST TECH
JI Int. J. Imaging Syst. Technol.
PD MAR
PY 2023
VL 33
IS 2
BP 495
EP 510
DI 10.1002/ima.22825
EA NOV 2022
PG 16
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA 9O0AE
UT WOS:000886169600001
DA 2023-08-21
ER

PT J
AU Nisha, JS
   Gopi, VP
AF Nisha, J. S.
   Gopi, Varun Palakuzhiyil
TI Colorectal polyp detection in colonoscopy videos using image enhancement
   and discrete orthonormal stockwell transform
SO SADHANA-ACADEMY PROCEEDINGS IN ENGINEERING SCIENCES
LA English
DT Article
DE Colonoscopy; discrete orthonormal stockwell transform; support vector
   machine; colorectal cancer; non-maximum suppression algorithm
ID VALIDATION; DIAGNOSIS
AB Computer-aided detection based on Machine Learning (ML) techniques is increasingly used to detect early-stage colorectal polyps from colonoscopy images. This study presents an efficient ML algorithm that analyses colonoscopy images and accurately detects polyps for reliable diagnosis of the early stages of Colo-Rectal Cancer (CRC). The proposed approach consists of mainly image enhancement, which enhances the low illumination colonoscopy images, followed by feature extraction using Discrete Orthonormal Stockwell Transform (DOST) and classification by a Support Vector Machine (SVM) classifier. We present an efficient image enhancement algorithm that highlights the clinically significant features in the colonoscopy image and the DOST feature extraction method to discriminate between the polyp area and non-polyp region in the colonoscopy data. The proposed method has been trained using the publicly available databases CVC ClinicDB and tested using ETIS Larib and CVC ColonDB. A sliding window with NMS-based post-processing is used in the selection of polyps from the test images. The performance measures are found in terms of precision (93.76%), recall (92.71%), F1 score (93.23%) and F2 score (93.54%) for CVC ColonDB database and precision (80.97%), recall (93.12%), F1 score (86.62%) and F2 score (83.13%) for the ETIS Larib database. Comparison with the existing method shows that the proposed approach surpasses the existing one in terms of precision, recall, F1-score, F2-score in the CVC ColonDB, and in terms of recall, F1-score in the Etis Larib database. This method would help doctors with timely evaluation and analysis of anomalies from colonoscopy data, which would help in the early planning of preventive or therapeutic protocols.
C1 [Nisha, J. S.; Gopi, Varun Palakuzhiyil] Natl Inst Technol, Trichy, Tamilnadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Gopi, VP (通讯作者)，Natl Inst Technol, Trichy, Tamilnadu, India.
EM varun@nitt.edu
RI P Gopi, Varun/S-3943-2019
OI P Gopi, Varun/0000-0001-5593-3949; J S, Nisha/0000-0002-9284-6729
CR Akbar B, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1735, DOI 10.1109/ECS.2015.7124883
   Akbari M, 2018, IEEE ENG MED BIO, P65, DOI 10.1109/EMBC.2018.8512226
   Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Behera B, 2019, INT CONF ADV COMPU, P220, DOI [10.1109/icoac48765.2019.246843, 10.1109/ICoAC48765.2019.246843]
   BENTLEY PM, 1994, ELECTRON COMMUN ENG, V6, P175, DOI 10.1049/ecej:19940401
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Boroff ES, 2017, GASTROENT RES PRACT, V2017, DOI 10.1155/2017/7207595
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491
   Cheng DC, 2011, BIOMED ENG-APP BAS C, V23, P357, DOI 10.4015/S1016237211002761
   Daqi G., 2007, IJCNN, P2971, DOI 10.1109/IJCNN.2007.4371433
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Deepa V, 2019, IET IMAGE PROCESS, V13, P1341, DOI 10.1049/iet-ipr.2018.5672
   Drabycz S, 2009, J DIGIT IMAGING, V22, P696, DOI 10.1007/s10278-008-9138-8
   Durak L, 2003, IEEE T SIGNAL PROCES, V51, P1231, DOI 10.1109/TSP.2003.810293
   Figueiredo IN, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102035
   Gibson PC, 2006, J FOURIER ANAL APPL, V12, P713, DOI 10.1007/s00041-006-6087-9
   Goyal H, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103313
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hariharan M, 2014, COMPUT ELECTR ENG, V40, P1741, DOI 10.1016/j.compeleceng.2014.01.010
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   Hazewinkel Y, 2011, NAT REV GASTRO HEPAT, V8, P554, DOI 10.1038/nrgastro.2011.141
   Kaur Taranjit, 2019, 2019 International Conference on Information Technology (ICIT), P94, DOI 10.1109/ICIT48102.2019.00023
   Kim M., 2020, BIOMEDICAL INFORM TE, P239, DOI [10.1016/b978-0-12-816034-3.00008-0, DOI 10.1016/B978-0-12-816034-3.00008-0]
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Leon K, 2006, FOOD RES INT, V39, P1084, DOI 10.1016/j.foodres.2006.03.006
   Lieberman D, 2005, GASTROINTEST ENDOSC, V61, P392, DOI 10.1016/S0016-5107(05)00133-1
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   McAllister P, 2018, COMPUT BIOL MED, V95, P217, DOI 10.1016/j.compbiomed.2018.02.008
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Palanisamy G, 2019, SIGNAL IMAGE VIDEO P, V13, P719, DOI 10.1007/s11760-018-1401-y
   Park S., 2015, POLYP DETECTION COLO
   Rahim T, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102654
   Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sahu Smriti, 2012, INT J ELECTR COMPUT, V2, P792, DOI DOI 10.11591/IJECE.V2I6.1513
   Salem N., 2019, PROCEDIA COMPUT SCI, V163, P300, DOI [10.1016/j.procs.2019.12.112, DOI 10.1016/J.PROCS.2019.12.112]
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Soleimani M, 2021, IEEE T NEUR SYS REH, V29, P163, DOI 10.1109/TNSRE.2020.3040627
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Stockwell RG, 2007, DIGIT SIGNAL PROCESS, V17, P371, DOI 10.1016/j.dsp.2006.04.006
   Taha B, 2017, IEEE IMAGE PROC, P2060, DOI 10.1109/ICIP.2017.8296644
   Tajbakhsh N, 2017, ADV COMPUT VIS PATT, P181, DOI 10.1007/978-3-319-42999-1_11
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Wang C, 2019, IEEE ACCESS, V7, P146533, DOI 10.1109/ACCESS.2019.2946000
   Wang DW, 2018, ACTA PHYS SIN-CH ED, V67, DOI 10.7498/aps.67.20181288
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 58
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 0256-2499
EI 0973-7677
J9 SADHANA-ACAD P ENG S
JI Sadhana-Acad. Proc. Eng. Sci.
PD NOV 12
PY 2022
VL 47
IS 4
AR 234
DI 10.1007/s12046-022-01970-8
PG 16
WC Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 6D0HP
UT WOS:000882383500002
DA 2023-08-21
ER

PT J
AU Gokkan, O
   Kuntalp, M
AF Gokkan, Ozan
   Kuntalp, Mehmet
TI A new imbalance-aware loss function to be used in a deep neural network
   for colorectal polyp segmentation
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Colorectal cancer; Polyp segmentation; Deep residual neural network;
   Class imbalance; Loss function
ID COLONOSCOPY; CLASSIFICATION
AB Colorectal cancers may occur in colon region of human body because of late detection of polyps. Therefore, colonoscopists often use colonoscopy device to view the entire colon in their routine practice to remove polyps by excisional biopsy. The aim of this study is to develop a new imbalance-aware loss function, i.e., omnicomprehensive loss, to be used in deep neural networks to overcome both imbalanced dataset and the vanishing gradient problem in identifying the related regions of a polyp. Another reason of developing a new loss function is to be able to produce a more comprehensive one that has evaluation capabilities of region-based, shape-aware, and pixel-wise distribution loss approaches at once. To measure the performance of the new loss function, two scenarios have been conducted. First, an 18-layer residual network as backbone with UNet as the decoder is implemented. Second, a 34-layer residual network as the encoder and a UNet as the decoder is designed. For both scenarios, the results of using popular imbalance-aware losses are compared with those of using our proposed new loss function. During training and 5-fold cross validation steps, multiple publicly available datasets are used. In addition to original data in these datasets, their augmented versions are also created by flipping, scaling, rotating and contrast-limited adaptive histogram equalization operations. As a result, our proposed new custom loss function produced the best performance metrics compared with the popular loss functions.
C1 [Gokkan, Ozan] Ege Univ, Grad Sch Nat & Appl Sci, Dept Biomed Technol, TR-35040 Bornova, Turkey.
   [Kuntalp, Mehmet] Dokuz Eylul Univ, Grad Sch Nat & Appl Sci, Dept Biomed Technol, TR-35390 Izmir, Turkey.
C3 Ege University; Dokuz Eylul University
RP Gokkan, O (通讯作者)，Ege Univ, Grad Sch Nat & Appl Sci, TR-35040 Bornova, Turkey.
EM 91180000675@ogrenei.ege.edu.tr
CR Abraham N., 2019, IEEE 16 INT S BIOMED
   ATTOUCH H, 1991, ANN MAT PUR APPL, V160, P303, DOI 10.1007/BF01764131
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bressler B, 2007, GASTROENTEROLOGY, V132, P96, DOI 10.1053/j.gastro.2006.10.027
   Cassinotti A, 2020, ENDOSC INT OPEN, V08, pE1414, DOI 10.1055/a-1165-0169
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Eelbode T, 2020, IEEE T MED IMAGING, V39, P3679, DOI 10.1109/TMI.2020.3002417
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Hicks SA, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09954-8
   Huang Y., 2022, MICCAI C
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P115, DOI 10.1109/cibcb48159.2020.9277638
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Li WS, 2022, KNOWL-BASED SYST, V247, DOI 10.1016/j.knosys.2022.108824
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, V1
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Loshchilov I., 2019, INT C LEARN REPR
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Mehrotra A, 2018, GASTROINTEST ENDOSC, V87, P778, DOI 10.1016/j.gie.2017.08.023
   Meijer Jose A., 2019, P REFERENCE ML C BEL
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Park KB, 2022, J COMPUT DES ENG, V9, P616, DOI 10.1093/jcde/qwac018
   Ribera J, 2019, PROC CVPR IEEE, P6472, DOI 10.1109/CVPR.2019.00664
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salehi SSM, 2017, LECT NOTES COMPUT SC, V10541, P379, DOI 10.1007/978-3-319-67389-9_44
   Ta N, 2022, MULTIMEDIA SYST, DOI 10.1007/s00530-022-00900-2
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   van Doorn SC, 2015, AM J GASTROENTEROL, V110, P180, DOI 10.1038/ajg.2014.326
   Wen HG, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22160-9
   Yeung M, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102026
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 35
TC 3
Z9 3
U1 2
U2 3
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD DEC
PY 2022
VL 151
AR 106205
DI 10.1016/j.compbiomed.2022.106205
EA NOV 2022
PN A
PG 13
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 7C9SB
UT WOS:000900142700006
PM 36370582
DA 2023-08-21
ER

PT J
AU Wu, C
   Long, C
   Li, SJ
   Yang, JJ
   Jiang, FG
   Zhou, R
AF Wu, Cong
   Long, Cheng
   Li, Shijun
   Yang, Junjie
   Jiang, Fagang
   Zhou, Ran
TI MSRAformer: Multiscale spatial reverse attention network for polyp
   segmentation
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp segmentation; Machine learning; Multiscale; Attention mechanism
AB Colon polyp is an important reference basis in the diagnosis of colorectal cancer(CRC). In routine diagnosis, the polyp area is segmented from the colorectal enteroscopy image, and the obtained pathological information is used to assist in the diagnosis of the disease and surgery. It is always a challenging task for accurate segmentation of polyps in colonoscopy images. There are great differences in shape, size, color and texture of the same type of polyps, and it is difficult to distinguish the polyp region from the mucosal boundary. In recent years, convolutional neural network(CNN) has achieved some results in the task of medical image segmentation. However, CNNs focus on the extraction of local features and be short of the extracting ability of global feature information. This paper presents a Multiscale Spatial Reverse Attention Network called MSRAformer with high performance in medical segmentation, which adopts the Swin Transformer encoder with pyramid structure to extract the features of four different stages, and extracts the multi-scale feature information through the multi-scale channel attention module, which enhances the global feature extraction ability and generalization of the network, and preliminarily aggregates a pre-segmentation result. This paper proposes a spatial reverse attention mechanism module to gradually supplement the edge structure and detail information of the polyp region. Extensive experiments on MSRAformer proved that the segmentation effect on the colonoscopy polyp dataset is better than most state-of-the-art(SOTA) medical image segmentation methods, with better generalization performance. Reference implementation of MSRAformer is available at https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/ChengLong1222/MSRAformer-main.
C1 [Wu, Cong; Long, Cheng; Li, Shijun; Zhou, Ran] Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
   [Yang, Junjie; Jiang, Fagang] Huazhong Univ Sci & Technol, Union Hosp, Tongji Med Coll, Wuhan, Peoples R China.
C3 Hubei University of Technology; Huazhong University of Science &
   Technology
RP Wu, C; Long, C (通讯作者)，Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
EM oidipous@hbut.edu.cn; longcheng.ninoling@gmail.com
RI 成, 龙/HPB-9160-2023
OI li, shijun/0000-0003-1360-1617; Wu, Cong/0000-0002-6670-8154
CR Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bi XL, 2019, IEEE COMPUT SOC CONF, P30, DOI 10.1109/CVPRW.2019.00010
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chen J., 2021, ARXIV
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Dai Y, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081384
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan DP, 2018, Arxiv, DOI arXiv:1805.10421
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C.-H., 2021, ARXIV
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lou AE, 2022, Arxiv, DOI arXiv:2108.07368
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Naseer M. M., 2021, ADV NEURAL INFORM PR, P23296, DOI DOI 10.48550/ARXIV.2105.10497
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Peng ZL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P357, DOI 10.1109/ICCV48922.2021.00042
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Shan T, 2021, IEEE ACCESS, V9, P160926, DOI 10.1109/ACCESS.2021.3132293
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Nguyen TC, 2021, LECT NOTES COMPUT SC, V12901, P633, DOI 10.1007/978-3-030-87193-2_60
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Tomar NK, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3159394
   Valanarasu JMJ, 2021, LECT NOTES COMPUT SC, V12901, P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A., 2017, P ADV NEUR INF PROC, P5999
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang JF, 2022, Arxiv, DOI [arXiv:2203.03635, 10.48550/ARXIV.2203.03635]
   Wu C., 2021, INT C NEUR INF PROC, p345?356
   Wu C, 2019, INT CONF COMP SCI ED, P642, DOI 10.1109/ICCSE.2019.8845397
   Wu C, 2019, IOP CONF SER-MAT SCI, V533, DOI 10.1088/1757-899X/533/1/012053
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 40
TC 1
Z9 1
U1 15
U2 18
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD DEC
PY 2022
VL 151
AR 106274
DI 10.1016/j.compbiomed.2022.106274
EA NOV 2022
PN A
PG 8
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 7C9SB
UT WOS:000900142700003
PM 36375412
DA 2023-08-21
ER

PT J
AU Murugesan, M
   Arieth, RM
   Balraj, S
   Nirmala, R
AF Murugesan, Malathi
   Arieth, R. Madonna
   Balraj, Shankarlal
   Nirmala, R.
TI Colon cancer stage detection in colonoscopy images using YOLOv3 MSF deep
   learning architecture
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
ID INVASIVE COLORECTAL-CARCINOMA; OPTICAL DIAGNOSIS; POLYP DETECTION;
   CLASSIFICATION; NETWORKS
AB Colo-Rectal Cancer (CRC) stood witnessed as the major cause of deaths worldwide, especially in men. But the early detection and removal of polyps can reduce the death rate to a considerable extent. The various stages of colon cancer using the YOLOv3 Multi-Scale Framework (YOLOv3-MSF) have been studied here in this context. Colonoscopy is an examination method to detect changes in the rectum by inserting a long flexible tube into the rectum. For screening colon cancer, gastroenterologist often refers to the pathological images of colonoscopy for diagnosis. In recent decades, various machine learning algorithms are used for diagnosis to get practical and reliable results. More often, the stages of colon cancer can be inspected by the Tumor Length (TL). In this study, the polyps are segmented and allowed to measure the TL value by assessing polyp length (P-len) and polyp width (P-wid). The various stages of colon cancer have been ascertained based on the maximum length between the P(len )and P-wid. Our research uses the single-stage YOLOv3 object detection model to locate and classify the various stages based on the TL value. It outputs the class probability and position coordinates of each image by enhancing accuracy and robustness. At the outset, during preprocessing to address the specific problems like reduced contrast, blurred images and noisy data, the proposed model defines a data augmentation with a jitter value of 0.3 to avoid overfitting. Next, for detecting and annotating various stages of colon cancer, YOLOv3-MSF deep learning architecture with multiscale detection layers used here. By adopting transfer learning, we used YOLOv3 in our work. It chooses the anchor boxes using the K-Medoids algorithm during object detection in the training stage based on the ResNet network structure of YOLOv3. Finally, additional layers such as fully connected layer are embedded into the existing architecture. we used the CVC colonDB database to train and evaluate the fully connected layer during experiments. To analyze the performance of the proposed system, we compare our model with the state of art object detection model. Experimental results show that the proposed model outperforms existing systems on peak to accuracy, precision rate, recall rate, and f-measures.
C1 [Murugesan, Malathi] EGS Pillay Engn Coll, Dept Biomed Engn, Nagapattinam 611002, Tamil Nadu, India.
   [Arieth, R. Madonna] Sreenivasa Inst Technol & Management Studies SITAM, Dept CSE AI & ML, Chittoor, Andra Pradesh, India.
   [Balraj, Shankarlal] Perunthalaivar Kamarajar Inst Engn & Technol, Dept ECE, Karaikal 609603, Puducherry, India.
   [Nirmala, R.] Vivekanandha Coll Engn Women Autonomous, Namakkal 637205, Tamilnadu, India.
RP Murugesan, M (通讯作者)，EGS Pillay Engn Coll, Dept Biomed Engn, Nagapattinam 611002, Tamil Nadu, India.
EM m_malathi123@rediffmail.com
OI , B. Shankarlal/0000-0002-5159-1563
CR Attia A, 2018, ARXIV
   Azimi SM, 2021, INT C PATT RECOG, P6920, DOI 10.1109/ICPR48806.2021.9412353
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Benkaddour Mohammed Kamel, 2021, 2020 2nd International Workshop on Human-Centric Smart Environments for Health and Well-being (IHSH), P215, DOI 10.1109/IHSH51661.2021.9378708
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Boikov A, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13071176
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Chen XZ, 2017, Arxiv, DOI arXiv:1611.07759
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Fu CY, 2017, DSSD DECONVOLUTIONAL, DOI DOI 10.48550/ARXIV.1701.06659
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Gono K, 2004, OPT LETT, V29, P971, DOI 10.1364/OL.29.000971
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hisabe T, 2018, ENDOSC INT OPEN, V6, pE156, DOI 10.1055/s-0043-121881
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Iwatate M, 2015, ENDOSC INT OPEN, V3, pE140, DOI 10.1055/s-0034-1391362
   Juneja A., 2021, J INFO TECH MANAGE, V13, P62
   Kitajima K, 2004, J GASTROENTEROL, V39, P534, DOI 10.1007/s00535-004-1339-4
   Kronborg O, 2004, ENDOSCOPY, V36, P3
   Lakshminarayanan K., 2021, DEEP LEARNING BASED
   Li P, 2005, PROC CVPR IEEE, P670
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu L., 2019, ARXIV, DOI [DOI 10.48550/ARXIV.1809.02165, DOI 10.1007/S11263-019-01247-4]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Lan PN, 2021, LECT NOTES COMPUT SC, V13018, P15, DOI 10.1007/978-3-030-90436-4_2
   Ramanujam E, 2021, IEEE SENS J, V21, P13029, DOI 10.1109/JSEN.2021.3069927
   REDMON J, 2016, PROC CVPR IEEE, P779, DOI DOI 10.1109/CVPR.2016.91
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Schoneveld L, 2021, PATTERN RECOGN LETT, V146, P1, DOI 10.1016/j.patrec.2021.03.007
   Shen JQ, 2021, IET IMAGE PROCESS, V15, P479, DOI 10.1049/ipr2.12038
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Stewart B. W., 2003, World Cancer Report
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   TANAKA S, 1995, J GASTROENTEROL, V30, P710, DOI 10.1007/BF02349636
   Nguyen-Meidine LT, 2018, Arxiv, DOI arXiv:1809.03336
   Ucar A, 2017, SIMUL-T SOC MOD SIM, V93, P759, DOI 10.1177/0037549717709932
   Wang L, 2017, Arxiv, DOI arXiv:1702.00254
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Watanabe T, 2018, INT J CLIN ONCOL, V23, P1, DOI 10.1007/s10147-017-1101-6
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yu Ruichi, 2018, Arxiv, DOI arXiv:1801.02031
   Zhang HJ, 2020, NEURAL COMPUT APPL, V32, P4519, DOI [10.1007/s00521-018-3691-y, 10.1007/s00521-018-3579-x]
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhou Y, 2016, Arxiv, DOI arXiv:1607.04564
NR 56
TC 2
Z9 2
U1 2
U2 3
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD FEB
PY 2023
VL 80
AR 104283
DI 10.1016/j.bspc.2022.104283
EA NOV 2022
PN 2
PG 8
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 6P8BK
UT WOS:000891151000008
DA 2023-08-21
ER

PT J
AU Zhou, JX
   Yang, Z
   Xi, DH
   Dai, SJ
   Feng, ZQ
   Li, JY
   Xu, W
   Wang, H
AF Zhou, Jun-Xiao
   Yang, Zhan
   Xi, Ding-Hao
   Dai, Shou-Jun
   Feng, Zhi-Qiang
   Li, Jun-Yan
   Xu, Wei
   Wang, Hong
TI Enhanced segmentation of gastrointestinal polyps from capsule endoscopy
   images with artifacts using ensemble learning
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Artifacts; Capsule endoscopy; Polyps; Ensemble learning; Segmentation;
   Robustness
ID COLONOSCOPY; CANCER
AB BACKGROUND Endoscopy artifacts are widespread in real capsule endoscopy (CE) images but not in high-quality standard datasets. AIM To improve the segmentation performance of polyps from CE images with artifacts based on ensemble learning. METHODS We collected 277 polyp images with CE artifacts from 5760 h of videos from 480 patients at Guangzhou First People's Hospital from January 2016 to December 2019. Two public high-quality standard external datasets were retrieved and used for the comparison experiments. For each dataset, we randomly segmented the data into training, validation, and testing sets for model training, selection, and testing. We compared the performance of the base models and the ensemble model in segmenting polyps from images with artifacts. RESULTS The performance of the semantic segmentation model was affected by artifacts in the sample images, which also affected the results of polyp detection by CE using a single model. The evaluation based on real datasets with artifacts and standard datasets showed that the ensemble model of all state-of-the-art models performed better than the best corresponding base learner on the real dataset with artifacts. Compared with the corresponding optimal base learners, the intersection over union (IoU) and dice of the ensemble learning model increased to different degrees, ranging from 0.08% to 7.01% and 0.61% to 4.93%, respectively. Moreover, in the standard datasets without artifacts, most of the ensemble models were slightly better than the base learner, as demonstrated by the IoU and dice increases ranging from -0.28% to 1.20% and -0.61% to 0.76%, respectively. CONCLUSION Ensemble learning can improve the segmentation accuracy of polyps from CE images with artifacts. Our results demonstrated an improvement in the detection rate of polyps with interference from artifacts.
C1 [Zhou, Jun-Xiao; Dai, Shou-Jun; Feng, Zhi-Qiang; Li, Jun-Yan; Wang, Hong] Guangzhou First Peoples Hosp, Dept Gastroenterol & Hepatol, 1 Panfu Rd, Guangzhou 510180, Guangdong, Peoples R China.
   [Yang, Zhan; Xi, Ding-Hao; Xu, Wei] Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.
C3 South China University of Technology; Renmin University of China
RP Wang, H (通讯作者)，Guangzhou First Peoples Hosp, Dept Gastroenterol & Hepatol, 1 Panfu Rd, Guangzhou 510180, Guangdong, Peoples R China.
EM wong.hong@163.com
RI Zhou, Junxiao/GZA-6013-2022
CR Abdelrahim M, 2022, GUT, V71, P7, DOI 10.1136/gutjnl-2021-324510
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brooker J, 2007, GASTROINTEST ENDOSC, V66, P820, DOI 10.1016/j.gie.2007.05.024
   Cai LL, 2021, IEEE T IMAGE PROCESS, V30, P8702, DOI 10.1109/TIP.2021.3120041
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Ertem FU, 2021, AM J GASTROENTEROL, V116, P1579, DOI 10.14309/ajg.0000000000001106
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Gao H., 2017, ICLR 2017 P 5 INT C
   Grovik E, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00398-4
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Huang C.-H., 2021, ARXIV
   Huang TY, 2021, J CHIN MED ASSOC, V84, P678, DOI 10.1097/JCMA.0000000000000559
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jiang Z, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab411
   Klang E, 2021, J CROHNS COLITIS, V15, P749, DOI 10.1093/ecco-jcc/jjaa234
   Li CC, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-99984-5
   Li L, 2021, IEEE J BIOMED HEALTH, V25, P1646, DOI 10.1109/JBHI.2020.3028243
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Lin HN, 2021, MED PHYS, V48, P7864, DOI 10.1002/mp.15322
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Melson J, 2021, GASTROINTEST ENDOSC, V93, P784, DOI 10.1016/j.gie.2020.12.001
   Muller D., 2022, PREPRINT
   Namikawa K, 2020, EXPERT REV GASTROENT, V14, P689, DOI 10.1080/17474124.2020.1779058
   Nguyen LH, 2020, GASTROENTEROLOGY, V158, P291, DOI 10.1053/j.gastro.2019.08.059
   Paul A, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101911
   Pennazio M, 2006, ENDOSCOPY, V38, P1079, DOI 10.1055/s-2006-944854
   Pennazio Marco, 2017, Gastrointest Endosc Clin N Am, V27, P29, DOI 10.1016/j.giec.2016.08.003
   Shi LT, 2022, FRONT BIOENG BIOTECH, V10, DOI 10.3389/fbioe.2022.799541
   Strauss T, 2018, Arxiv, DOI arXiv:1709.03423
   Trasolini R, 2021, DIGEST ENDOSC, V33, P290, DOI 10.1111/den.13896
   Van Gossum A, 2009, NEW ENGL J MED, V361, P264, DOI 10.1056/NEJMoa0806347
   Wang WJ, 2020, WORLD J GASTROENTERO, V26, P614, DOI 10.3748/wjg.v26.i6.614
   Xia CF, 2022, CHINESE MED J-PEKING, V135, P584, DOI 10.1097/CM9.0000000000002108
   Yao Y, 2021, BIOMED RES INT-UK, V2021, DOI 10.1155/2021/6683931
   Zhou JX, 2021, GUT, V70, pA60, DOI 10.1136/gutjnl-2021-IDDF.59
NR 39
TC 0
Z9 0
U1 3
U2 4
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD NOV 7
PY 2022
VL 28
IS 41
BP 5931
EP 5943
DI 10.3748/wjg.v28.i41.5931
PG 13
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 6J2WD
UT WOS:000886686800003
PM 36405108
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Parkash, O
   Siddiqui, ATS
   Jiwani, U
   Rind, F
   Padhani, ZA
   Rizvi, A
   Hoodbhoy, Z
   Das, JK
AF Parkash, Om
   Siddiqui, Asra Tus Saleha
   Jiwani, Uswa
   Rind, Fahad
   Padhani, Zahra Ali
   Rizvi, Arjumand
   Hoodbhoy, Zahra
   Das, Jai K.
TI Diagnostic accuracy of artificial intelligence for detecting
   gastrointestinal luminal pathologies: A systematic review and
   meta-analysis
SO FRONTIERS IN MEDICINE
LA English
DT Review
DE artificial intelligence; systematic review; gastroenterology; diagnostic
   accuracy; pathologies
ID WIRELESS CAPSULE ENDOSCOPY; DEEP-LEARNING ALGORITHM; COLORECTAL POLYPS;
   CELIAC-DISEASE; AUTOMATIC DETECTION; BARRETTS NEOPLASIA; CLASSIFICATION;
   LESIONS; COLONOSCOPY
AB Background Artificial Intelligence (AI) holds considerable promise for diagnostics in the field of gastroenterology. This systematic review and meta-analysis aims to assess the diagnostic accuracy of AI models compared with the gold standard of experts and histopathology for the diagnosis of various gastrointestinal (GI) luminal pathologies including polyps, neoplasms, and inflammatory bowel disease. Methods We searched PubMed, CINAHL, Wiley Cochrane Library, and Web of Science electronic databases to identify studies assessing the diagnostic performance of AI models for GI luminal pathologies. We extracted binary diagnostic accuracy data and constructed contingency tables to derive the outcomes of interest: sensitivity and specificity. We performed a meta-analysis and hierarchical summary receiver operating characteristic curves (HSROC). The risk of bias was assessed using Quality Assessment for Diagnostic Accuracy Studies-2 (QUADAS-2) tool. Subgroup analyses were conducted based on the type of GI luminal disease, AI model, reference standard, and type of data used for analysis. This study is registered with PROSPERO (CRD42021288360). Findings We included 73 studies, of which 31 were externally validated and provided sufficient information for inclusion in the meta-analysis. The overall sensitivity of AI for detecting GI luminal pathologies was 91.9% (95% CI: 89.0-94.1) and specificity was 91.7% (95% CI: 87.4-94.7). Deep learning models (sensitivity: 89.8%, specificity: 91.9%) and ensemble methods (sensitivity: 95.4%, specificity: 90.9%) were the most commonly used models in the included studies. Majority of studies (n = 56, 76.7%) had a high risk of selection bias while 74% (n = 54) studies were low risk on reference standard and 67% (n = 49) were low risk for flow and timing bias. Interpretation The review suggests high sensitivity and specificity of AI models for the detection of GI luminal pathologies. There is a need for large, multi-center trials in both high income countries and low- and middle- income countries to assess the performance of these AI models in real clinical settings and its impact on diagnosis and prognosis.
C1 [Parkash, Om; Siddiqui, Asra Tus Saleha] Aga Khan Univ, Dept Med, Karachi, Pakistan.
   [Jiwani, Uswa; Rizvi, Arjumand] Aga Khan Univ, Ctr Excellence Women & Child Hlth, Karachi, Pakistan.
   [Rind, Fahad] Ohio State Univ, Head & Neck Oncol, Columbus, OH USA.
   [Padhani, Zahra Ali; Das, Jai K.] Aga Khan Univ, Inst Global Hlth & Dev, Karachi, Pakistan.
   [Hoodbhoy, Zahra; Das, Jai K.] Aga Khan Univ, Dept Pediat & Child Hlth, Karachi, Pakistan.
C3 Aga Khan University; Aga Khan University; University System of Ohio;
   Ohio State University; Aga Khan University; Aga Khan University
RP Das, JK (通讯作者)，Aga Khan Univ, Inst Global Hlth & Dev, Karachi, Pakistan.; Das, JK (通讯作者)，Aga Khan Univ, Dept Pediat & Child Hlth, Karachi, Pakistan.
EM jai.das@aku.edu
RI Jiwani, Uswa/IXD-1418-2023; Rizvi, Arjumand/ISU-8429-2023
OI Rizvi, Arjumand/0000-0003-4553-8130
CR Amisha, 2019, J FAM MED PRIM CARE, V8, P2328, DOI 10.4103/jfmpc.jfmpc_440_19
   Bagheri M, 2019, IEEE ENG MED BIO, P6742, DOI 10.1109/EMBC.2019.8856793
   Barish M, 2020, NAT MACH INTELL, DOI 10.1038/s42256-020-00254-2
   Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Ben-Israel D, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2019.101785
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Brownlee J., 2016, MACHINE LEARNIN 0315, V16
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Charisis V, 2010, IEEE ENG MED BIO, P3674, DOI 10.1109/IEMBS.2010.5627648
   Charisis VS, 2016, WORLD J GASTROENTERO, V22, P8641, DOI 10.3748/wjg.v22.i39.8641
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cho M, 2018, INT J COLORECTAL DIS, V33, P549, DOI 10.1007/s00384-018-2980-3
   Chuks NS., 2011, GASTROINTEST ENDOSC
   Ciaccio EJ, 2013, WORLD J GASTRO ENDOS, V5, P313, DOI 10.4253/wjge.v5.i7.313
   de Groof AJ, 2020, GASTROINTEST ENDOSC, V91, P1242, DOI 10.1016/j.gie.2019.12.048
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Fu JJC, 2014, COMPUT MED IMAG GRAP, V38, P267, DOI 10.1016/j.compmedimag.2013.12.009
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Girgis HZ, 2010, I S BIOMED IMAGING, P1373, DOI 10.1109/ISBI.2010.5490253
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Guo LJ, 2021, SURG ENDOSC, V35, P6532, DOI 10.1007/s00464-020-08150-x
   Harkey K, 2021, JAMA SURG, V156, P221, DOI [10.1001/jamasurg.2020.6265, 10.1186/s13643-021-01626-4, 10.1016/j.jclinepi.2021.03.001, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n71, 10.1016/j.rec.2021.07.010]
   Ho SY, 2020, PATTERNS, V1, DOI 10.1016/j.patter.2020.100129
   Hoodbhoy Z, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.708365
   Hoodbhoy Z, 2021, PEDIATRICS, V147, DOI 10.1542/peds.2020-011833
   Huang CR, 2016, IEEE T BIO-MED ENG, V63, P588, DOI 10.1109/TBME.2015.2466460
   Hwang Y, 2021, DIGEST ENDOSC, V33, P598, DOI 10.1111/den.13787
   IHME, 2019, DIG DIS LEV 2 CAUS
   Itoh H, 2019, HEALTHC TECHNOL LETT, V6, P237, DOI 10.1049/htl.2019.0079
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Johnson KW, 2018, J AM COLL CARDIOL, V71, P2668, DOI 10.1016/j.jacc.2018.03.521
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Li BN, 2021, IEEE ACM T COMPUT BI, V18, P1396, DOI 10.1109/TCBB.2019.2953701
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P821, DOI 10.1016/j.gie.2020.06.034
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Maida M, 2020, ENDOSC INT OPEN, V8, pE525, DOI 10.1055/a-1093-0877
   Maslekar S, 2010, COLORECTAL DIS, V12, P1254, DOI 10.1111/j.1463-1318.2009.02005.x
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mossotto E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02606-2
   Namikawa K, 2020, ENDOSCOPY, V52, P1077, DOI 10.1055/a-1194-8771
   Otani K, 2020, ENDOSCOPY, V52, P786, DOI 10.1055/a-1167-8157
   Owais M, 2020, J MED INTERNET RES, V22, DOI 10.2196/18563
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8070986
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Peery AF, 2022, GASTROENTEROLOGY, V162, P621, DOI 10.1053/j.gastro.2021.10.017
   Pesapane Filippo, 2018, Eur Radiol Exp, V2, P35, DOI 10.1186/s41747-018-0061-6
   Poon CCY, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0281-z
   Pourhoseingholi Mohamad Amin, 2015, Gastroenterol Hepatol Bed Bench, V8, P19
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Schwalbe N, 2020, LANCET, V395, P1579, DOI 10.1016/S0140-6736(20)30226-9
   Sevo I, 2016, COMPUT BIOL MED, V72, P138, DOI 10.1016/j.compbiomed.2016.03.017
   Shi CF, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/4393124
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Silva J, 2013, IEEE ENG MED BIO, P5711, DOI 10.1109/EMBC.2013.6610847
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   StataCorp LLC, 2021, STAT STAT SOFTW REL
   Struyvenberg MR, 2021, GASTROINTEST ENDOSC, V93, P89, DOI 10.1016/j.gie.2020.05.050
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Syed S, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.5822
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Taunk P, 2019, INT J COLORECTAL DIS, V34, P2043, DOI 10.1007/s00384-019-03406-y
   Tenorio JM, 2011, INT J MED INFORM, V80, P793, DOI 10.1016/j.ijmedinf.2011.08.001
   The Cochrane Collaboration, 2020, REV MAN REVMAN
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   USAID, 2019, ARTIF INTELL
   Vecsei A, 2011, COMPUT BIOL MED, V41, P313, DOI 10.1016/j.compbiomed.2011.03.009
   Vecsei A, 2009, COMPUT METH PROG BIO, V95, pS68, DOI 10.1016/j.cmpb.2009.02.017
   VISCAINO M, 2019, 2019 41 ANN INT C IE, DOI DOI 10.1109/EMBC.2019.8857831
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang S, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab5086
   Wang S, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/7546215
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Wang XL, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105236
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Wimmer G, 2016, INT CONF IMAG PROC
   Xia J, 2021, GASTROINTEST ENDOSC, V93, P133, DOI 10.1016/j.gie.2020.05.027
   Xie X, 2022, BMC GASTROENTEROL, V22, DOI 10.1186/s12876-022-02130-2
   Yang JJ, 2020, INT J COMPUT ASS RAD, V15, P1291, DOI 10.1007/s11548-020-02190-3
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang SM, 2021, J DIGEST DIS, V22, P318, DOI 10.1111/1751-2980.12992
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhao Q, 2011, IEEE INT CONF ROBOT
   Zhao Q, 2015, COMPUT MED IMAG GRAP, V41, P108, DOI 10.1016/j.compmedimag.2014.05.011
   Zheng WF, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000109
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 104
TC 0
Z9 0
U1 3
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-858X
J9 FRONT MED-LAUSANNE
JI Front. Med.
PD NOV 4
PY 2022
VL 9
AR 1018937
DI 10.3389/fmed.2022.1018937
PG 20
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 6J2MT
UT WOS:000886662400001
PM 36405592
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Ji, GP
   Xiao, GB
   Chou, YC
   Fan, DP
   Zhao, K
   Chen, G
   Van Gool, L
AF Ji, Ge-Peng
   Xiao, Guobao
   Chou, Yu-Cheng
   Fan, Deng-Ping
   Zhao, Kai
   Chen, Geng
   Van Gool, Luc
TI Video Polyp Segmentation: A Deep Learning Perspective
SO MACHINE INTELLIGENCE RESEARCH
LA English
DT Article
DE Video polyp segmentation (VPS); dataset; self-attention; colonoscopy;
   abdomen
ID NETWORK; ATTENTION; IMAGES
AB We present the first comprehensive video polyp segmentation (VPS) study in the deep learning era. Over the years, developments in VPS are not moving forward with ease due to the lack of a large-scale dataset with fine-grained segmentation annotations. To address this issue, we first introduce a high-quality frame-by-frame annotated VPS dataset, named SUN-SEG, which contains 158 690 colonoscopy video frames from the well-known SUN-database. We provide additional annotation covering diverse types, i.e., attribute, object mask, boundary, scribble, and polygon. Second, we design a simple but efficient baseline, named PNS+, which consists of a global encoder, a local encoder, and normalized self-attention (NS) blocks. The global and local encoders receive an anchor frame and multiple successive frames to extract long-term and short-term spatial-temporal representations, which are then progressively refined by two NS blocks. Extensive experiments show that PNS+ achieves the best performance and real-time inference speed (170 fps), making it a promising solution for the VPS task. Third, we extensively evaluate 13 representative polyp/object segmentation models on our SUN-SEG dataset and provide attribute-based comparisons. Finally, we discuss several open issues and suggest possible research directions for the VPS community. Our project and dataset are publicly available at https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/GewelsJI/VPS.
C1 [Ji, Ge-Peng] Australian Natl Univ, Res Sch Engn, Canberra, ACT 2601, Australia.
   [Xiao, Guobao] Minjiang Univ, Coll Comp & Control Engn, Fuzhou 350108, Peoples R China.
   [Chou, Yu-Cheng] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.
   [Fan, Deng-Ping; Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland.
   [Zhao, Kai] Univ Calif Los Angeles, Dept Radiol Sci, Los Angeles, CA 90095 USA.
   [Chen, Geng] Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian 710072, Peoples R China.
C3 Australian National University; Minjiang University; Johns Hopkins
   University; Swiss Federal Institutes of Technology Domain; ETH Zurich;
   University of California System; University of California Los Angeles;
   Northwestern Polytechnical University
RP Fan, DP (通讯作者)，Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland.
EM gepengai.ji@gmail.com; x-gb@163.com; johnson111788@gmail.com;
   dengpfan@gmail.com; kz@kaizhao.net; geng.chen.cs@gmail.com;
   vangool@vision.ee.ethz.ch
RI Fan, Deng-Ping/ABD-4052-2020
OI Fan, Deng-Ping/0000-0002-5245-7518; Van Gool, Luc/0000-0002-3445-5711;
   Xiao, Guobao/0000-0003-2928-8100; Zhao, Kai/0000-0002-2496-0829; Chen,
   Geng/0000-0001-8350-6581
FU National Natural Science Foundation of China [62072223]; Natural Science
   Foundation of Fujian Province, China [2020J01131199]
FX This work was supported by the National Natural Science Foundation of
   China (No. 62072223), and supported by the Natural Science Foundation of
   Fujian Province, China (No. 2020J01131199). The authors would like to
   thank the anonymous reviewers and editors for their helpful comments on
   this manuscript. Besides, we thank Huazhu Fu for his insightful
   feedback.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Ali S., ARXIV
   Ali S., 2020, 6G WHITE PAPER MACHI
   [Anonymous], GASTROINTESTINAL IMA
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Carneiro G, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101653
   Cheng MJ, 2021, LECT NOTES COMPUT SC, V12901, P720, DOI 10.1007/978-3-030-87193-2_68
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Dong B., 2021, ARXIV
   Fan D.-P., 2021, SCI SIN INFORMATIONI, V6, DOI DOI 10.1360/SSI-2020-0370
   Fan DP, 2023, IEEE T PATTERN ANAL, V45, P2344, DOI 10.1109/TPAMI.2022.3166451
   Fan DP, 2022, IEEE T PATTERN ANAL, V44, P6024, DOI 10.1109/TPAMI.2021.3085766
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gammulle Harshala, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P742, DOI 10.1007/978-3-030-59716-0_71
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gu YC, 2020, AAAI CONF ARTIF INTE, V34, P10869
   Guo XQ, 2022, IEEE T MED IMAGING, V41, P434, DOI 10.1109/TMI.2021.3114329
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji GP, 2023, MACH INTELL RES, V20, P92, DOI 10.1007/s11633-022-1365-9
   Ji GP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4902, DOI 10.1109/ICCV48922.2021.00488
   Ji GP, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108414
   Ji GP, 2021, LECT NOTES COMPUT SC, V12901, P142, DOI 10.1007/978-3-030-87193-2_14
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Krahenbuhl P., 2011, ADV NEURAL INFORM PR, V24, P109, DOI DOI 10.5555/2986459.2986472
   Li KD, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255809
   Li S., 2021, PROC 13 INT JOINT C, P807, DOI [10.24963/IJCAI.2021/112, DOI 10.24963/IJCAI.2021/112, 10.24963/ijcai.2021/112]
   Liu R. T., 2021, P ADV NEURAL INFORM, P13137
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Ma YT, 2021, LECT NOTES COMPUT SC, V12905, P387, DOI 10.1007/978-3-030-87240-3_37
   Maghsoudi O H, 2017, 2017 IEEE SIGNAL PRO, P1, DOI [DOI 10.1109/SPMB.2017.8257027, 10.1109/SPMB.2017.8257027]
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI 10.1109/EMBC.2019.8857339
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Puyal Juana Gonzalez-Bueno, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P295, DOI 10.1007/978-3-030-59725-2_29
   Ramer U., 1972, COMPUT GRAPHICS IMAG, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/50146-664X(72)80017-0]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Senkyire IB, 2021, INT J AUTOM COMPUT, V18, P887, DOI 10.1007/s11633-021-1313-0
   Shamshad F., 2022, ARXIV
   Shen YT, 2021, LECT NOTES COMPUT SC, V12901, P559, DOI 10.1007/978-3-030-87193-2_53
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Smedsrud PH, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00920-z
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Nguyen TC, 2021, LECT NOTES COMPUT SC, V12901, P633, DOI 10.1007/978-3-030-87193-2_60
   Tavanapong W, 2022, IEEE J BIOMED HEALTH, V26, P3950, DOI 10.1109/JBHI.2022.3160098
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wu HS, 2021, AAAI CONF ARTIF INTE, V35, P2916
   Wu LY, 2021, LECT NOTES COMPUT SC, V12905, P302, DOI 10.1007/978-3-030-87240-3_29
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1533, DOI 10.1109/ICCV48922.2021.00158
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
   Zhou ZL, 2021, IEEE T BIG DATA, V7, P559, DOI 10.1109/TBDATA.2019.2919570
   Zou K., ARXIV
NR 85
TC 3
Z9 3
U1 2
U2 4
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2731-538X
EI 2731-5398
J9 MACH INTELL RES
JI Mach. Intell. Res.
PD DEC
PY 2022
VL 19
IS 6
BP 531
EP 549
DI 10.1007/s11633-022-1371-y
EA NOV 2022
PG 19
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Automation & Control Systems; Computer Science
GA 6G6SK
UT WOS:000878982900002
OA Green Published, hybrid, Green Submitted
DA 2023-08-21
ER

PT J
AU Doniyorjon, M
   Madinakhon, R
   Shakhnoza, M
   Cho, YI
AF Doniyorjon, Mukhtorov
   Madinakhon, Rakhmonova
   Shakhnoza, Muksimova
   Cho, Young-Im
TI An Improved Method of Polyp Detection Using Custom YOLOv4-Tiny
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE wireless capsule endoscopy (WCE); polyp; classification; neural
   networks; localization
ID SEGMENTATION; NETWORK
AB Automatic detection of Wireless Endoscopic Images can avoid dangerous possible diseases such as cancers. Therefore, a number of articles have been published on different methods to enhance the speed of detection and accuracy. We also present a custom version of the YOLOv4-tiny for Wireless Endoscopic Image detection and localization that uses a You Only Look Once (YOLO) version to enhance the model accuracy. We modified the YOLOv4-tiny model by replacing the CSPDarknet-53-tiny backbone structure with the Inception-ResNet-A block to enhance the accuracy of the original YOLOv4-tiny. In addition, we implemented a new custom data augmentation method to enhance the data quality, even for small datasets. We focused on maintaining the color of medical images because the sensitivity of medical images can affect the efficiency of the model. Experimental results showed that our proposed method obtains 99.4% training accuracy; compared with the previous models, this is more than a 1.2% increase. An original model used for both detection and the segmentation of medical images may cause a high error rate. In contrast, our proposed model could eliminate the error rate of the detection and localization of disease areas from wireless endoscopic images.
C1 [Doniyorjon, Mukhtorov; Madinakhon, Rakhmonova; Shakhnoza, Muksimova; Cho, Young-Im] Gachon Univ, Dept IT Convergence Engn, Seongnam Si 461701, South Korea.
   [Doniyorjon, Mukhtorov; Cho, Young-Im] Gachon Univ, Dept Comp Engn, Seongnam Si 461701, South Korea.
C3 Gachon University; Gachon University
RP Cho, YI (通讯作者)，Gachon Univ, Dept IT Convergence Engn, Seongnam Si 461701, South Korea.; Cho, YI (通讯作者)，Gachon Univ, Dept Comp Engn, Seongnam Si 461701, South Korea.
EM yicho@gachon.ac.kr
OI Muksimova, Shakhnoza/0000-0002-6223-4502
FU Korea Agency for Technology and Standards [K_G012002073401,
   K_G012002234001]; Gachon University [GCU-202008460006]
FX This study was funded by Korea Agency for Technology and Standards in
   2022, project numbers are K_G012002073401, K_G012002234001 and by the
   Gachon University research fund of 2020(GCU-202008460006).
CR Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Almotairi S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051516
   Barki C, 2021, INFORMATICS-BASEL, V8, DOI 10.3390/informatics8030055
   Bhatt D, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10202470
   Bote-Curiel L, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112331
   Zammit SC, 2021, EXPERT REV GASTROENT, V15, P127, DOI 10.1080/17474124.2021.1840351
   Deding U, 2020, CANCERS, V12, DOI 10.3390/cancers12113367
   Duan SS, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11131968
   Fu GH, 2021, METABOLITES, V11, DOI 10.3390/metabo11060389
   Ghosh T, 2021, J DIGIT IMAGING, V34, P404, DOI 10.1007/s10278-021-00428-3
   Grasso SM, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11111371
   Habibzadeh M, 2018, PROC SPIE, V10696, DOI 10.1117/12.2311282
   Habijan M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12063024
   Hoang MC, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11101878
   Inbaraj XA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10131541
   Jain S, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104789
   Kvasir-Capsule, 2021, VIDEO CAPSULE ENDOSC
   Li G, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157742
   Liu P, 2021, MATERIALS, V14, DOI 10.3390/ma14247504
   Mokhtari S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040407
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Rahim T, 2020, COMPUT MED IMAG GRAP, V85, DOI 10.1016/j.compmedimag.2020.101767
   Ravanelli M, 2019, CANCERS, V11, DOI 10.3390/cancers11010067
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Redmon J, 2017, P IEEE C COMPUTER VI, P7263
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Shakhnoza M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010098
   Sindhu CP, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Szegedy C., 2017, AAAI, DOI DOI 10.1609/AAAI.V31I1.11231
   Tofanelli MBD, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10101618
   Visaggi P, 2021, CANCERS, V13, DOI 10.3390/cancers13133162
   Wang CS, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14092225
   Wei X, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13112107
   Weng LG, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9040256
   Zimmermann-Fraedrich K, 2019, GASTROENTEROLOGY, V157, P660, DOI 10.1053/j.gastro.2019.05.011
NR 37
TC 2
Z9 2
U1 3
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD NOV
PY 2022
VL 12
IS 21
AR 10856
DI 10.3390/app122110856
PG 10
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA 6A9AX
UT WOS:000880940400001
OA gold
DA 2023-08-21
ER

PT J
AU Levy, I
   Bruckmayer, L
   Klang, E
   Ben-Horin, S
   Kopylov, U
AF Levy, Idan
   Bruckmayer, Liora
   Klang, Eyal
   Ben-Horin, Shomron
   Kopylov, Uri
TI Artificial Intelligence-Aided Colonoscopy Does Not Increase Adenoma
   Detection Rate in Routine Clinical Practice
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
ID QUALITY
AB The performance of artificial intelligence-aided colonoscopy (AIAC) in a real-world setting has not been described. We compared adenoma and polyp detection rates (ADR/PDR) in a 6-month period before (pre-AIAC) and after introduction of AIAC (GI Genius, Medtronic) in all endoscopy suites in our large-volume center. The ADR and PDR in the AIAC group was lower compared with those in the pre-AIAC group (30.3% vs 35.2%, P < 0.001; 36.5% vs 40.9%, P = 0.004, respectively); procedure time was significantly shorter in the AIAC group. In summary, introduction of AIAC did not result in performance improvement in our large-center cohort, raising important questions on AI-human interactions in medicine.
C1 [Levy, Idan; Ben-Horin, Shomron; Kopylov, Uri] Sheba Med Ctr, Dept Gastroenterol, Ramat Gan, Israel.
   [Levy, Idan; Bruckmayer, Liora; Klang, Eyal; Ben-Horin, Shomron; Kopylov, Uri] Tel Aviv Univ, Sch Med, Tel Aviv, Israel.
   [Bruckmayer, Liora] Sheba Med Ctr, Dept Internal Med D, Ramat Gan, Israel.
   [Klang, Eyal] Sheba Med Ctr, Dept Diagnost Imaging, Ramat Gan, Israel.
C3 Chaim Sheba Medical Center; Tel Aviv University; Chaim Sheba Medical
   Center; Chaim Sheba Medical Center
RP Kopylov, U (通讯作者)，Sheba Med Ctr, Dept Gastroenterol, Ramat Gan, Israel.; Kopylov, U (通讯作者)，Tel Aviv Univ, Sch Med, Tel Aviv, Israel.
EM idantours@gmail.com; liora.bruckmayer@sheba.health.gov.il;
   Eyal.Klang@sheba.health.gov.il; shomron.benhorin@gmail.com;
   ukopylov@gmail.com
OI Kopylov, Uri/0000-0002-7156-0588
FU Medtronic
FX The study was partially supported by Medtronic.
CR Antonelli G, 2021, BEST PRACT RES CL GA, V52-53, DOI 10.1016/j.bpg.2020.101713
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Keswani RN, 2021, GASTROENTEROLOGY, V161, P701, DOI 10.1053/j.gastro.2021.05.041
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Tziatzios G, 2020, GASTROINTEST ENDOSC, V91, P1027, DOI 10.1016/j.gie.2019.12.052
   Wallace MB, 2022, GASTROENTEROLOGY, V163, P295, DOI 10.1053/j.gastro.2022.03.007
NR 8
TC 11
Z9 11
U1 1
U2 2
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0002-9270
EI 1572-0241
J9 AM J GASTROENTEROL
JI Am. J. Gastroenterol.
PD NOV
PY 2022
VL 117
IS 11
BP 1871
EP 1873
DI 10.14309/ajg.0000000000001970
PG 3
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 5X0MP
UT WOS:000878303000028
PM 36001408
DA 2023-08-21
ER

PT J
AU Yu, H
   Kim, DK
AF Yu, Hyunjae
   Kim, Dong-Kyu
TI Neutrophils Play an Important Role in the Recurrence of Chronic
   Rhinosinusitis with Nasal Polyps
SO BIOMEDICINES
LA English
DT Article
DE neutrophil; rhinosinusitis; sinusitis; nasal polyp; machine learning
ID ENDOSCOPIC SINUS SURGERY; HEALING QUALITY
AB Despite the heterogeneity of chronic rhinosinusitis (CRS), a clear link exists between type 2 immunity and the severity of CRS with nasal polyps (CRSwNP). However, recent studies have demonstrated that patients with severe type 2 CRSwNP also display abundant neutrophilic inflammation. Therefore, we investigated the factors associated with the recurrence of CRSwNP following sinus surgery using a machine-learning algorithm. We collected the demographics, clinical variables, and inflammatory profiles of 210 patients with CRSwNP who underwent sinus surgery. After one year, we evaluated whether each patient showed recurrence. Machine-learning methods, such as decision trees, random forests, and support vector machine models, have been used to predict the recurrence of CRSwNP. The results indicated that neutrophil inflammation, such as tissue and serum neutrophils, is an important factor affecting the recurrence of surgical CRSwNP. Specifically, the random forest model showed the highest accuracy in detecting recurrence among the three machine-learning methods, which revealed tissue neutrophilia to be the most important variable in determining surgical outcomes. Therefore, our machine-learning approach suggests that neutrophilic inflammation is increased in patients with difficult-to-treat CRSwNP, and the increased presence of neutrophils in subepithelial regions is closely related to poor surgical outcomes in patients with CRSwNP.
C1 [Yu, Hyunjae; Kim, Dong-Kyu] Hallym Univ, Inst New Frontier Res, Coll Med, Div Big Data & Artificial Intelligence, Chunchon 24253, South Korea.
   [Kim, Dong-Kyu] Hallym Univ, Chuncheon Sacred Heart Hosp, Coll Med, Dept Otorhinolaryngol Head & Neck Surg, Chunchon 24253, South Korea.
C3 Hallym University; Hallym University
RP Kim, DK (通讯作者)，Hallym Univ, Inst New Frontier Res, Coll Med, Div Big Data & Artificial Intelligence, Chunchon 24253, South Korea.; Kim, DK (通讯作者)，Hallym Univ, Chuncheon Sacred Heart Hosp, Coll Med, Dept Otorhinolaryngol Head & Neck Surg, Chunchon 24253, South Korea.
EM doctordk@naver.com
OI Kim, Dong-Kyu/0000-0003-4917-0177; Yu, Hyunjae/0000-0002-3213-2353
FU Bio & Medical Technology Development Program of the National Research
   Foundation (NRF); Korean government (MSIT);  [2019-10-009]; 
   [NRF-2021R1C1C1005746]
FX This study was supported by a grant from the Bio & Medical Technology
   Development Program of the National Research Foundation (NRF)
   (2019-10-009), funded by the Korean government (MSIT)
   (NRF-2021R1C1C1005746).
CR Bassiouni A, 2013, LARYNGOSCOPE, V123, P36, DOI 10.1002/lary.23610
   DeConde AS, 2017, LARYNGOSCOPE, V127, P550, DOI 10.1002/lary.26391
   Delemarre T, 2021, J ALLERGY CLIN IMMUN, V148, P327, DOI 10.1016/j.jaci.2021.03.024
   Delemarre T, 2021, J ALLERGY CLIN IMMUN, V147, P179, DOI 10.1016/j.jaci.2020.08.036
   Fokkens WJ, 2020, RHINOLOGY, V58, P1, DOI 10.4193/Rhin20.401
   Gevaert E, 2020, J ALLERGY CLIN IMMUN, V145, P427, DOI 10.1016/j.jaci.2019.08.027
   Hwang CS, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44627-z
   Kato A, 2022, J ALLERGY CLIN IMMUN, V149, P1491, DOI 10.1016/j.jaci.2022.02.016
   Kim DW, 2019, CLIN EXP OTORHINOLAR, V12, P325, DOI 10.21053/ceo.2019.01452
   Kim DK, 2021, RHINOLOGY, V59, P173, DOI 10.4193/Rhin20.373
   Kim DK, 2021, CLIN EXP OTORHINOLAR, V14, P390, DOI 10.21053/ceo.2020.02250
   Kim DK, 2020, ALLERGY ASTHMA IMMUN, V12, P42, DOI 10.4168/aair.2020.12.1.42
   Kim DK, 2018, ALLERGY ASTHMA IMMUN, V10, P490, DOI 10.4168/aair.2018.10.5.490
   Kim DK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139945
   Mantovani A, 2011, NAT REV IMMUNOL, V11, P519, DOI 10.1038/nri3024
   Persson EK, 2019, SCIENCE, V364, P751, DOI 10.1126/science.aaw4295
   Ryu G, 2019, ALLERGY ASTHMA IMMUN, V11, P664, DOI 10.4168/aair.2019.11.5.664
   Stein NR, 2018, LARYNGOSCOPE, V128, P31, DOI 10.1002/lary.26741
   Thorwarth RM, 2021, INT FORUM ALLERGY RH, V11, P8, DOI 10.1002/alr.22632
   Tomassen P, 2016, J ALLERGY CLIN IMMUN, V137, P1449, DOI 10.1016/j.jaci.2015.12.1324
   Ueki S, 2018, BLOOD, V132, P2183, DOI 10.1182/blood-2018-04-842260
   Wang H, 2019, CLIN EXP OTORHINOLAR, V12, P337, DOI 10.21053/ceo.2019.00654
   Wang XY, 2021, ACTA OTO-LARYNGOL, V141, P279, DOI 10.1080/00016489.2020.1844288
   Watelet JB, 2005, LARYNGOSCOPE, V115, P56, DOI 10.1097/01.mlg.0000150674.30237.3f
   Watelet JB, 2004, WOUND REPAIR REGEN, V12, P412, DOI 10.1111/j.1067-1927.2004.012411.x
   Wu QW, 2020, J ALLERGY CLIN IMMUN, V145, P698, DOI 10.1016/j.jaci.2019.12.002
NR 26
TC 1
Z9 1
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-9059
J9 BIOMEDICINES
JI Biomedicines
PD NOV
PY 2022
VL 10
IS 11
AR 2911
DI 10.3390/biomedicines10112911
PG 12
WC Biochemistry & Molecular Biology; Medicine, Research & Experimental;
   Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Research & Experimental Medicine;
   Pharmacology & Pharmacy
GA 6U5IE
UT WOS:000894399500001
PM 36428479
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Feng, B
   Xu, C
   An, ZH
AF Feng, Bo
   Xu, Chao
   An, Ziheng
TI AI recognition preprocessing algorithm for polyp based on illumination
   equalization and highlight restoration
SO INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS
LA English
DT Article
DE Image Restoration; Colon Polyp; Intelligent Recognition; 2D Gamma
   Function Correction; Optimized Criminisi algorithm
ID COLONOSCOPY
AB AI intelligent detection of colon polyp has been found as a highly popular research direction. Moreover, mainstream research places a focus on how to recognize colon polyp using a better neural network model architecture. The video employed for recognition will be considered the original video output by the endoscope. Through research, it was found that besides the prominent neural network architecture, more excellent video preprocessing algorithms can significantly increase the accuracy of recognition and location for colon polyp. As revealed by the research result, the relative highlight area attributed to uneven illumination and the absolute highlight area attributed to specular reflection are the main factors of the recognition of colon polyp by the neural network. To solve the problem above, all highlight areas are divided into four categories, i.e., the relative highlight area, the large absolute highlight area, the medium absolute highlight area and the small absolute highlight area. This study designs different restoration algorithms in accordance with the nature and characteristics of the respective categories. The relative highlight area can be corrected and restored using the two-dimensional (2d) gamma function. The large absolute highlight area will not be processed since it will not reduce the recognition accuracy of the neural network. The small absolute highlight area has a slight effect on the recognition accuracy of the neural network, so the surrounding color filling method will be adopted to restore the area. The medium absolute highlight area will be restored by the optimized Criminisi algorithm. The test is performed on four neural networks, i.e., the Unet, Unet++, ResUnet and ResUnet++. After the sample is processed by this algorithm, the results show that the recognition accuracy of colon polyps by four kinds of neural network is significantly improved. Compared with other image restoration algorithms that take tens of seconds, the image restoration algorithm in this study takes less than 90 ms, which obviously reduces the time, and can basically meet the real-time requirements of AI intelligent detection.
C1 [Feng, Bo; Xu, Chao; An, Ziheng] Anhui Univ, Hefei, Anhui, Peoples R China.
C3 Anhui University
RP Xu, C (通讯作者)，Anhui Univ, Hefei, Anhui, Peoples R China.
EM 1160596116@qq.com; graymagpie@163.com
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Ahmed J, 2013, SCOT MED J, V58, P168, DOI 10.1177/0036933013496963
   Brelstaff G., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P297, DOI 10.1109/CCV.1988.590004
   Buyssens P, 2015, IEEE T IMAGE PROCESS, V24, P1809, DOI 10.1109/TIP.2015.2411437
   Cao JF, 2019, HERIT SCI, V7, DOI 10.1186/s40494-019-0281-y
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Goyal H, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103313
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Klinker G. J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P145
   Li KS, 2016, SOFT COMPUT, V20, P885, DOI 10.1007/s00500-014-1547-7
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Liu L, 2015, PROC SPIE, V9817, DOI 10.1117/12.2229039
   Liu Zhi-cheng, 2016, Transactions of Beijing Institute of Technology, V36, P191, DOI 10.15918/j.tbit1001-0645.2016.02.016
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Misawa M, 2021, DIGEST ENDOSC, V33, P273, DOI 10.1111/den.13847
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Tulsani A, 2021, BIOCYBERN BIOMED ENG, V41, P819, DOI 10.1016/j.bbe.2021.05.011
   Wang J., 2021, SOC PHOTOOPTICAL INS
   Yeo H, 2017, CLIN COLORECTAL CANC, V16, P293, DOI 10.1016/j.clcc.2017.06.002
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 24
TC 0
Z9 0
U1 1
U2 1
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2364-415X
EI 2364-4168
J9 INT J DATA SCI ANAL
JI Int. J, Data Sci. Anal.
PD MAR
PY 2023
VL 15
IS 2
SI SI
BP 217
EP 230
DI 10.1007/s41060-022-00353-w
EA OCT 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 9V4MN
UT WOS:000871852100001
DA 2023-08-21
ER

PT J
AU Hassan, C
   Balsamo, G
   Lorenzetti, R
   Zullo, A
   Antonelli, G
AF Hassan, Cesare
   Balsamo, Giuseppina
   Lorenzetti, Roberto
   Zullo, Angelo
   Antonelli, Giulio
TI Artificial Intelligence Allows Leaving-In-Situ Colorectal Polyps
SO CLINICAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE Artificial Intelligence; Optical Diagnosis; Leave in Situ; Resect and
   Discard; Diminutive Polyps; Colorectal Polyps; Colonoscopy; Machine
   Learning; Virtual Chromoendoscopy; Polyp Characterization; Colorectal
   Cancer Screening
ID COST-EFFECTIVENESS; GASTROINTESTINAL ENDOSCOPY; COLON POLYPS;
   COLONOSCOPY; CANCER; HISTOLOGY; ACCURACY; SOCIETY; DISCARD; RESECT
AB BACKGROUND & AIMS: Artificial Intelligence (AI) could support cost-saving strategies for colonoscopy because of its accuracy in the optical diagnosis of colorectal polyps. However, AI must meet predefined criteria to be implemented in clinical settings.
   METHODS: An approved computer-aided diagnosis (CADx) module for differentiating between adenoma and nonadenoma in unmagnified white-light colonoscopy was used in a consecutive series of colonoscopies. For each polyp, CADx output and subsequent endoscopist diagnosis with advanced imaging were matched against the histology gold standard. The primary outcome was the negative predictive value (NPV) of CADx for adenomatous histology for 5-mm pound rectosigmoid lesions. We also calculated the NPV for AI-assisted endoscopist predictions, and agreement between CADx and histology-based postpolypectomy surveillance intervals according to European and American guidelines.
   RESULTS: Overall, 544 polyps were removed in 162 patients, of which 295 (54.2%) were 5-mm pound rectosigmoid histologically verified lesions. CADx diagnosis was feasible in 291 of 295 (98.6%), and the NPV for 5-mm pound rectosigmoid lesions was 97.6% (95% CI, 94.1%-99.1%). There were 242 of 295 (82%) lesions that were amenable for a leave-in-situ strategy. Based on CADx output, 212 of 544 (39%) would be amenable to a resect-and-discard strategy, resulting in a 95.6% (95% CI, 90.8%-98.0%) and 95.9% (95% CI, 89.8%-98.4%) agreement between CADx- and histology-based surveillance intervals according to European and American guidelines, respectively. A similar NPV (97.6%; 95% CI, 94.8%-99.1%) for 5-mm pound rectosigmoids was achieved by AI-assisted endoscopists assessing polyps with electronic chromoendoscopy, with a CADx-concordant diagnosis in 97.2% of cases.
   CONCLUSIONS: In this study, CADx without advanced imaging exceeded the benchmarks required for optical diagnosis of colorectal polyps. CADx could help implement cost-saving strategies in colonoscopy by reducing the burden of polypectomy and/or pathology.
C1 [Hassan, Cesare] Humanitas Univ, Dept Biomed Sci, Milan, Italy.
   [Hassan, Cesare] Humanitas Clin & Res Ctr IRCCS, Endoscopy Unit, Milan, Italy.
   [Balsamo, Giuseppina] Azienda Sanitaria Locale Roma 1, Pathol Unit, Rome, Italy.
   [Lorenzetti, Roberto; Zullo, Angelo; Antonelli, Giulio] Nuovo Regina Margherita Hosp, Gastroenterol Unit, Rome, Italy.
   [Antonelli, Giulio] Sapienza Univ Rome, Dept Anat Histol Forens Med & Orthoped Sci, Rome, Italy.
   [Antonelli, Giulio] Osped Castelli Hosp, Gastroenterol & Digest Endoscopy Unit, Rome, Italy.
C3 Humanitas University; Poliambulatorio Nuovo Regina Margherita; Sapienza
   University Rome
RP Hassan, C (通讯作者)，Humanitas Res Hosp, Gastroenterol & Digest Endoscopy Unit, Via Manzoni 56, I-20089 Rozzano, Italy.
EM cesareh@hotmail.com
RI ; hassan, cesare/H-2844-2012
OI Antonelli, Giulio/0000-0003-1797-3864; hassan,
   cesare/0000-0001-7167-1459
CR Atkin WS, 2012, ENDOSCOPY, V44, pSE151, DOI 10.1055/s-0032-1309821
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1136/bmj.h5527, 10.1373/clinchem.2015.246280, 10.1148/radiol.2015151516]
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Dekker E, 2020, ENDOSCOPY, V52, P899, DOI 10.1055/a-1231-5123
   Gordon IO, 2021, AM J CLIN PATHOL, V156, P540, DOI 10.1093/ajcp/aqab021
   Greuter MJE, 2017, ANN INTERN MED, V167, P544, DOI 10.7326/M16-2891
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Gupta Samir, 2020, Gastroenterology, V158, P1154, DOI 10.1053/j.gastro.2020.02.014
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Krzeczewski B, 2021, POL ARCH INTERN MED, V131, P128, DOI 10.20452/pamw.15779
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Laish I, 2019, CLIN RES HEPATOL GAS, V43, P201, DOI 10.1016/j.clinre.2018.03.001
   Lansdorp-Vogelaar I, 2010, BEST PRACT RES CL GA, V24, P439, DOI 10.1016/j.bpg.2010.04.004
   Liu XX, 2020, LANCET DIGIT HEALTH, V2, pE537, DOI [10.1016/S2589-7500(20)30218-1, 10.1016/S2589-7500(20)30219-3]
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Plumb AA, 2016, ENDOSCOPY, V48, P899, DOI 10.1055/s-0042-108727
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Repici A, 2013, GASTROINTEST ENDOSC, V78, P106, DOI 10.1016/j.gie.2013.01.035
   Rex DK, 2020, TECH INNOVAT GASTROI, V22, P52, DOI 10.1016/j.tgie.2019.150638
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Saftoiu A, 2020, ENDOSCOPY, V52, P293, DOI 10.1055/a-1104-5245
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Singh R, 2013, DIGEST ENDOSC, V25, P16, DOI 10.1111/den.12075
   Smith SCL, 2021, ENDOSC INT OPEN, V09, pE716, DOI 10.1055/a-1381-7181
   Vu HT, 2015, DIGEST DIS SCI, V60, P502, DOI 10.1007/s10620-014-3376-z
   Wallace MB, 2014, GASTROINTEST ENDOSC, V80, P1072, DOI 10.1016/j.gie.2014.05.305
NR 34
TC 14
Z9 14
U1 2
U2 2
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1542-3565
EI 1542-7714
J9 CLIN GASTROENTEROL H
JI Clin. Gastroenterol. Hepatol.
PD NOV
PY 2022
VL 20
IS 11
BP 2505
EP +
DI 10.1016/j.cgh.2022.04.045
EA OCT 2022
PG 13
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 8X3BD
UT WOS:000931890100014
PM 35835342
OA hybrid
DA 2023-08-21
ER

PT J
AU Albuquerque, C
   Henriques, R
   Castelli, M
AF Albuquerque, Carina
   Henriques, Roberto
   Castelli, Mauro
TI A stacking-based artificial intelligence framework for an effective
   detection and localization of colon polyps
SO SCIENTIFIC REPORTS
LA English
DT Article
ID MISS RATE; COLONOSCOPY; RISK
AB Polyp detection through colonoscopy is a widely used method to prevent colorectal cancer. The automation of this process aided by artificial intelligence allows faster and improved detection of polyps that can be missed during a standard colonoscopy. In this work, we propose to implement various object detection algorithms for polyp detection. To improve the mean average precision (mAP) of the detection, we combine the baseline models through a stacking approach. The experiments demonstrate the potential of this new methodology, which can reduce the workload for oncologists and increase the precision of the localization of polyps. Our proposal achieves a mAP of 0.86, translated into an improvement of 34.9% compared to the best baseline model and 28.8% with respect to the weighted boxes fusion ensemble technique.
C1 [Albuquerque, Carina; Henriques, Roberto; Castelli, Mauro] Univ Nova Lisboa, NOVA Informat Management Sch NOVA IMS, Campus Campolide, P-1070312 Lisbon, Portugal.
C3 Universidade Nova de Lisboa
RP Albuquerque, C (通讯作者)，Univ Nova Lisboa, NOVA Informat Management Sch NOVA IMS, Campus Campolide, P-1070312 Lisbon, Portugal.
EM calbuquerque@novaims.unl.pt
RI Castelli, Mauro/O-8809-2019; Henriques, Roberto/AAA-2271-2019; Castelli,
   Mauro/U-5599-2017
OI Henriques, Roberto/0000-0002-4862-8177; Castelli,
   Mauro/0000-0002-8793-1451; Albuquerque, Carina/0000-0002-1888-9018
FU national funds through FCT (Fundacao para a Ciencia e a Tecnologia)
   [UIDB/04152/2020]
FX This work was supported by national funds through FCT (FundacAo para a
   Ciencia e a Tecnologia), under the project - UIDB/04152/2020 - Centro de
   InvestigacAo em GestAo de InformacAo (MagIC)/NOVA IMS.
CR ACS, 2020, AM CANC SOC, V66, P1
   Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Bohr A, 2020, ARTIF INTELL, P25
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Doubeni CA, 2013, ANN INTERN MED, V158, P312, DOI 10.7326/0003-4819-158-5-201303050-00003
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Girshick R., 2015, PROC IEEE INT C COMP, P1440, DOI DOI 10.1109/ICCV.2015.169
   Guo Z, 2020, I S BIOMED IMAGING, P1655, DOI 10.1109/ISBI45749.2020.9098500
   Hong A., 2021, P 3 INT WORKSHOP CHA, VVolume 2886, P80
   Howard J, 2020, INFORMATION, V11, DOI 10.3390/info11020108
   Issa IA, 2017, WORLD J GASTROENTERO, V23, P5086, DOI 10.3748/wjg.v23.i28.5086
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jocher G., 2020, YOLOV5 CODE REPOS
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li W., 2021, CEUR WORKSHOP PROC, P69
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Maeng L-S., 2007, GASTROINTEST ENDOSC, V65, P683
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   An NS, 2022, IEEE ACCESS, V10, P43669, DOI 10.1109/ACCESS.2022.3168693
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Padilla R, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030279
   Lan PN, 2021, LECT NOTES COMPUT SC, V13018, P15, DOI 10.1007/978-3-030-90436-4_2
   Polat G., 2021, INT WORKSHOP COMPUTE, V2886, P90
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sharma P, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.844391
   Solovyev R, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104117
   Stoffel EM, 2020, GASTROENTEROLOGY, V158, P341, DOI 10.1053/j.gastro.2019.07.055
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang CP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165315
   Tas M, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2020.106959
   Thambawita V., 2021, P 3 INT WORKSHOP CHA, V2886, P27
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wallace MB, 2022, GASTROENTEROLOGY, V163, P295, DOI 10.1053/j.gastro.2022.03.007
   Wan JJ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122264
   Wu LY, 2021, LECT NOTES COMPUT SC, V12905, P302, DOI 10.1007/978-3-030-87240-3_29
   Wu Y., 2019, DETECTRON2
   Younas F, 2023, APPL INTELL, V53, P2410, DOI 10.1007/s10489-022-03689-9
   Yu H., 2020, TENSORFLOW 2 DETECTI
   Zhou HJ, 2017, IEEE INT CONF COMP V, P760, DOI 10.1109/ICCVW.2017.95
NR 44
TC 1
Z9 1
U1 1
U2 2
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD OCT 21
PY 2022
VL 12
IS 1
AR 17678
DI 10.1038/s41598-022-21574-w
PG 12
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA 5M5DY
UT WOS:000871116800107
PM 36271114
OA Green Submitted, gold, Green Published
DA 2023-08-21
ER

PT J
AU Fu, JH
   Lin, SL
   Zhou, PH
   Guo, Y
   Wang, YY
AF Fu, Junhu
   Lin, Shengli
   Zhou, Pinghong
   Guo, Yi
   Wang, Yuanyuan
TI M(3)ResU-Net: a deep residual network for multi-center colorectal polyp
   segmentation based on multi-scale learning and attention mechanism
SO PHYSICS IN MEDICINE AND BIOLOGY
LA English
DT Article
DE colorectal polyp segmentation; multi-center datasets; attention
   mechanism; multi-scale learning
ID CANCER STATISTICS; VALIDATION
AB Colorectal polyps are considered as an important precursor of colorectal cancer (CRC) in clinical diagnosis. A network automatically and accurately segmenting polyps can recognize, locate and finally help to remove polyps, greatly reducing the misdiagnosis rate. Although many neural networks for polyp segmentation have been proposed, there still exist some difficulties including the diversity of image backgrounds, the jelly effect, and the various shapes and sizes of different polyps. These factors lead to the segmentation accuracy remaining to be improved. In this paper, we propose M(3)ResU-Net including multi-scale learning and attention mechanisms, aiming to segment multi-center colorectal polyps. First, we implement the contrast limited adaptive histogram equalization (CLAHE) and data augmentation for multi-center data. Then, channel and spatial attention mechanisms are introduced to focus on polyp features and suppress interference features. Finally, in order to balance small target segmentation and the acquisition of global information, multi-scale learning with dilated convolutions is employed. We compared other five polyp segmentation methods on three publicly available datasets. In single-center experiments, M(3)ResU-Net reaches a Dice similarity coefficient (DSC) exceeding that of the best compared method by over 2%. In various multi-center experiments, M(3)ResU-Net all achieves a DSC over 0.8. The results demonstrate that M(3)ResU-Net is capable of assisting clinicians in polyp segmentation in the field of colonoscopy, which provides important and reliable support to improve diagnostic efficiency.
C1 [Fu, Junhu; Guo, Yi; Wang, Yuanyuan] Fudan Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
   [Lin, Shengli] Fudan Univ, Zhongshan Hosp, Endoscopy Ctr, Shanghai, Peoples R China.
   [Lin, Shengli] Fudan Univ, Zhongshan Hosp, Endoscopy Res Inst, Shanghai, Peoples R China.
   [Zhou, Pinghong] Shanghai Collaborat Innovat Ctr Endoscopy, Shanghai, Peoples R China.
C3 Fudan University; Fudan University; Fudan University
RP Guo, Y; Wang, YY (通讯作者)，Fudan Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
EM guoyi@fudan.edu.cn; yywang@fudan.edu.cn
RI WANG, YUANYUAN/IQR-4295-2023; Wang, Yuan/HHC-1520-2022; WANG,
   HUIYUAN/IXX-2427-2023; li, wei/IUQ-2973-2023; wangwangwang,
   yuanyaunyuan/HHN-6432-2022; .., What/IXW-6776-2023; Wang,
   lili/IXD-9828-2023; Li, Yuan/IXD-9067-2023
FU National Natural Science Foundation of China [61871135, 81830058,
   82000623]; Science and Technology Commission of Shanghai Municipality
   [20DZ1100104, 20DZ1100102]; Zhongshan Hospital Innovation Fund
   [2020ZSCX06]; Zhongshan Hospital Outstanding Youth Fund [2021ZSYQ12]
FX This work was supported by the National Natural Science Foundation of
   China (Grants 61871135, 81830058 and 82000623), the Science and
   Technology Commission of Shanghai Municipality (Grants 20DZ1100104 and
   20DZ1100102), Zhongshan Hospital Innovation Fund (Grant 2020ZSCX06) and
   Zhongshan Hospital Outstanding Youth Fund (Grant 2021ZSYQ12).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], CA CANCER J CLIN
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Campos GFC, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0445-4
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Chollet F., 2018, KERAS PYTHON DEEP LE
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Figueiredo IN, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101577
   Guo XQ, 2021, IEEE T MED IMAGING, V40, P1134, DOI 10.1109/TMI.2020.3046843
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Larsen IK., 2016, CANC NORWAY 2015 CAN, V2016
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Poorneshwaran JM, 2019, IEEE ENG MED BIO, P7201, DOI 10.1109/EMBC.2019.8857958
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Ronneberger O., 2015, P INT C MED IM COMP, P234, DOI [10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Srivastava A, 2022, IEEE J BIOMED HEALTH, V26, P2252, DOI 10.1109/JBHI.2021.3138024
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yang C, 2021, IEEE J BIOMED HEALTH, V25, P3886, DOI 10.1109/JBHI.2021.3077271
   Yang XY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038011
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 34
TC 0
Z9 0
U1 9
U2 25
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0031-9155
EI 1361-6560
J9 PHYS MED BIOL
JI Phys. Med. Biol.
PD OCT 21
PY 2022
VL 67
IS 20
AR 205005
DI 10.1088/1361-6560/ac92bb
PG 16
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA 5D4HO
UT WOS:000864905200001
PM 36113443
DA 2023-08-21
ER

PT J
AU Zhang, WC
   Fu, C
   Zheng, Y
   Zhang, FY
   Zhao, YL
   Sham, CW
AF Zhang, Wenchao
   Fu, Chong
   Zheng, Yu
   Zhang, Fangyuan
   Zhao, Yanli
   Sham, Chiu-Wing
TI HSNet: A hybrid semantic network for polyp segmentation
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp segmentation; Hybrid semantic; Dual-branch; Long-range
   dependencies; Local details
AB Automatic polyp segmentation can help physicians to effectively locate polyps (a.k.a. region of interests) in clinical practice, in the way of screening colonoscopy images assisted by neural networks (NN). However, two significant bottlenecks hinder its effectiveness, disappointing physicians' expectations. (1) Changeable polyps in different scaling, orientation, and illumination, bring difficulty in accurate segmentation. (2) Current works building on a dominant decoder-encoder network tend to overlook appearance details (e.g., textures) for a tiny polyp, degrading the accuracy to differentiate polyps. For alleviating the bottlenecks, we investigate a hybrid semantic network (HSNet) that adopts both advantages of Transformer and convolutional neural networks (CNN), aiming at improving polyp segmentation. Our HSNet contains a cross-semantic attention module (CSA), a hybrid semantic complementary module (HSC), and a multi-scale prediction module (MSP). Unlike previous works on segmenting polyps, we newly insert the CSA module, which can fill the gap between low-level and high-level features via an interactive mechanism that exchanges two types of semantics from different NN attentions. By a dual-branch structure of Transformer and CNN, we newly design an HSC module, for capturing both long-range dependencies and local details of appearance. Besides, the MSP module can learn weights for fusing stage-level prediction masks of a decoder. Experimentally, we compared our work with 10 state-of-the-art works, including both recent and classical works, showing improved accuracy (via 7 evaluative metrics) over 5 benchmark datasets, e.g., it achieves 0.926/0.877 mDic/mIoU on Kvasir-SEG, 0.948/0.905 mDic/mIoU on ClinicDB, 0.810/0.735 mDic/mIoU on ColonDB, 0.808/0.74 mDic/mIoU on ETIS, and 0.903/0.839 mDic/mIoU on Endoscene. The proposed model is available at (https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/baiboat/ HSNet).
C1 [Zhang, Wenchao; Fu, Chong] Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110819, Peoples R China.
   [Fu, Chong] Minist Educ, Engn Res Ctr Secur Technol Complex Network Syst, Shenyang, Peoples R China.
   [Fu, Chong] Northeastern Univ, Key Lab Intelligent Comp Med Image, Minist Educ, Shenyang 110819, Peoples R China.
   [Zheng, Yu] Chinese Univ Hong Kong, Dept Informat Engn, Sha Tin, Hong Kong, Peoples R China.
   [Zhang, Fangyuan] China Med Univ, Dept Gen Surg, Shengjing Hosp, Shenyang, Peoples R China.
   [Zhao, Yanli] Ningxia Inst Sci & Technol, Sch Elect Informat Engn, Shizuishan 753000, Peoples R China.
   [Sham, Chiu-Wing] Univ Auckland, Sch Comp Sci, Auckland, New Zealand.
C3 Northeastern University - China; Northeastern University - China;
   Chinese University of Hong Kong; China Medical University; University of
   Auckland
RP Fu, C (通讯作者)，Northeastern Univ, Sch Comp Sci & Engn, Shenyang 110819, Peoples R China.
EM wczhang@stumail.neu.edu.cn; fuchong@mail.neu.edu.cn;
   zy018@ie.cuhk.edu.hk; fyzhang@cmu.edu.cn; 2010644@stu.neu.edu.cn;
   b.sham@auckland.ac.nz
RI Zheng, Yu/HPH-9632-2023; Sham, Chiu-Wing/C-3819-2014
OI Zheng, Yu/0000-0002-5816-4126; Sham, Chiu-Wing/0000-0001-7007-6746
FU National Natural Science Foun-dation of China; Fundamental Research
   Funds for the Central Universities; Natural Science Foundation of
   Ningxia Province; Natural Science Foundation of Liaoning Province; 
   [62032013];  [N2224001-7];  [N2116020];  [2022AAC03347];  [2021-YGJC-24]
FX Acknowledgments This research is supported by the National Natural
   Science Foun-dation of China (No. 62032013) , the Fundamental Research
   Funds for the Central Universities (Nos. N2224001-7 and N2116020) , the
   Natural Science Foundation of Ningxia Province (No. 2022AAC03347) , and
   the Natural Science Foundation of Liaoning Province (No. 2021-YGJC-24) .
CR Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen J., 2021, ARXIV
   Dai YC, 2023, ACM T SENSOR NETWORK, V19, DOI 10.1145/3522739
   Dai Z., 2021, ARXIV
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B, 2022, Arxiv, DOI arXiv:2108.06932
   Dong CY, 2021, I S BIOMED IMAGING, P645, DOI 10.1109/ISBI48211.2021.9433859
   Dosovitskiy A., 2021, PROC INT C LEARN REP
   Fan D.-P., 2021, SCI SIN INFORMATIONI, V6, DOI DOI 10.1360/SSI-2020-0370
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gao YH, 2021, LECT NOTES COMPUT SC, V12903, P61, DOI 10.1007/978-3-030-87199-4_6
   Graham B, 2021, Arxiv, DOI arXiv:2104.01136
   He BJ, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12822
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu KL, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105760
   Huang C.-H., 2021, ARXIV
   Iglovikov V, 2018, Arxiv, DOI arXiv:1801.05746
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji GP, 2021, Arxiv, DOI arXiv:2105.08468
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loshchilov I., 2018, P INT C LEARN REPR M
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Mehta S., 2022, INT C LEARNING REPRE
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Pan J, 2022, APPL INTELL, V52, P12457, DOI 10.1007/s10489-022-03274-0
   Patel K, 2021, Arxiv, DOI arXiv:2105.00999
   Poudel S, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107445
   Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155
   Ronneberger O., 2015, P INT C MED IM COMP
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song W, 2022, NEURAL COMPUT APPL, V34, P5743, DOI 10.1007/s00521-021-06725-w
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tang SY, 2021, J SUPERCOMPUT, V77, P3870, DOI 10.1007/s11227-020-03422-8
   Vaswani A, 2017, ADV NEUR IN, V30
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang WH, 2023, Arxiv, DOI arXiv:2106.13797
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu HP, 2021, Arxiv, DOI [arXiv:2103.15808, 10.1109/iccv48922.2021.00009]
   Wu HS, 2021, AAAI CONF ARTIF INTE, V35, P2916
   Wu Z., 2020, ARXIV200411886
   Wu ZD, 2021, J ORGAN END USER COM, V33, DOI 10.4018/JOEUC.292526
   Wu ZD, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105726
   Wu ZD, 2021, WORLD WIDE WEB, V24, P25, DOI 10.1007/s11280-020-00830-x
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Yan WH, 2020, WORLD WIDE WEB, V23, P3055, DOI 10.1007/s11280-020-00820-z
   Yin ZJ, 2022, Arxiv, DOI arXiv:2103.06725
   Yuan K, 2021, Arxiv, DOI arXiv:2103.11816
   Zhang WC, 2022, EXPERT SYST APPL, V202, DOI 10.1016/j.eswa.2022.117198
   Zhang WC, 2022, NEUROCOMPUTING, V499, P23, DOI 10.1016/j.neucom.2022.05.034
   Zhang WC, 2021, NEURAL COMPUT APPL, V33, P11627, DOI 10.1007/s00521-021-05867-1
   Zhang Y., 2021, ARXIV
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao YL, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105500
   Zhou DQ, 2021, Arxiv, DOI arXiv:2103.11886
   Zhou J, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5871684
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 66
TC 9
Z9 9
U1 8
U2 22
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD NOV
PY 2022
VL 150
AR 106173
DI 10.1016/j.compbiomed.2022.106173
EA OCT 2022
PG 10
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 5T1PJ
UT WOS:000875647400005
PM 36257278
DA 2023-08-21
ER

PT J
AU Chou, YC
   Chen, CC
AF Chou, Yung-Chien
   Chen, Chao-Chun
TI Improving deep learning-based polyp detection using feature extraction
   and data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colonoscopy; Polyps; Discrete wavelet transform; StyleGAN2; YOLOv4
ID MISS RATE; WAVELET; COLONOSCOPY; DIAGNOSIS; CLASSIFICATION;
   DECOMPOSITION; SYSTEM
AB In recent years, Colorectal Cancer (CRC) has been common reasons of lethal disease and cancer. However, colonoscopy can examine this disease, and the location of polyps and tumors can be detected. However, the early symptoms of CRC are not evident and specific, which is easy to be ignored by patients and doctors. As a result, the opportunity for early diagnosis and treatment was missed. This study aims to provide auxiliary detection to obtain accurate polyp diagnosis and assist clinicians in more precise detection. This paper proposes a novel polyp detection method through deep learning, which uses a fusion module combining feature extraction and data augmentation to enhance images. The Discrete Wavelet Transform (DWT) is applied to extract the texture features of polyps and strengthen the texture features that are not obvious in the polyp image. Then style-based GAN2 is used to enhance the image data, increase the image training data of YOLOv4, and let YOLOv4 learn more features of polyps. According to the experimental results, our method is better than state-of-the-art methods in polyp detection efficiency. In addition, because we have enhanced the image, the detection rate of small polyps is significantly improved.
C1 [Chou, Yung-Chien; Chen, Chao-Chun] Natl Cheng Kung Univ, Inst Mfg Informat & Syst, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Chen, CC (通讯作者)，Natl Cheng Kung Univ, Inst Mfg Informat & Syst, Tainan 701, Taiwan.
EM p98081069@gs.ncku.edu.tw; chaochun@mail.ncku.edu.tw
FU National Science and Technology Council (NSTC) of Taiwan [NSTC
   111-2221-E-006-202, 110-2221-E-006-124]; "Intelligent Manufacturing
   Research Center" (iMRC) from The Featured Areas Research Center Program
   within the Higher Education Sprout Project by the Ministry of Education
   in Taiwan
FX This work was supported by the National Science and Technology Council
   (NSTC) of Taiwan, under grants NSTC 111-2221-E-006-202 and
   110-2221-E-006-124. This work was also supported by the "Intelligent
   Manufacturing Research Center" (iMRC) from The Featured Areas Research
   Center Program within the framework of the Higher Education Sprout
   Project by the Ministry of Education in Taiwan.
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Billah M, 2020, MULTIMED TOOLS APPL, V79, P23633, DOI 10.1007/s11042-020-09151-7
   Bochkovskiy A., 2004, YOLOV4 OPTIMAL SPEED
   Cancer IAFRO, 2020, INT AG RES CANC
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Demirel H, 2011, IEEE T GEOSCI REMOTE, V49, P1997, DOI 10.1109/TGRS.2010.2100401
   Durak S, 2021, MED BIOL ENG COMPUT, V59, P1563, DOI 10.1007/s11517-021-02398-8
   Engelhardt S., 2010, BILDVERARBEITUNG MED, V574, P350
   Fetty L, 2020, Z MED PHYS, V30, P305, DOI 10.1016/j.zemedi.2020.05.001
   Fonolla R, 2021, ARTIF INTELL MED, V121, DOI 10.1016/j.artmed.2021.102178
   Gonzalez RC, 2008, DIGITAL IMAGE PROCES
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hasan M, 2022, MULTIMED TOOLS APPL, P1
   He WP, 2015, MECH SYST SIGNAL PR, V54-55, P457, DOI 10.1016/j.ymssp.2014.09.007
   Isola P., 2017, P COMP VIS PATT REC, P5967, DOI DOI 10.1109/CVPR.2017.632
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jiang GF, 2019, LECT NOTES COMPUT SC, V11769, P801, DOI 10.1007/978-3-030-32226-7_89
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karras T., 2020, P IEEECVF C COMPUTER, P8110
   Karras T., 2017, ARXIV PREPRINT ARXIV
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kim SH, 2021, MULTIMED TOOLS APPL, V80, P35941, DOI 10.1007/s11042-021-10551-6
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lee WL, 2003, IEEE T MED IMAGING, V22, P382, DOI 10.1109/TMI.2003.809593
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu DY, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1063-x
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Ozturk S, 2020, MULTIMED TOOLS APPL, V79, P28825, DOI 10.1007/s11042-020-09468-3
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Poorneshwaran JM, 2019, IEEE ENG MED BIO, P7201, DOI 10.1109/EMBC.2019.8857958
   Radford A., 2016, PROC 4 INT C LEARN R
   Rasti P, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P153, DOI 10.1109/SIU.2016.7495700
   REDMON J, 2016, PROC CVPR IEEE, P779, DOI DOI 10.1109/CVPR.2016.91
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rufai AM, 2014, DIGIT SIGNAL PROCESS, V24, P117, DOI 10.1016/j.dsp.2013.09.008
   Schoofs N, 2006, ENDOSCOPY, V38, P971, DOI 10.1055/s-2006-944835
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Thomaz VD, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101988
   Tulum G, 2017, INT J COMPUT ASS RAD, V12, P627, DOI 10.1007/s11548-017-1521-9
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   van Wijk C, 2010, IEEE T MED IMAGING, V29, P688, DOI 10.1109/TMI.2009.2031323
   Vazquez D, 2017, J HEALTHC ENG
   Velmurugan AK, 2013, 2013 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN ENGINEERING AND TECHNOLOGY (ICCTET), P213, DOI 10.1109/ICCTET.2013.6675949
   Vieira PM, 2021, ARTIF INTELL MED, V119, DOI 10.1016/j.artmed.2021.102141
   Wang TC, 1998, IEEE T MED IMAGING, V17, P498, DOI 10.1109/42.730395
   Wang WCV, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133661
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang TY, 2019, LECT NOTES COMPUT SC, V11767, P777, DOI 10.1007/978-3-030-32251-9_85
NR 72
TC 2
Z9 2
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16817
EP 16837
DI 10.1007/s11042-022-13995-6
EA OCT 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000869194800001
DA 2023-08-21
ER

PT J
AU Gilabert, P
   Vitria, J
   Laiz, P
   Malagelada, C
   Watson, A
   Wenzek, H
   Segui, S
AF Gilabert, Pere
   Vitria, Jordi
   Laiz, Pablo
   Malagelada, Carolina
   Watson, Angus
   Wenzek, Hagen
   Segui, Santi
TI Artificial intelligence to improve polyp detection and screening time in
   colon capsule endoscopy
SO FRONTIERS IN MEDICINE
LA English
DT Article
DE colon capsule endoscopy; artificial intelligence; screening time; polyp
   detection; colorectal cancer prevention
ID COLORECTAL-CANCER; FUTURE
AB Colon Capsule Endoscopy (CCE) is a minimally invasive procedure which is increasingly being used as an alternative to conventional colonoscopy. Videos recorded by the capsule cameras are long and require one or more experts' time to review and identify polyps or other potential intestinal problems that can lead to major health issues. We developed and tested a multi-platform web application, AI-Tool, which embeds a Convolution Neural Network (CNN) to help CCE reviewers. With the help of artificial intelligence, AI-Tool is able to detect images with high probability of containing a polyp and prioritize them during the reviewing process. With the collaboration of 3 experts that reviewed 18 videos, we compared the classical linear review method using RAPID Reader Software v9.0 and the new software we present. Applying the new strategy, reviewing time was reduced by a factor of 6 and polyp detection sensitivity was increased from 81.08 to 87.80%.
C1 [Gilabert, Pere; Vitria, Jordi; Laiz, Pablo; Segui, Santi] Univ Barcelona, Dept Matemat & Informat, Barcelona, Spain.
   [Malagelada, Carolina] Univ Hosp Vall dHebron, Digest Syst Res Unit, Barcelona, Spain.
   [Malagelada, Carolina] Univ Autonoma Barcelona, Dept Med, Barcelona, Spain.
   [Watson, Angus] NHS Highland, Dept Colorectal Surg, Raigmore Hosp, Inverness, Scotland.
   [Wenzek, Hagen] CorporateHlth Int ApS, Odense, Denmark.
C3 University of Barcelona; Hospital Universitari Vall d'Hebron; Autonomous
   University of Barcelona
RP Gilabert, P (通讯作者)，Univ Barcelona, Dept Matemat & Informat, Barcelona, Spain.
EM pere.gilabert@ub.edu; angus.watson@nhs.scot
RI Malagelada, Carolina/F-3743-2016; Segui, Santi/E-4860-2010
OI Malagelada, Carolina/0000-0001-7097-1492; Segui,
   Santi/0000-0002-8603-138X
CR Ahmad OF, 2020, TECH INNOVAT GASTROI, V22, P80, DOI 10.1016/j.tgie.2019.150636
   Ahmed M, 2020, GASTROENTEROL RES, V13, P1, DOI 10.14740/gr1239
   Aoki T, 2020, DIGEST ENDOSC, V32, P585, DOI 10.1111/den.13517
   Beg S, 2020, GASTROINTEST ENDOSC, V91, P1322, DOI 10.1016/j.gie.2020.01.026
   Bond JH, 2003, ENDOSCOPY, V35, P27, DOI 10.1055/s-2003-36410
   Byrne MF, 2019, GASTROINTEST ENDOSC, V89, P195, DOI 10.1016/j.gie.2018.08.017
   Zammit SC, 2021, EXPERT REV GASTROENT, V15, P127, DOI 10.1080/17474124.2021.1840351
   Farnbacher MJ, 2014, SCAND J GASTROENTERO, V49, P339, DOI 10.3109/00365521.2013.865784
   Goran L, 2018, WORLD J GASTRO ENDOS, V10, P184, DOI 10.4253/wjge.v10.i9.184
   Gunther U, 2012, INT J COLORECTAL DIS, V27, P521, DOI 10.1007/s00384-011-1347-9
   Guo XQ, 2019, LECT NOTES COMPUT SC, V11764, P293, DOI 10.1007/978-3-030-32239-7_33
   Hausmann J, 2019, INT J COLORECTAL DIS, V34, P1857, DOI 10.1007/s00384-019-03393-0
   Ismail MS, 2022, BMC GASTROENTEROL, V22, DOI 10.1186/s12876-021-02081-0
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   de Jonge L, 2021, LANCET GASTROENTEROL, V6, P304, DOI 10.1016/S2468-1253(21)00003-0
   Koulaouzidis A, 2021, THER ADV GASTROINTES, V14, DOI 10.1177/26317745211001983
   Laghi L, 2021, LANCET GASTROENTEROL, V6, P425, DOI 10.1016/S2468-1253(21)00098-4
   Laiz P, 2020, COMPUT MED IMAG GRAP, V86, DOI 10.1016/j.compmedimag.2020.101794
   Lauby-Secretan B, 2016, NEW ENGL J MED, V375, P794, DOI 10.1056/NEJMsr1606602
   Levin TR, 2018, GASTROENTEROLOGY, V155, P1383, DOI 10.1053/j.gastro.2018.07.017
   Loveday C, 2021, GUT, V70, P1053, DOI 10.1136/gutjnl-2020-321650
   Maieron A, 2004, ENDOSCOPY, V36, P864, DOI 10.1055/s-2004-825852
   Mascarenhas M, 2022, ENDOSC INT OPEN, V10, pE171, DOI 10.1055/a-1675-1941
   Muehlematter UJ, 2021, LANCET DIGIT HEALTH, V3, pE195, DOI 10.1016/S2589-7500(20)30292-2
   Noorda R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74668-8
   O'Sullivan DE, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76294-w
   Rahim T, 2020, COMPUT MED IMAG GRAP, V85, DOI 10.1016/j.compmedimag.2020.101767
   Rondonotti E, 2020, ENDOSC INT OPEN, V08, pE1220, DOI 10.1055/a-1210-4830
   Saurin JC, 2016, CLIN ENDOSC, V49, P26, DOI 10.5946/ce.2016.49.1.26
   Shiotani A, 2012, J CLIN GASTROENTEROL, V46, pE92, DOI 10.1097/MCG.0b013e31824fff94
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Valle L, 2014, WORLD J GASTROENTERO, V20, P9828, DOI 10.3748/wjg.v20.i29.9828
   Vuik FER, 2021, ENDOSCOPY, V53, P815, DOI 10.1055/a-1308-1297
   Yang YJ, 2020, CLIN ENDOSC, V53, P387, DOI 10.5946/ce.2020.133
   Ye PF, 2020, CANCERS, V12, DOI 10.3390/cancers12061408
   Yuan YX, 2020, IEEE T AUTOM SCI ENG, V17, P574, DOI 10.1109/TASE.2019.2936645
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 39
TC 2
Z9 2
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-858X
J9 FRONT MED-LAUSANNE
JI Front. Med.
PD OCT 13
PY 2022
VL 9
AR 1000726
DI 10.3389/fmed.2022.1000726
PG 8
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 5T2PO
UT WOS:000875715500001
PM 36314009
OA Green Submitted, Green Published, gold
DA 2023-08-21
ER

PT J
AU Sushama, G
   Menon, GC
AF Sushama, Geetha
   Menon, Gopakumar Chandrasekhara
TI Attention augmented residual autoencoder for efficient polyp
   segmentation
SO INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE attention module; autoencoder; colon polyps; residual skip-connected
   CNN; semantic segmentation
ID MEDICAL IMAGE SEGMENTATION
AB Colon cancer has been reported to be one of the frequently diagnosed cancers and the leading cause of cancer deaths. Early detection and removal of malicious polyps, which are precursors of colon cancer, can enormously lessen the fatality rate. The detection and segmentation of polyps in colonoscopy is a challenging task even for an experienced colonoscopist, due to divergences in the size, shape, texture, and the close resemblance of polyps with the colon lining. Machine-assisted detection, localization, and segmentation of polyps in the screening procedure can profoundly help the clinicians. Autoencoder-based architectures used in polyp segmentation lack the efficiency in incorporating both local and long-range pixel dependencies. To address the challenges in the automatic segmentation of colon polyps we propose an autoencoder architecture, augmented with a feature attention module in the decoder part. The salient features from RGB colonoscopic images are extracted using the residual skip-connected autoencoder. The decoder attention module joins spatial subspace with feature subspace extracted from the deep residual convolutional neural network and enhances the feature weight for precise segmentation of polyp regions. Extensive experiments on four publicly available polyp datasets demonstrate that the proposed architecture provides very impressive performance in terms of segmentation metrics (Dice scores and Jaccard scores) when compared with the state-of-the-art polyp segmentation approaches.
C1 [Sushama, Geetha] Coll Engn Chengannur, Dept Comp Sci & Engn, Alappuzha, India.
   [Sushama, Geetha; Menon, Gopakumar Chandrasekhara] Coll Engn Karunagappally, Dept Elect & Commun Engn, Kollam, India.
   [Sushama, Geetha; Menon, Gopakumar Chandrasekhara] APJ Abdul Kalam Technol Univ, Thiruvananthapuram, Kerala, India.
RP Menon, GC (通讯作者)，Coll Engn Karunagappally, Dept Elect & Commun Engn, Kollam, India.
EM gopan@ceknpy.ac.in
RI S, GEETHA/HTS-1161-2023
OI Chandrasekhara Menon, Gopakumar/0000-0002-8913-8991
CR Amirul Islam M., 2018, ARXIV
   Awais M, 2021, IEEE T NEUR NET LEAR, V32, P5082, DOI 10.1109/TNNLS.2020.3026784
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jacob C, 2022, INT J IMAG SYST TECH, V32, P1681, DOI 10.1002/ima.22684
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karimi D, 2021, ARTIF INTELL MED, V116, DOI 10.1016/j.artmed.2021.102078
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kingma D., 2015, ARXIV
   Kutty SK, 2022, INT J IMAG SYST TECH, V32, P1916, DOI 10.1002/ima.22740
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu SY, 2022, INT J INTELL SYST, V37, P1572, DOI 10.1002/int.22686
   Lu SY, 2021, NEURAL COMPUT APPL, V33, P10799, DOI 10.1007/s00521-020-05082-4
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oktay O., 2018, P MIDL, P1, DOI DOI 10.48550/ARXIV.1804.03999
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabeena K, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103288
   Sarvamangala DR, 2022, EVOL INTELL, V15, P1, DOI 10.1007/s12065-020-00540-3
   Sathyan RR, 2022, INT J IMAG SYST TECH, V32, P2017, DOI 10.1002/ima.22741
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Torr, 2018, ARXIV PREPRINT ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GT, 2019, NEUROCOMPUTING, V338, P34, DOI 10.1016/j.neucom.2019.01.103
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wei JW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40041-7
   Williams, 2009, COLONOSCOPY PRINCIPL, P537
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 41
TC 0
Z9 0
U1 18
U2 28
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-9457
EI 1098-1098
J9 INT J IMAG SYST TECH
JI Int. J. Imaging Syst. Technol.
PD MAR
PY 2023
VL 33
IS 2
BP 701
EP 713
DI 10.1002/ima.22814
EA OCT 2022
PG 13
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA 9O0AE
UT WOS:000865767400001
DA 2023-08-21
ER

PT J
AU Cui, RS
   Yang, RZ
   Liu, F
   Cai, CQ
AF Cui, Rongsheng
   Yang, Runzhuo
   Liu, Feng
   Cai, Chunqian
TI N-Net: Lesion region segmentations using the generalized hybrid dilated
   convolutions for polyps in colonoscopy images
SO FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY
LA English
DT Article
DE N-shape deep neural network; generalized hybrid dilated convolution;
   colonoscopy; colorectal polyp identification; lesion region
   segmentation; deep learning
AB Colorectal cancer is the cancer with the second highest and the third highest incidence rates for the female and the male, respectively. Colorectal polyps are potential prognostic indicators of colorectal cancer, and colonoscopy is the gold standard for the biopsy and the removal of colorectal polyps. In this scenario, one of the main concerns is to ensure the accuracy of lesion region identifications. However, the missing rate of polyps through manual observations in colonoscopy can reach 14%-30%. In this paper, we focus on the identifications of polyps in clinical colonoscopy images and propose a new N-shaped deep neural network (N-Net) structure to conduct the lesion region segmentations. The encoder-decoder framework is adopted in the N-Net structure and the DenseNet modules are implemented in the encoding path of the network. Moreover, we innovatively propose the strategy to design the generalized hybrid dilated convolution (GHDC), which enables flexible dilated rates and convolutional kernel sizes, to facilitate the transmission of the multi-scale information with the respective fields expanded. Based on the strategy of GHDC designing, we design four GHDC blocks to connect the encoding and the decoding paths. Through the experiments on two publicly available datasets on polyp segmentations of colonoscopy images: the Kvasir-SEG dataset and the CVC-ClinicDB dataset, the rationality and superiority of the proposed GHDC blocks and the proposed N-Net are verified. Through the comparative studies with the state-of-the-art methods, such as TransU-Net, DeepLabV3+ and CA-Net, we show that even with a small amount of network parameters, the N-Net outperforms with the Dice of 94.45%, the average symmetric surface distance (ASSD) of 0.38 pix and the mean intersection-over-union (mIoU) of 89.80% on the Kvasir-SEG dataset, and with the Dice of 97.03%, the ASSD of 0.16 pix and the mIoU of 94.35% on the CVC-ClinicDB dataset.
C1 [Cui, Rongsheng; Yang, Runzhuo; Liu, Feng] Nankai Univ, Coll Elect Informat & Opt Engn, Tianjin, Peoples R China.
   [Liu, Feng] Nankai Univ, Tianjin Key Lab Optoelect Sensor & Sensing Network, Tianjin, Peoples R China.
   [Cai, Chunqian] Tianjin Univ Tradit Chinese Med, Teaching Hosp 1, Tianjin, Peoples R China.
   [Cai, Chunqian] Natl Clin Res Ctr Chinese Med Acupuncture & Moxibu, Tianjin, Peoples R China.
C3 Nankai University; Nankai University; Tianjin University of Traditional
   Chinese Medicine
RP Liu, F (通讯作者)，Nankai Univ, Coll Elect Informat & Opt Engn, Tianjin, Peoples R China.; Liu, F (通讯作者)，Nankai Univ, Tianjin Key Lab Optoelect Sensor & Sensing Network, Tianjin, Peoples R China.
EM liuf@nankai.edu.cn
RI Cui, Rongsheng/GZA-6965-2022
FU National Natural Science Foundation of China; Natural Science Foundation
   of Tianjin City of Peoples Republic of China;  [61901233]; 
   [19JCQNJC00900]
FX Funding This work was supported by the National Natural Science
   Foundation of China (grant no. 61901233) and the Natural Science
   Foundation of Tianjin City of Peoples Republic of China (grant no.
   19JCQNJC00900).
CR Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen J., 2021, ARXIV
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen WM, 2020, IEEE T MED IMAGING, V39, P1582, DOI 10.1109/TMI.2019.2953626
   Fu XR, 2019, IEEE ACCESS, V7, P148645, DOI 10.1109/ACCESS.2019.2946582
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   He BS, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00737
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/icassp40776.2020.9053405, 10.1109/ICASSP40776.2020.9053405]
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Kingma D., 2015, ARXIV
   Li KD, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255809
   Pereira AAL, 2020, CLIN COLORECTAL CANC, V19, pE264, DOI 10.1016/j.clcc.2020.06.004
   Liu JF, 2020, IEEE J BIOMED HEALTH, V24, P3520, DOI 10.1109/JBHI.2020.3004271
   Ma YJ, 2022, IEEE T MULTIMEDIA, V24, P261, DOI 10.1109/TMM.2021.3050059
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   PIBAdb, 2022, COL POL IM COH
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Ren YC, 2019, IEEE J BIOMED HEALTH, V23, P324, DOI 10.1109/JBHI.2018.2808199
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rozo A, 2022, FRONT BIOENG BIOTECH, V10, DOI 10.3389/fbioe.2022.806761
   Rundle AG, 2008, GASTROENTEROLOGY, V134, P1311, DOI 10.1053/j.gastro.2008.02.032
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Sasmal P, 2018, INT CONF CIRC SYST S, P201, DOI 10.1109/ICSIGSYS.2018.8372666
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Sun ZJ, 2016, IEEE COMMUN LETT, V20, P622, DOI 10.1109/LCOMM.2016.2518662
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tan JX, 2020, IEEE T MED IMAGING, V39, P2013, DOI 10.1109/TMI.2019.2963177
   Torre LA, 2015, CA-CANCER J CLIN, V65, P87, DOI 10.3322/caac.21262
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   van Toledo DEFWM, 2022, LANCET GASTROENTEROL, V7, P747, DOI 10.1016/S2468-1253(22)00090-5
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Alom MZ, 2018, Arxiv, DOI arXiv:1802.06955
   Zhang QL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2235, DOI 10.1109/ICASSP39728.2021.9414568
   Zhou LC, 2018, IEEE COMPUT SOC CONF, P192, DOI 10.1109/CVPRW.2018.00034
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 41
TC 0
Z9 0
U1 5
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-4185
J9 FRONT BIOENG BIOTECH
JI Front. Bioeng. Biotechnol.
PD OCT 7
PY 2022
VL 10
AR 963590
DI 10.3389/fbioe.2022.963590
PG 15
WC Biotechnology & Applied Microbiology; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Science & Technology - Other
   Topics
GA 5R5DJ
UT WOS:000874530800001
PM 36277395
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Puyal, JGB
   Brandao, P
   Ahmad, OF
   Bhatia, KK
   Toth, D
   Kader, R
   Lovat, L
   Mountney, P
   Stoyanov, D
AF Puyal, Juana Gonzalez-Bueno
   Brandao, Patrick
   Ahmad, Omer F.
   Bhatia, Kanwal K.
   Toth, Daniel
   Kader, Rawen
   Lovat, Laurence
   Mountney, Peter
   Stoyanov, Danail
TI Polyp detection on video colonoscopy using a hybrid 2D/3D CNN
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Colonoscopy; Polyp segmentation; Computer aided diagnosis; Temporal
   segmentation
ID ARTIFICIAL-INTELLIGENCE; COLORECTAL-CANCER; ADENOMA DETECTION; MISS
   RATE; VALIDATION
AB Colonoscopy is the gold standard for early diagnosis and pre-emptive treatment of colorectal cancer by detecting and removing colonic polyps. Deep learning approaches to polyp detection have shown potential for enhancing polyp detection rates. However, the majority of these systems are developed and evaluated on static images from colonoscopies, whilst in clinical practice the treatment is performed on a real-time video feed. Non-curated video data remains a challenge, as it contains low-quality frames when compared to still, selected images often obtained from diagnostic records. Nevertheless, it also embeds temporal information that can be exploited to increase predictions stability. A hybrid 2D/3D convolutional neural network architecture for polyp segmentation is presented in this paper. The network is used to improve polyp detection by encompassing spatial and temporal correlation of the predictions while preserving real-time detections. Extensive experiments show that the hybrid method outperforms a 2D baseline. The proposed architecture is validated on videos from 46 patients and on the publicly available SUN polyp database. A higher performance and increased generalisability indicate that real-world clinical implementations of automated polyp detection can benefit from the hybrid algorithm and the inclusion of temporal information.
C1 [Puyal, Juana Gonzalez-Bueno; Ahmad, Omer F.; Kader, Rawen; Lovat, Laurence; Stoyanov, Danail] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London W1W 7TY, England.
   [Puyal, Juana Gonzalez-Bueno; Brandao, Patrick; Bhatia, Kanwal K.; Toth, Daniel; Mountney, Peter] Odin Vis, London W1W 7TY, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London
RP Puyal, JGB (通讯作者)，UCL, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London W1W 7TY, England.
EM j.puyal@ucl.ac.uk
RI Lovat, Laurence/C-1986-2009; Kader, Rawen/ABI-2203-2020
OI Lovat, Laurence/0000-0003-4542-3915; Kader, Rawen/0000-0001-9133-0838
FU Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS),
   UK [203145Z/16/Z]; Engineering and Physical Sciences Research Council
   (EPSRC), UK [EP/P027938/1, EP/R004080/1, EP/P012841/1]; Royal Academy of
   Engineering, UK [CiET1819 \2\36]; European Union's Horizon 2020 research
   and innovation programme [863146]; European Space Agency, France
FX This research was funded in whole, or in part, by the Wellcome/EPSRC
   Centre for Interventional and Surgical Sciences (WEISS), UK
   [203145Z/16/Z]; Engineering and Physical Sciences Research Council
   (EPSRC), UK [EP/P027938/1, EP/R004080/1, EP/P012841/1]; The Royal
   Academy of Engineering, UK [CiET1819 \2\36]; For the purpose of open
   access, the author has applied a CC BY public copyright licence to any
   author accepted manuscript version arising from this submission.
   European Union's Horizon 2020 research and innovation programme under
   grant agreement No 863146; Work carried out under a programme of and
   funded by the European Space Agency, France, the view expressed herein
   can in no way be taken to reflect the official opinion of the European
   Space Agency.
CR Ahmad OF, 2020, TECH INNOVAT GASTROI, V22, P80, DOI 10.1016/j.tgie.2019.150636
   Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Armin MA, 2018, LECT NOTES COMPUT SC, V11041, P108, DOI 10.1007/978-3-030-01201-4_13
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chahal D, 2020, GASTROINTEST ENDOSC, V92, P813, DOI 10.1016/j.gie.2020.04.074
   Cheng K, 2021, LECT NOTES COMPUT SC, V12906, P119, DOI 10.1007/978-3-030-87231-1_12
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Eelbode T, 2019, GASTROINTEST ENDOSC, V89, pAB618, DOI 10.1016/j.gie.2019.03.1075
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Itoh H, 2021, INT J COMPUT ASS RAD, V16, P989, DOI 10.1007/s11548-021-02398-x
   Itoh H, 2019, HEALTHC TECHNOL LETT, V6, P237, DOI 10.1049/htl.2019.0079
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Liu XT, 2018, LECT NOTES COMPUT SC, V11041, P128, DOI 10.1007/978-3-030-01201-4_15
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   Ma M, 2020, I S BIOMED IMAGING, P1360, DOI 10.1109/ISBI45749.2020.9098663
   Mathew S, 2020, PROC CVPR IEEE, P4695, DOI [10.1109/cvpr42600.2020.00475, 10.1109/CVPR42600.2020.00475]
   Medical P, 2019, HOYA GROUP PENTAX ME
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Odin Vision, 2020, CADDIE NEW ER EN END
   Podlasek J, 2021, ENDOSC INT OPEN, V09, pE741, DOI 10.1055/a-1388-6735
   Poon CCY, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0281-z
   Puyal Juana Gonzalez-Bueno, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P295, DOI 10.1007/978-3-030-59725-2_29
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2009, AM J GASTROENTEROL, V104, P739, DOI 10.1038/ajg.2009.104
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang P, 2018, GASTROINTEST ENDOSC, V87, pAB490
   Weigt J., 2020, Z GASTROENTEROL, V58, pP
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang PF, 2019, PROC INT C TOOLS ART, P1252, DOI 10.1109/ICTAI.2019.00-93
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 46
TC 6
Z9 6
U1 11
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD NOV
PY 2022
VL 82
AR 102625
DI 10.1016/j.media.2022.102625
EA OCT 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA 5I6UQ
UT WOS:000868489600001
PM 36209637
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Chen, WT
   Liu, YF
   Hu, JC
   Yuan, YX
AF Chen, Wenting
   Liu, Yifan
   Hu, Jiancong
   Yuan, Yixuan
TI Dynamic Depth-Aware Network for Endoscopy Super-Resolution
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Feature extraction; Endoscopes; Cancer; Superresolution; Deep learning;
   Task analysis; Three-dimensional displays; Endoscopy; super-resolution;
   depth information; polyp segmentation
AB Endoscopy super-resolution (SR) plays an important role in improving diagnostic results and reducing the misdiagnosis rate. Even though recent studies have investigated the SR for endoscopy, these methods apply equal importance to the whole image and do not consider the relationship among pixels, especially the depth information, which can provide diagnosis-related information for clinicians. To address this problem, we propose a dynamic depth-aware network for endoscopy super-resolution, which represents the first effort to comprehensively integrate the depth information to the SR task for endoscopic images. It includes a depth-wise feature extracting branch (DW-B) and a depth-guided SR branch (DGSR-B). The DW-B aims to extract the representative feature for each depth level (i.e. depth matrix) further to provide auxiliary information and guide the super-resolution of texture under different depth levels. In DGSR-B, a depth-guided block (DGB) consisting of depth-focus normalization (DFN) is introduced to inject both the depth matrix and depth map into the LR image feature, so as to guide the image generation for each depth region. To adaptively super-resolve the regions under different depth levels, we devise a dynamic depth-aware loss to assign different trainable weights to each region for SR optimization. Extensive experiments have been conducted on two main publicly available datasets, i.e., the Kvasir dataset and the EndoScene dataset, and the superior performance verifies the effectiveness of our method for SR task and polyp segmentation. Source code is to be released.
C1 [Chen, Wenting; Liu, Yifan; Yuan, Yixuan] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Yuan, Yixuan] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
   [Hu, Jiancong] Sun Yat Sen Univ, Affiliated Hosp 6, Dept Endoscop Surg, Guangzhou, Peoples R China.
C3 City University of Hong Kong; City University of Hong Kong; Shenzhen
   Research Institute, City University of Hong Kong; Sun Yat Sen University
RP Yuan, YX (通讯作者)，City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.; Yuan, YX (通讯作者)，City Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
EM wentichen7-c@my.cityu.edu.hk; yifliu3-c@my.cityu.edu.hk;
   hujianc@mail.sysu.edu.cn; yxyuan.ee@cityu.edu.hk
RI Hu, Jiancong/HLW-0576-2023
OI Chen, Wenting/0000-0002-7457-9540; Liu, Yifan/0000-0001-9342-9428; Yuan,
   Yixuan/0000-0002-0853-6948
FU National Natural Science Foundation of China [62001410]; Hong Kong
   Research Grants Council (RGC) [21207420 (CityU 9048179)]; Hong Kong RGC
   Collaborative Research Fund [C4063-18G (CityU 8739029)]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62001410, in part by Hong Kong Research
   Grants Council (RGC) Early Career Scheme under Grant 21207420 (CityU
   9048179), and in aprt by Hong Kong RGC Collaborative Research Fund under
   Grant C4063-18G (CityU 8739029).
CR Almalioglu Y, 2020, IEEE T MED IMAGING, V39, P4297, DOI 10.1109/TMI.2020.3016744
   Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12
   Bressler B, 2007, GASTROENTEROLOGY, V132, P96, DOI 10.1053/j.gastro.2006.10.027
   Chen WT, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2021.102340
   Chen Z, 2021, IEEE T MED IMAGING, V40, P1377, DOI 10.1109/TMI.2021.3055290
   Daneshpajooh V., 2021, MED IMAGE ANAL INT S, V11596, P585
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Duda K, 2008, ICSES 2008 INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS, CONFERENCE PROCEEDINGS, P197, DOI 10.1109/ICSES.2008.4673391
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Hafner M, 2013, COMP MED SY, P185, DOI 10.1109/CBMS.2013.6627786
   Hu XC, 2019, PROC CVPR IEEE, P1575, DOI 10.1109/CVPR.2019.00167
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Kingma D., 2015, ARXIV
   Kohler T, 2013, LECT NOTES COMPUT SC, V8149, P139, DOI 10.1007/978-3-642-40811-3_18
   Kong XT, 2021, PROC CVPR IEEE, P12011, DOI 10.1109/CVPR46437.2021.01184
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li L, 2021, IEEE T IND INFORM, V17, P3920, DOI 10.1109/TII.2020.3011067
   Liu J, 2022, IEEE T MED IMAGING, V41, P715, DOI 10.1109/TMI.2021.3121138
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Mcleod J., 2021, ARXIV
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Park J, 2019, CLIN ENDOSC, V52, P328, DOI 10.5946/ce.2018.172
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Recasens D, 2021, IEEE ROBOT AUTOM LET, V6, P7225, DOI 10.1109/LRA.2021.3095528
   Rupp S, 2007, P ANN INT IEEE EMBS, P6566
   Salimans T, 2016, ADV NEUR IN, V29
   Shamsolmoali P, 2019, NEUROCOMPUTING, V366, P140, DOI 10.1016/j.neucom.2019.07.094
   Shao SW, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2021.102338
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Son S, 2021, PROC CVPR IEEE, P7778, DOI 10.1109/CVPR46437.2021.00769
   Song DH, 2021, PROC CVPR IEEE, P15643, DOI 10.1109/CVPR46437.2021.01539
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Vu T, 2019, LECT NOTES COMPUT SC, V11133, P243, DOI 10.1007/978-3-030-11021-5_16
   Wang Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P595, DOI 10.1109/ICDSP.2015.7251943
   Wang YQ, 2021, IEEE T IMAGE PROCESS, V30, P1057, DOI 10.1109/TIP.2020.3042059
   Wenting Chen, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P616, DOI 10.1007/978-3-030-59722-1_59
   Yang XR, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTER ENGINEERING (ICAICE 2020), P168, DOI 10.1109/ICAICE51518.2020.00039
   Yu J., 2019, P BMVC
   Yuan YX, 2018, LECT NOTES COMPUT SC, V11071, P620, DOI 10.1007/978-3-030-00934-2_69
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang Tianyi, 2020, Arxiv, DOI arXiv:2003.08539
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhen Chen, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P184, DOI 10.1007/978-3-030-59722-1_18
NR 51
TC 1
Z9 1
U1 3
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD OCT
PY 2022
VL 26
IS 10
BP 5189
EP 5200
DI 10.1109/JBHI.2022.3188878
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA 5C3WS
UT WOS:000864195200042
PM 35793305
DA 2023-08-21
ER

PT J
AU Selnes, O
   Bjorsum-Meyer, T
   Histace, A
   Baatrup, G
   Koulaouzidis, A
AF Selnes, Ola
   Bjorsum-Meyer, Thomas
   Histace, Aymeric
   Baatrup, Gunnar
   Koulaouzidis, Anastasios
TI Annotation Tools in Gastrointestinal Polyp Annotation
SO DIAGNOSTICS
LA English
DT Review
DE annotation tool; polyp annotation; automated labelling; camera capsule
   endoscopy; computer-aided diagnosis
ID CAPSULE ENDOSCOPY; SOFTWARE
AB Capsule endoscopy (CE) is a valid alternative to conventional gastrointestinal (GI) endoscopy tools. In CE, annotation tools are crucial in developing large and annotated medical image databases for training deep neural networks (DNN). We provide an overview of the described and in-use various annotation systems available, focusing on the annotation of adenomatous polyp pathology in the GI tract. Some studies present promising results regarding time efficiency by implementing automated labelling features in annotation systems. Thus, data are inadequate regarding the general overview for users, and may also be more specific on which features provided are necessary for polyp annotation.
C1 [Selnes, Ola; Bjorsum-Meyer, Thomas; Baatrup, Gunnar; Koulaouzidis, Anastasios] Odense Univ Hosp, Dept Surg, DK-5700 Svendborg, Denmark.
   [Bjorsum-Meyer, Thomas; Baatrup, Gunnar; Koulaouzidis, Anastasios] Univ Southern Denmark, Dept Clin Res, DK-5000 Odense C, Denmark.
   [Histace, Aymeric] CY Paris Cergy Univ, CNRS, ENSEA, ETIS UMR 8051, F-95000 Cergy, France.
C3 University of Southern Denmark; Odense University Hospital; University
   of Southern Denmark; Centre National de la Recherche Scientifique
   (CNRS); CY Cergy Paris Universite
RP Selnes, O; Koulaouzidis, A (通讯作者)，Odense Univ Hosp, Dept Surg, DK-5700 Svendborg, Denmark.; Koulaouzidis, A (通讯作者)，Univ Southern Denmark, Dept Clin Res, DK-5000 Odense C, Denmark.
EM ola.selnes@rsyd.dk; akoulaouzidis@hotmail.com
OI baatrup, gunnar/0000-0003-0300-5766; HISTACE,
   Aymeric/0000-0002-3029-4412; Koulaouzidis,
   Anastasios/0000-0002-2248-489X
CR Akpunonu B, 2022, CLEV CLIN J MED, V89, P200, DOI 10.3949/ccjm.89a.20061
   Albisser Z., 2015, P 6 ACM MULTIMEDIA S
   [Anonymous], 2022, ENCORD ENDCORD
   [Anonymous], 2021, CORD CONTINUES RECOR
   Bernal J, 2019, INT J COMPUT ASS RAD, V14, P191, DOI 10.1007/s11548-018-1864-x
   Bjorsum-Meyer T, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11091671
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Guo XQ, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101733
   Hansen US, 2021, ENDOSC INT OPEN, V09, pE621, DOI 10.1055/a-1341-0689
   Hosoe N, 2019, DIGEST ENDOSC, V31, P498, DOI 10.1111/den.13346
   Iakovidis DK, 2014, SCI WORLD J, DOI 10.1155/2014/286856
   Iakovidis D. K., 2011, 2011 Proceedings of IEEE International Conference on Imaging Systems and Techniques (IST 2011), P146, DOI 10.1109/IST.2011.5962190
   Kjolhede T, 2021, ENDOSCOPY, V53, P713, DOI 10.1055/a-1249-3938
   Kobaek-Larsen M, 2018, COLORECTAL DIS, V20, P479, DOI 10.1111/codi.13965
   Krenzer A, 2022, BIOMED ENG ONLINE, V21, DOI 10.1186/s12938-022-01001-x
   Liu D, 2007, COMPUT METH PROG BIO, V88, P152, DOI 10.1016/j.cmpb.2007.07.011
   Mahmood F, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aada93
   Mary T, 2019, INTEL NEW COMPUTER V
   MathWorks T, 2022, GET START IM LAB
   Plumb T., ENCORD TACKLES GROWI
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Riegler M, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3079765
   Sekachev B., 2019, INTEL
   Solawetz J, ROBOFLOW
   Torralba A, 2010, P IEEE, V98, P1467, DOI 10.1109/JPROC.2010.2050290
   Wiggers K., 2021, CORD RAISES 4 5 M AU
NR 26
TC 0
Z9 0
U1 3
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD OCT
PY 2022
VL 12
IS 10
AR 2324
DI 10.3390/diagnostics12102324
PG 10
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 5O5MM
UT WOS:000872517300001
PM 36292013
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Rao, HB
   Sastry, NB
   Venu, RP
   Pattanayak, P
AF Rao, Harshavardhan B. B.
   Sastry, Nandakumar Bidare
   Venu, Rama P.
   Pattanayak, Preetiparna
TI The role of artificial intelligence based systems for cost optimization
   in colorectal cancer prevention programs
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
LA English
DT Review
DE artificial intelligence; colorectal (colon) cancer; colonoscopy;
   screening; cost-benefit; cost-effect analysis
ID COMPUTER-AIDED DETECTION; MISS RATE; ADENOMA DETECTION; POLYPS;
   CLASSIFICATION; COLONOSCOPY; EPIDEMIOLOGY; MORTALITY; HISTOLOGY; VISION
AB Colorectal Cancer (CRC) has seen a dramatic increase in incidence globally. In 2019, colorectal cancer accounted for 1.15 million deaths and 24.28 million disability-adjusted life-years (DALYs) worldwide. In India, the annual incidence rates (AARs) for colon cancer was 4.4 per 100,000. There has been a steady rise in the prevalence of CRC in India which may be attributed to urbanization, mass migration of population, westernization of diet and lifestyle practices and a rise of obesity and metabolic risk factors that place the population at a higher risk of CRC. Moreoever, CRC in India differs from that described in the Western countries, with a higher proportion of young patients and more patients presenting with an advanced stage. This may be due to poor access to specialized healthcare and socio-economic factors. Early identification of adenomatous colonic polyps, which are well-recognized pre-cancerous lesions, at the time of screening colonoscopy has been shown to be the most effective measure used for CRC prevention. However, colonic polyps are frequently missed during colonoscopy and moreover, these screening programs necessitate man-power, time and resources for processing resected polyps, that may hamper penetration and efficacy in mid- to low-income countries. In the last decade, there has been significant progress made in the automatic detection of colonic polyps by multiple AI-based systems. With the advent of better AI methodology, the focus has shifted from mere detection to accurate discrimination and diagnosis of colonic polyps. These systems, once validated, could usher in a new era in Colorectal Cancer (CRC) prevention programs which would center around "Leave in-situ" and "Resect and discard" strategies. These new strategies hinge around the specificity and accuracy of AI based systems in correctly identifying the pathological diagnosis of the polyps, thereby providing the endoscopist with real-time information in order to make a clinical decision of either leaving the lesion in-situ (mucosal polyps) or resecting and discarding the polyp (hyperplastic polyps). The major advantage of employing these strategies would be in cost optimization of CRC prevention programs while ensuring good clinical outcomes. The adoption of these AI-based systems in the national cancer prevention program of India in accordance with the mandate to increase technology integration could prove to be cost-effective and enable implementation of CRC prevention programs at the population level. This level of penetration could potentially reduce the incidence of CRC and improve patient survival by enabling early diagnosis and treatment. In this review, we will highlight key advancements made in the field of AI in the identification of polyps during colonoscopy and explore the role of AI based systems in cost optimization during the universal implementation of CRC prevention programs in the context of mid-income countries like India.
C1 [Rao, Harshavardhan B. B.; Sastry, Nandakumar Bidare; Pattanayak, Preetiparna] Ramaiah Univ Appl Sci, MS Ramaiah Med Coll, Dept Gastroenterol, Bangalore, Karnataka, India.
   [Venu, Rama P.] Amrita Inst Med Sci & Res Ctr, Dept Gastroenterol, Kochi, Kerala, India.
C3 M. S. Ramaiah University of Applied Sciences; Amrita Vishwa
   Vidyapeetham; Amrita Vishwa Vidyapeetham Kochi
RP Rao, HB (通讯作者)，Ramaiah Univ Appl Sci, MS Ramaiah Med Coll, Dept Gastroenterol, Bangalore, Karnataka, India.
EM harshavardhanrao1985@gmail.com
OI BIDARE SASTRY, NANDA KUMAR/0000-0001-8644-3395
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Aran V, 2016, CLIN COLORECTAL CANC, V15, P195, DOI 10.1016/j.clcc.2016.02.008
   Areia M, 2022, LANCET DIGIT HEALTH, V4, pE436, DOI 10.1016/S2589-7500(22)00042-5
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Attardo S, 2020, WORLD J GASTROENTERO, V26, P5606, DOI 10.3748/wjg.v26.i37.5606
   Awedew AF, 2022, BMC GASTROENTEROL, V22, DOI 10.1186/s12876-022-02275-0
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Colditz GA, 2012, ANNU REV PUBL HEALTH, V33, P137, DOI 10.1146/annurev-publhealth-031811-124627
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Moor JS, 2018, PREV MED, V112, P199, DOI 10.1016/j.ypmed.2018.05.001
   Deng YH, 2017, CURR TREAT OPTION ON, V18, DOI 10.1007/s11864-017-0500-2
   Dolatkhah R, 2015, J CANCER EPIDEMIOL, V2015, DOI 10.1155/2015/643020
   Farkkila N, 2015, ACTA ONCOL, V54, P454, DOI 10.3109/0284186X.2014.985797
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jahn B, 2019, BMC GASTROENTEROL, V19, DOI 10.1186/s12876-019-1121-y
   Jansman FGA, 2007, PHARMACOECONOMICS, V25, P537, DOI 10.2165/00019053-200725070-00002
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Khuhaprema T, 2008, JPN J CLIN ONCOL, V38, P237, DOI 10.1093/jjco/hyn020
   Kolligs FT, 2016, VISC MED, V32, P158, DOI 10.1159/000446488
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Leslie A, 2002, BRIT J SURG, V89, P845, DOI 10.1046/j.1365-2168.2002.02120.x
   Lin JS, 2016, JAMA-J AM MED ASSOC, V315, P2576, DOI 10.1001/jama.2016.3332
   Mahal A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071853
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Marley AR, 2016, INT J MOL EPIDEMIOL, V7, P105
   Mattiuzzi C, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2019.07.91
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   National Institute for Health Clinical Excellence, 2017, VIRT CHROM VIRT CHRO
   Onyoh Elias F, 2019, Curr Gastroenterol Rep, V21, P36, DOI 10.1007/s11894-019-0703-8
   Ouakrim DA, 2015, BMJ-BRIT MED J, V351, DOI 10.1136/bmj.h4970
   Rahman MM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056873
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   S Shakuntala T, 2022, Asian Pac J Cancer Prev, V23, P409, DOI 10.31557/APJCP.2022.23.2.409
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Senore C, 2019, J MED SCREEN, V26, P76, DOI 10.1177/0969141318789710
   Shaukat A, 2013, NEW ENGL J MED, V369, P1106, DOI 10.1056/NEJMoa1300720
   Spolverato G, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.620644
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Tangka Florence K L, 2008, Prev Chronic Dis, V5, pA47
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vahdatimanesh Zahra, 2017, Med J Islam Repub Iran, V31, P115, DOI 10.14196/mjiri.31.115
   van der Sommen F, 2020, GUT, V69, P2035, DOI 10.1136/gutjnl-2019-320466
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Veettil SK, 2017, ASIAN J SURG, V40, P481, DOI 10.1016/j.asjsur.2016.07.005
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zorzi M, 2015, GUT, V64, P784, DOI 10.1136/gutjnl-2014-307508
NR 63
TC 0
Z9 0
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-8212
J9 FRONT ARTIF INTELL
JI Front. Artif. Intell.
PD SEP 30
PY 2022
VL 5
AR 955399
DI 10.3389/frai.2022.955399
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA 7Z7ZB
UT WOS:000915772400001
PM 36248620
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Hu, JQ
   Xu, YQ
   Tang, ZX
AF Hu, Jiaqi
   Xu, Yongqin
   Tang, Zhixian
TI DAN-PD: Domain adaptive network with parallel decoder for polyp
   segmentation
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Article
DE Deep learning; Semantic segmentation; Polyp segmentation; Unsupervised
   domain adaptation; Adversarial learning
AB Endoscopy is essential for polyp diagnosis and prevention of colorectal cancer. Many deep learning methods have been proposed to perform automatic semantic segmentation of polyps in endoscopic images. However, labeled training images are always scarce, and the styles of endoscopic images from different medical centers vary greatly. The annotation of medical images requires much effort, and how to make more efficient utilization of the existing labeled data is becoming an increasingly critical issue. Considering the characteristics of polyp segmentation tasks and the need for generalization, we proposed a novel method named DAN-PD based on the Vision Transformer. Moreover, we devised the Teacher Parallel Encoder (TPE) and the Domain-Aware Parallel Decoder (DAPD) for the model. Our design innovatively introduces Unsupervised Domain Adaptation (UDA) methods and adversarial learning strategies to the polyp segmentation task. We conducted four transfer learning experiments with three public polyp image datasets to examine the model's performance. The results shows that our proposed method is ahead of other methods in all experiments and reaches the state-of-the-art level.
C1 [Hu, Jiaqi; Xu, Yongqin] Univ Shanghai Sci & Technol, 516 Jungong Rd, Shanghai 200093, Peoples R China.
   [Tang, Zhixian] Shanghai Univ Med & Hlth Sci, Coll Med Imaging, 279 Zhouzhu Rd, Shanghai 201318, Peoples R China.
C3 University of Shanghai for Science & Technology; Shanghai University of
   Medicine & Health Sciences
RP Tang, ZX (通讯作者)，Shanghai Univ Med & Hlth Sci, Coll Med Imaging, 279 Zhouzhu Rd, Shanghai 201318, Peoples R China.
EM tangzx@sumhs.edu.cn
RI H, J/GZM-6342-2022
OI /0000-0003-2557-9728
FU Shanghai Sailing Program, China;  [21YF1418600]
FX This research was Sponsored by Shanghai Sailing Program, China, grant
   number 21YF1418600. We would like to express our most pro-found
   appreciation to Dr. Geng Chen and Mr. Bo Dong for their help with this
   research. We would also like to extend our deepest gratitude to Mr.
   Ronggui Hu and Ms. Jie Hu for their support.
CR Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Chen C, 2019, AAAI CONF ARTIF INTE, P865
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Deng J., 2009, P IEEE C COMP VIS PA, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B., 2021, ARXIV
   Du L, 2019, IEEE I CONF COMP VIS, P982, DOI 10.1109/ICCV.2019.00107
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Guo XQ, 2021, PROC CVPR IEEE, P3926, DOI 10.1109/CVPR46437.2021.00392
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C. -H., 2021, ARXIV
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Li Gao, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2825, DOI 10.1145/3474085.3475186
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liu H, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.250502
   Liu P, 2019, LECT NOTES COMPUT SC, V11768, P521, DOI 10.1007/978-3-030-32254-0_58
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Ronneberger O., 2015, P INT C MED IM COMP, P234, DOI [10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Tran L, 2019, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2019.00278
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang W., 2021, ARXIV
   Wei J., 2021, ARXIV
   Xiao X, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P327, DOI 10.1109/ITME.2018.00080
   Xu MH, 2020, AAAI CONF ARTIF INTE, V34, P6502
   Xu YH, 2019, AAAI CONF ARTIF INTE, P5581
   Yang C, 2021, IEEE J BIOMED HEALTH, V25, P3886, DOI 10.1109/JBHI.2021.3077271
   Yin Z., 2021, ARXIV
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 44
TC 1
Z9 1
U1 10
U2 23
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD OCT
PY 2022
VL 101
AR 102124
DI 10.1016/j.compmedimag.2022.102124
EA SEP 2022
PG 7
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA 5R5DP
UT WOS:000874531400002
PM 36182740
DA 2023-08-21
ER

PT J
AU Soons, E
   Rath, T
   Hazewinkel, Y
   van Dop, WA
   Esposito, D
   Testoni, PA
   Siersema, PD
AF Soons, E.
   Rath, T.
   Hazewinkel, Y.
   van Dop, W. A.
   Esposito, D.
   Testoni, P. A.
   Siersema, P. D.
TI Real-time colorectal polyp detection using a novel computer-aided
   detection system (CADe): a feasibility study
SO INTERNATIONAL JOURNAL OF COLORECTAL DISEASE
LA English
DT Article
DE Endoscopy; Computer-aided detection (CADe) system; Colorectal polyp;
   Colorectal adenoma; Detection
ID DETECTION-ASSISTED COLONOSCOPY; ADENOMA DETECTION;
   ARTIFICIAL-INTELLIGENCE; MISS RATE; CANCER; NEOPLASIA; CLASSIFICATION;
   PARTICIPATION; PREVALENCE; INCREASES
AB Background and aims Colonoscopy aims to early detect and remove precancerous colorectal polyps, thereby preventing development of colorectal cancer (CRC). Recently, computer-aided detection (CADe) systems have been developed to assist endoscopists in polyp detection during colonoscopy. The aim of this study was to investigate feasibility and safety of a novel CADe system during real-time colonoscopy in three European tertiary referral centers. Methods Ninety patients undergoing colonoscopy assisted by a real-time CADe system (DISCOVERY; Pentax Medical, Tokyo, Japan) were prospectively included. The CADe system was turned on only at withdrawal, and its output was displayed on secondary monitor. To study feasibility, inspection time, polyp detection rate (PDR), adenoma detection rate (ADR), sessile serrated lesion (SSL) detection rate (SDR), and the number of false positives were recorded. To study safety, (severe) adverse events ((S)AEs) were collected. Additionally, user friendliness was rated from 1 (worst) to 10 (best) by endoscopists. Results Mean inspection time was 10.8 +/- 4.3 min, while PDR was 55.6%, ADR 28.9%, and SDR 11.1%. The CADe system users estimated that < 20 false positives occurred in 81 colonoscopy procedures (90%). No (S)AEs related to the CADe system were observed during the 30-day follow-up period. User friendliness was rated as good, with a median score of 8/10. Conclusion Colonoscopy with this novel CADe system in a real-time setting was feasible and safe. Although PDR and SDR were high compared to previous studies with other CADe systems, future randomized controlled trials are needed to confirm these detection rates. The high SDR is of particular interest since interval CRC has been suggested to develop frequently through the serrated neoplasia pathway.
C1 [Soons, E.; Hazewinkel, Y.; van Dop, W. A.; Siersema, P. D.] Radboud Univ Nijmegen, Radboud Inst Hlth Sci, Dept Gastroenterol & Hepatol, Med Ctr, NL-6500 HB Nijmegen, Netherlands.
   [Rath, T.] Friedrich Alexander Univ, Ludwig Demling Endoscopy Ctr Excellence, Dept Internal Med 1, Div Gastroenterol, Erlangen Nuernberg, Germany.
   [Esposito, D.; Testoni, P. A.] Univ Vita Salute San Raffaele, Sci Inst San Raffaele, Gastroenterol & Gastrointestinal Endoscopy Unit, Milan, Italy.
C3 Radboud University Nijmegen; University of Erlangen Nuremberg;
   Vita-Salute San Raffaele University; IRCCS Ospedale San Raffaele
RP Soons, E (通讯作者)，Radboud Univ Nijmegen, Radboud Inst Hlth Sci, Dept Gastroenterol & Hepatol, Med Ctr, NL-6500 HB Nijmegen, Netherlands.
EM elsa.soons@radboudumc.nl
CR Antonelli G, 2020, WORLD J GASTROENTERO, V26, P7436, DOI 10.3748/wjg.v26.i47.7436
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Bateman AC, 2021, HISTOPATHOLOGY, V78, P780, DOI 10.1111/his.14305
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brand M, 2022, DIGESTION, V103, P378, DOI 10.1159/000525345
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Carr NJ, 2009, J CLIN PATHOL, V62, P516, DOI 10.1136/jcp.2008.061960
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Hann A, 2021, UNITED EUR GASTROENT, V9, P527, DOI 10.1002/ueg2.12108
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   IJspeert JEG, 2015, NAT REV GASTRO HEPAT, V12, P401, DOI 10.1038/nrgastro.2015.73
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lash RH, 2010, J CLIN PATHOL, V63, P681, DOI 10.1136/jcp.2010.075507
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Leggett B, 2010, GASTROENTEROLOGY, V138, P2088, DOI 10.1053/j.gastro.2009.12.066
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Macken E, 2019, ENDOSC INT OPEN, V7, pE717, DOI 10.1055/a-0751-2660
   Memmert D, 2010, J GEN PSYCHOL, V137, P129, DOI 10.1080/00221301003645061
   Mohan BP, 2020, ECLINICALMEDICINE, V29-30, DOI 10.1016/j.eclinm.2020.100622
   Pfeifer L, 2021, EUR J GASTROEN HEPAT, V33, pE662, DOI 10.1097/MEG.0000000000002209
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Shaukat A, 2021, ENDOSC INT OPEN, V09, pE263, DOI 10.1055/a-1321-1317
   Spadaccini M, 2021, LANCET GASTROENTEROL, V6, P793, DOI 10.1016/S2468-1253(21)00215-6
   Su JR, 2019, GASTROINTEST ENDOSC
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wolfe JM, 2006, VIS COGN, V14, P749, DOI 10.1080/13506280500195292
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 36
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0179-1958
EI 1432-1262
J9 INT J COLORECTAL DIS
JI Int. J. Colorectal Dis.
PD OCT
PY 2022
VL 37
IS 10
BP 2219
EP 2228
DI 10.1007/s00384-022-04258-9
EA SEP 2022
PG 10
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 5H4YJ
UT WOS:000859560600001
PM 36163514
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Komanduri, S
   Dominitz, JA
   Rabeneck, L
   Kahi, C
   Ladabaum, U
   Imperiale, TF
   Byrne, MF
   Lee, JK
   Lieberman, D
   Wang, AY
   Sultan, S
   Shaukat, A
   Pohl, H
   Muthusamy, VR
AF Komanduri, Srinadh
   Dominitz, Jason A.
   Rabeneck, Linda
   Kahi, Charles
   Ladabaum, Uri
   Imperiale, Thomas F.
   Byrne, Michael F.
   Lee, Jeffrey K.
   Lieberman, David
   Wang, Andrew Y.
   Sultan, Shahnaz
   Shaukat, Aasma
   Pohl, Heiko
   Muthusamy, V. Raman
TI AGA White Paper: Challenges and Gaps in Innovation for the Performance
   of Colonoscopy for Screening and Surveillance of Colorectal Cancer
SO CLINICAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE Adenoma Detection Rate (ADR); Artificial Intelligence (AI); Colonoscopy;
   Colorectal Cancer (CRC); Polyp Detection; Screening
ID ENDOSCOPIC MUCOSAL RESECTION; ADENOMA DETECTION RATES; SOCIETY
   TASK-FORCE; QUALITY IMPROVEMENT PROGRAM; RANDOMIZED CONTROLLED-TRIAL;
   ANESTHESIA ASSISTANCE; RISK; POLYPS; TIME; RECOMMENDATIONS
AB In 2018, the American Gastroenterological Association's Center for GI Innovation and Technology convened a consensus conference, entitled "Colorectal Cancer Screening and Surveillance: Role of Emerging Technology and Innovation to Improve Outcomes." The conference participants, which included more than 60 experts in colorectal cancer, considered recent improvements in colorectal cancer screening rates and polyp detection, persistent barriers to colonoscopy uptake, and opportunities for performance improvement and innovation. This white paper originates from that conference. It aims to summarize current patient- and physician-centered gaps and challenges in colonoscopy, diagnostic and therapeutic challenges affecting colonoscopy uptake, and the potential use of emerging technologies and quality metrics to improve patient outcomes.
C1 [Komanduri, Srinadh] Northwestern Univ, Dept Dept Gastroenterol & Hepatol, Chicago, IL USA.
   [Dominitz, Jason A.] Univ Washington, Vet Affairs Puget Sound Hlth Care Syst, Sch Med, Seattle, WA USA.
   [Dominitz, Jason A.] Univ Washington, Div Gastroenterol, Dept Med, Sch Med, Seattle, WA USA.
   [Rabeneck, Linda] Univ Toronto, Dept Med, Toronto, ON, Canada.
   [Kahi, Charles] Indiana Univ Sch Med, Richard L Roudebush Vet Affairs Med Ctr, Indiana, PA USA.
   [Ladabaum, Uri] Stanford Univ, Div Gastroenterol & Hepatol, Sch Med, Stanford, CA USA.
   [Imperiale, Thomas F.] Indiana Univ Sch Med, Simon Canc Ctr, Dept Med, Regenstrief Inst, Indianapolis, IN USA.
   [Imperiale, Thomas F.] Roudebush Vet Affairs Med Ctr, Ctr Innovat, Indianapolis, IN USA.
   [Byrne, Michael F.] Univ British Columbia, Div Gastroenterol, Vancouver Gen Hosp, Vancouver, BC, Canada.
   [Lee, Jeffrey K.] Kaiser Permanente San Francisco, Collaborat Hlth Outcomes Res Digest Dis CHORD Grp, Kaiser Permanente Div Res, San Francisco, CA USA.
   [Lieberman, David] Oregon Hlth & Sci Univ, Div Gastroenterol & Hepatol, Portland, OR USA.
   [Wang, Andrew Y.] Univ Virginia, Div Gastroenterol & Hepatol, Charlottesville, VA USA.
   [Sultan, Shahnaz] Univ Minnesota, Sch Med, Div Gastroenterol Hepatol & Nutr, Minneapolis, MN USA.
   [Shaukat, Aasma] Univ Minnesota, Div Gastroenterol, Minneapolis Vet Affairs Hlth Care Syst, Minneapolis, MN USA.
   [Shaukat, Aasma] Univ Minnesota, Sch Med, Dept Med, Minneapolis, MN USA.
   [Pohl, Heiko] Vet Affairs Med Ctr White River Junct, White River Jct, VT USA.
   [Pohl, Heiko] Dartmouth Geisel Sch Med, Hanover, NH USA.
   [Muthusamy, V. Raman] Univ Calif Los Angeles, Vatche & Tamar Manoukian Div Digest Dis, Dept Med, Los Angeles, CA USA.
C3 Northwestern University; University of Washington; University of
   Washington Seattle; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); Vet Affairs Puget Sound Health Care System;
   University of Washington; University of Washington Seattle; University
   of Toronto; Stanford University; Indiana University System; Indiana
   University Bloomington; Indiana University-Purdue University
   Indianapolis; Regenstrief Institute Inc; US Department of Veterans
   Affairs; Veterans Health Administration (VHA); Richard L. Roudebush VA
   Medical Center; University of British Columbia; Kaiser Permanente;
   Oregon Health & Science University; University of Virginia; University
   of Minnesota System; University of Minnesota Twin Cities; University of
   Minnesota System; University of Minnesota Twin Cities; US Department of
   Veterans Affairs; Veterans Health Administration (VHA); Minneapolis VA
   Health Care System; University of Minnesota System; University of
   Minnesota Twin Cities; Dartmouth College; University of California
   System; University of California Los Angeles
RP Muthusamy, VR (通讯作者)，UCLA Hlth Syst, Endoscopy, 200 UCLA Med Plaza,Room 330-337, Los Angeles, CA 90095 USA.; Muthusamy, VR (通讯作者)，UCLA, Clin Med, David Geffen Sch Med, 200 UCLA Med Plaza,Room 330-337, Los Angeles, CA 90095 USA.
EM raman@mednet.ucla.edu
OI Sultan, Shahnaz/0000-0002-5867-8741
CR Anderson JC, 2017, J CLIN GASTROENTEROL, V51, pE95, DOI 10.1097/MCG.0000000000000795
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Atkin WS, 2010, LANCET, V375, P1624, DOI 10.1016/S0140-6736(10)60551-X
   Babberich MPMDT, 2020, GASTROINTEST ENDOSC, V92, P154, DOI 10.1016/j.gie.2020.01.052
   Babberich MPMDT, 2019, ENDOSCOPY, V51, P961, DOI 10.1055/a-0962-9780
   Barclay RL, 2008, CLIN GASTROENTEROL H, V6, P1091, DOI 10.1016/j.cgh.2008.04.018
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bielawska B, 2018, GASTROENTEROLOGY, V154, P77, DOI 10.1053/j.gastro.2017.08.043
   Bisschops R, 2019, ENDOSCOPY, V51, P60, DOI 10.1055/a-0638-8125
   Boroff ES, 2017, GASTROENT RES PRACT, V2017, DOI 10.1155/2017/7207595
   Bretthauer M, 2016, JAMA INTERN MED, V176, P894, DOI 10.1001/jamainternmed.2016.0960
   Burgess NG, 2017, GASTROENTEROLOGY, V153, P732, DOI 10.1053/j.gastro.2017.05.047
   Chandrasekar VT, 2019, GASTROINTEST ENDOSC, V89, P929, DOI 10.1016/j.gie.2018.12.022
   Church J, 2008, DIS COLON RECTUM, V51, P520, DOI 10.1007/s10350-008-9239-y
   Clark BT, 2016, GASTROENTEROLOGY, V150, P396, DOI 10.1053/j.gastro.2015.09.041
   Click B, 2018, JAMA-J AM MED ASSOC, V319, P2021, DOI 10.1001/jama.2018.5809
   Coe SG, 2013, AM J GASTROENTEROL, V108, P219, DOI 10.1038/ajg.2012.417
   Cooper GS, 2013, JAMA INTERN MED, V173, P551, DOI 10.1001/jamainternmed.2013.2908
   Corley DA, 2013, GASTROENTEROLOGY, V144, pS2
   Corley DA, 2013, CLIN GASTROENTEROL H, V11, P172, DOI 10.1016/j.cgh.2012.09.010
   Corley DA, 2011, GASTROINTEST ENDOSC, V74, P656, DOI 10.1016/j.gie.2011.04.017
   de Groen Piet C, 2010, Gastrointest Endosc Clin N Am, V20, P699, DOI 10.1016/j.giec.2010.07.012
   Djinbachian R, 2020, GASTROENTEROLOGY, V159, P904, DOI 10.1053/j.gastro.2020.05.018
   Do A, 2013, GASTROINTEST ENDOSC, V77, P376, DOI 10.1016/j.gie.2012.10.023
   Draganov PV, 2019, CLIN GASTROENTEROL H, V17, P16, DOI 10.1016/j.cgh.2018.07.041
   Dua Arshish, 2019, Gastrointest Endosc Clin N Am, V29, P687, DOI 10.1016/j.giec.2019.06.002
   Ferlitsch M, 2017, ENDOSCOPY, V49, P270, DOI 10.1055/s-0043-102569
   Fuccio L, 2018, GASTROINTEST ENDOSC, V88, P589, DOI 10.1016/j.gie.2018.06.028
   Gupta S, 2011, GASTROINTEST ENDOSC, V73, P1232, DOI 10.1016/j.gie.2011.01.069
   Gupta S, 2020, GASTROENTEROLOGY, V158, P1131, DOI 10.1053/j.gastro.2019.10.026
   Hardcastle JD, 1996, LANCET, V348, P1472, DOI 10.1016/S0140-6736(96)03386-7
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Holme O, 2014, JAMA-J AM MED ASSOC, V312, P606, DOI 10.1001/jama.2014.8266
   Hong DH, 2014, COMPUT MED IMAG GRAP, V38, P22, DOI 10.1016/j.compmedimag.2013.10.005
   Inadomi JM, 2010, GASTROINTEST ENDOSC, V72, P580, DOI 10.1016/j.gie.2010.04.040
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Jayanna M, 2016, CLIN GASTROENTEROL H, V14, P271, DOI 10.1016/j.cgh.2015.08.037
   Jetelina KK, 2019, J GEN INTERN MED, V34, P1730, DOI 10.1007/s11606-019-05117-0
   Jian HX, 2019, J DIGEST DIS, V20, P578, DOI 10.1111/1751-2980.12814
   Johnson DA, 2014, GASTROENTEROLOGY, V147, P903, DOI 10.1053/j.gastro.2014.07.002
   Kahi CJ, 2011, CLIN GASTROENTEROL H, V9, P42, DOI 10.1016/j.cgh.2010.09.013
   Kaltenbach T, 2020, AM J GASTROENTEROL, V115, P435, DOI 10.14309/ajg.0000000000000555
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kothari ST, 2019, GASTROINTEST ENDOSC, V90, P863, DOI 10.1016/j.gie.2019.07.033
   Kronborg O, 1996, LANCET, V348, P1467, DOI 10.1016/S0140-6736(96)03430-7
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Ladabaum U, 2019, GASTROENTEROLOGY, V157, P137, DOI 10.1053/j.gastro.2019.03.023
   Lam AY, 2020, GASTROINTEST ENDOSC, V92, P355, DOI 10.1016/j.gie.2020.02.016
   Lee RH, 2011, GASTROINTEST ENDOSC, V74, P128, DOI 10.1016/j.gie.2011.03.003
   Leung FW, 2017, JAMA-J AM MED ASSOC, V317, P2006, DOI 10.1001/jama.2017.4114
   Levin TR, 2018, GASTROENTEROLOGY, V155, P1383, DOI 10.1053/j.gastro.2018.07.017
   Lieberman DA, 2014, GASTROINTEST ENDOSC, V80, P133, DOI 10.1016/j.gie.2014.01.014
   Liu HS, 2012, JAMA-J AM MED ASSOC, V307, P1178, DOI 10.1001/jama.2012.270
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   MANDEL JS, 1993, NEW ENGL J MED, V328, P1365, DOI 10.1056/NEJM199305133281901
   Martel M, 2015, GASTROENTEROLOGY, V149, P79, DOI 10.1053/j.gastro.2015.04.004
   McQuaid KR, 2008, GASTROINTEST ENDOSC, V67, P910, DOI 10.1016/j.gie.2007.12.046
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Murphy CC, 2016, CLIN GASTROENTEROL H, V14, P436, DOI 10.1016/j.cgh.2015.10.008
   Pabby A, 2005, GASTROINTEST ENDOSC, V61, P385, DOI 10.1016/S0016-5107(04)02765-8
   Peery AF, 2018, GASTROENTEROLOGY, V154, P1352, DOI 10.1053/j.gastro.2018.01.003
   Jimenez JP, 2019, J CLIN GASTROENTEROL, V53, P530, DOI 10.1097/MCG.0000000000001114
   Predmore Z, 2017, AM J GASTROENTEROL, V112, P297, DOI 10.1038/ajg.2016.266
   Rex DK, 1999, GASTROINTEST ENDOSC, V50, P468, DOI 10.1016/S0016-5107(99)70067-2
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2019, GASTROINTEST ENDOSC, V89, P656, DOI 10.1016/j.gie.2018.11.009
   Rex DK, 2016, AM J GASTROENTEROL, V111, pS105, DOI 10.14309/00000434-201610001-00221
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Robertson DJ, 2014, GUT, V63, P949, DOI 10.1136/gutjnl-2012-303796
   Rose S, 2014, GASTROENTEROLOGY, V147, P233, DOI 10.1053/j.gastro.2014.04.038
   Saito Y, 2009, DIGEST ENDOSC, V21, pS7, DOI 10.1111/j.1443-1661.2009.00870.x
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Schoen RE, 2012, NEW ENGL J MED, V366, P2345, DOI 10.1056/NEJMoa1114635
   Schoen RE, 2010, GASTROENTEROLOGY, V138, P73, DOI 10.1053/j.gastro.2009.09.062
   Schreiber S, 2019, ENDOSCOPY, V51, P73, DOI 10.1055/a-0639-5070
   Sharara AI, 2019, CLIN GASTROENTEROL H, V17, P1239, DOI 10.1016/j.cgh.2018.12.042
   Shaukat A, 2021, GASTROENTEROLOGY, V30
   Shaukat A, 2013, NEW ENGL J MED, V369, P1106, DOI 10.1056/NEJMoa1300720
   Shaukat A, 2009, CLIN GASTROENTEROL H, V7, P1335, DOI 10.1016/j.cgh.2009.07.027
   Snover DC, 2011, HUM PATHOL, V42, P1, DOI 10.1016/j.humpath.2010.06.002
   Spadaccini M, 2020, GASTROENTEROLOGY, V159, P148, DOI 10.1053/j.gastro.2020.03.051
   Srinivasan N, 2012, AM J GASTROENTEROL, V107, pS596, DOI 10.14309/00000434-201210001-01492
   Stanek SR, 2013, COMPUT METH PROG BIO, V112, P407, DOI 10.1016/j.cmpb.2013.07.028
   Tinmouth J, 2016, BEST PRACT RES CL GA, V30, P473, DOI 10.1016/j.bpg.2016.04.002
   Triantafyllou K, 2019, WORLD J GASTROENTERO, V25, P1158, DOI 10.3748/wjg.v25.i9.1158
   Uraoka T, 2006, GUT, V55, P1592, DOI 10.1136/gut.2005.087452
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wallace MB, 2017, GASTROINTEST ENDOSC, V85, P538, DOI 10.1016/j.gie.2016.07.042
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wernli KJ, 2016, GASTROENTEROLOGY, V150, P888, DOI 10.1053/j.gastro.2015.12.018
   Yeung CK, 2019, J DIGEST DIS, V20, P196, DOI 10.1111/1751-2980.12718
   Zhao SB, 2022, CLIN GASTROENTEROL H, V20, pE168, DOI 10.1016/j.cgh.2020.11.019
NR 95
TC 1
Z9 1
U1 2
U2 2
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1542-3565
EI 1542-7714
J9 CLIN GASTROENTEROL H
JI Clin. Gastroenterol. Hepatol.
PD OCT
PY 2022
VL 20
IS 10
BP 2198
EP +
DI 10.1016/j.cgh.2022.03.051
EA SEP 2022
PG 15
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 7C6UH
UT WOS:000899945100013
PM 35688352
DA 2023-08-21
ER

PT J
AU Wang, KH
   Ren, Y
   Ma, L
   Fan, YP
   Yang, Z
   Yang, QT
   Shi, JB
   Sun, YQ
AF Wang, Kanghua
   Ren, Yong
   Ma, Ling
   Fan, Yunping
   Yang, Zheng
   Yang, Qintai
   Shi, Jianbo
   Sun, Yueqi
TI Deep learning-based prediction of treatment prognosis from nasal polyp
   histology slides
SO INTERNATIONAL FORUM OF ALLERGY & RHINOLOGY
LA English
DT Article
DE chronic rhinosinusitis with nasal polyps; deep learning; disease
   prognosis; histopathological features
ID CHRONIC RHINOSINUSITIS; CANCER; VALIDATION; ENDOTYPES
AB Background Histopathology of nasal polyps contains rich prognostic information, which is difficult to extract objectively. In the present study, we aimed to develop a prognostic indicator of patient outcomes by analyzing scanned conventional hematoxylin and eosin (H&E)-stained slides alone using deep learning. Methods An interpretable supervised deep learning model was developed using 185 H&E-stained whole-slide images (WSIs) of nasal polyps, each from a patient randomly selected from the pool of 232 patients who underwent endoscopic sinus surgery at the First Affiliated Hospital of Sun Yat-Sen University (internal cohort). We internally validated the model on a holdout dataset from the internal cohort (47 H&E-stained WSIs) and externally validated the model on 122 H&E-stained WSIs from the Seventh Affiliated Hospital of Sun Yat-Sen University and the University of Hong Kong-Shenzhen Hospital (external cohort). A poor prognosis score (PPS) was established to evaluate patient outcomes, and then risk activation mapping was applied to visualize the histopathological features underlying PPS. Results The model yielded a patient-level sensitivity of 79.5%, and specificity of 92.3%, with areas under the receiver operating characteristic curve of 0.943, on the multicenter external cohort. The predictive ability of PPS was superior to that of conventional tissue eosinophil number. Notably, eosinophil infiltration, goblet cell hyperplasia, glandular hyperplasia, squamous metaplasia, and fibrin deposition were identified as the main underlying features of PPS. Conclusions Our deep learning model is an effective method for decoding pathological images of nasal polyps, providing a valuable solution for disease prognosis prediction and precise patient treatment.
C1 [Wang, Kanghua; Fan, Yunping; Sun, Yueqi] Sun Yat Sen Univ, Dept Otolaryngol, Affiliated Hosp 7, 628 Zhenyuan Rd, Shenzhen 518107, Guangdong, Peoples R China.
   [Wang, Kanghua; Shi, Jianbo; Sun, Yueqi] Sun Yat Sen Univ, Dept Otolaryngol, Affiliated Hosp 1, 58 Zhongshan Rd 2, Guangzhou 510080, Guangdong, Peoples R China.
   [Ren, Yong] Sun Yat Sen Univ, Ctr Digest Dis, Affiliated Hosp 7, Shenzhen, Peoples R China.
   [Ren, Yong] Sun Yat Sen Univ, Guangdong Prov Key Lab Digest Canc Res, Affiliated Hosp 7, Shenzhen, Peoples R China.
   [Ma, Ling] Univ Hong Kong Shenzhen Hosp, Dept Otorhinolaryngol, Shenzhen, Peoples R China.
   [Yang, Zheng] Sun Yat Sen Univ, Dept Pathol, Affiliated Hosp 7, Shenzhen, Peoples R China.
   [Yang, Qintai] Sun Yat Sen Univ, Dept Otorhinolaryngol Head & Neck Surg, Affiliated Hosp 3, Guangzhou, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Sun Yat Sen University;
   Sun Yat Sen University; University of Hong Kong; Sun Yat Sen University;
   Sun Yat Sen University
RP Sun, YQ (通讯作者)，Sun Yat Sen Univ, Dept Otolaryngol, Affiliated Hosp 7, 628 Zhenyuan Rd, Shenzhen 518107, Guangdong, Peoples R China.; Shi, JB (通讯作者)，Sun Yat Sen Univ, Dept Otolaryngol, Affiliated Hosp 1, 58 Zhongshan Rd 2, Guangzhou 510080, Guangdong, Peoples R China.
EM tsjbent@163.com; aqi1733@163.com
RI Wang, lili/IXD-9828-2023; Zhang, Yanfei/IXW-5406-2023; Sun,
   Yue-qi/N-4528-2018
OI Sun, Yue-qi/0000-0002-2382-0429
FU National Natural Science Foundation of China [81873691, 81970854,
   82171105, 81970853]; Guangdong Basic and Applied Basic Research
   Foundation [2020A1515010134, 2019A1515011029]; Guangdong Provincial Key
   Laboratory of Digestive Cancer Research [2021B1212040006]
FX The authors acknowledge funding received from National Natural Science
   Foundation of China (81873691, 81970854, 82171105 and 81970853),
   Guangdong Basic and Applied Basic Research Foundation (2020A1515010134
   and 2019A1515011029), and Guangdong Provincial Key Laboratory of
   Digestive Cancer Research (2021B1212040006).
CR Ahmed S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165361
   Bachert C, 2020, J ALLER CL IMM-PRACT, V8, P1514, DOI 10.1016/j.jaip.2020.03.007
   Bassiouni A, 2016, INT FORUM ALLERGY RH, V6, P248, DOI 10.1002/alr.21661
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Brescia G, 2019, INT FORUM ALLERGY RH, V9, P813, DOI 10.1002/alr.22314
   Calus L, 2019, CLIN TRANSL ALLERGY, V9, DOI 10.1186/s13601-019-0269-4
   Chen CL, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21467-y
   Cheng N, 2022, GASTROENTEROLOGY, V162, P1948, DOI 10.1053/j.gastro.2022.02.025
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Courtiol P, 2019, NAT MED, V25, P1519, DOI 10.1038/s41591-019-0583-3
   Demsar J, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008671
   Fokkens WJ, 2012, RHINOLOGY, V50, P1, DOI 10.4193/Rhin20.600
   Kleppe A, 2021, NAT REV CANCER, V21, P199, DOI 10.1038/s41568-020-00327-9
   Kuhar HN, 2017, INT FORUM ALLERGY RH, V7, P679, DOI 10.1002/alr.21943
   Liao B, 2018, ALLERGY, V73, P1459, DOI 10.1111/all.13411
   Lou HF, 2016, RHINOLOGY, V54, P150, DOI [10.4193/Rhino15.271, 10.4193/Rhin15.271]
   Lou HF, 2015, AM J RHINOL ALLERGY, V29, P350, DOI 10.2500/ajra.2015.29.4231
   Marino MJ, 2019, LARYNGOSCOPE INVEST, V4, P497, DOI 10.1002/lio2.303
   McHugh T, 2018, INT FORUM ALLERGY RH, V8, P1421, DOI 10.1002/alr.22194
   Orlandi RR, 2021, INT FORUM ALLERGY RH, V11, P213, DOI 10.1002/alr.22741
   Pantanowitz L, 2020, LANCET DIGIT HEALTH, V2, pE407, DOI 10.1016/S2589-7500(20)30159-X
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmauch B, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17678-4
   Shi JY, 2021, GUT, V70, P951, DOI 10.1136/gutjnl-2020-320930
   Skrede OJ, 2020, LANCET, V395, P350, DOI 10.1016/S0140-6736(19)32998-8
   Stevens WW, 2019, J ALLER CL IMM-PRACT, V7, P2812, DOI 10.1016/j.jaip.2019.05.009
   Tao XY, 2018, LARYNGOSCOPE, V128, P2673, DOI 10.1002/lary.27267
   van der Laak J, 2021, NAT MED, V27, P775, DOI 10.1038/s41591-021-01343-4
   van der Veen J, 2017, ALLERGY, V72, P282, DOI 10.1111/all.12983
   Wang KH, 2019, WORLD ALLERGY ORGAN, V12, DOI 10.1016/j.waojou.2019.100052
   Wang XD, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21674-7
   Wei B, 2018, RHINOLOGY, V56, P216, DOI 10.4193/Rhin17.240
   Woerl AC, 2020, EUR UROL, V78, P256, DOI 10.1016/j.eururo.2020.04.023
   Wu QW, 2021, EBIOMEDICINE, V66, DOI 10.1016/j.ebiom.2021.103336
   Wu QW, 2020, J ALLERGY CLIN IMMUN, V145, P698, DOI 10.1016/j.jaci.2019.12.002
NR 35
TC 0
Z9 0
U1 4
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2042-6976
EI 2042-6984
J9 INT FORUM ALLERGY RH
JI Int. Forum Allergy Rhinol.
PD MAY
PY 2023
VL 13
IS 5
BP 886
EP 898
DI 10.1002/alr.23083
EA SEP 2022
PG 13
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology
GA E6HK2
UT WOS:000854866200001
PM 36066094
DA 2023-08-21
ER

PT J
AU Hanscom, M
   Cave, DR
AF Hanscom, Mark
   Cave, David R.
TI Endoscopic capsule robot-based diagnosis, navigation and localization in
   the gastrointestinal tract
SO FRONTIERS IN ROBOTICS AND AI
LA English
DT Review
DE capsule; capsule endoscopy; gastrointestinal tract; capsule locomotion;
   artificial intelligence; AI
ID SUSPECTED BLOOD INDICATOR; SMALL-BOWEL; VIDEO CAPSULE; PROTRUDING
   LESIONS; PERFORMANCE; DISEASE; SYSTEM; IMAGES; CLASSIFICATION;
   RECOGNITION
AB The proliferation of video capsule endoscopy (VCE) would not have been possible without continued technological improvements in imaging and locomotion. Advancements in imaging include both software and hardware improvements but perhaps the greatest software advancement in imaging comes in the form of artificial intelligence (AI). Current research into AI in VCE includes the diagnosis of tumors, gastrointestinal bleeding, Crohn's disease, and celiac disease. Other advancements have focused on the improvement of both camera technologies and alternative forms of imaging. Comparatively, advancements in locomotion have just started to approach clinical use and include onboard controlled locomotion, which involves miniaturizing a motor to incorporate into the video capsule, and externally controlled locomotion, which involves using an outside power source to maneuver the capsule itself. Advancements in locomotion hold promise to remove one of the major disadvantages of VCE, namely, its inability to obtain targeted diagnoses. Active capsule control could in turn unlock additional diagnostic and therapeutic potential, such as the ability to obtain targeted tissue biopsies or drug delivery. With both advancements in imaging and locomotion has come a corresponding need to be better able to process generated images and localize the capsule's position within the gastrointestinal tract. Technological advancements in computation performance have led to improvements in image compression and transfer, as well as advancements in sensor detection and alternative methods of capsule localization. Together, these advancements have led to the expansion of VCE across a number of indications, including the evaluation of esophageal and colon pathologies including esophagitis, esophageal varices, Crohn's disease, and polyps after incomplete colonoscopy. Current research has also suggested a role for VCE in acute gastrointestinal bleeding throughout the gastrointestinal tract, as well as in urgent settings such as the emergency department, and in resource-constrained settings, such as during the COVID-19 pandemic. VCE has solidified its role in the evaluation of small bowel bleeding and earned an important place in the practicing gastroenterologist's armamentarium. In the next few decades, further improvements in imaging and locomotion promise to open up even more clinical roles for the video capsule as a tool for non-invasive diagnosis of lumenal gastrointestinal pathologies.
C1 [Hanscom, Mark; Cave, David R.] Univ Massachusetts, Med Sch, Worcester, MA 01605 USA.
C3 University of Massachusetts System; University of Massachusetts
   Worcester
RP Hanscom, M; Cave, DR (通讯作者)，Univ Massachusetts, Med Sch, Worcester, MA 01605 USA.
EM mark.hanscom@umassmemorial.org; david.cave@umassmemorial.org
RI Cave, David/HPG-1312-2023
FU Olympus Corp. of America; Medtronic; AnX Robotica
FX The author DC received research funding from the Olympus Corp. of
   America, Medtronic, and AnX Robotica. The funder was not involved in the
   study design, collection, analysis, interpretation of data, the writing
   of this article or the decision to submit it for publication.
CR Aoki T, 2022, DIGESTION, V103, P367, DOI 10.1159/000525314
   Aoki T, 2020, J GASTROEN HEPATOL, V35, P1196, DOI 10.1111/jgh.14941
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Arezzo A, 2013, DIGEST LIVER DIS, V45, P657, DOI 10.1016/j.dld.2013.01.025
   Barash Y, 2021, GASTROINTEST ENDOSC, V93, P187, DOI 10.1016/j.gie.2020.05.066
   Buscaglia JM, 2008, CLIN GASTROENTEROL H, V6, P298, DOI 10.1016/j.cgh.2007.12.029
   Carpi F, 2007, IEEE T BIO-MED ENG, V54, P2028, DOI 10.1109/TBME.2007.894729
   Carpi F, 2011, IEEE T BIO-MED ENG, V58, P231, DOI 10.1109/TBME.2010.2087332
   Carpi F, 2009, IEEE T BIO-MED ENG, V56, P1482, DOI 10.1109/TBME.2009.2013336
   Chandrappan J, 2010, IEEE ENG MED BIO, P1890, DOI 10.1109/IEMBS.2010.5627090
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Chatrath H, 2014, J CLIN GASTROENTEROL, V48, P52, DOI 10.1097/MCG.0b013e318288a2cd
   Chen YZ, 2019, ENDOSCOPY, V51, P360, DOI 10.1055/a-0856-6845
   Ching HL, 2019, GASTROINTEST ENDOSC, V90, P430, DOI 10.1016/j.gie.2019.04.248
   Ching HL, 2019, ENDOSCOPY, V51, P409, DOI 10.1055/a-0750-5682
   Choi EH, 2013, GASTROINTEST ENDOSC, V78, P325, DOI 10.1016/j.gie.2013.02.039
   Ciuti G, 2010, ENDOSCOPY, V42, P148, DOI 10.1055/s-0029-1243808
   Ciuti G, 2016, J MICRO-BIO ROBOT, V11, P1, DOI 10.1007/s12213-016-0087-x
   De Falco I, 2014, IEEE T BIO-MED ENG, V61, P794, DOI 10.1109/TBME.2013.2290018
   Deding U, 2021, ENDOSC INT OPEN, V09, pE1712, DOI 10.1055/a-1546-8727
   Dickman R, 2007, AM J GASTROENTEROL, V102, P1173, DOI 10.1111/j.1572-0241.2007.01117.x
   Ding SL, 2012, MOL IMAGING, V11, P507, DOI 10.2310/7290.2012.00014
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Dolak W, 2012, ENDOSCOPY, V44, P1012, DOI 10.1055/s-0032-1310158
   Dung LR, 2010, IEEE T BIOMED CIRC S, V4, P462, DOI 10.1109/TBCAS.2010.2079932
   Eliakim R, 2005, J CLIN GASTROENTEROL, V39, P572, DOI 10.1097/01.mcg.0000170764.29202.24
   Faes L, 2019, LANCET DIGIT HEALTH, V1, pE232, DOI 10.1016/S2589-7500(19)30108-6
   Fischer Doron, 2004, Gastrointest Endosc Clin N Am, V14, P25, DOI 10.1016/j.giec.2003.10.020
   Gerson LB, 2015, AM J GASTROENTEROL, V110, P1265, DOI 10.1038/ajg.2015.246
   Gora MJ, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.10.104001
   Gupta T, 2011, WORLD J GASTROENTERO, V17, P4590, DOI 10.3748/wjg.v17.i41.4590
   Gyawali CP, 2018, GASTROENTEROLOGY, V154, P302, DOI 10.1053/j.gastro.2017.07.049
   Hakimian S, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.18796
   Hakimian Shahrad, 2021, Gastrointest Endosc Clin N Am, V31, P399, DOI 10.1016/j.giec.2020.12.011
   Han S, 2018, GASTROENTEROL RES, V11, P106, DOI 10.14740/gr949w
   Ibrahim M, 2013, GASTROENT RES PRACT, V2013, DOI 10.1155/2013/304723
   Imagawa H, 2011, GASTROINTEST ENDOSC, V73, P299, DOI 10.1016/j.gie.2010.10.016
   Jiang B, 2020, GASTROINTEST ENDOSC, V91, P1379, DOI 10.1016/j.gie.2020.01.027
   Karargyris A, 2015, IEEE T BIO-MED ENG, V62, P352, DOI 10.1109/TBME.2014.2352493
   Keller J, 2011, GASTROINTEST ENDOSC, V73, P22, DOI 10.1016/j.gie.2010.08.053
   Keuchel M., 2015, VIDEO CAPSULE ENDOSC
   Khan H, 2022, SURG ENDOSC, V36, P4624, DOI 10.1007/s00464-021-09007-7
   Kim HM, 2010, GASTROINTEST ENDOSC, V72, P381, DOI 10.1016/j.gie.2009.12.058
   Kim HJ, 2022, J PERS MED, V12, DOI 10.3390/jpm12040644
   Kim JH, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11101792
   Kimchy Y, 2017, ABDOM RADIOL, V42, P1291, DOI 10.1007/s00261-016-1026-y
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Koulaouzidis A, 2013, ANN GASTROENTEROL, V26, P365
   Koulaouzidis A, 2012, WORLD J GASTRO ENDOS, V4, P33, DOI 10.4253/wjge.v4.i2.33
   Krishna Chandar Apoorva, 2020, Gastroenterol Hepatol (N Y), V16, P238
   Kwon J, 2007, P I MECH ENG H, V221, P397, DOI 10.1243/09544119JEIM134
   Laine L, 2021, AM J GASTROENTEROL, V116, P899, DOI 10.14309/ajg.0000000000001245
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Liao Zhuan, 2012, J Interv Gastroenterol, V2, P155, DOI 10.4161/jig.23751
   Liu YW, 2022, BMC GASTROENTEROL, V22, DOI 10.1186/s12876-022-02302-0
   Marya N, 2014, GASTROINTEST ENDOSC, V79, P669, DOI 10.1016/j.gie.2013.11.022
   Marya NB, 2019, GASTROINTEST ENDOSC, V89, P33, DOI 10.1016/j.gie.2018.06.016
   Mascarenhas M, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12061445
   Meltzer AC, 2021, JACEP OPEN, V2, DOI 10.1002/emp2.12579
   Menciassi Arianna, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P2215
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Park Sukho, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P2211
   Pioche M, 2011, GASTROINTEST ENDOSC, V73, P1181, DOI 10.1016/j.gie.2011.02.011
   Qin KW, 2022, SURG ENDOSC, V36, P16, DOI 10.1007/s00464-021-08689-3
   Qiu YQ, 2020, ULTRASOUND MED BIOL, V46, P796, DOI 10.1016/j.ultrasmedbio.2019.12.003
   Quirini M, 2007, P ANN INT IEEE EMBS, P2827, DOI 10.1109/IEMBS.2007.4352917
   Quirini M, 2008, GASTROINTEST ENDOSC, V67, P1153, DOI 10.1016/j.gie.2007.11.052
   Rahman I, 2016, GASTROINTEST ENDOSC, V83, P889, DOI 10.1016/j.gie.2015.09.015
   Rey JF, 2012, GASTROINTEST ENDOSC, V75, P373, DOI 10.1016/j.gie.2011.09.030
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Sakai E, 2012, BMC GASTROENTEROL, V12, DOI 10.1186/1471-230X-12-83
   Sami SS, 2019, CLIN GASTROENTEROL H, V17, P638, DOI 10.1016/j.cgh.2018.07.019
   Schnoll-Sussman Felice, 2017, Curr Treat Options Gastroenterol, V15, P1, DOI 10.1007/s11938-017-0115-5
   Schostek S, 2016, BIOSENS BIOELECTRON, V78, P524, DOI 10.1016/j.bios.2015.11.073
   Schostek Sebastian, 2013, Stud Health Technol Inform, V189, P193
   Scott Ryan, 2015, Gastroenterol Hepatol (N Y), V11, P612
   Seibel EJ, 2008, IEEE T BIO-MED ENG, V55, P1032, DOI 10.1109/TBME.2008.915680
   Shamsudhin N, 2017, MED PHYS, V44, pE91, DOI [10.1002/mp.12446, 10.1002/mp.12299]
   Silva J, 2013, IEEE ENG MED BIO, P5711, DOI 10.1109/EMBC.2013.6610847
   Singh A, 2010, GASTROENTEROLOGY, V138, pS670
   Slawinski PR, 2015, WORLD J GASTROENTERO, V21, P10528, DOI 10.3748/wjg.v21.i37.10528
   Sung JJY, 2016, GASTROINTEST ENDOSC, V84, P907, DOI 10.1016/j.gie.2016.04.043
   Swain P, 2010, GASTROINTEST ENDOSC, V71, P1290, DOI 10.1016/j.gie.2010.01.064
   Szalai M, 2022, WORLD J GASTROENTERO, V28, P2227, DOI 10.3748/wjg.v28.i20.2227
   Tai FWD, 2022, ENDOSC INT OPEN, V10, pE735, DOI 10.1055/a-1790-5996
   Tortora G, 2009, MINIM INVASIV THER, V18, P280, DOI 10.1080/13645700903201167
   Trasolini R, 2021, DIGEST ENDOSC, V33, P290, DOI 10.1111/den.13896
   Triantafyllou K, 2011, WORLD J GASTROENTERO, V17, P1462, DOI 10.3748/wjg.v17.i11.1462
   Than TD, 2012, IEEE T BIO-MED ENG, V59, P2387, DOI 10.1109/TBME.2012.2201715
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Vedaei SS, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90523-w
   Vuik FER, 2021, ENDOSCOPY, V53, P815, DOI 10.1055/a-1308-1297
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wang LM, 2005, BIOMED MICRODEVICES, V7, P111, DOI 10.1007/s10544-005-1588-x
   Wang S, 2021, LANCET REG HEALTH-W, V6, DOI 10.1016/j.lanwpc.2020.100072
   Weitschies W, 1997, J PHARM SCI, V86, P1218, DOI 10.1021/js970185g
   Xing XH, 2018, IEEE ENG MED BIO, P3594, DOI 10.1109/EMBC.2018.8513012
   Yang S, 2011, IEEE ENG MED BIO, P6659, DOI 10.1109/IEMBS.2011.6091642
   Ye DX, 2022, IEEE T BIO-MED ENG, V69, P2905, DOI 10.1109/TBME.2022.3157451
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yung DE, 2017, ENDOSCOPY, V49, P258, DOI 10.1055/s-0042-122015
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P43, DOI 10.1080/17474124.2017.1257384
   Zeising S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12061333
   Zhang H, 2008, GASTROINTEST ENDOSC, V68, P520, DOI 10.1016/j.gie.2008.02.023
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 107
TC 1
Z9 1
U1 16
U2 29
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-9144
J9 FRONT ROBOT AI
JI Front. Robot. AI
PD SEP 2
PY 2022
VL 9
AR 896028
DI 10.3389/frobt.2022.896028
PG 16
WC Robotics
WE Emerging Sources Citation Index (ESCI)
SC Robotics
GA 4P9BT
UT WOS:000855685100001
PM 36119725
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Schauer, C
   Chieng, M
   Wang, MC
   Neave, M
   Watson, S
   Van Rijnsoever, M
   Walmsley, R
   Jafer, A
AF Schauer, Cameron
   Chieng, Michael
   Wang, Michael
   Neave, Michelle
   Watson, Sarah
   Van Rijnsoever, Marius
   Walmsley, Russell
   Jafer, Ali
TI Artificial intelligence improves adenoma detection rate during
   colonoscopy
SO NEW ZEALAND MEDICAL JOURNAL
LA English
DT Article
ID CAP-ASSISTED COLONOSCOPY; COMPUTER-AIDED DETECTION; QUALITY INDICATORS;
   POLYP DETECTION; METAANALYSIS; IMPACT; GASTROENTEROLOGY; PERFORMANCE;
   EFFICACY; SYSTEM
AB BACKGROUND: Artificial intelligence-assisted colonoscopy (AIAC) has gained attention as a tool to assist with polyp detection during colonoscopy. Uncertainty remains as to the clinical benefit, given limited publications using different modules. METHOD: A single-centre retrospective study was performed at Waitemata Endoscopy, a private endoscopy centre in Auckland, New Zealand. An Olympus Endo-AID module was utilised for the first time by 13 experienced endoscopists. Outcomes from AIAC between 10 March 2021 to 23 April 2021 were compared to a subsequent non-AI conventional colonoscopy (CC) control group from 27/4/21 to 20/6/21. RESULTS: A total of 213 AIACs were compared with 213 CCs. Baseline patient age, gender, indication for procedure, bowel preparation scores and specialty of proceduralist (gastroenterologist or surgeon) were well matched (p > 0.05). The withdrawal time was significantly longer in the AIAC group compared to CC controls (15 vs 13 minutes; p < 0.001). The adenoma detection rate (ADR) was significantly higher in the AIAC group compared to CC group (47.9% vs 38.5%; odds ratio 1.59; 95% CI [1.05-2.41]; p=0.03). The overall polyp detection rate (PDR) was similar between groups (70% vs 70%; p=0.79). Analysis by polyp size, location and other histology was not significant between groups. CONCLUSION: AI-assisted colonoscopy significantly improved ADR compared with conventional colonoscopy. Further research is required to understand its utility and impact on long-term clinical outcomes.
C1 [Schauer, Cameron; Neave, Michelle; Watson, Sarah; Van Rijnsoever, Marius; Walmsley, Russell; Jafer, Ali] Waitemata Endoscopy, 53 Lincoln Rd, Auckland, New Zealand.
   [Schauer, Cameron; Chieng, Michael; Wang, Michael; Walmsley, Russell] Univ Auckland, Fac Med, Auckland, New Zealand.
C3 University of Auckland
RP Schauer, C (通讯作者)，Waitemata Endoscopy, 53 Lincoln Rd, Auckland, New Zealand.
EM cameron.schauer@gmail.com
RI Watson, Sarah/HGB-2661-2022; Wang, Michael T. M./X-4197-2019
OI Wang, Michael T. M./0000-0001-8334-3911
CR Akarsu M, 2018, JSLS-J SOC LAPAROEND, V22, DOI 10.4293/JSLS.2017.00053
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bi WL, 2019, CA-CANCER J CLIN, V69, P127, DOI 10.3322/caac.21552
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Boniface C., 2020, NZ LAW J
   Bowel Cancer New Zealand, 2021, BOW CANC SYMPT STAT
   Brown JR., 2021, CLIN GASTROENTEROL H
   Burgess NG, 2014, GASTROINTEST ENDOSC, V80, P307, DOI 10.1016/j.gie.2014.03.050
   Coe SG, 2013, AM J GASTROENTEROL, V108, P219, DOI 10.1038/ajg.2012.417
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dilsizian SE, 2014, CURR CARDIOL REP, V16, DOI 10.1007/s11886-013-0441-8
   Diprose W, 2016, NEW ZEAL MED J, V129, P73
   Facciorusso A, 2019, CLIN GASTROENTEROL H, V17, P2439, DOI 10.1016/j.cgh.2018.11.058
   Franco Diana L, 2017, Gastroenterol Hepatol (N Y), V13, P476
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Jafer A., 2020, COLONOSCOPY AUDIT RE, V1
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Kaminski MF, 2016, GUT, V65, P616, DOI 10.1136/gutjnl-2014-307503
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lafeuille P, 2022, ENDOSCOPY, V54, P520, DOI 10.1055/a-1486-6220
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Leyden JE, 2011, ENDOSCOPY, V43, P935, DOI 10.1055/s-0030-1256633
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Ministry of Health New Zealand, 2021, NAT BOW SCREEN PROGR
   Mir FA, 2017, ANN GASTROENTEROL, V30, P640, DOI 10.20524/aog.2017.0180
   Misawa M, 2021, DIGEST ENDOSC, V33, P273, DOI 10.1111/den.13847
   Mori Y, 2021, J GASTROEN HEPATOL, V36, P7, DOI 10.1111/jgh.15339
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Ng SC, 2012, AM J GASTROENTEROL, V107, P1165, DOI 10.1038/ajg.2012.135
   Olympus, 2020, SETT FDN NEW ER END
   Patel K, 2022, ARTIF INTELL REV, V55, P3747, DOI 10.1007/s10462-021-10084-2
   Peduzzi P, 1996, J CLIN EPIDEMIOL, V49, P1373, DOI 10.1016/S0895-4356(96)00236-3
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2017, BEST PRACT RES CL GA, V31, P425, DOI 10.1016/j.bpg.2017.05.010
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2012, AM J GASTROENTEROL, V107, P1315, DOI 10.1038/ajg.2012.161
   Rex DK, 2010, AM J GASTROENTEROL, V105, P2312, DOI 10.1038/ajg.2010.245
   Rondonotti E, 2014, GASTROINTEST ENDOSC, V80, P1103, DOI 10.1016/j.gie.2014.05.319
   Stamm R, 2020, NEW ZEAL MED J, V133, P32
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Sweetser S, 2013, CLIN GASTROENTEROL H, V11, P760, DOI 10.1016/j.cgh.2012.12.004
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wong Y.T., 2021, IDDF2021ABS0048 BMJ
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
NR 50
TC 0
Z9 0
U1 0
U2 0
PU NEW ZEALAND MEDICAL ASSOC
PI CHRISTCHURCH
PA C/O BRENNAN EDWARDES, DEPT SURGERY, CHRISTCHURCH HOSPITAL, PO BOX 4345,
   CHRISTCHURCH, 00000, NEW ZEALAND
SN 0028-8446
EI 1175-8716
J9 NEW ZEAL MED J
JI N. Z. Med. J.
PD SEP 2
PY 2022
VL 135
IS 1561
BP 22
EP 30
PG 9
WC Medicine, General & Internal
WE Emerging Sources Citation Index (ESCI)
SC General & Internal Medicine
GA 4X0LM
UT WOS:000860543900004
PM 36049787
DA 2023-08-21
ER

PT J
AU Dornblaser, DW
   Gross, SA
AF Dornblaser, David W.
   Gross, Seth A.
TI Safe, efficient, and effective screening colonoscopy
SO CURRENT OPINION IN GASTROENTEROLOGY
LA English
DT Review
DE adenoma detection rate; artificial intelligence; bowel preparation;
   Colonoscopy
ID ADENOMA DETECTION RATE; BOWEL PREPARATION; ORAL ANTICOAGULANTS;
   METAANALYSIS; IMPACT; COMPLICATIONS; POLYPS
AB Purpose of review
   Colorectal cancer continues to be one of the most common causes of cancer-related death. Widespread dissemination of screening colonoscopy in the United States has led to a significant reduction in the incidence and mortality. Here we review current literature with an aim to highlight recent improvements in the safety, efficiency, and effectiveness of screening colonoscopy.
   Recent findings
   Colon capsule endoscopy is an emerging noninvasive method to capture images of colonic mucosa for select patients with appreciable sensitivity for polyp detection. Recent literature supports the use of the novel oral anticoagulant apixaban over other anticoagulants to reduce the risk of gastrointestinal bleeding related to colonoscopy. Cold snare polypectomy for smaller lesions and prophylactic clipping following resection of large polyps in the proximal colon may reduce the rate of delayed bleeding. Novel methods and devices for improving bowel preparation continue to emerge. Mechanical attachment devices and artificial intelligence represent recent innovations to improve polyp detection.
   Summary
   Clinicians should be aware of relevant data and literature that continue to improve the quality and safety of screening colonoscopy and incorporate these findings into their clinical practice.
C1 [Dornblaser, David W.; Gross, Seth A.] NYU Langone Hlth, New York, NY 11209 USA.
C3 NYU Langone Medical Center
RP Dornblaser, DW (通讯作者)，NYU Langone Hlth, New York, NY 11209 USA.
EM david.dornblaser@nyulangone.org
RI Dornblaser, David/GVS-3079-2022
CR Acosta RD, 2016, GASTROINTEST ENDOSC, V83, P3, DOI 10.1016/j.gie.2015.09.035
   [Anonymous], 2021, JAMA-J AM MED ASSOC, V326, P1431, DOI 10.1001/jama.2021.3606
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Bachwich DR, 2020, CLIN TRANSL GASTROEN, V11, DOI 10.14309/ctg.0000000000000264
   Bishay K, 2022, SURG ENDOSC, V36, P1251, DOI 10.1007/s00464-021-08398-x
   Boregowda U, 2021, ANN GASTROENTEROL, V34, P214, DOI 10.20524/aog.2021.0591
   Boumitri C, 2016, ANN GASTROENTEROL, V29, P502, DOI 10.20524/aog.2016.0075
   Chai-Adisaksopha C, 2014, BLOOD, V124, P2450, DOI 10.1182/blood-2014-07-590323
   Chokshi RV, 2012, GASTROINTEST ENDOSC, V75, P1197, DOI 10.1016/j.gie.2012.01.005
   di Palma JA, 2021, AM J GASTROENTEROL, V116, P319, DOI 10.14309/ajg.0000000000001020
   Forbes N., 2021, ENDOSC INT OPEN, V9, pE1583
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hosoe N, 2021, DIGEST ENDOSC, V33, P529, DOI 10.1111/den.13769
   Johnson CD, 2000, RADIOLOGY, V216, P331, DOI 10.1148/radiology.216.2.r00au47331
   Khalid-de Bakker CA, 2011, NETH J MED, V69, P186
   Kim GU, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82251-y
   Kingston-Smith H., 2021, FRONTIERS MEDICAL TE, V2, P27
   Lau LHS, 2022, GUT, V71, P100, DOI 10.1136/gutjnl-2020-323600
   Lawrence Zoe, 2020, Curr Treat Options Gastroenterol, DOI 10.1007/s11938-020-00280-4
   Manta R, 2015, TECH COLOPROCTOL, V19, P505, DOI 10.1007/s10151-015-1344-z
   Moyer VA, 2014, ANN INTERN MED, V160, P330, DOI 10.7326/M13-2771
   Neumann H, 2021, BMC GASTROENTEROL, V21, DOI 10.1186/s12876-021-01817-2
   Patel HK, 2021, GASTROINTEST ENDOSC, V93, P544, DOI 10.1016/j.gie.2020.09.045
   Jimenez JP, 2019, J CLIN GASTROENTEROL, V53, P530, DOI 10.1097/MCG.0000000000001114
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2002, AM J GASTROENTEROL, V97, P1296, DOI 10.1016/S0002-9270(02)04168-0
   Samarasena JB, 2022, DIGEST DIS SCI, V67, P2358, DOI 10.1007/s10620-021-07023-0
   Shaukat A, 2021, AM J GASTROENTEROL, V116, P458, DOI 10.14309/ajg.0000000000001122
   Shirin H, 2019, GASTROINTEST ENDOSC, V89, P545, DOI 10.1016/j.gie.2018.09.028
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Spadaccini M, 2020, GASTROENTEROLOGY, V159, P148, DOI 10.1053/j.gastro.2020.03.051
   Tagawa T, 2021, GASTROINTEST ENDOSC, V94, P803, DOI 10.1016/j.gie.2021.03.996
   Takamaru H., 2021, GASTROINTEST ENDOSC
   Tutticci Nicholas J, 2019, Gastrointest Endosc Clin N Am, V29, P721, DOI 10.1016/j.giec.2019.06.003
   Valvano M, 2022, SURG ENDOSC, V36, P2258, DOI 10.1007/s00464-021-08975-0
   van Keulen KE, 2019, ENDOSCOPY, V51, P85, DOI 10.1055/a-0632-1927
   Vuik FER, 2021, ENDOSCOPY, V53, P815, DOI 10.1055/a-1308-1297
   Waldmann E, 2021, CLIN GASTROENTEROL H, V19, P1890, DOI 10.1016/j.cgh.2021.04.023
   Zhang XB, 2020, GASTROINTEST ENDOSC, V92, P508, DOI 10.1016/j.gie.2020.04.069
   Zippelius C, 2022, ENDOSCOPY, V54, P465, DOI 10.1055/a-1556-5984
   Zorzi M, 2022, ENDOSCOPY, V54, P138, DOI 10.1055/a-1379-6868
NR 42
TC 0
Z9 0
U1 0
U2 1
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0267-1379
EI 1531-7056
J9 CURR OPIN GASTROEN
JI Curr. Opin. Gastroenterol.
PD SEP
PY 2022
VL 38
IS 5
BP 430
EP 435
DI 10.1097/MOG.0000000000000860
PG 6
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 3L6HK
UT WOS:000834861100004
PM 35894671
DA 2023-08-21
ER

PT J
AU Garcia-Rodriguez, A
   Tudela, Y
   Cordova, H
   Carballal, S
   Ordas, I
   Moreira, L
   Vaquero, E
   Ortiz, O
   Rivero, L
   Sanchez, FJ
   Cuatrecasas, M
   Pellise, M
   Bernal, J
   Fernandez-Esparrach, G
AF Garcia-Rodriguez, Ana
   Tudela, Yael
   Cordova, Henry
   Carballal, Sabela
   Ordas, Ingrid
   Moreira, Leticia
   Vaquero, Eva
   Ortiz, Oswaldo
   Rivero, Liseth
   Sanchez, F. Javier
   Cuatrecasas, Miriam
   Pellise, Maria
   Bernal, Jorge
   Fernandez-Esparrach, Gloria
TI In vivo computer-aided diagnosis of colorectal polyps using white light
   endoscopy
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID ARTIFICIAL-INTELLIGENCE; CLASSIFICATION; SYSTEM; HISTOLOGY; LESIONS;
   CANCER; COLON
AB Background and study aims Artificial intelligence is currently able to accurately predict the histology of colorectal polyps. However, systems developed to date use complex optical technologies and have not been tested in vivo. The objective of this study was to evaluate the efficacy of a new deep learning-based optical diagnosis system, ATENEA, in a real clinical setting using only high-definition white light endoscopy (WLE) and to compare its performance with endoscopists.
   Methods ATENEA was prospectively tested in real life on consecutive polyps detected in colorectal cancer screening colonoscopies at Hospital Clinic. No images were discarded, and only WLE was used. The in vivo ATENEA's prediction (adenoma vs non-adenoma) was compared with the prediction of four staff endoscopists without specific training in optical diagnosis for the study purposes. Endoscopists were blind to the ATENEA output. Histology was the gold standard.
   Results Ninety polyps (median size: 5 mm, range: 2-25) from 31 patients were included of which 69 (76.7%) were adenomas. ATENEA correctly predicted the histology in 63 of 69 (91.3%, 95% CI: 82%-97%) adenomas and 12 of 21 (57.1%, 95% CI: 34 %-78 %) non-adenomas while endoscopists made correct predictions in 52 of 69 (75.4%, 95% CI: 60%-85%) and 20 of 21 (95.2%, 95% CI: 76%-100%), respectively. The global accuracy was 83.3% (95% CI: 74%-90%) and 80%(95% CI: 70 %-88 %) for ATENEA and endoscopists, respectively.
   Conclusion ATENEA can accurately be used for in vivo characterization of colorectal polyps, enabling the endoscopist to make direct decisions. ATENEA showed a global accuracy similar to that of endoscopists despite an unsatisfactory performance for non-adenomatous lesions.
C1 [Garcia-Rodriguez, Ana; Cordova, Henry; Carballal, Sabela; Ordas, Ingrid; Moreira, Leticia; Vaquero, Eva; Ortiz, Oswaldo; Rivero, Liseth; Pellise, Maria; Fernandez-Esparrach, Gloria] Univ Barcelona, Hosp Clin Barcelona, Endoscopy Unit, Gastroenterol Dept,ICMDiM, Barcelona, Catalonia, Spain.
   [Tudela, Yael; Sanchez, F. Javier; Bernal, Jorge] Autonomous Univ Barcelona, Comp Sci Dept, Barcelona, Catalonia, Spain.
   [Tudela, Yael; Sanchez, F. Javier; Bernal, Jorge] Comp Vis Ctr, Barcelona, Catalonia, Spain.
   [Cordova, Henry; Carballal, Sabela; Ordas, Ingrid; Moreira, Leticia; Vaquero, Eva; Rivero, Liseth; Cuatrecasas, Miriam; Pellise, Maria; Fernandez-Esparrach, Gloria] IDIBAPS, Barcelona, Catalonia, Spain.
   [Cordova, Henry; Carballal, Sabela; Ordas, Ingrid; Moreira, Leticia; Vaquero, Eva; Rivero, Liseth; Cuatrecasas, Miriam; Pellise, Maria; Fernandez-Esparrach, Gloria] CIBEREHD, Barcelona, Spain.
   [Cuatrecasas, Miriam] Univ Barcelona, Hosp Clin Barcelona, Pathol Dept, Barcelona, Catalonia, Spain.
C3 University of Barcelona; Hospital Clinic de Barcelona; Autonomous
   University of Barcelona; Centre de Visio per Computador (CVC);
   University of Barcelona; Hospital Clinic de Barcelona; IDIBAPS; CIBER -
   Centro de Investigacion Biomedica en Red; CIBEREHD; University of
   Barcelona; Hospital Clinic de Barcelona
RP Fernandez-Esparrach, G (通讯作者)，Hosp Clin Barcelona, Inst Malalties Digest, Endoscopy Unit, Villarroel 170, Barcelona 08036, Spain.
EM mgfernan@clinic.cat
RI Moreira, Leticia/AAN-9863-2021
OI Moreira, Leticia/0000-0002-4518-8591; Ortiz Zuniga,
   Oswaldo/0000-0001-7488-7765
FU Fundacio la Marato de TV3 [201932-30]; Iniciacio a la recerca de la
   Societat Catalana de Digestologia; Generalitat de Catalunya CERCA
   Programme; Departament d'Innovacio, Universitats i Empresa, Generalitat
   de Catalunya [2014-SGR-135, 2014-SGR-1470, SGR-2017-1669, SGR2017-653];
   Instituto de Salud Carlos III [PI17/00894, PI19/01050,
   PID2020120611RB-I00]; Spanish Ministry for Science and Innovation (MCIN)
   [PID2020-120311RB-I00]
FX Fundacio la Marato de TV3 201932-30 Iniciacio a la recerca de la
   Societat Catalana de Digestologia Generalitat de Catalunya CERCA
   Programme Departament d'Innovacio, Universitats i Empresa, Generalitat
   de Catalunya 2014-SGR-135,2014-SGR-1470,SGR-2017-1669,SGR2017-653
   Instituto de Salud Carlos III PI17/00894,
   PI19/01050,PID2020-120611RB-I00 Spanish Ministry for Science and
   Innovation (MCIN) PID2020120311RB-I00
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Bernal J, 2019, INT J COMPUT ASS RAD, V14, P191, DOI 10.1007/s11548-018-1864-x
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Bustamante-Balen M, 2021, ENDOSC INT OPEN, V09, pE14, DOI 10.1055/a-1293-7086
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dekker E, 2020, ENDOSCOPY, V52, P899, DOI 10.1055/a-1231-5123
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Houwen BBSL, 2022, ENDOSCOPY, V54, P88, DOI 10.1055/a-1689-5130
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Levin B, 2008, GASTROENTEROLOGY, V134, P1570, DOI 10.1053/j.gastro.2008.02.002
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2018, DIGEST ENDOSC, V30, P52, DOI 10.1111/den.13005
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Vu HT, 2015, DIGEST DIS SCI, V60, P502, DOI 10.1007/s10620-014-3376-z
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
NR 29
TC 0
Z9 0
U1 1
U2 1
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD SEP
PY 2022
VL 10
IS 09
BP E1201
EP E1207
DI 10.1055/a-1881-3178
PG 7
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA 4N8SI
UT WOS:000854283700008
PM 36118638
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Gong, EJ
   Bang, CS
   Lee, JJ
   Yang, YJ
   Baik, GH
AF Gong, Eun Jeong
   Bang, Chang Seok
   Lee, Jae Jun
   Yang, Young Joo
   Baik, Gwang Ho
TI Impact of the Volume and Distribution of Training Datasets in the
   Development of Deep-Learning Models for the Diagnosis of Colorectal
   Polyps in Endoscopy Images
SO JOURNAL OF PERSONALIZED MEDICINE
LA English
DT Article
DE artificial intelligence; no code; endoscopy; colonoscopy; colonic
   neoplasms
AB Background: Establishment of an artificial intelligence model in gastrointestinal endoscopy has no standardized dataset. The optimal volume or class distribution of training datasets has not been evaluated. An artificial intelligence model was previously created by the authors to classify endoscopic images of colorectal polyps into four categories, including advanced colorectal cancer, early cancers/high-grade dysplasia, tubular adenoma, and nonneoplasm. The aim of this study was to evaluate the impact of the volume and distribution of training dataset classes in the development of deep-learning models for colorectal polyp histopathology prediction from endoscopic images. Methods: The same 3828 endoscopic images that were used to create earlier models were used. An additional 6838 images were used to find the optimal volume and class distribution for a deeplearning model. Various amounts of data volume and class distributions were tried to establish deep-learning models. The training of deep-learning models uniformly used no-code platform Neuro-T. Accuracy was the primary outcome on four-class prediction. Results: The highest internal-test classification accuracy in the original dataset, doubled dataset, and tripled dataset was commonly shown by doubling the proportion of data for fewer categories (2:2:1:1 for advanced colorectal cancer: early cancers/high-grade dysplasia: tubular adenoma: non-neoplasm). Doubling the proportion of data for fewer categories in the original dataset showed the highest accuracy (86.4%, 95% confidence interval: 85.0-97.8%) compared to that of the doubled or tripled dataset. The total required number of images in this performance was only 2418 images. Gradient-weighted class activation mapping confirmed that the part that the deep-learning model pays attention to coincides with the part that the endoscopist pays attention to. Conclusion: As a result of a data-volume-dependent performance plateau in the classification model of colonoscopy, a dataset that has been doubled or tripled is not always beneficial to training. Deep-learning models would be more accurate if the proportion of fewer category lesions was increased.
C1 [Gong, Eun Jeong; Bang, Chang Seok; Yang, Young Joo; Baik, Gwang Ho] Hallym Univ, Dept Internal Med, Coll Med, Chunchon 24253, South Korea.
   [Gong, Eun Jeong; Bang, Chang Seok; Lee, Jae Jun] Hallym Univ, Inst New Frontier Res, Coll Med, Chunchon 24253, South Korea.
   [Lee, Jae Jun] Hallym Univ, Dept Anesthesiol & Pain Med, Coll Med, Chunchon 24253, South Korea.
C3 Hallym University; Hallym University; Hallym University
RP Bang, CS (通讯作者)，Hallym Univ, Dept Internal Med, Coll Med, Chunchon 24253, South Korea.; Bang, CS (通讯作者)，Hallym Univ, Inst New Frontier Res, Coll Med, Chunchon 24253, South Korea.
EM csbang@hallym.ac.kr
RI Bang, Chang SEOK/I-9689-2019
OI Gong, Eun Jeong/0000-0003-3996-3472; Bang, Chang
   Seok/0000-0003-4908-5431
FU Technology Development Program - Ministry of SMEs and Startups (MSS,
   Korea) [S2931703]; Korea Technology & Information Promotion Agency for
   SMEs (TIPA) [S2931703] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This work was supported by the Technology Development Program (S2931703)
   funded by the Ministry of SMEs and Startups (MSS, Korea).
CR Almadi MA, 2015, CAN J GASTROENTEROL, V29, P304, DOI 10.1155/2015/789038
   Bang Chang Seok, 2021, Korean Journal of Helicobacter Upper Gastrointestinal Research, V21, P300, DOI 10.7704/kjhugr.2021.0030
   Bang CS, 2021, J MED INTERNET RES, V23, DOI 10.2196/29682
   Bang CS, 2021, GASTROINTEST ENDOSC, V93, P1006, DOI 10.1016/j.gie.2020.11.025
   Bang CS, 2021, J MED INTERNET RES, V23, DOI 10.2196/25167
   Bang CS, 2020, KOR J GASTROENTEROL, V75, P120, DOI 10.4166/kjg.2020.75.3.120
   Bria A, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103735
   Cho BJ, 2020, AM J GASTROENTEROL, V115, P70, DOI 10.14309/ajg.0000000000000476
   Gong EJ, 2022, J PERS MED, V12, DOI 10.3390/jpm12060963
   Jha Debesh, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P218, DOI 10.1007/978-3-030-67835-7_19
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Juba B, 2019, AAAI CONF ARTIF INTE, P4039
   Kandel P, 2019, CLIN ENDOSC, V52, P239, DOI 10.5946/ce.2018.136
   Khamparia A, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12400
   Milluzzo SM, 2021, CLIN ENDOSC, V54, P329, DOI 10.5946/ce.2020.082
   Schouten JPE, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-86995-5
   Shahinfar S, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101085
   Yang CB, 2022, CLIN ENDOSC, V55, P594, DOI 10.5946/ce.2021.229
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yoshida Y, 2020, J STAT MECH-THEORY E, V2020, DOI 10.1088/1742-5468/abc62f
NR 22
TC 1
Z9 1
U1 2
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4426
J9 J PERS MED
JI J. Pers. Med.
PD SEP
PY 2022
VL 12
IS 9
AR 1361
DI 10.3390/jpm12091361
PG 9
WC Health Care Sciences & Services; Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; General & Internal Medicine
GA 4R4EN
UT WOS:000856719500001
PM 36143146
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Koffas, A
   Papaefthymiou, A
   Laskaratos, FM
   Kapsoritakis, A
   Epstein, O
AF Koffas, Apostolos
   Papaefthymiou, Apostolis
   Laskaratos, Faidon-Marios
   Kapsoritakis, Andreas
   Epstein, Owen
TI Colon Capsule Endoscopy in the Diagnosis of Colon Polyps: Who Needs a
   Colonoscopy?
SO DIAGNOSTICS
LA English
DT Review
DE colon capsule endoscopy; colon polyps; colorectal cancer screening
ID SOCIETY-TASK-FORCE; ON-COLORECTAL-CANCER; CT COLONOGRAPHY; INCOMPLETE
   COLONOSCOPY; ARTIFICIAL-INTELLIGENCE; CLINICAL-EFFICACY;
   AMERICAN-COLLEGE; EUROPEAN-SOCIETY; VS. COLONOSCOPY; MISS RATE
AB Colon screening programs have reduced colon cancer mortality. Population screening should be minimally invasive, safe, acceptably sensitive, cost-effective, and scalable. The range of screening modalities include guaiac or immunochemical fecal occult blood testing and CT colonography and colonoscopy. A number of carefully controlled studies concur that second-generation capsule endoscopy has excellent sensitivity for polyp detection and a high negative predictive value. Colon capsules fulfill the screening expectation of safety, high sensitivity for polyp detection, and patient acceptance, and appear to straddle the divide between occult blood testing and colonoscopy. While meeting these criteria, there remains the challenges of scaling, capsule practitioner training, resource allocation, and implementing change of practice. Like CT colonography, capsule screening presents the clinician with a decision on the threshold for colonoscopy referral. Overall, colon capsules are an invaluable tool in polyp detection and colon screening and offer a filter that determines "who needs a colonoscopy?".
C1 [Koffas, Apostolos; Papaefthymiou, Apostolis; Kapsoritakis, Andreas] Univ Hosp Larissa, Dept Gastroenterol, Mezourlo 41110, Larissa, Greece.
   [Laskaratos, Faidon-Marios] St Marks Hosp, Wolfson Unit Endoscopy, London HA1 3UJ, England.
   [Epstein, Owen] Royal Free London, Inst Minimally Invas Gastroenterol, London NW3 2QG, England.
C3 General University Hospital of Larissa; Imperial College London;
   University of London; University College London; Royal Free London NHS
   Foundation Trust
RP Koffas, A (通讯作者)，Univ Hosp Larissa, Dept Gastroenterol, Mezourlo 41110, Larissa, Greece.
EM apostolos_koffas@hotmail.com
RI koffas, Apostolos/AAU-6858-2020
OI koffas, Apostolos/0000-0002-2637-3847; Papaefthymiou,
   Apostolis/0000-0002-3563-4973; Laskaratos,
   Faidon-Marios/0000-0002-8673-1837
CR Adrian-De-Ganzo Z, 2015, CLIN GASTROENTEROL H, V13, P2293, DOI 10.1016/j.cgh.2015.06.032
   Akyuz U, 2016, GASTROENT RES PRACT, V2016, DOI 10.1155/2016/2738208
   Alarcon-Fernandez O, 2013, CLIN GASTROENTEROL H, V11, P534, DOI 10.1016/j.cgh.2012.10.016
   Ali H, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.17560
   Alihosseini Samira, 2020, Med J Islam Repub Iran, V34, P81, DOI 10.34171/mjiri.34.81
   Baltes P, 2018, WORLD J GASTROENTERO, V24, P3556, DOI 10.3748/wjg.v24.i31.3556
   Benard F, 2018, WORLD J GASTROENTERO, V24, P124, DOI 10.3748/wjg.v24.i1.124
   Benech N, 2021, ENDOSC INT OPEN, V09, pE1542, DOI 10.1055/a-1526-0923
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Blanes-Vidal V, 2018, INT J COLORECTAL DIS, V33, P1309, DOI 10.1007/s00384-018-3064-0
   Bond J H, 2000, Semin Gastrointest Dis, V11, P176
   Buijs MM, 2018, UNITED EUR GASTROENT, V6, P1563, DOI 10.1177/2050640618798182
   Cash BD, 2021, GUT, V70, P2115, DOI 10.1136/gutjnl-2020-322578
   Chen CD, 2003, BRIT J CANCER, V88, P1866, DOI 10.1038/sj.bjc.6601007
   Coe S G, 2011, Minerva Gastroenterol Dietol, V57, P167
   Valdivia PC, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12051105
   Davidson KW, 2021, JAMA-J AM MED ASSOC, V325, P1965, DOI 10.1001/jama.2021.6238
   Deding U, 2020, UNITED EUR GASTROENT, V8, P782, DOI 10.1177/2050640620937593
   Deding U, 2022, CLIN EPIDEMIOL, V14, P437, DOI 10.2147/CLEP.S353527
   Deding U, 2021, ENDOSC INT OPEN, V09, pE1712, DOI 10.1055/a-1546-8727
   Deding U, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11091730
   Deding U, 2020, CANCERS, V12, DOI 10.3390/cancers12113367
   Edwards BK, 2010, CANCER-AM CANCER SOC, V116, P544, DOI 10.1002/cncr.24760
   Eliakim R, 2006, ENDOSCOPY, V38, P963, DOI 10.1055/s-2006-944832
   Eliakim R, 2009, ENDOSCOPY, V41, P1026, DOI 10.1055/s-0029-1215360
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Fernandez-Urien I, 2015, REV ESP ENFERM DIG, V107, P745
   Franco Diana L, 2017, Gastroenterol Hepatol (N Y), V13, P476
   Gay G, 2010, AM J GASTROENTEROL, V105, P1076, DOI 10.1038/ajg.2009.624
   Gonzalez-Suarez B, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01717-4
   Groth S, 2012, BMC GASTROENTEROL, V12, DOI 10.1186/1471-230X-12-80
   Hagel AF, 2014, CAN J GASTROENTEROL, V28, P77, DOI 10.1155/2014/691785
   Hamilton S.R., COLORECTAL CANC SCRE
   Hassan C, 2008, ENDOSCOPY, V40, P414, DOI 10.1055/s-2007-995565
   Hausmann J, 2021, CLIN ENDOSC, V54, P92, DOI 10.5946/ce.2020.049
   He E, 2019, INT J EPIDEMIOL, V48, P549, DOI 10.1093/ije/dyy271
   Hoff G, 2010, GUT, V59, P407, DOI 10.1136/gut.2009.192948
   Holleran G, 2014, ENDOSCOPY, V46, P473, DOI 10.1055/s-0034-1365402
   Hussey M, 2018, UNITED EUR GASTROENT, V6, P1556, DOI 10.1177/2050640618800629
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Igawa A, 2017, DIGESTION, V95, P43, DOI 10.1159/000452367
   Ismail MS, 2022, BMC GASTROENTEROL, V22, DOI 10.1186/s12876-021-02081-0
   Kim DH, 2007, NEW ENGL J MED, V357, P1403, DOI 10.1056/NEJMoa070543
   Kim DH, 2007, AM J ROENTGENOL, V188, P940, DOI 10.2214/AJR.06.0764
   Kjolhede T, 2021, ENDOSCOPY, V53, P713, DOI 10.1055/a-1249-3938
   Kobaek-Larsen M, 2018, COLORECTAL DIS, V20, P479, DOI 10.1111/codi.13965
   Koffas A, 2019, WORLD J GASTRO ENDOS, V11, P395, DOI 10.4253/wjge.v11.i6.395
   Koulaouzidis A, 2021, THER ADV GASTROINTES, V14, DOI 10.1177/26317745211001983
   Kroijer R, 2019, COLORECTAL DIS, V21, P532, DOI 10.1111/codi.14557
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Levin B, 2008, GASTROENTEROLOGY, V134, P1570, DOI 10.1053/j.gastro.2008.02.002
   MacLeod C, 2022, BMC GASTROENTEROL, V22, DOI 10.1186/s12876-022-02332-8
   Meklin J, 2020, ANTICANCER RES, V40, P3591, DOI 10.21873/anticanres.14349
   Mollers T, 2021, ENDOSC INT OPEN, V09, pE562, DOI 10.1055/a-1353-4849
   Moen S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12081994
   Muguruma N, 2017, CLIN J GASTROENTEROL, V10, P1, DOI 10.1007/s12328-016-0710-3
   Nakazawa K, 2021, INTERNAL MED, V60, P1805, DOI 10.2169/internalmedicine.6446-20
   Negreanu L, 2013, WORLD J GASTRO ENDOS, V5, P559, DOI 10.4253/wjge.v5.i11.559
   NHS England NHS, ROLLS OUT CAPS CAM T
   Njor SH, 2021, CANCER MED-US, V10, P1872, DOI 10.1002/cam4.3761
   Nogales O, 2017, REV ESP ENFERM DIG, V109, P322, DOI 10.17235/reed.2017.4369/2016
   Otani I, 2020, DIGESTION, V101, P262, DOI 10.1159/000499332
   Pannala Rahul, 2020, VideoGIE, V5, P598, DOI 10.1016/j.vgie.2020.08.013
   Pasha Shabana F, 2018, Curr Gastroenterol Rep, V20, P22, DOI 10.1007/s11894-018-0628-7
   Pecere S, 2020, GASTROINTEST ENDOSC, V91, P406, DOI 10.1016/j.gie.2019.09.041
   Pickhardt PJ, 2008, AM J ROENTGENOL, V190, P136, DOI 10.2214/AJR.07.2646
   Pickhardt PJ, 2004, RADIOLOGY, V232, P784, DOI 10.1148/radiol.2323031614
   Pilz JB, 2010, BMC GASTROENTEROL, V10, DOI 10.1186/1471-230X-10-66
   Pioche M, 2018, ENDOSCOPY, V50, P761, DOI 10.1055/s-0044-100721
   Rembacken BJ, 2000, LANCET, V355, P1211, DOI 10.1016/S0140-6736(00)02086-9
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2015, GASTROENTEROLOGY, V148, P948, DOI 10.1053/j.gastro.2015.01.025
   Rokkas T, 2010, GASTROINTEST ENDOSC, V71, P792, DOI 10.1016/j.gie.2009.10.050
   Rondagh EJA, 2012, SCAND J GASTROENTERO, V47, P80, DOI 10.3109/00365521.2011.638395
   Rondonotti E, 2014, CLIN GASTROENTEROL H, V12, P1303, DOI 10.1016/j.cgh.2013.12.027
   Sacher-Huvelin S, 2010, ALIMENT PHARM THER, V32, P1145, DOI 10.1111/j.1365-2036.2010.04458.x
   Saito Y, 2015, GASTROINTEST ENDOSC, V82, P861, DOI 10.1016/j.gie.2015.02.004
   Saurin JC, 2004, GASTROEN CLIN BIOL, V28, P641, DOI 10.1016/S0399-8320(04)95041-5
   Schoofs N, 2006, ENDOSCOPY, V38, P971, DOI 10.1055/s-2006-944835
   Senore C, 2019, GUT, V68, P1232, DOI 10.1136/gutjnl-2018-317293
   Shaukat A, 2021, AM J GASTROENTEROL, V116, P458, DOI 10.14309/ajg.0000000000001122
   Sieg A, 2009, AM J GASTROENTEROL, V104, P848, DOI 10.1038/ajg.2008.163
   Soetikno R, 2006, GASTROENTEROLOGY, V130, P566, DOI 10.1053/j.gastro.2005.12.006
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Spada C., 2013, DIGEST LIVER DIS, V45, pS141, DOI [10.1016/S1590-8658(13)60395-3, DOI 10.1016/S1590-8658(13)60395-3]
   Spada C, 2021, EUR RADIOL, V31, P2967, DOI 10.1007/s00330-020-07413-4
   Spada C, 2016, CLIN GASTROENTEROL H, V14, P1533, DOI 10.1016/j.cgh.2016.04.038
   Spada Cristiano, 2015, Gastrointest Endosc Clin N Am, V25, P387, DOI 10.1016/j.giec.2014.11.007
   Spada C, 2015, GUT, V64, P272, DOI 10.1136/gutjnl-2013-306550
   Spada C, 2011, GASTROINTEST ENDOSC, V74, P581, DOI 10.1016/j.gie.2011.03.1125
   Spada C, 2011, DIGEST LIVER DIS, V43, P300, DOI 10.1016/j.dld.2010.10.005
   Spada C, 2011, J CLIN GASTROENTEROL, V45, P119, DOI 10.1097/MCG.0b013e3181dac04b
   Spada C, 2010, CLIN GASTROENTEROL H, V8, P516, DOI 10.1016/j.cgh.2010.02.018
   Sulbaran M, 2022, J MED SCREEN, V29, P148, DOI 10.1177/09691413221074803
   Thygesen MK, 2019, ACTA ONCOL, V58, pS71, DOI 10.1080/0284186X.2019.1581372
   Togashi K, 2015, ENDOSC INT OPEN, V3, pE659, DOI 10.1055/s-0034-1393075
   Triantafyllou K, 2014, GASTROINTEST ENDOSC, V79, P307, DOI 10.1016/j.gie.2013.07.061
   Tsuda S, 2002, GUT, V51, P550, DOI 10.1136/gut.51.4.550
   Utano K, 2020, DIGESTION, V101, P615, DOI 10.1159/000501609
   Van Gossum A, 2009, NEW ENGL J MED, V361, P264, DOI 10.1056/NEJMoa0806347
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   von Karsa L, 2013, ENDOSCOPY, V45, P51, DOI 10.1055/s-0032-1325997
   Voska M, 2019, GASTROENT RES PRACT, V2019, DOI 10.1155/2019/5975438
   Vuik FER, 2021, ENDOSCOPY, V53, P815, DOI 10.1055/a-1308-1297
   Vuik FER, 2022, CLIN GASTROENTEROL H, V20, P692, DOI 10.1016/j.cgh.2020.10.048
   Wang YC, 2020, BMC GASTROENTEROL, V20, DOI 10.1186/s12876-020-01491-w
   Wilt TJ, 2015, ANN INTERN MED, V162, P718, DOI 10.7326/M14-2326
   Winawer SJ, 2006, GASTROENTEROLOGY, V130, P1872, DOI 10.1053/j.gastro.2006.03.012
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457
NR 110
TC 2
Z9 2
U1 2
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD SEP
PY 2022
VL 12
IS 9
AR 2093
DI 10.3390/diagnostics12092093
PG 17
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 4S5LJ
UT WOS:000857482200001
PM 36140494
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Lu, YB
   Lu, SC
   Huang, YN
   Cai, ST
   Le, PH
   Hsu, FY
   Hu, YX
   Hsieh, HS
   Chen, WT
   Xia, GL
   Xu, HZ
   Gong, W
AF Lu, Yang-Bor
   Lu, Si-Cun
   Huang, Yung-Ning
   Cai, Shun-Tian
   Le, Puo-Hsien
   Hsu, Fang-Yu
   Hu, Yan-Xing
   Hsieh, Hui-Shan
   Chen, Wei-Ting
   Xia, Gui-Li
   Xu, Hong-Zhi
   Gong, Wei
TI A Novel Convolutional Neural Network Model as an Alternative Approach to
   Bowel Preparation Evaluation Before Colonoscopy in the COVID-19 Era: A
   Multicenter, Single-Blinded, Randomized Study
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
ID COLORECTAL-CANCER; PREPARATION QUALITY; IMPACT; VALIDATION; GUIDELINES;
   SCALES
AB INTRODUCTION: Adequate bowel preparation is key to a successful colonoscopy, which is necessary for detecting adenomas and preventing colorectal cancer. We developed an artificial intelligence (AI) platform using a convolutional neural network (CNN) model (AI-CNN model) to evaluate the quality of bowel preparation before colonoscopy. METHODS: This was a colonoscopist-blinded, randomized study. Enrolled patients were randomized into an experimental group, in which our AI-CNN model was used to evaluate the quality of bowel preparation (AI-CNN group), or a control group, which performed self-evaluation per routine practice (control group). The primary outcome was the consistency (homogeneity) between the results of the 2 methods. The secondary outcomes included the quality of bowel preparation according to the Boston Bowel Preparation Scale (BBPS), polyp detection rate, and adenoma detection rate. RESULTS: A total of 1,434 patients were enrolled (AI-CNN, n = 730; control, n = 704). No significant difference was observed between the evaluation results ("pass" or "not pass") of the groups in the adequacy of bowel preparation as represented by BBPS scores. The mean BBPS scores, polyp detection rate, and adenoma detection rate were similar between the groups. These results indicated that the AI-CNN model and routine practice were generally consistent in the evaluation of bowel preparation quality. However, the mean BBPS score of patients with "pass" results were significantly higher in the AI-CNN group than in the control group, indicating that the AI-CNN model may further improve the quality of bowel preparation in patients exhibiting adequate bowel preparation. DISCUSSION: The novel AI-CNN model, which demonstrated comparable outcomes to the routine practice, may serve as an alternative approach for evaluating bowel preparation quality before colonoscopy.
C1 [Lu, Yang-Bor; Huang, Yung-Ning] Xiamen Chang Gung Hosp, Dept Digest Dis, Fujian, Peoples R China.
   [Lu, Si-Cun; Xia, Gui-Li; Gong, Wei] Southern Med Univ, Shenzhen Hosp, Dept Gastroenterol, Shenzhen, Peoples R China.
   [Cai, Shun-Tian; Xu, Hong-Zhi] Xiamen Univ, Zhongshan Hosp, Dept Gastroenterol, Xiamen, Peoples R China.
   [Le, Puo-Hsien; Hsu, Fang-Yu; Chen, Wei-Ting] Chang Gung Mem Hosp, Linkou Branch, Dept Gastroenterol & Hepatol, Taoyuan, Taiwan.
   [Hu, Yan-Xing] Xiamen Innovis Med Technol Co Ltd, Xiammen, Fujian, Peoples R China.
   [Hsieh, Hui-Shan] Xiamen Chang Gung Hosp, Sleep Ctr, Dept Otolaryngol Head & Neck Surg, Xiamen, Fujian, Peoples R China.
C3 Southern Medical University - China; Xiamen University; Chang Gung
   Memorial Hospital
RP Xia, GL; Gong, W (通讯作者)，Southern Med Univ, Shenzhen Hosp, Dept Gastroenterol, Shenzhen, Peoples R China.; Xu, HZ (通讯作者)，Xiamen Univ, Zhongshan Hosp, Dept Gastroenterol, Xiamen, Peoples R China.
EM bentleylu@gmail.com; lusicun@163.com; ning0219@gmail.com;
   nktianxingjian@163.com; puohsien@gmail.com; fish6364@cgmh.org.tw;
   huyx@xm-innovision.com; hsieh1111@gmail.com; weiting1972@gmail.com;
   354996454@qq.com; xuhongzhi@xmu.edu.cn; drgwei@foxmail.com
RI Hu, Yanxing/AHA-3827-2022
OI Huang, Yung-Ning/0000-0002-8912-6173
FU Xiamen Medical Health Science and Technology Project [3502Z20199172,
   3502Z20209026]; Xiamen Chang Gung Hospital Science Project [CMRPG1E0891]
FX The study was supported by the Xiamen Medical Health Science and
   Technology Project (Project numbers: 3502Z20199172 and 3502Z20209026)
   and Xiamen Chang Gung Hospital Science Project (CMRPG1E0891).
CR Back SY, 2018, GASTROINTEST ENDOSC, V87, P789, DOI 10.1016/j.gie.2017.09.007
   Brenner H, 2014, LANCET, V383, P1490, DOI 10.1016/S0140-6736(13)61649-9
   Calderwood AH, 2010, GASTROINTEST ENDOSC, V72, P686, DOI 10.1016/j.gie.2010.06.068
   Cancer Council Australia, CLIN PRACTICE GUIDEL
   Chokshi RV, 2012, GASTROINTEST ENDOSC, V75, P1197, DOI 10.1016/j.gie.2012.01.005
   Digestive Endoscopy Special Committee of Endoscopic Physicians Branch of Chinese Medical Association, 2019, Zhonghua Nei Ke Za Zhi, V58, P485, DOI 10.3760/cma.j.issn.0578-1426.2019.07.002
   Guo BM, 2020, J ADV NURS, V76, P1037, DOI 10.1111/jan.14295
   Guo R, 2019, BMC GASTROENTEROL, V19, DOI 10.1186/s12876-019-1019-8
   Hassan Cesare, 2020, Endosc Int Open, V8, pE928, DOI 10.1055/a-1167-1359
   Hassan C, 2019, ENDOSCOPY, V51, P775, DOI 10.1055/a-0959-0505
   Hassan C, 2012, CLIN GASTROENTEROL H, V10, P501, DOI 10.1016/j.cgh.2011.12.037
   Heron V, 2017, ENDOSC INT OPEN, V5, pE1179, DOI 10.1055/s-0043-119749
   Imperiale TF, 2008, NEW ENGL J MED, V359, P1218, DOI 10.1056/NEJMoa0803597
   Jover R, 2012, ENDOSCOPY, V44, P444, DOI 10.1055/s-0032-1306690
   Jover R, 2013, GASTROINTEST ENDOSC, V77, P381, DOI 10.1016/j.gie.2012.09.027
   Kang XY, 2016, CLIN GASTROENTEROL H, V14, P429, DOI 10.1016/j.cgh.2015.09.038
   Kastenberg D, 2018, WORLD J GASTROENTERO, V24, P2833, DOI 10.3748/wjg.v24.i26.2833
   Lee JK, 2019, JAMA INTERN MED, V179, P153, DOI 10.1001/jamainternmed.2018.5565
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Lorenzo-Zuniga V, 2015, DIGEST ENDOSC, V27, P590, DOI 10.1111/den.12467
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Morris EJA, 2021, LANCET GASTROENTEROL, V6, P199, DOI 10.1016/S2468-1253(21)00005-4
   Parmar R, 2016, AM J GASTROENTEROL, V111, P197, DOI 10.1038/ajg.2015.417
   Pillai A, 2018, J CLIN GASTROENTEROL, V52, P515, DOI 10.1097/MCG.0000000000000893
   Richter JM, 2015, CLIN COLORECTAL CANC, V14, P46, DOI 10.1016/j.clcc.2014.11.001
   Saltzman JR, 2015, GASTROINTEST ENDOSC, V81, P781, DOI 10.1016/j.gie.2014.09.048
   Solonowicz O, 2022, J CLIN GASTROENTEROL, V56, P166, DOI 10.1097/MCG.0000000000001497
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tae JW, 2012, GASTROINTEST ENDOSC, V76, P804, DOI 10.1016/j.gie.2012.05.026
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
NR 31
TC 3
Z9 3
U1 6
U2 15
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0002-9270
EI 1572-0241
J9 AM J GASTROENTEROL
JI Am. J. Gastroenterol.
PD SEP
PY 2022
VL 117
IS 9
BP 1437
EP 1443
DI 10.14309/ajg.0000000000001900
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 4E1MU
UT WOS:000847597800018
PM 35973166
OA hybrid
DA 2023-08-21
ER

PT J
AU Mohapatra, S
   Pati, GK
   Mishra, M
   Swarnkar, T
AF Mohapatra, Subhashree
   Pati, Girish Kumar
   Mishra, Manohar
   Swarnkar, Tripti
TI UPolySeg: A U-Net-Based Polyp Segmentation Network Using Colonoscopy
   Images
SO GASTROENTEROLOGY INSIGHTS
LA English
DT Article
DE segmentation; polyp; U-Net; colonoscopy; deep learning
AB Colonoscopy is a gold standard procedure for tracking the lower gastrointestinal region. A colorectal polyp is one such condition that is detected through colonoscopy. Even though technical advancements have improved the early detection of colorectal polyps, there is still a high percentage of misses due to various factors. Polyp segmentation can play a significant role in the detection of polyps at the early stage and can thus help reduce the severity of the disease. In this work, the authors implemented several image pre-processing techniques such as coherence transport and contrast limited adaptive histogram equalization (CLAHE) to handle different challenges in colonoscopy images. The processed image was then segmented into a polyp and normal pixel using a U-Net-based deep learning segmentation model named UPolySeg. The main framework of UPolySeg has an encoder-decoder section with feature concatenation in the same layer as the encoder-decoder along with the use of dilated convolution. The model was experimentally verified using the publicly available Kvasir-SEG dataset, which gives a global accuracy of 96.77%, a dice coefficient of 96.86%, an IoU of 87.91%, a recall of 95.57%, and a precision of 92.29%. The new framework for the polyp segmentation implementing UPolySeg improved the performance by 1.93% compared with prior work.
C1 [Mohapatra, Subhashree] Siksha O Anusandhan Deemed Univ, Dept Comp Sci & Engn, Bhubaneswar 751030, India.
   [Pati, Girish Kumar] Inst Med Sci, Dept Gastroenterol, Bhubaneswar 751003, India.
   [Pati, Girish Kumar] SUM Hosp, Bhubaneswar 751003, India.
   [Mishra, Manohar] Siksha O Anusandhan Deemed Univ, Dept Elect & Elect Engn, Bhubaneswar 751030, India.
   [Swarnkar, Tripti] Siksha O Anusandhan Deemed Univ, Dept Comp Applicat, Bhubaneswar 751030, India.
C3 Siksha 'O' Anusandhan University; Siksha 'O' Anusandhan University;
   Siksha 'O' Anusandhan University; Siksha 'O' Anusandhan University;
   Siksha 'O' Anusandhan University
RP Mishra, M (通讯作者)，Siksha O Anusandhan Deemed Univ, Dept Elect & Elect Engn, Bhubaneswar 751030, India.
EM manoharmishra@soa.ac.in
RI Mishra, Manohar/ADD-8409-2022
OI Mishra, Manohar/0000-0003-2160-4703; PATI, GIRISH
   KUMAR/0000-0002-9389-1425
CR Baldeon-Calisto M, 2020, NEUROCOMPUTING, V392, P325, DOI 10.1016/j.neucom.2019.01.110
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   Huang C. -H., 2021, ARXIV
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kayser M., 2020, ARXIV
   Koonsanit K., 2017, P 2017 10 BIOMEDICAL, P1
   Marz T, 2015, FOUND COMPUT MATH, V15, P973, DOI 10.1007/s10208-014-9199-7
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Mohapatra S, 2021, INTERDISCIP SCI, V13, P212, DOI 10.1007/s12539-021-00417-8
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/crv52889.2021.00032, 10.1109/CRV52889.2021.00032]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Rundo L, 2020, SMART INNOV SYST TEC, V151, P269, DOI 10.1007/978-981-13-8950-4_25
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Xi Y, 2021, TRANSL ONCOL, V14, DOI 10.1016/j.tranon.2021.101174
   Xu YX, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0246892
   Yao JH, 2007, MED PHYS, V34, P1655, DOI 10.1118/1.2717411
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Zhang JM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132686
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
NR 28
TC 1
Z9 1
U1 3
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2036-7414
EI 2036-7422
J9 GASTROENTEROL INSIGH
JI Gastroenterol. Insights
PD SEP
PY 2022
VL 13
IS 3
BP 264
EP 274
DI 10.3390/gastroent13030027
PG 11
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA 4S6JY
UT WOS:000857546100001
OA gold
DA 2023-08-21
ER

PT J
AU Ramzan, M
   Raza, M
   Sharif, MI
   Kadry, S
AF Ramzan, Muhammad
   Raza, Mudassar
   Sharif, Muhammad Imran
   Kadry, Seifedine
TI Gastrointestinal Tract Polyp Anomaly Segmentation on Colonoscopy Images
   Using Graft-U-Net
SO JOURNAL OF PERSONALIZED MEDICINE
LA English
DT Article
DE segmentation; convolutional neural network; deep learning;
   gastrointestinal tract; health informatics
ID CONVOLUTIONAL NEURAL-NETWORK; CLASSIFICATION; VALIDATION
AB Computer-aided polyp segmentation is a crucial task that supports gastroenterologists in examining and resecting anomalous tissue in the gastrointestinal tract. The disease polyps grow mainly in the colorectal area of the gastrointestinal tract and in the mucous membrane, which has protrusions of micro-abnormal tissue that increase the risk of incurable diseases such as cancer. So, the early examination of polyps can decrease the chance of the polyps growing into cancer, such as adenomas, which can change into cancer. Deep learning-based diagnostic systems play a vital role in diagnosing diseases in the early stages. A deep learning method, Graft-U-Net, is proposed to segment polyps using colonoscopy frames. Graft-U-Net is a modified version of UNet, which comprises three stages, including the preprocessing, encoder, and decoder stages. The preprocessing technique is used to improve the contrast of the colonoscopy frames. Graft-U-Net comprises encoder and decoder blocks where the encoder analyzes features, while the decoder performs the features' synthesizing processes. The Graft-U-Net model offers better segmentation results than existing deep learning models. The experiments were conducted using two open-access datasets, Kvasir-SEG and CVC-ClinicDB. The datasets were prepared from the large bowel of the gastrointestinal tract by performing a colonoscopy procedure. The anticipated model outperforms in terms of its mean Dice of 96.61% and mean Intersection over Union (mIoU) of 82.45% with the Kvasir-SEG dataset. Similarly, with the CVC-ClinicDB dataset, the method achieved a mean Dice of 89.95% and an mIoU of 81.38%.
C1 [Ramzan, Muhammad; Raza, Mudassar; Sharif, Muhammad Imran] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Islamabad 47040, Pakistan.
   [Kadry, Seifedine] Noroff Univ Coll, Dept Appl Data Sci, N-4612 Kristiansand, Norway.
   [Kadry, Seifedine] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 999095, Lebanon.
C3 COMSATS University Islamabad (CUI); Lebanese American University
RP Raza, M (通讯作者)，COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Islamabad 47040, Pakistan.
EM mudassarkazmi@yahoo.com
RI Sharif, Muhammad Imran/HJB-2089-2022; Kadry, Seifedine/C-7437-2011
OI Sharif, Muhammad Imran/0000-0002-4786-6579; Kadry,
   Seifedine/0000-0002-1939-4842; Raza, Mudassar/0000-0001-9124-9298
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Amin J, 2022, CMC-COMPUT MATER CON, V70, P6023, DOI 10.32604/cmc.2022.019115
   Amin J, 2021, CMC-COMPUT MATER CON, V69, P785, DOI 10.32604/cmc.2021.015249
   Amin J, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1483-2
   Amin J, 2020, NEURAL COMPUT APPL, V32, P15965, DOI 10.1007/s00521-019-04650-7
   Amin J, 2020, COGN SYST RES, V59, P304, DOI 10.1016/j.cogsys.2019.10.002
   Amin J, 2019, COMPUT METH PROG BIO, V177, P69, DOI 10.1016/j.cmpb.2019.05.015
   Amin J, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P497
   Amin J, 2018, MICROSC RES TECHNIQ, V81, P990, DOI 10.1002/jemt.23063
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grady WM, 2021, ADV CANCER RES, V151, P425, DOI 10.1016/bs.acr.2021.02.006
   Guo JT, 2017, ENDOSC ULTRASOUND, V6, P376, DOI 10.4103/eus.eus_87_17
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   Huang C. -H., 2021, ARXIV
   Ioffe S., 2015, PROC INT C MACH LEAR, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Kassani SH, 2022, INT J MED INFORM, V159, DOI 10.1016/j.ijmedinf.2021.104669
   Khan MA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12497
   Kronborg O, 2007, DIGEST DIS, V25, P270, DOI 10.1159/000103899
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Lin Y, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108917
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Mori Y, 2013, ENDOSCOPY, V45, P98, DOI 10.1055/s-0032-1325932
   Nagahara A, 2022, DIGEST ENDOSC, V34, P63, DOI 10.1111/den.13982
   Naz J, 2023, NEURAL PROCESS LETT, V55, P115, DOI 10.1007/s11063-021-10481-2
   Naz J, 2021, CURR MED IMAGING, V17, P479, DOI 10.2174/1573405616666200928144626
   Naz M, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.386
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Park KB, 2022, J COMPUT DES ENG, V9, P616, DOI 10.1093/jcde/qwac018
   Ramzan M, 2021, CMC-COMPUT MATER CON, V69, P3239, DOI 10.32604/cmc.2021.015920
   Rasheed S, 2022, J PERS MED, V12, DOI 10.3390/jpm12081232
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ribeiro Jose, 2022, Procedia Computer Science, P477, DOI 10.1016/j.procs.2021.12.039
   Riegler M, 2017, THESIS U OSLO OSLO N
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saba T, 2018, MICROSC RES TECHNIQ, V81, P1105, DOI 10.1002/jemt.23094
   Shahzad A, 2022, COMPLEX INTELL SYST, V8, P3143, DOI 10.1007/s40747-021-00564-x
   Sharif M, 2020, NEURAL COMPUT APPL, V32, P15975, DOI 10.1007/s00521-019-04679-8
   Sharif MI, 2022, COMPLEX INTELL SYST, V8, P3007, DOI 10.1007/s40747-021-00321-0
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Song PF, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105476
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Tomar N.K., 2021, ARXIV
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Yeung M, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102026
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
NR 60
TC 0
Z9 0
U1 2
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4426
J9 J PERS MED
JI J. Pers. Med.
PD SEP
PY 2022
VL 12
IS 9
AR 1459
DI 10.3390/jpm12091459
PG 17
WC Health Care Sciences & Services; Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; General & Internal Medicine
GA 4W3ZU
UT WOS:000860105900001
PM 36143244
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Shukla, J
   Samanta, J
AF Shukla, Jayendra
   Samanta, Jayanta
TI Endocuff Vision to Improve Adenoma Vision: A Brief Overview
SO JOURNAL OF DIGESTIVE ENDOSCOPY
LA English
DT Review
DE colonoscopy; polyp; adenoma detection rate; distal attachment cap;
   colorectal cancer
ID ASSISTED COLONOSCOPY; METAANALYSIS; MULTICENTER
AB Colorectal cancer (CRC)-related mortality can be reduced through screening and early detection. The aim of any CRC screening program is to detect as many adenomas/polyps in the early stage as possible and hence, adenoma detection rate (ADR) is a key quality indicator of colonoscopy. Various methods and techniques have been studied and developed over the years to improve the quality of colonoscopy and thereby increase ADR. This ranges from use of various regimens to improve bowel preparation, defining an optimum colonoscope withdrawal time for the operator, distal attachment caps, use of different wavelength of light, colonoscope with increased degree of view to the use of modern-day artificial intelligence to improve ADR. Of all the various measures, use of distal attachment device seems an easy, cheap and readily usable technique to increase real-time ADR. A variety of such devices have been evaluated over time starting from simple transparent caps, EndoRings, Endocuff to Endocuff Vision for their effectiveness. In this review, we have provided a brief description of the various available distal attachment devices and a detailed technical overview of Endocuff and its modification the Endocuff Vision.
C1 [Shukla, Jayendra; Samanta, Jayanta] Postgrad Inst Med Educ & Res, Dept Gastroenterol, Sect 12, Chandigarh 160012, India.
C3 Post Graduate Institute of Medical Education & Research (PGIMER),
   Chandigarh
RP Samanta, J (通讯作者)，Postgrad Inst Med Educ & Res, Dept Gastroenterol, Sect 12, Chandigarh 160012, India.
EM dj_samanta@yahoo.co.in
CR Aziz M, 2021, ENDOSC INT OPEN, V09, pE41, DOI 10.1055/a-1293-7327
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dik VK, 2015, ENDOSCOPY, V47, P1151, DOI 10.1055/s-0034-1392421
   Gkolfakis P, 2018, WORLD J GASTROENTERO, V24, P4243, DOI 10.3748/wjg.v24.i37.4243
   Hassan C, 2019, GASTROINTEST ENDOSC, V89, P583, DOI 10.1016/j.gie.2018.10.019
   Jacob A, 2019, ANZ J SURG, V89, pE174, DOI 10.1111/ans.15067
   Karsenti D, 2020, GUT, V69, P2159, DOI 10.1136/gutjnl-2019-319565
   Marsano J, 2019, ENDOSC INT OPEN, V7, pE1585, DOI 10.1055/a-0996-7891
   Mir FA, 2017, ANN GASTROENTEROL, V30, P640, DOI 10.20524/aog.2017.0180
   Ngu WS, 2019, GUT, V68, P280, DOI 10.1136/gutjnl-2017-314889
   Patel HK, 2021, GASTROINTEST ENDOSC, V93, P544, DOI 10.1016/j.gie.2020.09.045
   Rameshshanker R, 2020, GASTROINTEST ENDOSC, V91, P894, DOI 10.1016/j.gie.2019.11.046
   Rees CJ, 2020, GUT, V69, P1959, DOI 10.1136/gutjnl-2019-319621
   Rex DK, 2019, GASTROINTEST ENDOSC, V90, P835, DOI 10.1016/j.gie.2019.06.046
   Rex DK, 2020, CLIN GASTROENTEROL H, V18, P158, DOI 10.1016/j.cgh.2019.01.015
   Triantafyllou K, 2017, ENDOSCOPY, V49, P1051, DOI 10.1055/s-0043-114412
   von Figura G, 2020, ENDOSCOPY, V52, P45, DOI 10.1055/a-1018-1870
   Zippi M, 2017, WORLD J CLIN CASES, V5, P258, DOI 10.12998/wjcc.v5.i7.258
   Zorzi M, 2022, ENDOSCOPY, V54, P138, DOI 10.1055/a-1379-6868
NR 19
TC 0
Z9 0
U1 0
U2 0
PU THIEME MEDICAL PUBL INC
PI NEW YORK
PA 333 SEVENTH AVE, NEW YORK, NY 10001 USA
SN 0976-5042
EI 0976-5050
J9 J DIG ENDOSC
JI J. Dig. Endosc.
PD SEP
PY 2022
VL 13
IS 03
BP 193
EP 198
DI 10.1055/s-0042-1755338
PG 6
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA 4M3FQ
UT WOS:000853211000008
OA gold
DA 2023-08-21
ER

PT J
AU Yue, GH
   Han, WW
   Li, SY
   Zhou, TW
   Lv, J
   Wang, TF
AF Yue, Guanghui
   Han, Wanwan
   Li, Siying
   Zhou, Tianwei
   Lv, Jun
   Wang, Tianfu
TI Automated polyp segmentation in colonoscopy images via deep network with
   lesion-aware feature selection and refinement
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Polypsegmentation; Deepnetwork; Lesion-awarefeature; Colonoscopyimage
ID COLORECTAL-CANCER; VALIDATION
AB Clinically, proper polyp localization in colonoscopy images is crucial for early diagnosis and follow-up treatment of colorectal cancer. However, visual inspection is subjective, error-prone, and burdensome. In this paper, we propose an automated polyp segmentation method (named LFSRNet) to assist physicians to accurately segment polyps in colonoscopy images. The proposed LFSRNet follows an encoder-decoder architecture and benefits from two pivotal modules, i.e., a lesion-aware feature selection module (LFSM) and a lesion-aware feature refinement module (LFRM). Specifically, the LFSM selects lesion-aware features from the top-three highest layers of the encoder via a non-local attention mechanism and fuses them to generate the initial segmentation map for the decoder. The LFRM embedded in the decoder incorporates the guided context information and the output of LFRM from the adjacent higher layer to refine the lesion-aware features. Through top-down deep supervision, our LFSRNet can adaptively select and refine lesion-aware features and precisely localize the polyp regions. Experimental results on the Kvasir-SEG dataset (with the 80%-20% train-test split) show that LFSRNet is superior to six state-of-the-art competing methods and achieves a dice score of 0.9127, an intersection-over-union score of 0.8615, a sensitivity score of 0.9174, an accuracy score of 0.9728, an F2 score of 0.9123, and an MAE score of 0.0291, respectively. More extensive results show that LFSRNet also holds better generalization than competing methods when trained on the Kvasir-SEG dataset and tested on both the CVC-ClinicDB dataset and EndoScene dataset.
C1 [Yue, Guanghui; Han, Wanwan; Li, Siying; Wang, Tianfu] Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Shenzhen 518060, Peoples R China.
   [Zhou, Tianwei] Shenzhen Univ, Coll Management, Shenzhen 518060, Peoples R China.
   [Lv, Jun] Yantai Univ, Sch Comp & Control Engn, Yantai 264000, Peoples R China.
C3 Shenzhen University; Shenzhen University; Yantai University
RP Zhou, TW (通讯作者)，Shenzhen Univ, Coll Management, Shenzhen 518060, Peoples R China.
EM tianwei@szu.edu.cn
RI Zhou, Tianwei/GSI-8460-2022
FU Guangdong Basic and Applied Basic Research Foundation [2021A1515011348,
   2019A1515111205, 2019A1515110401]; Shenzhen Science and Technology
   Program, China [RCBS20200714114920379]; Natural Science Foundation of
   Shenzhen [JCYJ20190808145011259]; National Natural Science Foundation of
   China [62001302,62071309, 62103286, 61902338]; Tencent ? [21YJC630181];
   Scientific Research Foundation for Young Teachers of Shenzhen
   University, China [VRLAB2021C05]
FX This work was supported in part by Guangdong Basic and Applied Basic
   Research Foundation (Nos. 2021A1515011348, 2019A1515111205,
   2019A1515110401) , in part by Shenzhen Science and Technology Program,
   China (No. RCBS20200714114920379) , in part by Natural Science
   Foundation of Shenzhen (No. JCYJ20190808145011259) , in part by National
   Natural Science Foundation of China (Nos. 62001302,62071309, 62103286,
   61902338) , in part by Tencent ?Rhinoceros Birds?-Scientific Research
   Foundation for Young Teachers of Shenzhen University, China, in part by
   Social Science Youth Foundation of Ministry of Education of China (No.
   21YJC630181) , and in part by Open Project Program of State Key
   Laboratory of Virtual Reality Technology and Systems, Beihang
   University, China (No. VRLAB2021C05) .
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bretthauer M, 2016, JAMA INTERN MED, V176, P894, DOI 10.1001/jamainternmed.2016.0960
   Chen BL, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103019
   Chen Q, 2022, IEEE TETCI, V6, P1190, DOI 10.1109/TETCI.2021.3051910
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Ding HJ, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103116
   Fan DP, 2022, IEEE T PATTERN ANAL, V44, P6024, DOI 10.1109/TPAMI.2021.3085766
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Figueiredo IN, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101577
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   Gridach M, 2021, NEURAL NETWORKS, V140, P274, DOI 10.1016/j.neunet.2021.03.023
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guo XQ, 2021, IEEE T MED IMAGING, V40, P1134, DOI 10.1109/TMI.2020.3046843
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   Hasan MK, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102661
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Jemal A., 2020, CA-CANCER J CLIN, V70, p7, DOI DOI 10.3322/caac.21208
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Lin T.-Y., P IEEE C COMPUTER VI, P2117
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Rahim T, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102654
   Rex DK, 2017, GASTROENTEROLOGY, V153, P307, DOI 10.1053/j.gastro.2017.05.013
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sunija AP, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103192
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tjaden JM, 2018, SURG ENDOSC, V32, P3108, DOI 10.1007/s00464-018-6025-3
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Yang XY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038011
   Yin Z., 2021, ARXIV PREPRINT ARXIV
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yue GH, 2022, IEEE J BIOMED HEALTH, V26, P4090, DOI 10.1109/JBHI.2022.3173948
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhao X., INT C MEDICAL IMAGE, P120
   Zhu ML, 2021, IEEE T MED IMAGING, V40, P3315, DOI 10.1109/TMI.2021.3083586
NR 53
TC 4
Z9 4
U1 10
U2 26
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD SEP
PY 2022
VL 78
AR 103846
DI 10.1016/j.bspc.2022.103846
PG 11
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 3A0BQ
UT WOS:000826932200005
DA 2023-08-21
ER

PT J
AU Bhattacharya, D
   Eggert, D
   Betz, C
   Schlaefer, A
AF Bhattacharya, Debayan
   Eggert, Dennis
   Betz, Christian
   Schlaefer, Alexander
TI Squeeze and multi-context attention for polyp segmentation
SO INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE attention; attention gate; polyp segmentation; squeeze and excite;
   squeeze and multi-context; U-Net
ID VALIDATION
AB Artificial Intelligence-based Computer Aided Diagnostics (AI-CADx) have been proposed to help physicians in reducing misdetection of polyps in colonoscopy examination. The heterogeneity of a polyp's appearance makes detection challenging for physicians and AI-CADx. Towards building better AI-CADx, we propose an attention module called Squeeze and Multi-Context Attention (SMCA) that re-calibrates a feature map by providing channel and spatial attention by taking into consideration highly activated features and context of the features at multiple receptive fields simultaneously. We test the effectiveness of SMCA by incorporating it into the encoder of five popular segmentation models. We use five public datasets and construct intra-dataset and inter-dataset test sets to evaluate the generalizing capability of models with SMCA. Our intra-dataset evaluation shows that U-Net with SMCA and without SMCA has a precision of 0.86 +/- 0.01 and 0.76 +/- 0.02 respectively on CVC-ClinicDB. Our inter-dataset evaluation reveals that U-Net with SMCA and without SMCA has a precision of 0.62 +/- 0.01 and 0.55 +/- 0.09 respectively when trained on Kvasir-SEG and tested on CVC-ColonDB. Similar results are observed using other segmentation models and other public datasets. In conclusion, we demonstrate that incorporating SMCA into the segmentation models leads to an increase in generalizing capability of the segmentation models.
C1 [Bhattacharya, Debayan; Schlaefer, Alexander] Hamburg Univ Technol, Inst Med Technol & Intelligent Syst, Schwarzenberg Campus 1, D-21073 Hamburg, Germany.
   [Bhattacharya, Debayan; Eggert, Dennis; Betz, Christian] Univ Med Ctr, Clin Ears Nose & Throat, Hamburg, Germany.
C3 Hamburg University of Technology; University of Hamburg; University
   Medical Center Hamburg-Eppendorf
RP Bhattacharya, D (通讯作者)，Hamburg Univ Technol, Inst Med Technol & Intelligent Syst, Schwarzenberg Campus 1, D-21073 Hamburg, Germany.
EM debayan.bhattacharya@tuhh.de
RI Schlaefer, Alexander/HPE-1451-2023; Betz, Christian Stephan/B-3996-2013
OI Schlaefer, Alexander/0000-0001-9201-8854; Betz, Christian
   Stephan/0000-0003-3188-1026; Bhattacharya, Debayan/0000-0001-8552-2227
FU Free and Hanseatic City of Hamburg; Hamburg University of Technology;
   University Hospital Hamburg-Eppendorf
FX Free and Hanseatic City of Hamburg; Hamburg University of Technology;
   University Hospital Hamburg-Eppendorf
CR Alam S, ARXIV
   Alom MZ., RECURRENT RESIDUAL C
   [Anonymous], SQUEEZE EXCITATION N
   Bejani MM, 2021, ARTIF INTELL REV, V54, P6391, DOI 10.1007/s10462-021-09975-1
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chattopadhyay A., BALASUBRAMANIAN VN
   Chen LC., ATTENTION SCALE SCAL
   Chen LC., RETHINKING ATROUS CO
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Fan DP., PRANET PARALLEL REVE
   Galdran A., ARXIV
   Gotkowski K., M3D CAM PYTORCH LIB
   Gutman D.C., SKIN LESION ANAL MEL
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Jemal A., 2020, CA-CANCER J CLIN, V70, p7, DOI DOI 10.3322/caac.21208
   Jha D., ARXIV
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Jorge Bernal FJ., 2012, AUTOMATIC POLYP DETE
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Li Q, 2017, IEEE INT CONF COMM, P29, DOI 10.1109/ICCW.2017.7962629
   Liu LL, 2020, NEUROCOMPUTING, V409, P244, DOI 10.1016/j.neucom.2020.05.070
   Lutnick B, 2019, NAT MACH INTELL, V1, P112, DOI 10.1038/s42256-019-0018-3
   Ma J, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102035
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Menze Bjoern H, 2015, IEEE Trans Med Imaging, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Oktay O., ATTENTION U NET LEAR
   Peng J., ARXIV
   Quinn TP, 2022, ARTIF INTELL MED, V124, DOI 10.1016/j.artmed.2021.102158
   Ronneberger O., U NET CONVOLUTIONAL
   Rundo L, 2020, J BIOMED INFORM, V108, DOI 10.1016/j.jbi.2020.103479
   Rundo L, 2019, NEUROCOMPUTING, V365, P31, DOI 10.1016/j.neucom.2019.07.006
   Salehi SS., TVERSKY LOSS FUNCTIO
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sushma B., 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1762, DOI 10.1109/ICCMC51019.2021.9418037
   Tavanapong W, 2022, IEEE J BIOMED HEALTH, V26, P3950, DOI 10.1109/JBHI.2022.3160098
   Vaswani A, 2017, ADV NEUR IN, V30
   Vazquez, ARXIV
   Wang J., DEEP HIGH RESOLUTION
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yeung M, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104815
   Yeung M, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102026
   Zhang H., ARXIV
   Zhang Z, ARXIV
   Zhao H., PYRAMID SCENE PARSIN
   Zuo Q, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6625688
NR 49
TC 0
Z9 0
U1 2
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-9457
EI 1098-1098
J9 INT J IMAG SYST TECH
JI Int. J. Imaging Syst. Technol.
PD JAN
PY 2023
VL 33
IS 1
BP 123
EP 142
DI 10.1002/ima.22795
EA AUG 2022
PG 20
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA 7W2LZ
UT WOS:000844659200001
DA 2023-08-21
ER

PT J
AU Jin, Y
   Hu, YB
   Jiang, ZW
   Zheng, QF
AF Jin, Yan
   Hu, Yibiao
   Jiang, Zhiwei
   Zheng, Qiufu
TI Polyp segmentation with convolutional MLP
SO VISUAL COMPUTER
LA English
DT Article; Early Access
DE Polyp segmentation; MLP; Attention mechanism; Neural network; Medical
   image segmentation
ID NETWORK
AB Accurate polyp segmentation can help doctors find and resect abnormal tissue and decrease the chances of polyps changing into colorectal cancer. The current polyp segmentation neural networks are still challenged by complicated scenarios where polyps have large variations of shapes, size, color, and appearance. In this paper, we propose convolutional multilayer perceptron polyp segmentation network to achieve more accurate polyp segmentation in colonoscopy images. The proposed network adopts a convolutional MLP encoder and enhances the low-level feature using the parallel self-attention module. Furthermore, instead of directly adding encoder features to the decoder, we introduce a cascaded context aggregation module to aggregate the high-level semantic feature and low-level local feature. Finally, channel guide group reverse attention is used to enhance structural and textural details by mining the relationship between areas and boundary cues. The proposed approach is evaluated on six widely adopted datasets and demonstrates superior performance compared to other state-of-the-art models.
C1 [Jin, Yan; Hu, Yibiao; Jiang, Zhiwei; Zheng, Qiufu] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Jin, Y (通讯作者)，Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
EM jy@zjut.edu.cn
OI zhiwei, jiang/0000-0001-7314-2083; Jin, Yan/0000-0001-8956-7684
CR Ahmed A, 2020, MEDIAEVAL20 MULTIMED, DOI [10.1109/EMBC.2019.8857958, DOI 10.1109/EMBC.2019.8857958]
   Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   [Anonymous], 2015, P MED IM COMP COMP A
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen S., 2020, P EUROPEAN C COMPUTE, P520
   Chen SF, 2022, Arxiv, DOI arXiv:2107.10224
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Ding X., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2105.01883
   Fan D.-P., 2021, SCI SIN INFORMATIONI, V6, DOI DOI 10.1360/SSI-2020-0370
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Guo JY, 2021, Arxiv, DOI arXiv:2108.13341
   Guo JD, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102906
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou Q., 2021, ARXIV
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jaggi, 2020, INT C LEARN REPR, P1, DOI DOI 10.23919/CISTI49556.2020.9141108
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji GP, 2021, LECT NOTES COMPUT SC, V12901, P142, DOI 10.1007/978-3-030-87193-2_14
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Jiang M, 2022, VISUAL COMPUT, V38, P2473, DOI 10.1007/s00371-021-02124-3
   Lai HL, 2023, VISUAL COMPUT, V39, P1453, DOI 10.1007/s00371-022-02422-4
   Li HX, 2021, NEURAL COMPUT APPL, V33, P11589, DOI 10.1007/s00521-021-05856-4
   Li Jiachen, 2021, ARXIV
   Liu H., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2105.08050
   Loshchilov Ilya, 2019, Arxiv, DOI [arXiv:1711.05101, DOI 10.48550/ARXIV.1711.05101]
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI 10.1109/EMBC.2019.8857339
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/crv52889.2021.00032, 10.1109/CRV52889.2021.00032]
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Sabour S., 2017, P ADV NEUR INF PROC, P3859
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sundaram P, 2008, MED IMAGE ANAL, V12, P99, DOI 10.1016/j.media.2007.08.001
   Tolstikhin I., 2021, ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HS, 2021, AAAI CONF ARTIF INTE, V35, P2916
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou SK, 2021, P IEEE, V109, P820, DOI 10.1109/JPROC.2021.3054390
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 59
TC 1
Z9 1
U1 7
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD 2022 AUG 23
PY 2022
DI 10.1007/s00371-022-02630-y
EA AUG 2022
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3Y4YY
UT WOS:000843733800001
DA 2023-08-21
ER

PT J
AU Pecere, S
   Antonelli, G
   Dinis-Ribeiro, M
   Mori, Y
   Hassan, C
   Fuccio, L
   Bisschops, R
   Costamagna, G
   Ji, EH
   Lee, D
   Misawa, M
   Messmann, H
   Iacopini, F
   Petruzziello, L
   Repici, A
   Saito, Y
   Sharma, P
   Yamada, M
   Spada, C
   Frazzoni, L
AF Pecere, Silvia
   Antonelli, Giulio
   Dinis-Ribeiro, Mario
   Mori, Yuichi
   Hassan, Cesare
   Fuccio, Lorenzo
   Bisschops, Raf
   Costamagna, Guido
   Ji, Eun Hyo
   Lee, Dongheon
   Misawa, Masashi
   Messmann, Helmut
   Iacopini, Federico
   Petruzziello, Lucio
   Repici, Alessandro
   Saito, Yutaka
   Sharma, Prateek
   Yamada, Masayoshi
   Spada, Cristiano
   Frazzoni, Leonardo
TI Endoscopists performance in optical diagnosis of colorectal polyps in
   artificial intelligence studies
SO UNITED EUROPEAN GASTROENTEROLOGY JOURNAL
LA English
DT Review
DE artificial intelligence; colonoscopy; endoscopist performance; human
   factor; polyp characterization; polyp detection
ID GASTROINTESTINAL ENDOSCOPY; COLON POLYPS; CLASSIFICATION; HISTOLOGY;
   SOCIETY
AB Widespread adoption of optical diagnosis of colorectal neoplasia is prevented by suboptimal endoscopist performance and lack of standardized training and competence evaluation. We aimed to assess diagnostic accuracy of endoscopists in optical diagnosis of colorectal neoplasia in the framework of artificial intelligence (AI) validation studies. Literature searches of databases (PubMed/MEDLINE, EMBASE, Scopus) up to April 2022 were performed to identify articles evaluating accuracy of individual endoscopists in performing optical diagnosis of colorectal neoplasia within studies validating AI against a histologically verified ground-truth. The main outcomes were endoscopists' pooled sensitivity, specificity, positive and negative predictive value (PPV/NPV), positive and negative likelihood ratio (LR) and area under the curve (AUC for sROC) for predicting adenomas versus non-adenomas. Six studies with 67 endoscopists and 2085 (IQR: 115-243,5) patients were evaluated. Pooled sensitivity and specificity for adenomatous histology was respectively 84.5% (95% CI 80.3%-88%) and 83% (95% CI 79.6%-85.9%), corresponding to a PPV, NPV, LR+, LR- of 89.5% (95% CI 87.1%-91.5%), 75.7% (95% CI 70.1%-80.7%), 5 (95% CI 3.9%-6.2%) and 0.19 (95% CI 0.14%-0.25%). The AUC was 0.82 (CI 0.76-0.90). Expert endoscopists showed a higher sensitivity than non-experts (90.5%, [95% CI 87.6%-92.7%] vs. 75.5%, [95% CI 66.5%-82.7%], p < 0.001), and Eastern endoscopists showed a higher sensitivity than Western (85%, [95% CI 80.5%-88.6%] vs. 75.8%, [95% CI 70.2%-80.6%]). Quality was graded high for 3 studies and low for 3 studies. We show that human accuracy for diagnosis of colorectal neoplasia in the setting of AI studies is suboptimal. Educational interventions could benefit by AI validation settings which seem a feasible framework for competence assessment.
C1 [Pecere, Silvia; Costamagna, Guido; Petruzziello, Lucio] Fdn Policlin Univ A Gemelli IRCCS, Digest Endoscopy Unit, Rome, Italy.
   [Pecere, Silvia; Costamagna, Guido; Petruzziello, Lucio; Spada, Cristiano] Univ Cattolica Sacro Cuore, Ctr Endoscop Res Therapeut & Training CERTT, Rome, Italy.
   [Antonelli, Giulio] Sapienza Univ Rome, Dept Anat Histol Forens Med & Orthoped Sci, Rome, Italy.
   [Antonelli, Giulio; Iacopini, Federico] Osped Castelli Hosp, Gastroenterol & Digest Endoscopy Unit, Rome, Italy.
   [Dinis-Ribeiro, Mario] Univ Porto, Fac Med, CIDES CINTESIS, Porto, Portugal.
   [Mori, Yuichi] Univ Oslo, Clin Effectiveness Res Grp, Oslo, Norway.
   [Mori, Yuichi; Misawa, Masashi] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Hassan, Cesare; Repici, Alessandro] Humanitas Univ, Dept Biomed Sci, Milan, Italy.
   [Hassan, Cesare] IRCCS Humanitas Res Hosp, Dept Gastroenterol, Milan, Italy.
   [Fuccio, Lorenzo; Frazzoni, Leonardo] Univ Bologna, S Orsola Malpighi Hosp, Dept Med & Surg Sci DIMEC, Bologna, Italy.
   [Bisschops, Raf] Katholieke Univ Leuven, TARGID, Univ Hosp Leuven, Dept Gastroenterol & Hepatol, Leuven, Belgium.
   [Ji, Eun Hyo; Lee, Dongheon] Seoul Natl Univ Hosp, Healthcare Res Inst, Dept Internal Med, Healthcare Syst Gangnam Ctr, Seoul, South Korea.
   [Messmann, Helmut] Univ Klinikum Augsburg, Med Klin 3, Augsburg, Germany.
   [Saito, Yutaka; Yamada, Masayoshi] Natl Canc Ctr, Endoscopy Div, Tokyo, Japan.
   [Sharma, Prateek] Univ Kansas, Med Ctr, Dept Gastroenterol & Hepatol, Kansas City, KS 66103 USA.
   [Spada, Cristiano] Fdn Poliambulanza, Brescia, Italy.
C3 Catholic University of the Sacred Heart; IRCCS Policlinico Gemelli;
   Catholic University of the Sacred Heart; IRCCS Policlinico Gemelli;
   Sapienza University Rome; Universidade do Porto; University of Oslo;
   Showa University; Humanitas University; IRCCS Azienda
   Ospedaliero-Universitaria di Bologna; University of Bologna; KU Leuven;
   University Hospital Leuven; Seoul National University (SNU); Seoul
   National University Hospital; National Cancer Center - Japan; University
   of Kansas; University of Kansas Medical Center
RP Pecere, S (通讯作者)，Fdn Policlin Univ A Gemelli IRCCS, Digest Endoscopy Unit, Rome, Italy.
EM silvia.pecere@gmail.com
RI Sharma, Prateek/IZE-3910-2023; lee, dongheon/AAV-4862-2021; hassan,
   cesare/H-2844-2012; pecere, silvia/M-2541-2018; Repici,
   Alessandro/HFH-8162-2022; Dinis-Ribeiro, Mario/A-9248-2010
OI lee, dongheon/0000-0002-3121-7099; hassan, cesare/0000-0001-7167-1459;
   pecere, silvia/0000-0002-4401-7344; Repici,
   Alessandro/0000-0002-1621-6450; Antonelli, Giulio/0000-0003-1797-3864;
   Bisschops, Raf/0000-0002-9994-8226; Jin, Eun Hyo/0000-0002-2126-3315;
   Dinis-Ribeiro, Mario/0000-0003-0121-6850
FU BIBLIOSAN
FX Open access funding provided by BIBLIOSAN.
CR [Anonymous], R LANG ENV STAT COMP
   Arribas J, 2021, GUT, V70, P1458, DOI 10.1136/gutjnl-2020-321922
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dekker E, 2020, ENDOSCOPY, V52, P899, DOI 10.1055/a-1231-5123
   Doebler P., META ANAL DIAGNOSTIC, P21
   Frazzoni L, 2022, ENDOSCOPY, V54, P403, DOI 10.1055/a-1500-3730
   Greuter MJE, 2017, ANN INTERN MED, V167, P544, DOI 10.7326/M16-2891
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Houwen BBSL, 2022, ENDOSCOPY, V54, P88, DOI 10.1055/a-1689-5130
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Laish I, 2019, CLIN RES HEPATOL GAS, V43, P201, DOI 10.1016/j.clinre.2018.03.001
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1186/s13643-015-0087-2, 10.1136/bmj.b2535]
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Naaktgeboren CA, 2016, BMC MED RES METHODOL, V16, DOI 10.1186/s12874-016-0108-4
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Reitsma JB, 2005, J CLIN EPIDEMIOL, V58, P982, DOI 10.1016/j.jclinepi.2005.02.022
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Schachschal G, 2016, INT J COLORECTAL DIS, V31, P675, DOI 10.1007/s00384-016-2523-8
   Smith SCL, 2021, ENDOSC INT OPEN, V09, pE716, DOI 10.1055/a-1381-7181
   van der Sommen F, 2020, GUT, V69, P2035, DOI 10.1136/gutjnl-2019-320466
   Vu HT, 2015, DIGEST DIS SCI, V60, P502, DOI 10.1007/s10620-014-3376-z
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
NR 30
TC 2
Z9 2
U1 0
U2 2
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 2050-6406
EI 2050-6414
J9 UNITED EUR GASTROENT
JI United European Gastroenterol. J.
PD OCT
PY 2022
VL 10
IS 8
BP 817
EP 826
DI 10.1002/ueg2.12285
EA AUG 2022
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 5F6XK
UT WOS:000842313700001
PM 35984903
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Shaukat, A
   Lichtenstein, DR
   Somers, SC
   Chung, DC
   Perdue, DG
   Gopal, M
   Colucci, DR
   Phillips, SA
   Marka, NA
   Church, TR
   Brugge, WR
AF Shaukat, Aasma
   Lichtenstein, David R.
   Somers, Samuel C.
   Chung, Daniel C.
   Perdue, David G.
   Gopal, Murali
   Colucci, Daniel R.
   Phillips, Sloane A.
   Marka, Nicholas A.
   Church, Timothy R.
   Brugge, William R.
CA SKOUT Registration Study Team
TI Computer-Aided Detection Improves Adenomas per Colonoscopy for Screening
   and Surveillance Colonoscopy: A Randomized Trial
SO GASTROENTEROLOGY
LA English
DT Article
DE Adenomas; Artificial Intelligence; Colonoscopy; Histology
ID COLORECTAL-CANCER; QUALITY INDICATORS; ARTIFICIAL-INTELLIGENCE;
   TASK-FORCE; RISK; VARIABILITY; NEOPLASIA
AB BACKGROUND & AIMS: Colonoscopy for colorectal cancer screening is endoscopist dependent, and colonoscopy quality improvement programs aim to improve efficacy. This study evaluated the clinical benefit and safety of using a computer-aided detection (CADe) device in colonoscopy procedures. METHODS: This randomized study prospectively evaluated the use of a CADe device at 5 academic and community centers by US board-certified gastroenterologists (n = 22). Participants aged >40 scheduled for screening or surveillance (>= 3 years) colonoscopy were included; exclusion criteria included incomplete procedure, diagnostic indication, inflammatory bowel disease, and familial adenomatous polyposis. Patients were randomized by endoscopist to the standard or CADe colonoscopy arm using computer-generated, random-block method. The 2 primary endpoints were adenomas per colonoscopy (APC), the total number of adenomas resected divided by the total number of colonoscopies; and true histology rate (THR), the proportion of resections with clinically significant histology divided by the total number of polyp resections. The primary analysis used a modified intention-to-treat approach. RESULTS: Between January and September 2021, 1440 participants were enrolled to be randomized. After exclusion of participants who did not meet the eligibility criteria, 677 in the standard arm and 682 in the CADe arm were included in a modified intention-to-treat analysis. APC increased significantly with use of the CADe device (standard vs CADe: 0.83 vs 1.05, P = .002; total number of adenomas, 562 vs 719). There was no decrease in THR with use of the CADe device (standard vs CADe: 71.7% vs 67.4%, P for noninferiority <.001; total number of non-neoplastic lesions, 284 vs 375). Adenoma detection rate was 43.9% and 47.8% in the standard and CADe arms, respectively (P = .065). CONCLUSIONS: For experienced endoscopists performing screening and surveillance colonoscopies in the United States, the CADe device statistically improved overall adenoma detection (APC) without a concomitant increase in resection of non-neoplastic lesions (THR).
C1 [Shaukat, Aasma] NYU, Dept Med, Div Gastroenterol & Hepatol, Grossman Sch Med, 550 1St Ave, New York, NY 10016 USA.
   [Shaukat, Aasma; Church, Timothy R.] Univ Minnesota, Sch Publ Hlth, Div Environm Hlth Sci, Minneapolis, MN USA.
   [Lichtenstein, David R.] Boston Univ, Sch Med, Dept Med, Boston Med Ctr,Div Gastroenterol, Boston, MA 02118 USA.
   [Somers, Samuel C.] Concord Hosp Gastroenterol, Concord Endoscopy Ctr, Concord, NH USA.
   [Chung, Daniel C.] Harvard Med Sch, Massachusetts Gen Hosp, Dept Med, Div Gastroenterol, Boston, MA 02115 USA.
   [Perdue, David G.] MNGI Digest Hlth, Minneapolis, MN USA.
   [Gopal, Murali; Colucci, Daniel R.; Phillips, Sloane A.] Iterat Scopes Inc, Cambridge, MA USA.
   [Marka, Nicholas A.] Univ Minnesota, Clin & Translat Sci Inst, Minneapolis, MN USA.
   [Brugge, William R.] Harvard Med Sch, Mt Auburn Hosp, Dept Med, Div Gastroenterol, Boston, MA 02115 USA.
C3 New York University; University of Minnesota System; University of
   Minnesota Twin Cities; Boston Medical Center; Boston University; Harvard
   University; Harvard Medical School; Massachusetts General Hospital;
   University of Minnesota System; University of Minnesota Twin Cities;
   Harvard University; Harvard Medical School; Mount Auburn Hospital
RP Shaukat, A (通讯作者)，NYU, Div Gastroenterol & Hepatol, Langone Med Ctr, 240 East 38th St,23rd Floor, New York, NY 10016 USA.
EM shaukat@umn.edu
OI Coban, Sahin/0000-0002-6886-7474
FU Iterative Scopes, Inc., Cambridge, Massachusetts
FX Support for this study was provided by Iterative Scopes, Inc.,
   Cambridge, Massachusetts.
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Anderson J, 2021, AM COLL GASTROENTERO
   Aniwan S, 2016, AM J GASTROENTEROL, V111, P723, DOI 10.1038/ajg.2015.440
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Denis B, 2014, DIGEST LIVER DIS, V46, P176, DOI 10.1016/j.dld.2013.08.129
   Gupta S, 2020, GASTROENTEROLOGY, V158, P1131, DOI 10.1053/j.gastro.2019.10.026
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Heitman SJ, 2009, CLIN GASTROENTEROL H, V7, P1272, DOI 10.1016/j.cgh.2009.05.032
   Kahi CJ, 2009, CLIN GASTROENTEROL H, V7, P770, DOI 10.1016/j.cgh.2008.12.030
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kim SY, 2018, TRANSL GASTROENT HEP, V3, DOI 10.21037/tgh.2018.01.03
   Klabunde CN, 2009, AM J PREV MED, V37, P8, DOI 10.1016/j.amepre.2009.03.008
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Lakoff J, 2008, CLIN GASTROENTEROL H, V6, P1117, DOI 10.1016/j.cgh.2008.05.016
   le Clercq CMC, 2016, ENDOSCOPY, V48, P248, DOI 10.1055/s-0041-111117
   Lee RH, 2011, GASTROINTEST ENDOSC, V74, P128, DOI 10.1016/j.gie.2011.03.003
   Lieberman DA, 2001, NEW ENGL J MED, V345, P555, DOI 10.1056/NEJMoa010328
   Liem B, 2018, TRANSL GASTROENT HEP, V3, DOI 10.21037/tgh.2018.03.04
   Moyer VA, 2014, ANN INTERN MED, V160, P330, DOI 10.7326/M13-2771
   Regula J, 2006, NEW ENGL J MED, V355, P1863, DOI 10.1056/NEJMoa054967
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Shaukat A, 2021, ENDOSC INT OPEN, V09, pE263, DOI 10.1055/a-1321-1317
   Shaukat A, 2009, CLIN GASTROENTEROL H, V7, P1335, DOI 10.1016/j.cgh.2009.07.027
   Singh H, 2010, GASTROENTEROLOGY, V139, P1128, DOI 10.1053/j.gastro.2010.06.052
   Wang HS, 2013, GASTROINTEST ENDOSC, V77, P71, DOI 10.1016/j.gie.2012.08.038
   Wang S, 2020, ENDOSC INT OPEN, V08, pE1560, DOI 10.1055/a-1261-9074
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 32
TC 14
Z9 14
U1 1
U2 4
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD SEP
PY 2022
VL 163
IS 3
BP 732
EP 741
DI 10.1053/j.gastro.2022.05.028
EA AUG 2022
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 5C0OB
UT WOS:000863966500029
PM 35643173
OA hybrid
DA 2023-08-21
ER

PT J
AU Yamada, M
   Shino, R
   Kondo, H
   Yamada, S
   Takamaru, H
   Sakamoto, T
   Bhandari, P
   Imaoka, H
   Kuchiba, A
   Shibata, T
   Saito, Y
   Hamamoto, R
AF Yamada, Masayoshi
   Shino, Ryosaku
   Kondo, Hiroko
   Yamada, Shigemi
   Takamaru, Hiroyuki
   Sakamoto, Taku
   Bhandari, Pradeep
   Imaoka, Hitoshi
   Kuchiba, Aya
   Shibata, Taro
   Saito, Yutaka
   Hamamoto, Ryuji
TI Robust automated prediction of the revised Vienna Classification in
   colonoscopy using deep learning: development and initial external
   validation
SO JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Deep learning; Artificial intelligence; Colonoscopy; Multi-class
   classification; External validation
ID COLORECTAL-CANCER; POLYPS; DIAGNOSIS; ALGORITHM; DIFFERENTIATION;
   PREVENTION; ACCURACY; COLON
AB Background Improved optical diagnostic technology is needed that can be used by also outside expert centers. Hence, we developed an artificial intelligence (AI) system that automatically and robustly predicts the pathological diagnosis based on the revised Vienna Classification using standard colonoscopy images. Methods We prepared deep learning algorithms and colonoscopy images containing pathologically proven lesions (56,872 images, 6775 lesions). Four classifications were adopted: revised Vienna Classification category 1, 3, and 4/5 and normal images. The best algorithm-ResNet152-in the independent internal validation (14,048 images, 1718 lesions) was used for external validation (255 images, 128 lesions) based on neoplastic and non-neoplastic classification. Diagnostic performance of endoscopists was compared using a computer-assisted interpreting test. Results In the internal validation, the sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and accuracy for adenoma (category 3) of 84.6% (95% CI 83.5-85.6%), 99.7% (99.5-99.8%), 90.8% (89.9-91.7%), 89.2% (88.5-99.0%), and 89.8% (89.3-90.4%), respectively. In the external validation, ResNet152's sensitivity, specificity, PPV, NPV, and accuracy for neoplastic lesions were 88.3% (82.6-94.1%), 90.3% (83.0-97.7%), 94.6% (90.5-98.8%), 80.0% (70.6-89.4%), and 89.0% (84.5-93.6%), respectively. This diagnostic performance was superior to that of expert endoscopists. Area under the receiver-operating characteristic curve was 0.903 (0.860-0.946). Conclusions The developed AI system can help non-expert endoscopists make differential diagnoses of colorectal neoplasia on par with expert endoscopists during colonoscopy. (229/250 words).
C1 [Yamada, Masayoshi; Takamaru, Hiroyuki; Sakamoto, Taku; Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo, Japan.
   [Yamada, Masayoshi; Kondo, Hiroko; Yamada, Shigemi; Hamamoto, Ryuji] Natl Canc Ctr, Div Med AI Res & Dev, Tokyo, Japan.
   [Shino, Ryosaku; Imaoka, Hitoshi] NEC Corp Ltd, Biometr Res Labs, Kawasaki, Kanagawa, Japan.
   [Kondo, Hiroko; Yamada, Shigemi; Hamamoto, Ryuji] RIKEN Ctr Adv Intelligence Project, Canc Translat Res Team, Tokyo, Japan.
   [Bhandari, Pradeep] Portsmouth Hosp Univ NHS Trust, Dept Gastroenterol, Portsmouth, Hants, England.
   [Kuchiba, Aya; Shibata, Taro] Natl Canc Ctr, Biostat Div, Tokyo, Japan.
C3 National Cancer Center - Japan; National Cancer Center - Japan; NEC
   Corporation; RIKEN; National Cancer Center - Japan
RP Yamada, M (通讯作者)，Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo, Japan.; Yamada, M (通讯作者)，Natl Canc Ctr, Div Med AI Res & Dev, Tokyo, Japan.
EM masyamad@ncc.go.jp
RI Hamamoto, Ryuji/AAF-9600-2019
OI Hamamoto, Ryuji/0000-0002-2632-1334; Yamada,
   Masayoshi/0000-0003-3979-5560
FU JST CREST Grant [JPMJCR1689]; Center for Advanced Intelligence Project,
   RIKEN
FX This work was supported by a JST CREST Grant (JPMJCR1689), and the
   Center for Advanced Intelligence Project, RIKEN.
CR Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Dixon MF, 2002, GUT, V51, P130, DOI 10.1136/gut.51.1.130
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hamamoto R, 2020, CANCERS, V12, DOI 10.3390/cancers12123532
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kaku E, 2011, CLIN GASTROENTEROL H, V9, P503, DOI 10.1016/j.cgh.2011.03.018
   Kobayashi S, 2019, UNITED EUR GASTROENT, V7, P914, DOI 10.1177/2050640619845987
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Matsuda T, 2021, GUT, V70, P1469, DOI 10.1136/gutjnl-2020-321996
   McCarthy JF, 2004, ANN NY ACAD SCI, V1020, P239, DOI 10.1196/annals.1310.020
   Minegishi Y, 2022, GASTROENTEROLOGY, V163, P323, DOI 10.1053/j.gastro.2022.03.053
   Mohan BP, 2020, ECLINICALMEDICINE, V29-30, DOI 10.1016/j.eclinm.2020.100622
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Repici A, 2013, GASTROINTEST ENDOSC, V78, P106, DOI 10.1016/j.gie.2013.01.035
   Togashi K, 2009, GASTROINTEST ENDOSC, V69, P734, DOI 10.1016/j.gie.2008.10.063
   van den Broek FJC, 2009, GASTROINTEST ENDOSC, V69, P124, DOI 10.1016/j.gie.2008.09.040
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yamada M, 2019, RECENT ADV TREATMENT, P3
   Yamada M, 2021, BEST PRACT RES CL GA, V52-53, DOI 10.1016/j.bpg.2021.101745
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 33
TC 2
Z9 2
U1 5
U2 8
PU SPRINGER JAPAN KK
PI TOKYO
PA SHIROYAMA TRUST TOWER 5F, 4-3-1 TORANOMON, MINATO-KU, TOKYO, 105-6005,
   JAPAN
SN 0944-1174
EI 1435-5922
J9 J GASTROENTEROL
JI J. Gastroenterol.
PD NOV
PY 2022
VL 57
IS 11
BP 879
EP 889
DI 10.1007/s00535-022-01908-1
EA AUG 2022
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 5N8AO
UT WOS:000841111600001
PM 35972582
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Yue, GH
   Li, SY
   Zhou, TW
   Wang, MH
   Du, JF
   Jiang, QP
   Gao, W
   Wang, TF
   Lv, J
AF Yue, Guanghui
   Li, Siying
   Zhou, Tianwei
   Wang, Miaohui
   Du, Jingfeng
   Jiang, Qiuping
   Gao, Wei
   Wang, Tianfu
   Lv, Jun
TI Adaptive Context Exploration Network for Polyp Segmentation in
   Colonoscopy Images
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE
LA English
DT Article
DE Image segmentation; Feature extraction; Colonoscopy; Shape; Decoding;
   Convolution; Annotations; Convolutional neural network; polyp
   segmentation; colonoscopy image; context exploration
ID COLORECTAL-CANCER; VALIDATION; FEATURES
AB Recently, automatic and accurate polyp segmentation has become an emerging yet challenging issue. Although convolutional neural networks (CNNs) exhibit a promising future modality to address this issue, most CNN-based methods highly require extensive labeled data. Unfortunately, there is a lack of large-scale public colorectal polyp segmentation datasets in the clinical community and academia. In this study, we construct a new benchmark dataset, which includes 2163 colonoscopy images and their pixel-wise annotations. Moreover, for intelligent polyp segmentation, we propose a novel adaptive context exploration network (ACENet). Our ACENet follows an encoder-decoder architecture and consists of two key modules, i.e., an attentional atrous spatial pyramid pooling (AASPP) module and an adaptive context extraction (ACE) module. The AASPP fuses semantic features from the encoder, and generates the global guidance information for the following decoder. The ACE captures multi-scale features and aggregates them by a branch-wise attention mechanism. Benefiting from these two modules, our ACENet is capable of adaptively exploring the context features to locate and detect the polyp regions effectively. Extensive experiments on the collected dataset and four publicly available datasets show that the proposed ACENet achieves superior performance on five evaluation metrics over three mainstream categories of the state-of-the-art methods.
C1 [Yue, Guanghui; Li, Siying; Wang, Tianfu] Shenzhen Univ, Sch Biomed Engn, Hlth Sci Ctr, Shenzhen 518060, Peoples R China.
   [Zhou, Tianwei] Shenzhen Univ, Coll Management, Shenzhen 518060, Peoples R China.
   [Wang, Miaohui] Shenzhen Univ, Guangdong Key Lab Intelligent format Proc, Shenzhen 518060, Peoples R China.
   [Du, Jingfeng] Shenzhen Univ, Dept Gastroenterol & Hepatol, Gen Hosp, Shenzhen 518060, Peoples R China.
   [Jiang, Qiuping] Ningbo Univ, Sch Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [Gao, Wei] Peking Univ, Shenzhen Grad Sch, Sch Elect & Comp Engn, Shenzhen 518055, Peoples R China.
   [Gao, Wei] Peng Cheng Lab, Shenzhen 518066, Peoples R China.
   [Lv, Jun] Yantai Univ, Sch Comp & Control Engn, Yantai 264000, Peoples R China.
C3 Shenzhen University; Shenzhen University; Shenzhen University; Shenzhen
   University; Ningbo University; Peking University; Peng Cheng Laboratory;
   Yantai University
RP Zhou, TW (通讯作者)，Shenzhen Univ, Coll Management, Shenzhen 518060, Peoples R China.
EM yueguanghui@szu.edu.cn; 2070246077@email.szu.edu.cn; tianwei@szu.edu.cn;
   wang.miaohui@gmail.com; djfjms1231@qq.com; jiangqiuping@nbu.edu.cn;
   gaowei262@pku.edu.cn; wang.miaohui@gmail.com; ljdream0710@pku.edu.cn
RI Jiang, Qiuping/AAL-8273-2020; Zhou, Tianwei/GSI-8460-2022; Lyu,
   Jun/HLQ-3356-2023
OI Qiuping, Jiang/0000-0002-6025-9343
FU Guangdong Basic and Applied Basic Research Foundation [2021A1515011348,
   2019A1515111205, 2019A1515110401]; Shenzhen Science andTechnology
   Program [RCBS20200714114920379]; Natural Science Foundation of Shenzhen
   [JCYJ20190808145011259]; National Natural Science Foundation of China
   [62001302, 62071309, 62103286]; Tencent "Rhinoceros Birds" -Scientific
   Research Foundation for Young Teachers of Shenzhen University; Social
   Science Youth Foundation of Ministry of Education of China
   [21YJC630181]; Open Project Program of State Key Laboratory of Virtual
   Reality Technology and Systems, Beihang University [VRLAB2021C05]
FX This work was supported in part by Guangdong Basic and Applied Basic
   Research Foundation underGrants 2021A1515011348, 2019A1515111205, and
   2019A1515110401, in part by Shenzhen Science andTechnology Program under
   Grant RCBS20200714114920379, in part by the Natural Science Foundation
   of Shenzhen under Grant JCYJ20190808145011259, in part by the National
   Natural Science Foundation of China under Grants 62001302, 62071309, and
   62103286, in part by Tencent "Rhinoceros Birds" -Scientific Research
   Foundation for Young Teachers of Shenzhen University, in part by Social
   Science Youth Foundation of Ministry of Education of China under Grant
   21YJC630181, and in part by Open Project Program of State Key Laboratory
   of Virtual Reality Technology and Systems, Beihang University under
   Grant VRLAB2021C05.
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], 2007, IEEE INT C IMAGE PRO, DOI [10.1109/ICIP.2007.4379193, DOI 10.1109/ICIP.2007.4379193]
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Q, 2022, IEEE TETCI, V6, P1190, DOI 10.1109/TETCI.2021.3051910
   Cheng MJ, 2021, LECT NOTES COMPUT SC, V12901, P720, DOI 10.1007/978-3-030-87193-2_68
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   Heinrich MP, 2019, MED IMAGE ANAL, V54, P1, DOI 10.1016/j.media.2019.02.006
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Lee S. -G., IEEE T EMERG TOPICS, P2021, DOI 10.1109/TETCI.2021.3132382
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Qu XY, 2022, IEEE TETCI, V6, P580, DOI 10.1109/TETCI.2021.3070713
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P471, DOI 10.1016/S0002-9270(02)05928-2
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shunjie Dong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P98, DOI 10.1007/978-3-030-59719-1_10
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Ul Ain Q, 2021, IEEE TETCI, V5, P554, DOI 10.1109/TETCI.2020.2983426
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   Wu HS, 2021, AAAI CONF ARTIF INTE, V35, P2916
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yap MH, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104596
   Yeung M, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104815
   Yin Zenong, 2022, Public Health Nutr, P1, DOI [10.1017/S1368980022002439, 10.1109/ICIT48603.2022.10002826]
   Yu F., 2016, P 4 INT C LEARN REP, DOI 10.48550/arXiv.1511.07122Focustolearnmore
   Zhou WJ, 2022, IEEE TETCI, V6, P957, DOI 10.1109/TETCI.2021.3118043
   Zhou WJ, 2022, IEEE TETCI, V6, P593, DOI 10.1109/TETCI.2021.3097393
   Zhou ZL, 2021, IEEE T BIG DATA, V7, P559, DOI 10.1109/TBDATA.2019.2919570
   ZHUGE M, 2021, IEEE T PATTERNANAL M
NR 56
TC 4
Z9 4
U1 8
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2471-285X
J9 IEEE TETCI
JI IEEE Trans. Emerg. Top. Comput. Intell.
PD APR
PY 2023
VL 7
IS 2
BP 487
EP 499
DI 10.1109/TETCI.2022.3193677
EA AUG 2022
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J0ZS7
UT WOS:000840486600001
DA 2023-08-21
ER

PT J
AU Itoh, H
   Misawa, M
   Mori, Y
   Kudo, SE
   Oda, M
   Mori, K
AF Itoh, Hayato
   Misawa, Masashi
   Mori, Yuichi
   Kudo, Shin-Ei
   Oda, Masahiro
   Mori, Kensaku
TI Positive-gradient-weighted object activation mapping: visual explanation
   of object detector towards precise colorectal-polyp localisation
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Colonoscopy; Polyp detection; Polyp localisation; Model analysis;
   Computer-aided diagnosis; Deep learning
AB Purpose Precise polyp detection and localisation are essential for colonoscopy diagnosis. Statistical machine learning with a large-scale data set can contribute to the construction of a computer-aided diagnosis system for the prevention of overlooking and miss-localisation of a polyp in colonoscopy. We propose new visual explaining methods for a well-trained object detector, which achieves fast and accurate polyp detection with a bounding box towards a precise automated polyp localisation. Method We refine gradient-weighted class activation mapping for more accurate highlighting of important patterns in processing a convolutional neural network. Extending the refined mapping into multiscaled processing, we define object activation mapping that highlights important object patterns in an image for a detection task. Finally, we define polyp activation mapping to achieve precise polyp localisation by integrating adaptive local thresholding into object activation mapping. We experimentally evaluate the proposed visual explaining methods with four publicly available databases. Results The refined mapping visualises important patterns in each convolutional layer more accurately than the original gradient-weighted class activation mapping. The object activation mapping clearly visualises important patterns in colonoscopic images for polyp detection. The polyp activation mapping localises the detected polyps in ETIS-Larib, CVC-Clinic and Kvasir-SEG database with mean Dice scores of 0.76, 0.72 and 0.72, respectively. Conclusions We developed new visual explaining methods for a convolutional neural network by refining and extending gradient-weighted class activation mapping. Experimental results demonstrated the validity of the proposed methods by showing that accurate visualisation of important patterns and localisation of polyps in a colonoscopic image. The proposed visual explaining methods are useful for the interpreting and applying a trained polyp detector.
C1 [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Misawa, Masashi; Mori, Yuichi; Kudo, Shin-Ei] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Tsuzuki Ku, Chigasaki Chuo 35-1, Yokohama, Kanagawa 2248503, Japan.
   [Mori, Yuichi] Univ Oslo, Clin Effectiveness Res Grp, Bygg 20,Sognsvannsveien 21, N-0372 Oslo, Norway.
C3 Nagoya University; Showa University; University of Oslo
RP Itoh, H (通讯作者)，Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM hitoh@mori.m.is.nagoya-u.ac.jp
RI Itoh, Hayato/AAM-4022-2021
OI Itoh, Hayato/0000-0002-1410-1078
FU AMED [19hs0110006h0003]; JSPS MEXT KAKENHI [26108006, 17H00867,
   17K20099]; JSPS Bilateral Joint Research Project
FX This study was funded by grants from AMED (19hs0110006h0003), JSPS MEXT
   KAKENHI(26108006, 17H00867, 17K20099), and the JSPS Bilateral Joint
   Research Project.
CR Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Itoh H, 2022, COMP M BIO BIO E-IV, V10, P289, DOI 10.1080/21681163.2021.2004445
   Itoh H, 2021, INT J COMPUT ASS RAD, V16, P1817, DOI 10.1007/s11548-021-02477-z
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Springenberg JT, 2015, P 3 INT C LEARNING R, P1
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
NR 21
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD NOV
PY 2022
VL 17
IS 11
BP 2051
EP 2063
DI 10.1007/s11548-022-02696-y
EA AUG 2022
PG 13
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA 4X3QM
UT WOS:000837551600001
PM 35939251
DA 2023-08-21
ER

PT J
AU Kavitha, MS
   Gangadaran, P
   Jackson, A
   Maran, BAV
   Kurita, T
   Ahn, BC
AF Kavitha, Muthu Subash
   Gangadaran, Prakash
   Jackson, Aurelia
   Maran, Balu Alagar Venmathi
   Kurita, Takio
   Ahn, Byeong-Cheol
TI Deep Neural Network Models for Colon Cancer Screening
SO CANCERS
LA English
DT Review
DE artificial intelligence; colorectal cancer; interpretation; neural
   network; transfer learning; transparency
ID COMPUTER-AIDED DIAGNOSIS; COLORECTAL LESIONS; POLYPS; CLASSIFICATION;
   METASTASIS; SYSTEM; COLONOSCOPY; PREDICTION; CARCINOMA; HISTOLOGY
AB Simple Summary Deep learning models have been shown to achieve high performance in diagnosing colon cancer compared to conventional image processing and hand-crafted machine learning methods. Hence, several studies have focused on developing hybrid learning, end-to-end, and transfer learning techniques to reduce manual interaction and for labelling the regions of interest. However, these weak learning techniques do not always provide a clear diagnosis. Therefore, it is necessary to develop a clear explainable learning method that can highlight factors and form the basis of clinical decisions. However, there has been little research carried out employing such transparent approaches. This study discussed the aforementioned models for colon cancer diagnosis. Early detection of colorectal cancer can significantly facilitate clinicians' decision-making and reduce their workload. This can be achieved using automatic systems with endoscopic and histological images. Recently, the success of deep learning has motivated the development of image- and video-based polyp identification and segmentation. Currently, most diagnostic colonoscopy rooms utilize artificial intelligence methods that are considered to perform well in predicting invasive cancer. Convolutional neural network-based architectures, together with image patches and preprocesses are often widely used. Furthermore, learning transfer and end-to-end learning techniques have been adopted for detection and localization tasks, which improve accuracy and reduce user dependence with limited datasets. However, explainable deep networks that provide transparency, interpretability, reliability, and fairness in clinical diagnostics are preferred. In this review, we summarize the latest advances in such models, with or without transparency, for the prediction of colorectal cancer and also address the knowledge gap in the upcoming technology.
C1 [Kavitha, Muthu Subash] Nagasaki Univ, Sch Informat & Data Sci, Nagasaki 8528521, Japan.
   [Gangadaran, Prakash; Ahn, Byeong-Cheol] Kyungpook Natl Univ, Sch Med, BK21 FOUR KNU Convergence Educ Program Biomed Sci, Daegu 41944, South Korea.
   [Gangadaran, Prakash; Ahn, Byeong-Cheol] Kyungpook Natl Univ, Kyungpook Natl Univ Hosp, Sch Med, Dept Nucl Med, Daegu 41944, South Korea.
   [Jackson, Aurelia; Maran, Balu Alagar Venmathi] Univ Malaysia Sabah, Borneo Marine Res Inst, Kota Kinabalu 88400, Sabah, Malaysia.
   [Kurita, Takio] Hiroshima Univ, Grad Sch Adv Sci & Engn, Higashihiroshima 7398521, Japan.
C3 Nagasaki University; Kyungpook National University; Kyungpook National
   University; Kyungpook National University Hospital; Universiti Malaysia
   Sabah; Hiroshima University
RP Ahn, BC (通讯作者)，Kyungpook Natl Univ, Sch Med, BK21 FOUR KNU Convergence Educ Program Biomed Sci, Daegu 41944, South Korea.; Ahn, BC (通讯作者)，Kyungpook Natl Univ, Kyungpook Natl Univ Hosp, Sch Med, Dept Nucl Med, Daegu 41944, South Korea.
EM kavitha@nagasaki-u.ac.jp; prakashg@knu.ac.kr; aureliajcksn@gmail.com;
   baymaran@ums.edu.my; tkurita@hiroshima-u.ac.jp; abc2000@knu.ac.kr
RI Venmathi Maran, Balu Alagar/G-5163-2014; Gangadaran,
   Prakash/AAV-3102-2021; Kurita, Takio/D-8674-2012
OI Venmathi Maran, Balu Alagar/0000-0003-1090-5295; Gangadaran,
   Prakash/0000-0002-0658-4604; Kurita, Takio/0000-0003-3982-6750; Kavitha,
   Muthu Subash/0000-0002-1676-561X
CR Abdeljawad K, 2015, GASTROINTEST ENDOSC, V81, P517, DOI 10.1016/j.gie.2014.04.064
   [Anonymous], 2016, NIPS
   Bejnordi BE, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.044504
   Ben Hamida A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104730
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Buendgens L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08773-1
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Ding HJ, 2020, NEUROCOMPUTING, V380, P150, DOI 10.1016/j.neucom.2019.10.097
   European Parliament. News, 2020, TRANSFER LEARNING 20
   Ficarra E, 2018, P 11 INT JOINT C BIO, V2, P58, DOI [10.5220/0006643100580066, DOI 10.5220/0006643100580066]
   Gessert N, 2019, INT J COMPUT ASS RAD, V14, P1837, DOI 10.1007/s11548-019-02004-1
   Ghosh J., 2021, ADV MACHINE LEARNING, P195
   Glasmachers T., 2017, AS C MACH LEARN, P17
   Graves A., 2014, ARXIV
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hagele M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62724-2
   Ho CW, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06264-x
   Iizuka O, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58467-9
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Kahi Charles J, 2019, Gastrointest Endosc Clin N Am, V29, P577, DOI 10.1016/j.giec.2019.05.001
   Kainz P, 2017, PEERJ, V5, DOI 10.7717/peerj.3874
   Kather JN, 2019, NAT MED, V25, P1054, DOI 10.1038/s41591-019-0462-y
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Kitajima K, 2004, J GASTROENTEROL, V39, P534, DOI 10.1007/s00535-004-1339-4
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Komura D, 2018, COMPUT STRUCT BIOTEC, V16, P34, DOI 10.1016/j.csbj.2018.01.001
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Korbar B, 2017, IEEE COMPUT SOC CONF, P821, DOI 10.1109/CVPRW.2017.114
   Koziarski M., 2020, ARXIV
   Lee H, 2022, PUBLIC MANAG REV, V24, P512, DOI 10.1080/14719037.2020.1846368
   Leggett B, 2010, GASTROENTEROLOGY, V138, P2088, DOI 10.1053/j.gastro.2009.12.066
   Li Y, 2019, AM J CANCER RES, V9, P2482
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Lopez AJS., 2010, HDB RES MACHINE LEAR, DOI [10.4018/978-1-60566-766-9, DOI 10.4018/978-1-60566-766-9]
   Lu FI, 2010, AM J SURG PATHOL, V34, P927, DOI 10.1097/PAS.0b013e3181e4f256
   Malhi A, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P530, DOI 10.1109/dicta47822.2019.8945986
   Malik J., 2019, ARXIV
   Miller FG, 2011, NEW ENGL J MED, V364, P476, DOI 10.1056/NEJMsb1011301
   Mirowski P, 2016, ARXIV
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mobadersany P, 2018, P NATL ACAD SCI USA, V115, pE2970, DOI 10.1073/pnas.1717139115
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nadimi ES, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106531
   Nartowt BJ, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.00006
   Okamoto T, 2015, IEEE ENG MED BIO, P2997, DOI 10.1109/EMBC.2015.7319022
   Pinckaers H., 2019, ARXIV
   Raczkowski L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50587-1
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Rathore S, 2015, COMPUT BIOL MED, V65, P279, DOI 10.1016/j.compbiomed.2015.03.004
   Sabol P, 2020, J BIOMED INFORM, V109, DOI 10.1016/j.jbi.2020.103523
   Sena P, 2019, ONCOL LETT, V18, P6101, DOI 10.3892/ol.2019.10928
   Shapcott M, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00052
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Song ZG, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2019-036423
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takamatsu M, 2019, COMPUT METH PROG BIO, V178, P155, DOI 10.1016/j.cmpb.2019.06.022
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Thomaz VD, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101988
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Trebeschi S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05728-9
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Veta M, 2015, MED IMAGE ANAL, V20, P237, DOI 10.1016/j.media.2014.11.010
   Vu HT, 2011, DIS COLON RECTUM, V54, P1216, DOI 10.1097/DCR.0b013e318228f8a9
   Wan JJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54031-2
   Wang KS, 2021, BMC MED, V19, DOI 10.1186/s12916-021-01942-5
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   West NP, 2010, BRIT J CANCER, V102, P1519, DOI 10.1038/sj.bjc.6605674
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Wong MCS, 2021, CLIN GASTROENTEROL H, V19, P955, DOI 10.1016/j.cgh.2020.02.026
   Xu Lin, 2020, J Pathol Inform, V11, P28, DOI 10.4103/jpi.jpi_68_19
   Xu Y, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1685-x
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yao JW, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101789
   Yoon H, 2019, J DIGIT IMAGING, V32, P131, DOI 10.1007/s10278-018-0112-9
   Yu G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26643-8
   Zhao XY, 2020, EBIOMEDICINE, V56, DOI 10.1016/j.ebiom.2020.102780
NR 83
TC 4
Z9 4
U1 9
U2 21
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-6694
J9 CANCERS
JI Cancers
PD AUG
PY 2022
VL 14
IS 15
AR 3707
DI 10.3390/cancers14153707
PG 14
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA 3T3HN
UT WOS:000840169900001
PM 35954370
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Lo, CM
   Yeh, YH
   Tang, JH
   Chang, CC
   Yeh, HJ
AF Lo, Chung-Ming
   Yeh, Yu-Hsuan
   Tang, Jui-Hsiang
   Chang, Chun-Chao
   Yeh, Hsing-Jung
TI Rapid Polyp Classification in Colonoscopy Using Textural and
   Convolutional Features
SO HEALTHCARE
LA English
DT Article
DE colorectal cancer; colon polyp; image features; convolutional neural
   network
ID COLORECTAL-CANCER; POLYPECTOMY; RISK
AB Colorectal cancer is the leading cause of cancer-associated morbidity and mortality worldwide. One of the causes of developing colorectal cancer is untreated colon adenomatous polyps. Clinically, polyps are detected in colonoscopy and the malignancies are determined according to the biopsy. To provide a quick and objective assessment to gastroenterologists, this study proposed a quantitative polyp classification via various image features in colonoscopy. The collected image database was composed of 1991 images including 1053 hyperplastic polyps and 938 adenomatous polyps and adenocarcinomas. From each image, textural features were extracted and combined in machine learning classifiers and machine-generated features were automatically selected in deep convolutional neural networks (DCNN). The DCNNs included AlexNet, Inception-V3, ResNet-101, and DenseNet-201. AlexNet trained from scratch achieved the best performance of 96.4% accuracy which is better than transfer learning and textural features. Using the prediction models, the malignancy level of polyps can be evaluated during a colonoscopy to provide a rapid treatment plan.
C1 [Lo, Chung-Ming; Yeh, Yu-Hsuan; Yeh, Hsing-Jung] Taipei Med Univ, Grad Inst BioMed Informat, Coll Med Sci & Technol, Taipei 110301, Taiwan.
   [Lo, Chung-Ming] Natl Chengchi Univ, Grad Inst Lib Informat & Archival Studies, Taipei 116011, Taiwan.
   [Tang, Jui-Hsiang; Chang, Chun-Chao; Yeh, Hsing-Jung] Taipei Med Univ, Coll Med, Div Gastroenterol & Hepatol, Sch Med,Dept Internal Med, Taipei 110301, Taiwan.
   [Chang, Chun-Chao; Yeh, Hsing-Jung] Taipei Med Univ Hosp, Dept Internal Med, Div Gastroenterol & Hepatol, Taipei 110301, Taiwan.
   [Chang, Chun-Chao; Yeh, Hsing-Jung] Taipei Med Univ, Res Ctr Digest Med, Taipei 110301, Taiwan.
C3 National Chengchi University; Taipei Medical University Hospital
RP Yeh, HJ (通讯作者)，Taipei Med Univ, Grad Inst BioMed Informat, Coll Med Sci & Technol, Taipei 110301, Taiwan.; Yeh, HJ (通讯作者)，Taipei Med Univ, Coll Med, Div Gastroenterol & Hepatol, Sch Med,Dept Internal Med, Taipei 110301, Taiwan.; Yeh, HJ (通讯作者)，Taipei Med Univ Hosp, Dept Internal Med, Div Gastroenterol & Hepatol, Taipei 110301, Taiwan.; Yeh, HJ (通讯作者)，Taipei Med Univ, Res Ctr Digest Med, Taipei 110301, Taiwan.
EM yiew@ms10.hinet.net
OI Yeh, Hsing-Jung/0000-0003-3415-836X; chang,
   chun-chao/0000-0002-3396-1559
FU Division of Gastroenterology and Hepatology, Department of Internal
   Medicine, Taipei Medical University Hospital
FX The authors would like to thank the Division of Gastroenterology and
   Hepatology, Department of Internal Medicine, Taipei Medical University
   Hospital for financially supporting this research.
CR [Anonymous], 2014, COL CANC PREV PDQ
   [Anonymous], 2005, PRINCIPAL COMPONENT, DOI [10.1002/0470013192.bsa501, DOI 10.1002/0470013192.BSA501]
   [Anonymous], 2014, WORLD CANC REPORT
   Ay B, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105725
   Beaugerie L, 2015, NEW ENGL J MED, V372, P1441, DOI 10.1056/NEJMra1403718
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Buciu I, 2009, 2009 2ND INTERNATIONAL SYMPOSIUM ON APPLIED SCIENCES IN BIOMEDICAL AND COMMUNICATION TECHNOLOGIES (ISABEL 2009), P8
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai Wen-Li, 2018, Chronic Dis Transl Med, V4, P18, DOI 10.1016/j.cdtm.2018.01.002
   Carethers JM, 2015, GASTROENTEROLOGY, V149, P1177, DOI 10.1053/j.gastro.2015.06.047
   Chaddad A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149893
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Eckstein J., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   Han S, 2015, ADV NEUR IN, V28
   Hiramatsu K, 2012, ALIMENT PHARM THER, V36, P575, DOI 10.1111/j.1365-2036.2012.05221.x
   Hsu YC, 2017, J CHIN MED ASSOC, V80, P56, DOI 10.1016/j.jcma.2016.08.009
   Hu KL, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105760
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Lee JG, 2011, COMPUT BIOL MED, V41, P790, DOI 10.1016/j.compbiomed.2011.06.015
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Mann R, 2022, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.728704
   Moreno P, 2005, LECT NOTES COMPUT SC, V3522, P11
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pogorelov K, 2018, COMP MED SY, P381, DOI 10.1109/CBMS.2018.00073
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shalman D, 2015, ALIMENT PHARM THER, V42, P949, DOI 10.1111/apt.13367
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Siegel RL, 2017, JNCI-J NATL CANCER I, V109, DOI 10.1093/jnci/djw322
   Szegedy C., 2015, PROC IEEE C COMPUT V, DOI DOI 10.1109/CVPR.2015.7298594
   Tan JX, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI)
   Torres J, 2017, LANCET, V389, P1741, DOI 10.1016/S0140-6736(16)31711-1
   Yang Q, 2015, MED PHYS, V42, P103, DOI 10.1118/1.4903280
   Yoshida H, 2002, RADIOGRAPHICS, V22, P963, DOI 10.1148/radiographics.22.4.g02jl16963
   Yuan, 2016, FEATURE EXTRACTION I, VVolume 10033
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhai Y, 2018, PROC CVPR IEEE, P4139, DOI 10.1109/CVPR.2018.00435
NR 41
TC 3
Z9 3
U1 7
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-9032
J9 HEALTHCARE-BASEL
JI Healthcare
PD AUG
PY 2022
VL 10
IS 8
AR 1494
DI 10.3390/healthcare10081494
PG 9
WC Health Care Sciences & Services; Health Policy & Services
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services
GA 4B9DB
UT WOS:000846067200001
PM 36011151
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Moen, S
   Vuik, FER
   Kuipers, EJ
   Spaander, MCW
AF Moen, Sarah
   Vuik, Fanny E. R.
   Kuipers, Ernst J.
   Spaander, Manon C. W.
TI Artificial Intelligence in Colon Capsule Endoscopy-A Systematic Review
SO DIAGNOSTICS
LA English
DT Review
DE colon capsule endoscopy; artificial intelligence; polyp detection; bowel
   cleansing
ID BOWEL PREPARATION; EUROPEAN-SOCIETY; QUALITY; ESGE
AB Background and aims: The applicability of colon capsule endoscopy in daily practice is limited by the accompanying labor-intensive reviewing time and the risk of inter-observer variability. Automated reviewing of colon capsule endoscopy images using artificial intelligence could be timesaving while providing an objective and reproducible outcome. This systematic review aims to provide an overview of the available literature on artificial intelligence for reviewing colonic mucosa by colon capsule endoscopy and to assess the necessary action points for its use in clinical practice. Methods: A systematic literature search of literature published up to January 2022 was conducted using Embase, Web of Science, OVID MEDLINE and Cochrane CENTRAL. Studies reporting on the use of artificial intelligence to review second-generation colon capsule endoscopy colonic images were included. Results: 1017 studies were evaluated for eligibility, of which nine were included. Two studies reported on computed bowel cleansing assessment, five studies reported on computed polyp or colorectal neoplasia detection and two studies reported on other implications. Overall, the sensitivity of the proposed artificial intelligence models were 86.5-95.5% for bowel cleansing and 47.4-98.1% for the detection of polyps and colorectal neoplasia. Two studies performed per-lesion analysis, in addition to per-frame analysis, which improved the sensitivity of polyp or colorectal neoplasia detection to 81.3-98.1%. By applying a convolutional neural network, the highest sensitivity of 98.1% for polyp detection was found. Conclusion: The use of artificial intelligence for reviewing second-generation colon capsule endoscopy images is promising. The highest sensitivity of 98.1% for polyp detection was achieved by deep learning with a convolutional neural network. Convolutional neural network algorithms should be optimized and tested with more data, possibly requiring the setup of a large international colon capsule endoscopy database. Finally, the accuracy of the optimized convolutional neural network models need to be confirmed in a prospective setting.
C1 [Moen, Sarah; Vuik, Fanny E. R.; Kuipers, Ernst J.; Spaander, Manon C. W.] Erasmus MC, Univ Med Ctr, Dept Gastroenterol & Hepatol, NL-3015 CE Rotterdam, Netherlands.
C3 Erasmus University Rotterdam; Erasmus MC
RP Spaander, MCW (通讯作者)，Erasmus MC, Univ Med Ctr, Dept Gastroenterol & Hepatol, NL-3015 CE Rotterdam, Netherlands.
EM v.spaander@erasmusmc.nl
OI Spaander, Manon/0000-0002-9103-9757
CR Adjei PE, 2022, INT J COMPUT ASS RAD, V17, P1289, DOI 10.1007/s11548-022-02651-x
   Antonelli G, 2021, BEST PRACT RES CL GA, V52-53, DOI 10.1016/j.bpg.2020.101713
   Becq A, 2018, ENDOSC INT OPEN, V6, pE844, DOI 10.1055/a-0577-2897
   Buijs MM, 2018, UNITED EUR GASTROENT, V6, P1563, DOI 10.1177/2050640618798182
   Buijs MM, 2018, ENDOSC INT OPEN, V6, pE1044, DOI 10.1055/a-0627-7136
   Figueiredo Pedro N, 2011, Diagn Ther Endosc, V2011, P182435, DOI 10.1155/2011/182435
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Herp J, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020193
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Kjolhede T, 2021, ENDOSCOPY, V53, P713, DOI 10.1055/a-1249-3938
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI 10.7326/0003-4819-151-4-200908180-00135
   Nadimi ES, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106531
   Ozyoruk KB, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102058
   Saraiva MM, 2021, TECH COLOPROCTOL, V25, P1243, DOI 10.1007/s10151-021-02517-5
   Saraiva MM, 2021, ENDOSC INT OPEN, V09, pE1264, DOI 10.1055/a-1490-8960
   Soffer S, 2020, GASTROINTEST ENDOSC, V92, P831, DOI 10.1016/j.gie.2020.04.039
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Spada C, 2021, EUR RADIOL, V31, P2967, DOI 10.1007/s00330-020-07413-4
   Spada C, 2016, CLIN GASTROENTEROL H, V14, P1533, DOI 10.1016/j.cgh.2016.04.038
   Vuik FER, 2021, ENDOSC INT OPEN, V09, pE1852, DOI 10.1055/a-1578-1800
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Yamada A, 2021, ENDOSCOPY, V53, P832, DOI 10.1055/a-1266-1066
NR 25
TC 6
Z9 6
U1 1
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD AUG
PY 2022
VL 12
IS 8
AR 1994
DI 10.3390/diagnostics12081994
PG 14
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 4D2YU
UT WOS:000847012400001
PM 36010345
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Souaidi, M
   El Ansari, M
AF Souaidi, Meryem
   El Ansari, Mohamed
TI Multi-Scale Hybrid Network for Polyp Detection in Wireless Capsule
   Endoscopy and Colonoscopy Images
SO DIAGNOSTICS
LA English
DT Article
DE deep transfer learning; multi-scale encoding; weighted feature maps
   fusion; image augmentation; polyp; inception module; single-shot
   multibox detector (SSD); wireless capsule endoscopy images (WCE)
ID VALIDATION; DIAGNOSIS; WCE
AB The trade-off between speed and precision is a key step in the detection of small polyps in wireless capsule endoscopy (WCE) images. In this paper, we propose a hybrid network of an inception v4 architecture-based single-shot multibox detector (Hyb-SSDNet) to detect small polyp regions in both WCE and colonoscopy frames. Medical privacy concerns are considered the main barriers to WCE image acquisition. To satisfy the object detection requirements, we enlarged the training datasets and investigated deep transfer learning techniques. The Hyb-SSDNet framework adopts inception blocks to alleviate the inherent limitations of the convolution operation to incorporate contextual features and semantic information into deep networks. It consists of four main components: (a) multi-scale encoding of small polyp regions, (b) using the inception v4 backbone to enhance more contextual features in shallow and middle layers, and (c) concatenating weighted features of mid-level feature maps, giving them more importance to highly extract semantic information. Then, the feature map fusion is delivered to the next layer, followed by some downsampling blocks to generate new pyramidal layers. Finally, the feature maps are fed to multibox detectors, consistent with the SSD process-based VGG16 network. The Hyb-SSDNet achieved a 93.29% mean average precision (mAP) and a testing speed of 44.5 FPS on the WCE dataset. This work proves that deep learning has the potential to develop future research in polyp detection and classification tasks.
C1 [Souaidi, Meryem; El Ansari, Mohamed] Univ Ibn Zohr, Fac Sci, Comp Sci, LABSIV, Agadir 80000, Morocco.
   [El Ansari, Mohamed] Univ Moulay Ismail, Fac Sci, Comp Sci Dept, Informat & Applicat Lab, Meknes 50070, Morocco.
C3 Ibn Zohr University of Agadir; Moulay Ismail University of Meknes
RP Souaidi, M (通讯作者)，Univ Ibn Zohr, Fac Sci, Comp Sci, LABSIV, Agadir 80000, Morocco.
EM souaidi.meryem@gmail.com
RI El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066
FU Ministry of National Education, Vocational Training, Higher Education
   and Scientific Research; Ministry of Industry, Trade and Green and
   Digital Economy; National Center for Scientific and Technical Research
   (CNRST) [ALKHAWARIZMI/2020/20]; Digital Development Agency (ADD)
FX This work was partially supported by the Ministry of National Education,
   Vocational Training, Higher Education and Scientific Research, the
   Ministry of Industry, Trade and Green and Digital Economy, the Digital
   Development Agency (ADD), and the National Center for Scientific and
   Technical Research (CNRST). Project number: ALKHAWARIZMI/2020/20.
CR Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], 2015, PROC IEEE C COMPUT V
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Charfi S, 2020, SOFT COMPUT, V24, P4469, DOI 10.1007/s00500-019-04208-8
   Charfi S, 2019, IET IMAGE PROCESS, V13, P1023, DOI 10.1049/iet-ipr.2018.6232
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Chatfield K, 2014, ARXIV
   Chen BL, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103019
   Chen XL, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/2144472
   Choi HT, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082842
   Dulf EH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175704
   Fu CY, 2017, DSSD DECONVOLUTIONAL, DOI DOI 10.48550/ARXIV.1701.06659
   Garrido A, 2021, IEEE ACCESS, V9, P148048, DOI 10.1109/ACCESS.2021.3124019
   Girshick R., 2014, P IEEE COMP SOC C CO
   Hasanpour S.H., 2018, ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jeong J., 2017, ARXIV
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Jifeng D., 2016, ARXIV
   Krenzer A., REAL TIME POLYP DETE
   Lafraxo S, 2020, INT C ADV INTELLIGEN, P887
   Lafraxo S., 2021, P 2020 6 IEEE C INFO, P489
   Lafraxo S, 2022, MULTIMED TOOLS APPL, V81, P16021, DOI 10.1007/s11042-022-12521-y
   Lafraxo S, 2020, 2020 8TH INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND MOBILE COMMUNICATIONS (WINCOM 2020), P130, DOI 10.1109/wincom50532.2020.9272456
   Li Z., 2017, ARXIV
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102052
   Ma W, 2020, IEEE ACCESS, V8, P188577, DOI 10.1109/ACCESS.2020.3031990
   Mash Robert, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P113, DOI 10.1007/978-3-319-50835-1_11
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pan HD, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115987
   PICARD RR, 1984, J AM STAT ASSOC, V79, P575, DOI 10.2307/2288403
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy AG, 2019, IEEE T MED IMAGING, V38, P540, DOI 10.1109/TMI.2018.2867261
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shin HC, 2015, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2015.7298712
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Souaidi M., 2020, ADV INTELLIGENT SYST, P870
   Souaidi M., 2017, P 2017 INT C ADV TEC, P1
   Souaidi M, 2022, IEEE ACCESS, V10, P47124, DOI 10.1109/ACCESS.2022.3171238
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Szegedy C., 2017, AAAI, DOI DOI 10.1609/AAAI.V31I1.11231
   Tashk A, 2020, IEEE C EVOL COMPUTAT
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang TC, 2022, ANAL METHODS-UK, V14, P508, DOI [10.1039/D1AY01726H, 10.1039/d1ay01726h]
   WE O, ETIS LARIB POLYP DB
   Xu LX, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10161892
   Zamil Mohammed AL., 2018, ARXIV
   Zhai SP, 2020, IEEE ACCESS, V8, P24344, DOI 10.1109/ACCESS.2020.2971026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 64
TC 4
Z9 4
U1 3
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD AUG
PY 2022
VL 12
IS 8
AR 2030
DI 10.3390/diagnostics12082030
PG 23
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 4D2PB
UT WOS:000846987100001
PM 36010380
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Yu, J
   Li, ZP
   Xu, C
   Feng, B
AF Yu, Jing
   Li, Zhengping
   Xu, Chao
   Feng, Bo
TI A Segmentation Algorithm of Colonoscopy Images Based on Multi-Scale
   Feature Fusion
SO ELECTRONICS
LA English
DT Article
DE colorectal cancer; polyp segmentation; multi-scale feature fusion; cross
   extraction module; multi-proportion fusion module
ID POLYP DETECTION; CANCER
AB Colorectal cancer is a common malignant tumor. Colorectal cancer is primarily caused by the cancerization of an adenomatous polyp. Segmentation of polyps in computer-assisted enteroscopy images is helpful for doctors to diagnose and treat the disease accurately. In this study, a segmentation algorithm of colonoscopy images based on multi-scale feature fusion is proposed. The proposed algorithm adopts ResNet50 as the backbone network to extract features. The shallow features are processed using the cross extraction module, thus increasing the receptive field, retaining the texture information, and fusing the processed shallow features and deep features at different proportions based on a multi-proportion fusion module. The proposed algorithm is capable of suppressing redundant information, removing background noise, and sharpening boundaries while acquiring considerable semantic information. As revealed by the results of the experiments on the published Kvasir-SEG dataset of intestinal polyps, the mean Dice coefficient and mean intersection over union were obtained as 0.9192 and 0.8873, better than that of existing mainstream algorithms. The result verifies the effectiveness of the proposed network and provides a reference for deep learning concerning the image processing and analysis of intestinal polyps.
C1 [Yu, Jing; Li, Zhengping; Xu, Chao; Feng, Bo] Anhui Univ, Sch Integrated Circuits, Hefei 230601, Peoples R China.
   [Yu, Jing; Li, Zhengping; Xu, Chao; Feng, Bo] AnHui Engn Lab Agro Ecol Big Data, Hefei 230601, Peoples R China.
C3 Anhui University
RP Li, ZP (通讯作者)，Anhui Univ, Sch Integrated Circuits, Hefei 230601, Peoples R China.; Li, ZP (通讯作者)，AnHui Engn Lab Agro Ecol Big Data, Hefei 230601, Peoples R China.
EM 04173@ahu.edu.cn
RI Yu, Yifu/M-6338-2018
FU National Key Research and Development Program of China [2019YFC0117800]
FX This research was funded by the National Key Research and Development
   Program of China (No. 2019YFC0117800).
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B., 2021, ARXIV
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Graham S, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101563
   He K, 2016, P IEEE C COMP VIS PA
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C. -H., 2021, ARXIV
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jiang D, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091536
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Lou AG, 2022, PROC SPIE, V12032, DOI 10.1117/12.2611802
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mattyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Ramachandran P, 2017, ARXIV
   Ronneberger O, 2015, 161207003 ARXIV
   Srivastava A., 2021, ARXIV, DOI 10.48550/ARXIV.2111.10614
   Srivastava A, 2022, IEEE J BIOMED HEALTH, V26, P2252, DOI 10.1109/JBHI.2021.3138024
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Vaswani A., 2017, ADV NEURAL INFORM PR, P6000, DOI [DOI 10.48550/ARXIV.1706.03762, 10.5555/3295222.3295349]
   Wang J., 2022, ARXIV
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 39
TC 0
Z9 0
U1 8
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD AUG
PY 2022
VL 11
IS 16
AR 2501
DI 10.3390/electronics11162501
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Physics
GA 4B6XU
UT WOS:000845918300001
OA gold
DA 2023-08-21
ER

PT J
AU Yue, GH
   Han, WW
   Jiang, B
   Zhou, TW
   Cong, RM
   Wang, TF
AF Yue, Guanghui
   Han, Wanwan
   Jiang, Bin
   Zhou, Tianwei
   Cong, Runmin
   Wang, Tianfu
TI Boundary Constraint Network With Cross Layer Feature Integration for
   Polyp Segmentation
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Feature extraction; Shape; Data mining; Image segmentation;
   Bioinformatics; Endoscopes; Task analysis; Polyp segmentation; deep
   network; boundary constraint; cross-layer feature integration; endoscope
ID COLORECTAL-CANCER; CONTEXT; VALIDATION; ENDOSCOPY; COLON
AB Clinically, proper polyp localization in endoscopy images plays a vital role in the follow-up treatment (e.g., surgical planning). Deep convolutional neural networks (CNNs) provide a favoured prospect for automatic polyp segmentation and evade the limitations of visual inspection, e.g., subjectivity and overwork. However, most existing CNNs-based methods often provide unsatisfactory segmentation performance. In this paper, we propose a novel boundary constraint network, namely BCNet, for accurate polyp segmentation. The success of BCNet benefits from integrating cross-level context information and leveraging edge information. Specifically, to avoid the drawbacks caused by simple feature addition or concentration, BCNet applies a cross-layer feature integration strategy (CFIS) in fusing the features of the top-three highest layers, yielding a better performance. CFIS consists of three attention-driven cross-layer feature interaction modules (ACFIMs) and two global feature integration modules (GFIMs). ACFIM adaptively fuses the context information of the top-three highest layers via the self-attention mechanism instead of direct addition or concentration. GFIM integrates the fused information across layers with the guidance from global attention. To obtain accurate boundaries, BCNet introduces a bilateral boundary extraction module that explores the polyp and non-polyp information of the shallow layer collaboratively based on the high-level location information and boundary supervision. Through joint supervision of the polyp area and boundary, BCNet is able to get more accurate polyp masks. Experimental results on three public datasets show that the proposed BCNet outperforms seven state-of-the-art competing methods in terms of both effectiveness and generalization.
C1 [Yue, Guanghui; Han, Wanwan; Wang, Tianfu] Shenzhen Univ, Hlth Sci Ctr, Natl Reg Key Technol Engn Lab Med Ultrasound, Sch Biomed Engn,Guangdong Key Lab Biomed Measurem, Shenzhen 518060, Peoples R China.
   [Jiang, Bin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Zhou, Tianwei] Shenzhen Univ, Coll Management, Shenzhen 518060, Peoples R China.
   [Cong, Runmin] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100091, Peoples R China.
C3 Shenzhen University; Shenzhen University; Shenzhen University; Beijing
   Jiaotong University
RP Zhou, TW (通讯作者)，Shenzhen Univ, Coll Management, Shenzhen 518060, Peoples R China.
EM yueguanghui@szu.edu.cn; wan_h0921@163.com; jiangbin@ieee.org;
   tianwei@szu.edu.cn; rmcong@bjtu.edu.cn; tfwang@szu.edu.cn
RI Zhou, Tianwei/GSI-8460-2022
FU National Natural Science Foundation of China [62001302, 62071309,
   62103286]; Guangdong Basic and Applied Basic Research Foundation
   [2021A1515011348, 2019A1515111205, 2019A1515110401]; Shenzhen Science
   and Technology Program [RCBS2020071411 4920379]; Natural Science
   Foundation of Shenzhen [JCYJ20190808145011259]; Tencent "Rhinoceros
   Birds" -Scientific Research Foundation for Young Teachers of Shenzhen
   University; Social Science Youth Foundation of Ministry of Education of
   China [21YJC630181]; Open Project Program of State Key Laboratory of
   Virtual Reality Technology and Systems, Beihang University
   [VRLAB2021C05]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62001302, 62071309, and 62103286, in
   part by Guangdong Basic and Applied Basic Research Foundation under
   Grants 2021A1515011348, 2019A1515111205, and 2019A1515110401, in part by
   Shenzhen Science and Technology Program under Grant RCBS2020071411
   4920379, in part by the Natural Science Foundation of Shenzhen under
   Grant JCYJ20190808145011259, in part by the Tencent "Rhinoceros Birds"
   -Scientific Research Foundation for Young Teachers of Shenzhen
   University, in part by the Social Science Youth Foundation of Ministry
   of Education of China under Grant 21YJC630181, and in part by the Open
   Project Program of State Key Laboratory of Virtual Reality Technology
   and Systems, Beihang University under Grant VRLAB2021C05.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Bernal Jorge, 2012, Abdominal Imaging. Computational and Clinical Applications. Third International Workshop Held in Conjunction with MICCAI 2011. Revised Selected Papers, P76, DOI 10.1007/978-3-642-28557-8_10
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bretthauer M, 2016, JAMA INTERN MED, V176, P894, DOI 10.1001/jamainternmed.2016.0960
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Ghatwary N, 2021, IEEE J BIOMED HEALTH, V25, P131, DOI 10.1109/JBHI.2020.2995193
   Gridach M, 2021, NEURAL NETWORKS, V140, P274, DOI 10.1016/j.neunet.2021.03.023
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guo XQ, 2021, IEEE T MED IMAGING, V40, P1134, DOI 10.1109/TMI.2020.3046843
   Huang C.-H., 2021, ARXIV
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Iwahori Y., 2013, PROC INT C MACH VIS, P21
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Lin TH, 2021, IEEE J BIOMED HEALTH, V25, P77, DOI 10.1109/JBHI.2020.2999731
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Poudel S, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107445
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Sasmal P, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3082315
   Siegel RL., 2020, CA-CANCER J CLIN, V70, P145, DOI [DOI 10.3322/caac.21590, 10.3322/caac.21601]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Nguyen TC, 2021, LECT NOTES COMPUT SC, V12901, P633, DOI 10.1007/978-3-030-87193-2_60
   Tjaden JM, 2018, SURG ENDOSC, V32, P3108, DOI 10.1007/s00464-018-6025-3
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Vaswani A, 2017, ADV NEUR IN, V30
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu H., PROC AAAI C ARTIF IN, V35, P2916
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yang XY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038011
   Yeung M, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104815
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 56
TC 11
Z9 11
U1 11
U2 31
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD AUG
PY 2022
VL 26
IS 8
BP 4090
EP 4099
DI 10.1109/JBHI.2022.3173948
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA 3V7PB
UT WOS:000841851000048
PM 35536816
DA 2023-08-21
ER

PT J
AU Fan, X
   Kang, XJ
   Tian, SW
   Wu, WD
   Yu, L
AF Fan, Xin
   Kang, Xiaojing
   Tian, Shengwei
   Wu, Weidong
   Yu, Long
TI Warp-based edge feature reinforcement network for medical image
   segmentation
SO MEDICAL PHYSICS
LA English
DT Article
DE edge reinforcement; medical image; multiscale feature fusion; semantic
   segmentation
AB Background Rapid and accurate segmentation of medical images can provide important guidance in the early stages of life-threatening diseases. Purpose However, fuzzy edges and high similarity with the background in images usually cause undersegmentation or oversegmentation. To solve these problems. Methods We propose a novel edge features-reinforcement (EFR) module that uses relative frequency changes before and after warping images to extract edge information. Then, the EFR module leverages deep features to guide shallow features to produce a band-shaped edge attention map for reinforcing the edge region of all channels. We also propose a multiscale context exploration (MCE) module to fuse multiscale features and to extract channel and spatial correlations, which allows a model to focus on the parts that contribute most to the final segmentation. We construct EFR-Net by embedding EFR and MCE modules on the encoder-decoder architecture. Results We verify EFR-Net's performance with four medical datasets: retinal vessel segmentation dataset DRIVE, endoscopic polyp segmentation dataset CVC-ClinicDB, dermoscopic image dataset ISIC2018, and aortic true lumen dataset Aorta-computed tomography (CT). The proposed model achieves Dice similarity coefficients (DSCs) of 81.61%, 92.87%, 89.87%, and 96.98% on DRIVE, CVC-ClinicDB, ISIC2018, and Aorta-CT, respectively, which are better than those of current mainstream methods. In particular, the DSC of polyp segmentation increased by 3.87%. Conclusion Through quantitative and qualitative research, our method is determined to surpass current mainstream segmentation methods, and EFR modules can effectively improve the edge prediction effect of color images and CT images. The proposed modules are easily embedded in other encoder-decoder architectures, which has the potential to be applied and expanded.
C1 [Fan, Xin] Xinjiang Univ, Sch Informat Sci & Engn, Urumqi, Peoples R China.
   [Kang, Xiaojing; Wu, Weidong] Xinjiang Univ, Peoples Hosp Xinjiang Uygur Autonomous Reg, Urumqi, Peoples R China.
   [Tian, Shengwei; Yu, Long] Xinjiang Univ, Coll Software, Urumqi 830000, Peoples R China.
   [Tian, Shengwei] Xin Jiang Univ, Coll Software, Key Lab Software Engn Technol, Urumqi, Peoples R China.
   [Yu, Long] Xinjiang Univ, Coll Informat Sci & Engn, Signal & Signal Proc Lab, Urumqi, Peoples R China.
C3 Xinjiang University; Xinjiang University; Xinjiang University; Xinjiang
   University; Xinjiang University
RP Tian, SW (通讯作者)，Xinjiang Univ, Coll Software, Urumqi 830000, Peoples R China.
EM tianshengwei@163.com
RI Wang, Zhi/GZB-2713-2022
OI Wang, Zhi/0000-0001-6952-8848; Yu, Long/0000-0001-9041-0801; Yu,
   Long/0000-0002-9038-4129
FU Xinjiang Uygur Autonomous Region Key RD Program [2021B03001-4]
FX Xinjiang Uygur Autonomous Region Key R&D Program, Grant/Award Number:
   2021B03001-4
CR Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Cao WW, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102856
   Chen L.-C., 2015, PROC INT C LEARN REP, P1, DOI DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen W., 2021, ICASSP 2021 2021 IEE
   Du XF, 2021, MED PHYS, V48, P3827, DOI 10.1002/mp.14944
   Ebner M, 2004, J PARALLEL DISTR COM, V64, P79, DOI 10.1016/j.jpdc.2003.06.004
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Ji LY, 2020, MED PHYS, V47, P4254, DOI 10.1002/mp.14364
   Jiang Y, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253056
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kuang H., 2021, 2021 IEEE INT C BIOI
   Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Marchetti M, 2019, ARXIV PREPRINT ARXIV
   Oktay O., 2018, P MIDL, P1, DOI DOI 10.48550/ARXIV.1804.03999
   Raza M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0261698
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Wang DY, 2020, IEEE J BIOMED HEALTH, V24, P3384, DOI 10.1109/JBHI.2020.3002985
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Zhang YH, 2021, J INTELL FUZZY SYST, V41, P7329, DOI 10.3233/JIFS-211182
   Zhang Z., 2019, ET NET GENERIC EDGE
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 29
TC 1
Z9 1
U1 1
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD DEC
PY 2022
VL 49
IS 12
BP 7609
EP 7622
DI 10.1002/mp.15872
EA JUL 2022
PG 14
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA 8B9XQ
UT WOS:000832979800001
PM 35870115
DA 2023-08-21
ER

PT J
AU Byeon, SJ
   Park, J
   Cho, YA
   Cho, BJ
AF Byeon, Sun-ju
   Park, Jungkap
   Cho, Yoon Ah
   Cho, Bum-Joo
TI Automated histological classification for digital pathology images of
   colonoscopy specimen via deep learning
SO SCIENTIFIC REPORTS
LA English
DT Article
ID EVOLUTION
AB Colonoscopy is an effective tool to detect colorectal lesions and needs the support of pathological diagnosis. This study aimed to develop and validate deep learning models that automatically classify digital pathology images of colon lesions obtained from colonoscopy-related specimen. Histopathological slides of colonoscopic biopsy or resection specimens were collected and grouped into six classes by disease category: adenocarcinoma, tubular adenoma (TA), traditional serrated adenoma (TSA), sessile serrated adenoma (SSA), hyperplastic polyp (HP), and non-specific lesions. Digital photographs were taken of each pathological slide to fine-tune two pre-trained convolutional neural networks, and the model performances were evaluated. A total of 1865 images were included from 703 patients, of which 10% were used as a test dataset. For six-class classification, the mean diagnostic accuracy was 97.3% (95% confidence interval [CI], 96.0-98.6%) by DenseNet-161 and 95.9% (95% CI 94.1-97.7%) by EfficientNet-B7. The per-class area under the receiver operating characteristic curve (AUC) was highest for adenocarcinoma (1.000; 95% CI 0.999-1.000) by DenseNet-161 and TSA (1.000; 95% CI 1.000-1.000) by EfficientNet-B7. The lowest per-class AUCs were still excellent: 0.991 (95% CI 0.983-0.999) for HP by DenseNet-161 and 0.995 for SSA (95% CI 0.992-0.998) by EfficientNet-B7. Deep learning models achieved excellent performances for discriminating adenocarcinoma from non-adenocarcinoma lesions with an AUC of 0.995 or 0.998. The pathognomonic area for each class was appropriately highlighted in digital images by saliency map, particularly focusing epithelial lesions. Deep learning models might be a useful tool to help the diagnosis for pathologic slides of colonoscopy-related specimens.
C1 [Byeon, Sun-ju] Hallym Univ, Coll Med, Dept Pathol, Dongtan Sacred Heart Hosp, Hwaseong, South Korea.
   [Park, Jungkap; Cho, Bum-Joo] Hallym Univ, Med Artificial Intelligence Ctr, Sacred Heart Hosp, Anyang, South Korea.
   [Cho, Yoon Ah] Hallym Univ, Coll Med, Dept Pathol, Sacred Heart Hosp, Anyang, South Korea.
   [Cho, Bum-Joo] Hallym Univ, Coll Med, Dept Ophthalmol, Sacred Heart Hosp, 22 Gwanpyeong Ro 170 Beon Gil, Anyang 14068, Gyeonggi Do, South Korea.
C3 Hallym University; Hallym University; Hallym University; Hallym
   University
RP Cho, BJ (通讯作者)，Hallym Univ, Med Artificial Intelligence Ctr, Sacred Heart Hosp, Anyang, South Korea.; Cho, BJ (通讯作者)，Hallym Univ, Coll Med, Dept Ophthalmol, Sacred Heart Hosp, 22 Gwanpyeong Ro 170 Beon Gil, Anyang 14068, Gyeonggi Do, South Korea.
EM bjcho8@gmail.com
OI Byeon, Sun-ju/0000-0002-9599-4970
FU Bio & Medical Technology Development Program of the National Research
   Foundation (NRF); Korean government (MSIT) [NRF-2019R1G1A1011227];
   Hallym University [HURF-2018-30]
FX This research was supported by the Bio & Medical Technology Development
   Program of the National Research Foundation (NRF), and funded by the
   Korean government (MSIT) (No. NRF-2019R1G1A1011227) and Hallym
   University Research Fund 2018 (HURF-2018-30).
CR Cardoso R, 2019, CANCER PREV RES, V12, P617, DOI 10.1158/1940-6207.CAPR-19-0202
   Cerilli LA, 2012, ARCH PATHOL LAB MED, V136, P854, DOI 10.5858/arpa.2012-0205-RA
   Cui M, 2021, LAB INVEST, V101, P412, DOI 10.1038/s41374-020-00514-0
   Greaves M, 2012, NATURE, V481, P306, DOI 10.1038/nature10762
   Gross DJ, 2019, ARCH PATHOL LAB MED, V143, P610, DOI 10.5858/arpa.2018-0223-CP
   Huang G, 2018, Arxiv, DOI [arXiv:1608.06993, 10.48550/arXiv.1608.06993]
   Iizuka O, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58467-9
   Jones AD, 2019, HISTOPATHOLOGY, V75, P39, DOI 10.1111/his.13844
   Kinchen J, 2018, CELL, V175, P372, DOI 10.1016/j.cell.2018.08.067
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Kumar N, 2020, J DIGIT IMAGING, V33, P1034, DOI 10.1007/s10278-020-00351-z
   Li JY, 2020, GUT, V69, P1283, DOI 10.1136/gutjnl-2019-319438
   Lichtblau D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209274
   Liu Y, 2019, ARCH PATHOL LAB MED, V143, P859, DOI 10.5858/arpa.2018-0147-OA
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Metter DM, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.4337
   Niazi MKK, 2019, LANCET ONCOL, V20, pE253, DOI 10.1016/S1470-2045(19)30154-8
   Park CW, 2020, J KOREAN MED SCI, V35, DOI 10.3346/jkms.2020.35.e379
   Qi W.H., 2017, IEEE I CONF COMP VIS
   Sari CT, 2019, IEEE T MED IMAGING, V38, P1139, DOI 10.1109/TMI.2018.2879369
   Steiner DF, 2018, AM J SURG PATHOL, V42, P1636, DOI 10.1097/PAS.0000000000001151
   Tan M., 2019, ARXIV
   Walk EE, 2009, ARCH PATHOL LAB MED, V133, P605, DOI 10.1043/1543-2165-133.4.605
   Wang YL, 2020, J EXP MED, V217, DOI 10.1084/jem.20191130
   WHO classification of tumours editorial board, 2019, TUM COL RECT WHO CLA, V5th
   Wu H, 2017, ONCOGENE, V36, P2857, DOI 10.1038/onc.2016.438
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Yoshida H, 2017, ONCOTARGET, V8, P90719, DOI 10.18632/oncotarget.21819
NR 28
TC 5
Z9 5
U1 1
U2 3
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JUL 27
PY 2022
VL 12
IS 1
AR 12804
DI 10.1038/s41598-022-16885-x
PG 8
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA 3H2RJ
UT WOS:000831887000046
PM 35896791
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Koh, FH
   Ladlad, J
   Teo, EK
   Lin, CL
   Foo, FJ
AF Koh, Frederick H.
   Ladlad, Jasmine
   Teo, Eng-Kiong
   Lin, Cui-Li
   Foo, Fung-Joon
CA SKH Endoscopy Ctr
TI Real-time artificial intelligence (AI)-aided endoscopy improves adenoma
   detection rates even in experienced endoscopists: a cohort study in
   Singapore
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
LA English
DT Article
DE Artificial intelligence; Polyp detection; Colonoscopy; Adenoma
   detection; Endoscopy
ID SOCIETY TASK-FORCE; GASTROINTESTINAL ENDOSCOPY; COLORECTAL-CANCER;
   COLONOSCOPY; RECOMMENDATIONS; SURVEILLANCE; IMPACT
AB Background: Colonoscopy is a mainstay to detect premalignant neoplastic lesions in the colon. Real-time Artificial Intelligence (AI)-aided colonoscopy purportedly improves the polyp detection rate, especially for small flat lesions. The aim of this study is to evaluate the performance of real-time AI-aided colonoscopy in the detection of colonic polyps.
   Methods: A prospective single institution cohort study was conducted in Singapore. All real-time AI-aided colonoscopies, regardless of indication, performed by specialist-grade endoscopists were anonymously recorded from July to September 2021 and reviewed by 2 independent authors (FHK, JL). Sustained detection of an area by the program was regarded as a "hit". Histology for the polypectomies were reviewed to determine adenoma detection rate (ADR). Individual endoscopist's performance with AI were compared against their baseline performance without AI endoscopy.
   Results: A total of 24 (82.8%) endoscopists participated with 18 (62.1%) performing >= 5 AI-aided colonoscopies. Of the 18, 72.2% (n = 13) were general surgeons. During that 3-months period, 487 "hits" encountered in 298 colonoscopies. Polypectomies were performed for 51.3% and 68.4% of these polypectomies were adenomas on histology. The post-intervention median ADR was 30.4% was higher than the median baseline polypectomy rate of 24.3% (p = 0.02). Of the adenomas excised, 14 (5.6%) were sessile serrated adenomas. Of those who performed >= 5 AI-aided colonoscopies, 13 (72.2%) had an improvement of ADR compared to their polypectomy rate before the introduction of AI, of which 2 of them had significant improvement.
   Conclusions Real-time AI-aided colonoscopy have the potential to improved ADR even for experienced endoscopists and would therefore, improve the quality of colonoscopy.
   [GRAPHICS]
   .
C1 [Koh, Frederick H.; Ladlad, Jasmine; Foo, Fung-Joon] Sengkang Gen Hosp, Dept Gen Surg, Colorectal Serv, SingHlth Serv, 110 Sengkang East Way, Singapore 544886, Singapore.
   [Foo, Fung-Joon; SKH Endoscopy Ctr] Sengkang Gen Hosp, Endoscopy Ctr, Div Hyperacute Care, Singapore, Singapore.
   [Teo, Eng-Kiong; Lin, Cui-Li] Sengkang Gen Hosp, Dept Gastroenterol & Hepatol, SingHlth Serv, Singapore, Singapore.
RP Koh, FH (通讯作者)，Sengkang Gen Hosp, Dept Gen Surg, Colorectal Serv, SingHlth Serv, 110 Sengkang East Way, Singapore 544886, Singapore.
EM frederickkohhx@gmail.com
CR Abu-Freha N, 2021, UNITED EUR GASTROENT, V9, P681, DOI 10.1002/ueg2.12106
   Ahmad OF, 2022, DIGEST ENDOSC, V34, P862, DOI 10.1111/den.14187
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Antonelli G, 2021, BEST PRACT RES CL GA, V52-53, DOI 10.1016/j.bpg.2020.101713
   Antonelli G, 2020, WORLD J GASTROENTERO, V26, P7436, DOI 10.3748/wjg.v26.i47.7436
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Atkin W, 2013, LANCET, V381, P1194, DOI 10.1016/S0140-6736(12)62186-2
   Azer SA, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55080473
   Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Chan DKH, 2018, SURG ENDOSC, V32, P1377, DOI 10.1007/s00464-017-5818-0
   Desai M, 2021, ENDOSC INT OPEN, V09, pE610, DOI 10.1055/a-1352-4095
   Georgiou KE, 2021, JSLS-J SOC LAPAROEND, V25, DOI 10.4293/JSLS.2021.00064
   Hassan C, 2019, ENDOSCOPY, V51, P775, DOI 10.1055/a-0959-0505
   Hassan C, 2019, ENDOSCOPY, V51, P266, DOI 10.1055/a-0831-2522
   Hill A, 2017, SURG ENDOSC, V31, P2426, DOI 10.1007/s00464-016-5243-9
   Huang D, 2022, INT J COLORECTAL DIS, V37, P495, DOI 10.1007/s00384-021-04062-x
   Jorgensen Benjamin, 2015, S D Med, VSpec No, P82
   Kahi CJ, 2016, GASTROINTEST ENDOSC, V83, P489, DOI 10.1016/j.gie.2016.01.020
   Kaltenbach T, 2020, GASTROENTEROLOGY, V158, P1095, DOI 10.1053/j.gastro.2019.12.018
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Koh FH, 2019, J GASTROINTEST ONCOL, V10, P166, DOI 10.21037/jgo.2018.11.06
   Lee J, 2021, CLCWEB-COMP LIT CULT, V23, DOI 10.1007/s11894-021-00810-9
   Menees SB, 2014, AM J GASTROENTEROL, V109, P148, DOI 10.1038/ajg.2013.243
   Milluzzo SM, 2021, CLIN ENDOSC, V54, P329, DOI 10.5946/ce.2020.082
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Sonnenberg A, 2022, DIGEST DIS SCI, V67, P4702, DOI 10.1007/s10620-021-07358-8
   Spadaccini M, 2022, FUTURE ONCOL, V18, P1405, DOI 10.2217/fon-2021-1135
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yoon JY, 2016, CLIN ENDOSC, V49, P6, DOI 10.5946/ce.2016.49.1.6
   Yoshida N, 2021, INT J COLORECTAL DIS, V36, P2237, DOI 10.1007/s00384-021-04006-5
   Zhao SB, 2021, WORLD J GASTROENTERO, V27, P5232, DOI 10.3748/wjg.v27.i31.5232
NR 34
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0930-2794
EI 1432-2218
J9 SURG ENDOSC
JI Surg. Endosc.
PD JAN
PY 2023
VL 37
IS 1
BP 165
EP 171
DI 10.1007/s00464-022-09470-w
EA JUL 2022
PG 7
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA I5TB2
UT WOS:000830262400003
PM 35882667
OA Green Published, Bronze
DA 2023-08-21
ER

PT J
AU Lin, Y
   Wu, JC
   Xiao, GB
   Guo, JW
   Chen, G
   Ma, JY
AF Lin, Yi
   Wu, Jichun
   Xiao, Guobao
   Guo, Junwen
   Chen, Geng
   Ma, Jiayi
TI BSCA-Net: Bit Slicing Context Attention network for polyp segmentation
SO PATTERN RECOGNITION
LA English
DT Article
DE Medical image segmentation; Polyp segmentation; Colonoscopy; Attention
   mechanism
AB In this paper, we propose a novel Bit-Slicing Context Attention Network (BSCA-Net), an end-to-end net-work, to improve the extraction ability of boundary information for polyp segmentation. The core of BSCA-Net is a new Bit Slice Context Attention (BSCA) module, which exploits the bit-plane slicing infor-mation to effectively extract the boundary information between polyps and the surrounding tissue. In addition, we design a novel Split-Squeeze-Bottleneck-Union (SSBU) module, to exploit the geometrical in-formation from different aspects. Also, based on SSBU, we propose an multipath concat attention decoder (MCAD) and an multipath attention concat encoder (MACE), to further improve the network performance for polyp segmentation. Finally, by combining BSCA, SSBU, MCAD and MACE, the proposed BSCA-Net is able to effectively suppress noises in feature maps, and simultaneously improve the ability of feature ex-pression in different levels, for polyp segmentation. Empirical experiments on five benchmark datasets (Kvasir, CVC-ClinicDB, ETIS, CVC-ColonDB and CVC-30 0) demonstrate the superior of the proposed BSCA-Net over existing cutting-edge methods.(c) 2022 Elsevier Ltd. All rights reserved.
C1 [Lin, Yi; Wu, Jichun; Xiao, Guobao; Guo, Junwen] Minjiang Univ, Coll Comp & Control Engn, Fujian Prov Key Lab Informat Proc & Intelligent Co, Fuzhou 350108, Peoples R China.
   [Chen, Geng] Northwestern Polytech Univ, Sch Comp Sci & Engn, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710072, Peoples R China.
   [Ma, Jiayi] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China.
C3 Minjiang University; Northwestern Polytechnical University; Wuhan
   University
RP Xiao, GB (通讯作者)，Minjiang Univ, Coll Comp & Control Engn, Fujian Prov Key Lab Informat Proc & Intelligent Co, Fuzhou 350108, Peoples R China.
EM gbx@mju.edu.cn
RI wu, ji/IAR-8520-2023; Ma, Jiayi/Y-2470-2019
OI Ma, Jiayi/0000-0003-3264-3265; Xiao, Guobao/0000-0003-2928-8100
FU National Natural Science Foundation of China [62072223]; Natural Science
   Foundation of Fujian Province [2020J01131199]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 62072223 , and supported by the Natural Science
   Foundation of Fujian Province under Grant 2020J01131199 .
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Guo XQ, 2021, IEEE T MED IMAGING, V40, P1134, DOI 10.1109/TMI.2020.3046843
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J., 2017, PROC IEEE C COMPUT V, P7132, DOI DOI 10.1109/CVPR.2018.00745
   Huang C. -H., 2021, ARXIV
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji GP, 2021, LECT NOTES COMPUT SC, V12901, P142, DOI 10.1007/978-3-030-87193-2_14
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI 10.1109/EMBC.2019.8857339
   Oulefki A, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2020.107747
   Park JH, 2018, POULTRY SCI, V97, P2854, DOI 10.3382/ps/pey151
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/crv52889.2021.00032, 10.1109/CRV52889.2021.00032]
   Rizzi M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093045
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Sang D., 2021, IMAGE VIDEO PROCESSI, P1
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Tuan TA, 2019, LECT NOTES COMPUT SC, V11384, P466, DOI 10.1007/978-3-030-11726-9_41
   Tripathi P., 2018, GASTROENTEROLOGY, V154, pS
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Yang YY, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107985
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yu Q, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107756
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhong Z, 2022, INFORM FUSION, V77, P81, DOI 10.1016/j.inffus.2021.07.018
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 46
TC 7
Z9 7
U1 4
U2 15
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD DEC
PY 2022
VL 132
AR 108917
DI 10.1016/j.patcog.2022.108917
EA JUL 2022
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5B1EK
UT WOS:000863318300001
DA 2023-08-21
ER

PT J
AU Yuan, XL
   Zhou, Y
   Liu, W
   Luo, Q
   Zeng, XH
   Yi, Z
   Hu, B
AF Yuan, Xiang-Lei
   Zhou, Yao
   Liu, Wei
   Luo, Qi
   Zeng, Xian-Hui
   Yi, Zhang
   Hu, Bing
TI Artificial intelligence for diagnosing gastric lesions under white-light
   endoscopy
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
LA English
DT Article
DE Artificial intelligence; Gastric cancer; Submucosal tumor; Polyp; Peptic
   ulcer; Erosion
ID UPPER GASTROINTESTINAL ENDOSCOPY; CANCER
AB Background The ability of endoscopists to identify gastric lesions is uneven. Even experienced endoscopists may miss or misdiagnose lesions due to heavy workload or fatigue or subtle changes in lesions under white-light endoscopy (WLE). This study aimed to develop an artificial intelligence (AI) system that could diagnose six common gastric lesions under WLE and to explore its role in assisting endoscopists in diagnosis. Methods Images of early gastric cancer, advanced gastric cancer, submucosal tumor, polyp, peptic ulcer, erosion, and lesion-free gastric mucosa were retrospectively collected to train and test the system. The performance of the system was compared with that of 12 endoscopists. The performance of endoscopists with or without referring to the system was also evaluated. Results A total of 29,809 images from 8947 patients and 1579 images from 496 patients were used to train and test the system, respectively. For per-lesion analysis, the overall accuracy of the system was 85.7%, which was comparable to that of senior endoscopists (85.1%, P = 0.729) and significantly higher than that of junior endoscopists (78.8%, P < 0.001). With system assistance, the overall accuracies of senior and junior endoscopists increased to 89.3% (4.2%, P < 0.001) and 86.2% (7.4%, P < 0.001), respectively. Senior and junior endoscopists achieved varying degrees of improvement in the diagnostic performance of other types of lesions except for polyp. The diagnostic times of senior (3.8 vs 3.2 s per image, P = 0.500) and junior endoscopists (6.2 vs 4.6 s per image, P = 0.144) assisted by the system were both slightly shortened, despite no significant differences. Conclusions The proposed AI system could be applied as an auxiliary tool to reduce the workload of endoscopists and improve the diagnostic accuracy of gastric lesions.
C1 [Yuan, Xiang-Lei; Liu, Wei; Luo, Qi; Zeng, Xian-Hui; Hu, Bing] Sichuan Univ, West China Hosp, Dept Gastroenterol, 37 Guo Xue Alley, Chengdu 610041, Sichuan, Peoples R China.
   [Zhou, Yao; Yi, Zhang] Sichuan Univ, Coll Comp Sci, Ctr Intelligent Med, 24 South Sect 1,Yihuan Rd Chengdu, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University; Sichuan University
RP Hu, B (通讯作者)，Sichuan Univ, West China Hosp, Dept Gastroenterol, 37 Guo Xue Alley, Chengdu 610041, Sichuan, Peoples R China.; Yi, Z (通讯作者)，Sichuan Univ, Coll Comp Sci, Ctr Intelligent Med, 24 South Sect 1,Yihuan Rd Chengdu, Chengdu 610065, Sichuan, Peoples R China.
EM zhangyi@scu.edu.cn; hubingnj@163.com
FU 1.3.5 project for disciplines of excellence, West China Hospital,
   Sichuan University [ZYJC21011]; National Natural Science Foundation of
   China [82170675, 62006163]; National Postdoctoral Program for Innovative
   Talents [BX20200226]; Sichuan Science and Technology Planning Project
   [2022YFSY0047]
FX 1 center dot 3 center dot 5 project for disciplines of excellence, West
   China Hospital, Sichuan University (Grant No: ZYJC21011), National
   Natural Science Foundation of China (Grant No: 82170675), National
   Natural Science Foundation of China (Grant No: 62006163), National
   Postdoctoral Program for Innovative Talents (Grant No: BX20200226), and
   Sichuan Science and Technology Planning Project (Grant No:
   2022YFSY0047).
CR Alexey Dosovitskiy LB., 2021, PROC INT C LEARN REP
   An P, 2020, GASTRIC CANCER, V23, P884, DOI 10.1007/s10120-020-01071-7
   Beg S, 2017, GUT, V66, P1886, DOI 10.1136/gutjnl-2017-314109
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   Faulx AL, 2017, GASTROINTEST ENDOSC, V85, P273, DOI 10.1016/j.gie.2016.10.036
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   Hu H, 2021, GASTROINTEST ENDOSC, V93, P1333, DOI 10.1016/j.gie.2020.11.014
   Ling TS, 2021, ENDOSCOPY, V53, P469, DOI 10.1055/a-1229-0920
   Nagao S, 2020, GASTROINTEST ENDOSC, V92, P866, DOI 10.1016/j.gie.2020.06.047
   Nam JY., 2022, GASTROINTEST ENDOSC, V95, pe210
   Pimenta-Melo AR, 2016, EUR J GASTROEN HEPAT, V28, P1041, DOI 10.1097/MEG.0000000000000657
   REDMON J, 2016, PROC CVPR IEEE, P779, DOI DOI 10.1109/CVPR.2016.91
   Tang DH, 2020, EBIOMEDICINE, V62, DOI 10.1016/j.ebiom.2020.103146
   Waki K, 2021, DIGEST ENDOSC, V33, P1101, DOI 10.1111/den.13934
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Xia J, 2021, GASTROINTEST ENDOSC, V93, P133, DOI 10.1016/j.gie.2020.05.027
   Yuan XL, 2022, J GASTROEN HEPATOL, V37, P169, DOI 10.1111/jgh.15689
   Zhang LM, 2021, DIGEST ENDOSC, V33, P788, DOI 10.1111/den.13844
   Zippelius C, 2022, ENDOSCOPY, V54, P465, DOI 10.1055/a-1556-5984
NR 22
TC 2
Z9 2
U1 3
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0930-2794
EI 1432-2218
J9 SURG ENDOSC
JI Surg. Endosc.
PD DEC
PY 2022
VL 36
IS 12
BP 9444
EP 9453
DI 10.1007/s00464-022-09420-6
EA JUL 2022
PG 10
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA 6D1PZ
UT WOS:000829724300005
PM 35879572
DA 2023-08-21
ER

PT J
AU Nemoto, D
   Guo, Z
   Peng, B
   Zhang, R
   Nakajima, Y
   Hayashi, Y
   Yamashina, T
   Aizawa, M
   Utano, K
   Lefor, AK
   Zhu, X
   Togashi, K
AF Nemoto, Daiki
   Guo, Zhe
   Peng, Boyuan
   Zhang, Ruiyao
   Nakajima, Yuki
   Hayashi, Yoshikazu
   Yamashina, Takeshi
   Aizawa, Masato
   Utano, Kenichi
   Lefor, Alan Kawarai
   Zhu, Xin
   Togashi, Kazutomo
TI Computer-aided diagnosis of serrated colorectal lesions using
   non-magnified white-light endoscopic images
SO INTERNATIONAL JOURNAL OF COLORECTAL DISEASE
LA English
DT Article
DE Colonoscopy; Colonic polyps; Artificial intelligence; Serrated lesion
ID CLASSIFICATION; SYSTEM
AB Purpose Computer-aided diagnosis systems for polyp characterization are commercially available but cannot recognize subtypes of sessile lesions. This study aimed to develop a computer-aided diagnosis system to characterize polyps using non-magnified white-light endoscopic images. Methods A total of 2249 non-magnified white-light images from 1030 lesions including 534 tubular adenomas, 225 sessile serrated adenoma/polyps, and 271 hyperplastic polyps in the proximal colon were consecutively extracted from an image library and divided into training and testing datasets (4:1), based on the date of colonoscopy. Using ResNet-50 networks, we developed a classifier (1) to differentiate adenomas from serrated lesions, and another classifier (2) to differentiate sessile serrated adenoma/polyps from hyperplastic polyps. Diagnostic performance was assessed using the testing dataset. The computer-aided diagnosis system generated a probability score for each image, and a probability score for each lesion was calculated as the weighted mean with a log(10)-transformation. Two experts (E1, E2) read the identical testing dataset with a probability score. Results The area under the curve of classifier (1) for adenomas was equivalent to E1 and superior to E2 (classifier 86%, E1 86%, E2 69%; classifier vs. E2, p < 0.001). In contrast, the area under the curve of classifier (2) for sessile serrated adenoma/polyps was inferior to both experts (classifier 55%, E1 68%, E2 79%; classifier vs. E2, p < 0.001). Conclusion The classifier (1) developed using white-light images alone compares favorably with experts in differentiating adenomas from serrated lesions. However, the classifier (2) to identify sessile serrated adenoma/polyps is inferior to experts.
C1 [Nemoto, Daiki; Nakajima, Yuki; Aizawa, Masato; Utano, Kenichi; Togashi, Kazutomo] Fukushima Med Univ, Aizu Med Ctr, Dept Coloproctol & Gastroenterol, 21-2 Maeda, Aizu Wakamatsu, Fukushima 9693492, Japan.
   [Guo, Zhe; Peng, Boyuan; Zhang, Ruiyao; Zhu, Xin] Univ Aizu, Biomed Informat Engn Lab, Aizu Wakamatsu, Fukushima, Japan.
   [Hayashi, Yoshikazu] Jichi Med Univ, Dept Med, Div Gastroenterol, Shimotsuke, Tochigi, Japan.
   [Yamashina, Takeshi] Kansai Med Univ, Gastroenterol & Hepatol, Med Ctr, Moriguchi, Osaka, Japan.
   [Lefor, Alan Kawarai] Jichi Med Univ, Dept Surg, Shimotsuke, Tochigi, Japan.
C3 University of Aizu; Jichi Medical University; Kansai Medical University;
   Jichi Medical University
RP Togashi, K (通讯作者)，Fukushima Med Univ, Aizu Med Ctr, Dept Coloproctol & Gastroenterol, 21-2 Maeda, Aizu Wakamatsu, Fukushima 9693492, Japan.
EM togashik@fmu.ac.jp
RI Guo, Zhe/AAD-4026-2021
OI Guo, Zhe/0000-0001-6657-4793
CR [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Bettington M, 2013, HISTOPATHOLOGY, V62, P367, DOI 10.1111/his.12055
   Bosman FT., 2010, WHO CLASSIFICATION T, P160
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Collins GS, 2015, J CLIN EPIDEMIOL, V68, P112, DOI [10.7326/M14-0697, 10.1002/bjs.9736, 10.7326/M14-0698, 10.1016/j.jclinepi.2014.11.010, 10.1186/s12916-014-0241-z, 10.1136/bmj.g7594, 10.1016/j.eururo.2014.11.025, 10.1038/bjc.2014.639]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Glover B, 2019, J CLIN GASTROENTEROL, V53, P495, DOI 10.1097/MCG.0000000000001222
   GUO Z, 2020, I S BIOMED IMAGING
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   I JESPEERT JE B, 2016, GUT, V65, P963
   Ignjatovic A, 2011, ENDOSCOPY, V43, P94, DOI 10.1055/s-0030-1256074
   Kashida H, 2019, DIGEST ENDOSC, V31, P16, DOI 10.1111/den.13263
   Kobayashi S, 2019, UNITED EUR GASTROENT, V7, P914, DOI 10.1177/2050640619845987
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Pai RK., 2019, WHO CLASSIFICATION T, P163
   Parikh ND, 2016, ENDOSCOPY, V48, P731, DOI 10.1055/s-0042-107592
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Rosty C, 2013, J GASTROENTEROL, V48, P287, DOI 10.1007/s00535-012-0720-y
   Togashi K, 2016, THER ADV GASTROENTER, V9, P50, DOI 10.1177/1756283X15603614
   Vennelaganti S, 2021, GASTROENTEROLOGY, V160, P452, DOI 10.1053/j.gastro.2020.09.015
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhou DJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16777-6
NR 25
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0179-1958
EI 1432-1262
J9 INT J COLORECTAL DIS
JI Int. J. Colorectal Dis.
PD AUG
PY 2022
VL 37
IS 8
BP 1875
EP 1884
DI 10.1007/s00384-022-04210-x
EA JUL 2022
PG 10
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 3W2QB
UT WOS:000828434500001
PM 35861862
OA Green Submitted
DA 2023-08-21
ER

PT J
AU Yu, T
   Lin, N
   Zhang, X
   Pan, YQ
   Hu, HY
   Zheng, WF
   Liu, JQ
   Hu, WL
   Duan, HL
   Si, JM
AF Yu, Tao
   Lin, Ne
   Zhang, Xu
   Pan, Yanqi
   Hu, Huiyi
   Zheng, Wenfang
   Liu, Jiquan
   Hu, Weiling
   Duan, Huilong
   Si, Jianmin
TI An end-to-end tracking method for polyp detectors in colonoscopy videos
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Computer aided diagnosis; Endoscopy; Neural networks; Detection;
   Tracking
ID COLORECTAL-CANCER INCIDENCE; DIAGNOSIS; STAGE
AB Deep learning based computer-aided diagnosis technology demonstrates an encouraging performance in aspect of polyp lesion detection on reducing the miss rate of polyps during colonoscopies. However, to date, few studies have been conducted for tracking polyps that have been detected in colonoscopy videos, which is an essential and intuitive issue in clinical intelligent video analysis task (e.g. lesion counting, lesion retrieval, report generation). In the paradigm of conventional tracking-by-detection system, detection task for lesion localization is separated from the tracking task for cropped lesions re-identification. In the multi object tracking problem, each target is supposed to be tracked by invoking a tracker after the detector, which introduces multiple inferences and leads to external resource and time consumption. To tackle these problems, we proposed a plug-in module named instance tracking head (ITH) for synchronous polyp detection and tracking, which can be simply inserted into object detection frameworks. It embeds a feature-based polyp tracking procedure into the detector frameworks to achieve multi-task model training. ITH and detection head share the model backbone for low level feature extraction, and then low level feature flows into the separate branches for task-driven model training. For feature maps from the same receptive field, the region of interest head assigns these features to the detection head and the ITH, respectively, and outputs the object category, bounding box coordinates, and instance feature embedding simultaneously for each specific polyp target. We also proposed a method based on similarity metric learning. The method makes full use of the prior boxes in the object detector to provide richer and denser instance training pairs, to improve the performance of the model evaluation on the tracking task. Compared with advanced tracking-by-detection paradigm methods, detectors with proposed ITH can obtain comparative tracking performance but approximate 30% faster speed. Optimized model based on Scaled-YOLOv4 detector with ITH illustrates good trade-off between detection (mAP 91.70%) and tracking (MOTA 92.50% and Rank-1 Acc 88.31%) task at the frame rate of 66 FPS. The proposed structure demonstrates the potential to aid clinicians in real-time detection with online tracking or offline retargeting of polyp instances during colonoscopies.
C1 [Yu, Tao; Zhang, Xu; Pan, Yanqi; Hu, Huiyi; Liu, Jiquan; Duan, Huilong] Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou, Peoples R China.
   [Lin, Ne; Zheng, Wenfang; Hu, Weiling; Si, Jianmin] Zhejiang Univ, Sir Run Run Shaw Hosp, Med Sch, Dept Gastroenterol, Hangzhou, Peoples R China.
   [Lin, Ne; Zheng, Wenfang; Hu, Weiling; Si, Jianmin] Zhejiang Univ, Inst Gastroenterol, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University
RP Liu, JQ (通讯作者)，Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou, Peoples R China.; Hu, WL (通讯作者)，Zhejiang Univ, Sir Run Run Shaw Hosp, Med Sch, Dept Gastroenterol, Hangzhou, Peoples R China.; Hu, WL (通讯作者)，Zhejiang Univ, Inst Gastroenterol, Hangzhou, Peoples R China.
EM liujq@zju.edu.cn; huweiling@zju.edu.cn
OI Yu, Tao/0000-0001-9617-7465
FU National Natural Science Foundation of China [81827804]; Zhejiang
   Province Key Research and Development Program [2021C03111]
FX Acknowledgments This work was supported in part by the National Natural
   Science Foundation of China (No. 81827804) and the Zhejiang Province Key
   Research and Development Program (No. 2021C03111 Demonstration of
   innovative medical device application based on new service model of
   medical community) .
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   ALDAZ AD, 1994, EUR J CANCER, V30A, P860, DOI 10.1016/0959-8049(94)90306-9
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Amber A, 2015, 3RD INTERNATIONAL CONFERENCE ON APPLIED COMPUTING AND INFORMATION TECHNOLOGY (ACIT 2015) 2ND INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND INTELLIGENCE (CSI 2015), P299, DOI 10.1109/ACIT-CSI.2015.60
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Angermann Q, REAL TIME POLYP DETE, P29
   [Anonymous], 2010, K MEANS CLUSTERING, DOI [DOI 10.1007/978-0-387-30164-8425, 10.1007/978-0-387-30164-8_425]
   [Anonymous], 2021, ACG CLIN GUIDELINES, P116
   Bergmann P, 2019, ARXIV
   Bernal J, 2018, P 32 CARS C, V13, pS166
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bochkovskiy A., 2020, ARXIV E PRINTS, V2004, P10934, DOI 10.48550/arXiv.2004.10934
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cress RD, 2006, CANCER, V107, P1142, DOI 10.1002/cncr.22011
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Ge Z., 2021, YOLOX EXCEEDING YOLO, V2107, P08430, DOI 10.48550/arXiv.2107.08430
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Glorot X., 2010, PROC 13 INT C ARTIFI, V9, P249, DOI DOI 10.1177/1753193409103364.
   Guizard N, 2019, GASTROENTEROLOGY, V156, pS48
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S., 2015, PROC INT C MACH LEAR, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   LI W, 2011, SPIE, V7963, P758, DOI DOI 10.1117/12.877879
   Li XH, 2014, IEEE T GEOSCI REMOTE, V52, P7086, DOI 10.1109/TGRS.2014.2307354
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu MZ, 2011, LECT NOTES COMPUT SC, V6893, P41, DOI 10.1007/978-3-642-23626-6_6
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Moyer VA, 2014, ANN INTERN MED, V160, P330, DOI 10.7326/M13-2771
   Neumann B., 1984, Computer Graphics, V18, P17, DOI 10.1145/988525.988528
   Pang J, 2020, ARXIV
   PARK SY, 2016, SPIE, V9785, P577, DOI DOI 10.1117/12.2217148
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saito Y, 2021, DIGEST ENDOSC, V33, P486, DOI 10.1111/den.13972
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Siegel RL, 2012, CANCER EPIDEM BIOMAR, V21, P411, DOI 10.1158/1055-9965.EPI-11-1020
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sung JJY, 2015, GUT, V64, P121, DOI 10.1136/gutjnl-2013-306503
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Talbot R, 2010, LANCET, V376, P330, DOI 10.1016/S0140-6736(10)61182-8
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang C-Y, 2020, ARXIV
   Wang C-Y, 2019, ARXIV
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhang PF, 2019, PROC INT C TOOLS ART, P1252, DOI 10.1109/ICTAI.2019.00-93
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang Y., ARXIV
   Zheng H, 2019, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2019.8759180
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 64
TC 1
Z9 1
U1 7
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD SEP
PY 2022
VL 131
AR 102363
DI 10.1016/j.artmed.2022.102363
EA JUL 2022
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA 3P1AI
UT WOS:000837271400004
PM 36100343
DA 2023-08-21
ER

PT J
AU Li, WS
   Zhao, YH
   Li, FY
   Wang, LH
AF Li, Weisheng
   Zhao, Yinghui
   Li, Feiyan
   Wang, Linhong
TI MIA-Net: Multi-information aggregation network combining transformers
   and convolutional feature learning for polyp segmentation
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Colonoscopy; Multi-information aggregation; Polyp segmentation;
   Transformer
AB Accurate polyp segmentation is of immense importance for the early diagnosis and treatment of colorectal cancer. However, polyp segmentation is a difficult task, and most current methods suffer from two challenges. First, individual polyps widely vary in shape, size, and location (intra-class inconsistency). Second, subject to conditions such as motion blur and light reflection, polyps and their surrounding background have a high degree of similarity (inter-class indistinction). To overcome intra-class inconsistency and inter-class indistinction, we propose a multi-information aggregation network (MIA-Net) combining transformer and convolutional features. We use the transformer encoder to extract powerful global features and better localize polyps with an advanced global contextual feature extraction module. This approach reduces the influence of intra-class inconsistency. In addition, we capture fine-grained local texture features using the convolutional encoder and aggregate them with high-level and low-level information extracted by the transformer. This rich feature information makes the model more sensitive to edge information and alleviates inter-class indistinction. We evaluated the new approach quantitatively and qualitatively on five datasets using six metrics. The experimental results revealed that MIA-Net has good fitting ability and strong generalization ability. In addition, MIA-Net significantly improved the accuracy of polyp segmentation and outperformed the current state-of-the-art algorithms. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Li, Weisheng; Zhao, Yinghui; Li, Feiyan; Wang, Linhong] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Li, WS (通讯作者)，Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing, Peoples R China.
EM liws@cqupt.edu.cn
RI zhao, ying/ISA-2502-2023
FU National Key Research and Development Program of China [2019YFE0110800];
   National Natural Science Foundation of China [61972060, 62027827];
   Natural Science Foundation of Chongqing [cstc2020jcyj-zdxmX0025,
   cstc2019cxcyljrc-td0270]
FX This work was supported by the National Key Research and Development
   Program of China (No. 2019YFE0110800), National Natural Science
   Foundation of China [Nos. 61972060 and 62027827], and Natural Science
   Foundation of Chongqing [cstc2020jcyj-zdxmX0025,
   cstc2019cxcyljrc-td0270].
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bhojanapalli S, 2021, Arxiv, DOI arXiv:2103.14586
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Chu X., 2021, P INT C NEUR INF PRO, P9355, DOI DOI 10.48550/ARXIV.2104.13840
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B, 2022, Arxiv, DOI arXiv:2108.06932
   Dong XY, 2022, Arxiv, DOI [arXiv:2107.00652, 10.48550/arXiv.2107.00652]
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan DP, 2018, Arxiv, DOI arXiv:1805.10421
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gao CL, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2021.106754
   Granados-Romero JJ, 2017, INT J RES MED SCI, V5, P4667, DOI [10.18203/2320-6012.ijrms20174914, DOI 10.18203/2320-6012.IJRMS20174914]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C.-H., 2021, ARXIV
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu Z, 2021, Arxiv, DOI [arXiv:2103.14030, DOI 10.48550/ARXIV.2103.14030]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Rawla P, 2019, GASTROENTEROL REV, V14, P89, DOI 10.5114/pg.2018.81072
   Ronneberger O., 2015, P INT C MED IM COMP, P234, DOI [10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Nguyen TC, 2021, LECT NOTES COMPUT SC, V12901, P633, DOI 10.1007/978-3-030-87193-2_60
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang WH, 2023, Arxiv, DOI arXiv:2106.13797
   Wang WH, 2021, Arxiv, DOI arXiv:2102.12122
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu YH, 2022, Arxiv, DOI arXiv:2106.12011
   Xie E, 2021, ARXIV
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang Q., 2021, REST EFFICIENT TRANS
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 46
TC 7
Z9 7
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD JUL 8
PY 2022
VL 247
AR 108824
DI 10.1016/j.knosys.2022.108824
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8B0AM
UT WOS:000916595600012
DA 2023-08-21
ER

PT J
AU Hu, KL
   Zhao, LP
   Feng, S
   Zhang, SD
   Zhou, QW
   Gao, XZ
   Guo, YH
AF Hu, Keli
   Zhao, Liping
   Feng, Sheng
   Zhang, Shengdong
   Zhou, Qianwei
   Gao, Xiaozhi
   Guo, Yanhui
TI Colorectal polyp region extraction using saliency detection network with
   neutrosophic enhancement
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Colorectal polyp; Polyp recognition; Polyp segmentation; Saliency
   detection; Short connection
ID COMPUTER-AIDED DIAGNOSIS; SEGMENTATION; VALIDATION; ALGORITHM; CANCERS;
   SETS
AB Colorectal polyp recognition is crucial for early colorectal cancer detection and treatment. Colonoscopy is always employed for colorectal polyp scanning. However, one out of four polyps may be ignored, due to the similarity of polyp and normal tissue. In this paper, we present a novel method called NeutSS-PLP for polyp region extraction in colonoscopy images using a short connected saliency detection network with neutrosophic enhancement. We first utilize the neutrosophic theory to enhance the quality of specular reflections detection in the colonoscopy images. We develop the local and global threshold criteria in the single-valued neutrosophic set (SVNS) domain and define the corresponding T (Truth), I (Indeterminacy), and F (Falsity) functions for each criterion. The well-built neutrosophic images are processed and employed for specular reflection detection and suppressing. Next, we introduce two-level short connections into the saliency detection network, aiming to take advantage of the multi-level and multi-scale features extracted from different stages of the network. Experimental results conducted on two public colorectal polyp datasets achieve 0.877 and 0.9135 mIoU for polyp extraction respectively, and our method performs better compared with several state-of-the-art saliency networks and semantic segmentation networks, which demonstrate the effectiveness of applying the saliency detection mechanism for colorectal polyp region extraction.
C1 [Hu, Keli] Hangzhou Med Coll, Dept Gastroenterol, Zhejiang Prov Peoples Hosp, Affiliated Peoples Hosp,Canc Ctr, Hangzhou 310014, Peoples R China.
   [Hu, Keli; Zhao, Liping; Feng, Sheng; Zhang, Shengdong] Shaoxing Univ, Dept Comp Sci & Engn, Shaoxing 312000, Peoples R China.
   [Zhou, Qianwei] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
   [Gao, Xiaozhi] Univ Eastern Finland, Joensuu 80101, Finland.
   [Guo, Yanhui] Univ Illinois, One Univ Plaza, Springfield, IL 62703 USA.
C3 Hangzhou Medical College; Zhejiang Provincial People's Hospital;
   Shaoxing University; Zhejiang University of Technology; University of
   Eastern Finland; University of Illinois System; University of Illinois
   Springfield
RP Hu, KL (通讯作者)，Hangzhou Med Coll, Dept Gastroenterol, Zhejiang Prov Peoples Hosp, Affiliated Peoples Hosp,Canc Ctr, Hangzhou 310014, Peoples R China.; Zhou, QW (通讯作者)，Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
EM ancimoon@gmail.com; zqw@zjut.edu.cn
RI Zhou, Qianwei/B-5636-2019
OI Zhou, Qianwei/0000-0002-1322-7293; Hu, Keli/0000-0002-5628-7640
FU Zhejiang Provincial Natural Science Foundation of China [LTY22F020003,
   LY19F020015, LY20F020011]; Social Sciences and Humanities Youth
   Foundation of Ministry of Education [21YJCZH039]; National Natural
   Science Foundation of China [61603258, 61871289, 61802347, 62002227];
   Key scientific research project of Shaoxing University [2020LG1004]
FX This work was supported in part by the Zhejiang Provincial Natural
   Science Foundation of China under Grant LY20F020011, the Social Sciences
   and Humanities Youth Foundation of Ministry of Education under Grant
   21YJCZH039, the Zhejiang Provincial Natural Science Foundation of China
   under Grant LTY22F020003, LY19F020015, the National Natural Science
   Foundation of China under Grant 61603258, 61871289, 61802347, 62002227,
   and in part by the Key scientific research project of Shaoxing
   University under Grant 2020LG1004.
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Alsaleh SM, 2015, IEEE ENG MED BIO, P675, DOI 10.1109/EMBC.2015.7318452
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bhat S, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107307
   Cui WH, 2020, SOFT COMPUT, V24, P18521, DOI 10.1007/s00500-020-05089-y
   Cui WH, 2019, COMPUT IND, V111, P198, DOI 10.1016/j.compind.2019.06.008
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dhar S, 2021, APPL SOFT COMPUT, V112, DOI 10.1016/j.asoc.2021.107759
   Fan CX, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719843059
   Fang YQ, 2021, IEEE SENS J, V21, P11799, DOI 10.1109/JSEN.2020.3015831
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Hu KL, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060832
   Hu KL, 2017, J INTELL FUZZY SYST, V32, P1775, DOI 10.3233/JIFS-152381
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Khalifa NEM, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09802-9
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Li Q, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105488
   Liang-Chieh Chen, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11211), P833, DOI 10.1007/978-3-030-01234-2_49
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   Peng XD, 2020, ARTIF INTELL REV, V53, P199, DOI 10.1007/s10462-018-9652-0
   Rashno A, 2018, IEEE T BIO-MED ENG, V65, P989, DOI 10.1109/TBME.2017.2734058
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Sasmal P, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3082315
   Sharma M, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.107058
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Smarandache F., 1998, NEUTROSOPHY NEUTROSO
   Song SS, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.3026973
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tang SY, 2021, J SUPERCOMPUT, V77, P3870, DOI 10.1007/s11227-020-03422-8
   Ullah I, 2020, MULTIMED TOOLS APPL, V79, P34605, DOI 10.1007/s11042-020-08849-y
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Ye J, 2014, INT J FUZZY SYST, V16, P204
   Ye J, 2013, INT J GEN SYST, V42, P386, DOI 10.1080/03081079.2012.761609
   Yuan YX, 2018, LECT NOTES COMPUT SC, V11071, P620, DOI 10.1007/978-3-030-00934-2_69
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Yuan YH, 2021, INT J COMPUT VISION, V129, P2375, DOI 10.1007/s11263-021-01465-9
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang S., 2021, IEEE T CYBERNETICS
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhou H., 2020, P IEEE CVF C COMP VI, P9141, DOI DOI 10.1109/CVPR42600.2020.00916
NR 58
TC 73
Z9 74
U1 23
U2 27
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD AUG
PY 2022
VL 147
AR 105760
DI 10.1016/j.compbiomed.2022.105760
EA JUL 2022
PG 13
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 4Y5LP
UT WOS:000861569700004
PM 35803078
HC Y
HP Y
DA 2023-08-21
ER

PT J
AU Han, JB
   Xu, C
   An, ZH
   Qian, K
   Tan, W
   Wang, D
   Fang, QQ
AF Han, Jubao
   Xu, Chao
   An, Ziheng
   Qian, Kai
   Tan, Wei
   Wang, Dou
   Fang, Qianqian
TI PRAPNet: A Parallel Residual Atrous Pyramid Network for Polyp
   Segmentation
SO SENSORS
LA English
DT Article
DE medical image analysis; semantic segmentation; colonoscopy; polyp
   segmentation; deep learning; health informatics
ID COLORECTAL-CANCER; U-NET; PREVENTION; ENDOSCOPY
AB In a colonoscopy, accurate computer-aided polyp detection and segmentation can help endoscopists to remove abnormal tissue. This reduces the chance of polyps developing into cancer, which is of great importance. In this paper, we propose a neural network (parallel residual atrous pyramid network or PRAPNet) based on a parallel residual atrous pyramid module for the segmentation of intestinal polyp detection. We made full use of the global contextual information of the different regions by the proposed parallel residual atrous pyramid module. The experimental results showed that our proposed global prior module could effectively achieve better segmentation results in the intestinal polyp segmentation task compared with the previously published results. The mean intersection over union and dice coefficient of the model in the Kvasir-SEG dataset were 90.4% and 94.2%, respectively. The experimental results outperformed the scores achieved by the seven classical segmentation network models (U-Net, U-Net++, ResUNet++, praNet, CaraNet, SFFormer-L, TransFuse-L).
C1 [Han, Jubao; Xu, Chao; An, Ziheng; Qian, Kai; Tan, Wei; Wang, Dou; Fang, Qianqian] Anhui Univ, Sch Integrated Circuits, Hefei 230601, Peoples R China.
   [Han, Jubao; Xu, Chao; An, Ziheng; Qian, Kai; Tan, Wei; Wang, Dou; Fang, Qianqian] Anhui Engn Lab Agroecol Big Data, Hefei 230601, Peoples R China.
C3 Anhui University
RP Xu, C (通讯作者)，Anhui Univ, Sch Integrated Circuits, Hefei 230601, Peoples R China.; Xu, C (通讯作者)，Anhui Engn Lab Agroecol Big Data, Hefei 230601, Peoples R China.
EM p20201029@stu.ahu.edu.cn; xchao@ahu.edu.cn; p20301227@stu.ahu.edu.cn;
   p20201085@stu.ahu.edu.cn; p20301226@stu.ahu.edu.cn;
   p20301228@stu.ahu.edu.cn; p20201087@stu.ahu.edu.cn
FU National Key Research and Development Program of China [2019YFC0117800]
FX This research was funded by the National Key Research and Development
   Program of China (No. 2019YFC0117800).
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   [Anonymous], 2014, CORR
   Branch M., 2021, ARXIV
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Dung CV, 2019, AUTOMAT CONSTR, V99, P52, DOI 10.1016/j.autcon.2018.11.028
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   Han Y, 2018, IEEE T MED IMAGING, V37, P1418, DOI 10.1109/TMI.2018.2823768
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Kiesslich R, 2004, GASTROENTEROLOGY, V127, P706, DOI 10.1053/j.gastro.2004.06.050
   Lafferty J., 2001, P INT C MACH LEARN, P282
   Lou A., 2021, ARXIV
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Saood A, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-020-00529-5
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vaswani A., 2017, PROC 31 INT C NEURAL, V30, DOI DOI 10.5555/3295222.3295349
   Wang J., 2022, ARXIV
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Xu T., 2020, P 2020 IEEE 17 INT S
   Yu F., 2016, P 4 INT C LEARN REP, DOI 10.48550/arXiv.1511.07122Focustolearnmore
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 37
TC 0
Z9 0
U1 9
U2 35
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD JUL
PY 2022
VL 22
IS 13
AR 4658
DI 10.3390/s22134658
PG 12
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA 2T1JQ
UT WOS:000822237300001
PM 35808154
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Liu, XY
   Yuan, YX
AF Liu, Xinyu
   Yuan, Yixuan
TI A Source-Free Domain Adaptive Polyp Detection Framework With Style
   Diversification Flow
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Adaptation models; Detectors; Data models; Task analysis; Training;
   Cancer; Object detection; Automatic polyp detection; self-distillation;
   style diversification; source-free domain adaptation
ID CAPSULE ENDOSCOPY
AB The automatic detection of polyps across colonoscopy and Wireless Capsule Endoscopy (WCE) datasets is crucial for early diagnosis and curation of colorectal cancer. Existing deep learning approaches either require mass training data collected from multiple sites or use unsupervised domain adaptation (UDA) technique with labeled source data. However, these methods are not applicable when the data is not accessible due to privacy concerns or data storage limitations. Aiming to achieve source-free domain adaptive polyp detection, we propose a consistency based model that utilizes Source Model as Proxy Teacher (SMPT) with only a transferable pretrained model and unlabeled target data. SMPT first transfers the stored domain-invariant knowledge in the pretrained source model to the target model via Source Knowledge Distillation (SKD), then uses Proxy Teacher Rectification (PTR) to rectify the source model with temporal ensemble of the target model. Moreover, to alleviate the biased knowledge caused by domain gaps, we propose Uncertainty-Guided Online Bootstrapping (UGOB) to adaptively assign weights for each target image regarding their uncertainty. In addition, we design Source Style Diversification Flow (SSDF) that gradually generates diverse style images and relaxes style-sensitive channels based on source and target information to enhance the robustness of the model towards style variation. The capacities of SMPT and SSDF are further boosted with iterative optimization, constructing a stronger framework SMPT++ for cross-domain polyp detection. Extensive experiments are conducted on five distinct polyp datasets under two types of cross-domain settings. Our proposed method shows the state-of-the-art performance and even outperforms previous UDA approaches that require the source data by a large margin. The source code is available at github.com/CityU-AIM-Group/SFPolypDA.
C1 [Liu, Xinyu; Yuan, Yixuan] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Yuan, YX (通讯作者)，City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM xliu423-c@my.cityu.edu.hk; yxyuan.ee@cityu.edu.hk
OI Yuan, Yixuan/0000-0002-0853-6948; Liu, Xinyu/0000-0002-5180-6958
FU Hong Kong Research Grants Council (RGC) General Research Fund [11211221
   (CityU 9043152)]; Hong Kong RGC Collaborative Research Fund [C4063-18G
   (CityU 8739029)]
FX This work was supported in part by the Hong Kong Research Grants Council
   (RGC) General Research Fund under Grant 11211221 (CityU 9043152) and in
   part by the Hong Kong RGC Collaborative Research Fund under Grant
   C4063-18G (CityU 8739029).
CR Bernal J., 2021, COMPUTER AIDED ANAL
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chang-Dong Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11721, DOI 10.1109/CVPR42600.2020.01174
   Chen T., 2020, ARXIV200610029, V33, P22243, DOI DOI 10.48550/ARXIV.2006.10029
   Chen YH, 2021, INT J COMPUT VISION, V129, P2223, DOI 10.1007/s11263-021-01447-x
   Cheng-Chun Hsu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P733, DOI 10.1007/978-3-030-58545-7_42
   D'Innocente Antonio, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P732, DOI 10.1007/978-3-030-58517-4_43
   Edwards BK, 2010, CANCER-AM CANCER SOC, V116, P544, DOI 10.1002/cncr.24760
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ganlong Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P86, DOI 10.1007/978-3-030-58523-5_6
   Gerber J, 2007, GASTROINTEST ENDOSC, V66, P1188, DOI 10.1016/j.gie.2007.06.003
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZW, 2019, IEEE I CONF COMP VIS, P6667, DOI 10.1109/ICCV.2019.00677
   Holleran G, 2014, ENDOSCOPY, V46, P473, DOI 10.1055/s-0034-1365402
   Hongxu Yin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8712, DOI 10.1109/CVPR42600.2020.00874
   Hsu HK, 2020, IEEE WINT CONF APPL, P738, DOI 10.1109/WACV45572.2020.9093358
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Jun-Yan Zhu, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2242, DOI 10.1109/ICCV.2017.244
   Kim S, 2019, IEEE I CONF COMP VIS, P6091, DOI 10.1109/ICCV.2019.00619
   Kim T, 2019, PROC CVPR IEEE, P12448, DOI 10.1109/CVPR.2019.01274
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kurmi VK, 2021, IEEE WINT CONF APPL, P615, DOI 10.1109/WACV48630.2021.00066
   Li XF, 2021, AAAI CONF ARTIF INTE, V35, P8474
   Liang J., 2020, PROC INT C MACH LEAR, P6028
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102052
   LIU YC, 2021, ARXIV210209480
   Ren S., 2015, ANN C NEUR INF PROC, P91
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Rodriguez A. L., 2019, PROC BRIT MACH VIS C
   RoyChowdhury A, 2019, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2019.00087
   Saito K, 2019, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR.2019.00712
   Shen Z., 2019, ARXIV191102559
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sohn K., 2020, ADV NEURAL INFORM PR, V33, P596, DOI DOI 10.5555/3495724.3495775
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tao C., 2021, PROC NEURIPS, P1
   Tarvainen A., 2017, ARXIV170301780, DOI DOI 10.1137/0330046
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Hoang TH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2578, DOI 10.1145/3343031.3356073
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wei DM, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278040
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Yang YC, 2020, PROC CVPR IEEE, P4084, DOI 10.1109/CVPR42600.2020.00414
   Yeh HW, 2021, IEEE WINT CONF APPL, P474, DOI 10.1109/WACV48630.2021.00052
   Yuan YX, 2015, IEEE INT CONF ROBOT, P1310, DOI 10.1109/ICRA.2015.7139360
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 55
TC 1
Z9 1
U1 3
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD JUL
PY 2022
VL 41
IS 7
BP 1897
EP 1908
DI 10.1109/TMI.2022.3150435
PG 12
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA 2P6EL
UT WOS:000819831700025
PM 35139013
DA 2023-08-21
ER

PT J
AU Su, YZ
   Cheng, J
   Yi, MR
   Liu, HJ
AF Su, Yanzhou
   Cheng, Jian
   Yi, Murong
   Liu, Haijun
TI FAPN: Feature Augmented Pyramid Network for polyp segmentation
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Deeplearning; Polypsegmentation; Crossembedding; Predictivecalibration;
   Hierarchicalfeaturefusion
ID VALIDATION; IMAGES
AB Accurate polyp segmentation during colonoscopy examinations can help the clinicians accurately locate polyp areas for further diagnosis or surgeries and thereby decrease the chances of polyps growing into cancer. Although existing approaches can achieve significant improvement by multi-scale feature learning, attention/contextual augmentation, and deep supervision, polyp segmentation is still far from being solved. Actually, enhancing the capability of feature representation may be an excellent way to improve the polyp segmentation performance. From this perspective, we propose a simple but strong framework over feature pyramid network (FPN), called Feature Augmented Pyramid Networks (FAPN), for accurate polyp segmentation with augmented feature representation. Specifically, FAPN consists of three components: Cross-Embedding Module (CEM), Predictive Calibration Module (PCM), and Hierarchical Feature Fusion Module (HFFM). CEM is a two-stage fusion approach that first performs an interactive embedding of multi-level features followed by a second fusion, thus enhancing the fused feature representation. After fusing, PCM leverages the predicted probability maps of each stage (after supervised optimization) to calibrate the fused feature representations, which effectively highlights the regions of interest while avoiding the interference of irrelevant information. Finally, HFFM sequentially combines features from each stage in the top-down pathway, yielding a more robust multi-scale feature representation that allows the framework to segment polyps more accurately. Extensive experiments demonstrate that the proposed network performs favorably against more than a dozen of state-of-the-art methods on five popular polyp segmentation benchmarks.
C1 [Su, Yanzhou; Cheng, Jian; Yi, Murong] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Sichuan, Peoples R China.
   [Liu, Haijun] Chongqing Univ, Sch Microelect & Commun Engn, Chongqing 400044, Peoples R China.
C3 University of Electronic Science & Technology of China; Chongqing
   University
RP Cheng, J (通讯作者)，Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Sichuan, Peoples R China.
EM chengjian@uestc.edu.cn
OI Su, Yanzhou/0000-0002-3377-469X
FU National Natural Science Foundation of China [62071104, 62001063];
   Sichuan Science and Technology Program [2021YFG0328, U2133211]; China
   Postdoctoral Science Foundation [2020M673135]; Chongqing Postdoctoral
   Research Program [XmT2020050]
FX This research was partly supported by the National Natural Science
   Foundation of China (No. 62071104, No. 62001063) , partly supported by
   the Sichuan Science and Technology Program (No. 2021YFG0328) , partly
   supported by the NSFC&CAAC (No. U2133211) , partly supported by the
   China Postdoctoral Science Foundation (No. 2020M673135) , and partly
   supported by the Chongqing Postdoctoral Research Program (No.
   XmT2020050) .
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fang YQ, 2021, IEEE SENS J, V21, P11799, DOI 10.1109/JSEN.2020.3015831
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gkioxari G., 2017, P IEEE INT C COMP VI, P2961, DOI DOI 10.1109/ICCV.2017.322
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K, 2016, DEEP RESIDUAL LEARNI
   Huang C.H., 2021, ARXIV PREPRINT ARXIV
   Huang ZL, 2022, IEEE T PATTERN ANAL, V44, P550, DOI 10.1109/TPAMI.2021.3062772
   Huang ZL, 2023, IEEE T PATTERN ANAL, V45, P6896, DOI 10.1109/TPAMI.2020.3007032
   Huynh L.D., 2020, CEUR WORKSHOP PROC, V2595, P13
   Jha D., IEEE J BIOMED HLTH I
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji GP, 2021, LECT NOTES COMPUT SC, V12901, P142, DOI 10.1007/978-3-030-87193-2_14
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Li S., 2021, IJCAI
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Lou A., 2021, ARXIV PREPRINT ARXIV
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Miao H, 2019, IEEE IJCNN
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ronneberger O, 2015, 161207003 ARXIV
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Nguyen TC, 2021, LECT NOTES COMPUT SC, V12901, P633, DOI 10.1007/978-3-030-87193-2_60
   Vaswani A., 2017, ADV NEURAL INFORM PR
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P775, DOI 10.1007/978-3-030-58452-8_45
   Zhang ZY, 2018, LECT NOTES COMPUT SC, V11214, P238, DOI 10.1007/978-3-030-01249-6_15
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao X., 2020, PROC EUR C COMPUT VI, P35, DOI 10.1007/978-3-030-58536-5_3
   Zhao X., INT C MEDICAL IMAGE, P120
   Zhou ZL, 2021, IEEE T BIG DATA, V7, P559, DOI 10.1109/TBDATA.2019.2919570
NR 56
TC 4
Z9 4
U1 3
U2 17
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD SEP
PY 2022
VL 78
AR 103903
DI 10.1016/j.bspc.2022.103903
EA JUL 2022
PG 11
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 3A0LJ
UT WOS:000826957800007
DA 2023-08-21
ER

PT J
AU Wallace, MB
   Sharma, P
   Bhandari, P
   East, J
   Antonelli, G
   Lorenzetti, R
   Vieth, M
   Speranza, I
   Spadaccini, M
   Desai, M
   Lukens, FJ
   Babameto, G
   Batista, D
   Singh, D
   Palmer, W
   Ramirez, F
   Palmer, R
   Lunsford, T
   Ruff, K
   Bird-Liebermann, E
   Ciofoaia, V
   Arndtz, S
   Cangemi, D
   Puddick, K
   Derfus, G
   Johal, AS
   Barawi, M
   Longo, L
   Moro, L
   Repici, A
   Hassan, C
AF Wallace, Michael B.
   Sharma, Prateek
   Bhandari, Pradeep
   East, James
   Antonelli, Giulio
   Lorenzetti, Roberto
   Vieth, Micheal
   Speranza, Ilaria
   Spadaccini, Marco
   Desai, Madhav
   Lukens, Frank J.
   Babameto, Genci
   Batista, Daisy
   Singh, Davinder
   Palmer, William
   Ramirez, Francisco
   Palmer, Rebecca
   Lunsford, Tisha
   Ruff, Kevin
   Bird-Liebermann, Elizabeth
   Ciofoaia, Victor
   Arndtz, Sophie
   Cangemi, David
   Puddick, Kirsty
   Derfus, Gregory
   Johal, Amitpal S.
   Barawi, Mohammed
   Longo, Luigi
   Moro, Luigi
   Repici, Alessandro
   Hassan, Cesare
TI Impact of Artificial Intelligence on Miss Rate of Colorectal Neoplasia
SO GASTROENTEROLOGY
LA English
DT Article
DE Colorectal Cancer; Artificial Intelligence; Miss Rate; Tandem
   Colonoscopy; Adenoma Miss Rate
ID COMPUTER-AIDED DETECTION; GASTROINTESTINAL ENDOSCOPY; EUROPEAN-SOCIETY;
   COLONOSCOPY; CANCERS; HISTOLOGY; RISK
AB BACKGROUND & AIMS: Artificial intelligence (AI) may detect colorectal polyps that have been missed due to perceptual pitfalls. By reducing such miss rate, AI may increase the detection of colorectal neoplasia leading to a higher degree of colorectal cancer (CRC) prevention. METHODS: Patients undergoing CRC screening or surveillance were enrolled in 8 centers (Italy, UK, US), and randomized (1:1) to undergo 2 same-day, back-to-back colonoscopies with or without AI (deep learning computer aided diagnosis endoscopy) in 2 different arms, namely AI followed by colonoscopy without AI or vice-versa. Adenoma miss rate (AMR) was calculated as the number of histologically verified lesions detected at second colonoscopy divided by the total number of lesions detected at first and second colonoscopy. Mean number of lesions detected in the second colonoscopy and proportion of false negative subjects (no lesion at first colonoscopy and at least 1 at second) were calculated. Odds ratios (ORs) and 95% confidence intervals (CIs) were adjusted by endoscopist, age, sex, and indication for colonoscopy. Adverse events were also measured. RESULTS: A total of 230 subjects (116 AI first, 114 standard colonoscopy first) were included in the study analysis. AMR was 15.5% (38 of 246) and 32.4% (80 of 247) in the arm with AI and non-AI colonoscopy first, respectively (adjusted OR, 0.38; 95% CI, 0.23-0.62). In detail, AMR was lower for AI first for the <= 5 mm (15.9% vs 35.8%; OR, 0.34; 95% CI, 0.21-0.55) and nonpolypoid lesions (16.8% vs 45.8%; OR, 0.24; 95% CI, 0.13-0.43), and it was lower both in the proximal (18.3% vs 32.5%; OR, 0.46; 95% CI, 0.26-0.78) and distal colon (10.8% vs 32.1%; OR, 0.25; 95% CI, 0.11-0.57). Mean number of adenomas at second colonoscopy was lower in the AI-first group as compared with non-AI colonoscopy first (0.33 +/- 0.63 vs 0.70 +/- 0.97, P < .001). False negative rates were 6.8% (3 of 44 patients) and 29.6% (13 of 44) in the AI and non-AI first arms, respectively (OR, 0.17; 95% CI, 0.05-0.67). No difference in the rate of adverse events was found between the 2 groups. CONCLUSIONS: AI resulted in an approximately 2-fold reduction in miss rate of colorectal neoplasia, supporting AI-benefit in reducing perceptual errors for small and subtle lesions at standard colonoscopy.
C1 [Wallace, Michael B.; Lukens, Frank J.; Palmer, William; Cangemi, David] Mayo Clin Jacksonville, Div Gastroenterol & Hepatol, Jacksonville, FL USA.
   [Wallace, Michael B.] Sheikh Shakhbout Med City SSMC, Div Gastroenterol, Abu Dhabi, U Arab Emirates.
   [Sharma, Prateek] Univ Kansas, Med Ctr, Dept Gastroenterol & Hepatol, Kansas City, KS 66103 USA.
   [Bhandari, Pradeep; Desai, Madhav; Arndtz, Sophie; Puddick, Kirsty] Queen Alexandra Hosp, Div Gastroenterol, Portsmouth, Hants, England.
   [East, James; Palmer, Rebecca; Bird-Liebermann, Elizabeth] John Radcliffe Hosp, Translat Gastroenterol Unit, Oxford, England.
   [Antonelli, Giulio; Lorenzetti, Roberto; Spadaccini, Marco] Nuovo Regina Margherita Hosp, Gastroenterol Unit, Rome, Italy.
   [Antonelli, Giulio] Sapienza Univ Rome, Dept Anat Histol Forens Med & Orthoped Sci, Rome, Italy.
   [Antonelli, Giulio] Osped Castelli Hosp, Gastroenterol & Digest Endoscopy Unit, Rome, Italy.
   [Vieth, Micheal] Klinikum Bayreuth GmbH, Inst Pathol, Bayreuth, Germany.
   [Speranza, Ilaria] Cros NT, Verona, Italy.
   [Babameto, Genci; Batista, Daisy; Singh, Davinder; Ciofoaia, Victor] Mayo Clin LaCrosse, Div Gastroenterol & Hepatol, La Crosse, WI USA.
   [Ramirez, Francisco; Lunsford, Tisha; Ruff, Kevin] Mayo Clin Scottsdale, Div Gastroenterol & Hepatol, Scottsdale, AZ USA.
   [Derfus, Gregory] Mayo Clin Eau Claire, Div Gastroenterol & Hepatol, Eau Claire, WI USA.
   [Johal, Amitpal S.] Geisinger Med Ctr, Div Gastroenterol, Danville, PA 17822 USA.
   [Barawi, Mohammed] Ascens St John Hosp, Gastroenterol & Digest Hlth, Detroit, MI USA.
   [Longo, Luigi; Moro, Luigi] Cosmo Artificial Intelligence AI Ltd, Dublin, Ireland.
   [Repici, Alessandro; Hassan, Cesare] Humanitas Univ, Dept Biomed Sci, Milan, Italy.
   [Repici, Alessandro; Hassan, Cesare] Humanitas Clin & Res Ctr IRCCS, Endoscopy Unit, Milan, Italy.
C3 Mayo Clinic; University of Kansas; University of Kansas Medical Center;
   Portsmouth Hospitals NHS Trust; Queen Alexandra Hospital; University of
   Oxford; Poliambulatorio Nuovo Regina Margherita; Sapienza University
   Rome; Klinikum Bayreuth; Mayo Clinic; Mayo Clinic Phoenix; Geisinger
   Medical Center; Humanitas University
RP Wallace, MB (通讯作者)，Mayo Clin, Div Gastroenterol & Hepatol, 4500 San Pablo Rd, Jacksonville, FL 32224 USA.
EM mwallace@ssmc.ae
RI Sharma, Prateek/IZE-3910-2023; Repici, Alessandro/HFH-8162-2022;
   Spadaccini, Marco/HOH-7613-2023; hassan, cesare/H-2844-2012; Wallace,
   Michael/GZL-9731-2022
OI Repici, Alessandro/0000-0002-1621-6450; Spadaccini,
   Marco/0000-0003-3909-9012; hassan, cesare/0000-0001-7167-1459; Wallace,
   Michael/0000-0002-6446-5785; Antonelli, Giulio/0000-0003-1797-3864
FU Cosmo Artificial Intelligence-AI Ltd.
FX This article was funded by Cosmo Artificial Intelligence-AI Ltd.
CR Anderson R, 2020, GASTROENTEROLOGY, V158, P1287, DOI 10.1053/j.gastro.2019.12.031
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Arribas J, 2021, GUT, V70, P1458, DOI 10.1136/gutjnl-2020-321922
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Frazzoni L, 2022, ENDOSCOPY, V54, P403, DOI 10.1055/a-1500-3730
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Repici A, 2019, GASTROENTEROLOGY, V156, P2198, DOI 10.1053/j.gastro.2019.02.001
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Robertson DJ, 2014, GUT, V63, P949, DOI 10.1136/gutjnl-2012-303796
   Rutter MD, 2018, GASTROENTEROLOGY, V155, P909, DOI 10.1053/j.gastro.2018.05.038
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Walsh CM, 2021, GASTROINTEST ENDOSC, V93, P297, DOI 10.1016/j.gie.2020.06.054
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
   Zimmermann-Fraedrich K, 2021, GUT, V70, P268, DOI 10.1136/gutjnl-2020-320984
NR 27
TC 41
Z9 41
U1 24
U2 39
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD JUL
PY 2022
VL 163
IS 1
BP 295
EP +
DI 10.1053/j.gastro.2022.03.007
PG 15
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 3J6GU
UT WOS:000833492600011
PM 35304117
OA hybrid
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Wang, DC
   Chen, SJ
   Sun, XZ
   Chen, QL
   Cao, Y
   Liu, BY
   Liu, XW
AF Wang, Dechun
   Chen, Shuijiao
   Sun, Xinzi
   Chen, Qilei
   Cao, Yu
   Liu, Benyuan
   Liu, Xiaowei
TI AFP-Mask: Anchor-Free Polyp Instance Segmentation in Colonoscopy
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Detectors; Head; Feature extraction; Colonoscopy; Cancer; Principal
   component analysis; Semantics; Deep learning; computer vision; convolut-
   ional neural network; polyp detection; colonoscopy
ID VALIDATION
AB Colorectal cancer (CRC) is a common and lethal disease. Globally, CRC is the third most commonly diagnosed cancer in males and the second in females. The most effective way to prevent CRC is through using colonoscopy to identify and remove precancerous growths at an early stage. The detection and removal of colorectal polyps have been found to be associated with a reduction in mortality from colorectal cancer. However, the false negative rate of polyp detection during colonoscopy is often high even for experienced physicians. With recent advances in deep learning based object detection techniques, automated polyp detection shows great potential in helping physicians reduce false positive rate during colonoscopy. In this paper, we propose a novel anchor-free instance segmentation framework that can localize polyps and produce the corresponding instance level masks without using predefined anchor boxes. Our framework consists of two branches: (a) an object detection branch that performs classification and localization, (b) a mask generation branch that produces instance level masks. Instead of predicting a two-dimensional mask directly, we encode it into a compact representation vector, which allows us to incorporate instance segmentation with one-stage bounding-box detectors in a simple yet effective way. Moreover, our proposed encoding method can be trained jointly with object detector. Our experiment results show that our framework achieves a precision of 99.36% and a recall of 96.44% on public datasets, outperforming existing anchor-free instance segmentation methods by at least 2.8% in mIoU on our private dataset.
C1 [Chen, Shuijiao; Liu, Xiaowei] Cent South Univ, Dept Gastroenterol, Xiangya Hosp, Changsha 410008, Hunan, Peoples R China.
   [Chen, Shuijiao; Liu, Xiaowei] Hunan Int Sci & Technol Cooperat Base Artificial, Changsha 410008, Hunan, Peoples R China.
   [Wang, Dechun; Sun, Xinzi; Chen, Qilei; Cao, Yu; Liu, Benyuan] Univ Massachusetts Lowell, Dept Comp Sci, Lowell, MA 01854 USA.
C3 Central South University; University of Massachusetts System; University
   of Massachusetts Lowell
RP Liu, XW (通讯作者)，Cent South Univ, Dept Gastroenterol, Xiangya Hosp, Changsha 410008, Hunan, Peoples R China.; Liu, XW (通讯作者)，Hunan Int Sci & Technol Cooperat Base Artificial, Changsha 410008, Hunan, Peoples R China.; Liu, BY (通讯作者)，Univ Massachusetts Lowell, Dept Comp Sci, Lowell, MA 01854 USA.
EM dechun_wang@student.uml.edu; 4010383@csu.edu.cn;
   xinzi_sun@student.uml.edu; qilei_chen@student.uml.edu; ycao@cs.uml.edu;
   bliu@cs.uml.edu; liuxw@csu.edu.cn
OI wang, dechun/0000-0003-2965-0608; chen, qilei/0000-0001-5506-8094; Sun,
   Xinzi/0000-0002-8890-739X
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], 2017, P IEEE INT C COMPUTE
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Eggert C, 2017, IEEE INT CON MULTI, P421, DOI 10.1109/ICME.2017.8019550
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Kong Tao, 2019, ARXIV COMPUTER VISIO
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Lee Y., 2020, PROC IEEE C COMPUT V, P13906, DOI DOI 10.1109/CVPR42600.2020.01392
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S., 2015, ANN C NEUR INF PROC, P91
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Rufeng Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10223, DOI 10.1109/CVPR42600.2020.01024
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Sun XZ, 2020, PROC INT C TOOLS ART, P706, DOI 10.1109/ICTAI50040.2020.00113
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Xinlong Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P649, DOI 10.1007/978-3-030-58523-5_38
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yang C, 2021, IEEE J BIOMED HEALTH, V25, P3886, DOI 10.1109/JBHI.2021.3077271
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhou X, 2019, PSYCHOL HEALTH, V34, P811, DOI 10.1080/08870446.2019.1574348
NR 51
TC 6
Z9 6
U1 3
U2 38
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD JUL
PY 2022
VL 26
IS 7
BP 2995
EP 3006
DI 10.1109/JBHI.2022.3147686
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA 2P6EU
UT WOS:000819832600017
PM 35104234
DA 2023-08-21
ER

PT J
AU Zeng, ZH
   Fan, CD
   Xiao, LY
   Qu, XL
AF Zeng, Zhenhuan
   Fan, Chaodong
   Xiao, Leyi
   Qu, Xilong
TI DEA-UNet: a dense-edge-attention UNet architecture for medical image
   segmentation
SO JOURNAL OF ELECTRONIC IMAGING
LA English
DT Article
DE image segmentation; coronavirus disease-19; edge-guidance; colonoscopy
   polyp; computed tomography image
ID CLASSIFICATION
AB Classical UNet with an encoder and decoder structure and its variants perform very well in the field of medical image segmentation. They have a key similarity of a skip-connection, which combines deep, semantic, and coarse-grained feature maps from the decoder subnetwork with shallow, low-level, and fine-grained feature maps from the encoder subnetwork. We noted that, in many cases in medical image segmentation, the boundary of the segmentation target is fuzzy and complex. Traditional UNet cannot accurately segment these details. The main purpose is to solve the fuzzy boundary problem in medical image segmentation. To solve this problem, we combine the advantages of previous models and improve them and propose a new dense edge attention U-type network (DEA-UNet) for medical image segmentation. Starting from the traditional UNet, we modified the concat and skip-connection operations in the latter part. We designed an edge guidance module that fused the features of all layers. Starting from the upsample at the deepest layer, the reverse attention module was used step by step to extract features from high to low, and the edge guidance module was combined with it, so each layer could fully extract boundary details that were difficult to be noticed by previous models, thus solving the problem of the fuzzy boundary of the lesion region. We conducted experiments on two kinds of medical datasets (chest CT and colonoscopic polyp) and compared them with the traditional network. The experimental results showed that our DEA-UNet performed better in multiple indicators. In the segmentation of coronavirus disease-19 images, the results indicate that DEA-UNet has a Dice of 74.6%, sensitivity (Sen) of 70.8%, specificity (Spe) of 96.7%, structural measure (S-alpha) of 0.766%, enhanced-alignment measure (E-phi) of 0.910%, and mean absolute error (MAE) of 0.062%. Our DEA-UNET is 31%, 16%, 3%, and 0.7 and higher than the traditional medical segmentation model UNet, UNet++, the last model Few-shot UNet, and Inf-Net in Dice. In the segmentation of colonoscopic polyp dataset Kvasir, the results indicate that DEA-UNet has a Dice of 95%, structural measure (S-alpha) of 0.953%, enhanced-alignment measure (E-phi) of 0.974%, and MAE of 0.015%. Our DEA-UNet is 13%, 13%, 23%, and 5% higher than the traditional medical segmentation model UNet, UNet++, the last model SFA, and PraNet in Dice. In other evaluation metrics, our DEA-UNet also performed better. When designing DEA-UNet, we also consider the balance between model size and prediction accuracy. Experiments show that, by proper pruning, we can greatly reduce the number of model parameters while maintaining the accuracy of prediction results with little change. This proves that our DEA-UNET has great potential in the field of medical image segmentation.
C1 [Zeng, Zhenhuan] Xiangtan Univ, Sch Comp Sci, Xiangtan, Peoples R China.
   [Fan, Chaodong; Xiao, Leyi; Qu, Xilong] Hunan Univ Finance & Econ, Sch Informat Technol & Management, Changsha, Peoples R China.
   [Fan, Chaodong; Xiao, Leyi] Hainan Univ, Sch Comp Sci & Technol, Haikou, Hainan, Peoples R China.
   [Xiao, Leyi] AnHui Polytech Univ, AnHui Prov Key Lab Detect Technol & Energy Saving, Wuhu, Peoples R China.
   [Xiao, Leyi] Quanzhou Normal Univ, Fujian Prov Key Lab Data Intens Comp, Quanzhou, Peoples R China.
   [Xiao, Leyi] Xihua Univ, Vehicle Measurement Control & Safety Key Lab Sich, Chengdu, Peoples R China.
C3 Xiangtan University; Hainan University; Anhui Polytechnic University;
   Quanzhou Normal University; Xihua University
RP Fan, CD (通讯作者)，Hunan Univ Finance & Econ, Sch Informat Technol & Management, Changsha, Peoples R China.; Fan, CD (通讯作者)，Hainan Univ, Sch Comp Sci & Technol, Haikou, Hainan, Peoples R China.
EM fchdmy@hnu.edu.cn
RI zeng, zhenhuan/HGF-3010-2022
OI zeng, zhenhuan/0000-0001-7613-0416
FU Hunan Provincial Natural Science Foundation of China [2020JJ4587];
   Guangdong Basic and Applied Basic Research Foundation [2019A1515110423];
   Scientific Research Project of Hunan Provincial Department of Education
   [21C0922]; Open Fund Project of Fujian Provincial Key Laboratory of Data
   Intensive Computing [BD202004]; Open Research Fund of AnHui Province Key
   Laboratory of Detection Technology and Energy Saving Devices
   [JCKJ2021B05]; Open Fund Project of Vehicle Measurement, Control and
   Safety Key Laboratory of Sichuan Province [QCCK2021-006]
FX This work is supported by the Hunan Provincial Natural Science
   Foundation of China (Grant No. 2020JJ4587), Guangdong Basic and Applied
   Basic Research Foundation (Grant No. 2019A1515110423), Scientific
   Research Project of Hunan Provincial Department of Education (Grant No.
   21C0922), Open Fund Project of Fujian Provincial Key Laboratory of Data
   Intensive Computing (Grant No. BD202004), Open Research Fund of AnHui
   Province Key Laboratory of Detection Technology and Energy Saving
   Devices (Grant No. JCKJ2021B05), and Open Fund Project of Vehicle
   Measurement, Control and Safety Key Laboratory of Sichuan Province
   (Grant No. QCCK2021-006).
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   Hirra I, 2021, IEEE ACCESS, V9, P24273, DOI 10.1109/ACCESS.2021.3056516
   Huang CL, 2020, LANCET, V395, P497, DOI 10.1016/S0140-6736(20)30183-5
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Jin S, 2020, MEDRXIV
   Li L, 2020, RADIOLOGY, DOI [DOI 10.1148/RADIOL.2020200905, 10.1148/radiol.2020200905]
   Liu Y, 2017, PROC CVPR IEEE, P5872, DOI 10.1109/CVPR.2017.622
   medicalseg, COVID 19 CT SEGMENTA
   Murugesan B, 2019, Arxiv, DOI arXiv:1902.04099
   Qadri SF, 2021, IEEE ACCESS, V9, P158227, DOI 10.1109/ACCESS.2021.3131216
   Qadri SF, 2019, PROC SPIE, V11179, DOI 10.1117/12.2540176
   Qadri SF, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9010069
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Shan F., 2020, ARXIV
   Shi F, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abe838
   Touret F, 2020, SCI REP-UK
   Voulodimos A, 2021, SENSORS-BASEL, V21, DOI [10.3390/s21062215, 10.1145/3453892.3461322]
   Wang GT, 2020, IEEE T MED IMAGING, V39, P2653, DOI 10.1109/TMI.2020.3000314
   Wang XG, 2020, IEEE T MED IMAGING, V39, P2615, DOI 10.1109/TMI.2020.2995965
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 35
TC 0
Z9 1
U1 32
U2 72
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1017-9909
EI 1560-229X
J9 J ELECTRON IMAGING
JI J. Electron. Imaging
PD JUL 1
PY 2022
VL 31
IS 4
DI 10.1117/1.JEI.31.4.043032
PG 17
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA 4F8HM
UT WOS:000848751400050
DA 2023-08-21
ER

PT J
AU Biffi, C
   Salvagnini, P
   Dinh, NN
   Hassan, C
   Sharma, P
   Cherubini, A
AF Biffi, Carlo
   Salvagnini, Pietro
   Dinh, Nhan Ngo
   Hassan, Cesare
   Sharma, Prateek
   Cherubini, Andrea
CA GI Genius CADx Study Grp
TI A novel AI device for real-time optical characterization of colorectal
   polyps
SO NPJ DIGITAL MEDICINE
LA English
DT Article
ID COMPUTER-AIDED DETECTION; ARTIFICIAL-INTELLIGENCE; ENDOSCOPIC
   CLASSIFICATION; NEOPLASIA; SOCIETY; CANCER; SYSTEM; JAPAN
AB Accurate in-vivo optical characterization of colorectal polyps is key to select the optimal treatment regimen during colonoscopy. However, reported accuracies vary widely among endoscopists. We developed a novel intelligent medical device able to seamlessly operate in real-time using conventional white light (WL) endoscopy video stream without virtual chromoendoscopy (blue light, BL). In this work, we evaluated the standalone performance of this computer-aided diagnosis device (CADx) on a prospectively acquired dataset of unaltered colonoscopy videos. An international group of endoscopists performed optical characterization of each polyp acquired in a prospective study, blinded to both histology and CADx result, by means of an online platform enabling careful video assessment. Colorectal polyps were categorized by reviewers, subdivided into 10 experts and 11 non-experts endoscopists, and by the CADx as either "adenoma" or "non-adenoma". A total of 513 polyps from 165 patients were assessed. CADx accuracy in WL was found comparable to the accuracy of expert endoscopists (CADx(WL)/Exp; OR 1.211 [0.766-1.915]) using histopathology as the reference standard. Moreover, CADx accuracy in WL was found superior to the accuracy of non-expert endoscopists (CADx(WL)/NonExp; OR 1.875 [1.191-2.953]), and CADx accuracy in BL was found comparable to it (CADx(BL)/CADx(WL); OR 0.886 [0.612-1.282]). The proposed intelligent device shows the potential to support non-expert endoscopists in systematically reaching the performances of expert endoscopists in optical characterization.
C1 [Biffi, Carlo; Salvagnini, Pietro; Dinh, Nhan Ngo; Cherubini, Andrea] Cosmo AI Linkverse Lainate, Artificial Intelligence Grp, Rome, Italy.
   [Hassan, Cesare] Nuovo Regina Margherita Hosp, Gastroenterol Unit, Rome, Italy.
   [Hassan, Cesare] Endoscopy Unit, Humanitas Clin & Res Ctr IRCCS, Rozzano, Italy.
   [Sharma, Prateek] Va Med Ctr, Kansas City, MO USA.
   [Sharma, Prateek] Univ Kansas, Sch Med, Kansas City, MO USA.
   [Cherubini, Andrea] Univ Milano Bicocca, Milan Ctr Neurosci, I-20126 Milan, Italy.
C3 Poliambulatorio Nuovo Regina Margherita; University of Kansas;
   University of Milano-Bicocca
RP Cherubini, A (通讯作者)，Cosmo AI Linkverse Lainate, Artificial Intelligence Grp, Rome, Italy.; Cherubini, A (通讯作者)，Univ Milano Bicocca, Milan Ctr Neurosci, I-20126 Milan, Italy.
EM acherubini@cosmopharma.com
RI Cherubini, Andrea/D-1327-2009; Sharma, Prateek/IZE-3910-2023; hassan,
   cesare/H-2844-2012; Dinis-Ribeiro, Mario/A-9248-2010
OI Cherubini, Andrea/0000-0002-5946-4390; hassan,
   cesare/0000-0001-7167-1459; Salvagnini, Pietro/0000-0002-1103-894X;
   Ordas, Ingrid/0000-0001-7632-0340; Fernandez Clotet,
   Agnes/0000-0001-7513-0764; Sanchez, Ariadna/0000-0003-0409-1328;
   Dinis-Ribeiro, Mario/0000-0003-0121-6850; Biffi,
   Carlo/0000-0002-4913-7441
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Berzin TM, 2020, GASTROINTEST ENDOSC, V92, P951, DOI 10.1016/j.gie.2020.06.035
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bisschops R., 2019, ENDOSCOPY, V51, P1179
   Bisschops R, 2018, ENDOSCOPY, V50, P211, DOI 10.1055/s-0043-121570
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Dellermann D, 2019, BUS INFORM SYST ENG+, V61, P637, DOI 10.1007/s12599-019-00595-2
   FDA, FDA AUTH MARK 1 DEV
   Glissen Brown Jeremy R, 2021, Gastrointest Endosc Clin N Am, V31, P743, DOI 10.1016/j.giec.2021.05.010
   Iacucci M, 2018, ENDOSCOPY, V50, P779, DOI 10.1055/s-0044-100791
   IJspeert JEG, 2016, GUT, V65, P963, DOI 10.1136/gutjnl-2014-308411
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Manfredi MA, 2015, GASTROINTEST ENDOSC, V81, P249, DOI 10.1016/j.gie.2014.06.020
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Ponugoti P, 2019, ENDOSCOPY, V51, P221, DOI 10.1055/a-0831-2348
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Schlemper RJ, 2000, J GASTROEN HEPATOL, V15, pG49, DOI 10.1046/j.1440-1746.2000.02266.x
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Thulasidasan S, 2019, ADV NEUR IN, V32
   Vieth M, 2019, ENDOSCOPY, V51, P212, DOI 10.1055/a-0832-8381
   Walradt T, 2020, GASTROINTEST ENDOSC, V92, P801, DOI 10.1016/j.gie.2020.05.040
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wei J, 2021, IEEE WINT CONF APPL, P2472, DOI 10.1109/WACV48630.2021.00252
NR 30
TC 11
Z9 11
U1 0
U2 2
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2398-6352
J9 NPJ DIGIT MED
JI npj Digit. Med.
PD JUN 30
PY 2022
VL 5
IS 1
AR 84
DI 10.1038/s41746-022-00633-6
PG 8
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA 2P0KJ
UT WOS:000819440000001
PM 35773468
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Brand, M
   Troya, J
   Krenzer, A
   De Maria, C
   Mehlhase, N
   Goetze, S
   Walter, B
   Meining, A
   Hann, A
AF Brand, Markus
   Troya, Joel
   Krenzer, Adrian
   De Maria, Costanza
   Mehlhase, Niklas
   Goetze, Sebastian
   Walter, Benjamin
   Meining, Alexander
   Hann, Alexander
TI Frame-by-Frame Analysis of a Commercially Available Artificial
   Intelligence Polyp Detection System in Full-Length Colonoscopies
SO DIGESTION
LA English
DT Article
DE Colonoscopy; Deep learning; Computer-aided detection; Artificial
   intelligence
ID COMPUTER-AIDED DETECTION; DETECTION-ASSISTED COLONOSCOPY;
   GASTROINTESTINAL ENDOSCOPY; MISS RATE
AB Introduction: Computer-aided detection (CADe) helps increase colonoscopic polyp detection. However, little is known about other performance metrics like the number and duration of false-positive (FP) activations or how stable the detection of a polyp is. Methods: 111 colonoscopy videos with total 1,793,371 frames were analyzed on a frame-by-frame basis using a commercially available CADe system (GI-Genius, Medtronic Inc.). Primary endpoint was the number and duration of FP activations per colonoscopy. Additionally, we analyzed other CADe performance parameters, including per-polyp sensitivity, per-frame sensitivity, and first detection time of a polyp. We additionally investigated whether a threshold for withholding CADe activations can be set to suppress short FP activations and how this threshold alters the CADe performance parameters. Results: A mean of 101 +/- 88 FPs per colonoscopy were found. Most of the FPs consisted of less than three frames with a maximal 66-ms duration. The CADe system detected all 118 polyps and achieved a mean per-frame sensitivity of 46.6 +/- 26.6%, with the lowest value for flat polyps (37.6 +/- 24.8%). Withholding CADe detections up to 6 frames length would reduce the number of FPs by 87.97% (p < 0.001) without a significant impact on CADe performance metrics. Conclusions: The CADe system works reliable but generates many FPs as a side effect. Since most FPs are very short, withholding short-term CADe activations could substantially reduce the number of FPs without impact on other performance metrics. Clinical practice would benefit from the implementation of customizable CADe thresholds.
C1 [Brand, Markus; Troya, Joel; Krenzer, Adrian; Meining, Alexander; Hann, Alexander] Univ Hosp Wurzburg, Dept Internal Med 2, Intervent & Expt Endoscopy InExEn, Wurzburg, Germany.
   [Krenzer, Adrian] Julius Maximilians Univ, Inst Comp Sci, Artificial Intelligence & Knowledge Syst, Wurzburg, Germany.
   [De Maria, Costanza] Ente Ospedaliero Cantonale EOC, Dept Gastroenterol & Hepatol, Bellinzona, Switzerland.
   [De Maria, Costanza] Univ Italian Switzerland USI, Dept Biomed Sci, Lugano, Switzerland.
   [Mehlhase, Niklas; Goetze, Sebastian; Walter, Benjamin] Univ Hosp Ulm, Dept Internal Medicine1, Ulm, Germany.
C3 University of Wurzburg; University of Wurzburg; Universita della
   Svizzera Italiana; Ulm University
RP Hann, A (通讯作者)，Univ Hosp Wurzburg, Dept Internal Med 2, Intervent & Expt Endoscopy InExEn, Wurzburg, Germany.
EM hann_a@ukw.de
OI Brand, Markus/0000-0002-3495-5206; Hann, Alexander/0000-0001-8035-3559;
   Troya, Joel/0000-0002-7992-0146
FU state government of Baden-Wurttemberg, Germany; IZKF Wuerzburg; Bavarian
   Center for Cancer Research (BZKF)
FX Alexander Hann receives public funding from the state government of
   Baden-Wurttemberg, Germany (funding cluster "Forum Gesundheitsstandort
   Baden-Wuerttemberg"), to research and de-velop artificial intelligence
   applications for polyp detection in screening colonoscopy. Alexander
   Meining receives funding from the IZKF Wuerzburg and the Bavarian Center
   for Cancer Research (BZKF) for further implementation and development of
   artificial intelligence for detection of (pre)neoplastic lesions.
CR Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Deliwala SS, 2021, INT J COLORECTAL DIS, V36, P2291, DOI 10.1007/s00384-021-03929-3
   Hagege H, 2015, ENDOSC INT OPEN, V3, pE346, DOI 10.1055/s-0034-1391847
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Krenzer Adrian, 2021, Stud Health Technol Inform, V281, P484, DOI 10.3233/SHTI210206
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Pfeifer L, 2021, EUR J GASTROEN HEPAT, V33, pE662, DOI 10.1097/MEG.0000000000002209
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Riphaus A, 2015, Z GASTROENTEROL, V53, P802, DOI 10.1055/s-0035-1553458
   Spadaccini M, 2022, GASTROINTEST ENDOSC, V95, P975, DOI 10.1016/j.gie.2021.12.031
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Troya J, 2022, ENDOSCOPY, V54, P1009, DOI 10.1055/a-1770-7353
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Zhao SB, 2021, WORLD J GASTROENTERO, V27, P5232, DOI 10.3748/wjg.v27.i31.5232
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
NR 24
TC 1
Z9 1
U1 0
U2 0
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0012-2823
EI 1421-9867
J9 DIGESTION
JI Digestion
PY 2022
VL 103
IS 5
BP 378
EP 385
DI 10.1159/000525345
EA JUN 2022
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 7S5SB
UT WOS:000879449200001
PM 35767938
OA hybrid
DA 2023-08-21
ER

PT J
AU Shi, LT
   Wang, YF
   Li, ZG
   Qiumiao, W
AF Shi, Liantao
   Wang, Yufeng
   Li, Zhengguo
   Qiumiao, Wen
TI FRCNet: Feature Refining and Context-Guided Network for Efficient Polyp
   Segmentation
SO FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY
LA English
DT Article
DE deep learning; polyp segmentation; enhanced context-calibrated module;
   progressive context-aware fusion module; multi-scale pyramid aggregation
ID CT COLONOGRAPHY; IMAGES
AB Colorectal cancer, also known as rectal cancer, is one of the most common forms of cancer, and it can be completely cured with early diagnosis. The most effective and objective method of screening and diagnosis is colonoscopy. Polyp segmentation plays a crucial role in the diagnosis and treatment of diseases related to the digestive system, providing doctors with detailed auxiliary boundary information during clinical analysis. To this end, we propose a novel light-weight feature refining and context-guided network (FRCNet) for real-time polyp segmentation. In this method, we first employed the enhanced context-calibrated module to extract the most discriminative features by developing long-range spatial dependence through a context-calibrated operation. This operation is helpful to alleviate the interference of background noise and effectively distinguish the target polyps from the background. Furthermore, we designed the progressive context-aware fusion module to dynamically capture multi-scale polyps by collecting multi-range context information. Finally, the multi-scale pyramid aggregation module was used to learn more representative features, and these features were fused to refine the segmented results. Extensive experiments on the Kvasir, ClinicDB, ColonDB, ETIS, and Endoscene datasets demonstrated the effectiveness of the proposed model. Specifically, FRCNet achieves an mIoU of 84.9% and mDice score of 91.5% on the Kvasir dataset with a model size of only 0.78 M parameters, outperforming state-of-the-art methods. Models and codes are available at the footnote.(1)
C1 [Shi, Liantao; Li, Zhengguo] Shenzhen Polytech, Sch Automobile & Transportat Engn, Shenzhen, Peoples R China.
   [Shi, Liantao; Wang, Yufeng] Univ Sci & Technol Liaoning, Sch Elect & Informat Engn, Anshan, Peoples R China.
   [Qiumiao, Wen] Zhejiang Sci Tech Univ, Sch Sci, Dept Math, Hangzhou, Peoples R China.
C3 ShenZhen Polytechnic; University of Science & Technology Liaoning;
   Zhejiang Sci-Tech University
RP Li, ZG (通讯作者)，Shenzhen Polytech, Sch Automobile & Transportat Engn, Shenzhen, Peoples R China.; Wang, YF (通讯作者)，Univ Sci & Technol Liaoning, Sch Elect & Informat Engn, Anshan, Peoples R China.
EM Lizhengguo@szpt.edu.cn; wangyufeng@ustl.edu
OI Shi, Liantao/0000-0002-5806-3405
FU Shenzhen Polytechnic
FX The authors would like to thank Shenzhen Polytechnic for providing good
   experimental conditions and financial support, as well as many teachers
   from the School of Electronics and Information, University of Science
   and Technology Liaoning for their discussion of experimental ideas.
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   [Anonymous], 2015, P MED IM COMP COMP A
   Bai DX, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6614
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Deans S. R., 2007, RADON TRANSFORM SOME
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gross S., 2009, BILDVERARBEITUNG F R, P252
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hao ZQ, 2022, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.810876
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861, DOI [DOI 10.48550/ARXIV.1704.04861, 10.48550/arXiv.1704.04861]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C.-H., 2021, ARXIV PREPRINT ARXIV, DOI [10.48550/arXiv.2101.07172, DOI 10.48550/ARXIV.2101.07172]
   Huang L, 2022, FRONT NEUROROBOTICS, V16, DOI 10.3389/fnbot.2022.881021
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Jerebko AK, 2003, P SOC PHOTO-OPT INS, V5031, P359, DOI 10.1117/12.480696
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jiang D, 2021, J AMB INTEL HUM COMP, V12, P10809, DOI 10.1007/s12652-020-02843-w
   Jiang D, 2021, FUTURE GENER COMP SY, V123, P94, DOI 10.1016/j.future.2021.04.019
   Jiang-Jiang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10093, DOI 10.1109/CVPR42600.2020.01011
   Kingma D., 2015, ARXIV
   Kolligs FT, 2016, VISC MED, V32, P158, DOI 10.1159/000446488
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li GF, 2019, IEEE ACCESS, V7, P11533, DOI 10.1109/ACCESS.2019.2891749
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Lin T.-Y., P IEEE C COMPUTER VI, P2117
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qin LB, 2020, AAAI CONF ARTIF INTE, V34, P8665
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Xie Q., 2020, P IEEECVF C COMPUTER, P10444
   Yao JH, 2004, IEEE T MED IMAGING, V23, P1344, DOI 10.1109/TMI.2004.826941
   Yu F., 2016, MULTI SCALE CONTEXT, DOI [10.48550/arXiv.1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Zhang YH, 2018, PROC CVPR IEEE, P6810, DOI 10.1109/CVPR.2018.00712
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 53
TC 1
Z9 1
U1 5
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-4185
J9 FRONT BIOENG BIOTECH
JI Front. Bioeng. Biotechnol.
PD JUN 29
PY 2022
VL 10
AR 799541
DI 10.3389/fbioe.2022.799541
PG 15
WC Biotechnology & Applied Microbiology; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Science & Technology - Other
   Topics
GA 3B7BP
UT WOS:000828092100001
PM 35845422
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Ay, B
   Turker, C
   Emre, E
   Ay, K
   Aydin, G
AF Ay, Betul
   Turker, Cihan
   Emre, Elif
   Ay, Kevser
   Aydin, Galip
TI Automated classification of nasal polyps in endoscopy video-frames using
   handcrafted and CNN features
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Nasal polyps; Rhinology; Machine learning; Deep learning; CNN
AB Nasal polyps are edematous polypoid masses covered by smooth, gray, shiny, soft and gelatinous mucosa. They often pose a threat for the patients to result in allergic rhinitis, sinus infections and asthma. The aim of this paper is to design a reliable rhinology assistance system for recognizing the nasal polyps in endoscopic videos. We introduce NP-80, a novel dataset that contains high-quality endoscopy video-frames of 80 participants with and without nasal polyps (NP). We benchmark vanilla machine learning and deep learning-based classifiers on the proposed dataset with respect to robustness and accuracy. We conduct a series of classification experiments and an exhaustive empirical comparison on handcrafted features (texture features-Local Binary Patterns (LBP) and shape features-Histogram of Oriented Gradients (HOG) and Convolutional Neural Network (CNN) features for recognizing nasal polyps automatically. The classification experiments are carried out by K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Random Forest (RF), Decision Tree (DT) and CNN classifiers. The best obtained precision, recall, and accuracy rates are 99%, 98%, and 98.3%, respectively. The classifier methods built with handcrafted features have shown poor recognition performance (best accuracy of %96.3) from the proposed CNN classifier (best accuracy of %98.3). The empirical results of the proposed learning techniques on NP-80 dataset are promising to support clinical decision systems. We make our dataset publicly available to encourage further research on rhinology experiments. The major research objective accomplished in this study is the creation of a high-accuracy deep learning based nasal polyps classification model using easily obtainable portable rhino fiberoscope images to be integrated into an otolaryngologist decision support system. We conclude from the research that using appropriate image processing techniques along with suitable deep learning networks allow researchers to obtain high accuracy recommendations in identifying nasal polyps. Furthermore, the results from the study encourages us to develop deep learning models for various other medical conditions.
C1 [Ay, Betul; Aydin, Galip] Firat Univ, Dept Comp Engn, Fac Engn, Elazig, Turkey.
   [Turker, Cihan] Mus State Hosp, Dept Otorhinolaryngol, Mus, Turkey.
   [Emre, Elif] Firat Univ, Dept Anat, Fac Med, Elazig, Turkey.
   [Ay, Kevser] Firat Univ, Dept Internal Med Sci, Fac Med, Elazig, Turkey.
C3 Firat University; Mus Bulanik State Hospital; Mus Malazgirt State
   Hospital; Firat University; Firat University
RP Ay, B (通讯作者)，Firat Univ, Dept Comp Engn, Fac Engn, Elazig, Turkey.
EM betulay@firat.edu.tr; cihan_turker23@hotmail.com; eemre@firat.edu.tr;
   kevseray@firat.edu.tr; gaydin@firat.edu.tr
RI AY, BETÜL/V-6868-2018
OI AY, BETUL/0000-0002-3060-0432
CR Ali S, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101900
   Bachert C, 1997, J ALLERGY CLIN IMMUN, V99, P837, DOI 10.1016/S0091-6749(97)80019-X
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bhattacharyya N, 2011, OTOLARYNG HEAD NECK, V144, P440, DOI 10.1177/0194599810391852
   Boateng E.Y., 2020, J DATA ANAL INF PROC
   Coleman C., 2017, TRAINING, V100, P102
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fokkens W, 2007, RHINOLOGY, P1
   Gupta Y., 2014, INT J ADV HEAL SCI, V1, P11
   Ho TK, 2002, PATTERN ANAL APPL, V5, P102, DOI 10.1007/s100440200009
   Jena B., MACH VISION APPL, V33, P1
   Jun YJ, 2020, AM J OTOLARYNG, V41, DOI 10.1016/j.amjoto.2020.102627
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Komorowski M., 2016, SECONDARY ANAL ELECT, DOI 10.1007/978-3-319-43742-2_15
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1990, ADV NEURAL INFORM PR, V2, P396, DOI DOI 10.1111/DSU.12130
   Liu GS, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.03.24
   Liu L, 2016, LECT NOTES COMPUT SC, V9907, P69, DOI 10.1007/978-3-319-46487-9_5
   Meltzer Eli O, 2004, J Allergy Clin Immunol, V114, P155, DOI 10.1016/j.jaci.2004.09.029
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Shariaty F., 2019, IEEE INT C EL ENG PH, P181
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Stevens WW, 2015, IMMUN INFLAMM DIS, V3, P14, DOI 10.1002/iid3.46
   Taha Bilal, 2017, Proceedings of the IASTED International Conference on Biomedical Engineering (BioMed 2017), P233, DOI 10.2316/P.2017.852-031
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tama BA, 2020, CLIN EXP OTORHINOLAR, V13, P326, DOI 10.21053/ceo.2020.00654
   Tan SB, 2006, EXPERT SYST APPL, V30, P290, DOI 10.1016/j.eswa.2005.07.019
   Tyagi V., 2019, 2019 INT C ISS CHALL, V1, P1, DOI [10.1109/ICICT46931.2019.8977658, DOI 10.1109/ICICT46931.2019.8977658]
   Viscaino M, 2019, IEEE ENG MED BIO, P961, DOI 10.1109/EMBC.2019.8857831
   Vispute M, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P735, DOI 10.1109/SPIN.2018.8474032
   Widjaja E, 2008, INT J ONCOL, V32, P653
   Wu QW, 2020, J ALLERGY CLIN IMMUN, V145, P698, DOI 10.1016/j.jaci.2019.12.002
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
NR 37
TC 7
Z9 7
U1 2
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD AUG
PY 2022
VL 147
AR 105725
DI 10.1016/j.compbiomed.2022.105725
EA JUN 2022
PG 12
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 2I1QT
UT WOS:000814759300005
PM 35716434
DA 2023-08-21
ER

PT J
AU Brown, JRG
   Mansour, NM
   Wang, P
   Chuchuca, MA
   Minchenberg, SB
   Chandnani, M
   Liu, L
   Gross, SA
   Sengupta, N
   Berzin, TM
AF Brown, Jeremy R. Glissen
   Mansour, Nabil M.
   Wang, Pu
   Chuchuca, Maria Aguilera
   Minchenberg, Scott B.
   Chandnani, Madhuri
   Liu, Lin
   Gross, Seth A.
   Sengupta, Neil
   Berzin, Tyler M.
TI Deep Learning Computer-aided Polyp Detection Reduces Adenoma Miss Rate:
   A United States Multi-center Randomized Tandem Colonoscopy Study
   (CADeT-CS Trial)
SO CLINICAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE Adenoma Detection Rate; Adenoma Miss Rate; Computer-aided Detection;
   Deep Learning; Randomized Tandem Colonoscopy Study
AB BACKGROUND & AIMS: Artificial intelligence-based computer-aided polyp detection (CADe) systems are intended to address the issue of missed polyps during colonoscopy. The effect of CADe during screening and surveillance colonoscopy has not previously been studied in a United States (U.S.) population.
   METHODS: We conducted a prospective, multi-center, single-blind randomized tandem colonoscopy study to evaluate a deep-learning based CADe system (EndoScreener, Shanghai Wision AI, China). Patients were enrolled across 4 U.S. academic medical centers from 2019 through 2020. Patients presenting for colorectal cancer screening or surveillance were randomized to CADe colonoscopy first or high-definition white light (HDWL) colonoscopy first, followed immediately by the other procedure in tandem fashion by the same endoscopist. The primary outcome was adenoma miss rate (AMR), and secondary outcomes included sessile serrated lesion (SSL) miss rate and adenomas per colonoscopy (APC).
   RESULTS: A total of 232 patients entered the study, with 116 patients randomized to undergo CADe colonoscopy first and 116 patients randomized to undergo HDWL colonoscopy first. After the exclusion of 9 patients, the study cohort included 223 patients. AMR was lower in the CADe-first group compared with the HDWL-first group (20.12% [34/169] vs 31.25% [45/144]; odds ratio [OR], 1.8048; 95% confidence interval [CI], 1.0780-3.0217; P=.0247). SSL miss rate was lower in the CADe-first group (7.14% [1/14]) vs the HDWL-first group (42.11% [8/19]; P=.0482). First-pass APC was higher in the CADe-first group (1.19 [standard deviation (SD), 2.03] vs 0.90 [SD, 1.55]; P=.0323). First-pass ADR was 50.44% in the CADe-first group and 43.64 % in the HDWL-first group (P=.3091).
   CONCLUSION: In this U.S. multicenter tandem colonoscopy randomized controlled trial, we demonstrate a decrease in AMR and SSL miss rate and an increase in first-pass APC with the use of a CADe-system when compared with HDWL colonoscopy alone.
C1 [Brown, Jeremy R. Glissen; Chuchuca, Maria Aguilera; Chandnani, Madhuri; Berzin, Tyler M.] Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Div Gastroenterol, Boston, MA 02130 USA.
   [Brown, Jeremy R. Glissen; Chuchuca, Maria Aguilera; Minchenberg, Scott B.; Chandnani, Madhuri; Berzin, Tyler M.] Harvard Med Sch, 330 Brookline Ave, Boston, MA 02130 USA.
   [Mansour, Nabil M.] Baylor Coll Med, Sect Gastroenterol & Hepatol, Houston, TX 77030 USA.
   [Wang, Pu] Sichuan Acad Med Sci, Dept Gastroenterol, Chengdu, Peoples R China.
   [Wang, Pu] Sichuan Prov Peoples Hosp, Chengdu, Peoples R China.
   [Minchenberg, Scott B.] Beth Israel Deaconess Med Ctr, Dept Internal Med, Boston, MA 02130 USA.
   [Liu, Lin] Shanghai Jiao Tong Univ, Sch Math Sci & SJTU Yale Joint Ctr Biostat & Data, Inst Nat Sci, MOE LSC, Shanghai, Peoples R China.
   [Gross, Seth A.] NYU Langone Hlth Syst, Div Gastroenterol & Hepatol, New York, NY USA.
   [Sengupta, Neil] Univ Chicago Med, Sect Gastroenterol, Chicago, IL USA.
C3 Harvard University; Beth Israel Deaconess Medical Center; Harvard
   University; Harvard Medical School; Baylor College of Medicine; Sichuan
   Provincial People's Hospital; Sichuan Provincial People's Hospital;
   Harvard University; Beth Israel Deaconess Medical Center; Shanghai Jiao
   Tong University; NYU Langone Medical Center
RP Brown, JRG (通讯作者)，Harvard Med Sch, 330 Brookline Ave, Boston, MA 02130 USA.; Brown, JRG (通讯作者)，Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Div Gastroenterol & Hepatol, 330 Brookline Ave, Boston, MA 02130 USA.
EM jglissen@bidmc.harvard.edu
OI Wang, Pu/0000-0002-1234-309X; Glissen Brown, Jeremy/0000-0002-7204-7241
FU Shanghai Municipal Science and Technology Major Project
   [2021SHZDZX0102]; Major Program of National Natural Science Foundation
   of China [12090024]; Shanghai Natural Science Foundation [21ZR1431000];
   Wision LLC
FX This was an investigator-initiated study, with research software and
   study funding provided by Wision LLC. Lin Liu gratefully acknowledges
   funding support by Shanghai Municipal Science and Technology Major
   Project No.2021SHZDZX0102, Major Program of National Natural Science
   Foundation of China No.12090024 and Shanghai Natural Science Foundation
   Grant No.21ZR1431000.
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Almansa C, 2011, AM J GASTROENTEROL, V106, P1070, DOI 10.1038/ajg.2011.26
   Anderson JC, 2019, GASTROINTEST ENDOSC, V90, P495, DOI 10.1016/j.gie.2019.05.029
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chan AW, 2013, ANN INTERN MED, V158, P200, DOI 10.7326/0003-4819-158-3-201302050-00583
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Holzwanger EA, 2021, ENDOSCOPY, V53, P937, DOI 10.1055/a-1302-2942
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Kudo T, 2018, GASTROINTEST ENDOSC, V88, P854, DOI 10.1016/j.gie.2018.06.011
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu XX, 2020, LANCET DIGIT HEALTH, V2, pE537, DOI [10.1016/S2589-7500(20)30218-1, 10.1016/S2589-7500(20)30219-3]
   Lui TKL, 2021, GASTROINTEST ENDOSC, V93, P193, DOI 10.1016/j.gie.2020.04.066
   Ngu WS, 2019, GUT, V68, P280, DOI 10.1136/gutjnl-2017-314889
   Pohl H, 2013, GASTROENTEROLOGY, V144, P74, DOI 10.1053/j.gastro.2012.09.043
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rivera SC, 2020, LANCET DIGIT HEALTH, V2, pE549, DOI [10.1016/S2589-7500(20)30219-3, 10.1136/bmj.m3210, 10.1038/s41591-020-1037-7]
   Schulz KF, 2010, J CLIN EPIDEMIOL, V63, P834, DOI [10.1136/bmj.c869, 10.1016/j.jclinepi.2010.02.005, 10.4103/0976-500X.72352, 10.1186/1741-7015-8-18, 10.1016/j.ijsu.2011.09.004, 10.1016/j.jclinepi.2010.03.004]
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
NR 26
TC 34
Z9 34
U1 6
U2 14
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1542-3565
EI 1542-7714
J9 CLIN GASTROENTEROL H
JI Clin. Gastroenterol. Hepatol.
PD JUL
PY 2022
VL 20
IS 7
BP 1499
EP +
DI 10.1016/j.cgh.2021.09.009
EA JUN 2022
PG 13
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 5A1ZV
UT WOS:000862693200022
PM 34530161
OA hybrid
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Fitting, D
   Krenzer, A
   Troya, J
   Banck, M
   Sudarevic, B
   Brand, M
   Bock, W
   Zoller, WG
   Rosch, T
   Puppe, F
   Meining, A
   Hann, A
AF Fitting, Daniel
   Krenzer, Adrian
   Troya, Joel
   Banck, Michael
   Sudarevic, Boban
   Brand, Markus
   Boeck, Wolfgang
   Zoller, Wolfram G.
   Roesch, Thomas
   Puppe, Frank
   Meining, Alexander
   Hann, Alexander
TI A video based benchmark data set (ENDOTEST) to evaluate computer-aided
   polyp detection systems
SO SCANDINAVIAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Colonoscopy; polyp; artificial intelligence; deep learning; CADe
ID ADENOMA DETECTION; VALIDATION
AB Background and aims Computer-aided polyp detection (CADe) may become a standard for polyp detection during colonoscopy. Several systems are already commercially available. We report on a video-based benchmark technique for the first preclinical assessment of such systems before comparative randomized trials are to be undertaken. Additionally, we compare a commercially available CADe system with our newly developed one. Methods ENDOTEST consisted in the combination of two datasets. The validation dataset contained 48 video-snippets with 22,856 manually annotated images of which 53.2% contained polyps. The performance dataset contained 10 full-length screening colonoscopies with 230,898 manually annotated images of which 15.8% contained a polyp. Assessment parameters were accuracy for polyp detection and time delay to first polyp detection after polyp appearance (FDT). Two CADe systems were assessed: a commercial CADe system (GI-Genius, Medtronic), and a self-developed new system (ENDOMIND). The latter being a convolutional neuronal network trained on 194,983 manually labeled images extracted from colonoscopy videos recorded in mainly six different gastroenterologic practices. Results On the ENDOTEST, both CADe systems detected all polyps in at least one image. The per-frame sensitivity and specificity in full colonoscopies was 48.1% and 93.7%, respectively for GI-Genius; and 54% and 92.7%, respectively for ENDOMIND. Median FDT of ENDOMIND with 217 ms (Inter-Quartile Range(IQR)8-1533) was significantly faster than GI-Genius with 1050 ms (IQR 358-2767, p = 0.003). Conclusions Our benchmark ENDOTEST may be helpful for preclinical testing of new CADe devices. There seems to be a correlation between a shorter FDT with a higher sensitivity and a lower specificity for polyp detection.
C1 [Fitting, Daniel; Krenzer, Adrian; Troya, Joel; Banck, Michael; Sudarevic, Boban; Brand, Markus; Meining, Alexander; Hann, Alexander] Univ Hosp Wuerzburg, Intervent & Expt Endoscopy InExEn, Internal Med 2, Wurzburg, Germany.
   [Krenzer, Adrian; Banck, Michael; Puppe, Frank] Julius Maximilians Univ, Inst Comp Sci, Artificial Intelligence & Knowledge Syst, Wurzburg, Germany.
   [Sudarevic, Boban; Zoller, Wolfram G.] Katharinenhospital, Dept Internal Med & Gastroenterol, Stuttgart, Germany.
   [Roesch, Thomas] Univ Hosp Hamburg Eppendorf, Dept Interdisciplinary Endoscopy, Hamburg, Germany.
C3 University of Wurzburg; University of Wurzburg; Klinikum Stuttgart;
   University of Hamburg; University Medical Center Hamburg-Eppendorf
RP Hann, A (通讯作者)，Univ Klinikum Wurzburg, Med Klin & Poliklin 2, Oberdurrbacher Str 6, D-97080 Wurzburg, Germany.
EM hann_a@ukw.de
OI Brand, Markus/0000-0002-3495-5206; Hann, Alexander/0000-0001-8035-3559
FU Foundation for early detection of colon cancer
FX The authors acknowledge the support by Prof. J.F. Riemann, "Stiftung
   Lebensblicke" the Foundation for early detection of colon cancer.
CR Ali S., 2020, ENDOSCOPY DIS DETECT
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Benson ME, 2010, DIGEST DIS SCI, V55, P166, DOI 10.1007/s10620-008-0703-2
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Kaminski MF, 2020, GASTROENTEROLOGY, V158, P404, DOI 10.1053/j.gastro.2019.11.026
   Krenzer Adrian, 2021, Stud Health Technol Inform, V281, P484, DOI 10.3233/SHTI210206
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Livovsky DM, 2021, GASTROINTEST ENDOSC, V94, P1099, DOI 10.1016/j.gie.2021.06.021
   Ma YT, 2021, LECT NOTES COMPUT SC, V12905, P387, DOI 10.1007/978-3-030-87240-3_37
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Pfeifer L, 2021, EUR J GASTROEN HEPAT, V33, pE662, DOI 10.1097/MEG.0000000000002209
   Redmon J., 2018, YOLOV3 INCREMENTAL I
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   Yoshida N, 2021, INT J COLORECTAL DIS, V36, P2237, DOI 10.1007/s00384-021-04006-5
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 30
TC 4
Z9 4
U1 1
U2 4
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0036-5521
EI 1502-7708
J9 SCAND J GASTROENTERO
JI Scand. J. Gastroenterol.
PD NOV 2
PY 2022
VL 57
IS 11
BP 1397
EP 1403
DI 10.1080/00365521.2022.2085059
EA JUN 2022
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 6C2IK
UT WOS:000811093400001
PM 35701020
OA hybrid
DA 2023-08-21
ER

PT J
AU Adjei, PE
   Lonseko, ZM
   Du, WJ
   Zhang, H
   Rao, NN
AF Adjei, Prince Ebenezer
   Lonseko, Zenebe Markos
   Du, Wenju
   Zhang, Han
   Rao, Nini
TI Examining the effect of synthetic data augmentation in polyp detection
   and segmentation
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Data augmentation; Polyps; Generative adversarial networks; Deep
   learning; Segmentation; Colonoscopy
ID IMAGES
AB Purpose As with several medical image analysis tasks based on deep learning, gastrointestinal image analysis is plagued with data scarcity, privacy concerns and an insufficient number of pathology samples. This study examines the generation and utility of synthetic samples of colonoscopy images with polyps for data augmentation. Methods We modify and train a pix2pix model to generate synthetic colonoscopy samples with polyps to augment the original dataset. Subsequently, we create a variety of datasets by varying the quantity of synthetic samples and traditional augmentation samples, to train a U-Net network and Faster R-CNN model for segmentation and detection of polyps, respectively. We compare the performance of the models when trained with the resulting datasets in terms of F-1 score, intersection over union, precision and recall. Further, we compare the performances of the models with unseen polyp datasets to assess their generalization ability. Results The average F-1 coefficient and intersection over union are improved with increasing number of synthetic samples in U-Net over all test datasets. The performance of the Faster R-CNN model is also improved in terms of polyp detection, while decreasing the false-negative rate. Further, the experimental results for polyp detection outperform similar studies in the literature on the ETIS-PolypLaribDB dataset. Conclusion By varying the quantity of synthetic and traditional augmentation, there is the potential to control the sensitivity of deep learning models in polyp segmentation and detection. Further, GAN-based augmentation is a viable option for improving the performance of models for polyp segmentation and detection.
C1 [Adjei, Prince Ebenezer; Lonseko, Zenebe Markos; Du, Wenju; Zhang, Han; Rao, Nini] Univ Elect Sci & Technol China, Key Lab Neuroinformat, Minist Educ, Chengdu 610054, Peoples R China.
   [Adjei, Prince Ebenezer; Lonseko, Zenebe Markos; Du, Wenju; Zhang, Han; Rao, Nini] Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu 610054, Peoples R China.
   [Adjei, Prince Ebenezer] Kwame Nkrumah Univ Sci & Technol, Dept Comp Engn, Kumasi, Ghana.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; Kwame Nkrumah University
   Science & Technology
RP Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Key Lab Neuroinformat, Minist Educ, Chengdu 610054, Peoples R China.; Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu 610054, Peoples R China.
EM raonn@uestc.edu.cn
RI Lonseko, Zenebe Markos/GRX-2495-2022
OI Lonseko, Zenebe Markos/0000-0003-0885-3406
FU National Natural Science Foundation of China [61872405, 61720106004];
   Key R&D Project of Sichuan Province [2020YFS0243]
FX The present study was funded by the National Natural Science Foundation
   of China (61872405 and 61720106004) and the Key R&D Project of Sichuan
   Province (2020YFS0243).
CR Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Ali Sharib, 2021, ARXIV210604463V1 EES
   Armanious K, 2020, COMPUT MED IMAG GRAP, V79, DOI 10.1016/j.compmedimag.2019.101684
   Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Du WJ, 2019, IEEE ACCESS, V7, P142053, DOI 10.1109/ACCESS.2019.2944676
   Goodfellow IJ, 2014, J HEALTHC ENG, V3
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   Isola P., 2017, P COMP VIS PATT REC, P5967, DOI DOI 10.1109/CVPR.2017.632
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Koehn C, 2022, DIGEST ENDOSC, V34, P191, DOI 10.1111/den.14050
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu DY, 2020, IEEE ACCESS, V8, P97907, DOI 10.1109/ACCESS.2020.2996631
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Sanchez-Peralta LF, 2020, INT J COMPUT ASS RAD, V15, P1975, DOI 10.1007/s11548-020-02262-4
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Skrede OJ, 2020, LANCET, V395, P350, DOI 10.1016/S0140-6736(19)32998-8
   Thomaz VD, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101988
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wilcox RR., 2003, APPL CONT STAT TECHN, P237, DOI [10.1016/B978-012751541-0/50029-8, DOI 10.1016/B978-012751541-0/50029-8]
   Wu J, 2021, J CLIN GASTROENTEROL, V55, P110, DOI 10.1097/MCG.0000000000001423
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 38
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD JUL
PY 2022
VL 17
IS 7
BP 1289
EP 1302
DI 10.1007/s11548-022-02651-x
EA JUN 2022
PG 14
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA 2F1PP
UT WOS:000808432900001
PM 35678960
DA 2023-08-21
ER

PT J
AU Chen, J
   Song, XX
   Huang, ZC
   Li, JQ
   Wang, ZX
   Luo, CW
   Yu, F
AF Chen, Jie
   Song, Xiaoxiao
   Huang, Zhichao
   Li, Jianqiang
   Wang, Zhaoxia
   Luo, Chengwen
   Yu, Fei
TI On-Site Colonoscopy Autodiagnosis Using Smart Internet of Medical Things
SO IEEE INTERNET OF THINGS JOURNAL
LA English
DT Article
DE Colonoscopy; Data models; Hospitals; Computational modeling; Medical
   diagnostic imaging; Internet of Things; Distributed databases;
   Colonoscopy; image segmentation; knowledge distillation; model
   compression
ID SEARCH
AB Colonoscopy screening is one of the most effective diagnostic tools for detecting intestinal diseases, such as bleeding, polyp, Meckel's diverticulum, and ulcer. However, the missed rate of manual detection is high due to the lack of experience or fatigue among clinicians. To address this issue, this work proposed a novel autodiagnosis framework built on Internet of Medical Things (IoMT) systems, which can be deployed among multiple hospitals in a distributed fusion. This work presents a two-stage knowledge distillation (TSKD) method coupled with Bayesian optimization (BO) that can exploit distributed colonoscopy data to learn a compact diagnostic model achieving a good tradeoff between predictive performance and resource consumption (e.g., memory and computation). The proposed framework is extensively evaluated in real-world data sets in comparison with its counterparts. A prototype of on-site diagnostic device is implemented to demonstrate the potential for real-world deployment.
C1 [Chen, Jie; Song, Xiaoxiao; Huang, Zhichao; Li, Jianqiang; Luo, Chengwen; Yu, Fei] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Wang, Zhaoxia] Shenzhen Childrens Hosp, Gastroenterol Dept, Shenzhen 518034, Peoples R China.
C3 Shenzhen University; Shenzhen Children's Hospital
RP Li, JQ (通讯作者)，Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.; Wang, ZX (通讯作者)，Shenzhen Childrens Hosp, Gastroenterol Dept, Shenzhen 518034, Peoples R China.
EM lijq@szu.edu.cn; wangzhaoxia1969@163.com
OI Chen, Jie/0000-0002-9811-1694
FU National Key Research and Development Program of China [2020YFA0908700];
   National Nature Science Foundation of China [U1713212, 62072315,
   62073225, 61836005, 61972263, 62006157]; Natural Science Foundation of
   Guangdong Province-Outstanding Youth Program [2019B151502018]; Natural
   Science Foundation of Guangdong Province [2019A1515011608]; Science and
   Technology Development Program of Jilin Province [20170204061SF];
   Guangdong "Pearl River Talent Recruitment Program" [2019ZT08X603];
   Shenzhen Science and Technology Innovation Commission [R2020A045];
   Public Technology Platform of Shenzhen City [GGFW2018021118145859]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFA0908700; in part by the
   National Nature Science Foundation of China under Grant U1713212, Grant
   62072315, Grant 62073225, Grant 61836005, Grant 61972263, and Grant
   62006157; in part by the Natural Science Foundation of Guangdong
   Province-Outstanding Youth Program under Grant 2019B151502018; in part
   by the Natural Science Foundation of Guangdong Province under Grant
   2019A1515011608; in part by the Science and Technology Development
   Program of Jilin Province under Grant 20170204061SF; in part by the
   Guangdong "Pearl River Talent Recruitment Program" under Grant
   2019ZT08X603; in part by the Shenzhen Science and Technology Innovation
   Commission under Grant R2020A045; and in part by the Public Technology
   Platform of Shenzhen City under Grant GGFW2018021118145859.
CR [Anonymous], 2012, P 25 INT C NEUR INF
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Cho K., 2014, P 2014 C EMP METH NA, DOI [DOI 10.3115/V1/D14-1179, 10.3115/v1/d14]
   Gatouillat A, 2018, IEEE INTERNET THINGS, V5, P3810, DOI 10.1109/JIOT.2018.2849014
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, ARXIV150302531
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Hu H., 2016, ARXIV160703250V1
   Kim Y., 2016, ARXIV151106530
   LaValle SM, 2004, INT J ROBOT RES, V23, P673, DOI 10.1177/0278364904045481
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Limaye A, 2018, IEEE INTERNET THINGS, V5, P4212, DOI 10.1109/JIOT.2018.2849859
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Nigam N, 2018, J CLIN GASTROENTEROL, V52, P721, DOI 10.1097/MCG.0000000000000937
   Nogueira F., 2014, BAYESIAN OPTIMIZATIO
   Omole PW, 2019, PAN AFR MED J, V32, DOI 10.11604/pamj.2019.32.117.16523
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Polino A., 2018, MODEL COMPRESSION VI
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P1186, DOI 10.1016/S0002-9270(03)00183-7
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Rawla P, 2019, GASTROENTEROL REV, V14, P89, DOI 10.5114/pg.2018.81072
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Rizwan P, 2017, BIOMED RES-INDIA, V28, P4979
   Romero A., 2015, PROC INT C LEARN REP
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sagar J, 2006, J ROY SOC MED, V99, P501, DOI 10.1258/jrsm.99.10.501
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Stidham RW, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3963
   Turabieh H, 2019, IEEE INTERNET THINGS, V6, P9316, DOI 10.1109/JIOT.2019.2926321
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Wu MC, 2019, INT CONF ACOUST SPEE, P2202, DOI 10.1109/ICASSP.2019.8682450
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yu XY, 2017, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.2017.15
   Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381
   Zhou ZW, 2017, PROC CVPR IEEE, P4761, DOI 10.1109/CVPR.2017.506
NR 46
TC 1
Z9 1
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2327-4662
J9 IEEE INTERNET THINGS
JI IEEE Internet Things J.
PD JUN 1
PY 2022
VL 9
IS 11
BP 8657
EP 8668
DI 10.1109/JIOT.2021.3116699
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 1M8KR
UT WOS:000800215600060
DA 2023-08-21
ER

PT J
AU Fati, SM
   Senan, EM
   Azar, AT
AF Fati, Suliman Mohamed
   Senan, Ebrahim Mohammed
   Azar, Ahmad Taher
TI Hybrid and Deep Learning Approach for Early Diagnosis of Lower
   Gastrointestinal Diseases
SO SENSORS
LA English
DT Article
DE deep learning; hybrid techniques; neural network; gastrointestinal
   diseases; LBP; GLCM; FCH; endoscope
ID IMAGES; GRAPHS
AB Every year, nearly two million people die as a result of gastrointestinal (GI) disorders. Lower gastrointestinal tract tumors are one of the leading causes of death worldwide. Thus, early detection of the type of tumor is of great importance in the survival of patients. Additionally, removing benign tumors in their early stages has more risks than benefits. Video endoscopy technology is essential for imaging the GI tract and identifying disorders such as bleeding, ulcers, polyps, and malignant tumors. Videography generates 5000 frames, which require extensive analysis and take a long time to follow all frames. Thus, artificial intelligence techniques, which have a higher ability to diagnose and assist physicians in making accurate diagnostic decisions, solve these challenges. In this study, many multi-methodologies were developed, where the work was divided into four proposed systems; each system has more than one diagnostic method. The first proposed system utilizes artificial neural networks (ANN) and feed-forward neural networks (FFNN) algorithms based on extracting hybrid features by three algorithms: local binary pattern (LBP), gray level co-occurrence matrix (GLCM), and fuzzy color histogram (FCH) algorithms. The second proposed system uses pre-trained CNN models which are the GoogLeNet and AlexNet based on the extraction of deep feature maps and their classification with high accuracy. The third proposed method uses hybrid techniques consisting of two blocks: the first block of CNN models (GoogLeNet and AlexNet) to extract feature maps; the second block is the support vector machine (SVM) algorithm for classifying deep feature maps. The fourth proposed system uses ANN and FFNN based on the hybrid features between CNN models (GoogLeNet and AlexNet) and LBP, GLCM and FCH algorithms. All the proposed systems achieved superior results in diagnosing endoscopic images for the early detection of lower gastrointestinal diseases. All systems produced promising results; the FFNN classifier based on the hybrid features extracted by GoogLeNet, LBP, GLCM and FCH achieved an accuracy of 99.3%, precision of 99.2%, sensitivity of 99%, specificity of 100%, and AUC of 99.87%.
C1 [Fati, Suliman Mohamed; Azar, Ahmad Taher] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh 11586, Saudi Arabia.
   [Senan, Ebrahim Mohammed] Dr Babasaheb Ambedkar Marathwada Univ, Dept Comp Sci & Informat Technol, Aurangabad 431004, Maharashtra, India.
   [Azar, Ahmad Taher] Benha Univ, Fac Comp & Artificial Intelligence, Banha 13518, Egypt.
C3 Prince Sultan University; Dr. Babasaheb Ambedkar Marathwada University
   (BAMU); Egyptian Knowledge Bank (EKB); Benha University
RP Fati, SM (通讯作者)，Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh 11586, Saudi Arabia.
EM smfati@yahoo.com; senan1710@gmail.com; aazar@psu.edu.sa
RI Senan, Ebrahim Mohammed/ACL-1016-2022; Fati, Suliman
   Mohamed/W-9547-2018; Azar, Ahmad Taher/O-5566-2014
OI Senan, Ebrahim Mohammed/0000-0002-7508-7601; Fati,
   Suliman/0000-0002-6969-2338; Azar, Ahmad Taher/0000-0002-7869-6373
FU Prince Sultan University
FX The authors would like to acknowledge the support of Prince Sultan
   University for paying the Article Processing Charges (APC) of this
   publication. Special acknowledgement to Automated Systems & Soft
   Computing Lab (ASSCL), Prince Sultan University, Riyadh, Saudi Arabia.
CR Ali S, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102002
   Billah M, 2018, BIOMED ENG LETT, V8, P69, DOI 10.1007/s13534-017-0048-x
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Budak U, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105765
   Chaki J., 2021, IMAGE COLOR FEATURE, P29, DOI [10.1007/978-981-15-5761-3_2, DOI 10.1007/978-981-15-5761-3_2]
   Ezzat D., 2021, MACHINE LEARNING BIG, P113, DOI 10.1007/978-3-030-59338-4_7
   Fonolla R, 2019, I S BIOMED IMAGING, P74, DOI 10.1109/ISBI.2019.8759320
   Gamage C, 2019, 2019 MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON) / 5TH INTERNATIONAL MULTIDISCIPLINARY ENGINEERING RESEARCH CONFERENCE, P66, DOI 10.1109/MERCon.2019.8818929
   Godkhindi Akshay M., 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P1722, DOI 10.1109/ICECDS.2017.8389744
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   Herrin J, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.10703
   Hmoud al-adhaileh Mosleh, 2021, Complexity, DOI 10.1155/2021/6170416
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Kim HJ, 2022, J PERS MED, V12, DOI 10.3390/jpm12040644
   Lan LB, 2019, IEEE ACCESS, V7, P30017, DOI 10.1109/ACCESS.2019.2901568
   Liaqat S, 2021, IEEE SENS J, V21, P9515, DOI 10.1109/JSEN.2021.3055898
   Liu JB, 2016, APPL MATH COMPUT, V291, P84, DOI 10.1016/j.amc.2016.06.017
   Liu JB, 2016, NEUROCOMPUTING, V198, P69, DOI 10.1016/j.neucom.2015.06.109
   Liu JB, 2016, DISCRETE APPL MATH, V200, P95, DOI 10.1016/j.dam.2015.07.001
   Liu JB, 2015, APPL MATH COMPUT, V253, P205, DOI 10.1016/j.amc.2014.12.035
   Liu MJ, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115714
   Maghsoudi O H, 2017, 2017 IEEE SIGNAL PRO, P1, DOI [DOI 10.1109/SPMB.2017.8257027, 10.1109/SPMB.2017.8257027]
   Milluzzo SM, 2021, CLIN ENDOSC, V54, P329, DOI 10.5946/ce.2020.082
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Mohammed BA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10222860
   Nudel J, 2021, SURG ENDOSC, V35, P182, DOI 10.1007/s00464-020-07378-x
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8070986
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Ozturk S, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103638
   Patel Jayeshkumar, 2021, Osteoarthr Cartil Open, V3, P100148, DOI 10.1016/j.ocarto.2021.100148
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pozdeev AA, 2019, IEEE NW RUSS YOUNG, P1216, DOI 10.1109/EIConRus.2019.8657018
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Roy RB, 2021, IEEE ACCESS, V9, P102137, DOI 10.1109/ACCESS.2021.3096864
   Saeidifar M, 2021, J DIGIT IMAGING, V34, P1209, DOI 10.1007/s10278-021-00514-6
   Senan Ebrahim Mohammed, 2022, Proceedings of Third International Conference on Sustainable Computing: SUSCOM 2021. Advances in Intelligent Systems and Computing (1404), P125, DOI 10.1007/978-981-16-4538-9_13
   Senan E.M., 2020, P INT C RECENT TREND, P14, DOI [10.1007/978-981-16-0493-5_2, DOI 10.1007/978-981-16-0493-5_2]
   Senan EM, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/8500314
   Senan EM, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/6919483
   Senan EM, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9417893
   Senan EM, 2021, J APPL SCI ENG, V24, P323, DOI 10.6180/jase.202106_24(3).0007
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Sutton RT, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06726-2
   Ueyama H, 2021, J GASTROEN HEPATOL, V36, P482, DOI 10.1111/jgh.15190
   Vleugels JLA, 2017, BEST PRACT RES CL GA, V31, P359, DOI 10.1016/j.bpg.2017.05.005
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 46
TC 15
Z9 15
U1 2
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD JUN
PY 2022
VL 22
IS 11
AR 4079
DI 10.3390/s22114079
PG 31
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA 1Z5PB
UT WOS:000808875200001
PM 35684696
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Gong, EJ
   Bang, CS
   Lee, JJ
   Seo, SI
   Yang, YJ
   Baik, GH
   Kim, JW
AF Gong, Eun Jeong
   Bang, Chang Seok
   Lee, Jae Jun
   Seo, Seung In
   Yang, Young Joo
   Baik, Gwang Ho
   Kim, Jong Wook
TI No-Code Platform-Based Deep-Learning Models for Prediction of Colorectal
   Polyp Histology from White-Light Endoscopy Images: Development and
   Performance Verification
SO JOURNAL OF PERSONALIZED MEDICINE
LA English
DT Article
DE convolutional neural network; deep learning; no code; endoscopy; polyps;
   colonoscopy; colonic neoplasms
ID ARTIFICIAL-INTELLIGENCE; CLASSIFICATION; DIAGNOSIS; SOCIETY
AB Background: The authors previously developed deep-learning models for the prediction of colorectal polyp histology (advanced colorectal cancer, early cancer/high-grade dysplasia, tubular adenoma with or without low-grade dysplasia, or non-neoplasm) from endoscopic images. While the model achieved 67.3% internal-test accuracy and 79.2% external-test accuracy, model development was labour-intensive and required specialised programming expertise. Moreover, the 240-image external-test dataset included only three advanced and eight early cancers, so it was difficult to generalise model performance. These limitations may be mitigated by deep-learning models developed using no-code platforms. Objective: To establish no-code platform-based deep-learning models for the prediction of colorectal polyp histology from white-light endoscopy images and compare their diagnostic performance with traditional models. Methods: The same 3828 endoscopic images used to establish previous models were used to establish new models based on no-code platforms Neuro-T, VLAD, and Create ML-Image Classifier. A prospective multicentre validation study was then conducted using 3818 novel images. The primary outcome was the accuracy of four-category prediction. Results: The model established using Neuro-T achieved the highest internal-test accuracy (75.3%, 95% confidence interval: 71.0-79.6%) and external-test accuracy (80.2%, 76.9-83.5%) but required the longest training time. In contrast, the model established using Create ML-Image Classifier required only 3 min for training and still achieved 72.7% (70.8-74.6%) external-test accuracy. Attention map analysis revealed that the imaging features used by the no-code deep-learning models were similar to those used by endoscopists during visual inspection. Conclusion: No-code deep-learning tools allow for the rapid development of models with high accuracy for predicting colorectal polyp histology.
C1 [Gong, Eun Jeong; Bang, Chang Seok; Seo, Seung In; Yang, Young Joo; Baik, Gwang Ho] Hallym Univ, Dept Internal Med, Coll Med, Chunchon 24253, South Korea.
   [Gong, Eun Jeong; Bang, Chang Seok; Seo, Seung In; Yang, Young Joo; Baik, Gwang Ho] Hallym Univ, Inst Liver & Digest Dis, Chunchon 24253, South Korea.
   [Gong, Eun Jeong; Bang, Chang Seok; Lee, Jae Jun] Hallym Univ, Inst New Frontier Res, Coll Med, Chunchon 24253, South Korea.
   [Bang, Chang Seok; Lee, Jae Jun] Chuncheon Sacred Heart Hosp, Div Big Data & Artificial Intelligence, Chunchon 24253, South Korea.
   [Lee, Jae Jun] Hallym Univ, Dept Anesthesiol & Pain Med, Coll Med, Chunchon 24253, South Korea.
   [Kim, Jong Wook] Inje Univ, Dept Internal Med, Ilsan Paik Hosp, Goyang 10556, South Korea.
C3 Hallym University; Hallym University; Hallym University; Hallym
   University; Inje University
RP Bang, CS (通讯作者)，Hallym Univ, Dept Internal Med, Coll Med, Chunchon 24253, South Korea.; Bang, CS (通讯作者)，Hallym Univ, Inst Liver & Digest Dis, Chunchon 24253, South Korea.; Bang, CS (通讯作者)，Hallym Univ, Inst New Frontier Res, Coll Med, Chunchon 24253, South Korea.; Bang, CS (通讯作者)，Chuncheon Sacred Heart Hosp, Div Big Data & Artificial Intelligence, Chunchon 24253, South Korea.
EM gongeun@hallym.ac.kr; csbang@hallym.ac.kr; iloveu59@hallym.or.kr;
   doctorssi@kdh.or.kr; yjyang@hallym.or.kr; baikgh@hallym.or.kr;
   jongman12@gmail.com
RI Bang, Chang SEOK/I-9689-2019
OI Seo, Seung In/0000-0003-4417-0135; Bang, Chang Seok/0000-0003-4908-5431
FU Technology Development Program - Ministry of SMEs and Startups (MSS,
   Korea) [S2931703]; Korea Technology & Information Promotion Agency for
   SMEs (TIPA) [S2931703] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This work was supported by the Technology Development Program (S2931703)
   funded by the Ministry of SMEs and Startups (MSS, Korea).
CR Almadi MA, 2015, CAN J GASTROENTEROL, V29, P304, DOI 10.1155/2015/789038
   Bagrow JP, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.296
   Bang CS, 2021, J MED INTERNET RES, V23, DOI 10.2196/25167
   Bang CS, 2020, KOR J GASTROENTEROL, V75, P120, DOI 10.4166/kjg.2020.75.3.120
   Berzin TM, 2020, GASTROINTEST ENDOSC, V92, P951, DOI 10.1016/j.gie.2020.06.035
   Cho BJ, 2020, AM J GASTROENTEROL, V115, P70, DOI 10.14309/ajg.0000000000000476
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Kaltenbach T, 2020, GASTROENTEROLOGY, V158, P1095, DOI 10.1053/j.gastro.2019.12.018
   Kandel P, 2019, CLIN ENDOSC, V52, P239, DOI 10.5946/ce.2018.136
   Kobayashi S, 2019, UNITED EUR GASTROENT, V7, P914, DOI 10.1177/2050640619845987
   Luo Gang, 2017, JMIR Res Protoc, V6, pe175, DOI 10.2196/resprot.7757
   Milluzzo SM, 2021, CLIN ENDOSC, V54, P329, DOI 10.5946/ce.2020.082
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Yang YJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44719-w
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yang YJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182014
NR 19
TC 4
Z9 4
U1 6
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4426
J9 J PERS MED
JI J. Pers. Med.
PD JUN
PY 2022
VL 12
IS 6
AR 963
DI 10.3390/jpm12060963
PG 12
WC Health Care Sciences & Services; Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; General & Internal Medicine
GA 8Z3RB
UT WOS:000933298700001
PM 35743748
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Chen, SJ
   Lu, S
   Tang, YX
   Wang, DC
   Sun, XZ
   Yi, J
   Liu, BY
   Cao, Y
   Chen, YH
   Liu, XW
AF Chen, Shuijiao
   Lu, Shuang
   Tang, Yingxin
   Wang, Dechun
   Sun, Xinzi
   Yi, Jun
   Liu, Benyuan
   Cao, Yu
   Chen, Yongheng
   Liu, Xiaowei
TI A Machine Learning-Based System for Real-Time Polyp Detection (DeFrame):
   A Retrospective Study
SO FRONTIERS IN MEDICINE
LA English
DT Article
DE artificial intelligence; convolutional neural networks; deep learning;
   colonoscopy; computer-aided detection
ID COLORECTAL-CANCER; ADENOMA DETECTION; COLONOSCOPY; STATISTICS;
   VALIDATION; RISK
AB Background and AimsRecent studies have shown that artificial intelligence-based computer-aided detection systems possess great potential in reducing the heterogeneous performance of doctors during endoscopy. However, most existing studies are based on high-quality static images available in open-source databases with relatively small data volumes, and, hence, are not applicable for routine clinical practice. This research aims to integrate multiple deep learning algorithms and develop a system (DeFrame) that can be used to accurately detect intestinal polyps in real time during clinical endoscopy. MethodsA total of 681 colonoscopy videos were collected for retrospective analysis at Xiangya Hospital of Central South University from June 2019 to June 2020. To train the machine learning (ML)-based system, 6,833 images were extracted from 48 collected videos, and 1,544 images were collected from public datasets. The DeFrame system was further validated with two datasets, consisting of 24,486 images extracted from 176 collected videos and 12,283 images extracted from 259 collected videos. The remaining 198 collected full-length videos were used for the final test of the system. The measurement metrics were sensitivity and specificity in validation dataset 1, precision, recall and F1 score in validation dataset 2, and the overall performance when tested in the complete video perspective. ResultsA sensitivity and specificity of 79.54 and 95.83%, respectively, was obtained for the DeFrame system for detecting intestinal polyps. The recall and precision of the system for polyp detection were determined to be 95.43 and 92.12%, respectively. When tested using full colonoscopy videos, the system achieved a recall of 100% and precision of 80.80%. ConclusionWe have developed a fast, accurate, and reliable DeFrame system for detecting polyps, which, to some extent, is feasible for use in routine clinical practice.
C1 [Chen, Shuijiao; Lu, Shuang; Yi, Jun; Liu, Xiaowei] Xiangya Hosp Cent South Univ, Dept Gastroenterol, Changsha, Peoples R China.
   [Chen, Shuijiao; Yi, Jun; Liu, Xiaowei] Xiangya Hosp Cent South Univ, Natl Clin Res Ctr Geriatr Disorders, Changsha, Peoples R China.
   [Chen, Shuijiao; Yi, Jun; Liu, Xiaowei] Comp Aided Diag & Treatment Digest Dis, Hunan Int Sci & Technol Cooperat Base Artificial I, Hunan, Peoples R China.
   [Tang, Yingxin] HighWise Med Technol Co Ltd, Suzhou, Peoples R China.
   [Wang, Dechun; Sun, Xinzi; Liu, Benyuan; Cao, Yu] Univ Massachusetts Lowell, Dept Comp Sci, Lowell, MA USA.
   [Chen, Yongheng] Cent South Univ, Xiangya Hosp, Natl Clin Res Ctr Geriatr Disorders, Dept Oncol, Changsha, Peoples R China.
C3 Central South University; Central South University; University of
   Massachusetts System; University of Massachusetts Lowell; Central South
   University
RP Liu, XW (通讯作者)，Xiangya Hosp Cent South Univ, Dept Gastroenterol, Changsha, Peoples R China.; Liu, XW (通讯作者)，Xiangya Hosp Cent South Univ, Natl Clin Res Ctr Geriatr Disorders, Changsha, Peoples R China.; Liu, XW (通讯作者)，Comp Aided Diag & Treatment Digest Dis, Hunan Int Sci & Technol Cooperat Base Artificial I, Hunan, Peoples R China.; Chen, YH (通讯作者)，Cent South Univ, Xiangya Hosp, Natl Clin Res Ctr Geriatr Disorders, Dept Oncol, Changsha, Peoples R China.
EM yonghenc@163.com; liuxw@csu.edu.cn
CR Adler A, 2012, CLIN GASTROENTEROL H, V10, P155, DOI 10.1016/j.cgh.2011.10.026
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Facciorusso A, 2018, CLIN GASTROENTEROL H, V16, P1209, DOI 10.1016/j.cgh.2017.11.007
   Horton N, 2016, AM J GASTROENTEROL, V111, P1330, DOI 10.1038/ajg.2016.273
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   Poon CCY, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0281-z
   Rex DK, 2008, CLIN GASTROENTEROL H, V6, P506, DOI 10.1016/j.cgh.2008.02.025
   Siegel R, 2013, CA-CANCER J CLIN, V63, P11, DOI 10.3322/caac.21166
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Torre LA, 2015, CA-CANCER J CLIN, V65, P87, DOI 10.3322/caac.21262
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang D., 2019, PREPRINT, DOI [10.48550/arXiv.1909.02477, DOI 10.48550/ARXIV.1909.02477]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang PF, 2019, PROC INT C TOOLS ART, P1252, DOI 10.1109/ICTAI.2019.00-93
   Zhang YM, 2020, 2020 IEEE/ACM 28TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI [10.1109/iwqos49365.2020.9212868, 10.1109/TransAI49837.2020.00007, 10.1007/s11053-019-09613-2]
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 30
TC 1
Z9 1
U1 2
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-858X
J9 FRONT MED-LAUSANNE
JI Front. Med.
PD MAY 31
PY 2022
VL 9
AR 852553
DI 10.3389/fmed.2022.852553
PG 8
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 2C5JS
UT WOS:000810905300001
PM 35712105
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Pascual, G
   Laiz, P
   Garcia, A
   Wenzek, H
   Vitria, J
   Segui, S
AF Pascual, Guillem
   Laiz, Pablo
   Garcia, Albert
   Wenzek, Hagen
   Vitria, Jordi
   Segui, Santi
TI Time-based self-supervised learning for Wireless Capsule Endoscopy
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE capsule endoscopy; deep learning; self-supervised learning;
   semi-supervised learning
AB State-of-the-art machine learning models, and especially deep learning ones, are significantly data-hungry; they require vast amounts of manually labeled samples to function correctly. However, in most medical imaging fields, obtaining said data can be challenging. Not only the volume of data is a problem, but also the imbalances within its classes; it is common to have many more images of healthy patients than of those with pathology. Computer-aided diagnostic systems suffer from these issues, usually over-designing their models to perform accurately. This work proposes using self-supervised learning for wireless endoscopy videos by introducing a custom-tailored method that does not initially need labels or appropriate balance. We prove that using the inferred inherent structure learned by our method, extracted from the temporal axis, improves the detection rate on several domain-specific applications even under severe imbalance. State-of-the-art results are achieved in polyp detection, with 95.00 & PLUSMN; 2.09% Area Under the Curve, and 92.77 & PLUSMN; 1.20% accuracy in the CAD-CAP dataset.
C1 [Pascual, Guillem; Laiz, Pablo; Garcia, Albert; Vitria, Jordi; Segui, Santi] Univ Barcelona UB, Dept Matemat Informat, Gran Via Corts Catalanes 585, Barcelona 08007, Spain.
   [Wenzek, Hagen] Corp Hlth Int ApS, Odense, Denmark.
C3 University of Barcelona
RP Pascual, G (通讯作者)，Univ Barcelona UB, Dept Matemat Informat, Gran Via Corts Catalanes 585, Barcelona 08007, Spain.
EM guillem.pascual@ub.edu
RI Segui, Santi/E-4860-2010; Vitria, Jordi/C-7072-2008
OI Segui, Santi/0000-0002-8603-138X; Garcia I Sanchez,
   Albert/0000-0002-5239-3737; Vitria, Jordi/0000-0003-1484-539X; Pascual,
   Guillem/0000-0003-1892-7042
FU MINECO [RTI2018-095232-B-C21, SGR 1742]; Innovate UK [104633]; Spanish
   Ministry of Universities [FPU16/06843]; NVIDIA Corporation; Innovate UK
   [104633] Funding Source: UKRI
FX This work was partially founded by MINECO Grant RTI2018-095232-B-C21,
   SGR 1742, Innovate UK project 104633, and by an FPU grant (Formacion de
   Profesorado Universitario) from the Spanish Ministry of Universities to
   Guillem Pascual (FPU16/06843) . We gratefully acknowledge the support of
   NVIDIA Corporation with the donation of the Titan Xp Pascal GPU used for
   this research.
CR Akay A, 2019, IEEE J BIOMED HEALTH, V23, P906, DOI 10.1109/JBHI.2019.2894713
   Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Attallah O, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.423
   Azizi S., 2021, ARXIV210105224
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Caroppo A, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101852
   Chen T, 2020, PR MACH LEARN RES, V119
   Cheplygina V, 2019, MED IMAGE ANAL, V54, P280, DOI 10.1016/j.media.2019.03.009
   Falcon W, ARXIV AUG 2020 ARXIV
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Guo Xiaoqing, 2022, Med Image Anal, V78, P102394, DOI 10.1016/j.media.2022.102394
   Guo XQ, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101733
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jain S, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104789
   Jain S, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104094
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Kim S.H, 2021, DIAGNOSTICS, DOI DOI 10.3390/DIAGNOSTICS11091722
   Kingma DP., 2014, P ADV NEUR INF PROC, V1050, P1
   Kundu AK, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103478
   Laiz P, 2020, COMPUT MED IMAG GRAP, V86, DOI 10.1016/j.compmedimag.2020.101794
   Laiz P, 2019, IEEE INT CONF COMP V, P399, DOI 10.1109/ICCVW.2019.00051
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Li C., 2018, JOURNE ES FRANCOPHON, V50, DOI [10.1055/s-0038-1623358, 000441, DOI 10.1055/S-0038-1623358,000441]
   Liu W., 2020, P ADV NEUR INF PROC, P1, DOI DOI 10.48550/ARXIV.2006.10029
   Liu X, 2023, IEEE T KNOWL DATA EN, V35, P857, DOI [10.1109/TCYB.2021.3064571, 10.1109/TKDE.2021.3090866, 10.1080/00207543.2021.2003462]
   Lv GL, 2011, IEEE ENG MED BIO, P6643, DOI 10.1109/IEMBS.2011.6091638
   Malagelada C, 2008, GASTROENTEROLOGY, V135, P1155, DOI 10.1053/j.gastro.2008.06.084
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32
   Nadimi ES, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106531
   Navarro F, 2021, ARXIV210506986
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   Pogorelov K, 2019, J APPL CLIN MED PHYS, V20, P141, DOI 10.1002/acm2.12662
   Rumelhart D.E., 1985, PARALLEL DISTRIBUTED, DOI [10.1016/b978-1-4832-1446-7.50035-2, DOI 10.7551/MITPRESS/5236.001.0001]
   Saier MH, 2007, WATER AIR SOIL POLL, V181, P1, DOI 10.1007/s11270-007-9372-6
   Schutt M, 2004, PEPTIDE REVOLUTION: GENOMICS, PROTEOMICS & THERAPEUTICS, P41
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sermanet P, 2018, IEEE INT CONF ROBOT, P1134
   Trasolini R, 2021, ARTIF INTELL, DOI [10.1111/den.13896, DOI 10.1111/DEN.13896]
   Tschannen M, 2015, P IEEE INT C COMP VI, P2794
   van den Oord Aaron, 2018, REPRESENTATION LEARN, DOI DOI 10.48550/ARXIV.1807.03748
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vani V, 2022, J KING SAUD UNIV-COM, V34, P3319, DOI 10.1016/j.jksuci.2020.09.008
   Vasilakakis M, 2019, EXPERT REV GASTROENT, V13, P129, DOI 10.1080/17474124.2019.1553616
   Vats A., 2021, INT C MEDICAL IMAGE, DOI 10.1007/978-3-030-87234-2_1
   Wang XL, 2019, PROC CVPR IEEE, P2561, DOI 10.1109/CVPR.2019.00267
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Wang XL, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105236
   Wenzek H., 2022, SCI REP-UK, DOI [10.21203/RS.3.RS-1278962/V1, DOI 10.21203/RS.3.RS-1278962/V1]
   Xu DJ, 2019, PROC CVPR IEEE, P10326, DOI 10.1109/CVPR.2019.01058
   Yeh J-Y, 2014, J SOFTWARE ENG APPL, V7, P422, DOI DOI 10.4236/JSEA.2014.75039
   Yuan YX, 2020, IEEE T AUTOM SCI ENG, V17, P574, DOI 10.1109/TASE.2019.2936645
   Yuan YX, 2015, IEEE INT CONF ROBOT, P1310, DOI 10.1109/ICRA.2015.7139360
NR 57
TC 2
Z9 2
U1 0
U2 6
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD JUL
PY 2022
VL 146
AR 105631
DI 10.1016/j.compbiomed.2022.105631
EA MAY 2022
PG 10
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 1W5CA
UT WOS:000806790100008
PM 35751203
OA Green Published, Green Submitted, hybrid
DA 2023-08-21
ER

PT J
AU Huang, ZH
   Zhang, XC
   Zhang, GW
   Cai, GR
AF Huang, Zhaohong
   Zhang, Xiangchen
   Zhang, Guowei
   Cai, Guorong
TI MSSA-Net: A novel multi-scale feature fusion and global self-attention
   network for lesion segmentation
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
LA English
DT Article
DE 2015 MICCAI subchallenge on automatic polyp detection dataset; ATLAS;
   CVC-ClinicDB; lesion segmentation; multiple encoders; transformer
ID POLYP DETECTION; VALIDATION
AB In medical image segmentation tasks, it is typical to adopt convolutional neural networks with a serial encoder-decoder structure. However, mainstream networks cannot simultaneously achieve sufficient extraction of global features and the fusion of multi-scale information, which may lead to unpromising results for the segmentation of pathological images. Therefore, this article proposed a novel multi-scale feature fusion and global self-attention network (MSSA-Net) for medical image segmentation. Specifically, we designed a parallel double-encoder network with a multi-scale feature fusion encoder (MS-Encoder) and a self-attention encoder (SA-Encoder). The SA-Encoder introduces the transformer's global self-attention mechanism to extract global features, and the MS-Encoder adopts atrous spatial pyramid pooling (ASPP) to realize multi-scale fusion. We have evaluated the proposed MSSA-Net using three medical segmentation datasets, covering various imaging modalities such as colonoscopy and magnetic resonance imaging. Experiments on the CVC-ClinicDC, the 2015 MICCAI subchallenge on automatic polyp detection dataset, and anatomical tracings of lesions after stroke (ATLAS) show that our MSSA-Net outperforms mainstream methods such as DoubleU-Net and TransUNet. Moreover, MSSA-Net can predict more accurate segmentation masks, especially in the case of ATLAS, which has challenging images such as multiple shadow areas and discrete lesions.
C1 [Huang, Zhaohong; Zhang, Xiangchen; Cai, Guorong] Jimei Univ, Comp Engn Coll, Xiamen, Peoples R China.
   [Zhang, Guowei] Xiamen Med Coll, Affiliated Hosp 2, Xiamen, Peoples R China.
C3 Jimei University; Xiamen Medical College
RP Cai, GR (通讯作者)，Jimei Univ, Comp Engn Coll, Xiamen, Peoples R China.; Zhang, GW (通讯作者)，Xiamen Med Coll, Affiliated Hosp 2, Xiamen, Peoples R China.
EM guoweizhang1979@163.com; guorongcai.jmu@gmail.com
RI Zhang, Guowei/HJH-0318-2022
OI Zhang, Guowei/0000-0002-6371-5455
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]
   Badrinarayanan V., SEGNET DEEP CONVOLUT
   Baldeon-Calisto M., 2018, RESU NET RESIDUAL CO, P731
   Beal J., TRANSFORMER BASED OB
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Cai XJ, 2021, IEEE INTERNET THINGS, V8, P9645, DOI 10.1109/JIOT.2020.3040019
   Cai XJ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5478
   Carion F., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-813
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   CHENL, 2018, P 2 INT C COMPUTER S
   Chollet F., 2015, KERAS PROBABILISTIC
   Cui ZH, 2021, IEEE INTERNET THINGS, V8, P12540, DOI 10.1109/JIOT.2021.3056578
   Cui ZH, 2020, IEEE T SERV COMPUT, V13, P241, DOI 10.1109/TSC.2020.2964537
   Cui ZY, 2020, IEEE INT CON MULTI, DOI [10.1109/icme46284.2020.9102712, 10.1109/TSC.2020.2964552]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Devlin J., NAACL HLT 1, P4171
   Dosovitskiy A., IMAGE IS WORTH 16X16
   Grossberg AJ, 2018, SCI DATA, V5, DOI [10.1038/s41597-018-0002-5, 10.1038/sdata.2018.173, 10.1038/sdata.2018.214]
   Hassan MU, 2020, IEEE COMMUN SURV TUT, V22, P746, DOI 10.1109/COMST.2019.2944748
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kayalibay B, 2017, ARXIV PREPRINT ARXIV
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Li YH, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5182
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo Y, 2017, IEEE INT SYMP ELEC
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Oktay O., ATTENTION U NET LEAR
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Qi KH, 2019, LECT NOTES COMPUT SC, V11766, P247, DOI 10.1007/978-3-030-32248-9_28
   Qi LY, 2016, COMPUTING, V98, P195, DOI 10.1007/s00607-014-0413-x
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salehi SSM, 2017, LECT NOTES COMPUT SC, V10541, P379, DOI 10.1007/978-3-319-67389-9_44
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Ul Hassan M, 2020, IEEE T SERV COMPUT, V13, P263, DOI 10.1109/TSC.2019.2947471
   Ul Hassan M, 2019, FUTURE GENER COMP SY, V97, P512, DOI 10.1016/j.future.2019.02.060
   Vaswani A., 2017, ADV NEURAL INFORM PR
   Wang PH, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5464
   Zhang K, 2022, IMMUNOL INVEST, V51, P1895, DOI [10.1080/08820139.2022.2077113, 10.1016/j.ins.2022.03.055, 10.1109/JIOT.2022.3145845]
   Zhang X., 2021, MULTIPLE ENCODERS NE, P524
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Y., 2021, ACM COMPUT SURV, DOI 10.1145/3490237
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
   Zhu X., DEFORMABLE DETR DEFO
NR 47
TC 0
Z9 0
U1 7
U2 35
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1532-0626
EI 1532-0634
J9 CONCURR COMP-PRACT E
JI Concurr. Comput.-Pract. Exp.
PD SEP 25
PY 2022
VL 34
IS 21
AR e7060
DI 10.1002/cpe.7060
EA MAY 2022
PG 12
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4N2JB
UT WOS:000798632700001
DA 2023-08-21
ER

PT J
AU Ainechi, D
   Misawa, M
   Barua, I
   Larsen, SLV
   Paulsen, V
   Garborg, KK
   Aabakken, L
   Tonnesen, CJ
   Loberg, M
   Kalager, M
   Kudo, SE
   Hotta, K
   Ohtsuka, K
   Saito, S
   Ikematsu, H
   Saito, Y
   Matsuda, T
   Itoh, H
   Mori, K
   Bretthauer, M
   Mori, Y
AF Ainechi, Diba
   Misawa, Masashi
   Barua, Ishita
   Larsen, Solveig Linnea Veen
   Paulsen, Vemund
   Garborg, Kjetil Kjeldstad
   Aabakken, Lars
   Tonnesen, Christer Julseth
   Loberg, Magnus
   Kalager, Mette
   Kudo, Shin-Ei
   Hotta, Kinichi
   Ohtsuka, Kazuo
   Saito, Shoichi
   Ikematsu, Hiroaki
   Saito, Yutaka
   Matsuda, Takahisa
   Itoh, Hayato
   Mori, Kensaku
   Bretthauer, Michael
   Mori, Yuichi
TI Impact of artificial intelligence on colorectal polyp detection for
   early-career endoscopists: an international comparative study
SO SCANDINAVIAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Colonoscopy; adenoma; colon cancer
ID COLONOSCOPY
AB Background Artificial intelligence (AI) for polyp detection is being introduced to colonoscopy, but there is uncertainty how this affects endoscopists' ability to detect polyps and neoplasms. We performed a video-based study to address whether AI improved the endoscopists' performance to detect polyps. Methods We established a dataset of 200 colonoscopy videos (length 5 s; 100 without polyps and 100 with one polyp). About 33 early-career endoscopists (50-400 colonoscopies performed) from 10 European countries classified each video as either 'polyp present' or 'polyp not present'. The video assessment was performed twice with a four-week interval. The first assessment was performed without any AI tool, whereas the second was performed with an AI tool for polyp detection. The primary endpoint was early-career endoscopists' sensitivity to detect polyps. Gold standard for presence and histology of polyps were confirmed by two expert endoscopists and pathologists, respectively. McNemar's test was used for statistical significance. Results There were 86 neoplastic and 14 non-neoplastic polyps (mean size 5.6 mm) in the 100 videos with polyps. Early-career endoscopists' sensitivity to detect polyps increased from 86.3% (95% confidence interval [CI]: 85.1-87.5%) to 91.7% (95%CI: 90.7-92.6%) with the AI aid (p < .0001). Their sensitivity to detect neoplastic polyps increased from 85.4% (95% CI: 84.0-86.7%) to 92.1% (95%CI: 91.1-93.1%) with the AI aid (p < .0001). Conclusion The polyp detection AI tool helped early-career endoscopists to increase their sensitivity to identify all polyps and neoplastic polyps during colonoscopy.
C1 [Ainechi, Diba; Barua, Ishita; Larsen, Solveig Linnea Veen; Garborg, Kjetil Kjeldstad; Tonnesen, Christer Julseth; Loberg, Magnus; Kalager, Mette; Bretthauer, Michael; Mori, Yuichi] Univ Oslo, Clin Effectiveness Res Grp, Oslo, Norway.
   [Ainechi, Diba; Barua, Ishita; Larsen, Solveig Linnea Veen; Tonnesen, Christer Julseth; Loberg, Magnus; Kalager, Mette; Bretthauer, Michael; Mori, Yuichi] Oslo Univ Hosp, Clin Effectiveness Res Grp, Oslo, Norway.
   [Misawa, Masashi; Kudo, Shin-Ei; Bretthauer, Michael; Mori, Yuichi] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Yokohama, Kanagawa, Japan.
   [Paulsen, Vemund; Garborg, Kjetil Kjeldstad; Aabakken, Lars; Tonnesen, Christer Julseth; Mori, Yuichi] Oslo Univ Hosp, Dept Transplantat Med, Sect Gastroenterol, Oslo, Norway.
   [Hotta, Kinichi] Shizuoka Canc Ctr, Div Endoscopy, Shizuoka, Japan.
   [Ohtsuka, Kazuo] Tokyo Med & Dent Univ, Dept Endoscopy, Tokyo, Japan.
   [Saito, Shoichi] Canc Inst Hosp, Dept Gastroenterol, Tokyo, Japan.
   [Ikematsu, Hiroaki] Natl Canc Ctr Hosp East, Dept Gastroenterol & Endoscopy, Kashiwa, Chiba, Japan.
   [Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Tokyo, Japan.
   [Matsuda, Takahisa] Toho Univ, Omori Med Ctr, Div Gastroenterol & Hepatol, Tokyo, Japan.
   [Itoh, Hayato; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
C3 University of Oslo; University of Oslo; Showa University; University of
   Oslo; Shizuoka Cancer Center; Tokyo Medical & Dental University (TMDU);
   Japanese Foundation for Cancer Research; National Cancer Center - Japan;
   National Cancer Center - Japan; Toho University; Nagoya University
RP Mori, Y (通讯作者)，Univ Oslo, Inst Hlth & Soc, Clin Effectiveness Res Grp, Oslo, Norway.; Mori, Y (通讯作者)，Oslo Univ Hosp, Dept Transplantat Med, Bygg 20,Sognsvannsveien 21, N-0372 Oslo, Norway.; Mori, Y (通讯作者)，Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, 35-1 Chigasaki Chuo, Tsuzuki 2248503, Japan.
EM yuichi.mori@medisin.uio.no
RI Misawa, Masashi/H-9004-2019; Ohtsuka, Kazuo/AAA-5139-2021
OI Misawa, Masashi/0000-0002-8520-2036; Garborg,
   Kjetil/0000-0002-5484-5995; Tonnesen, Christer
   Julseth/0000-0002-9003-433X
FU Cybernet System Corp. (Tokyo)
FX Cybernet System Corp. (Tokyo) paid the fee for the participant
   recruitment and statistical analysis. The company played no role in
   design, conduct, and analysis of the study.
CR Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Ishiyama M, 2022, GASTROINTEST ENDOSC, V95, P155, DOI 10.1016/j.gie.2021.07.022
   Kodama K, 2021, ENDOSC INT OPEN, V09, pE1472, DOI 10.1055/a-1518-6754
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Mori Y, 2021, GASTROENTEROLOGY, V161, P774, DOI 10.1053/j.gastro.2021.04.078
   Mori Y, 2021, J GASTROEN HEPATOL, V36, P7, DOI 10.1111/jgh.15339
   Nagtegaal ID, 2020, HISTOPATHOLOGY, V76, P182, DOI 10.1111/his.13975
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Xu DQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154276
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 13
TC 0
Z9 0
U1 0
U2 2
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0036-5521
EI 1502-7708
J9 SCAND J GASTROENTERO
JI Scand. J. Gastroenterol.
PD OCT 3
PY 2022
VL 57
IS 10
BP 1272
EP 1277
DI 10.1080/00365521.2022.2070436
EA MAY 2022
PG 6
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 4Y2NS
UT WOS:000801007300001
PM 35605150
OA Green Submitted, hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Kwak, MS
   Cha, JM
   Jeon, JW
   Yoon, JY
   Park, JW
AF Kwak, Min Seob
   Cha, Jae Myung
   Jeon, Jung Won
   Yoon, Jin Young
   Park, Jong Wook
TI Artificial intelligence-based measurement outperforms current methods
   for colorectal polyp size measurement
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE colonoscopy; deep learning; model; polyp size; vessel
ID SURVEILLANCE; ENDOSCOPISTS; CANCER; CONCORDANCE; POLYPECTOMY;
   COLONOSCOPY; ACCURACY; SOCIETY; IMAGES; IMPACT
AB Objectives An accurate polyp size estimation during colonoscopy is crucial to determine the surveillance interval and predict the risk of malignant progression. However, there is a high degree of subjectivity in estimating polyp size among endoscopists in clinical practice. We aimed to assess the efficacy of a novel method that uses artificial intelligence (AI) to measure the size of colon polyps and compare it with current approaches. Methods Using the W-Net model for vessel segmentation and based on retinal image datasets (DRIVE, STARE, CHASE-DB, and HRF) and colonoscopy images, we developed the bifurcation-to-bifurcation (BtoB) distance measuring method and applied it to endoscopic images. Measurements were compared with those obtained by eight endoscopists (four expert and four trainees). Diagnostic ability and reliability were evaluated using Lin's concordance correlation coefficients (CCCs) and Bland-Altman analyses. Results For both experts and trainees, visually estimated sizes of the same polyp were significantly inconsistent depending on the camera view used (P < 0.001). Bland-Altman analyses showed that there was a trend toward underestimation of the sizes of the polyps in both groups, especially for polyps larger than 10 mm. The new technique was highly accurate and reliable in measuring the size of colon polyp (CCC, 0.961; confidence interval 0.926-0.979), clearly outperforming the visual estimation and open biopsy forceps methods. Conclusion The new AI measurement method improved the accuracy and reliability of polyp size measurements in colonoscopy images. Incorporating AI might be particularly important to improve the efficiency of trainees at estimating polyp size during colonoscopy.
C1 [Kwak, Min Seob; Cha, Jae Myung; Jeon, Jung Won; Yoon, Jin Young; Park, Jong Wook] Kyung Hee Univ, Coll Med, Kyung Hee Univ Hosp Gangdong, Dept Internal Med, 892 Dongnam Ro, Seoul 05278, South Korea.
C3 Kyung Hee University; Kyung Hee University Hospital
RP Kwak, MS (通讯作者)，Kyung Hee Univ, Coll Med, Kyung Hee Univ Hosp Gangdong, Dept Internal Med, 892 Dongnam Ro, Seoul 05278, South Korea.
EM kwac63@khu.ac.kr
OI Park, Jongwook/0000-0001-7310-4028
FU Basic Science Research Program of the National Research Foundation of
   Korea (NRF) - Korean Ministry of Science, ICT, and Future Planning
   [NRF-2019R1C1C1003524]
FX THIS RESEARCH WAS supported by a grant from the Basic Science Research
   Program of the National Research Foundation of Korea (NRF), which is
   funded by the Korean Ministry of Science, ICT, and Future Planning
   (grant number NRF-2019R1C1C1003524).
CR ATKIN WS, 1992, NEW ENGL J MED, V326, P658, DOI 10.1056/NEJM199203053261002
   BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
   Bradski G, 2000, DR DOBBS J, V25, P120
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Chadebecq F, 2012, IEEE ENG MED BIO, P1478, DOI 10.1109/EMBC.2012.6346220
   Chang CY, 2010, INT J COLORECTAL DIS, V25, P655, DOI 10.1007/s00384-010-0878-9
   Chaptini L, 2014, GASTROINTEST ENDOSC, V80, P652, DOI 10.1016/j.gie.2014.01.053
   Eichenseer PJ, 2013, DIS COLON RECTUM, V56, P315, DOI 10.1097/DCR.0b013e31826dd138
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Galdran A., 2020, ARXIV 2020 200901907
   Gehan MA, 2017, PEERJ, V5, DOI 10.7717/peerj.4088
   Gopalswamy N, 1997, GASTROINTEST ENDOSC, V46, P497, DOI 10.1016/S0016-5107(97)70003-8
   Gupta S, 2020, AM J GASTROENTEROL, V115, P415, DOI 10.14309/ajg.0000000000000544
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Hyun YS, 2011, DIGEST LIVER DIS, V43, P391, DOI 10.1016/j.dld.2010.12.015
   Izzy M, 2015, WORLD J GASTROINTEST, V7, P824, DOI 10.4253/wjge.v7.i8.824
   LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051
   Morales TG, 1996, GASTROINTEST ENDOSC, V43, P25
   Moug SJ, 2010, COLORECTAL DIS, V12, P646, DOI 10.1111/j.1463-1318.2009.01870.x
   Owen CG, 2009, INVEST OPHTH VIS SCI, V50, P2004, DOI 10.1167/iovs.08-3018
   Paszke A, 2019, ADV NEUR IN, V32
   Rex DK, 2014, GASTROINTEST ENDOSC, V79, P402, DOI 10.1016/j.gie.2013.08.030
   Rutter MD, 2020, GUT, V69, P201, DOI 10.1136/gutjnl-2019-319858
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Schoen RE, 1997, GASTROINTEST ENDOSC, V46, P492, DOI 10.1016/S0016-5107(97)70002-6
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [DOI 10.3322/caac.20073, 10.3322/caac.21442]
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Turner JK, 2013, EUR J GASTROEN HEPAT, V25, P562, DOI 10.1097/MEG.0b013e32835d1f2d
NR 29
TC 10
Z9 10
U1 2
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD SEP
PY 2022
VL 34
IS 6
BP 1188
EP 1195
DI 10.1111/den.14318
EA MAY 2022
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 4H4WG
UT WOS:000797359800001
PM 35385184
DA 2023-08-21
ER

PT J
AU Huang, XD
   Zhuo, L
   Zhang, H
   Yang, Y
   Li, XG
   Zhang, J
   Wei, W
AF Huang, Xiaodong
   Zhuo, Li
   Zhang, Hui
   Yang, Yang
   Li, Xiaoguang
   Zhang, Jing
   Wei, Wei
TI Polyp segmentation network with hybrid channel-spatial attention and
   pyramid global context guided feature fusion
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Article
DE Polyp segmentation; Hybrid channel-spatial attention; Global
   context-aware pyramid feature extraction; Feature fusion
AB In clinical practice, automatic polyp segmentation from colonoscopy images is an effective assistant manner in the early detection and prevention of colorectal cancer. This paper proposed a new deep model for accurate polyp segmentation based on an encoder-decoder framework. ResNet50 is adopted as the encoder, and three functional modules are introduced to improve the performance. Firstly, a hybrid channel-spatial attention module is introduced to reweight the encoder features spatially and channel-wise, enhancing the critical features for the segmentation task while suppressing irrelevant ones. Secondly, a global context pyramid feature extraction module and a series of global context flows are proposed to extract and deliver the global context information. The former captures the multi-scale and multi-receptive-field global context information, while the latter explicitly transmits the global context information to each decoder level. Finally, a feature fusion module is designed to effectively incorporate the high-level features, low-level features, and global context information, considering the gaps between different features. These modules help the model fully exploit the global context information to deduce the complete polyp regions. Extensive experiments are conducted on five public colorectal polyp datasets. The results demonstrate that the proposed network has powerful learning and generalization capability, significantly improving segmentation accuracy and outperforming state-of-the-art methods.
C1 [Huang, Xiaodong; Zhuo, Li; Zhang, Hui; Li, Xiaoguang; Zhang, Jing] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Zhuo, Li; Zhang, Hui; Li, Xiaoguang; Zhang, Jing] Beijing Univ Technol, Beijing Key Lab Computat Intelligence & Intelligen, Beijing 100124, Peoples R China.
   [Yang, Yang; Wei, Wei] China Acad Chinese Med Sci, Wangjing Hosp, Beijing 100102, Peoples R China.
   [Huang, Xiaodong] Henan Univ Sci & Technol, Luoyang 471000, Peoples R China.
C3 Beijing University of Technology; Beijing University of Technology;
   China Academy of Chinese Medical Sciences; Wang Jing Hospital, CACMS;
   Henan University of Science & Technology
RP Zhuo, L (通讯作者)，Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM zhuoli@bjut.edu.cn
RI Huang, Xiaodong/HOH-0292-2023
OI Huang, Xiaodong/0000-0001-5644-4653
FU National Natural Science Foundation of China, China [61871006]; China
   Academy of Chinese Medical Sciences Innovation Fund, China
   [CI2021A01008]
FX Acknowledgement The work was supported by the National Natural Science
   Foundation of China, China (No. 61871006) . The work was supported by
   the China Academy of Chinese Medical Sciences Innovation Fund, China
   (CI2021A01008) .
CR Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Breier M, 2011, PROC SPIE, V7963, DOI 10.1117/12.877986
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Gross S., 2009, BILDVERARBEITUNG F R, P252
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C.-H., ARXIV PREPRINT ARXIV
   Huynh L.D., 2020, CEUR WORKSHOP PROC, V2595, P13
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia ZK, 2019, IEEE INT CONF COMM
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu YY, 2020, IEEE ACCESS, V8, P78193, DOI 10.1109/ACCESS.2020.2989807
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Mattyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372
   Ohrenstein D.C., 2020, ARXIV ARXIV201015937
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy A.G., 2018, IEEE T MED IMAGING
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tomar N.K., ARXIV PREPRINT 17235
   Khanh TLB, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175729
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wan JJ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122264
   Wang D., 2019, ARXIV ARXIV190902477
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 44
TC 1
Z9 1
U1 8
U2 27
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD JUN
PY 2022
VL 98
AR 102072
DI 10.1016/j.compmedimag.2022.102072
EA MAY 2022
PG 10
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA 1S2SY
UT WOS:000803907300004
PM 35594809
DA 2023-08-21
ER

PT J
AU Tang, CP
   Lin, TL
   Hsieh, YH
   Hsieh, CH
   Tseng, CW
   Leung, FW
AF Tang, Chia-Pei
   Lin, Tu-Liang
   Hsieh, Yu-Hsi
   Hsieh, Chen-Hung
   Tseng, Chih-Wei
   Leung, Felix W.
TI Polyp detection and false-positive rates by computer-aided analysis of
   withdrawal-phase videos of colonoscopy of the right-sided colon segment
   in a randomized controlled trial comparing water exchange and air
   insufflation
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID ADENOMA DETECTION RATE; DETECTION-ASSISTED COLONOSCOPY;
   ARTIFICIAL-INTELLIGENCE; COLORECTAL-CANCER; MISS RATE; MULTICENTER;
   ENDOSCOPY; REDUCTION; NEOPLASMS; DIAGNOSIS
AB Background and Aims: Water exchange (WE) improves lesion detection but misses polyps because of human limitations. Computer-aided detection (CADe) identifies additional polyps overlooked by the colonoscopist. Additional polyp detection rate (APDR) is the proportion of patients with at least 1 additional polyp detected by CADe. The number of false positives (because of feces and air bubble) per colonoscopy (FPPC) is a major CADe limitation, which might be reduced by salvage cleaning with WE. We compared the APDR and FPPC by CADe between videos of WE and air insufflation in the right-sided colon.
   Methods: CADe used a convolutional neural network with transfer learning. We edited and coded withdrawal-phase videos in a randomized controlled trial that compared right-sided colon findings between air insufflation and WE. Two experienced blinded endoscopists analyzed the CADe-overlaid videos and identified additional polyps by consensus. An artifact triggered by CADe but not considered a polyp by the reviewers was defined as a false positive. The primary outcome was APDR.
   Results: Two hundred forty-five coded videos of colonoscopies inserted with WE (n = 123) and air insufflation (n = 122) methods were analyzed. The APDR in the WE group was significantly higher (37 [30.1%] vs 15 [12.3%], P = .001). The mean [standard deviation] FPPC related to feces (1.78 [1.67] vs 2.09 [2.09], P = .007) and bubbles (.53 [.89] vs 1.25 [2.45], P = .001) in the WE group were significantly lower.
   Conclusions: CADe showed significantly higher APDR and lower number of FPPC related to feces and bubbles in the WE group. The results support the hypothesis that the strengths of CADe and WE complement the weaknesses of each other in optimizing polyp detection.
C1 [Tang, Chia-Pei; Hsieh, Yu-Hsi; Tseng, Chih-Wei] Buddhist Tzu Chi Med Fdn, Dalin Tzu Chi Hosp, Div Gastroenterol, Dept Internal Med, Chiayi, Taiwan.
   [Tang, Chia-Pei; Hsieh, Yu-Hsi; Tseng, Chih-Wei] Tzu Chi Univ, Sch Med, Hualien, Taiwan.
   [Lin, Tu-Liang; Hsieh, Chen-Hung] Natl Chiayi Univ, Dept Management Informat Syst, Chiayi, Taiwan.
   [Leung, Felix W.] Vet Affairs Greater Los Angeles Healthcare Syst, Sepulveda Ambulatory Care Ctr, North Hills, CA USA.
   [Leung, Felix W.] Univ Calif Los Angeles, David Geffen Sch Med, Los Angeles, CA 90095 USA.
C3 Buddhist Tzu Chi General Hospital; Dalin Tzu Chi Hospital; Tzu Chi
   University; National Chiayi University; US Department of Veterans
   Affairs; Veterans Health Administration (VHA); VA Greater Los Angeles
   Healthcare System; University of California System; University of
   California Los Angeles; University of California Los Angeles Medical
   Center; David Geffen School of Medicine at UCLA
RP Hsieh, YH (通讯作者)，Buddhist Tzu Chi Med Fdn, Dalin Tzu Chi Hosp, 2 Min Sheng Rd, Chiayi 622, Taiwan.
RI Tseng, Chih-Wei/AAP-8291-2020
OI Tseng, Chih-Wei/0000-0002-6951-4646; Tang, Chia -
   Pei/0000-0003-0687-2566; Lin, Tu-Liang/0000-0002-5008-7736
FU VA Clinical Merit; Dalin Tzu Chi Hospital, Buddhist Tzu Chi Medical
   Foundation [DTCRD109-E-11]; Ministry of Science and Technology (MOST) of
   Taiwan [109-2314-B-303-013]
FX F.W. Leung received research support for this study from VA Clinical
   Merit and ASGE Clinical Research Funds Research support for this study
   was provided by the Dalin Tzu Chi Hospital, Buddhist Tzu Chi Medical
   Foundation (DTCRD109-E-11) to C. P. Tang and Y. H. Hsieh and the
   Ministry of Science and Technology (MOST) of Taiwan (project no.
   109-2314-B-303-013) to C. P. Tang, Y. H. Hsieh. T. L. Lin, and F. W.
   Leung. All other authors disclosed no financial relationships.
CR Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Bochkovskiy A, 2004, ARXIV PREPRINT ARXIV, V2020
   Bressler B, 2007, GASTROENTEROLOGY, V132, P96, DOI 10.1053/j.gastro.2006.10.027
   Cadoni S, 2021, GASTROINTEST ENDOSC, V93, P1411, DOI 10.1016/j.gie.2020.10.011
   Cadoni S, 2017, ENDOSCOPY, V49, P456, DOI 10.1055/s-0043-101229
   Cheng CL, 2021, J CLIN GASTROENTEROL, V55, P869, DOI 10.1097/MCG.0000000000001454
   Cohen J, 2019, GASTROINTEST ENDOSC, V90, P35, DOI 10.1016/j.gie.2019.03.020
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dekker E, 2019, LANCET, V394, P1467, DOI 10.1016/S0140-6736(19)32319-0
   Desilets DJ, 2018, GASTROINTEST ENDOSC, V88, P1, DOI 10.1016/j.gie.2018.04.2333
   Gupta S, 2012, CLIN GASTROENTEROL H, V10, P1395, DOI 10.1016/j.cgh.2012.07.004
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Holzwanger EA, 2021, ENDOSCOPY, V53, P937, DOI 10.1055/a-1302-2942
   Hsieh YH, 2019, EXPERT REV GASTROENT, V13, P1153, DOI 10.1080/17474124.2019.1694903
   Hsieh YH, 2019, UNITED EUR GASTROENT, V7, P230, DOI 10.1177/2050640618817105
   Hsieh YH, 2017, GASTROINTEST ENDOSC, V86, P192, DOI 10.1016/j.gie.2016.12.005
   Hwang JH, 2020, GASTROINTEST ENDOSC, V92, P241, DOI 10.1016/j.gie.2020.05.021
   Jia H, 2017, AM J GASTROENTEROL, V112, P568, DOI 10.1038/ajg.2016.501
   Kushnir VM, 2015, AM J GASTROENTEROL, V110, P415, DOI 10.1038/ajg.2015.21
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Lavine RA, 2002, AVIAT SPACE ENVIR MD, V73, P367
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Leung FW, 2013, GASTROENTEROL CLIN N, V42, P507, DOI 10.1016/j.gtc.2013.05.006
   Leung FW, 2020, GASTROINTEST ENDOSC, V93, P86
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2021, GASTROINTEST ENDOSC, V93, P193, DOI 10.1016/j.gie.2020.04.066
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mo X, EFFICIENT APPROACH P
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rondagh EJA, 2012, GASTROINTEST ENDOSC, V75, P1218, DOI 10.1016/j.gie.2012.02.010
   Shergill AK, 2015, GASTROINTEST ENDOSC, V82, P529, DOI 10.1016/j.gie.2015.01.053
   Singh H, 2010, GASTROENTEROLOGY, V139, P1128, DOI 10.1053/j.gastro.2010.06.052
   Soetikno RM, 2008, JAMA-J AM MED ASSOC, V299, P1027, DOI 10.1001/jama.299.9.1027
   Spadaccini M, 2020, CLIN GASTROENTEROL H, V18, P1454, DOI 10.1016/j.cgh.2019.10.044
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tang CP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165315
   Tang CP, 2021, TZU CHI MED J, V33, P108, DOI 10.4103/tcmj.tcmj_88_20
   Tseng CW, 2022, TECH COLOPROCTOL, V26, P35, DOI 10.1007/s10151-021-02537-1
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wadhwa V, 2020, ENDOSC INT OPEN, V08, pE1379, DOI 10.1055/a-1223-1926
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Warm JS, 2008, HUM FACTORS, V50, P433, DOI 10.1518/001872008X312152
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
   Zhou HB, 2020, GASTROENT RES PRACT, V2020, DOI 10.1155/2020/5363827
NR 61
TC 3
Z9 3
U1 0
U2 1
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JUN
PY 2022
VL 95
IS 6
BP 1198
EP +
DI 10.1016/j.gie.2021.12.020
EA MAY 2022
PG 15
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 1S0NC
UT WOS:000803755400023
PM 34973967
DA 2023-08-21
ER

PT J
AU Minchenberg, SB
   Walradt, T
   Brown, JRG
AF Minchenberg, Scott B.
   Walradt, Trent
   Brown, Jeremy R. Glissen
TI Scoping out the future: The application of artificial intelligence to
   gastrointestinal endoscopy
SO WORLD JOURNAL OF GASTROINTESTINAL ONCOLOGY
LA English
DT Review
DE Artificial intelligence; Oncology; Gastroenterology; Endoscopy; Machine
   learning; Computer-assisted decision making; Computer-aided detection;
   Computer-aided diagnosis
ID COMPUTER-AIDED DETECTION; CONVOLUTIONAL NEURAL-NETWORK;
   COLORECTAL-CANCER INCIDENCE; POLYP DETECTION; AUTOMATIC DETECTION;
   BARRETTS NEOPLASIA; ADENOMA DETECTION; DETECTION SYSTEM; DIAGNOSIS;
   LESIONS
AB Artificial intelligence (AI) is a quickly expanding field in gastrointestinal endoscopy. Although there are a myriad of applications of AI ranging from identification of bleeding to predicting outcomes in patients with inflammatory bowel disease, a great deal of research has focused on the identification and classification of gastrointestinal malignancies. Several of the initial randomized, prospective trials utilizing AI in clinical medicine have centered on polyp detection during screening colonoscopy. In addition to work focused on colorectal cancer, AI systems have also been applied to gastric, esophageal, pancreatic, and liver cancers. Despite promising results in initial studies, the generalizability of most of these AI systems have not yet been evaluated. In this article we review recent developments in the field of AI applied to gastrointestinal oncology.
C1 [Minchenberg, Scott B.; Walradt, Trent] Beth Israel Deaconess Med Ctr, Dept Internal Med, Boston, MA 02130 USA.
   [Brown, Jeremy R. Glissen] Beth Israel Deaconess Med Ctr, Div Gastroenterol, Boston, MA 02130 USA.
   [Brown, Jeremy R. Glissen] Beth Israel Deaconess Med Ctr, Div Gastroenterol, 330 Brookline Ave, Boston, MA 02130 USA.
C3 Harvard University; Beth Israel Deaconess Medical Center; Harvard
   University; Beth Israel Deaconess Medical Center; Harvard University;
   Beth Israel Deaconess Medical Center
RP Brown, JRG (通讯作者)，Beth Israel Deaconess Med Ctr, Div Gastroenterol, 330 Brookline Ave, Boston, MA 02130 USA.
EM jglissen@bidmc.harvard.edu
OI Glissen Brown, Jeremy/0000-0002-7204-7241
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Adler SN, 2017, ANN TRANSL MED, V5, DOI 10.21037/atm.2017.03.90
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Algorry AM, 2017, PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), P516, DOI 10.1109/CSCI.2017.87
   Antioquia A.M.C., 2018, IEEE VISUAL COMMUNIC, P1, DOI 10.1109/VCIP.2018.8698672
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Behrens A, 2011, DTSCH ARZTEBL INT, V108, P313, DOI 10.3238/arztebl.2011.0313
   Bilal M, 2020, AM J GASTROENTEROL, V115, P963, DOI 10.14309/ajg.0000000000000646
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Cogan T, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103351
   Cybernet Systems Co L, 2018, ENDOBRAIN ART INT SY
   Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036
   de Groof AJ, 2020, GASTROINTEST ENDOSC, V91, P1242, DOI 10.1016/j.gie.2019.12.048
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   de Groof J, 2019, UNITED EUR GASTROENT, V7, P538, DOI 10.1177/2050640619837443
   FDA, 2021, FDA AUTH MARK 1 DEV
   Fukuda H, 2020, GASTROINTEST ENDOSC, V92, P848, DOI 10.1016/j.gie.2020.05.043
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   Hashimoto R, 2020, GASTROINTEST ENDOSC, V91, P1264, DOI 10.1016/j.gie.2019.12.049
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Huang GL, 2017, IEEE ICC
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   K Geetha, 2017, Asian Pac J Cancer Prev, V18, P1681
   Kahi CJ, 2009, CLIN GASTROENTEROL H, V7, P770, DOI 10.1016/j.cgh.2008.12.030
   Kaise M, 2015, BEST PRACT RES CL GA, V29, P575, DOI 10.1016/j.bpg.2015.05.010
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Kuwahara T, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000045
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Lieberman D, 2020, GASTROENTEROLOGY, V158, P862, DOI 10.1053/j.gastro.2019.07.052
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   Liu GS, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.03.24
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Liu XX, 2020, LANCET DIGIT HEALTH, V2, pE537, DOI [10.1016/S2589-7500(20)30218-1, 10.1016/S2589-7500(20)30219-3]
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Marcondes FO, 2018, DIGEST DIS SCI, V63, P856, DOI 10.1007/s10620-018-4947-1
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Marya NB, 2021, GASTROINTEST ENDOSC, V93, P1121, DOI 10.1016/j.gie.2020.08.024
   Marya NB, 2021, GUT, V70, P1335, DOI 10.1136/gutjnl-2020-322821
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Medtronic, 2019, MEDTR LAUNCH 1 ART I
   Minoda Y, 2020, J GASTROENTEROL, V55, P1119, DOI 10.1007/s00535-020-01725-4
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Mohan BP, 2020, ECLINICALMEDICINE, V29-30, DOI 10.1016/j.eclinm.2020.100622
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Niu PH, 2020, WORLD J GASTROENTERO, V26, DOI 10.3748/wjg.v26.i36.5408
   Ohmori M, 2020, GASTROINTEST ENDOSC, V91, P301, DOI 10.1016/j.gie.2019.09.034
   Patel N, 2018, CUREUS J MED SCIENCE, V10, DOI 10.7759/cureus.3709
   Phoa KN, 2016, GUT, V65, P555, DOI 10.1136/gutjnl-2015-309298
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rehnberg Victor, 2017, J Intensive Care Soc, V18, P71, DOI 10.1177/1751143716676822
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Repici A, 2019, GASTROENTEROLOGY, V156, P2198, DOI 10.1053/j.gastro.2019.02.001
   Saftoiu A, 2015, GASTROINTEST ENDOSC, V82, P59, DOI 10.1016/j.gie.2014.11.040
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Szegedy C., 2016, P IEEE C COMP VIS PA
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Vieira PM, 2020, MED PHYS, V47, P52, DOI 10.1002/mp.13709
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zhang X, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P439, DOI 10.1109/ICIVC.2018.8492860
   Zheng YP, 2012, AM J GASTROENTEROL, V107, P554, DOI 10.1038/ajg.2011.461
   Zhu ML, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063820
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 81
TC 3
Z9 3
U1 2
U2 6
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1948-5204
J9 WORLD J GASTRO ONCOL
JI World J. Gastrointest. Oncol.
PD MAY 15
PY 2022
VL 14
IS 5
DI 10.4251/wjgo.v14.i5.989
PG 14
WC Oncology; Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology; Gastroenterology & Hepatology
GA 1T8NR
UT WOS:000804983100004
PM 35646286
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Sivananthan, A
   Nazarian, S
   Ayaru, L
   Patel, K
   Ashrafian, H
   Darzi, A
   Patel, N
AF Sivananthan, Arun
   Nazarian, Scarlet
   Ayaru, Lakshmana
   Patel, Kinesh
   Ashrafian, Hutan
   Darzi, Ara
   Patel, Nisha
TI Does computer-aided diagnostic endoscopy improve the detection of
   commonly missed polyps? A meta-analysis
SO CLINICAL ENDOSCOPY
LA English
DT Article
DE Artificial intelligence; Colonoscopy; Colorectal neoplasms;
   Computer-aided detection
ID COLORECTAL-CANCER; ADENOMA DETECTION; COLONOSCOPY; SYSTEM; RISK
AB Background/Aims: Colonoscopy is the gold standard diagnostic method for colorectal neoplasia, allowing detection and resection of adenomatous polyps; however, significant proportions of adenomas arc missed. Computer-aided detection (CADe) systems in endoscopy are currently available to help identify lesions. Diminutive (<= 5 mm) and nonpedunculated polyps are most commonly missed. This meta-analysis aimed to assess whether CADe systems can improve the real-time detection of these commonly missed lesions.
   Methods: A comprehensive literature search was performed. Randomized controlled trials evaluating CADe systems categorized by morphology and lesion size were included. The mean number of polyps and adenomas per patient was derived. Independent proportions and their differences were calculated using DerSimonian and Laird random-effects modeling.
   Results: Seven studios, including 2,595 CADe-assisted colonoscopies and 2,622 conventional colonoscopies, were analyzed. CADe-assisted colonoscopy demonstrated an 80% increase in the mean number of diminutive adenomas detected per patient compared with conventional colonoscopy (0.31 vs. 0.17; effect size, 0.13; 95% confidence interval [CI], 0.09-0.18); it also demonstrated a 91.7% increase in the mean number of nonpedunculated adenomas detected per patient (0.32 vs. 0.19; effect size, 0.05; 95% CI, 0.02-0.07).
   Conclusions: CADe-assisted endoscopy significantly improved the detection of most commonly missed adenomas. Although this method is a potentially exciting technology, limitations still apply to current data, prompting the need for further real-time studies.
C1 [Sivananthan, Arun; Nazarian, Scarlet; Ashrafian, Hutan; Darzi, Ara; Patel, Nisha] Imperial Coll, Inst Global Hlth Innovat, London, England.
   [Sivananthan, Arun; Ayaru, Lakshmana; Ashrafian, Hutan; Darzi, Ara; Patel, Nisha] Imperial Coll NHS Healthcare Trust, Dept Surg & Canc, London W2 1NY, England.
   [Patel, Kinesh] Chelsea & Westminster NHS Healthcare Trust, Dept Gastroenterol, London, England.
C3 Imperial College London
RP Sivananthan, A (通讯作者)，Imperial Coll NHS Healthcare Trust, Dept Surg & Canc, London W2 1NY, England.
EM arun.sivananthan@nhs.net
OI Ashrafian, Hutan/0000-0003-1668-0672; Sivananthan,
   Arun/0000-0002-1649-0150
CR Anderson R, 2020, GASTROENTEROLOGY, V158, P1287, DOI 10.1053/j.gastro.2019.12.031
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Centelles Josep J, 2012, ISRN Oncol, V2012, P139268, DOI 10.5402/2012/139268
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Delavari Alireza, 2015, Middle East J Dig Dis, V7, P214
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Harlow C, 2020, THER ADV GASTROINTES, V13, DOI 10.1177/2631774520957220
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Jadad AR, 1996, CONTROL CLIN TRIALS, V17, P1, DOI 10.1016/0197-2456(95)00134-4
   James P, 2018, BMC GASTROENTEROL, V18, DOI 10.1186/s12876-018-0800-4
   Kahi CJ, 2014, GASTROENTEROLOGY, V146, P718, DOI 10.1053/j.gastro.2013.11.050
   Kim JY, 2018, AM J GASTROENTEROL, V113, P1855, DOI 10.1038/s41395-018-0210-9
   Leslie A, 2002, BRIT J SURG, V89, P845, DOI 10.1046/j.1365-2168.2002.02120.x
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1186/s13643-015-0087-2, 10.1136/bmj.b2535]
   Nazarian S, 2021, J MED INTERNET RES, V23, DOI 10.2196/27370
   Ng S, 2020, DIGEST DIS SCI, V65, P2229, DOI 10.1007/s10620-020-06049-0
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rodriguez-Diaz E, 2017, GASTROENTEROLOGY, V152, pS81, DOI 10.1016/S0016-5085(17)30619-4
   Rutter MD, 2018, GASTROENTEROLOGY, V155, P909, DOI 10.1053/j.gastro.2018.05.038
   Sivananthan A, 2020, THER ADV GASTROINTES, V13, DOI 10.1177/2631774520979591
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Vleugels JLA, 2019, GASTROENTEROLOGY, V156, P623, DOI 10.1053/j.gastro.2018.10.050
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 30
TC 4
Z9 4
U1 1
U2 1
PU KOREAN SOC GASTROINTESTINAL ENDOSCOPY
PI SEOUL
PA 2003 LG PALACE, 165-8 DONGGYO-DONG, MAPO-GU, SEOUL, 121-754, SOUTH KOREA
SN 2234-2400
EI 2234-2443
J9 CLIN ENDOSC
JI Clin. Endosc.
PD MAY
PY 2022
VL 55
IS 3
BP 355
EP 364
DI 10.5946/ce.2021.228
EA MAY 2022
PG 10
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA 2B5GX
UT WOS:000799014000001
PM 35545215
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Lux, TJ
   Banck, M
   Sassmannshausen, Z
   Troya, J
   Krenzer, A
   Fitting, D
   Sudarevic, B
   Zoller, WG
   Puppe, F
   Meining, A
   Hann, A
AF Lux, Thomas J.
   Banck, Michael
   Sassmannshausen, Zita
   Troya, Joel
   Krenzer, Adrian
   Fitting, Daniel
   Sudarevic, Boban
   Zoller, Wolfram G.
   Puppe, Frank
   Meining, Alexander
   Hann, Alexander
TI Pilot study of a new freely available computer-aided polyp detection
   system in clinical practice
SO INTERNATIONAL JOURNAL OF COLORECTAL DISEASE
LA English
DT Article
DE Colonoscopy; Polyp; Artificial intelligence; Deep learning; CADe
ID ADENOMA DETECTION; COLONOSCOPY; TRIAL
AB Purpose Computer-aided polyp detection (CADe) systems for colonoscopy are already presented to increase adenoma detection rate (ADR) in randomized clinical trials. Those commercially available closed systems often do not allow for data collection and algorithm optimization, for example regarding the usage of different endoscopy processors. Here, we present the first clinical experiences of a, for research purposes publicly available, CADe system. Methods We developed an end-to-end data acquisition and polyp detection system named EndoMind. Examiners of four centers utilizing four different endoscopy processors used EndoMind during their clinical routine. Detected polyps, ADR, time to first detection of a polyp (TFD), and system usability were evaluated (NCT05006092). Results During 41 colonoscopies, EndoMind detected 29 of 29 adenomas in 66 of 66 polyps resulting in an ADR of 41.5%. Median TFD was 130 ms (95%-CI, 80-200 ms) while maintaining a median false positive rate of 2.2% (95%-CI, 1.7-2.8%). The four participating centers rated the system using the System Usability Scale with a median of 96.3 (95%-CI, 70-100). Conclusion EndoMind's ability to acquire data, detect polyps in real-time, and high usability score indicate substantial practical value for research and clinical practice. Still, clinical benefit, measured by ADR, has to be determined in a prospective randomized controlled trial.
C1 [Lux, Thomas J.; Banck, Michael; Sassmannshausen, Zita; Troya, Joel; Krenzer, Adrian; Fitting, Daniel; Sudarevic, Boban; Meining, Alexander; Hann, Alexander] Univ Hosp Wurzburg, Intervent & Expt Endoscopy InExEn, Internal Med 2, Wurzburg, Germany.
   [Banck, Michael; Krenzer, Adrian; Puppe, Frank] Julius Maximilians Univ Wurzburg, Inst Comp Sci, Artificial Intelligence & Knowledge Syst, Wurzburg, Germany.
   [Sudarevic, Boban; Zoller, Wolfram G.] Katharinenhospital, Dept Internal Med & Gastroenterol, Stuttgart, Germany.
C3 University of Wurzburg; University of Wurzburg; Klinikum Stuttgart
RP Hann, A (通讯作者)，Univ Hosp Wurzburg, Intervent & Expt Endoscopy InExEn, Internal Med 2, Wurzburg, Germany.
EM hann_a@ukw.de
RI Lux, Thomas/GWC-6062-2022
OI Lux, Thomas/0000-0003-1049-9872; Hann, Alexander/0000-0001-8035-3559
FU Projekt DEAL; state government of Baden-Wurttemberg, Germany (Funding
   cluster "Forum Gesundheitsstandort Baden-Wurttemberg")
   [5409.0-001.01/15]; IZKF Wurzburg [F-406]; Bavarian Center for Cancer
   Research (BZKF)
FX Open Access funding enabled and organized by Projekt DEAL. The authors
   AH and WGZ receive public funding from the state government of
   Baden-Wurttemberg, Germany (Funding cluster "Forum Gesundheitsstandort
   Baden-Wurttemberg") to research and develop artificial intelligence
   applications for polyp detection in screening colonoscopy (funding
   number 5409.0-001.01/15). AM receives funding from the IZKF Wurzburg
   (funding number F-406) and the Bavarian Center for Cancer Research
   (BZKF) for further implementation and development of artificial
   intelligence for detection of (pre-) neoplastic lesions.
CR Bangor A, 2009, J USABILITY STUD, V4, P114
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Pfeifer L, 2021, EUR J GASTROEN HEPAT, V33, pE662, DOI 10.1097/MEG.0000000000002209
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Spadaccini M, 2022, GASTROINTEST ENDOSC, V95, P975, DOI 10.1016/j.gie.2021.12.031
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Troya J, 2022, ENDOSCOPY, V54, P1009, DOI 10.1055/a-1770-7353
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
NR 16
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0179-1958
EI 1432-1262
J9 INT J COLORECTAL DIS
JI Int. J. Colorectal Dis.
PD JUN
PY 2022
VL 37
IS 6
BP 1349
EP 1354
DI 10.1007/s00384-022-04178-8
EA MAY 2022
PG 6
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 1V2SI
UT WOS:000793656500003
PM 35543874
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Ohki, D
   Yamamichi, N
   Sakaguchi, Y
   Takahashi, Y
   Kageyama-Yahara, N
   Yamamichi, M
   Takeuchi, C
   Tsuji, Y
   Sakai, Y
   Sakurai, K
   Tomida, S
   Koike, K
   Fujishiro, M
AF Ohki, Daisuke
   Yamamichi, Nobutake
   Sakaguchi, Yoshiki
   Takahashi, Yu
   Kageyama-Yahara, Natsuko
   Yamamichi, Mitsue
   Takeuchi, Chihiro
   Tsuji, Yosuke
   Sakai, Yasuhiro
   Sakurai, Kouhei
   Tomida, Shuta
   Koike, Kazuhiko
   Fujishiro, Mitsuhiro
TI Transcriptome of sessile serrated adenoma/polyps is associated with
   MSI-high colorectal cancer and decreased expression of CDX2
SO CANCER MEDICINE
LA English
DT Article
DE CDX2; comprehensive gene expression analysis; microsatellite
   instability-high colorectal cancer; sessile serrated adenoma; polyp;
   transcriptome analysis
ID CONSENSUS MOLECULAR SUBTYPES; HYPERPLASTIC POLYPS; PATHWAY; COLON;
   ADENOMAS; RECOMMENDATIONS; HETEROGENEITY; MUTATION; LESIONS; UPDATE
AB The objective of this study was to elucidate the molecular background of sessile serrated adenoma/polyp (SSA/P) endoscopically resected with comprehensive gene expression analysis. Gene expression profiling was performed for 10 tumor-normal pairs of SSA/P. Cluster analysis, gene set enrichment analysis (GSEA), and consensus molecular subtype (CMS) classification of colorectal cancer (CRC) were applied to our transcriptome analysis. Unsupervised cluster analysis showed that the gene expression profile of SSA/Ps is different from that of adjacent normal epithelial cells, even in the very early stage of tumorigenesis. According to the CMS classification, our microarray data indicated that SSA/Ps were classified as CMS1. GSEA demonstrated a strong association between SSA/P and microsatellite instability-high (MSI-H) CRC (p < 10(-5)). Transcriptome analysis of five MSI-related genes (MSH2, MSH6, MLH1, PMS1, and PMS2) and five CRC-related genes (BRAF, KRAS, APC, TP53, and CDX2) showed that CDX2 expression was most severely decreased in SSA/P. Immunohistochemical staining confirmed that CDX2 protein was reduced compared with the surrounding mucosa. Direct sequencing of the BRAF gene showed that the BRAF V600E mutation was detected in only nine of 36 cases. In a mouse model, BRAF, APC, or CDX2 deficiency indicated that the gene expression pattern with loss of CDX2 is more similar to our SSA/Ps compared with those induced by BRAF or APC mutation. Transcriptome analysis of SSA/Ps showed characteristic gene expression with a strong resemblance to MSI-H CRC. Downregulation of CDX2 expression is an essential molecular mechanism involved in the initial stage of SSA/P tumorigenesis. (UMIN000027365).
C1 [Ohki, Daisuke; Yamamichi, Nobutake; Sakaguchi, Yoshiki; Takahashi, Yu; Kageyama-Yahara, Natsuko; Yamamichi, Mitsue; Takeuchi, Chihiro; Tsuji, Yosuke; Koike, Kazuhiko; Fujishiro, Mitsuhiro] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Sakai, Yasuhiro; Sakurai, Kouhei] Fujita Hlth Univ, Sch Med, Dept Joint Res Lab Clin Med, Toyoake, Aichi, Japan.
   [Tomida, Shuta] Okayama Univ Hosp, Ctr Comprehens Genom Med, Okayama, Japan.
C3 University of Tokyo; Fujita Health University; Okayama University
RP Yamamichi, N (通讯作者)，Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138655, Japan.
EM nobutakeyamamichi@gmail.com
RI Tsuji, Yosuke/IYS-9042-2023; 坂口, 賀基/IUN-9262-2023; Takahashi,
   Yu/I-4665-2015
OI Takahashi, Yu/0000-0002-3066-9501; tomida, shuta/0000-0003-3786-936X;
   Fujishiro, Mitsuhiro/0000-0002-4074-1140; Sakai,
   Yasuhiro/0000-0001-7210-9249
FU JSPS KAKENHI [JP20K16980]
FX JSPS KAKENHI, Grant/Award Number: JP20K16980
CR Ahadi M, 2021, PATHOLOGY, V53, P454, DOI 10.1016/j.pathol.2020.10.010
   Bettington M, 2013, HISTOPATHOLOGY, V62, P367, DOI 10.1111/his.12055
   Cappellesso R, 2019, PATHOL RES PRACT, V215, P957, DOI 10.1016/j.prp.2019.02.001
   Caruso M, 2009, VIRCHOWS ARCH, V454, P291, DOI 10.1007/s00428-009-0731-0
   Chan DKH, 2021, ONCOGENESIS, V10, DOI 10.1038/s41389-021-00342-x
   Cross W, 2018, NAT ECOL EVOL, V2, P1661, DOI 10.1038/s41559-018-0642-z
   Dalerba P, 2016, NEW ENGL J MED, V374, P211, DOI 10.1056/NEJMoa1506597
   Dawson H, 2014, INT J CANCER, V134, P2342, DOI 10.1002/ijc.28564
   De Sousa E Melo F, 2013, NAT MED, V19, P614, DOI 10.1038/nm.3174
   Dehghanizadeh S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192499
   Delker DA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088367
   Dienstmann R, 2017, NAT REV CANCER, V17, P79, DOI 10.1038/nrc.2016.126
   Eide PW, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16747-x
   Erlenbach-Wunscha K, 2018, ANN DIAGN PATHOL, V35, P48, DOI 10.1016/j.anndiagpath.2018.05.002
   Gonzalo DH, 2013, J PATHOL, V230, P420, DOI 10.1002/path.4200
   Guinney J, 2015, NAT MED, V21, P1350, DOI 10.1038/nm.3967
   Guo RJ, 2004, CANCER BIOL THER, V3, P593, DOI 10.4161/cbt.3.7.913
   IJspeert JEG, 2016, ENDOSCOPY, V48, P740, DOI 10.1055/s-0042-105436
   Inoue A, 2015, BRIT J CANCER, V112, P403, DOI 10.1038/bjc.2014.545
   Kahi CJ, 2015, DIGEST DIS SCI, V60, P773, DOI 10.1007/s10620-014-3449-z
   Kanth P, 2016, CANCER PREV RES, V9, P456, DOI 10.1158/1940-6207.CAPR-15-0363
   Liu C, 2017, MODERN PATHOL, V30, P1728, DOI 10.1038/modpathol.2017.92
   Mochizuka A, 2007, HISTOCHEM CELL BIOL, V128, P445, DOI 10.1007/s00418-007-0326-2
   Patai AV, 2017, PATHOL ONCOL RES, V23, P589, DOI 10.1007/s12253-016-0154-6
   Pino MS, 2010, GASTROENTEROLOGY, V138, P2059, DOI 10.1053/j.gastro.2009.12.065
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Rex DK, 2012, AM J GASTROENTEROL, V107, P1315, DOI 10.1038/ajg.2012.161
   Ross WA, 2015, GASTROINTEST ENDOSC, V81, P567, DOI 10.1016/j.gie.2014.07.030
   Rotondano G, 2015, DIGEST LIVER DIS, V47, P512, DOI 10.1016/j.dld.2015.03.005
   Sabates-Beliver J, 2007, MOL CANCER RES, V5, P1263, DOI 10.1158/1541-7786.MCR-07-0267
   Saito T, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-05226-0
   Sakamoto N, 2017, ELIFE, V6, DOI 10.7554/eLife.20331
   Sano W, 2015, ENDOSC INT OPEN, V3, pE354, DOI 10.1055/s-0034-1391948
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Snover DC, 2011, HUM PATHOL, V42, P1, DOI 10.1016/j.humpath.2010.06.002
   Vasen HFA, 2007, J MED GENET, V44, P353, DOI 10.1136/jmg.2007.048991
   Watanabe T, 2006, CANCER RES, V66, P9804, DOI 10.1158/0008-5472.CAN-06-1163
   Wu JM, 2008, AM J CLIN PATHOL, V129, P416, DOI 10.1309/603UQKM7C2KELGJU
   Yao T., 2011, STOMACH INTEST, V46, P442
   Zorzi M, 2017, GUT, V66, P1233, DOI 10.1136/gutjnl-2015-310587
NR 40
TC 2
Z9 2
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2045-7634
J9 CANCER MED-US
JI Cancer Med.
PD DEC
PY 2022
VL 11
IS 24
BP 5066
EP 5078
DI 10.1002/cam4.4810
EA MAY 2022
PG 13
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA 7D0MF
UT WOS:000792652900001
PM 35535692
OA Green Published
DA 2023-08-21
ER

PT J
AU Younas, F
   Usman, M
   Yan, WQ
AF Younas, Farah
   Usman, Muhammad
   Yan, Wei Qi
TI A deep ensemble learning method for colorectal polyp classification with
   optimized network parameters
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Colorectal Cancer; Deep learning; Ensemble learning; Prediction;
   Transfer learning; Virtual biopsy
ID CONVOLUTIONAL NEURAL-NETWORK
AB Colorectal Cancer (CRC), a leading cause of cancer-related deaths, can be abated by timely polypectomy. Computer-aided classification of polyps helps endoscopists to resect timely without submitting the sample for histology. Deep learning-based algorithms are promoted for computer-aided colorectal polyp classification. However, the existing methods do not accommodate any information on hyperparametric settings essential for model optimisation. Furthermore, unlike the polyp types, i.e., hyperplastic and adenomatous, the third type, serrated adenoma, is difficult to classify due to its hybrid nature. Moreover, automated assessment of polyps is a challenging task due to the similarities in their patterns; therefore, the strength of individual weak learners is combined to form a weighted ensemble model for an accurate classification model by establishing the optimised hyperparameters. In contrast to existing studies on binary classification, multiclass classification require evaluation through advanced measures. This study compared six existing Convolutional Neural Networks in addition to transfer learning and opted for optimum performing architecture only for ensemble models. The performance evaluation on UCI and PICCOLO dataset of the proposed method in terms of accuracy (96.3%, 81.2%), precision (95.5%, 82.4%), recall (97.2%, 81.1%), F1-score (96.3%, 81.3%) and model reliability using Cohen's Kappa Coefficient (0.94, 0.62) shows the superiority over existing models. The outcomes of experiments by other studies on the same dataset yielded 82.5% accuracy with 72.7% recall by SVM and 85.9% accuracy with 87.6% recall by other deep learning methods. The proposed method demonstrates that a weighted ensemble of optimised networks along with data augmentation significantly boosts the performance of deep learning-based CAD.
C1 [Younas, Farah; Usman, Muhammad; Yan, Wei Qi] Auckland Univ Technol, Dept Comp Sci & Software Engn, 55 Wellesley St East, Auckland 1010, New Zealand.
   [Usman, Muhammad] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol, Dept Comp Sci, Islamabad, Pakistan.
C3 Auckland University of Technology; Shaheed Zulfikar Ali Bhutto Institute
   of Science & Technology
RP Younas, F (通讯作者)，Auckland Univ Technol, Dept Comp Sci & Software Engn, 55 Wellesley St East, Auckland 1010, New Zealand.
EM kpj7505@autuni.ac.nz; musman@aut.ac.nz; weiqi.yan@aut.ac.nz
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Bauer Valerie P, 2008, Clin Colon Rectal Surg, V21, P273, DOI 10.1055/s-0028-1089942
   Bengio Y., 2007, LARGE SCALE KERNEL M, V34, P1, DOI DOI 10.1038/NATURE14539
   Brownlee, 2019, ENSEMBLE LEARNING ME
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Hsu CM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21185995
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Jha D, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102007
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kim J, 2018, PRECIS FUTURE MED, V2, P37, DOI 10.23838/pfm.2018.00030
   Kim YJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83199-9
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kopelman Y, 2019, J GASTROENTEROL COMP, V3, P101
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Y, 2011, INFORM PROCESS MANAG, V47, P617, DOI 10.1016/j.ipm.2010.11.007
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pacal I, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104003
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Poudel S, 2020, IEEE ACCESS, V8, P99227, DOI 10.1109/ACCESS.2020.2996770
   Rahman Mohammad Motiur, 2021, Informatics in Medicine Unlocked, V24, P458, DOI 10.1016/j.imu.2021.100603
   Sahiner B, 2019, MED PHYS, V46, pe1, DOI 10.1002/mp.13264
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Thany SH, 2010, ADV EXP MED BIOL, V683, P1
   Wei JW, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.3398
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 39
TC 9
Z9 9
U1 9
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD JAN
PY 2023
VL 53
IS 2
BP 2410
EP 2433
DI 10.1007/s10489-022-03689-9
EA MAY 2022
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7N9IH
UT WOS:000791874400002
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Brand, M
   Troya, J
   Krenzer, A
   Sassmannshausen, Z
   Zoller, WG
   Meining, A
   Lux, TJ
   Hann, A
AF Brand, Markus
   Troya, Joel
   Krenzer, Adrian
   Sassmannshausen, Zita
   Zoller, Wolfram G.
   Meining, Alexander
   Lux, Thomas J.
   Hann, Alexander
TI Development and evaluation of a deep learning model to improve the
   usability of polyp detection systems during interventions
SO UNITED EUROPEAN GASTROENTEROLOGY JOURNAL
LA English
DT Article
DE CADe; colonoscopy; deep learning; instrument; intervention
AB Background The efficiency of artificial intelligence as computer-aided detection (CADe) systems for colorectal polyps has been demonstrated in several randomized trials. However, CADe systems generate many distracting detections, especially during interventions such as polypectomies. Those distracting CADe detections are often induced by the introduction of snares or biopsy forceps as the systems have not been trained for such situations. In addition, there are a significant number of non-false but not relevant detections, since the polyp has already been previously detected. All these detections have the potential to disturb the examiner's work. Objectives Development and evaluation of a convolutional neuronal network that recognizes instruments in the endoscopic image, suppresses distracting CADe detections, and reliably detects endoscopic interventions. Methods A total of 580 different examination videos from 9 different centers using 4 different processor types were screened for instruments and represented the training dataset (519,856 images in total, 144,217 contained a visible instrument). The test dataset included 10 full-colonoscopy videos that were analyzed for the recognition of visible instruments and detections by a commercially available CADe system (GI Genius, Medtronic). Results The test dataset contained 153,623 images, 8.84% of those presented visible instruments (12 interventions, 19 instruments used). The convolutional neuronal network reached an overall accuracy in the detection of visible instruments of 98.59%. Sensitivity and specificity were 98.55% and 98.92%, respectively. A mean of 462.8 frames containing distracting CADe detections per colonoscopy were avoided using the convolutional neuronal network. This accounted for 95.6% of all distracting CADe detections. Conclusions Detection of endoscopic instruments in colonoscopy using artificial intelligence technology is reliable and achieves high sensitivity and specificity. Accordingly, the new convolutional neuronal network could be used to reduce distracting CADe detections during endoscopic procedures. Thus, our study demonstrates the great potential of artificial intelligence technology beyond mucosal assessment.
C1 [Brand, Markus; Troya, Joel; Krenzer, Adrian; Sassmannshausen, Zita; Meining, Alexander; Lux, Thomas J.; Hann, Alexander] Univ Hosp Wurzburg, Internal Med 2, Gastroenterol, Intervent & Expt Endoscopy InExEn, Wurzburg, Germany.
   [Krenzer, Adrian] Julius Maximilians Univ Wurzburg, Inst Comp Sci, Artificial Intelligence & Knowledge Syst, Wurzburg, Germany.
   [Zoller, Wolfram G.] Katharinen Hosp, Dept Internal Med & Gastroenterol, Stuttgart, Germany.
C3 University of Wurzburg; University of Wurzburg; Klinikum Stuttgart
RP Troya, J (通讯作者)，Univ Klinikum Wurzburg, Med Klin & Poliklin 2, Oberdurrbacher Str 6, D-97080 Wurzburg, Germany.
EM TroyaSebas_J@ukw.de
RI Lux, Thomas/GWC-6062-2022
OI Lux, Thomas/0000-0003-1049-9872; Troya, Joel/0000-0002-7992-0146; Hann,
   Alexander/0000-0001-8035-3559; Brand, Markus/0000-0002-3495-5206
FU Eva Mayr-Stihl Foundation
FX Dieter von Holtzbrinck; Eva Mayr-Stihl Foundation; Fischerwerke GmbH;
   Forum Gesundheitsstandort Baden-Wurttemberg Open access funding enabled
   and organized by Projekt DEAL.
CR Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   Hann A, 2021, UNITED EUR GASTROENT, V9, P527, DOI 10.1002/ueg2.12108
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Holzwanger EA, 2021, ENDOSCOPY, V53, P937, DOI 10.1055/a-1302-2942
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Koo CS, 2022, ENDOSCOPY, V54, P1018, DOI 10.1055/a-1701-6201
   Lu ZH, 2022, GASTROINTEST ENDOSC, V95, P1186, DOI 10.1016/j.gie.2021.11.049
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Troya J, 2022, ENDOSCOPY, V54, P1009, DOI 10.1055/a-1770-7353
   Ueyama H, 2021, J GASTROEN HEPATOL, V36, P482, DOI 10.1111/jgh.15190
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
NR 19
TC 2
Z9 2
U1 1
U2 2
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 2050-6406
EI 2050-6414
J9 UNITED EUR GASTROENT
JI United European Gastroenterol. J.
PD JUN
PY 2022
VL 10
IS 5
BP 477
EP 484
DI 10.1002/ueg2.12235
EA MAY 2022
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 2A7OO
UT WOS:000790868900001
PM 35511456
OA Green Published
DA 2023-08-21
ER

PT J
AU Biscaglia, G
   Cocomazzi, F
   Gentile, M
   Loconte, I
   Mileti, A
   Paolillo, R
   Marra, A
   Castellana, S
   Mazza, T
   Di Leo, A
   Perri, F
AF Biscaglia, Giuseppe
   Cocomazzi, Francesco
   Gentile, Marco
   Loconte, Ilaria
   Mileti, Alessia
   Paolillo, Rosa
   Marra, Antonella
   Castellana, Stefano
   Mazza, Tommaso
   Di Leo, Alfredo
   Perri, Francesco
TI Real-time, computer-aided, detection-assisted colonoscopy eliminates
   differences in adenoma detection rate between trainee and experienced
   endoscopists
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID CANCER
AB Background and study aims Adenoma detection rate (ADR) is a well-accepted quality indicator of screening colonoscopy. In recent years, the added value of artificial intelligence (AI) has been demonstrated in terms of ADR and adenoma miss rate (AMR). To date, there are no studies evaluating the impact of AI on the performance of trainee endoscopists (TEs). This study aimed to assess whether AI might eliminate any difference in ADR or AMR between TEs and experienced endoscopists (EEs).
   Patients and methods We performed a prospective observational study in 45 subjects referred for screening colonoscopy. A same-day tandem examination was carried out for each patient by a TE with the AI assistance and subsequently by an EE unaware of the lesions detected by the TE. Besides ADR and AMR, we also calculated for each subgroup of endoscopists the adenoma per colonoscopy (APC), polyp detection rate (PDR), polyp per colonoscopy (PPC) and polyp miss rate (PMR). Subgroup analyses according to size, morphology, and site were also performed.
   Results ADR, APC, PDR, and PPC of AI-supported TEs were 38%, 0.93, 62%, 1.93, respectively. The corresponding parameters for EEs were 40%, 1.07, 58%, 2.22. No significant difference was found for each analysis between the two groups (P>0.05). AMR and PMR for AI-assisted TEs were 12.5% and 13%, respectively. Sub-analyses did not show any significant difference (P>0.05) between the two categories of operators.
   Conclusions In this single-center prospective study, the possible impact of AI on endoscopist quality training was demonstrated. In the future, this could result in better efficacy of screening colonoscopy by reducing the incidence of interval or missed cancers.
C1 [Biscaglia, Giuseppe; Cocomazzi, Francesco; Gentile, Marco; Marra, Antonella; Perri, Francesco] Casa Sollievo Sofferenza Hosp, IRCCS, Div Gastroenterol & Endoscopy, San Giovanni Rotondo, Italy.
   [Loconte, Ilaria; Mileti, Alessia; Paolillo, Rosa; Di Leo, Alfredo] Univ Bari, Dept Emergency & Organ Transplantat, Sect Gastroenterol, Bari, Italy.
   [Castellana, Stefano; Mazza, Tommaso] Fdn IRCCS Casa Sollievo Sofferenza, Lab Bioinformat, San Giovanni Rotondo, Italy.
C3 IRCCS Casa Sollievo Della Sofferenza; Universita degli Studi di Bari
   Aldo Moro
RP Cocomazzi, F (通讯作者)，Casa Sollievo Sofferenza Hosp, IRCCS, Div Gastroenterol & Endoscopy, San Giovanni Rotondo, Italy.
EM francescococomazzi@gmail.com
RI Cocomazzi, Francesco/GWV-4811-2022; Mazza, Tommaso/H-6414-2016; Mazza,
   Tommaso/I-4531-2019; Castellana, Stefano/K-1965-2016
OI Mazza, Tommaso/0000-0003-0434-8533; Mazza, Tommaso/0000-0003-0434-8533;
   Castellana, Stefano/0000-0001-8688-9530
CR Barua I., ENDOSCOPY, V2021, P284
   Bisschops R., 2019, ADV IMAGING DETECTIO, V51, P1179
   Cocomazzi F., ENDOSC INT OPEN, V2021, p9 E388 E394
   Cocomazzi F., INT J COLORECTAL DIS, V2021, P1568
   Dekker E, 2019, LANCET, V394, P1467, DOI 10.1016/S0140-6736(19)32319-0
   East JE., 2016, TECHNOLOGY REV ENDOS, V48, P1045
   Hassan C., 2021, PERFORMANCE ARTIFICI, V93, P77
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Kaminski MF., 2014, EUROPEAN SOC GASTROI, V46, P449
   Krigel A, 2020, DIGEST DIS SCI, V65, P961, DOI 10.1007/s10620-019-05820-2
   Kudo S., 2008, GASTROINTEST ENDOSC, V68, pS47
   Lambert R., 2007, HIGH RESOLUTION ENDO, V39, P237
   Lambert R, 2009, GASTROINTEST ENDOSC, V70, P1182, DOI 10.1016/j.gie.2009.09.015
   Leggett B, 2010, GASTROENTEROLOGY, V138, P2088, DOI 10.1053/j.gastro.2009.12.066
   Lui TKL, GASTROINTEST ENDOSC, V2021
   MORSON B, 1974, P ROY SOC MED, V67, P451, DOI 10.1177/00359157740676P115
   Munroe CA, 2012, GASTROINTEST ENDOSC, V75, P561, DOI 10.1016/j.gie.2011.11.037
   Puig I, 2019, CURR OPIN GASTROEN, V35, P432, DOI 10.1097/MOG.0000000000000570
   Repici A., 2020, GASTROENTEROLOGY, V159
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Sinagra E., 2020, WORLD J GASTROENTERO, V26, P5918
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Williamson JM, 2003, BIOMETRICS, V59, P36, DOI 10.1111/1541-0420.00005
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zorron Cheng, 2020, GASTROINTEST TUMORS, V7, P82
NR 26
TC 2
Z9 2
U1 0
U2 0
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD MAY
PY 2022
VL 10
IS 05
BP E616
EP E621
DI 10.1055/a-1783-9678
PG 6
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA 1F2AX
UT WOS:000794976400011
PM 35571479
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Boulind, CE
   Gould, O
   Costello, B
   Allison, J
   White, P
   Ewings, P
   Wicaksono, AN
   Curtis, NJ
   Pullyblank, A
   Jayne, D
   Covington, JA
   Ratcliffe, N
   Turner, C
   Francis, NK
AF Boulind, Caroline E.
   Gould, Oliver
   Costello, Ben de Lacy
   Allison, Joanna
   White, Paul
   Ewings, Paul
   Wicaksono, Alfian N.
   Curtis, Nathan J.
   Pullyblank, Anne
   Jayne, David
   Covington, James A.
   Ratcliffe, Norman
   Turner, Claire
   Francis, Nader K.
TI Urinary Volatile Organic Compound Testing in Fast-Track Patients with
   Suspected Colorectal Cancer
SO CANCERS
LA English
DT Article
DE volatile organic compounds; colorectal cancer; fast track
ID LUNG-CANCER; METABOLITES; REFERRALS; MARKERS; BREATH
AB Simple Summary The current pathway for the investigation of possible colorectal cancer includes the use of colonoscopy. This is an invasive and unpleasant procedure, and currently, a large number of those performed are normal. Previous research has demonstrated that urinary volatile organic compounds (VOCs) can be used to detect cancer, including colorectal cancer. However, these studies have only taken place in patients already known to have cancer. This study aimed to assess the role of urinary VOC analysis in the NHS two weeks wait for cancer pathway. Three analytical techniques were used to analyze urine samples of 558 patients during the standard NHS assessment pathway. It demonstrated that gas chromatography-mass spectrometry (GCMS) has excellent sensitivity and specificity for the identification of cancer and polyps in this patient group. These results show a potential role for urinary VOC analysis in the NHS cancer screening pathway, to reduce the need for invasive colonoscopy testing. Colorectal symptoms are common but only infrequently represent serious pathology, including colorectal cancer (CRC). A large number of invasive tests are presently performed for reassurance. We investigated the feasibility of urinary volatile organic compound (VOC) testing as a potential triage tool in patients fast-tracked for assessment for possible CRC. A prospective, multi-center, observational feasibility study was performed across three sites. Patients referred to NHS fast-track pathways for potential CRC provided a urine sample that underwent Gas Chromatography-Mass Spectrometry (GC-MS), Field Asymmetric Ion Mobility Spectrometry (FAIMS), and Selected Ion Flow Tube Mass Spectrometry (SIFT-MS) analysis. Patients underwent colonoscopy and/or CT colonography and were grouped as either CRC, adenomatous polyp(s), or controls to explore the diagnostic accuracy of VOC output data supported by an artificial neural network (ANN) model. 558 patients participated with 23 (4%) CRC diagnosed. 59% of colonoscopies and 86% of CT colonographies showed no abnormalities. Urinary VOC testing was feasible, acceptable to patients, and applicable within the clinical fast track pathway. GC-MS showed the highest clinical utility for CRC and polyp detection vs. controls (sensitivity = 0.878, specificity = 0.882, AUROC = 0.896) but it is labour intensive. Urinary VOC testing and analysis are feasible within NHS fast-track CRC pathways. Clinically meaningful differences between patients with cancer, polyps, or no pathology were identified suggesting VOC analysis may have future utility as a triage tool.
C1 [Boulind, Caroline E.; Allison, Joanna; Curtis, Nathan J.; Francis, Nader K.] Yeovil Dist Hosp NHS Fdn Trust, Dept Gen Surg, Yeovil BA21 4AT, England.
   [Gould, Oliver; Costello, Ben de Lacy; White, Paul; Ratcliffe, Norman] Univ West England, Inst Biosensing Technol, Frenchay Campus,Coldharbour Lane, Bristol BS16 1QY, Avon, England.
   [White, Paul] Somerset NHS Fdn Trust, Southwest NIHR Res Design Serv, Parkfield Dr, Taunton TA1 5DA, Somerset, England.
   [Wicaksono, Alfian N.; Covington, James A.] Univ Warwick, Sch Engn, Coventry CV4 7AL, W Midlands, England.
   [Pullyblank, Anne] North Bristol NHS Fdn Trust, Dept Surg, Bristol BS10 5NB, Avon, England.
   [Jayne, David] Leeds Teaching Hosp NHS Trust, St Jamess Univ Hosp, John Goligher Colorectal Surg Unit, Leeds LS9 7TF, W Yorkshire, England.
   [Jayne, David] Univ Leeds, St Jamess Univ Hosp, Clin Sci Bldg, Leeds LS9 7TF, W Yorkshire, England.
   [Turner, Claire] Brunel Univ, Coll Hlth Med & Life Sci, Lane, Uxbridge UB8 3PH, Middx, England.
   [Francis, Nader K.] UCL, Div Surg & Intervent Sci, London NW3 2PF, England.
C3 University of West England; University of Warwick; N8 Research
   Partnership; White Rose University Consortium; University of Leeds;
   Saint James's University Hospital; N8 Research Partnership; White Rose
   University Consortium; University of Leeds; Saint James's University
   Hospital; Brunel University; University of London; University College
   London
RP Francis, NK (通讯作者)，Yeovil Dist Hosp NHS Fdn Trust, Dept Gen Surg, Yeovil BA21 4AT, England.; Francis, NK (通讯作者)，UCL, Div Surg & Intervent Sci, London NW3 2PF, England.
EM caroline.boulind@nhs.net; oliver.gould@uwe.ac.uk;
   ben.delacycostello@uwe.ac.uk; joanna.allison@ydh.nhs.uk;
   paul.white@uwe.ac.uk; paul.ewings@somersetft.nhs.uk;
   a.wicaksono@warwick.ac.uk; nathan.curtis@ydh.nhs.uk;
   anne.pullyblank@nbt.nhs.uk; d.g.jayne@leeds.ac.uk;
   j.a.covington@warwick.ac.uk; norman.ratcliffe@uwe.ac.uk;
   claire.turner@brunel.ac.uk; nader.francis@ydh.nhs.uk
RI Covington, James A./Q-1934-2018; De Lacy Costello, Ben/I-8259-2019
OI Covington, James A./0000-0003-1307-6488; Wicaksono,
   Alfian/0000-0003-0425-1678; White, Paul/0000-0002-7503-9896; de Lacy
   Costello, Ben/0000-0003-2999-6801; Jayne, David/0000-0002-8725-3283;
   Francis, Nader/0000-0001-8498-9175
FU National Institute for Health Research, Research for Patient Benefit
   Scheme [PB-PG-0416-20022]; National Institutes of Health Research (NIHR)
   [PB-PG-0416-20022] Funding Source: National Institutes of Health
   Research (NIHR)
FX This research was funded by the National Institute for Health Research,
   Research for Patient Benefit Scheme grant number PB-PG-0416-20022.
CR Altomare DF, 2013, BRIT J SURG, V100, P144, DOI 10.1002/bjs.8942
   Altomare DF, 2015, ANN SURG, V262, P862, DOI 10.1097/SLA.0000000000001471
   [Anonymous], NATL INSTITUE HEATH
   Arasaradnam RP, 2016, DIGEST LIVER DIS, V48, P148, DOI 10.1016/j.dld.2015.10.013
   Arasaradnam RP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108750
   Arasaradnam RP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107312
   Astin Margaret, 2011, Br J Gen Pract, V61, pe231, DOI 10.3399/bjgp11X572427
   Bloor RN, 2006, ADDICT BIOL, V11, P163, DOI 10.1111/j.1369-1600.2006.00015.x
   da Costa BRB, 2020, CLIN MASS SPECTROM, V18, P27, DOI 10.1016/j.clinms.2020.10.004
   Costello BD, 2014, J BREATH RES, V8, DOI 10.1088/1752-7155/8/1/014001
   Covington JA, 2015, ANALYST, V14, P6775, DOI 10.1039/c5an00868a
   D'Souza N, 2021, GUT, V70, P1130, DOI 10.1136/gutjnl-2020-321956
   Di Lena M, 2016, COLORECTAL DIS, V18, P654, DOI 10.1111/codi.13271
   Dinges SS, 2019, NAT REV UROL, V16, P339, DOI 10.1038/s41585-019-0185-3
   Ford AC, 2008, GUT, V57, P1545, DOI 10.1136/gut.2008.159723
   Francis NK, 2015, TECH COLOPROCTOL, V19, P419, DOI 10.1007/s10151-015-1319-0
   Hanna GB, 2019, JAMA ONCOL, V5, DOI 10.1001/jamaoncol.2018.2815
   Hashimoto DA, 2018, ANN SURG, V268, P70, DOI 10.1097/SLA.0000000000002693
   Huang JZ, 2013, ANAL CHEM, V85, P3409, DOI 10.1021/ac4000656
   Jellema Petra, 2010, BMJ, V340, pc1269, DOI 10.1136/bmj.c1269
   LeCun Y., 2015, NATURE, V521, P444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Leuraud K, 2013, CANCER EPIDEMIOL, V37, P959, DOI 10.1016/j.canep.2013.07.008
   Logan RFA, 2012, GUT, V61, P1439, DOI 10.1136/gutjnl-2011-300843
   Malila Nea, 2008, BMJ, V337, pa2261, DOI 10.1136/bmj.a2261
   Markar SR, 2018, JAMA ONCOL, V4, P970, DOI 10.1001/jamaoncol.2018.0991
   Michalcikova RB, 2016, INT J MASS SPECTROM, V396, P35, DOI 10.1016/j.ijms.2015.12.007
   Mozdiak E, 2019, TECH COLOPROCTOL, V23, P343, DOI 10.1007/s10151-019-01963-6
   NHS Digital, HOSP ADMITTED PATIEN
   Opitz P, 2018, J OTOLARYNGOL-HEAD N, V47, DOI 10.1186/s40463-018-0288-5
   Patel SG, 2014, CLIN GASTROENTEROL H, V12, P7, DOI 10.1016/j.cgh.2013.04.027
   Phillips M, 1999, LANCET, V353, P1930, DOI 10.1016/S0140-6736(98)07552-7
   Porto-Figueira P, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31380-y
   Porto-Figueira P, 2018, ANAL CHIM ACTA, V1023, P53, DOI 10.1016/j.aca.2018.04.027
   Riordan H.D., 2003, J ORTHOMOL MED, V18, P41
   Royle TJ, 2014, COLORECTAL DIS, V16, pO176, DOI 10.1111/codi.12508
   Silva CL, 2019, METABOLOMICS, V15, DOI 10.1007/s11306-019-1525-2
   Sun T, 2019, SENSOR ACTUAT B-CHEM, V298, DOI 10.1016/j.snb.2019.126926
   Thompson M, 2020, BMJ-BRIT MED J, V371, DOI 10.1136/bmj.m3273
   Vaughan-Shaw PG, 2013, COLORECTAL DIS, V15, P292, DOI 10.1111/j.1463-1318.2012.03173.x
   Wen Q, 2021, METABOLITES, V11, DOI 10.3390/metabo11010017
NR 40
TC 4
Z9 4
U1 3
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-6694
J9 CANCERS
JI Cancers
PD MAY
PY 2022
VL 14
IS 9
AR 2127
DI 10.3390/cancers14092127
PG 12
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA 1E7TF
UT WOS:000794685300001
PM 35565258
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Chen, SW
   Urban, G
   Baldi, P
AF Chen, Siwei
   Urban, Gregor
   Baldi, Pierre
TI Weakly Supervised Polyp Segmentation in Colonoscopy Images Using Deep
   Neural Networks
SO JOURNAL OF IMAGING
LA English
DT Article
DE machine learning; deep learning; convolutional neural networks;
   colorectal cancer; colonoscopy quality improvement
ID COLORECTAL POLYPS; ENDOSCOPY
AB Colorectal cancer (CRC) is a leading cause of mortality worldwide, and preventive screening modalities such as colonoscopy have been shown to noticeably decrease CRC incidence and mortality. Improving colonoscopy quality remains a challenging task due to limiting factors including the training levels of colonoscopists and the variability in polyp sizes, morphologies, and locations. Deep learning methods have led to state-of-the-art systems for the identification of polyps in colonoscopy videos. In this study, we show that deep learning can also be applied to the segmentation of polyps in real time, and the underlying models can be trained using mostly weakly labeled data, in the form of bounding box annotations that do not contain precise contour information. A novel dataset, Polyp-Box-Seg of 4070 colonoscopy images with polyps from over 2000 patients, is collected, and a subset of 1300 images is manually annotated with segmentation masks. A series of models is trained to evaluate various strategies that utilize bounding box annotations for segmentation tasks. A model trained on the 1300 polyp images with segmentation masks achieves a dice coefficient of 81.52%, which improves significantly to 85.53% when using a weakly supervised strategy leveraging bounding box images. The Polyp-Box-Seg dataset, together with a real-time video demonstration of the segmentation system, are publicly available.
C1 [Chen, Siwei; Urban, Gregor; Baldi, Pierre] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
   [Chen, Siwei; Urban, Gregor; Baldi, Pierre] Univ Calif Irvine, Inst Genom & Bioinformat, Irvine, CA 92697 USA.
   [Baldi, Pierre] Univ Calif Irvine, Ctr Machine Learning & Intelligent Syst, Irvine, CA 92697 USA.
C3 University of California System; University of California Irvine;
   University of California System; University of California Irvine;
   University of California System; University of California Irvine
RP Baldi, P (通讯作者)，Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.; Baldi, P (通讯作者)，Univ Calif Irvine, Inst Genom & Bioinformat, Irvine, CA 92697 USA.; Baldi, P (通讯作者)，Univ Calif Irvine, Ctr Machine Learning & Intelligent Syst, Irvine, CA 92697 USA.
EM siweic@uci.edu; gurban@uci.edu; pfbaldi@uci.edu
OI Baldi, Pierre/0000-0001-8752-4664
FU NIH [GM123558, R01-EB029751]; NSF NRT [1633631]
FX This work was supported in part by grants NIH GM123558, NSF NRT 1633631,
   and NIH R01-EB029751 to Pierre Baldi.
CR Anderson JC, 2015, CLIN TRANSL GASTROEN, V6, DOI 10.1038/ctg.2015.5
   [Anonymous], COLORECTAL CANC STAT
   [Anonymous], 2017, P IEEE INT C COMPUTE
   Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412
   Baldi P, 2021, DEEP LEARNING SCI
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Byrne MF, 2017, GASTROINTEST ENDOSC, V85, pAB364, DOI 10.1016/j.gie.2017.03.843
   Chang P, 2018, AM J NEURORADIOL, V39, P1201, DOI 10.3174/ajnr.A5667
   Dai J, 2015, ARXIV
   Forsberg A, 2020, CLIN GASTROENTEROL H, V18, P2724, DOI 10.1016/j.cgh.2020.06.010
   Girshick R., 2015, P IEEE INT C COMP VI
   Girshick R.B., 2013, ARXIV
   Guo YB, 2020, J IMAGING, V6, DOI 10.3390/jimaging6070069
   Han X., 2019, ARXIV, DOI [10.1109/TPAMI.2019.2954885, DOI 10.1109/TPAMI.2019.2954885]
   Hassan H, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105123
   He K., 2016, PROC IEEE C COMP VIS, P770, DOI [DOI 10.48550/ARXIV.1512.03385, 10.48550/arXiv.1512.03385]
   Jha D., 2019, P 2019 IEEE INT S MU
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lee J, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000007468
   Lee YM, 2017, CLIN ENDOSC, V50, P254, DOI 10.5946/ce.2016.115
   Li R, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020298
   Li TB, 2016, GASTROINTEST ENDOSC, V83, pAB482, DOI 10.1016/j.gie.2016.03.671
   Long J., 2014, ARXIV
   Macken E, 2019, ENDOSC INT OPEN, V7, pE717, DOI 10.1055/a-0751-2660
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Meng J, 2020, OPEN LIFE SCI, V15, P588, DOI 10.1515/biol-2020-0055
   Mylonaki M, 2003, GUT, V52, P1122, DOI 10.1136/gut.52.8.1122
   Nguyen NQ, 2020, IEEE ACCESS, V8, P99495, DOI 10.1109/ACCESS.2020.2995630
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Redmon J., 2015, ARXIV
   Riegler M, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3079765
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seitz S. M., 2006, P IEEE COMP SOC C CO, V1, P519
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tavanapong W, 2020, COMP MED SY, P13, DOI 10.1109/CBMS49503.2020.00010
   Tomar N.K., 2022, ARXIV, DOI [10.1109/TNNLS.2022.3159394, DOI 10.1109/TNNLS.2022.3159394]
   Troelsen FS, 2022, CLIN GASTROENTEROL H, V20, pE984, DOI 10.1016/j.cgh.2021.05.039
   Urban G, 2021, LASER SURG MED, V53, P171, DOI 10.1002/lsm.23324
   Urban G, 2019, IEEE ACM T COMPUT BI, V16, P1029, DOI 10.1109/TCBB.2018.2841396
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D., 2016, ARXIV, DOI [10.1155/2017/4037190, DOI 10.1155/2017/4037190]
   Wang J, 2017, IEEE T MED IMAGING, V36, P1172, DOI 10.1109/TMI.2017.2655486
   Wang J, 2017, COMPUT BIOL MED, V84, P137, DOI 10.1016/j.compbiomed.2017.03.024
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
NR 50
TC 1
Z9 1
U1 0
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2313-433X
J9 J IMAGING
JI J. Imaging
PD MAY
PY 2022
VL 8
IS 5
AR 121
DI 10.3390/jimaging8050121
PG 16
WC Imaging Science & Photographic Technology
WE Emerging Sources Citation Index (ESCI)
SC Imaging Science & Photographic Technology
GA 1O8WH
UT WOS:000801604500001
PM 35621885
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Zippelius, C
   Alqahtani, SA
   Schedel, J
   Brookman-Amissah, D
   Muehlenberg, K
   Federle, C
   Salzberger, A
   Schorr, W
   Pech, O
AF Zippelius, Carolin
   Alqahtani, Saleh A.
   Schedel, Jorg
   Brookman-Amissah, Dominic
   Muehlenberg, Klaus
   Federle, Christoph
   Salzberger, Andrea
   Schorr, Wolfgang
   Pech, Oliver
TI Diagnostic accuracy of a novel artificial intelligence system for
   adenoma detection in daily practice: a prospective non-randomized
   comparative study
SO ENDOSCOPY
LA English
DT Article
ID COMPUTER-AIDED DETECTION; MISS RATE; COLORECTAL-CANCER; COLONOSCOPY;
   QUALITY; POLYPS; RISK
AB Background Adenoma detection rate (ADR) varies significantly between endoscopists, with adenoma miss rates (AMRs) up to 26%. Artificial intelligence (AI) systems may improve endoscopy quality and reduce the rate of interval cancer. We evaluated the efficacy of an AI system in real-time colonoscopy and its influence on AMR and ADR.
   Methods This prospective, nonrandomized, comparative study analyzed patients undergoing diagnostic colonoscopy at a single endoscopy center in Germany from June to October 2020. Every patient was examined concurrently by an endoscopist and AI using two opposing screens. The AI system, overseen by a second observer, was not visible to the endoscopist. AMR was the primary outcome. Both methods were compared using McNemar test.
   Results 150 patients were included (mean age 65 years [standard deviation 14]; 69 women). There was no significant or clinically relevant difference (P = 0.75) in AMR between the AI system (6/197, 3.0%; 95% confidence interval [CI] 1.1-6.5) and routine colonoscopy (4/197, 2.0%; 95 %CI 0.6-5.1). The polyp miss rate of the AI system (14/311, 4.5 %; 95 %CI 2.5-7.4) was not significantly different (P=0.72) from routine colonoscopy (17/311, 5.5%; 95%CI 3.2-8.6). There was no significant difference (P=0.50) in ADR between routine colonoscopy (78/150, 52.0%; 95%CI 43.760.2) and the AI system (76/150, 50.7%; 95%Cl 42.458.9). Routine colonoscopy detected adenomas in two patients that were missed by the AI system.
   Conclusion The AI system performance was comparable to that of experienced endoscopists during real-time colonoscopy with similar high ADR (>50%).
C1 [Zippelius, Carolin; Schedel, Jorg; Brookman-Amissah, Dominic; Muehlenberg, Klaus; Federle, Christoph; Salzberger, Andrea; Schorr, Wolfgang; Pech, Oliver] Krankenhaus Barmherzige Bruder Regensburg, Dept Gastroenterol & Intervent Endoscopy, Pruefeninger Str 86, D-93049 Regensburg, Germany.
   [Alqahtani, Saleh A.] Johns Hopkins Univ, Div Gastroenterol & Hepatol, Baltimore, MD USA.
   [Schorr, Wolfgang] King Faisal Specialist Hosp & Res Ctr, Liver Transplant Ctr, Riyadh, Saudi Arabia.
C3 Johns Hopkins University; King Faisal Specialist Hospital & Research
   Center
RP Pech, O (通讯作者)，Krankenhaus Barmherzige Bruder Regensburg, Dept Gastroenterol & Intervent Endoscopy, Pruefeninger Str 86, D-93049 Regensburg, Germany.
EM Oliver.Pech@t-online.de
OI Alqahtani, Saleh/0000-0003-2017-3526
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Fayad Nabil F, 2015, Gastrointest Endosc Clin N Am, V25, P373, DOI 10.1016/j.giec.2014.11.008
   Goyal H, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103313
   Hartstein JD, 2020, GASTROINTEST ENDOSC, V91, P614, DOI 10.1016/j.gie.2019.08.047
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Jung YS, 2020, GASTROINTEST ENDOSC, V92, P692, DOI 10.1016/j.gie.2020.04.042
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Meester RGS, 2020, GASTROENTEROLOGY, V159, P105, DOI 10.1053/j.gastro.2020.03.025
   Milluzzo SM, 2021, CLIN ENDOSC, V54, P329, DOI 10.5946/ce.2020.082
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zorzi M, 2015, GUT, V64, P1389, DOI 10.1136/gutjnl-2014-307954
NR 19
TC 12
Z9 12
U1 0
U2 6
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD MAY
PY 2022
VL 54
IS 05
BP 465
EP 472
DI 10.1055/a-1556-5984
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 0T0LE
UT WOS:000786663400039
PM 34293812
DA 2023-08-21
ER

PT J
AU Sharma, P
   Balabantaray, BK
   Bora, K
   Mallik, S
   Kasugai, K
   Zhao, ZM
AF Sharma, Pallabi
   Balabantaray, Bunil Kumar
   Bora, Kangkana
   Mallik, Saurav
   Kasugai, Kunio
   Zhao, Zhongming
TI An Ensemble-Based Deep Convolutional Neural Network for Computer-Aided
   Polyps Identification From Colonoscopy
SO FRONTIERS IN GENETICS
LA English
DT Article
DE colorectal cancer; deep learning; polyp detection; colonoscopy; ensemble
   classifier
ID CLASSIFICATION; VALIDATION; LESIONS
AB Colorectal cancer (CRC) is the third leading cause of cancer death globally. Early detection and removal of precancerous polyps can significantly reduce the chance of CRC patient death. Currently, the polyp detection rate mainly depends on the skill and expertise of gastroenterologists. Over time, unidentified polyps can develop into cancer. Machine learning has recently emerged as a powerful method in assisting clinical diagnosis. Several classification models have been proposed to identify polyps, but their performance has not been comparable to an expert endoscopist yet. Here, we propose a multiple classifier consultation strategy to create an effective and powerful classifier for polyp identification. This strategy benefits from recent findings that different classification models can better learn and extract various information within the image. Therefore, our Ensemble classifier can derive a more consequential decision than each individual classifier. The extracted combined information inherits the ResNet's advantage of residual connection, while it also extracts objects when covered by occlusions through depth-wise separable convolution layer of the Xception model. Here, we applied our strategy to still frames extracted from a colonoscopy video. It outperformed other state-of-the-art techniques with a performance measure greater than 95% in each of the algorithm parameters. Our method will help researchers and gastroenterologists develop clinically applicable, computational-guided tools for colonoscopy screening. It may be extended to other clinical diagnoses that rely on image.
EM zhongming.zhao@uth.tmc.edu
OI SHARMA, PALLABI/0000-0003-3447-9251; Mallik, Saurav/0000-0003-4107-6784
CR Akbari M, 2018, IEEE ENG MED BIO, P65, DOI 10.1109/EMBC.2018.8512226
   Ayaz M, 2021, PHYS ENG SCI MED, V44, P183, DOI 10.1007/s13246-020-00966-0
   Bandyopadhyay S, 2014, IEEE ACM T COMPUT BI, V11, P95, DOI 10.1109/TCBB.2013.147
   Bedrikovetski S, 2021, ARTIF INTELL MED, V113, DOI 10.1016/j.artmed.2021.102022
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bolon-Canedo V, 2012, PATTERN RECOGN, V45, P531, DOI 10.1016/j.patcog.2011.06.006
   Bose SSC, 2021, J AMB INTEL HUM COMP, V12, P6713, DOI 10.1007/s12652-020-02295-2
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Graham S, 2019, MED IMAGE ANAL, V52, P199, DOI 10.1016/j.media.2018.12.001
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Huang GL, 2017, IEEE ICC
   Hussain E, 2020, TISSUE CELL, V65, DOI 10.1016/j.tice.2020.101347
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Mahfouz MA, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101985
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Pacal I, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104003
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Sevo I, 2016, COMPUT BIOL MED, V72, P138, DOI 10.1016/j.compbiomed.2016.03.017
   Shakeel PM, 2022, NEURAL COMPUT APPL, V34, P9579, DOI 10.1007/s00521-020-04842-6
   Sharif MS, 2020, IEEE ACCESS, V8, P37482, DOI 10.1109/ACCESS.2020.2975135
   Sharma P, 2020, ONCOLOGIE, V22, P129, DOI 10.32604/oncologie.2020.013870
   Sharma P, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTATIONAL PERFORMANCE EVALUATION (COMPE-2020), P316, DOI 10.1109/ComPE49325.2020.9200003
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Soh NYT, 2018, INT J COLORECTAL DIS, V33, P991, DOI 10.1007/s00384-018-3039-1
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Sun ZB, 2015, PATTERN RECOGN, V48, P1623, DOI 10.1016/j.patcog.2014.11.014
   Sundaram PS, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1153-9
   Szegedy C., 2015, PROC IEEE C COMPUT V, DOI DOI 10.1109/CVPR.2015.7298594
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yang C, 2020, INT J COLORECTAL DIS, V35, P101, DOI 10.1007/s00384-019-03455-3
   Yang JJ, 2016, COMPUT METH PROG BIO, V124, P45, DOI 10.1016/j.cmpb.2015.10.007
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 44
TC 12
Z9 12
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1664-8021
J9 FRONT GENET
JI Front. Genet.
PD APR 26
PY 2022
VL 13
AR 844391
DI 10.3389/fgene.2022.844391
PG 11
WC Genetics & Heredity
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Genetics & Heredity
GA 1V2RU
UT WOS:000805944100001
PM 35559018
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Quan, SY
   Wei, MT
   Lee, J
   Mohi-Ud-Din, R
   Mostaghim, R
   Sachdev, R
   Siegel, D
   Friedlander, Y
   Friedland, S
AF Quan, Susan Y.
   Wei, Mike T.
   Lee, Jun
   Mohi-Ud-Din, Raja
   Mostaghim, Radman
   Sachdev, Ritu
   Siegel, David
   Friedlander, Yishai
   Friedland, Shai
TI Clinical evaluation of a real-time artificial intelligence-based polyp
   detection system: a US multi-center pilot study
SO SCIENTIFIC REPORTS
LA English
DT Article
ID COLONOSCOPY
AB Artificial intelligence (AI) has increasingly been employed in multiple fields, and there has been significant interest in its use within gastrointestinal endoscopy. Computer-aided detection (CAD) can potentially improve polyp detection rates and decrease miss rates in colonoscopy. However, few clinical studies have evaluated real-time CAD during colonoscopy. In this study, we analyze the efficacy of a novel real-time CAD system during colonoscopy. This was a single-arm prospective study of patients undergoing colonoscopy with a real-time CAD system. This AI-based system had previously been trained using manually labeled colonoscopy videos to help detect neoplastic polyps (adenomas and serrated polyps). In this pilot study, 300 patients at two centers underwent elective colonoscopy with the CAD system. These results were compared to 300 historical controls consisting of consecutive colonoscopies performed by the participating endoscopists within 12 months prior to onset of the study without the aid of CAD. The primary outcome was the mean number of adenomas per colonoscopy. Use of real-time CAD trended towards increased adenoma detection (1.35 vs 1.07, p = 0.099) per colonoscopy though this did not achieve statistical significance. Compared to historical controls, use of CAD demonstrated a trend towards increased identification of serrated polyps (0.15 vs 0.07) and all neoplastic (adenomatous and serrated) polyps (1.50 vs 1.14) per procedure. There were significantly more non-neoplastic polyps detected with CAD (1.08 vs 0.57, p < 0.0001). There was no difference in >= 10 mm polyps identified between the two groups. A real-time CAD system can increase detection of adenomas and serrated polyps during colonoscopy in comparison to historical controls without CAD, though this was not statistically significant. As this pilot study is underpowered, given the findings we recommend pursuing a larger randomized controlled trial to further evaluate the benefits of CAD.
C1 [Quan, Susan Y.; Wei, Mike T.; Friedland, Shai] Stanford Univ, Stanford, CA 94305 USA.
   [Quan, Susan Y.; Friedland, Shai] Vet Affairs Palo Alto Hlth Care Syst, Palo Alto, CA USA.
   [Lee, Jun] Chosun Univ, Gwangju, South Korea.
   [Mohi-Ud-Din, Raja; Mostaghim, Radman; Sachdev, Ritu; Siegel, David] Greenbelt Endoscopy Ctr, Lanham, MD USA.
   [Friedlander, Yishai] StatistX, Beer Tuvya, Israel.
C3 Stanford University; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); VA Palo Alto Health Care System; Chosun University
RP Wei, MT (通讯作者)，Stanford Univ, Stanford, CA 94305 USA.
EM mtwei@stanford.edu
CR Ali S., 2022, ARXIV220212031
   Chin M, 2016, WORLD J GASTROENTERO, V22, P9642, DOI 10.3748/wjg.v22.i43.9642
   Dik VK, 2015, ENDOSCOPY, V47, P1151, DOI 10.1055/s-0034-1392421
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Rex DK, 2018, GASTROINTEST ENDOSC, V88, P335, DOI 10.1016/j.gie.2018.02.043
   Singh S, 2014, AM J GASTROENTEROL, V109, P1375, DOI 10.1038/ajg.2014.171
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wei MKT, 2021, DIGEST DIS SCI, V66, P989, DOI 10.1007/s10620-020-06596-6
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 19
TC 1
Z9 1
U1 0
U2 2
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD APR 21
PY 2022
VL 12
IS 1
AR 6598
DI 10.1038/s41598-022-10597-y
PG 7
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA 0Q4GB
UT WOS:000784878300025
PM 35449442
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Spadaccini, M
   Hassan, C
   Alfarone, L
   Da Rio, L
   Maselli, R
   Carrara, S
   Galtieri, PA
   Pellegatta, G
   Fugazza, A
   Koleth, G
   Emmanuel, J
   Anderloni, A
   Mori, Y
   Wallace, MB
   Sharma, P
   Repici, A
AF Spadaccini, Marco
   Hassan, Cesare
   Alfarone, Ludovico
   Da Rio, Leonardo
   Maselli, Roberta
   Carrara, Silvia
   Galtieri, Piera Alessia
   Pellegatta, Gaia
   Fugazza, Alessandro
   Koleth, Glenn
   Emmanuel, James
   Anderloni, Andrea
   Mori, Yuichi
   Wallace, Michael B.
   Sharma, Prateek
   Repici, Alessandro
TI Comparing the number and relevance of false activations between 2
   artificial intelligence computer-aided detection systems: the NOISE
   study
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID DETECTION-ASSISTED COLONOSCOPY
AB Background and Aims: Artificial intelligence has been shown to be effective in polyp detection, and multiple computer-aided detection (CADe) systems have been developed. False-positive (FP) activation emerged as a possible way to benchmark CADe performance in clinical practice. The aim of this study was to validate a previously developed classification of FPs comparing the performances of different brands of approved CADe systems.
   Methods: We compared 2 different consecutive video libraries (40 video per arm) collected at Humanitas Research Hospital with 2 different CADe system brands (CADe A and CADe B). For each video, the number of CADe false activations, cause, and time spent by the endoscopist to examine the area erroneously highlighted were reported. The FP activations were classified according to the previously developed classification of FPs (the NOISE classification) according to their cause and relevance.
   Results: In CADe A 1021 FP activations were registered across the 40 videos (25.5 +/- 12.2 FPs per colonoscopy), whereas in CADe B 1028 were identified (25.7 +/- 13.2 FPs per colonoscopy; P = .53). Among them, 22.9 +/- 9.9 (89.8% in CADe A) and 22.1 +/- 10.0 (86.0% in CADe B) were because of artifacts from the bowel wall. Conversely, 2.6 +/- 1.9 (10.2% in CADe A) and 3.5 +/- 2.1 (14% in CADe B) were caused by bowel content (P = .45). Within CADe A each false activation required .2 +/- .9 seconds, with 1.6 +/- 1.0 FPs (6.3%) requiring additional time for endoscopic assessment. Comparable results were reported within CADe B with .2 +/- .8 seconds spent per false activation and 1.8 +/- 1.2 FPs per colonoscopy requiring additional inspection.
   Conclusions: The use of a standardized nomenclature provided comparable results with either of the 2 recently approved CADe systems.
C1 [Spadaccini, Marco; Hassan, Cesare; Alfarone, Ludovico; Da Rio, Leonardo; Maselli, Roberta; Carrara, Silvia; Galtieri, Piera Alessia; Pellegatta, Gaia; Fugazza, Alessandro; Anderloni, Andrea; Repici, Alessandro] Humanitas Univ, Dept Biomed Sci, Pieve Emanuele, Italy.
   [Spadaccini, Marco; Hassan, Cesare; Alfarone, Ludovico; Da Rio, Leonardo; Maselli, Roberta; Repici, Alessandro] IRCCS, Endoscopy Unit, Humanitas Clin & Res Ctr, Rozzano, Italy.
   [Koleth, Glenn] Hosp Selayang, Dept Gastroenterol & Hepatol, Batu Caves, Selangor, Malaysia.
   [Emmanuel, James] Queen Elizabeth Hosp, Dept Gastroenterol & Hepatol, Kota Kinabalu, Sabah, Malaysia.
   [Mori, Yuichi] Univ Oslo, Fac Med, Inst Hlth & Soc, Clin Effectiveness Res Grp, Oslo, Norway.
   [Mori, Yuichi] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Wallace, Michael B.] Sheikh Shakhbout Med City, Endoscopy Unit, Abu Dhabi, U Arab Emirates.
   [Sharma, Prateek] Kansas City VA Med Ctr, Dept Gastroenterol & Hepatol, Kansas City, KS USA.
C3 Humanitas University; IRCCS Humanitas Research Hospital; University of
   Oslo; Showa University
RP Spadaccini, M (通讯作者)，Humanitas Res Hosp & Univ, Via Manzoni 56, I-20089 Milan, Italy.
RI Sharma, Prateek/IZE-3910-2023; Fugazza, Alessandro/ABG-9381-2021;
   hassan, cesare/H-2844-2012; Repici, Alessandro/HFH-8162-2022; Maselli,
   Roberta/HJY-6995-2023; Spadaccini, Marco/HOH-7613-2023; Wallace,
   Michael/GZL-9731-2022
OI Fugazza, Alessandro/0000-0003-0485-4903; hassan,
   cesare/0000-0001-7167-1459; Repici, Alessandro/0000-0002-1621-6450;
   Maselli, Roberta/0000-0001-7291-9110; Spadaccini,
   Marco/0000-0003-3909-9012; Wallace, Michael/0000-0002-6446-5785; Koleth,
   Glenn/0000-0002-2939-6876; Pellegatta, Gaia/0000-0003-0235-4905;
   Galtieri, Piera/0000-0002-3253-6972; Carrara, Silvia/0000-0003-4206-9463
FU Fujifilm; Boston Scientific; Olympus; Medtronic; Ninepoint Medical;
   Cosmo/Aries Pharmaceuticals
FX The following authors disclosed financial relationships: C. Hassan, A.
   Repici: Consultant for Medtronic and Fuji. R. Maselli: Consultant for
   Fuji. S. Carrara, A. Anderloni: Consultant for Olympus Corp. Y. Mori:
   Consultant for Olympus Corp; ownership in Cybernet Corp. M. B. Wallace:
   Research funding from Medtronic; Research grants from Fujifilm, Boston
   Scientific, Olympus, Medtronic, Ninepoint Medical, and Cosmo/Aries
   Pharmaceuticals; Stock options in Virgo Inc; Minor food/beverage at
   meetings from Synergy Pharmaceuticals, Boston Scientific, and Cook
   Medical; Consultant on behalf of Mayo Clinic, paid to Mayo Clinic, for
   GI Supply (2018), Endokey, Endostart, Boston Scientific, Microtek, and
   Verily. All other authors disclosed no financial relationships.
CR Ahmad OF., DIGEST ENDOSC
   Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Antonelli G, 2020, WORLD J GASTROENTERO, V26, P7436, DOI 10.3748/wjg.v26.i47.7436
   Attardo S, 2020, WORLD J GASTROENTERO, V26, P5606, DOI 10.3748/wjg.v26.i37.5606
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gilbert FJ, 2008, NEW ENGL J MED, V359, P1675, DOI 10.1056/NEJMoa0803545
   Glissen Brown JR, CLIN GASTROENTEROL H
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Greenhill AT, 2020, TECH INNOVAT GASTROI, V22, P85, DOI 10.1016/j.tgie.2019.150642
   Guo Z, 2021, DIGEST ENDOSC, V33, P162, DOI 10.1111/den.13670
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Holzwanger EA, 2021, ENDOSCOPY, V53, P937, DOI 10.1055/a-1302-2942
   Hoogenboom SA, 2020, TECH INNOVAT GASTROI, V22, P42, DOI 10.1016/j.tgie.2019.150634
   Hsieh YH, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11061113
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Neumann H, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255955
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Spadaccini M, 2021, LANCET GASTROENTEROL, V6, P793, DOI 10.1016/S2468-1253(21)00215-6
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   van der Sommen F, 2020, GUT, V69, P2035, DOI 10.1136/gutjnl-2019-320466
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
NR 28
TC 5
Z9 5
U1 1
U2 1
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD MAY
PY 2022
VL 95
IS 5
BP 975
EP +
DI 10.1016/j.gie.2021.12.031
EA APR 2022
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 1B7VE
UT WOS:000792640200019
PM 34995639
DA 2023-08-21
ER

PT J
AU Montalbo, FJP
AF Montalbo, Francis Jesmar P.
TI Diagnosing gastrointestinal diseases from endoscopy images through a
   multi-fused CNN with auxiliary layers, alpha dropouts, and a fusion
   residual block
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Colonoscopy; Deep convolutional neural networks; Deep learning;
   Endoscopy; Feature fusion; Gastrointestinal diseases
ID CONVOLUTIONAL NEURAL-NETWORKS; CLASSIFICATION; CHALLENGES; CANCER; MODEL
AB In this work, a proposed Multi-Fused Residual Convolutional Neural Network (MFuRe-CNN) with Auxiliary Fusing Layers (AuxFL), a Fusion Residual Block (FuRB) both with Alpha Dropouts (aDO) diagnosed various endoscopic images of gastrointestinal (GI) conditions or diseases. The proposed MFuRe-CNN handled four cases, including colons with ulcerative colitis, polyps, esophagitis, and a healthy colon, sourced from reliable databases like the KVASIR and ETIS-Larib Polyp DB. The proposed model consisted of three state-of-the-art models fused into a single feature extraction pipeline with their partially frozen and truncated layers, which helped propagate robust features and improved the diagnostic performance without consuming a hefty fraction of computing cost compared to most existing state-of-the-art models. In addition, the MFuRe-CNN incorporated with AuxFLs, alpha DOs, and FuRB have shown a significant contribution in reducing overfitting and performance saturation compared to those without the said components. Upon evaluation, the proposed model achieved an outstanding 97.25% test accuracy with only 4.8 M parameters and consumed 7.8 GFLOPs during inference, making it more efficient and accurate than most conventionally trained DCNNs. As concluded, the proposed MFuRe-CNN can potentially improve the diagnosis of the GI tract more cost-efficiently than ensembles and perform better diagnosis than most conventional pre-trained and fine-tuned DCNNs.
C1 [Montalbo, Francis Jesmar P.] Batangas State Univ, Quezon City, Philippines.
C3 Batangas State University
RP Montalbo, FJP (通讯作者)，Batangas State Univ, Quezon City, Philippines.
EM francismontalbo@ieee.org
OI Montalbo, Francis Jesmar/0000-0002-1493-5080
FU Batangas State University
FX The author sincerely acknowledges the support given by Batangas State
   University during and after conducting this research.
CR Alsaade FW, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/9998379
   [Anonymous], 2020, LOSS FUNCTIONS ML GL
   Apostolopoulos ID, 2020, J MED BIOL ENG, V40, P462, DOI 10.1007/s40846-020-00529-4
   Bonmati E, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.2.021206
   Buetti-Dinh Antoine, 2019, Biotechnology Reports, V22, pe00321, DOI 10.1016/j.btre.2019.e00321
   Buiu C, 2020, PROCESSES, V8, DOI 10.3390/pr8050595
   Castaneda G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0233-0
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chollet F., 2015, KERAS PROBABILISTIC
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Das D, 2020, PHYS ENG SCI MED, V43, P915, DOI 10.1007/s13246-020-00888-x
   EKBOM A, 1990, NEW ENGL J MED, V323, P1228, DOI 10.1056/NEJM199011013231802
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Torrijos EG, 2018, FRONT MED-LAUSANNE, V5, DOI 10.3389/fmed.2018.00247
   Goutam K., 2020, SN COMPUT SCI, V1
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI [DOI 10.5121/IJDKP.2015.5201, 10.5121/ijdkp.2015.5201]
   Howard A.G., 2017, ARXIV
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jeni LA, 2013, INT CONF AFFECT, P245, DOI 10.1109/ACII.2013.47
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Kashyap S, 2020, I S BIOMED IMAGING, P1125, DOI 10.1109/ISBI45749.2020.9098370
   KEVIN PRATAMA, 2017, The International Journal of Advanced Smart Convergence, V6, P73, DOI 10.7236/IJASC.2017.6.4.11
   Khan MA, 2021, CMC-COMPUT MATER CON, V67, P3381, DOI 10.32604/cmc.2021.014983
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Klambauer G., 2017, PROC NEURIPS, P971
   Koivu A, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-020-00105-9
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Montalbo Francis Jesmar P, 2021, MethodsX, V8, P101408, DOI 10.1016/j.mex.2021.101408
   Montalbo FJP, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102583
   Montalbo FJP, 2021, KSII T INTERNET INF, V15, P147, DOI 10.3837/tiis.2021.01.009
   Montalbo FJP, 2020, KSII T INTERNET INF, V14, P4816, DOI 10.3837/tiis.2020.12.011
   Montalbo FJP, 2020, 2020 16TH IEEE INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2020), P213, DOI [10.1109/cspa48992.2020.9068683, 10.1109/CSPA48992.2020.9068683]
   Munien C, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5580914
   Nigam B, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114883
   Nour M, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2742781
   Oh Y, 2021, IEEE WINT CONF APPL, P3578, DOI 10.1109/WACV48630.2021.00362
   Ozturk S, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103638
   Pal K., 2020, 2020 4 INT C COMPUTI, P83, DOI [10.1109/ICCMC48092.2020.ICCMC-00016, DOI 10.1109/ICCMC48092.2020.ICCMC-00016]
   Piccialli F, 2021, INFORM FUSION, V66, P111, DOI 10.1016/j.inffus.2020.09.006
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Poudel S, 2020, IEEE ACCESS, V8, P99227, DOI 10.1109/ACCESS.2020.2996770
   Rabi B, 2019, 29TH INTERNATIONAL CONFERENCE ON COMPUTER THEORY AND APPLICATIONS (ICCTA 2019), P85, DOI 10.1109/ICCTA48790.2019.9478820
   Rasamoelina AD, 2020, 2020 IEEE 18TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2020), P281, DOI 10.1109/SAMI48414.2020.9108717
   Ren YM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204209
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shorfuzzaman M, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5513679
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wang HJ, 2020, Cambria Sinophone Wo, P111, DOI 10.1109/CVPRW50498.2020.00020
   Wang SH, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.687456
   Wang SH, 2021, INFORM FUSION, V76, P376, DOI 10.1016/j.inffus.2021.07.001
   Wu HJ, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.04.39
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang HJ, 2021, IEEE COMPUT SOC CONF, P2339, DOI 10.1109/CVPRW53098.2021.00266
   Yao QH, 2020, INFORM FUSION, V53, P174, DOI 10.1016/j.inffus.2019.06.024
   Zhang YD, 2020, INFORM FUSION, V64, P149, DOI 10.1016/j.inffus.2020.07.006
NR 70
TC 3
Z9 3
U1 3
U2 5
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD JUL
PY 2022
VL 76
AR 103683
DI 10.1016/j.bspc.2022.103683
EA APR 2022
PG 15
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 2S6VE
UT WOS:000821927500001
DA 2023-08-21
ER

PT J
AU Tanwar, S
   Vijayalakshmi, S
   Sabharwal, M
   Kaur, M
   AlZubi, AA
   Lee, HN
AF Tanwar, Sushama
   Vijayalakshmi, S.
   Sabharwal, Munish
   Kaur, Manjit
   AlZubi, Ahmad Ali
   Lee, Heung-No
TI Detection and Classification of Colorectal Polyp Using Deep Learning
SO BIOMED RESEARCH INTERNATIONAL
LA English
DT Article
ID ENDOSCOPY; STATISTICS; HISTOLOGY; CANCER
AB Colorectal Cancer (CRC) is the third most dangerous cancer in the world and also increasing day by day. So, timely and accurate diagnosis is required to save the life of patients. Cancer grows from polyps which can be either cancerous or noncancerous. So, if the cancerous polyps are detected accurately and removed on time, then the dangerous consequences of cancer can be reduced to a large extent. The colonoscopy is used to detect the presence of colorectal polyps. However, manual examinations performed by experts are prone to various errors. Therefore, some researchers have utilized machine and deep learning-based models to automate the diagnosis process. However, existing models suffer from overfitting and gradient vanishing problems. To overcome these problems, a convolutional neural network- (CNN-) based deep learning model is proposed. Initially, guided image filter and dynamic histogram equalization approaches are used to filter and enhance the colonoscopy images. Thereafter, Single Shot MultiBox Detector (SSD) is used to efficiently detect and classify colorectal polyps from colonoscopy images. Finally, fully connected layers with dropouts are used to classify the polyp classes. Extensive experimental results on benchmark dataset show that the proposed model achieves significantly better results than the competitive models. The proposed model can detect and classify colorectal polyps from the colonoscopy images with 92% accuracy.
C1 [Tanwar, Sushama; Sabharwal, Munish] Galgotias Univ, Greater Noida 201307, Uttar Pradesh, India.
   [Vijayalakshmi, S.] Christ Univ, Lavasa 412112, India.
   [Kaur, Manjit; Lee, Heung-No] Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju 61005, South Korea.
   [AlZubi, Ahmad Ali] King Saud Univ, Community Coll, Comp Sci Dept, Riyadh, Saudi Arabia.
C3 Galgotias University; Gwangju Institute of Science & Technology (GIST);
   King Saud University
RP Lee, HN (通讯作者)，Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju 61005, South Korea.
EM heungno@gist.ac.kr
RI AlZubi, Ahmad Ali/ABB-4190-2020; Selvakumar,
   Vijayalakshmi/GON-9515-2022; SABHARWAL, MUNISH/J-9910-2016; Lee,
   Heung-No/CSV-9346-2022
OI AlZubi, Ahmad Ali/0000-0001-8477-8319; Selvakumar,
   Vijayalakshmi/0000-0002-0348-4333; SABHARWAL,
   MUNISH/0000-0002-7338-6982; S, Vijayalakshmi/0000-0002-0310-5495
FU National Research Foundation of Korea (NRF) - Korean government (MSIP)
   [NRF-2021R1A2B5B03002118]; Ministry of Science and ICT (MSIT), Korea,
   under the ITRC (Information Technology Research Center) support program
   [IITP-2021-0-01835]; King Saud University, Riyadh, Saudi Arabia
   [RSP-2021/395]
FX This work was supported in part by the National Research Foundation of
   Korea (NRF) grant funded by the Korean government (MSIP)
   (NRF-2021R1A2B5B03002118). This research was supported by the Ministry
   of Science and ICT (MSIT), Korea, under the ITRC (Information Technology
   Research Center) support program (IITP-2021-0-01835) supervised by the
   IITP (Institute of Information & Communications Technology Planning &
   Evaluation). This work was supported by the Researchers Supporting
   Project (No. RSP-2021/395), King Saud University, Riyadh, Saudi Arabia.
CR Ahmed SS, 2017, MED BIOL ENG COMPUT, V55, P101, DOI 10.1007/s11517-016-1508-7
   Alammari A., 2017, P 9 INT C INF MAN EN, P139, DOI DOI 10.1145/3149572.3149613
   Bai S., 2021, J ARTIFICIAL INTELLI, V2, P16, DOI DOI 10.37965/JAIT.2021.12003
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bibbins-Domingo K., 2021, JAMA-J AM MED ASSOC, V315, P2564
   Chen R, 2022, CAAI T INTELL TECHNO, V7, P117, DOI 10.1049/cit2.12044
   Ciompi F, 2017, SCI REP-UK, V7, DOI 10.1038/srep46479
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Farooq MS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051803
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Han L, 2018, BIOINFORMATICS, V34, P985, DOI 10.1093/bioinformatics/btx651
   Hassan C., 2015, CLIN GASTROENTEROL H, V8, pe861
   IJspeert JEG, 2017, GUT, V66, P1225, DOI 10.1136/gutjnl-2015-310784
   IJspeert JEG, 2016, GUT, V65, P963, DOI 10.1136/gutjnl-2014-308411
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Mahapatra Dwarikanath, 2012, Abdominal Imaging. Computational and Clinical Applications. Proceedings of the 4th International Workshop. Held in Conjunction with MICCAI 2012, P97, DOI 10.1007/978-3-642-33612-6_11
   Mahapatra D, 2013, J DIGIT IMAGING, V26, P920, DOI 10.1007/s10278-013-9576-9
   Melih Y., 2020, EUR J MOLEC CLIN MED, V7, P2515
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mossotto E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02606-2
   Nadeem S, 2018, LECT NOTES ARTIF INT, V11056, P469, DOI 10.1007/978-3-319-98446-9_44
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Pogorelov K., P 8 ACM MULT SYST C, P164
   Postgate A, 2008, ENDOSCOPY, V40, P496, DOI 10.1055/s-2007-995590
   Poudel S, 2020, IEEE ACCESS, V8, P99227, DOI 10.1109/ACCESS.2020.2996770
   Rattue G., 2021, WHAT ARE LEADING CAU
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   SHIN Y, 2017 39 ANN INT C IE, P3277, DOI DOI 10.1109/EMBC.2017.8037556
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Singh, 2022, J ARTIF INTELL TECHN, V2, P3, DOI DOI 10.37965/JAIT.2021.12001
   Singh D, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-017-9433-4
   Singh D, 2018, REMOTE SENS LETT, V9, P942, DOI 10.1080/2150704X.2018.1500044
   Stehle T, 2009, PROC SPIE, V7260, DOI 10.1117/12.808103
   Stidham RW, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3963
   Strum WB, 2016, NEW ENGL J MED, V374, P1065, DOI [10.1056/NEJMra1513581, 10.1056/NEJMc1604867]
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wei ZS, 2013, I S BIOMED IMAGING, P141, DOI 10.1109/ICCCAS.2013.6765204
   Wimmer G., INT C PATT RECOG, P2150, DOI 10.1109/ICPR.2016.7899954
   Wimmer G, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.034504
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   XLA, 2021, NATURE
   Yadav K, 2022, CAAI T INTELL TECHNO, V7, P107, DOI 10.1049/cit2.12052
   Yu F., 2017, P IEEE C COMP VIS PA, P472, DOI DOI 10.1109/CVPR.2017.75
   Yuan Y., IEEE INT C INT ROBOT, P5010
   Zhang JX, 2022, CAAI T INTELL TECHNO, V7, P46, DOI 10.1049/cit2.12012
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X., 2021, J ARTIFICIAL INTELLI, V2, P32, DOI DOI 10.37965/JAIT.2021.12005
NR 56
TC 3
Z9 3
U1 9
U2 18
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2314-6133
EI 2314-6141
J9 BIOMED RES INT-UK
JI Biomed Res. Int.
PD APR 15
PY 2022
VL 2022
AR 2805607
DI 10.1155/2022/2805607
PG 9
WC Biotechnology & Applied Microbiology; Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Research & Experimental Medicine
GA 1B8UJ
UT WOS:000792707200007
PM 35463989
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Wu, HS
   Zhao, ZB
   Zhong, JF
   Wang, W
   Wen, ZK
   Qin, J
AF Wu, Huisi
   Zhao, Zebin
   Zhong, Jiafu
   Wang, Wei
   Wen, Zhenkun
   Qin, Jing
TI PolypSeg plus : A Lightweight Context-Aware Network for Real-Time Polyp
   Segmentation
SO IEEE TRANSACTIONS ON CYBERNETICS
LA English
DT Article; Early Access
DE Feature extraction; Image segmentation; Cancer; Real-time systems;
   Colonoscopy; Task analysis; Data mining; Colonoscopy; context-aware
   network; feature pyramid fusion (FPF); lightweight deep learning model;
   real-time polyp segmentation
ID CT COLONOGRAPHY; VOLUMETRIC FEATURES; COLONIC POLYPS; CLASSIFICATION
AB Automatic polyp segmentation from colonoscopy videos is a prerequisite for the development of a computer-assisted colon cancer examination and diagnosis system. However, it remains a very challenging task owing to the large variation of polyps, the low contrast between polyps and background, and the blurring boundaries of polyps. More importantly, real-time performance is a necessity of this task, as it is anticipated that the segmented results can be immediately presented to the doctor during the colonoscopy intervention for his/her prompt decision and action. It is difficult to develop a model with powerful representation capability, yielding satisfactory segmentation results and, simultaneously, maintaining real-time performance. In this article, we present a novel lightweight context-aware network, namely, PolypSeg+, attempting to capture distinguishable features of polyps without increasing network complexity and sacrificing time performance. To achieve this, a set of novel lightweight techniques is developed and integrated into the proposed PolypSeg+, including an adaptive scale context (ASC) module equipped with a lightweight attention mechanism to tackle the large-scale variation of polyps, an efficient global context (EGC) module to promote the fusion of low-level and high-level features by excluding background noise and preserving boundary details, and a lightweight feature pyramid fusion (FPF) module to further refine the features extracted from the ASC and EGC. We extensively evaluate the proposed PolypSeg+ on two famous public available datasets for the polyp segmentation task: 1) Kvasir-SEG and 2) CVC-Endoscenestill. The experimental results demonstrate that our PolypSeg+ consistently outperforms other state-of-the-art networks by achieving better segmentation accuracy in much less running time. The code is available at https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/szu-zzb/polypsegplus.
C1 [Wu, Huisi; Zhao, Zebin; Zhong, Jiafu; Wang, Wei; Wen, Zhenkun] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Qin, Jing] Hong Kong Polytech Univ, Ctr Smart Hlth, Sch Nursing, Hong Kong, Peoples R China.
C3 Shenzhen University; Hong Kong Polytechnic University
RP Wu, HS (通讯作者)，Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM hswu@szu.edu.cn; harry.qin@polyu.edu.hk
RI Wang, Wei/I-1218-2016
OI Wang, Wei/0000-0003-4163-3173; Wu, Huisi/0000-0002-0399-9089
FU Foundation of China [61973221]; Natural Science Foundation of Guangdong
   Province, China [2018A030313381, 2019A1515011165]; COVID-19 Prevention
   Project of Guangdong Province, China [2020KZDZX1174]; Hong Kong Research
   Grant Council under General Research Fund Scheme [15205919]; Major
   Project of the New Generation of Artificial Intelligence
   [2018AAA0102900]
FX Foundation of China under Grant 61973221; in part by the Natural Science
   Foundation of Guangdong Province, China, under Grant 2018A030313381 and
   Grant 2019A1515011165; in part by the COVID-19 Prevention Project of
   Guangdong Province, China, under Grant 2020KZDZX1174; in part by the
   Major Project of the New Generation of Artificial Intelligence under
   Grant 2018AAA0102900; and in part by the Hong Kong Research Grant
   CounDcil under General Research Fund Scheme under Project 15205919.
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Cao Y., 2019, ARXIV190411492, P1, DOI DOI 10.1109/ICCVW.2019.00246
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cui LS, 2022, IEEE T CYBERNETICS, V52, P2300, DOI 10.1109/TCYB.2020.3004636
   Fu HZ, 2020, IEEE T CYBERNETICS, V50, P3358, DOI 10.1109/TCYB.2019.2897162
   Goyal P., 2017, ARXIV170602677
   Gross S., 2009, BILDVERARBEITUNG F R, P252
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   He K., 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jerebko AK, 2002, RADIOLOGY, V225, P257
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kingma D., 2015, ARXIV
   Kolligs FT, 2016, VISC MED, V32, P158, DOI 10.1159/000446488
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Lin M., 2013, 13124400 ARXIV
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   Nie D, 2019, IEEE T CYBERNETICS, V49, P1123, DOI 10.1109/TCYB.2018.2797905
   Oktay O., 2018, P MIDL, P1, DOI DOI 10.48550/ARXIV.1804.03999
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qi XF, 2022, IEEE T CYBERNETICS, V52, P3446, DOI 10.1109/TCYB.2020.3012186
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Siegel RL, 2017, JNCI-J NATL CANCER I, V109, DOI 10.1093/jnci/djw322
   Song Q, 2021, AAAI CONF ARTIF INTE, V35, P2567
   Sun YN, 2020, IEEE T CYBERNETICS, V50, P3840, DOI 10.1109/TCYB.2020.2983860
   Tao D., 2021, IEEE T CYBERNETICS, V51, P1731, DOI DOI 10.1109/TCYB.2020.2969046
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Xue B, 2019, IEEE T CYBERNETICS, V49, P3991, DOI 10.1109/TCYB.2018.2856821
   Xue J, 2021, IEEE T CYBERNETICS, V51, P2153, DOI 10.1109/TCYB.2019.2955178
   Yao JH, 2004, IEEE T MED IMAGING, V23, P1344, DOI 10.1109/TMI.2004.826941
   Yoshida H, 2002, RADIOLOGY, V222, P327, DOI 10.1148/radiol.2222010506
   YU F, 2015, 1511 ARXIV, V1511, DOI DOI 10.1109/CVPR.2017.660
   Zhang MM, 2020, IEEE T CYBERNETICS, V50, P100, DOI 10.1109/TCYB.2018.2864670
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhong J., 2020, MED IMAGE COMPUT ASS
   Zhong ZL, 2020, IEEE T CYBERNETICS, V50, P3318, DOI 10.1109/TCYB.2019.2915094
NR 44
TC 3
Z9 3
U1 13
U2 42
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2267
EI 2168-2275
J9 IEEE T CYBERNETICS
JI IEEE T. Cybern.
PD 2022 APR 13
PY 2022
DI 10.1109/TCYB.2022.3162873
EA APR 2022
PG 12
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA 0N4TQ
UT WOS:000782832300001
PM 35417366
DA 2023-08-21
ER

PT J
AU Wong, YT
   Tai, TF
   Wong, KF
   Leung, SK
   Lam, SM
   Wong, SY
   Lo, YY
   Yan, KM
   Tam, SK
   Wong, MF
   Chan, HL
AF Wong, Yuen Ting
   Tai, Tze Fung
   Wong, Ka Fai
   Leung, Siu Kee
   Lam, Shuk Man
   Wong, Shun Yi
   Lo, Yik Yu
   Yan, Kit Man
   Tam, Shuk Kwan
   Wong, Man Fan
   Chan, Hing Lung
TI The study on artificial intelligence (AI) colonoscopy in affecting the
   rate of polyp detection in colonoscopy: A single centre retrospective
   study
SO SURGICAL PRACTICE
LA English
DT Article
ID COLORECTAL-CANCER
AB Aim: The aim of this study was to evaluate if the application of Artificial Intelligence (AI) Colonoscopy CLN (ENDO-AID) could increase the polyp detection rate (PDR).
   Methods and Materials: A single center retrospective study was performed in Tin Shui Wai Hospital. PDR in CLN from 11/2020 to 03/2021 after the application of ENDO-AID (AI group) was compared to the cases from 12/2019 to 11/2020 before the application of the practice (non-Al group). Procedures were performed by a single endoscopist with experience in performing > 3,000 CLN. Variables, such as patients' demographic data, indications, incidence of PDR, Boston Bowel Preparation Scale BBPS, withdrawal time, post CLN complication rate between the 2 groups, were compared. Categorical and continuous variables were analyzed by using the Chi-Square test (Fisher exact test if appropriate) and Mann-Whitney test respectively. Results were considered to be significant if p-value < 0.05.
   Results: Total 234 patients were recruited. 115 patients (49.1%) were in the non-AI group while 119 patients (50.9%) were in the AI group. The mean age of the non-AI was higher than the AI group (65.3 vs 59.2, p< 0.001*), otherwise, there was no significant difference in sex (p = 0.05), percentage of smokers (20.8% vs 27.7%, p = 0.22), past medical history of IBD (0 vs 0, p = 1.0), family history of colorectal cancer (9 vs 9, p = 0.94), indications for CLN (e.g. follow up CLN for polyp/ cancer, per-rectal bleeding, altered bowel habit etc. p > 0.05), BBPS (7.88 vs 8.04, p = 0.217), withdrawal time (7.65 min vs 7.48 min, p = 0.935), completion rate (95.6% vs 98.3%, p = 0.27) and complication rate (0% in both groups,p=1.0) between groups. In the contrary, PDR was significantly higher in the AI group than the non-AI group (64.7% vs 46.0%, p = 0.003*). Besides, adenoma detection rate was also found significantly higher in the AI group than the non-AI group (52.9% vs 37.4%, p = 0.017*).
   Conclusions: AI CLN can improve the PDR.
C1 [Wong, Yuen Ting; Tai, Tze Fung; Wong, Ka Fai; Leung, Siu Kee] Hosp Author, Dept Surg, New Terr West Cluster, Hong Kong, Peoples R China.
   [Lam, Shuk Man; Wong, Shun Yi; Lo, Yik Yu; Yan, Kit Man; Tam, Shuk Kwan; Wong, Man Fan; Chan, Hing Lung] Tin Shui Wai Hosp, Combined Endoscopy Unit, Hong Kong, Peoples R China.
RP Wong, YT (通讯作者)，Hosp Author, Dept Surg, New Terr West Cluster, Tuen Mun, 23 Tsing Chung Koon Rd, Hong Kong, Peoples R China.
EM wongyuentinganna@gmail.com
OI Wong, Yuen Ting/0000-0003-0809-7428
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Berzin TM, 2020, LANCET, V395, P485, DOI 10.1016/S0140-6736(20)30294-4
   Heitman SJ, 2009, CLIN GASTROENTEROL H, V7, P1272, DOI 10.1016/j.cgh.2009.05.032
   LAI E, 2018, GASTROINTEST ENDOSC, V69
   Lam TH, 2018, HONG KONG MED J, V24, P521, DOI 10.12809/hkmj177095
   Ng Sandy., POLYP DETECTION RATE
   Niv Y, 2018, EUR J GASTROEN HEPAT, V30, P247, DOI 10.1097/MEG.0000000000001062
   Peters SL, 2010, CLIN GASTROENTEROL H, V8, P439, DOI 10.1016/j.cgh.2010.01.013
   Sung JJY, 2003, GASTROENTEROLOGY, V124, P608, DOI 10.1053/gast.2003.50090
   Zauber AG, 2007, GASTROENTEROLOGY, V132, pA50
NR 10
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1744-1625
EI 1744-1633
J9 SURG PRACT
JI Surg. Pract.
PD MAY
PY 2022
VL 26
IS 2
BP 115
EP 119
DI 10.1111/1744-1633.12559
EA APR 2022
PG 5
WC Surgery
WE Emerging Sources Citation Index (ESCI)
SC Surgery
GA 1P7HP
UT WOS:000779523700001
DA 2023-08-21
ER

PT J
AU Park, KB
   Lee, JY
AF Park, Kyeong-Beom
   Lee, Jae Yeol
TI SwinE-Net: hybrid deep learning approach to novel polyp segmentation
   using convolutional neural network and Swin Transformer
SO JOURNAL OF COMPUTATIONAL DESIGN AND ENGINEERING
LA English
DT Article
DE polyp segmentation; convolutional neural networks; multidilation
   convolutional block; multifeature aggregation block; Swin Transformer;
   Vision Transformer
ID COLONOSCOPY
AB Prevention of colorectal cancer (CRC) by inspecting and removing colorectal polyps has become a global health priority because CRC is one of the most frequent cancers in the world. Although recent U-Net-based convolutional neural networks (CNNs) with deep feature representation and skip connections have shown to segment polyps effectively, U-Net-based approaches still have limitations in modeling explicit global contexts, due to the intrinsic nature locality of convolutional operations. To overcome these problems, this study proposes a novel deep learning model, SwinE-Net, for polyp segmentation that effectively combines a CNN-based EfficientNet and Vision Transformer (ViT)-based Swin Ttransformer. The main challenge is to conduct accurate and robust medical segmentation in maintaining global semantics without sacrificing low-level features of CNNs through Swin Transformer. First, the multidilation convolutional block generates refined feature maps to enhance feature discriminability for multilevel feature maps extracted from CNN and ViT. Then, the multifeature aggregation block creates intermediate side outputs from the refined polyp features for efficient training. Finally, the attentive deconvolutional network-based decoder upsamples the refined and combined feature maps to accurately segment colorectal polyps. We compared the proposed approach with previous state-of-the-art methods by evaluating various metrics using five public datasets (Kvasir, ClinicDB, ColonDB, ETIS, and EndoScene). The comparative evaluation, in particular, proved that the proposed approach showed much better performance in the unseen dataset, which shows the generalization and scalability in conducting polyp segmentation. Furthermore, an ablation study was performed to prove the novelty and advantage of the proposed network. The proposed approach outperformed previous studies.
C1 [Park, Kyeong-Beom; Lee, Jae Yeol] Chonnam Natl Univ, Dept Ind Engn, 77,Yongbong Ro, Gwangju 61186, South Korea.
C3 Chonnam National University
RP Lee, JY (通讯作者)，Chonnam Natl Univ, Dept Ind Engn, 77,Yongbong Ro, Gwangju 61186, South Korea.
EM jaeyeol@chonnam.ac.kr
OI Park, Kyeong-Beom/0000-0003-4737-730X
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2019R1I1A3A01059082]; Korea
   Health Technology Research and Development Project through the Korea
   Health Industry Development Institute (KHIDI) - Ministry of Health and
   Welfare [HI19C0642]; National Research Foundation of Korea
   [2019R1I1A3A01059082] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF), funded by the Ministry
   of Education (2019R1I1A3A01059082), and the Korea Health Technology
   Research and Development Project through the Korea Health Industry
   Development Institute (KHIDI), funded by the Ministry of Health and
   Welfare (HI19C0642).
CR [Anonymous], 2010, GLOBOCAN 2008 V1 2 C
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P., 2017, P SPIE MED IM, V10134
   Cao H., 2021, ARXIV210505537
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dosovitskiy A., 2020, PROC INT C LEARN REP
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fan TL, 2020, IEEE ACCESS, V8, P179656, DOI 10.1109/ACCESS.2020.3025372
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Guo YB, 2020, J IMAGING, V6, DOI 10.3390/jimaging6070069
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang Chien-Hsiang, 2021, ARXIV210107172, P2021
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Mao Yuxin, 2021, ARXIV210410127
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Nguyen NQ, 2020, IEEE ACCESS, V8, P99495, DOI 10.1109/ACCESS.2020.2995630
   Park KB, 2020, IEEE ACCESS, V8, P146308, DOI 10.1109/ACCESS.2020.3015108
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Seo H, 2020, IEEE T MED IMAGING, V39, P1316, DOI 10.1109/TMI.2019.2948320
   Siegel RL., 2020, CA-CANCER J CLIN, V70, P145, DOI [DOI 10.3322/caac.21590, 10.3322/caac.21601]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Tomar N. K., 2021, ARXIV210317235
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vania M, 2021, J COMPUT DES ENG, V8, P1023, DOI 10.1093/jcde/qwab030
   Vania M, 2019, J COMPUT DES ENG, V6, P224
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xie E., 2021, ARXIV210108461
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 50
TC 20
Z9 20
U1 10
U2 47
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
EI 2288-5048
J9 J COMPUT DES ENG
JI J. Comput. Des. Eng.
PD APR 7
PY 2022
VL 9
IS 2
BP 616
EP 632
DI 10.1093/jcde/qwac018
PG 17
WC Computer Science, Interdisciplinary Applications; Engineering,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0I0CF
UT WOS:000779095500001
OA gold
DA 2023-08-21
ER

PT J
AU Nisha, JS
   Gopi, VP
   Palanisamy, P
AF Nisha, J. S.
   Gopi, Varun P.
   Palanisamy, P.
TI CLASSIFICATION OF INFORMATIVE FRAMES IN COLONOSCOPY VIDEO BASED ON IMAGE
   ENHANCEMENT AND PHOG FEATURE EXTRACTION
SO BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS
LA English
DT Article
DE Colonoscopy; Image enhancement; PHOG feature extractor; feature
   selection; Adaboost; SVM; MLP; Random Forest classifier
ID FEATURE-SELECTION; VALIDATION; POLYPS
AB Colonoscopy allows doctors to check the abnormalities in the intestinal tract without any surgical operations. The major problem in the Computer-Aided Diagnosis (CAD) of colonoscopy images is the low illumination condition of the images. This study aims to provide an image enhancement method and feature extraction and classification techniques for detecting polyps in colonoscopy images. We propose a novel image enhancement method with a Pyramid Histogram of Oriented Gradients (PHOG) feature extractor to detect polyps in the colonoscopy images. The approach is evaluated across different classifiers, such as Multi-Layer Perceptron (MLP), Adaboost, Support Vector Machine (SVM), and Random Forest. The proposed method has been trained using the publicly available databases CVC ClinicDB and tested in ETIS Larib and CVC ColonDB. The proposed approach outperformed the existing state-of-the-art methods on both databases. The reliability of the classifiers performance was examined by comparing their F1 score, precision, F2 score, recall, and accuracy. PHOG with Random Forest classifier outperformed the existing methods in terms of recall of 97.95%, precision 98.46%. F1 score 98.20%, F2 score of 98.00%, and accuracy of 98.21% in the CVC-ColonDB. In the ETIS-LARIB dataset it attained a recall value of 96.83%, precision 98.65%, F1 score 97.73%, F2 score 98.59%, and accuracy of 97.75%. We observed that the proposed image enhancement method with PHOG feature extraction and the Random Forest classifier will help doctors to evaluate and analyze anomalies from colonoscopy data and make decisions quickly.
C1 [Nisha, J. S.; Gopi, Varun P.; Palanisamy, P.] Natl Inst Technol, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Gopi, VP (通讯作者)，Natl Inst Technol, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamil Nadu, India.
EM nishajs2007@gmail.com; varun@nitt.edu; palan@nitt.edu
RI P Gopi, Varun/S-3943-2019
OI P Gopi, Varun/0000-0001-5593-3949; J S, Nisha/0000-0002-9284-6729
CR Akbari M, 2018, IEEE ENG MED BIO, P65, DOI 10.1109/EMBC.2018.8512226
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, SCREEN COLORECTAL CA, V109
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bosch A., 2007, P 6 ACM INT C IM VID, P401, DOI [10.1145/1282280.1282340, DOI 10.1145/1282280.1282340]
   Botalb A., 2018, P INT C INT ADV SYST, P1
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chauhan A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112980
   Cheng DC, 2011, BIOMED ENG-APP BAS C, V23, P357, DOI 10.4015/S1016237211002761
   Daqi G., 2007, IJCNN, P2971, DOI 10.1109/IJCNN.2007.4371433
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Gayathri S, 2020, PHYS ENG SCI MED, V43, P927, DOI 10.1007/s13246-020-00890-3
   Gopi Varun P., 2013, International Journal of Imaging & Robotics, V9, P48
   Gopi VP, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P743, DOI 10.1109/ICICICT.2014.6781373
   Gopi VP, 2013, 2013 SECOND INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, NETWORKING AND SECURITY (ADCONS 2013), P68, DOI 10.1109/ADCONS.2013.38
   Gopi VP, 2012, COMM COM INF SC, V292, P220
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Hazewinkel Y, 2011, NAT REV GASTRO HEPAT, V8, P554, DOI 10.1038/nrgastro.2011.141
   Ibraheem N.A., 2012, ARPN J, V2, P265
   Jemshi KM, 2018, INT J COMPUT ASS RAD, V13, P1369, DOI 10.1007/s11548-018-1795-6
   Lieberman D, 2005, GASTROINTEST ENDOSC, V61, P392, DOI 10.1016/S0016-5107(05)00133-1
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Radovic M, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1423-9
   Rahim T, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102654
   Roychowdhury A, 2018, LECT NOTES ELECTR EN, V475, P168, DOI 10.1007/978-981-10-8240-5_19
   Sahu Smriti, 2012, INT J ELECTR COMPUT, V2, P792, DOI DOI 10.11591/IJECE.V2I6.1513
   Salem N., 2019, PROCEDIA COMPUT SCI, V163, P300, DOI [10.1016/j.procs.2019.12.112, DOI 10.1016/J.PROCS.2019.12.112]
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Singh K., 2020, P 2020 INT C EMERGIN, P1, DOI [10.1109/ic-ETITE47903.2020.195, DOI 10.1109/IC-ETITE47903.2020.195]
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang RH, 2012, PHYSCS PROC, V25, P800, DOI 10.1016/j.phpro.2012.03.160
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
NR 40
TC 1
Z9 1
U1 0
U2 0
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 1016-2372
EI 1793-7132
J9 BIOMED ENG-APP BAS C
JI Biomed. Eng.-Appl. Basis Commun.
PD APR
PY 2022
VL 34
IS 02
AR 2250015
DI 10.4015/S1016237222500156
PG 16
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA 0T4XF
UT WOS:000786971300001
DA 2023-08-21
ER

PT J
AU Nogueira-Rodriguez, A
   Reboiro-Jato, M
   Glez-Pena, D
   Lopez-Fernandez, H
AF Nogueira-Rodriguez, Alba
   Reboiro-Jato, Miguel
   Glez-Pena, Daniel
   Lopez-Fernandez, Hugo
TI Performance of Convolutional Neural Networks for Polyp Localization on
   Public Colonoscopy Image Datasets
SO DIAGNOSTICS
LA English
DT Article
DE colorectal cancer; deep learning; convolutional neural network (CNN);
   polyp detection; polyp localization
ID COMPUTER-AIDED DETECTION; ARTIFICIAL-INTELLIGENCE; ADENOMA DETECTION;
   VALIDATION; SYSTEM
AB Colorectal cancer is one of the most frequent malignancies. Colonoscopy is the de facto standard for precancerous lesion detection in the colon, i.e., polyps, during screening studies or after facultative recommendation. In recent years, artificial intelligence, and especially deep learning techniques such as convolutional neural networks, have been applied to polyp detection and localization in order to develop real-time CADe systems. However, the performance of machine learning models is very sensitive to changes in the nature of the testing instances, especially when trying to reproduce results for totally different datasets to those used for model development, i.e., inter-dataset testing. Here, we report the results of testing of our previously published polyp detection model using ten public colonoscopy image datasets and analyze them in the context of the results of other 20 state-of-the-art publications using the same datasets. The F1-score of our recently published model was 0.88 when evaluated on a private test partition, i.e., intra-dataset testing, but it decayed, on average, by 13.65% when tested on ten public datasets. In the published research, the average intra-dataset F1-score is 0.91, and we observed that it also decays in the inter-dataset setting to an average F1-score of 0.83.
C1 [Nogueira-Rodriguez, Alba; Reboiro-Jato, Miguel; Glez-Pena, Daniel; Lopez-Fernandez, Hugo] Univ Vigo, Dept Comp Sci, ESEI Escuela Super Ingn Informat, CINBIO, Orense 32004, Spain.
   [Nogueira-Rodriguez, Alba; Reboiro-Jato, Miguel; Glez-Pena, Daniel; Lopez-Fernandez, Hugo] SERGAS UVIGO, Galicia Sur Hlth Res Inst IIS Galicia Sur, SING Res Grp, Vigo 36213, Spain.
C3 Universidade de Vigo
RP Lopez-Fernandez, H (通讯作者)，Univ Vigo, Dept Comp Sci, ESEI Escuela Super Ingn Informat, CINBIO, Orense 32004, Spain.; Lopez-Fernandez, H (通讯作者)，SERGAS UVIGO, Galicia Sur Hlth Res Inst IIS Galicia Sur, SING Res Grp, Vigo 36213, Spain.
EM alnogueira@uvigo.es; mrjato@uvigo.es; dgpena@uvigo.es;
   hlfernandez@uvigo.es
RI Glez-Peña, Daniel/D-5922-2014; Reboiro-Jato, Miguel/G-1102-2011;
   Lopez-Fernandez, Hugo/H-7558-2017
OI Glez-Peña, Daniel/0000-0002-6129-7245; Reboiro-Jato,
   Miguel/0000-0001-8749-2703; Lopez-Fernandez, Hugo/0000-0002-6476-7206;
   Nogueira Rodriguez, Alba/0000-0001-5991-7698
FU MEIC/AEI [DPI2017-87494-R]; ERDF A way of making Europe; MCIN/AEI
   [PDC2021-121644-I00]; European Union; Conselleria de Educacion,
   Universidades e Formacion Profesional (Xunta de Galicia)
   [ED431C2018/55-GRC]; Fundacao para a Ciencia e a Tecnologia (FCT)
   [2020.00515.CEECIND]; Xunta de Galicia [ED481A-2019/299]; Ministerio de
   Universidades (Gobierno de Espana)
FX This work was partially supported by: (i) grant PolyDeep
   (DPI2017-87494-R) funded by MEIC/AEI/10.13039/501100011033 and by ERDF A
   way of making Europe; (ii) grant PolyDeepAdvance (PDC2021-121644-I00)
   funded by MCIN/AEI/10.13039/501100011033 and by the European Union
   NextGenerationEU/PRTR; (iii) by Conselleria de Educacion, Universidades
   e Formacion Profesional (Xunta de Galicia) under the scope of the
   strategic funding ED431C2018/55-GRC Competitive Reference Group; and
   (iv) by National Funds through Fundacao para a Ciencia e a Tecnologia
   (FCT) through the individual scientific employment program contract with
   Hugo Lopez-Fernandez (2020.00515.CEECIND). A. Nogueira-Rodriguez is
   supported by a pre-doctoral contract from Xunta de Galicia
   (ED481A-2019/299). H. Lopez-Fernandez is supported by a "Maria Zambrano"
   post-doctoral contract from Ministerio de Universidades (Gobierno de
   Espana).
CR Ahmad OF, 2019, GASTROINTEST ENDOSC, V89, pAB647, DOI 10.1016/j.gie.2019.03.1135
   Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Ali S., 2021, POLYPGEN MULTICENTER, DOI [10.48550/ARXIV.2106.04463, DOI 10.48550/ARXIV.2106.04463]
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], INT J COMPUT VISION, DOI DOI 10.1007/s11263-009-0275-4
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2018, P 32 CARS C, V13, pS166
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Guo J, 2020, J MACH LEARN RES, V21
   Hann A, 2021, UNITED EUR GASTROENT, V9, P527, DOI 10.1002/ueg2.12108
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Li KD, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255809
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Liu XY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102052
   Lopez-Fernandez H, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.593
   Ma M, 2020, I S BIOMED IMAGING, P1360, DOI 10.1109/ISBI45749.2020.9098663
   Ma YT, 2021, LECT NOTES COMPUT SC, V12905, P387, DOI 10.1007/978-3-030-87240-3_37
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Nogueira-Rodriguez A., 2021, PRACTICAL APPL COMPU, P51, DOI DOI 10.1007/978-3-030-54568-0_6
   Nogueira-Rodriguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Podlasek J, 2021, ENDOSC INT OPEN, V09, pE741, DOI 10.1055/a-1388-6735
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tashk Ashkan, 2019, 2019 International Conference on Control, Artificial Intelligence, Robotics & Optimization (ICCAIRO). Proceedings, P37, DOI 10.1109/ICCAIRO47923.2019.00015
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Viscaino M, 2021, WORLD J GASTROENTERO, V27, P6399, DOI 10.3748/wjg.v27.i38.6399
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Yu Tian, 2019, 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), P70, DOI 10.1109/ISBI.2019.8759521
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 51
TC 7
Z9 7
U1 1
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD APR
PY 2022
VL 12
IS 4
AR 898
DI 10.3390/diagnostics12040898
PG 17
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA 0S1NQ
UT WOS:000786048800001
PM 35453946
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Buendgens, L
   Cifci, D
   Laleh, NG
   Van Treeck, M
   Koenen, MT
   Zimmermann, HW
   Herbold, T
   Lux, TJ
   Hann, A
   Trautwein, C
   Kather, JN
AF Buendgens, Lukas
   Cifci, Didem
   Laleh, Narmin Ghaffari
   van Treeck, Marko
   Koenen, Maria T.
   Zimmermann, Henning W.
   Herbold, Till
   Lux, Thomas Joachim
   Hann, Alexander
   Trautwein, Christian
   Kather, Jakob Nikolas
TI Weakly supervised end-to-end artificial intelligence in gastrointestinal
   endoscopy
SO SCIENTIFIC REPORTS
LA English
DT Article
ID CLASSIFICATION; CANCER
AB Artificial intelligence (AI) is widely used to analyze gastrointestinal (GI) endoscopy image data. AI has led to several clinically approved algorithms for polyp detection, but application of AI beyond this specific task is limited by the high cost of manual annotations. Here, we show that a weakly supervised AI can be trained on data from a clinical routine database to learn visual patterns of GI diseases without any manual labeling or annotation. We trained a deep neural network on a dataset of N = 29,506 gastroscopy and N = 18,942 colonoscopy examinations from a large endoscopy unit serving patients in Germany, the Netherlands and Belgium, using only routine diagnosis data for the 42 most common diseases. Despite a high data heterogeneity, the AI system reached a high performance for diagnosis of multiple diseases, including inflammatory, degenerative, infectious and neoplastic diseases. Specifically, a cross-validated area under the receiver operating curve (AUROC) of above 0.70 was reached for 13 diseases, and an AUROC of above 0.80 was reached for two diseases in the primary data set. In an external validation set including six disease categories, the AI system was able to significantly predict the presence of diverticulosis, candidiasis, colon and rectal cancer with AUROCs above 0.76. Reverse engineering the predictions demonstrated that plausible patterns were learned on the level of images and within images and potential confounders were identified. In summary, our study demonstrates the potential of weakly supervised AI to generate high-performing classifiers and identify clinically relevant visual patterns based on non-annotated routine image data in GI endoscopy and potentially other clinical imaging modalities.
C1 [Buendgens, Lukas; Cifci, Didem; Laleh, Narmin Ghaffari; van Treeck, Marko; Koenen, Maria T.; Zimmermann, Henning W.; Trautwein, Christian; Kather, Jakob Nikolas] Univ Hosp RWTH Aachen, Dept Med 3, Pauwelsstr 30, D-52074 Aachen, Germany.
   [Koenen, Maria T.] Rhein Maas Klinikum, Dept Med, Wurselen, Germany.
   [Herbold, Till] Univ Hosp RWTH Aachen, Dept Visceral Surg & Transplantat, Aachen, Germany.
   [Lux, Thomas Joachim; Hann, Alexander] Univ Hosp Wurzburg, Internal Med 2, Intervent & Expt Endoscopy InExEn, Wurzburg, Germany.
   [Kather, Jakob Nikolas] Univ Leeds, Leeds Inst Med Res St Jamess, Div Pathol & Data Analyt, Leeds, W Yorkshire, England.
   [Kather, Jakob Nikolas] Univ Hosp Heidelberg, Natl Ctr Tumor Dis NCT, Med Oncol, Heidelberg, Germany.
C3 RWTH Aachen University; RWTH Aachen University Hospital; RWTH Aachen
   University; RWTH Aachen University Hospital; University of Wurzburg;
   University of Leeds; Helmholtz Association; German Cancer Research
   Center (DKFZ); Ruprecht Karls University Heidelberg
RP Kather, JN (通讯作者)，Univ Hosp RWTH Aachen, Dept Med 3, Pauwelsstr 30, D-52074 Aachen, Germany.; Kather, JN (通讯作者)，Univ Leeds, Leeds Inst Med Res St Jamess, Div Pathol & Data Analyt, Leeds, W Yorkshire, England.; Kather, JN (通讯作者)，Univ Hosp Heidelberg, Natl Ctr Tumor Dis NCT, Med Oncol, Heidelberg, Germany.
EM jkather@ukaachen.de
RI Kather, Jakob Nikolas/D-4279-2015; Lux, Thomas/GWC-6062-2022
OI Kather, Jakob Nikolas/0000-0002-3730-5348; Lux,
   Thomas/0000-0003-1049-9872; Cifci, Didem/0000-0002-2647-9959; Hann,
   Alexander/0000-0001-8035-3559
FU German Federal Ministry of Health (DEEP LIVER) [ZMVI1-2520DAT111];
   Max-Eder-Programme of the German Cancer Aid [70113864]; German Research
   Foundation (DFG) [SFB CRC1382, SFB-TRR57]
FX JNK is supported by the German Federal Ministry of Health (DEEP LIVER,
   ZMVI1-2520DAT111) and the Max-Eder-Programme of the German Cancer Aid
   (Grant #70113864). CT is supported by the German Research Foundation
   (DFG) (SFB CRC1382, SFB-TRR57).
CR Abadir AP, 2020, CLIN ENDOSC, V53, P132, DOI 10.5946/ce.2020.038
   Bang CS, 2020, J MED INTERNET RES, V22, DOI 10.2196/21983
   Boehm KM, 2022, NAT REV CANCER, V22, P114, DOI 10.1038/s41568-021-00408-3
   Brenner H, 2006, GUT, V55, P1145, DOI [10.1136/gut.2005087130, 10.1136/gut.2005.087130]
   Brinker TJ, 2019, EUR J CANCER, V111, P30, DOI 10.1016/j.ejca.2018.12.016
   Calderaro J, 2021, GUT, V70, P1183, DOI 10.1136/gutjnl-2020-322880
   Cardoso R, 2021, LANCET ONCOL, V22, P1002, DOI 10.1016/S1470-2045(21)00199-6
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   de Groof J, 2019, UNITED EUR GASTROENT, V7, P538, DOI 10.1177/2050640619837443
   Echle A, 2021, BRIT J CANCER, V124, P686, DOI 10.1038/s41416-020-01122-x
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fu Y, 2020, NAT CANCER, V1, P800, DOI 10.1038/s43018-020-0085-8
   Hann A, 2021, UNITED EUR GASTROENT, V9, P527, DOI 10.1002/ueg2.12108
   Hao DG, 2020, IEEE J BIOMED HEALTH, V24, P2701, DOI 10.1109/JBHI.2020.2974425
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Howard FM, 2020, BIOINFORMATICS, DOI [10.1101/2020.12.03.410845, DOI 10.1101/2020.12.03.410845]
   Kather JN, 2020, NAT REV GASTRO HEPAT, V17, P591, DOI 10.1038/s41575-020-0343-3
   Kather JN, 2020, NAT CANCER, V1, P789, DOI 10.1038/s43018-020-0087-6
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   Mohan BP, 2020, ECLINICALMEDICINE, V29-30, DOI 10.1016/j.eclinm.2020.100622
   Moore M, 2021, CURR OPIN GASTROEN, V37, P428, DOI 10.1097/MOG.0000000000000774
   Niu PH, 2020, WORLD J GASTROENTERO, V26, DOI 10.3748/wjg.v26.i36.5408
   Pannala R, 2020, GASTROINTEST ENDOSC, V92, P1151, DOI 10.1016/j.gie.2020.09.022
   Schmitz R, 2022, GUT, V71, P451, DOI 10.1136/gutjnl-2020-323115
   Sundaram S, 2021, THER ADV GASTROINTES, V14, DOI 10.1177/26317745211017809
   van der Sommen F, 2020, GUT, V69, P2035, DOI 10.1136/gutjnl-2019-320466
   van Treeck M, 2021, DEEPMED UNIFIED MODU, DOI [10.1101/2021.12.19.473344, DOI 10.1101/2021.12.19.473344]
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wilhelm D, 2020, VISC MED, V36, P471, DOI 10.1159/000512440
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
NR 31
TC 2
Z9 2
U1 2
U2 8
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAR 22
PY 2022
VL 12
IS 1
AR 4829
DI 10.1038/s41598-022-08773-1
PG 13
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA ZX9AH
UT WOS:000772185000081
PM 35318364
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Mi, JJ
   Han, XF
   Wang, R
   Ma, RJ
   Zhao, DY
AF Mi, Junjie
   Han, Xiaofang
   Wang, Rong
   Ma, Ruijun
   Zhao, Danyu
TI Diagnostic Accuracy of Wireless Capsule Endoscopy in Polyp Recognition
   Using Deep Learning: A Meta-Analysis
SO INTERNATIONAL JOURNAL OF CLINICAL PRACTICE
LA English
DT Review
ID COLON CAPSULE; COLORECTAL-CANCER; COLONOSCOPY; MULTICENTER; SOCIETY;
   TOOL; 1ST
AB Aim. As the completed studies have small sample sizes and different algorithms, a meta-analysis was conducted to assess the accuracy of WCE in identifying polyps using deep learning. Method. Two independent reviewers searched PubMed, Embase, the Web of Science, and the Cochrane Library for potentially eligible studies published up to December 8, 2021, which were analysed on a per-image basis. STATA RevMan and Meta-DiSc were used to conduct this meta-analysis. A random effects model was used, and a subgroup and regression analysis was performed to explore sources of heterogeneity. Results. Eight studies published between 2017 and 2021 included 819 patients, and 18,414 frames were eventually included in the meta-analysis. The summary estimates for the WCE in identifying polyps by deep learning were sensitivity 0.97 (95% confidence interval (CI), 0.95-0.98); specificity 0.97 (95% CI, 0.94-0.98); positive likelihood ratio 27.19 (95% CI, 15.32-50.42); negative likelihood ratio 0.03 (95% CI 0.02-0.05); diagnostic odds ratio 873.69 (95% CI, 387.34-1970.74); and the area under the sROC curve 0.99. Conclusion. WCE uses deep learning to identify polyps with high accuracy, but multicentre prospective randomized controlled studies are needed in the future.
C1 [Mi, Junjie; Wang, Rong; Ma, Ruijun; Zhao, Danyu] Shanxi Prov Peoples Hosp, Digest Endoscopy Ctr, Taiyuan, Peoples R China.
   [Han, Xiaofang] Shanxi Prov Peoples Hosp, Reprod Med, Taiyuan, Peoples R China.
C3 Shanxi People's Hospital; Shanxi People's Hospital
RP Mi, JJ (通讯作者)，Shanxi Prov Peoples Hosp, Digest Endoscopy Ctr, Taiyuan, Peoples R China.
EM 614660@163.com
RI junjie, mi/ADG-1944-2022
OI junjie, mi/0000-0002-7999-4188; Ma, Ruijun/0000-0002-9773-1023
CR Aggarwal R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00438-z
   Araghi M, 2019, INT J CANCER, V144, P2992, DOI 10.1002/ijc.32055
   Benson AB, 2017, J NATL COMPR CANC NE, V15, P370, DOI 10.6004/jnccn.2017.0036
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Cash BD, 2021, GUT, V70, P2115, DOI 10.1136/gutjnl-2020-322578
   Chang ZL, 2021, J THORAC DIS, V13, P7034, DOI 10.21037/jtd-21-747
   Coe SG, 2013, GASTROINTEST ENDOSC, V77, P631, DOI 10.1016/j.gie.2012.12.001
   Eliakim R, 2006, ENDOSCOPY, V38, P963, DOI 10.1055/s-2006-944832
   Eliakim R, 2009, ENDOSCOPY, V41, P1026, DOI 10.1055/s-0029-1215360
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Figueiredo Pedro N, 2011, Diagn Ther Endosc, V2011, P182435, DOI 10.1155/2011/182435
   Fourcade A, 2019, J STOMATOL ORAL MAXI, V120, P279, DOI 10.1016/j.jormas.2019.06.002
   Garbay T, 2019, CONF DESIGN ARCHIT, P19, DOI [10.1109/dasip48288.2019.9049201, 10.1109/DASIP48288.2019.9049201]
   Groth S, 2012, BMC GASTROENTEROL, V12, DOI 10.1186/1471-230X-12-80
   Gueye L, 2015, IEEE IMAGE PROC, P1061, DOI 10.1109/ICIP.2015.7350962
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   MacLeod C, 2020, COLORECTAL DIS, V22, P621, DOI 10.1111/codi.15134
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   McKendrick M, 2021, ANAESTHESIA, V76, P171, DOI 10.1111/anae.15274
   Nadimi ES, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106531
   Niikura R, 2016, GASTROINTEST ENDOSC, V84, P971, DOI 10.1016/j.gie.2016.05.013
   Orlando C, 2020, IEEE T BIOMED CIRC S, V14, P646, DOI 10.1109/TBCAS.2020.3008458
   Otani I, 2020, DIGESTION, V101, P262, DOI 10.1159/000499332
   Pasha Shabana F, 2018, Curr Gastroenterol Rep, V20, P22, DOI 10.1007/s11894-018-0628-7
   Rex DK, 2017, GASTROENTEROLOGY, V153, P307, DOI 10.1053/j.gastro.2017.05.013
   Sae Hwang, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P320, DOI 10.1007/978-3-642-24031-7_32
   Saraiva MM, 2021, TECH COLOPROCTOL, V25, P1243, DOI 10.1007/s10151-021-02517-5
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sindhu C.P, 2017, ICIIECS, P1, DOI [10.1109/iciiecs.2017.8276073, DOI 10.1109/ICIIECS.2017.8276073]
   Soffer S, 2020, GASTROINTEST ENDOSC, V92, P831, DOI 10.1016/j.gie.2020.04.039
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Spada C, 2016, CLIN GASTROENTEROL H, V14, P1533, DOI 10.1016/j.cgh.2016.04.038
   Spada C, 2015, GUT, V64, P272, DOI 10.1136/gutjnl-2013-306550
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Van Gossum A, 2009, NEW ENGL J MED, V361, P264, DOI 10.1056/NEJMoa0806347
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Yuan YX, 2018, LECT NOTES COMPUT SC, V11071, P620, DOI 10.1007/978-3-030-00934-2_69
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zhang WY, 2018, J CLIN ANESTH, V51, P10, DOI 10.1016/j.jclinane.2018.07.005
   Zhang XH, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1457-4
   Zhao Q., 2012, STUD HLTH TECHNOL IN, V173, P559
   Zhao Q, 2015, COMPUT MED IMAG GRAP, V41, P108, DOI 10.1016/j.compmedimag.2014.05.011
NR 48
TC 0
Z9 0
U1 3
U2 11
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 1368-5031
EI 1742-1241
J9 INT J CLIN PRACT
JI Int. J. Clin. Pract.
PD MAR 19
PY 2022
VL 2022
AR 9338139
DI 10.1155/2022/9338139
PG 10
WC Medicine, General & Internal; Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine; Pharmacology & Pharmacy
GA 0H0OJ
UT WOS:000778439400001
PM 35685533
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Chen, JW
   Zhang, ZQ
   Xie, XP
   Li, YX
   Xu, T
   Ma, K
   Zheng, YF
AF Chen, Jiawei
   Zhang, Ziqi
   Xie, Xinpeng
   Li, Yuexiang
   Xu, Tao
   Ma, Kai
   Zheng, Yefeng
TI Beyond Mutual Information: Generative Adversarial Network for Domain
   Adaptation Using Information Bottleneck Constraint
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Generative adversarial networks; Task analysis; Image segmentation;
   Adaptation models; Training; Biomedical imaging; Mutual information;
   Information bottleneck; image translation; domain adaptation
ID IMAGE
AB Medical images from multicentres often suffer from the domain shift problem, which makes the deep learning models trained on one domain usually fail to generalize well to another. One of the potential solutions for the problem is the generative adversarial network (GAN), which has the capacity to translate images between different domains. Nevertheless, the existing GAN-based approaches are prone to fail at preserving image-objects in image-to-image (I2I) translation, which reduces their practicality on domain adaptation tasks. In this regard, a novel GAN (namely IB-GAN) is proposed to preserve image-objects during cross-domain I2I adaptation. Specifically, we integrate the information bottleneck constraint into the typical cycle-consistency-based GAN to discard the superfluous information (e.g., domain information) and maintain the consistency of disentangled content features for image-object preservation. The proposed IB-GAN is evaluated on three tasks-polyp segmentation using colonoscopic images, the segmentation of optic disc and cup in fundus images and the whole heart segmentation using multi-modal volumes. We show that the proposed IB-GAN can generate realistic translated images and remarkably boost the generalization of widely used segmentation networks (e.g., U-Net).
C1 [Chen, Jiawei; Zhang, Ziqi; Xie, Xinpeng; Li, Yuexiang; Ma, Kai; Zheng, Yefeng] Tencent Jarvis Lab, Shenzhen 518057, Peoples R China.
   [Zhang, Ziqi; Xu, Tao] Tsinghua Univ, Tsinghua Berkeley Shenzhen Inst, Shenzhen 518055, Peoples R China.
C3 Tsinghua University
RP Li, YX (通讯作者)，Tencent Jarvis Lab, Shenzhen 518057, Peoples R China.
EM jiaweichen@tencent.com; zq-zhang18@mails.tsinghua.edu.cn;
   xavieryxie@tencent.com; vicyxli@tencent.com; taoxu@tsinghua.edu.cn;
   kylekma@tencent.com; yefengzheng@tencent.com
RI li, yueyue/IVH-9846-2023; Zhang, Ziqi/HHN-7875-2022; LI,
   Yue/GRS-8071-2022; li, yue/HSF-7296-2023; li, yue/IXD-9935-2023; li,
   yue/HZL-3265-2023; zhang, ziqi/GPW-6618-2022; Zheng,
   Yefeng/ABG-7053-2020
OI Ma, Kai/0000-0003-2805-3692; Zheng, Yefeng/0000-0003-2195-2847
FU Key-Area Research and Development Program of Guangdong Province, China
   [2018B010111001]; National Key Research and Development Program of China
   [2018YFC2000702, 2020AAA0104100]
FX This work was supported in part by the Key-Area Research and Development
   Program of Guangdong Province, China, under Grant 2018B010111001; in
   part by the National Key Research and Development Program of China under
   Grant 2018YFC2000702; and in part by the Scientific and Technical
   Innovation 2030-"New Generation Artificial Intelligence" Project, under
   Grant 2020AAA0104100.
CR Achille A, 2018, J MACH LEARN RES, V19
   Ajakan H, 2014, ARXIV PREPRINT ARXIV
   Benjdira B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111369
   Bian C, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101732
   Chen C, 2019, AAAI CONF ARTIF INTE, P865
   Chen C, 2018, LECT NOTES COMPUT SC, V11046, P143, DOI 10.1007/978-3-030-00919-9_17
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dou Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P691
   Dou Q, 2019, IEEE ACCESS, V7, P99065, DOI 10.1109/ACCESS.2019.2929258
   Federici M., 2020, 8 INT C LEARNING REP
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hjelm R Devon, 2019, ICLR
   Hoffman J., 2017, ARXIV PREPRINT ARXIV
   Huang SW, 2018, LECT NOTES COMPUT SC, V11213, P731, DOI 10.1007/978-3-030-01240-3_44
   Huang X, 2017, PROC CVPR IEEE, P1866, DOI 10.1109/CVPR.2017.202
   Igl M., 2019, P ADV NEURAL INFORM, V32, P13978
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma D., 2015, ARXIV
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Liu M.-Y., 2016, P 30 INT C NEUR INF, V29, P469
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Liu MY, 2017, ADV NEUR IN, V30
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Luo YW, 2019, IEEE I CONF COMP VIS, P6777, DOI 10.1109/ICCV.2019.00688
   Mahmood F, 2018, IEEE T MED IMAGING, V37, P2572, DOI 10.1109/TMI.2018.2842767
   Pensia Ankit, 2020, IEEE Journal on Selected Areas in Information Theory, V1, P131, DOI 10.1109/JSAIT.2020.2991005
   Qian K., ARXIV200411284, V2020
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Saito Kuniaki, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P382, DOI 10.1007/978-3-030-58580-8_23
   Saxe AM, 2019, J STAT MECH-THEORY E, V2019, DOI 10.1088/1742-5468/ab3985
   Schubert K, 2021, PHILOS SOC CRIT, V47, P634, DOI 10.1177/0191453720917733
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tishby N., 2000, PHYSICS0004057, V49
   Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW)
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Tzeng E, 2014, COMPUT SCI
   Ulyanov D., 2016, INSTANCE NORMALIZATI
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Xinpeng Xie, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12262), P516, DOI 10.1007/978-3-030-59713-9_50
   Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47
   Yang ZG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3374754
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yingying Xue, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12261), P408, DOI 10.1007/978-3-030-59710-8_40
   Zhang TY, 2020, IEEE T MED IMAGING, V39, P1149, DOI 10.1109/TMI.2019.2944488
   Zhang Y, 2018, LECT NOTES COMPUT SC, V11071, P599, DOI 10.1007/978-3-030-00934-2_67
   Zhang ZZ, 2018, PROC CVPR IEEE, P9242, DOI 10.1109/CVPR.2018.00963
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhuang XH, 2016, MED IMAGE ANAL, V31, P77, DOI 10.1016/j.media.2016.02.006
NR 55
TC 5
Z9 5
U1 11
U2 41
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD MAR
PY 2022
VL 41
IS 3
BP 595
EP 607
DI 10.1109/TMI.2021.3117996
PG 13
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA ZP2QG
UT WOS:000766268800009
PM 34606453
DA 2023-08-21
ER

PT J
AU Nisha, JS
   Gopi, VP
   Palanisamy, P
AF Nisha, J. S.
   Gopi, Varun P.
   Palanisamy, P.
TI Automated colorectal polyp detection based on image enhancement and
   dual-path CNN architecture
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Colonoscopy; Dual path convolutional neural network; Sigmoid function;
   Colorectal cancer
ID MISS RATE; COLONOSCOPY; VALIDATION; PCA
AB Colorectal Cancer (CRC) has the highest mortality rate of all cancers and is currently the third leading cause of cancer-related death worldwide. The early detection and diagnosis of colorectal polyps are necessary for early interventional therapies. The use of AI and ML techniques to analyse colonoscopy images has been gaining traction in recent years for early and accurate detection of polyps and other colorectal abnormalities. Existing deep learning classification and detection methods of polyps are computationally intensive, restrict memory potency, require extensive training, and affect the optimization of hyperparameters. This makes them unsuitable for real-time applications and applications with limited computing resources. This paper proposes a Dual-Path Convolutional Neural Network (DP-CNN) to classify polyp and non-polyp patches from the colonoscopy images. The proposed approach comprises image enhancement followed by the use of DP-CNN architecture and a sigmoid classifier for efficient detection of polyps. The publicly available database CVC ClinicDB is used to train the proposed network, and it is tested on ETIS-Larib and CVC ColonDB databases. The testing accuracy of the network on CVC ColonDB and ETIS-Larib are 99.60%, 90.81%, respectively. The performance measures are as follows: precision (100%), recall (99.20%), F1 score (99.60%) and F2 score (99.83%) on CVC ColonDB database and precision (89.81%), recall (92.85%), F1 score (91.00%) and F2 score (89.91%) on ETIS-Larib database. Compared with other existing methods, the proposed approach outperforms in precision, recall, F1-score, and F2-score in both databases. The number of learnable parameters of the proposed method is 8737. The proposed approach is promising as an accurate polyp detection technique. It is applicable for real-time applications due to lower complexity and fewer learnable parameters than required by other existing methods.
C1 [Nisha, J. S.; Gopi, Varun P.; Palanisamy, P.] Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Gopi, VP (通讯作者)，Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamil Nadu, India.
EM varun@nitt.edu; palan@nitt.edu
RI P Gopi, Varun/S-3943-2019
OI P Gopi, Varun/0000-0001-5593-3949; J S, Nisha/0000-0002-9284-6729
CR Akbari M, 2018, IEEE ENG MED BIO, P65, DOI 10.1109/EMBC.2018.8512226
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Behera B, 2019, INT CONF ADV COMPU, P220, DOI [10.1109/icoac48765.2019.246843, 10.1109/ICoAC48765.2019.246843]
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal Jorge, 2015, SCREENING COLORECTAL, P109
   Boroff ES, 2017, GASTROENT RES PRACT, V2017, DOI 10.1155/2017/7207595
   Cheng DC, 2011, BIOMED ENG-APP BAS C, V23, P357, DOI 10.4015/S1016237211002761
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Figueiredo IN, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102035
   Gopi VP, 2017, INT J COMPUT ASS RAD, V12, P2195, DOI 10.1007/s11548-017-1670-x
   Goyal H, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103313
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Han J, 1995, LECT NOTES COMPUT SC, V930, P195
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   Hazewinkel Y, 2011, NAT REV GASTRO HEPAT, V8, P554, DOI 10.1038/nrgastro.2011.141
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Ibraheem N.A., 2012, ARPN J, V2, P265
   Kaur Taranjit, 2019, 2019 International Conference on Information Technology (ICIT), P94, DOI 10.1109/ICIT48102.2019.00023
   Lee JH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76153-8
   Lieberman D, 2005, GASTROINTEST ENDOSC, V61, P392, DOI 10.1016/S0016-5107(05)00133-1
   LIEBERMAN DA, 1991, AM J GASTROENTEROL, V86, P946
   Liu W, 2006, LECT NOTES COMPUT SC, V4233, P481
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   McAllister P, 2018, COMPUT BIOL MED, V95, P217, DOI 10.1016/j.compbiomed.2018.02.008
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Palanisamy G, 2019, SIGNAL IMAGE VIDEO P, V13, P719, DOI 10.1007/s11760-018-1401-y
   Park S., 2015, POLYP DETECTION COLO
   Rahim T, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102654
   Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sahu Smriti, 2012, INT J ELECTR COMPUT, V2, P792, DOI DOI 10.11591/IJECE.V2I6.1513
   Salem N., 2019, PROCEDIA COMPUT SCI, V163, P300, DOI [10.1016/j.procs.2019.12.112, DOI 10.1016/J.PROCS.2019.12.112]
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Singh K., 2020, P 2020 INT C EMERGIN, P1, DOI [10.1109/ic-ETITE47903.2020.195, DOI 10.1109/IC-ETITE47903.2020.195]
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   van der Aar AMG, 2011, J ALLERGY CLIN IMMUN, V127, P1532, DOI 10.1016/j.jaci.2011.01.068
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang C, 2019, IEEE ACCESS, V7, P146533, DOI 10.1109/ACCESS.2019.2946000
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 47
TC 11
Z9 11
U1 4
U2 5
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD MAR
PY 2022
VL 73
AR 103465
DI 10.1016/j.bspc.2021.103465
PG 13
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 2Q6YJ
UT WOS:000820565900005
DA 2023-08-21
ER

PT J
AU Ta, N
   Chen, HP
   Lyu, YD
   Wu, TS
AF Ta, Na
   Chen, Haipeng
   Lyu, Yingda
   Wu, Taosuo
TI BLE-Net: boundary learning and enhancement network for polyp
   segmentation
SO MULTIMEDIA SYSTEMS
LA English
DT Article; Early Access
DE Boundary learning; Polyp segmentation; Boundary-aware attention;
   Coarse-to-fine
ID U-NET; COLONOSCOPY
AB Automatic polyp segmentation can improve the accuracy of colonoscopy and plays a crucial role in colorectal cancer prevention. However, existing U-shaped convolutional neural networks fail to satisfactorily localize the boundaries for polyp region, which inevitably degenerates the performance of polyp segmentation. In this article, we propose a boundary learning and enhancement network (BLE-Net) that finely restores edge localization by combining two novel boundary modules. Specifically, a novel boundary learning (BL) module is deployed on the encoder stage to embed edge details into high-level features via a bottom-up fusion way, thereby producing discriminative features with both semantics and boundary information. Moreover, to strengthen the weak responses at fuzzy boundaries, we further design a boundary enhancement (BE) module, in which three cascaded boundary-aware attention blocks progressively endow ambiguous edge cues and rectify preceding maps in a coarse-to-fine fashion. Extensive experimental results on five polyp datasets demonstrate that BLE-Net has excellent segmentation performance and generalization capability, outperforming the state-of-the-arts.
C1 [Ta, Na; Chen, Haipeng] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Ta, Na] Hulunbuir Univ, Coll Comp, Hulunbuir 021008, Peoples R China.
   [Ta, Na; Chen, Haipeng] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Lyu, Yingda] Jilin Univ, Publ Comp Educ & Res Ctr, Changchun 130012, Peoples R China.
   [Wu, Taosuo] Hulunbuir Univ, Sch Phys & Elect Informat, Hulunbuir 021008, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Lyu, YD (通讯作者)，Jilin Univ, Publ Comp Educ & Res Ctr, Changchun 130012, Peoples R China.
EM ydlv@jlu.edu.cn
FU National Key Research and Development Program of China [2018 YFB0804202,
   2018YFB0804203]; NSFC [U19A2057]; National Natural Science Foundation of
   China [61876070]; Jilin Province Science and Technology Development Plan
   Project [20190303134SF]; Science and Technology Planning Project of
   Inner Mongolia [2020GG0130]; Natural Science Foundation of Inner
   Mongolia [2020MS04007]; Ph.D. Foundation of Hulunbuir University
   [2020BS11]
FX This research is supported by the National Key Research and Development
   Program of China (2018 YFB0804202, 2018YFB0804203), the Regional Joint
   Fund of NSFC (U19A2057), the National Natural Science Foundation of
   China (61876070), the Jilin Province Science and Technology Development
   Plan Project (20190303134SF), the Science and Technology Planning
   Project of Inner Mongolia (2020GG0130), the Natural Science Foundation
   of Inner Mongolia (2020MS04007), and the Ph.D. Foundation of Hulunbuir
   University (2020BS11).
CR Araujo RL, 2022, MULTIMEDIA SYST, V28, P1239, DOI 10.1007/s00530-021-00840-3
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P323, DOI 10.1007/978-3-030-58604-1_20
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fang YQ, 2021, IEEE SENS J, V21, P11799, DOI 10.1109/JSEN.2020.3015831
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Feng RW, 2020, I S BIOMED IMAGING, P225, DOI 10.1109/ISBI45749.2020.9098492
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   Hao SJ, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3398728
   Hao Shijie, 2016, Med Image Comput Comput Assist Interv, V9900, P219, DOI 10.1007/978-3-319-46720-7_26
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Li X, 2021, IEEE T IND INFORM, V17, P1958, DOI 10.1109/TII.2020.2993842
   Lin DY, 2020, PATTERN RECOGN LETT, V138, P267, DOI 10.1016/j.patrec.2020.07.013
   Liu Z, 2021, MULTIMEDIA SYST, V27, P111, DOI 10.1007/s00530-020-00709-x
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lui TKL, 2021, GASTROINTEST ENDOSC, V93, P193, DOI 10.1016/j.gie.2020.04.066
   Luo YW, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTER ENGINEERING (ICAICE 2020), P542, DOI 10.1109/ICAICE51518.2020.00110
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Murugesan B., 2019, ARXIV190108824
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI 10.1109/EMBC.2019.8857339
   Oktay O., 2018, P MIDL, P1, DOI DOI 10.48550/ARXIV.1804.03999
   Qureshi KN, 2022, MULTIMEDIA SYST, V28, P1439, DOI 10.1007/s00530-021-00839-w
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Smith RA, 2018, CA-CANCER J CLIN, V68, P297, DOI 10.3322/caac.21446
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang MX, 2021, MULTIMEDIA SYST, V27, P1091, DOI 10.1007/s00530-021-00783-9
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu JY, 2019, I C DATA ENGIN WORKS, P306, DOI 10.1109/ICDEW.2019.00010
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 48
TC 8
Z9 8
U1 10
U2 28
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0942-4962
EI 1432-1882
J9 MULTIMEDIA SYST
JI Multimedia Syst.
PD 2022 FEB 25
PY 2022
DI 10.1007/s00530-022-00900-2
EA FEB 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH7TU
UT WOS:000761137200001
DA 2023-08-21
ER

PT J
AU Lai, HL
   Luo, Y
   Zhang, GK
   Shen, X
   Li, B
   Lu, JW
AF Lai, Huilin
   Luo, Ye
   Zhang, Guokai
   Shen, Xiaoang
   Li, Bo
   Lu, Jianwei
TI Toward accurate polyp segmentation with cascade boundary-guided
   attention
SO VISUAL COMPUTER
LA English
DT Article
DE Polyp segmentation; Colonoscopy image; Boundary; Attention; Neural
   network
ID MULTISCALE
AB In clinical practice, accurate polyp segmentation provides important information for the early detection of colorectal cancer. Benefiting from the advancement of deep learning techniques, various neural networks have been developed for polyp segmentation. However, most state-of-the-art methods have suffered from the challenge of precisely segmenting polyps with clear boundaries. To tackle this challenge, in this paper, we propose a novel and effective cascade boundary-guided attention network based on an encoder-decoder framework. Specifically, instead of just using the addition of shallow and deep features, the fine-grained boundary information is explicitly introduced into the skip connection of encoder and decoder layers to achieve accurate polyp segmentation. Moreover, the cascade refinement strategy is utilized into the multi-stage enhancement of boundary features to progressively produce better predictions. Extensive evaluations on five public benchmark datasets show that our method outperforms state-of-the-arts on various polyp segmentation tasks. Further experiments conducted on the cross-dataset (training on one dataset and testing on another dataset) validate the generalization ability of the proposed method.
C1 [Lai, Huilin; Luo, Ye; Shen, Xiaoang; Li, Bo; Lu, Jianwei] Tongji Univ, Sch Software Engn, Shanghai 200092, Peoples R China.
   [Luo, Ye] Chinese Acad Sci, Shenyang Inst Automat, State key Lab Robot, Shenyang 110016, Peoples R China.
   [Zhang, Guokai] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Lu, Jianwei] Shanghai Univ Tradit Chinese Med, Coll Rehabil Sci, Shanghai 201203, Peoples R China.
   [Lu, Jianwei] Minist Educ, Engn Res Ctr Tradit Chinese Med Intelligent Rehab, Shanghai 201203, Peoples R China.
C3 Tongji University; Chinese Academy of Sciences; Shenyang Institute of
   Automation, CAS; University of Shanghai for Science & Technology;
   Shanghai University of Traditional Chinese Medicine
RP Luo, Y; Lu, JW (通讯作者)，Tongji Univ, Sch Software Engn, Shanghai 200092, Peoples R China.; Luo, Y (通讯作者)，Chinese Acad Sci, Shenyang Inst Automat, State key Lab Robot, Shenyang 110016, Peoples R China.; Lu, JW (通讯作者)，Shanghai Univ Tradit Chinese Med, Coll Rehabil Sci, Shanghai 201203, Peoples R China.; Lu, JW (通讯作者)，Minist Educ, Engn Res Ctr Tradit Chinese Med Intelligent Rehab, Shanghai 201203, Peoples R China.
EM yeluo@tongji.edu.cn; jwlu33@tongji.edu.cn
FU National Natural Science Foundation of China (NSFC) [61806147,
   62102259]; Shanghai Sailing Program [21YF1431600]; StateKey Laboratory
   of Robotics [2019O15]
FX This work was supported by the General Program of National Natural
   Science Foundation of China (NSFC) (Grant No. 61806147), the Shanghai
   Sailing Program (21YF1431600), the General Program of National Natural
   Science Foundation of China (NSFC) (Grant No. 62102259), and the
   StateKey Laboratory ofRobotics (2019O15).
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Cheng ZM, 2022, VISUAL COMPUT, V38, P749, DOI 10.1007/s00371-021-02075-9
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2021, IEEE SENS J, V21, P11799, DOI 10.1109/JSEN.2020.3015831
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Galdran Adrian, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P293, DOI 10.1007/978-3-030-68763-2_22
   Ho Jonathan, 2019, ARXIV191212180
   Huang LY, 2022, VISUAL COMPUT, V38, P135, DOI 10.1007/s00371-020-02008-y
   Huang SW, 2012, ADV MATER RES-SWITZ, V340, P70, DOI 10.4028/www.scientific.net/AMR.340.70
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jiang M, 2022, VISUAL COMPUT, V38, P2473, DOI 10.1007/s00371-021-02124-3
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI 10.1109/EMBC.2019.8857339
   Oktay O., 2018, P MIDL, P1, DOI DOI 10.48550/ARXIV.1804.03999
   Pal S, 2019, MULTIDIM SYST SIGN P, V30, P373, DOI 10.1007/s11045-018-0561-9
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Qian X., 2021, VISUAL COMPUT, P1
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Rutter CM, 2012, CANCER CAUSE CONTROL, V23, P289, DOI 10.1007/s10552-011-9878-5
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang D, 2021, VISUAL COMPUT, V37, P1101, DOI 10.1007/s00371-020-01855-z
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Yeung M, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104815
   Yue KY, 2018, ADV NEUR IN, V31
   Zhang GK, 2022, IEEE J BIOMED HEALTH, V26, P5298, DOI 10.1109/JBHI.2021.3127688
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhao Y., 2006, 2006 6 WORLD C INT C, V2, P9795
   Zhou YN, 2019, LECT NOTES COMPUT SC, V11492, P682, DOI 10.1007/978-3-030-20351-1_53
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
   Zhu L., 2021, P IEEECVF INT C COMP, P12292
NR 50
TC 4
Z9 4
U1 4
U2 16
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PD APR
PY 2023
VL 39
IS 4
BP 1453
EP 1469
DI 10.1007/s00371-022-02422-4
EA FEB 2022
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C3OY5
UT WOS:000759383200002
DA 2023-08-21
ER

PT J
AU Hasan, MM
   Hossain, MM
   Mia, S
   Ahammad, MS
   Rahman, MM
AF Hasan, Md Mahmodul
   Hossain, Muhammad Minoar
   Mia, Shisir
   Ahammad, Mohd Sultan
   Rahman, Mohammad Motiur
TI A combined approach of non-subsampled contourlet transform and
   convolutional neural network to detect gastrointestinal polyp
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gastrointestinal polyp detection; Convolutional neural network; NSCT;
   Feature reduction; Polyp detection; Multi-criteria decision making
AB The abnormal growth of tissues that disarray the typical organization of cells is popularly known as polyps. The polyp on the gastrointestinal is a primary sign of gastrointestinal cancer. False diagnosis is extremely high using traditional diagnosis procedures that make the polyp diagnosis is a crucial task in real-time colonoscopy. We have developed a polyp detection methodology using a combination of hand-crafted and automated feature extraction techniques. In this study, we have experimented with different convolutional neural network (CNN) architectures and hand-crafted feature extractors to select the best combination. The combined approach of the fine-tuned Xception model with non-subsampled contourlet transform (NSCT) performed significantly well. Besides, we have applied the multi-criteria frame selection technique for selecting the best images from colonoscopy videos. Afterward, the feature extractors have worked on enhanced patch images of selected frames. This study has also experimented with dimensionality reduction techniques to remove irrelevant features from the combined feature vector. We designed an algorithm to localize the polyp regions using the outcomes of patch images. The method did significantly well on several available public datasets. This work might be helpful for the endoscopist during real-time endoscopy to detect polyps.
C1 [Hasan, Md Mahmodul; Hossain, Muhammad Minoar; Mia, Shisir; Ahammad, Mohd Sultan; Rahman, Mohammad Motiur] Mawlana Bhashani Sci & Technol Univ, Dept Comp Sci & Engn, Tangail 1902, Bangladesh.
C3 Mawlana Bhashani Science & Technology University
RP Rahman, MM (通讯作者)，Mawlana Bhashani Sci & Technol Univ, Dept Comp Sci & Engn, Tangail 1902, Bangladesh.
EM mahmodul.mbstu@gmail.com; minoarhossain16005@gmail.com;
   shisircse31@yahoo.com; sultan.ahammad36@gmail.com; motiurcse@mbstu.ac.bd
RI Rahman, Mohammad Motiur/AAR-2994-2020
OI Rahman, Mohammad Motiur/0000-0003-4417-8276
CR Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   [Anonymous], 2009, J MACH LEARN RES JML
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Billah M, 2020, MULTIMED TOOLS APPL, V79, P23633, DOI 10.1007/s11042-020-09151-7
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Das TK, 2020, J BIOMIM BIOMATER BI, V45, P57, DOI 10.4028/www.scientific.net/JBBBE.45.57
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Gopalakrishnan K, 2017, CONSTR BUILD MATER, V157, P322, DOI 10.1016/j.conbuildmat.2017.09.110
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   Hu YF, 2016, IEEE T MED IMAGING, V35, P1522, DOI 10.1109/TMI.2016.2518958
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Ma C, 2019, AM J GASTROENTEROL, V114, P1802, DOI 10.14309/ajg.0000000000000407
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song MY, 2020, LANCET GASTROENTEROL, V5, P537, DOI 10.1016/S2468-1253(20)30009-1
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wimmer G, 2016, INT C PATT RECOG, P2150, DOI 10.1109/ICPR.2016.7899954
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
NR 35
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 FEB 14
PY 2022
DI 10.1007/s11042-022-12250-2
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZA9TO
UT WOS:000756497800010
DA 2023-08-21
ER

PT J
AU Yao, LW
   Zhang, LH
   Liu, J
   Zhou, W
   He, CP
   Zhang, J
   Wu, LL
   Wang, HG
   Xu, YM
   Gong, DX
   Xu, M
   Li, X
   Bai, YT
   Gong, RR
   Sharma, P
   Yu, HG
AF Yao, Liwen
   Zhang, Lihui
   Liu, Jun
   Zhou, Wei
   He, Chunping
   Zhang, Jun
   Wu, Lianlian
   Wang, Hongguang
   Xu, Youming
   Gong, Dexin
   Xu, Ming
   Li, Xun
   Bai, Yutong
   Gong, Rongrong
   Sharma, Prateek
   Yu, Honggang
TI Effect of an artificial intelligence-based quality improvement system on
   efficacy of a computer-aided detection system in colonoscopy: a
   four-group parallel study
SO ENDOSCOPY
LA English
DT Article
ID ADENOMA DETECTION; COLORECTAL-CANCER; WITHDRAWAL TIME; TRIAL
AB Background Tandem colonoscopy studies have found that about one in five adenomas are missed at colonoscopy. It remains debatable whether the combination of a computer-aided polyp detection (CADe) system with a computer-aided quality improvement (CAQ) system for real-time monitoring of withdrawal speed results in additional benefits in adenoma detection or if the synergetic effect may be harmed due to excessive visual burden resulting from information overload. This study aimed to evaluate the interaction effect on improving the adenoma detection rate (ADR).
   Methods This single-center, randomized, four-group, parallel, controlled study was performed at Renmin Hospital of Wuhan University. Between 1 July and 15 October 2020, 1076 patients were randomly allocated into four treatment groups: control 271, CADe 268, CAQ 269, and CADe plus CAQ (COMBO) 268. The primary outcome was ADR.
   Results The ADR in the control, CADe, CAQ, and COMBO groups was 14.76% (95% confidence interval [CI] 10.54 to 18.98), 21.27% (95 %CI 16.37 to 26.17), 24.54% (95 %CI 19.39 to 29.68), and 30.60% (95 %CI 25.08 to 36.11), respectively. The ADR was higher in the COMBO group compared with the CADe group (21.27% vs. 30.6%, P = 0.024, odds ratio [OR] 1.284, 95 %CI 1.033 to 1.596) but not compared with the CAQ group (24.54% vs. 30.6%, P = 0.213, OR 1.309, 95 %CI 0.857 to 2.000, respectively).
   Conclusions CAQ significantly improved the efficacy of CADe in a four-group, parallel, controlled study. No significant difference in the ADR or polyp detection rate was found between CAQ and COMBO.
C1 [Yao, Liwen; Zhang, Lihui; Liu, Jun; Zhou, Wei; He, Chunping; Zhang, Jun; Wu, Lianlian; Xu, Youming; Gong, Dexin; Xu, Ming; Li, Xun; Bai, Yutong; Gong, Rongrong; Yu, Honggang] Wuhan Univ, Dept Gastroenterol, Renmin Hosp, 99 Zhangzhidong Rd, Wuhan 430060, Hubei, Peoples R China.
   [Yao, Liwen; Zhang, Lihui; Zhou, Wei; He, Chunping; Zhang, Jun; Wu, Lianlian; Xu, Youming; Gong, Dexin; Xu, Ming; Li, Xun; Bai, Yutong; Gong, Rongrong; Yu, Honggang] Wuhan Univ, Key Lab Hubei Prov Digest Syst Dis, Renmin Hosp, Wuhan, Peoples R China.
   [Yao, Liwen; Zhang, Lihui; Zhou, Wei; He, Chunping; Zhang, Jun; Wu, Lianlian; Xu, Youming; Gong, Dexin; Xu, Ming; Li, Xun; Bai, Yutong; Gong, Rongrong; Yu, Honggang] Wuhan Univ, Hubei Prov Clin Res Ctr Digest Dis Minimally Inva, Renmin Hosp, Wuhan, Peoples R China.
   [Liu, Jun] Wuhan Univ, Dept Nursing, Renmin Hosp, Wuhan, Peoples R China.
   [Wang, Hongguang] Jilin Renmin Hosp, Dept Gastroenterol, Jilin, Jilin, Peoples R China.
   [Sharma, Prateek] Univ Kansas, Sch Med, Kansas City, MO USA.
   [Sharma, Prateek] Univ Kansas, Vet Affairs Med Ctr, Kansas City, MO USA.
C3 Wuhan University; Wuhan University; Wuhan University; Wuhan University;
   University of Kansas; University of Kansas; US Department of Veterans
   Affairs; Veterans Health Administration (VHA)
RP Yu, HG (通讯作者)，Wuhan Univ, Dept Gastroenterol, Renmin Hosp, 99 Zhangzhidong Rd, Wuhan 430060, Hubei, Peoples R China.
EM yuhonggang@whu.edu.cn
RI Sharma, Prateek/IZE-3910-2023
OI Yao, Liwen/0000-0001-5412-9991
FU Project of Hubei Provincial Clinical Research Center for Digestive
   Disease Minimally Invasive Incisio [2018BCC337]; Hubei Province Major
   Science and Technology Innovation Project [2018-916-000-008]
FX the Project of Hubei Provincial Clinical Research Center for Digestive
   Disease Minimally Invasive Incisio 2018BCC337; Hubei Province Major
   Science and Technology Innovation Project 2018-916-000-008
CR Adler A, 2013, GUT, V62, P236, DOI 10.1136/gutjnl-2011-300167
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Bailey CE, 2015, JAMA SURG, V150, P17, DOI 10.1001/jamasurg.2014.1756
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Click B, 2018, JAMA-J AM MED ASSOC, V319, P2021, DOI 10.1001/jama.2018.5809
   Crockett SD, 2019, GASTROENTEROLOGY, V157, P949, DOI 10.1053/j.gastro.2019.06.041
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hung IFN, 2020, LANCET, V395, P1695, DOI 10.1016/S0140-6736(20)31042-4
   Jung Y, 2019, GASTROINTEST ENDOSC, V89, P523, DOI 10.1016/j.gie.2018.09.016
   Kudo T, 2018, GASTROINTEST ENDOSC, V88, P854, DOI 10.1016/j.gie.2018.06.011
   Lami M, 2018, ENDOSCOPY, V50, P701, DOI 10.1055/s-0044-101026
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Sawhney MS, 2008, GASTROENTEROLOGY, V135, P1892, DOI 10.1053/j.gastro.2008.08.024
   Shaukat A, 2015, GASTROENTEROLOGY, V149, P952, DOI 10.1053/j.gastro.2015.06.044
   Siegel RL., 2020, CA-CANCER J CLIN, V70, P145, DOI [DOI 10.3322/caac.21590, 10.3322/caac.21601]
   Suzuki S, 2020, GUT, V69, P1019, DOI 10.1136/gutjnl-2019-319954
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 26
TC 22
Z9 22
U1 2
U2 9
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD AUG
PY 2022
VL 54
IS 08
BP 757
EP 768
DI 10.1055/a-1706-6174
EA FEB 2022
PG 12
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 3O7EG
UT WOS:000836995600040
PM 34823258
OA Bronze
DA 2023-08-21
ER

PT J
AU Khadka, R
   Jha, D
   Hicks, S
   Thambawita, V
   Riegler, MA
   Ali, S
   Halvorsen, P
AF Khadka, Rabindra
   Jha, Debesh
   Hicks, Steven
   Thambawita, Vajira
   Riegler, Michael A.
   Ali, Sharib
   Halvorsen, Pal
TI Meta-learning with implicit gradients in a few-shot setting for medical
   image segmentation
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Meta-learning; Few-shot learning; Colonoscopy; Polyp segmentation;
   Wireless capsule endoscopy; Skin lesion segmentation; Generalization
ID NETWORK
AB Widely used traditional supervised deep learning methods require a large number of training samples but often fail to generalize on unseen datasets. Therefore, a more general application of any trained model is quite limited for medical imaging for clinical practice. Using separately trained models for each unique lesion category or a unique patient population will require sufficiently large curated datasets, which is not practical to use in a real world clinical set-up. Few-shot learning approaches can not only minimize the need for an enormous number of reliable ground truth labels that are labour-intensive and expensive, but can also be used to model on a dataset coming from a new population. To this end, we propose to exploit an optimization-based implicit model agnostic meta-learning (iMAML) algorithm under few-shot settings for medical image segmentation. Our approach can leverage the learned weights from diverse but small training samples to perform analysis on unseen datasets with high accuracy. We show that, unlike classical few-shot learning approaches, our method improves generalization capability. To our knowledge, this is the first work that exploits iMAML for medical image segmentation and explores the strength of the model on scenarios such as meta-training on unique and mixed instances of lesion datasets. Our quantitative results on publicly available skin and polyp datasets show that the proposed method outperforms the naive supervised baseline model and two recent few-shot segmentation approaches by large margins. In addition, our iMAML approach shows an improvement of 2%-4% in dice score compared to its counterpart MAML for most experiments.
C1 [Khadka, Rabindra; Jha, Debesh; Hicks, Steven; Thambawita, Vajira; Riegler, Michael A.; Halvorsen, Pal] SimulaMet, Oslo, Norway.
   [Jha, Debesh; Riegler, Michael A.] UiT Arctic Univ Norway, Tromso, Norway.
   [Ali, Sharib] Univ Oxford, Inst Biomed Engn, Dept Engn Sci, Oxford, Oxon, England.
   [Khadka, Rabindra; Hicks, Steven; Thambawita, Vajira] Oslo Metropolitan Univ, Oslo, Norway.
   [Ali, Sharib] Univ Oxford, NIHR Oxford Biomed Res Ctr, Oxford, Oxon, England.
C3 UiT The Arctic University of Tromso; University of Oxford; Oslo
   Metropolitan University (OsloMet); University of Oxford
RP Jha, D (通讯作者)，SimulaMet, Oslo, Norway.; Ali, S (通讯作者)，Univ Oxford, Inst Biomed Engn, Dept Engn Sci, Oxford, Oxon, England.
EM debesh@simula.no; sharib.ali@eng.ox.ac.uk
RI Thambawita, Vajira/R-8469-2017; Ali, Sharib/U-3807-2019
OI Thambawita, Vajira/0000-0001-6026-0929; Ali, Sharib/0000-0003-1313-3542;
   Jha, Debesh/0000-0002-8078-6730
FU Research Council of Norway (RCN) [263 248, 270 053]; National Institute
   for Health Research (NIHR) Oxford Biomedical Research Centre (BRC)
FX D. Jha is funded by the PRIVATON project (#263 248) which is funded by
   Research Council of Norway (RCN) . S. Ali is supported by the National
   Institute for Health Research (NIHR) Oxford Biomedical Research Centre
   (BRC) . Our experiments were performed on the Experimental
   Infrastructure for Exploration of Exascale Computing (eX3) system, which
   is financially supported by RCN under contract 270 053. The views
   expressed are those of the author (s) and not necessarily those of the
   NHS, the NIHR or the Department of Health.
CR Ali S, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102002
   Ali S, 2020, LECT NOTES COMPUT SC, V12436, P494, DOI 10.1007/978-3-030-59861-7_50
   Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brown JM, 2018, JAMA OPHTHALMOL, V136, P803, DOI 10.1001/jamaophthalmol.2018.1934
   Castro DC, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17478-w
   Celik N., 2021, INT C MED IM COMP CO
   Cheng Ouyang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P762, DOI 10.1007/978-3-030-58526-6_45
   Dou Q., 2019, P C NEUR INF PROC SY
   Feyjie A.R., 2020, ARXIV PREPRINT ARXIV
   Finn C, 2017, PR MACH LEARN RES, V70
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Hinton G, 2018, JAMA-J AM MED ASSOC, V320, P1101, DOI 10.1001/jama.2018.11100
   Horng S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174708
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P115, DOI 10.1109/cibcb48159.2020.9277638
   Jha Debesh, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P218, DOI 10.1007/978-3-030-67835-7_19
   Jha D, 2021, COMP MED SY, P37, DOI 10.1109/CBMS52027.2021.00014
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Khadka R., 2021, THESIS
   Khandelwal Pulkit, 2020, Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning. Second MICCAI Workshop, DART 2020 and First MICCAI Workshop, DCL 2020 Held in Conjunction with MICCAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12444), P73, DOI 10.1007/978-3-030-60548-3_8
   Kingma D, 2014, P 3 INT C LEARN REPR
   Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591
   Ma YD, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P743
   Mahajan K., 2020, PROC IEEECVF C COMPU, P730
   Marchetti M, 2019, ARXIV PREPRINT ARXIV
   Mendonca T, 2013, IEEE ENG MED BIO, P5437
   Motiian S, 2017, IEEE I CONF COMP VIS, P5716, DOI 10.1109/ICCV.2017.609
   Oktay O., 2018, P MIDL, P1, DOI DOI 10.48550/ARXIV.1804.03999
   Oliver A, 2018, ADV NEUR IN, V31
   Pedano N., 2016, CANC IMAG ARCH, V2
   Quande Liu, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12262), P475, DOI 10.1007/978-3-030-59713-9_46
   Rajeswaran A, 2019, ADV NEUR IN, V32
   Ravi Sachin, 2016, OPTIMIZATION MODEL F
   Roy AG, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101587
   Rutter Erica M., 2019, Domain Adaptation and Representation Transfer and Medical Image Learning with Less Labels and Imperfect Data. First MICCAI Workshop, DART 2019 and First International Workshop, MIL3ID 2019 Shenzhen, Held in Conjunction with MICCAI 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11795), P190, DOI 10.1007/978-3-030-33391-1_22
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Smedsrud PH, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00920-z
   Song YY, 2017, IEEE J BIOMED HEALTH, V21, P1095, DOI 10.1109/JBHI.2016.2594239
   Song YY, 2017, IEEE T MED IMAGING, V36, P288, DOI 10.1109/TMI.2016.2606380
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Thrun S., 2012, LEARNING LEARN
   Tian SK, 2021, IEEE T MED IMAGING, V40, P2415, DOI 10.1109/TMI.2021.3077334
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Xiao JS, 2023, COMPUTING, V105, P717, DOI 10.1007/s00607-021-00907-z
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   You CY, 2020, IEEE T MED IMAGING, V39, P188, DOI 10.1109/TMI.2019.2922960
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhang PH, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020031
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
NR 51
TC 10
Z9 10
U1 8
U2 32
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD APR
PY 2022
VL 143
AR 105227
DI 10.1016/j.compbiomed.2022.105227
EA FEB 2022
PG 10
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 0V1JB
UT WOS:000788100400002
PM 35124439
OA Green Submitted, hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Nisha, JS
   Gopi, VP
   Palanisamy, P
AF Nisha, J. S.
   Gopi, V. P.
   Palanisamy, P.
TI AUTOMATED POLYP DETECTION IN COLONOSCOPY VIDEOS USING IMAGE ENHANCEMENT
   AND SALIENCY DETECTION ALGORITHM
SO BIOMEDICAL ENGINEERING-APPLICATIONS BASIS COMMUNICATIONS
LA English
DT Article
DE Colonoscopy; Image enhancement; Saliency map formation; HOG feature
   extractor; SVM classifier
ID COLORECTAL POLYPS; MISS RATE; VALIDATION
AB Colonoscopy has proven to be an active diagnostic tool that examines the lower half of the digestive system's anomalies. This paper confers a Computer-Aided Detection (CAD) method for polyps from colonoscopy images that helps to diagnose the early stage of Colorectal Cancer (CRC). The proposed method consists primarily of image enhancement, followed by the creation of a saliency map, feature extraction using the Histogram of Oriented-Gradients (HOG) feature extractor, and classification using the Support Vector Machine (SVM). We present an efficient image enhancement algorithm for highlighting clinically significant features in colonoscopy images. The proposed enhancement approach can improve the overall contrast and brightness by minimizing the effects of inconsistent illumination conditions. Detailed experiments have been conducted using the publicly available colonoscopy databases CVC ClinicDB, CVC ColonDB and the ETIS Larib. The performance measures are found to be in terms of precision (91.69%), recall (81.53%), F1-score (86.31%) and F2-score (89.45%) for the CVC ColonDB database and precision (90.29%), recall (61.73%), F1-score (73.32%) and F2-score (82.64%) for the ETIS Larib database. Comparison with the futuristic method shows that the proposed approach surpasses the existing one in terms of precision, F1-score, and F2-score. The proposed enhancement with saliency-based selection significantly reduced the number of search windows, resulting in an efficient polyp detection algorithm.
C1 [Nisha, J. S.; Gopi, V. P.; Palanisamy, P.] Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Gopi, VP (通讯作者)，Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli 620015, Tamil Nadu, India.
EM varun@nitt.edu
RI P Gopi, Varun/S-3943-2019; PONNUSAMY, PALANISAMY/AAM-5285-2020
OI P Gopi, Varun/0000-0001-5593-3949; PONNUSAMY,
   PALANISAMY/0000-0003-3687-5944; J S, Nisha/0000-0002-9284-6729
CR Al Sadeque Z, 2019, INT CONF ADV ELECTR, P21, DOI [10.1109/icaee48663.2019.8975602, 10.1109/ICAEE48663.2019.8975602]
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J., 2015, SCREENING COLORECTAL, V109
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Boroff ES., 2017, GASTROENT RES PRACT, V2017, P16
   Cheng DC, 2011, BIOMED ENG-APP BAS C, V23, P357, DOI 10.4015/S1016237211002761
   Dalal N., 2005, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2005.177
   Damkliang K, 2021, BIOMED ENG-APP BAS C, V33, DOI 10.4015/S1016237221500228
   Daqi G., 2007, IJCNN, P2971, DOI 10.1109/IJCNN.2007.4371433
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Deeba F, 2016, IEEE ENG MED BIO, P3871, DOI 10.1109/EMBC.2016.7591573
   Figueiredo IN, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102035
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Hasan M., 2020, J KING SAUD U COMPUT
   Hazewinkel Y, 2011, NAT REV GASTRO HEPAT, V8, P554, DOI 10.1038/nrgastro.2011.141
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   k Geetha, 2016, Asian Pac J Cancer Prev, V17, P4869
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Lieberman D, 2005, GASTROINTEST ENDOSC, V61, P392, DOI 10.1016/S0016-5107(05)00133-1
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Novitasari Dian Candra Rini, 2019, 2019 International Conference on Advanced Mechatronics, Intelligent Manufacture and Industrial Automation (ICAMIMIA), P185, DOI 10.1109/ICAMIMIA47173.2019.9223361
   Rahtu Esa, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1137, DOI 10.1109/ICCVW.2009.5457577
   Renukadevi NT., 2013, INT J COMPUT SCI INF, V13, P975
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sahu Smriti, 2012, INT J ELECTR COMPUT, V2, P792, DOI DOI 10.11591/IJECE.V2I6.1513
   Salem N., 2019, PROCEDIA COMPUT SCI, V163, P300, DOI [10.1016/j.procs.2019.12.112, DOI 10.1016/J.PROCS.2019.12.112]
   Siegel RL., 2020, CA-CANCER J CLIN, V70, P145, DOI [DOI 10.3322/caac.21590, 10.3322/caac.21601]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Timotius IK, 2012, BIOMED ENG-APP BAS C, V24, P71, DOI 10.4015/S1016237212002962
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Yeh J-Y, 2014, J SOFTWARE ENG APPL, V7, P422, DOI DOI 10.4236/JSEA.2014.75039
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhou M, 2018, IEEE T BIO-MED ENG, V65, P521, DOI 10.1109/TBME.2017.2700627
NR 44
TC 0
Z9 0
U1 0
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 1016-2372
EI 1793-7132
J9 BIOMED ENG-APP BAS C
JI Biomed. Eng.-Appl. Basis Commun.
PD FEB
PY 2022
VL 34
IS 01
AR 2250001
DI 10.4015/S1016237222500016
PG 14
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA ZF3XB
UT WOS:000759503000008
DA 2023-08-21
ER

PT J
AU Reuss, J
   Pascual, G
   Wenzek, H
   Segui, S
AF Reuss, Joana
   Pascual, Guillem
   Wenzek, Hagen
   Segui, Santi
TI Sequential Models for Endoluminal Image Classification
SO DIAGNOSTICS
LA English
DT Article
DE polyp detection; wireless capsule endoscopy (WCE); endoluminal image
   classification; neural networks; sequential models
ID RECOGNITION
AB Wireless Capsule Endoscopy (WCE) is a procedure to examine the human digestive system for potential mucosal polyps, tumours, or bleedings using an encapsulated camera. This work focuses on polyp detection within WCE videos through Machine Learning. When using Machine Learning in the medical field, scarce and unbalanced datasets often make it hard to receive a satisfying performance. We claim that using Sequential Models in order to take the temporal nature of the data into account improves the performance of previous approaches. Thus, we present a bidirectional Long Short-Term Memory Network (BLSTM), a sequential network that is particularly designed for temporal data. We find the BLSTM Network outperforms non-sequential architectures and other previous models, receiving a final Area under the Curve of 93.83%. Experiments show that our method of extracting spatial and temporal features yields better performance and could be a possible method to decrease the time needed by physicians to analyse the video material.
C1 [Reuss, Joana; Pascual, Guillem; Segui, Santi] Univ Barcelona, Dept Math & Comp Sci, Barcelona 08007, Spain.
   [Reuss, Joana] Tech Univ Munich, Chair Remote Sensing Technol, D-80333 Munich, Germany.
   [Wenzek, Hagen] CorporateHlth Int ApS, DK-5230 Odense, Denmark.
C3 University of Barcelona; Technical University of Munich
RP Reuss, J (通讯作者)，Univ Barcelona, Dept Math & Comp Sci, Barcelona 08007, Spain.; Reuss, J (通讯作者)，Tech Univ Munich, Chair Remote Sensing Technol, D-80333 Munich, Germany.
EM joana.reuss@tum.de; guillem.pascual@ub.edu; hagen@corphealth.co;
   santi.segui@ub.edu
RI Segui, Santi/E-4860-2010
OI Segui, Santi/0000-0002-8603-138X; Wenzek, Hagen/0000-0002-5395-4567;
   Reuss, Joana/0000-0001-5842-0356; Pascual, Guillem/0000-0003-1892-7042
FU MINECO/FEDER [RTI2018-095232-B-C21]; Generalitat de Catalunya
   [2017.SGR.1742]; Innovate UK project [104633]; NIHR [AI AWARD02440];
   NHSX; FPU (Ministerio de Universidades, Spain) [FPU16/06843]; Innovate
   UK [104633] Funding Source: UKRI; National Institutes of Health Research
   (NIHR) [AI_AWARD02440] Funding Source: National Institutes of Health
   Research (NIHR)
FX This work has been partially funded by project RTI2018-095232-B-C21
   (MINECO/FEDER), 2017.SGR.1742 (Generalitat de Catalunya), Innovate UK
   project 104633, AI AWARD02440 project from NIHR and NHSX and the FPU
   grant FPU16/06843 (Ministerio de Universidades, Spain).
CR Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Guo XQ, 2019, LECT NOTES COMPUT SC, V11764, P293, DOI 10.1007/978-3-030-32239-7_33
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kim J, 2017, INTERSPEECH, P1591, DOI 10.21437/Interspeech.2017-477
   Laiz P, 2020, COMPUT MED IMAG GRAP, V86, DOI 10.1016/j.compmedimag.2020.101794
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Mohammed A, 2020, COMPUT VIS IMAGE UND, V201, DOI 10.1016/j.cviu.2020.103062
   Nair V., 2010, P 27 INT C MACHINE L, P807, DOI DOI 10.5555/3104322.3104425
   Pascual G., 2021, TIME BASED SELF SUPE
   Rahim T, 2020, COMPUT MED IMAG GRAP, V85, DOI 10.1016/j.compmedimag.2020.101767
   Raschka S., 2018, PREPRINT, DOI DOI 10.48550/ARXIV.1811.12808
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Siegel RL., 2020, CA-CANCER J CLIN, V70, P145, DOI [DOI 10.3322/caac.21590, 10.3322/caac.21601]
   Swain P, 2001, PROC SPIE, V4158, P19
   Takada K, 2020, DIGEST ENDOSC, V32, P529, DOI 10.1111/den.13659
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yuan YX, 2020, IEEE T AUTOM SCI ENG, V17, P574, DOI 10.1109/TASE.2019.2936645
   Yuan YX, 2018, LECT NOTES COMPUT SC, V11071, P620, DOI 10.1007/978-3-030-00934-2_69
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
NR 24
TC 0
Z9 0
U1 0
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD FEB
PY 2022
VL 12
IS 2
AR 501
DI 10.3390/diagnostics12020501
PG 11
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA ZM4TG
UT WOS:000764351200001
PM 35204591
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Shin, W
   Lee, MS
   Han, SW
AF Shin, Wooseok
   Lee, Min Seok
   Han, Sung Won
TI COMMA: Propagating Complementary Multi-Level Aggregation Network for
   Polyp Segmentation
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE colorectal cancer; colonoscopy; polyp segmentation; deep learning;
   convolutional neural network
AB Colonoscopy is an effective method for detecting polyps to prevent colon cancer. Existing studies have achieved satisfactory polyp detection performance by aggregating low-level boundary and high-level region information in convolutional neural networks (CNNs) for precise polyp segmentation in colonoscopy images. However, multi-level aggregation provides limited polyp segmentation owing to the distribution discrepancy that occurs when integrating different layer representations. To address this problem, previous studies have employed complementary low- and high- level representations. In contrast to existing methods, we focus on propagating complementary information such that the complementary low-level explicit boundary with abstracted high-level representations diminishes the discrepancy. This study proposes COMMA, which propagates complementary multi-level aggregation to reduce distribution discrepancies. COMMA comprises a complementary masking module (CMM) and a boundary propagation module (BPM) as a multi-decoder. The CMM masks the low-level boundary noises through the abstracted high-level representation and leverages the masked information at both levels. Similarly, the BPM incorporates the lowest- and highest-level representations to obtain explicit boundary information and propagates the boundary to the CMMs to improve polyp detection. CMMs can discriminate polyps more elaborately than prior CMMs based on boundary and complementary representations. Moreover, we propose a hybrid loss function to mitigate class imbalance and noisy annotations in polyp segmentation. To evaluate the COMMA performance, we conducted experiments on five benchmark datasets using five metrics. The results proved that the proposed network outperforms state-of-the-art methods in terms of all datasets. Specifically, COMMA improved mIoU performance by 0.043 on average for all datasets compared to the existing state-of-the-art methods.
C1 [Shin, Wooseok; Lee, Min Seok; Han, Sung Won] Korea Univ, Sch Ind & Management Engn, 145 Anam Ro, Seoul 02841, South Korea.
C3 Korea University
RP Han, SW (通讯作者)，Korea Univ, Sch Ind & Management Engn, 145 Anam Ro, Seoul 02841, South Korea.
EM wsshin95@korea.ac.kr; karel@korea.ac.kr; swhan@korea.ac.kr
OI Han, Sung Won/0000-0002-0040-3542; Shin, Wooseok/0000-0002-8475-4795;
   Lee, Min Seok/0000-0002-8028-3260
FU Brain Korea 21 FOUR; National Research Foundation of Korea
   [NRF-2019R1F1A1060250]
FX FundingThis research was supported by Brain Korea 21 FOUR. This research
   was also supported by National Research Foundation of Korea
   (NRF-2019R1F1A1060250).
CR Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Cao FL, 2022, INT J MACH LEARN CYB, V13, P1461, DOI 10.1007/s13042-021-01459-6
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dongchao Wang, 2021, Proceedings of the 2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS), P88, DOI 10.1109/DDCLS52934.2021.9455514
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Ghosh A., 2017, P AAAI C ART INT SAN, V31
   Granados-Romero JJ, 2017, INT J RES MED SCI, V5, P4667, DOI [10.18203/2320-6012.ijrms20174914, DOI 10.18203/2320-6012.IJRMS20174914]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   JAIN V, 2009, ADV NEURAL INFORM PR, P769
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji GP, 2021, LECT NOTES COMPUT SC, V12901, P142, DOI 10.1007/978-3-030-87193-2_14
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Marmol I, 2017, INT J MOL SCI, V18, DOI 10.3390/ijms18010197
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI 10.1109/EMBC.2019.8857339
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/crv52889.2021.00032, 10.1109/CRV52889.2021.00032]
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Schreuders EH, 2015, GUT, V64, P1637, DOI 10.1136/gutjnl-2014-309086
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang GT, 2020, IEEE T MED IMAGING, V39, P2653, DOI 10.1109/TMI.2020.3000314
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 46
TC 1
Z9 1
U1 1
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD FEB
PY 2022
VL 12
IS 4
AR 2114
DI 10.3390/app12042114
PG 17
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA ZL5JR
UT WOS:000763713800001
OA gold
DA 2023-08-21
ER

PT J
AU Pacal, I
   Karaman, A
   Karaboga, D
   Akay, B
   Basturk, A
   Nalbantoglu, U
   Coskun, S
AF Pacal, Ishak
   Karaman, Ahmet
   Karaboga, Dervis
   Akay, Bahriye
   Basturk, Alper
   Nalbantoglu, Ufuk
   Coskun, Seymanur
TI An efficient real-time colonic polyp detection with YOLO algorithms
   trained by using negative samples and large datasets
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp detection; Deep learning; Medical image analysis; YOLOv4; YOLOv3;
   Scaled-YOLOv4; YOLOv4-CSP; Rectal cancer; Colon cancer; Real-time polyp
   detection; Negative samples; PICCOLO polyp dataset; SUN polyp dataset;
   Etis-Larib dataset; Convolutional neural networks; Colorectal cancer
ID COLORECTAL-CANCER
AB Colorectal cancer (CRC) is one of the common types of cancer with a high mortality rate. Colonoscopy is the gold standard for CRC screening and significantly reduces CRC mortality. However, due to many factors, the rate of missed polyps, which are the precursors of colorectal cancer, is high in practice. Therefore, many artificial intelligence-based computer-aided diagnostic systems have been presented to increase the detection rate of missed polyps. In this article, we present deep learning-based methods for reliable computer-assisted polyp detection. The proposed methods differ from state-of-the-art methods as follows. First, we improved the performances of YOLOv3 and YOLOv4 object detection algorithms by integrating Cross Stage Partial Network (CSPNet) for real-time and high-performance automatic polyp detection. Then, we utilized advanced data augmentation techniques and transfer learning to improve the performance of polyp detection. Next, for further improving the performance of polyp detection using negative samples, we substituted the Sigmoid-weighted Linear Unit (SiLU) activation functions instead of the Leaky ReLU and Mish activation functions, and Complete Intersection over Union (CIoU) as the loss function. In addition, we present a comparative analysis of these activation functions for polyp detection. We applied the proposed methods on the recently published novel datasets, which are the SUN polyp database and the PICCOLO database. Additionally, we investigated the proposed models for MICCAI Sub-Challenge on Automatic Polyp Detection in Colonoscopy dataset. The proposed methods outperformed the other studies in both real-time performance and polyp detection accuracy.
C1 [Pacal, Ishak] Igdir Univ, Engn Fac, Comp Engn Dept, Igdir, Turkey.
   [Karaman, Ahmet; Coskun, Seymanur] Acibadem Hosp, Gastroenterol Dept, Kayseri, Turkey.
   [Karaboga, Dervis; Akay, Bahriye; Basturk, Alper; Nalbantoglu, Ufuk] Erciyes Univ, Comp Engn Dept, Engn Fac, Kayseri, Turkey.
C3 Igdir University; Acibadem Hastaneleri; Erciyes University
RP Pacal, I (通讯作者)，Igdir Univ, Engn Fac, Comp Engn Dept, Igdir, Turkey.
EM ishak.pacal@igdir.edu.tr
RI pacal, ishak/HJJ-1662-2023; Basturk, Alper/A-8953-2012
OI Basturk, Alper/0000-0001-5810-0643
CR Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED, DOI DOI 10.48550/ARXIV.2004.10934
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Colorectal Cancer, STAT
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Elfwing S, 2018, NEURAL NETWORKS, V107, P3, DOI 10.1016/j.neunet.2017.12.012
   Hacking SM, 2021, PATHOL RES PRACT, V220, DOI 10.1016/j.prp.2021.153378
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Inik O, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107582
   Inik O, 2019, COMPUT BIOL MED, V112, DOI 10.1016/j.compbiomed.2019.103350
   Jass JR, 2004, CLIN GASTROENTEROL H, V2, P1, DOI 10.1016/S1542-3565(03)00284-2
   Kilicarslan S, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114805
   Kingma D., 2015, ARXIV
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102052
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misra D., 2019, ARXIV PREPRINT
   Ozcan T, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107669
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pacal I, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104003
   Rahman Mohammad Motiur, 2021, Informatics in Medicine Unlocked, V24, P458, DOI 10.1016/j.imu.2021.100603
   Ramachandran Prajit, 2017, ABS171005941 CORR
   Redmon J., 2018, ARXIV PREPRINT ARXIV
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruder S., 2016, ARXIV160904747, V2016, p1609.04747, DOI DOI 10.48550/ARXIV.1609.04747
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Shen Z., COTR CONVOLUTION TRA, V2021, P1
   Shin Y., 2019, AUTOMATIC COLON POLY, V20
   Wang C.-Y., 2020, SCALED YOLOV4 SCALIN
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zisserman A., 2014, ICLR, DOI DOI 10.2146/AJHP170251
NR 38
TC 32
Z9 32
U1 31
U2 69
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD FEB
PY 2022
VL 141
AR 105031
DI 10.1016/j.compbiomed.2021.105031
EA JAN 2022
PG 11
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA 0V0XX
UT WOS:000788071000003
PM 34802713
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Itoh, H
   Oda, M
   Jiang, K
   Mori, Y
   Misawa, M
   Kudo, SE
   Imai, K
   Ito, S
   Hotta, K
   Mori, K
AF Itoh, Hayato
   Oda, Masahiro
   Jiang, Kai
   Mori, Yuichi
   Misawa, Masashi
   Kudo, Shin-Ei
   Imai, Kenichiro
   Ito, Sayo
   Hotta, Kinichi
   Mori, Kensaku
TI Uncertainty meets 3D-spatial feature in colonoscopic polyp-size
   determination
SO COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND
   VISUALIZATION
LA English
DT Article
DE Polyp-size estimation; depth estimation; polyp localisation;
   computer-aided diagnosis
ID SOCIETY-TASK-FORCE; CONSENSUS UPDATE; SURVEILLANCE; POLYPECTOMY;
   GUIDELINES; ENDOSCOPY
AB This paper presents a new 3D-spatial feature extraction from a 2D colonoscopic image for polyp-size estimation. The polyp-size estimation poses potential demands on colonoscopy, since an endoscopist's subjective estimation is apt to result in uncertain polyp-size determination. This uncertain determination is derived from the lack of 3D-spatial information. Even though a previous work clarified that depth estimation mitigates uncertainty in binary polyp-size classification, precise estimation of 3D structure from a colonoscopic image(s) remains an unsolved challenge in medical image analysis. This work proposes a 3D-spatial feature that expresses a polyp's precise 3D shape to mitigate uncertainty in polyp-size determination. First, we introduce an accurate depth estimation method to capture the 3D structure of a colon. Next, we integrate depth estimation and polyp localisation to extract a 3D polyp shape as a feature. Finally, we achieve polyp-size estimation by statistical learning of extracted features. The experimental results demonstrated the validity both of our depth estimation and 3D-spatial feature. Compared with deep RGB and RGB-D convolutional neural networks (CNNs), a shallow CNN with the proposed 3D-spatial feature achieved a more accurate polyp-size estimation with a mean absolute error of 1.36 mm, whereas the one of the deep CNN is 3.11 mm.
C1 [Itoh, Hayato; Oda, Masahiro; Jiang, Kai; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
   [Oda, Masahiro] Nagoya Univ, Informat & Commun, Nagoya, Aichi, Japan.
   [Mori, Yuichi] Univ Oslo, Clin Effectiveness Res Grp, Oslo, Norway.
   [Mori, Yuichi; Misawa, Masashi; Kudo, Shin-Ei] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Imai, Kenichiro; Ito, Sayo; Hotta, Kinichi] Shizuoka Canc Ctr, Div Endoscopy, Yokohama, Kanagawa, Japan.
   [Mori, Kensaku] Nagoya Univ, Informat Technol Ctr, Nagoya, Aichi, Japan.
   [Mori, Kensaku] Natl Inst Informat, Res Ctr Med Bigdata, Tokyo, Japan.
C3 Nagoya University; Nagoya University; University of Oslo; Showa
   University; Shizuoka Cancer Center; Nagoya University; Research
   Organization of Information & Systems (ROIS); National Institute of
   Informatics (NII) - Japan
RP Itoh, H (通讯作者)，Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
EM hitoh@mori.m.is.nagoya-u.ac.jp
RI Misawa, Masashi/H-9004-2019; Itoh, Hayato/AAM-4022-2021
OI Misawa, Masashi/0000-0002-8520-2036; Itoh, Hayato/0000-0002-1410-1078;
   Oda, Masahiro/0000-0001-7714-422X
FU Japan Agency for Medical Research [19hs0110006h0003]; Japan Society for
   the Promotion of Science [26108006, 17H00867, 17K20099, 21K19898]; Japan
   Society for the Promotion of Science CREST [JPMJCR20D5]; Japan Society
   for the Promotion of Science Bilateral Joint Research Project;
   Grants-in-Aid for Scientific Research [21K19898] Funding Source: KAKEN
FX This study was funded by grants from the Japan Agency for Medical
   Research (No.19hs0110006h0003), Japan Society for the Promotion of
   Science (No. 26108006, No.17H00867, No.17K20099, No. 21K19898), the
   Japan Society for the Promotion of Science CREST (No. JPMJCR20D5) and
   the Japan Society for the Promotion of Science Bilateral Joint Research
   Project.
CR Anderson BW, 2016, GASTROINTEST ENDOSC, V83, P201, DOI 10.1016/j.gie.2015.06.058
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hartley R. I., 2004, MULTIPLE VIEW GEOMET, V2nd, DOI 10.1016/S0143-8166(01)00145-2
   Hassan C, 2016, ENDOSCOPY, V48, P881, DOI 10.1055/s-0042-112580
   Hassan C, 2013, ENDOSCOPY, V45, P842, DOI 10.1055/s-0033-1344548
   Hyun YS, 2011, DIGEST LIVER DIS, V43, P391, DOI 10.1016/j.dld.2010.12.015
   Itoh H., 2020, SUN COLONOSCOPY VIDE
   Itoh H, 2021, INT J COMPUT ASS RAD, V16, P989, DOI 10.1007/s11548-021-02398-x
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Kaz AM, 2016, GASTROINTEST ENDOSC, V83, P812, DOI 10.1016/j.gie.2015.08.082
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Ma FC, 2018, IEEE INT CONF ROBOT, P4796
   Ma RB, 2019, LECT NOTES COMPUT SC, V11768, P573, DOI 10.1007/978-3-030-32254-0_64
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Mathew S, 2020, PROC CVPR IEEE, P4695, DOI [10.1109/cvpr42600.2020.00475, 10.1109/CVPR42600.2020.00475]
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Mori K, 2003, PROC SPIE, V5031, P111, DOI 10.1117/12.480417
   Oda M, 2019, HEALTHC TECHNOL LETT, V6, P214, DOI 10.1049/htl.2019.0071
   Plumb AA, 2016, ENDOSCOPY, V48, P899, DOI 10.1055/s-0042-108727
   Ranjan A, 2019, PROC CVPR IEEE, P12232, DOI 10.1109/CVPR.2019.01252
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Saxena A., 2006, PROCEEDINS ADV NEURA, P1161, DOI [10.1109/TPAMI.2015.2505283a, DOI 10.1109/TPAMI.2015.2505283A]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang CY, 2018, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2018.00216
   Winawer SJ, 2006, GASTROENTEROLOGY, V130, P1872, DOI 10.1053/j.gastro.2006.03.012
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 34
TC 1
Z9 1
U1 0
U2 2
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2168-1163
EI 2168-1171
J9 COMP M BIO BIO E-IV
JI Comp. Meth. Biomech. Biomed. Eng.
PD MAY 4
PY 2022
VL 10
IS 3
BP 289
EP 298
DI 10.1080/21681163.2021.2004445
EA JAN 2022
PG 10
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA 1A8XO
UT WOS:000746807700001
DA 2023-08-21
ER

PT J
AU Spadaccini, M
   De Marco, A
   Franchellucci, G
   Sharma, P
   Hassan, C
   Repici, A
AF Spadaccini, Marco
   De Marco, Alessandro
   Franchellucci, Gianluca
   Sharma, Prateek
   Hassan, Cesare
   Repici, Alessandro
TI Discovering the first FDA-approved computer-aided polyp detection system
SO FUTURE ONCOLOGY
LA English
DT Review
DE cancer; colonoscopy; computer-aided; innovation; prevention; screening;
   technology
ID COLORECTAL NEOPLASIA; COLONOSCOPY; ENDOSCOPY; PARTICIPATION; INCREASES
AB Colorectal cancer is the third most common cancer worldwide. Because of the slow progression of the precancerous precursors, an efficient endoscopic surveillance strategy may be expected. It seems that around one-fourth of colorectal malignancies are still missed during colonoscopy. Several endoscopic technologies have been introduced, without radical changes. Interest in the development of artificial intelligence applications in the medical field has grown in the past decade. Artificial intelligence can help to highlight a specific region of interest that needs closer examination for the identification of polyps. The aim of this review is to report the first clinical experiences with the first US FDA-approved, real-time, deep-learning, computer-aided detection system (GI Genius (TM), Medtronic).
   Plain language summary Prevention of colorectal cancer through the diagnosis of its precursors is one of the greatest aims of an endoscopist. In this way we can avoid the development of a serious disease from lesions, which at early presentation don't have malignant aspects and could be removed during a colonoscopy. Identification of these lesions could be challenging and is based on the experiences and abilities of physicians, but this could lead to huge differences in the detection of polyps among the population. In the last decade, to improve the ability to detect the aforementioned lesions, which in endoscopy terms are defined as polyps, different systems of detection guided by artificial intelligence have been designed. This technology has been shown to be very helpful and, so, the more lesions that are recognized, the more colorectal cancer could be prevented. This article presents the first system of polyp detection guided by artificial intelligence approved by one of the world's regulatory agencies, the US FDA.
C1 [Spadaccini, Marco; De Marco, Alessandro; Franchellucci, Gianluca; Repici, Alessandro] Humanitas Univ, Dept Biomed Sci, Pieve Emanuele, Italy.
   [Spadaccini, Marco; De Marco, Alessandro; Franchellucci, Gianluca; Repici, Alessandro] Humanitas Clin & Res Ctr IRCCS, Endoscopy Unit, Rozzano, Italy.
   [Sharma, Prateek] Kansas City VA Med Ctr, Gastroenterol & Hepatol, Kansas City, MO 66045 USA.
   [Hassan, Cesare] Nuovo Regina Margherita Hosp, Digest Endoscopy Unit, Rome, Italy.
C3 Humanitas University; Poliambulatorio Nuovo Regina Margherita
RP Repici, A (通讯作者)，Humanitas Univ, Dept Biomed Sci, Pieve Emanuele, Italy.; Repici, A (通讯作者)，Humanitas Clin & Res Ctr IRCCS, Endoscopy Unit, Rozzano, Italy.
EM alessandro.repici@humanitas.it
RI Sharma, Prateek/IZE-3910-2023; Repici, Alessandro/HFH-8162-2022; hassan,
   cesare/H-2844-2012; Spadaccini, Marco/HOH-7613-2023
OI Repici, Alessandro/0000-0002-1621-6450; hassan,
   cesare/0000-0001-7167-1459; Spadaccini, Marco/0000-0003-3909-9012;
   Franchellucci, Gianluca/0000-0002-3440-4981
CR Abu-Freha N, 2021, UNITED EUR GASTROENT, V9, P681, DOI 10.1002/ueg2.12106
   Areia MM., 2021, LANCET DIGIT HEALTH
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Attardo S, 2020, WORLD J GASTROENTERO, V26, P5606, DOI 10.3748/wjg.v26.i37.5606
   Badalamenti Matteo, 2021, VideoGIE, V6, P350, DOI 10.1016/j.vgie.2021.05.004
   Brenner H, 2014, LANCET, V383, P1490, DOI 10.1016/S0140-6736(13)61649-9
   Brenner H, 2012, INT J CANCER, V131, P1649, DOI 10.1002/ijc.26192
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Duvvuri A, 2021, GASTROENTEROLOGY, V160, P1986, DOI 10.1053/j.gastro.2021.01.214
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Holzwanger EA, 2021, ENDOSCOPY, V53, P937, DOI 10.1055/a-1302-2942
   Jerebko A., 2020, MED IMAGE COMPUT COM, V9, P169
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   Repici A, 2022, GUT, V71, P757, DOI 10.1136/gutjnl-2021-324471
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Schoen RE, 2012, NEW ENGL J MED, V366, P2345, DOI 10.1056/NEJMoa1114635
   Sinagra E, 2020, WORLD J GASTROENTERO, V26, DOI 10.3748/wjg.v26.i39.5911
   Spadaccini M, 2021, LANCET GASTROENTEROL, V6, P793, DOI 10.1016/S2468-1253(21)00215-6
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Xu YX, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0246892
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 38
TC 6
Z9 6
U1 0
U2 7
PU FUTURE MEDICINE LTD
PI LONDON
PA UNITEC HOUSE, 3RD FLOOR, 2 ALBERT PLACE, FINCHLEY CENTRAL, LONDON, N3
   1QB, ENGLAND
SN 1479-6694
EI 1744-8301
J9 FUTURE ONCOL
JI Future Oncol.
PD APR
PY 2022
VL 18
IS 11
BP 1405
EP 1412
DI 10.2217/fon-2021-1135
EA JAN 2022
PG 8
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA 0C1ZN
UT WOS:000747330200001
PM 35081745
DA 2023-08-21
ER

PT J
AU Wesp, P
   Grosu, S
   Graser, A
   Maurus, S
   Schulz, C
   Knosel, T
   Fabritius, MP
   Schachtner, B
   Yeh, BM
   Cyran, CC
   Ricke, J
   Kazmierczak, PM
   Ingrisch, M
AF Wesp, Philipp
   Grosu, Sergio
   Graser, Anno
   Maurus, Stefan
   Schulz, Christian
   Knosel, Thomas
   Fabritius, Matthias P.
   Schachtner, Balthasar
   Yeh, Benjamin M.
   Cyran, Clemens C.
   Ricke, Jens
   Kazmierczak, Philipp M.
   Ingrisch, Michael
TI Deep learning in CT colonography: differentiating premalignant from
   benign colorectal polyps
SO EUROPEAN RADIOLOGY
LA English
DT Article
DE Colonography; Computed tomographic; Colonic polyp; Deep learning; Early
   detection of cancer
ID CANCER; COLONOSCOPY; PARTICIPATION; PREVENTION; ADENOMA; RATES
AB Objectives To investigate the differentiation of premalignant from benign colorectal polyps detected by CT colonography using deep learning. Methods In this retrospective analysis of an average risk colorectal cancer screening sample, polyps of all size categories and morphologies were manually segmented on supine and prone CT colonography images and classified as premalignant (adenoma) or benign (hyperplastic polyp or regular mucosa) according to histopathology. Two deep learning models SEG and noSEG were trained on 3D CT colonography image subvolumes to predict polyp class, and model SEG was additionally trained with polyp segmentation masks. Diagnostic performance was validated in an independent external multicentre test sample. Predictions were analysed with the visualisation technique Grad-CAM++. Results The training set consisted of 107 colorectal polyps in 63 patients (mean age: 63 +/- 8 years, 40 men) comprising 169 polyp segmentations. The external test set included 77 polyps in 59 patients comprising 118 polyp segmentations. Model SEG achieved a ROC-AUC of 0.83 and 80% sensitivity at 69% specificity for differentiating premalignant from benign polyps. Model noSEG yielded a ROC-AUC of 0.75, 80% sensitivity at 44% specificity, and an average Grad-CAM++ heatmap score of >= 0.25 in 90% of polyp tissue. Conclusions In this proof-of-concept study, deep learning enabled the differentiation of premalignant from benign colorectal polyps detected with CT colonography and the visualisation of image regions important for predictions. The approach did not require polyp segmentation and thus has the potential to facilitate the identification of high-risk polyps as an automated second reader.
C1 [Wesp, Philipp; Grosu, Sergio; Maurus, Stefan; Fabritius, Matthias P.; Schachtner, Balthasar; Cyran, Clemens C.; Ricke, Jens; Kazmierczak, Philipp M.; Ingrisch, Michael] Ludwig Maximilians Univ Munchen, Dept Radiol, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany.
   [Graser, Anno] Radiol Munchen, Burgstr 7, D-80331 Munich, Germany.
   [Schulz, Christian] Ludwig Maximilians Univ Munchen, Dept Med 2, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany.
   [Knosel, Thomas] Ludwig Maximilians Univ Munchen, Dept Pathol, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany.
   [Schachtner, Balthasar] German Ctr Lung Res DZL, Comprehens Pneumol Ctr CPC M, Max Lebsche Pl 31, D-81377 Munich, Germany.
   [Yeh, Benjamin M.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 513 Parnassus Ave, San Francisco, CA 94117 USA.
C3 University of Munich; University of Munich; University of Munich;
   University of California System; University of California San Francisco
RP Wesp, P (通讯作者)，Ludwig Maximilians Univ Munchen, Dept Radiol, Univ Hosp, Marchioninistr 15, D-81377 Munich, Germany.
EM philipp.wesp@med.uni-muenchen.de
RI Wesp, Philipp/HNO-9426-2023; schulz, christian/HOA-7122-2023
OI Wesp, Philipp/0000-0001-7356-3371; Grosu, Sergio/0000-0002-9093-6499
FU Projekt DEAL; FoFoLe, Medizinische Fakultat,
   Ludwig-Maximilians-Universitat Munchen, Germany
FX Open Access funding enabled and organized by Projekt DEAL. This study
   has received funding by FoFoLe, Medizinische Fakultat,
   Ludwig-Maximilians-Universitat Munchen, Germany (PI: Sergio Grosu).
CR Atkin W, 2013, LANCET, V381, P1194, DOI 10.1016/S0140-6736(12)62186-2
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Chattopadhay Aditya, 2018, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P839, DOI 10.1109/WACV.2018.00097
   Chollet F., 2015, KERAS PROBABILISTIC
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Dachman AH, 2010, RADIOLOGY, V256, P827, DOI 10.1148/radiol.10091890
   Graser A, 2009, GUT, V58, P241, DOI 10.1136/gut.2008.156448
   Grosu S, 2021, RADIOLOGY, V299, P326, DOI 10.1148/radiol.2021202363
   Halligan S, 2011, RADIOLOGY, V258, P469, DOI 10.1148/radiol.10100354
   Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996
   Kim DH, 2007, NEW ENGL J MED, V357, P1403, DOI 10.1056/NEJMoa070543
   Kim DH, 2016, RADIOLOGY, V280, P455, DOI 10.1148/radiol.2016151608
   Kumar V., 2013, ROBBINS BASIC PATHOL
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   MANDEL JS, 1993, NEW ENGL J MED, V328, P1365, DOI 10.1056/NEJM199305133281901
   Nolden M, 2013, INT J COMPUT ASS RAD, V8, P607, DOI 10.1007/s11548-013-0840-8
   Pickhardt PJ, 2008, AM J ROENTGENOL, V190, P136, DOI 10.2214/AJR.07.2646
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Song BW, 2014, INT J COMPUT ASS RAD, V9, P1021, DOI 10.1007/s11548-014-0991-2
   SPADA C, EUR RADIOL 2021, V31, P2982
   Stoop EM, 2012, LANCET ONCOL, V13, P55, DOI 10.1016/S1470-2045(11)70283-2
   Tan JX, 2020, IEEE T MED IMAGING, V39, P2013, DOI 10.1109/TMI.2019.2963177
   van der Meulen MP, 2018, RADIOLOGY, V287, P901, DOI 10.1148/radiol.2017162359
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 29
TC 3
Z9 3
U1 2
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0938-7994
EI 1432-1084
J9 EUR RADIOL
JI Eur. Radiol.
PD JUL
PY 2022
VL 32
IS 7
BP 4749
EP 4759
DI 10.1007/s00330-021-08532-2
EA JAN 2022
PG 11
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA 2I3RK
UT WOS:000747080500001
PM 35083528
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Sierra-Jerez, F
   Martinez, F
AF Sierra-Jerez, Franklin
   Martinez, Fabio
TI A deep representation to fully characterize hyperplastic, adenoma, and
   serrated polyps on narrow band imaging sequences
SO HEALTH AND TECHNOLOGY
LA English
DT Article
DE Deep learning; Cancer; Narrow band imaging; Polyp characterization
ID COMPUTER-AIDED CLASSIFICATION; COLORECTAL POLYPS;
   ARTIFICIAL-INTELLIGENCE; CANCER; ENDOSCOPY; DIAGNOSIS
AB An effective and early polypectomy of adenomatous and serrated polyps may dramatically reduce the incidence of colorectal cancer. Recently, Narrow-band imaging (NBI) sequences have emerged to enhance the description of these polyp types from the description of their microvascular and surface textural patterns. Despite the major observation capabilities, the in-situ analysis from the colonoscopy procedure remains challenging due to dependence on the expertise of gastroenterologists to localize and characterize polyps. This work introduces a robust frame-level strategy that achieves a full characterization of polyp patterns to differentiate among serrated, adenoma, and hyperplastic samples. The proposed strategy learns a deep convolutional representation that supports classification but also retrieves attention maps to localize main regions associated with the lesion. From this deep representation, it was also possible to build a low-dimensional representation space that allows visualizing a particular frame-video sample w.r.t to other diagnosed samples. From a total of 76 public available colonoscopies, the proposed strategy achieves an average classification accuracy of 90.79%. Besides, the proposed approach achieves a remarkable classification of polyps to be resected and also the masses diagnosed as serrated, a task with major diagnostic variability among experts.
C1 [Sierra-Jerez, Franklin; Martinez, Fabio] Univ Ind Santander UIS, Biomed Imaging Vis & Learning Lab BivL2ab, Cra 27,Cl 9, Bucaramanga, Colombia.
C3 Universidad Industrial de Santander
RP Martinez, F (通讯作者)，Univ Ind Santander UIS, Biomed Imaging Vis & Learning Lab BivL2ab, Cra 27,Cl 9, Bucaramanga, Colombia.
EM famarcar@saber.uis.edu.co
RI Sierra-Jerez, Franklin/HNR-3954-2023
OI Martinez, Fabio/0000-0001-7353-049X
CR Abadi M., 2015, P 12 USENIX C OPERAT, DOI [DOI 10.5555/3026877.3026899, DOI 10.1038/NN.3331]
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chollet F., 2015, KERAS PROBABILISTIC
   El Hajjar A, 2020, CHINESE MED J-PEKING, V133, P326, DOI 10.1097/CM9.0000000000000623
   Ortega-Moran JF, 2021, BMC CANCER, V21, DOI 10.1186/s12885-021-08190-z
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Haumaier F, 2017, BEST PRACT RES CL GA, V31, P369, DOI 10.1016/j.bpg.2017.06.005
   Horiuchi Y, 2020, DIGEST DIS SCI, V65, P1355, DOI 10.1007/s10620-019-05862-6
   Howard A, 2017, ARXIV170404861 CS, P04
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kim DH, 2016, RADIOLOGY, V280, P455, DOI 10.1148/radiol.2016151608
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   LONGACRE TA, 1990, AM J SURG PATHOL, V14, P524, DOI 10.1097/00000478-199006000-00003
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Okamoto K, 2017, J GASTROEN HEPATOL, V32, P358, DOI 10.1111/jgh.13482
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Ribeiro C, 2016, IEEE INT CONF SERIOU
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Stehle T, 2009, MED IMAGING 2009 COM, V7260
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Thorlacius H, 2017, SCAND J GASTROENTERO, V52, P654, DOI 10.1080/00365521.2017.1298154
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Ueyama H, 2021, J GASTROEN HEPATOL, V36, P482, DOI 10.1111/jgh.15190
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Usami Hiroyasu, 2020, Procedia Computer Science, V176, P2507, DOI 10.1016/j.procs.2020.09.325
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Doorn SC, 2015, AM J GASTROENTEROL, V110, P180, DOI 10.1038/ajg.2014.326
   Visovan II, 2017, BOSNIAN J BASIC MED, V17, P152, DOI 10.17305/bjbms.2017.1686
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 37
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2190-7188
EI 2190-7196
J9 HEALTH TECHNOL-GER
JI Health Technol.
PD MAR
PY 2022
VL 12
IS 2
BP 401
EP 413
DI 10.1007/s12553-021-00633-8
EA JAN 2022
PG 13
WC Medical Informatics
WE Emerging Sources Citation Index (ESCI)
SC Medical Informatics
GA 0F2FZ
UT WOS:000744859800001
DA 2023-08-21
ER

PT J
AU Pan, H
   Cai, MY
   Liao, Q
   Jiang, Y
   Liu, YG
   Zhuang, XL
   Yu, Y
AF Pan, Hui
   Cai, Mingyan
   Liao, Qi
   Jiang, Yong
   Liu, Yige
   Zhuang, Xiaolong
   Yu, Ying
TI Artificial Intelligence-Aid Colonoscopy Vs. Conventional Colonoscopy for
   Polyp and Adenoma Detection: A Systematic Review of 7 Discordant
   Meta-Analyses
SO FRONTIERS IN MEDICINE
LA English
DT Review
DE colonoscopy; artificial intelligence; polyp detection; adenoma
   detection; discordant meta-analysis; Jadad algorithm
ID COLORECTAL-CANCER; TASK-FORCE; EFFICACY
AB Objectives: Multiple meta-analyses which investigated the comparative efficacy and safety of artificial intelligence (AI)-aid colonoscopy (AIC) vs. conventional colonoscopy (CC) in the detection of polyp and adenoma have been published. However, a definitive conclusion has not yet been generated. This systematic review selected from discordant meta-analyses to draw a definitive conclusion about whether AIC is better than CC for the detection of polyp and adenoma.Methods: We comprehensively searched potentially eligible literature in PubMed, Embase, Cochrane library, and China National Knowledgement Infrastructure (CNKI) databases from their inceptions until to April 2021. Assessment of Multiple Systematic Reviews (AMSTAR) instrument was used to assess the methodological quality. Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) checklist was used to assess the reporting quality. Two investigators independently used the Jadad decision algorithm to select high-quality meta-analyses which summarized the best available evidence.Results: Seven meta-analyses met our selection criteria finally. AMSTAR score ranged from 8 to 10, and PRISMA score ranged from 23 to 26. According to the Jadad decision algorithm, two high-quality meta-analyses were selected. These two meta-analyses suggested that AIC was superior to CC for colonoscopy outcomes, especially for polyp detection rate (PDR) and adenoma detection rate (ADR).Conclusion: Based on the best available evidence, we conclude that AIC should be preferentially selected for the route screening of colorectal lesions because it has potential value of increasing the polyp and adenoma detection. However, the continued improvement of AIC in differentiating the shape and pathology of colorectal lesions is needed.
C1 [Pan, Hui; Liu, Yige; Zhuang, Xiaolong; Yu, Ying] Shanghai Jiangong Hosp, Dept Endoscopy, Shanghai, Peoples R China.
   [Cai, Mingyan] Fudan Univ, Zhongshan Hosp, Endoscopy Ctr, Shanghai, Peoples R China.
   [Liao, Qi] Shanghai Jiangong Hosp, Dept Gastroenterol, Shanghai, Peoples R China.
   [Jiang, Yong] Shanghai Jiangong Hosp, Dept Surg, Shanghai, Peoples R China.
C3 Fudan University
RP Pan, H (通讯作者)，Shanghai Jiangong Hosp, Dept Endoscopy, Shanghai, Peoples R China.; Cai, MY (通讯作者)，Fudan Univ, Zhongshan Hosp, Endoscopy Ctr, Shanghai, Peoples R China.
EM Jennyp730@163.com; Cai.mingyan@qq.com
RI Cai, Mingyan/ACQ-4127-2022
FU Shanghai Youth Medical Talents-Specialist Program [2019[72]]; Zhongshan
   Hospital Youth Medical Talents [2019ZSYQ11]; National Key Research and
   Development Plan of China [2017YFC1308802]
FX This study was support by Shanghai Youth Medical Talents-Specialist
   Program (2019[72]), Zhongshan Hospital Youth Medical Talents
   (2019ZSYQ11) and National Key Research and Development Plan of China
   (No.2017YFC1308802).
CR Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Cheung D, 2016, GASTROINTEST ENDOSC, V84, P287, DOI 10.1016/j.gie.2016.01.047
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deliwala SS, 2021, INT J COLORECTAL DIS, V36, P2291, DOI 10.1007/s00384-021-03929-3
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Facciorusso A, 2018, CLIN GASTROENTEROL H, V16, P1209, DOI 10.1016/j.cgh.2017.11.007
   Facciorusso A, 2019, CLIN GASTROENTEROL H, V17, P2439, DOI 10.1016/j.cgh.2018.11.058
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Higgins JP., 2019, COCHRANE HDB SYSTEMA, P205, DOI 10.1002/9781119536604.ch8
   Jadad AR, 1997, CAN MED ASSOC J, V156, P1411
   Kader R., 2020, UNIT EUR GASTROENTER, V8, P772, DOI [10.1055/s-0041-1724968, DOI 10.1055/S-0041-1724968]
   Kataoka S, 2020, ENDOSC INT OPEN, V8, pE360, DOI 10.1055/a-1068-9228
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mohan BP, 2020, ECLINICALMEDICINE, V29-30, DOI 10.1016/j.eclinm.2020.100622
   Page MJ, 2022, REV PANAM SALUD PUBL, V46, DOI [10.26633/RPSP.2022.112, 10.1136/bmj.n160]
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Shea BJ, 2007, BMC MED RES METHODOL, V7, DOI 10.1186/1471-2288-7-10
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wright JG, 2003, J BONE JOINT SURG AM, V85A, P1, DOI 10.2106/00004623-200301000-00001
   Xue P, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01860-y
   Zhang YC, 2021, J LAPAROENDOSC ADV S, V31, P1143, DOI 10.1089/lap.2020.0777
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 39
TC 2
Z9 2
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-858X
J9 FRONT MED-LAUSANNE
JI Front. Med.
PD JAN 13
PY 2022
VL 8
AR 775604
DI 10.3389/fmed.2021.775604
PG 11
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA YP2BZ
UT WOS:000748432700001
PM 35096870
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Qadir, HA
   Balasingham, I
   Shin, Y
AF Qadir, Hemin Ali
   Balasingham, Ilangko
   Shin, Younghak
TI Simple U-net based synthetic polyp image generation: Polyp to negative
   and negative to polyp
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Colonoscopy; Polyp detection; Image synthesis; Convolutional neural
   network; Generative adversarial networks
ID VALIDATION; CNN
AB Synthetic polyp generation is a good alternative to overcome the privacy problem of medical data and the lack of various polyp samples. In this study, we propose a deep learning-based polyp image generation framework that generates synthetic polyp images that are similar to real ones. We suggest a framework that converts a given polyp image into a negative image (image without a polyp) using a simple conditional GAN architecture and then converts the negative image into a new-looking polyp image using the same network. In addition, by using the controllable polyp masks, polyps with various characteristics can be generated from one input condition. The generated polyp images can be used directly as training images for polyp detection and segmentation without additional labeling. To quantitatively assess the quality of generated synthetic polyps, we use public polyp image and video datasets combined with the generated synthetic images to examine the performance improvement of several detection and segmentation models. Experimental results show that we obtain performance gains when the generated polyp images are added to the training set.
C1 [Qadir, Hemin Ali; Balasingham, Ilangko] Oslo Univ Hosp OUS, Intervent Ctr, Sognsvannsveien 20, N-0372 Oslo, Norway.
   [Balasingham, Ilangko] Norwegian Univ Sci & Technol NTNU, Dept Elect Syst, Hogskoleringen 1, N-7491 Trondheim, Norway.
   [Shin, Younghak] Mokpo Natl Univ, Dept Comp Engn, Mokpo 1666, South Korea.
C3 Norwegian University of Science & Technology (NTNU); Mokpo National
   University
RP Shin, Y (通讯作者)，Mokpo Natl Univ, Dept Comp Engn, Mokpo 1666, South Korea.
EM shinyh0919@gmail.com
RI Balasingham, Ilangko/AGU-7268-2022
FU Research Funds of Mokpo National University
FX This research was supported by the Research Funds of Mokpo National
   University in 2020. The authors would like to thank Jacob Bergsland at
   Oslo University Hospital for his valuable comments.
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Dai JF, 2016, ADV NEUR IN, V29
   Elgammal A, 2017, Arxiv, DOI [arXiv:1706.07068, 10.48550/ARXIV.1706.07068]
   Gulrajani I, IMPROVED TRAINING WA
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Iglovikov V, 2018, Arxiv, DOI arXiv:1801.05746
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Mahmood F, 2018, IEEE T MED IMAGING, V37, P2572, DOI 10.1109/TMI.2018.2842767
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Shvets AA, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P612, DOI 10.1109/ICMLA.2018.00098
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Thomaz VD, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101988
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan LC, 2019, IEEE ACCESS, V7, P46411, DOI 10.1109/ACCESS.2019.2909553
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 29
TC 0
Z9 0
U1 1
U2 2
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD APR
PY 2022
VL 74
AR 103491
DI 10.1016/j.bspc.2022.103491
EA JAN 2022
PG 9
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA 6A1TR
UT WOS:000880444100008
OA Green Submitted
DA 2023-08-21
ER

PT J
AU Sasmal, P
   Bhuyan, MK
   Dutta, S
   Iwahori, Y
AF Sasmal, Pradipta
   Bhuyan, M. K.
   Dutta, Soumayan
   Iwahori, Yuji
TI An unsupervised approach of colonic polyp segmentation using adaptive
   markov random fields
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Endoscopic image; Super-pixel; Markov random field (MRF); Local binary
   pattern (LBP)
ID IMAGE SEGMENTATION; MODEL
AB In this article, an unsupervised image segmentation method is proposed to segment out polyps in endoscopic images. Based on the skeleton of an over-segmented image, an adaptive Markov Random Field (MRF)-based framework is employed. The polyps or abnormal regions show markedly different texture and color characteristics in contrast to normal tissues. In our method, the endoscope images are first over-segmented into superpixels. For final refinement, Local binary pattern (LBP) and color features are used in the adaptive MRF. The experimental results show that the proposed method can perfectly localize polyp regions, and it can give a mean dice value of 60.77% in a test set of 612 images taken from 29 different video sequences. Deep learning models require a huge number of training images for tweaking of network parameters. In this context, it is sometimes challenging to deploy a deep model for unseen medical datasets having many segmentation challenges, like complex background, specularity, non-uniform illuminations, etc. Also, manual labeling of a huge number of images is another challenge. That is why we adopted an unsupervised approach in this paper. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Sasmal, Pradipta; Bhuyan, M. K.; Dutta, Soumayan] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, Assam, India.
   [Iwahori, Yuji] Chubu Univ, Dept Comp Sci, Kasugai, Aichi 4878501, Japan.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Chubu University
RP Sasmal, P (通讯作者)，Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, Assam, India.
EM s.pradipta@iitg.ac.in
RI Iwahori, Yuji/AAH-4257-2020
OI Iwahori, Yuji/0000-0002-6421-8186
FU JSPS [20K11873]; Grants-in-Aid for Scientific Research [20K11873]
   Funding Source: KAKEN
FX The work of Yuji Iwahori was supported by the JSPS Grant-inAid
   Scientific Research (C) under Grant 20K11873.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SF, 2010, IEEE T IMAGE PROCESS, V19, P2254, DOI 10.1109/TIP.2010.2047164
   Deng HW, 2004, PATTERN RECOGN, V37, P2323, DOI 10.1016/j.patcog.2004.04.015
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Esedoglu S, 2002, EUR J APPL MATH, V13, P353, DOI 10.1017/S0956792501004904
   Feng W, 2010, IEEE T PATTERN ANAL, V32, P1871, DOI 10.1109/TPAMI.2010.24
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Isola P., 2017, P COMP VIS PATT REC, P5967, DOI DOI 10.1109/CVPR.2017.632
   Iwahori Y., 2013, PROC INT C MACH VIS, P21
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Lin DY, 2020, PATTERN RECOGN LETT, V138, P267, DOI 10.1016/j.patrec.2020.07.013
   Markowitz AJ, 1997, CA-CANCER J CLIN, V47, P93, DOI 10.3322/canjclin.47.2.93
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Peter J.D., 2019, ADV COMPUTERIZED ANA
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Zhang L, 2010, IEEE T PATTERN ANAL, V32, P1406, DOI 10.1109/TPAMI.2009.145
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
NR 31
TC 5
Z9 5
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD FEB
PY 2022
VL 154
BP 7
EP 15
DI 10.1016/j.patrec.2021.12.014
EA JAN 2022
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YI8KA
UT WOS:000744090300002
DA 2023-08-21
ER

PT J
AU Yoon, D
   Kong, HJ
   Kim, BS
   Cho, WS
   Lee, JC
   Cho, M
   Lim, MH
   Yang, SY
   Lim, SH
   Lee, J
   Song, JH
   Chung, GE
   Choi, JM
   Kang, HY
   Bae, JH
   Kim, S
AF Yoon, Dan
   Kong, Hyoun-Joong
   Kim, Byeong Soo
   Cho, Woo Sang
   Lee, Jung Chan
   Cho, Minwoo
   Lim, Min Hyuk
   Yang, Sun Young
   Lim, Seon Hee
   Lee, Jooyoung
   Song, Ji Hyun
   Chung, Goh Eun
   Choi, Ji Min
   Kang, Hae Yeon
   Bae, Jung Ho
   Kim, Sungwan
TI Colonoscopic image synthesis with generative adversarial network for
   enhanced detection of sessile serrated lesions using convolutional
   neural network
SO SCIENTIFIC REPORTS
LA English
DT Article
ID ADENOMA DETECTION; MISS RATE; POLYPS; RISK; ADENOMAS/POLYPS;
   AUGMENTATION; PERFORMANCE; PREVALENCE; VALIDATION; DIAGNOSIS
AB Computer-aided detection (CADe) systems have been actively researched for polyp detection in colonoscopy. To be an effective system, it is important to detect additional polyps that may be easily missed by endoscopists. Sessile serrated lesions (SSLs) are a precursor to colorectal cancer with a relatively higher miss rate, owing to their flat and subtle morphology. Colonoscopy CADe systems could help endoscopists; however, the current systems exhibit a very low performance for detecting SSLs. We propose a polyp detection system that reflects the morphological characteristics of SSLs to detect unrecognized or easily missed polyps. To develop a well-trained system with imbalanced polyp data, a generative adversarial network (GAN) was used to synthesize high-resolution whole endoscopic images, including SSL. Quantitative and qualitative evaluations on GAN-synthesized images ensure that synthetic images are realistic and include SSL endoscopic features. Moreover, traditional augmentation methods were used to compare the efficacy of the GAN augmentation method. The CADe system augmented with GAN synthesized images showed a 17.5% improvement in sensitivity on SSLs. Consequently, we verified the potential of the GAN to synthesize high-resolution images with endoscopic features and the proposed system was found to be effective in detecting easily missed polyps during a colonoscopy.
C1 [Yoon, Dan; Kim, Byeong Soo; Cho, Woo Sang] Seoul Natl Univ, Grad Sch, Interdisciplinary Program Bioengn, Seoul 08826, South Korea.
   [Kong, Hyoun-Joong; Cho, Minwoo] Seoul Natl Univ Hosp, Transdisciplinary Dept Med & Adv Technol, Seoul 03080, South Korea.
   [Kong, Hyoun-Joong; Lee, Jung Chan; Lim, Min Hyuk; Kim, Sungwan] Seoul Natl Univ, Dept Biomed Engn, Coll Med, Seoul, South Korea.
   [Kong, Hyoun-Joong] Seoul Natl Univ, Med Big Data Res Ctr, Coll Med, Seoul 03080, South Korea.
   [Kong, Hyoun-Joong; Kim, Sungwan] Seoul Natl Univ, Artificial Intelligence Inst, Seoul 08826, South Korea.
   [Lee, Jung Chan] Seoul Natl Univ, Med Res Ctr, Inst Med & Biol Engn, Seoul 03080, South Korea.
   [Lee, Jung Chan; Kim, Sungwan] Seoul Natl Univ, Inst Bioengn, Seoul 08826, South Korea.
   [Cho, Minwoo] Seoul Natl Univ Hosp, Biomed Res Inst, Seoul 03080, South Korea.
   [Yang, Sun Young; Lim, Seon Hee; Lee, Jooyoung; Song, Ji Hyun; Chung, Goh Eun; Choi, Ji Min; Kang, Hae Yeon; Bae, Jung Ho] Seoul Natl Univ Hosp, Healthcare Syst Gangnam Ctr, Dept Internal Med, Seoul 06236, South Korea.
   [Yang, Sun Young; Lim, Seon Hee; Lee, Jooyoung; Song, Ji Hyun; Chung, Goh Eun; Choi, Ji Min; Kang, Hae Yeon; Bae, Jung Ho] Seoul Natl Univ Hosp, Healthcare Res Inst, Healthcare Syst Gangnam Ctr, Seoul 06236, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU); Seoul
   National University Hospital; Seoul National University (SNU); Seoul
   National University (SNU); Seoul National University (SNU); Seoul
   National University (SNU); Seoul National University (SNU); Seoul
   National University (SNU); Seoul National University Hospital; Seoul
   National University (SNU); Seoul National University Hospital; Seoul
   National University (SNU); Seoul National University Hospital
RP Kim, S (通讯作者)，Seoul Natl Univ, Dept Biomed Engn, Coll Med, Seoul, South Korea.; Kim, S (通讯作者)，Seoul Natl Univ, Artificial Intelligence Inst, Seoul 08826, South Korea.; Kim, S (通讯作者)，Seoul Natl Univ, Inst Bioengn, Seoul 08826, South Korea.; Bae, JH (通讯作者)，Seoul Natl Univ Hosp, Healthcare Syst Gangnam Ctr, Dept Internal Med, Seoul 06236, South Korea.; Bae, JH (通讯作者)，Seoul Natl Univ Hosp, Healthcare Res Inst, Healthcare Syst Gangnam Ctr, Seoul 06236, South Korea.
EM newsanapd@naver.com; sungwan@snu.ac.kr
RI Lim, Min Hyuk/AAU-3256-2021
OI Lim, Min Hyuk/0000-0003-1547-2804; Yoon, Dan/0000-0002-5657-5984
FU Ministry of Science and ICT (MSIT), Korea, under the Information
   Technology Research Center (ITRC) support program
   [IITP-2021-2018-0-01833]
FX This work was supported by the Ministry of Science and ICT (MSIT),
   Korea, under the Information Technology Research Center (ITRC) support
   program (IITP-2021-2018-0-01833) supervised by the Institute for
   Information & Communications Technology Planning & Evaluation (IITP).
CR Abdeljawad K, 2015, GASTROINTEST ENDOSC, V81, P517, DOI 10.1016/j.gie.2014.04.064
   Alnujaim I, 2019, HEALTHC INFORM RES, V25, P344, DOI 10.4258/hir.2019.25.4.344
   Anderson JC, 2013, CLIN GASTROENTEROL H, V11, P1308, DOI 10.1016/j.cgh.2013.04.042
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Bae JH, 2019, CLIN GASTROENTEROL H, V17, P2479, DOI 10.1016/j.cgh.2019.02.019
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bowles C., 2018, CORR
   Burgess NG, 2014, GASTROINTEST ENDOSC, V80, P307, DOI 10.1016/j.gie.2014.03.050
   Cerilli LA, 2012, ARCH PATHOL LAB MED, V136, P854, DOI 10.5858/arpa.2012-0205-RA
   Choi J, 2020, CLIN ENDOSC, V53, P117, DOI 10.5946/ce.2020.054
   Fan Claire, 2018, Curr Treat Options Gastroenterol, V16, P182, DOI 10.1007/s11938-018-0176-0
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Ganesan P, 2019, IEEE ENG MED BIO, P841, DOI 10.1109/EMBC.2019.8857516
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Goodfellow I., 2016, NIPS 2016 TUTORIAL G
   Han C, 2019, INT CONF 3D VISION, P729, DOI 10.1109/3DV.2019.00085
   Hassan C, 2021, DIGEST ENDOSC, V33, P285, DOI 10.1111/den.13807
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hensel M, 2017, ADV NEUR IN, V30
   Hetzel JT, 2010, AM J GASTROENTEROL, V105, P2656, DOI 10.1038/ajg.2010.315
   IJspeert JEG, 2016, ENDOSCOPY, V48, P740, DOI 10.1055/s-0042-105436
   Jang JH, 2021, HEALTHC INFORM RES, V27, P19, DOI 10.4258/hir.2021.27.1.19
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kanayama T, 2019, LECT NOTES COMPUT SC, V11768, P530, DOI 10.1007/978-3-030-32254-0_59
   Kang H, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072628
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Lee J, 2022, DIGEST ENDOSC, V34, P180, DOI 10.1111/den.14046
   Leevy JL, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0151-6
   Leggett B, 2010, GASTROENTEROLOGY, V138, P2088, DOI 10.1053/j.gastro.2009.12.066
   Limketkai BN, 2013, GASTROINTEST ENDOSC, V77, P360, DOI 10.1016/j.gie.2012.11.013
   Liu X., 2021, J KING SAUD UNIV-COM, DOI 10.1016/j.jksuci.2021.07.014
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Mahmood F, 2018, IEEE T MED IMAGING, V37, P2572, DOI 10.1109/TMI.2018.2842767
   Mathew S, 2020, PROC CVPR IEEE, P4695, DOI [10.1109/cvpr42600.2020.00475, 10.1109/CVPR42600.2020.00475]
   Patel K, 2001, J CLIN GASTROENTEROL, V33, P222, DOI 10.1097/00004836-200109000-00011
   Pohl H, 2013, GASTROENTEROLOGY, V144, P74, DOI 10.1053/j.gastro.2012.09.043
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rajaraman S, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101715
   Rashtak S, 2017, CANCER PREV RES, V10, P270, DOI 10.1158/1940-6207.CAPR-16-0264
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Richardson E., 2018, ADV NEURAL INFORM PR, P5852
   Rossini F. P., 1975, ATLAS COLONOSCOPY, P46, DOI [10.1007/978-1-4615-9650-9_12/, DOI 10.1007/978-1-4615-9650-9_12]
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Turner KO, 2018, AM J GASTROENTEROL, V113, P303, DOI 10.1038/ajg.2017.439
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang QF, 2019, IEEE ACCESS, V7, P18450, DOI 10.1109/ACCESS.2019.2896409
   Wozniak M, 2021, NEURAL COMPUT APPL, DOI 10.1007/s00521-021-05841-x
   Wu X, 2020, C CAIH, P244
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
NR 64
TC 0
Z9 0
U1 4
U2 16
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JAN 7
PY 2022
VL 12
IS 1
AR 261
DI 10.1038/s41598-021-04247-y
PG 12
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA YD5VU
UT WOS:000740510500242
PM 34997124
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Guo, QQ
   Fang, XY
   Wang, LB
   Zhang, EM
AF Guo, Qingqing
   Fang, Xianyong
   Wang, Linbo
   Zhang, Enming
TI Polyp Segmentation of Colonoscopy Images by Exploring the Uncertain
   Areas
SO IEEE ACCESS
LA English
DT Article
DE Image segmentation; Transformers; Colonoscopy; Feature extraction; Deep
   learning; Cancer; Uncertainty; Polyp segmentation; deep learning;
   colonoscopy image; colorectal cancer
ID NETWORK
AB Colorectal cancer is one of the leading causes of death worldwide. Polyps are early symptoms of colorectal cancer and prone to malignant transformation. Polyp segmentation of colonoscopy images can help diagnosis. However, existing studies on polyp segmentation of colonoscopy images face two main difficulties: blurry polyp boundaries, close resemblances between polyps and surrounding tissues. The former may lead to partial segmentations, while the latter can result in false positive segmentations. This paper proposes a new polyp segmentation framework to tackle the two challenges. In this method, an uncertainty region based module called Uncertainty eXploration (UnX) is introduced to get the complete polyp region while eliminating the interferences from the backgrounds. Specifically, it refines the feature maps with ternary guidance masks by dividing the initial guidance maps into three types: foreground, background and uncertain region, so that the uncertain areas are highlighted for more foreground objects while the backgrounds are forcefully suppressed to avoid interferences of tissues in background. Taking UnX as side supervision to the transformer encoder based backbone stages, the proposed method can mine the boundary areas from the uncertainty regions gradually and obtain robust polyp segmentation finally. Moreover, a new module called Feature Enhancement (FeE) is also incorporated in the framework to enhance the discrimination for images with significant variation of sizes and shapes of polyps. FeE can supply multi-scale features to the global oriented transformer features. Experiments on five polyp segmentation benchmark datasets of colonoscopy images, Kvasir, CVC-ClinicDB, ETIS, CVC-ColonDB and CVC-300, show the superior performances of our proposed method. Especially, for ETIS, the most challenging among the five datasets, our method achieves 7.7% and 5.6% improvements in mDSC (mean Dice Similarity Coefficient) and mIoU (mean Intersection over Union) respectively in comparison with the state-of-the-arts methods.
C1 [Guo, Qingqing; Fang, Xianyong; Wang, Linbo] Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Peoples R China.
   [Zhang, Enming] Lund Univ, Dept Clin Sci, Islet Pathophysiol, Diabet Ctr, S-21428 Malmo, Sweden.
C3 Anhui University; Lund University
RP Fang, XY (通讯作者)，Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Peoples R China.
EM fangxianyong@ahu.edu.cn
RI wang, lin/GSE-3040-2022
FU Natural Science Foundation of Anhui Province, China [2108085MF210]
FX This work was supported by the Natural Science Foundation of Anhui
   Province, China, under Grant 2108085MF210.
CR Alamdar S, 2020, PSYCH J, V9, P738, DOI 10.1002/pchj.360
   [Anonymous], 2021, PROC MICCAI
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B., 2021, ARXIV210806932
   Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI DOI 10.48550/ARXIV.2010.11929
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Favoriti P, 2016, UPDATES SURG, V68, P7, DOI 10.1007/s13304-016-0359-y
   Fiori M, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414600143
   Granados-Romero JJ, 2017, INT J RES MED SCI, V5, P4667, DOI [10.18203/2320-6012.ijrms20174914, DOI 10.18203/2320-6012.IJRMS20174914]
   Guo Xiaoqing, 2022, Med Image Anal, V78, P102394, DOI 10.1016/j.media.2022.102394
   Guo XQ, 2021, IEEE T MED IMAGING, V40, P1134, DOI 10.1109/TMI.2020.3046843
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong LTT, 2021, IEEE ACCESS, V9, P156987, DOI 10.1109/ACCESS.2021.3129480
   Hou Q, 2018, P NIPS
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Kingma D., 2015, P INT C LEARN REPR I
   Lee Y., 2022, P CVPR
   Li FF, 2002, P NATL ACAD SCI USA, V99, P9596, DOI 10.1073/pnas.092277599
   Li S, 2022, PLANT SOIL, V470, P35, DOI 10.1007/s11104-021-04913-0
   Maghsoudi O H, 2017, 2017 IEEE SIGNAL PRO, P1, DOI [DOI 10.1109/SPMB.2017.8257027, 10.1109/SPMB.2017.8257027]
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI 10.1109/EMBC.2019.8857339
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Nguyen NQ, 2020, IEEE ACCESS, V8, P99495, DOI 10.1109/ACCESS.2020.2995630
   Nguyen NQ, 2019, IEEE ACCESS, V7, P33795, DOI 10.1109/ACCESS.2019.2904094
   Park KB, 2022, J COMPUT DES ENG, V9, P616, DOI 10.1093/jcde/qwac018
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Taehun Kim, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2167, DOI 10.1145/3474085.3475375
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tustison N.J., 2009, INSIGHT J, V2, P707, DOI [10.54294/1vixgg, DOI 10.54294/1VIXGG]
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang DC, 2022, IEEE J BIOMED HEALTH, V26, P2995, DOI 10.1109/JBHI.2022.3147686
   Wang J., 2022, ARXIV220303635
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Xu Q., 2022, ARXIV220200972
   Yeung M, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104815
   Yu F., 2016, INT C LEARN REPRESEN, P1
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 61
TC 4
Z9 4
U1 7
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 52971
EP 52981
DI 10.1109/ACCESS.2022.3175858
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 1P4RD
UT WOS:000801996900001
OA gold
DA 2023-08-21
ER

PT J
AU Ismail, R
   Nagy, S
AF Ismail, Raneem
   Nagy, Szilvia
TI WAYS OF IMPROVING OF ACTIVE CONTOUR METHODS IN COLON- OSCOPY IMAGE
   SEGMENTATION
SO IMAGE ANALYSIS & STEREOLOGY
LA English
DT Article
DE active contour segmentation methods; Chan-Vese method; colonoscopy
   image; geodesic method; Sorensen-Dice Similarity Coefficient
ID VALIDATION
AB As colonoscopy is the standard screening approach for colorectal polyps, and the first step of the correct classification and the efficient automatic diagnostics is the accurate detection and segmentation of the existing polyps, it is worth researching systematically, how colonoscopy databases are responding to two of the most influential variational segmentation methods, the geodesic and Chan-Vese active contour methods. Due to the quality variation of the colonoscopy databases, pre-processing steps are made. Then, 14 various filtered images are evaluated as different inputs for the active contour methods using the Sorensen- Dice Similarity Coefficient as a performance measurement metric. The effects of the initial mask shape and its size together with the number of iterations, contraction bias and smoothness factor are studied. In general, the Chan-Vese method showed more efficiency to match the actual contour of the polyp than the geodesic one with an initial mask possibly located within the polyp area. Preprocessing such as reflection removal, background subtraction and mean or median filtering can improve the Sorensen-Dice coefficient by up to 0.5.
C1 [Ismail, Raneem; Nagy, Szilvia] Szechenyi Istvan Univ, Egyet Ter 1, H-9026 Gyor, Hungary.
C3 University of Istvan Szechenyi
RP Ismail, R (通讯作者)，Szechenyi Istvan Univ, Egyet Ter 1, H-9026 Gyor, Hungary.
EM raneem.ismail@hallgato.sze.hu; nagysz@sze.hu
RI Nagy, Szilvia/HLG-6619-2023
OI Nagy, Szilvia/0000-0001-9556-5095; Ismail, Raneem/0000-0002-3333-4205
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], LECT NOTES MATH
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bhattacharya S, 2019, SCIENCE OF HORMESIS IN HEALTH AND LONGEVITY, P35, DOI [10.1007/978-981-13-2414-7_4, 10.1016/B978-0-12-814253-0.00003-6]
   Brice Claude R., 1970, 17 SRI INT AI CTR
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carass A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64803-w
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan T.F., 2000, 0014 COMP APPL MATH
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Dutta S, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Fang LL, 2020, SOFT COMPUT, V24, P18611, DOI 10.1007/s00500-020-05097-y
   Georgieva V, 2017, C COMM EL MED APPL C
   Georgieva V, 2018, P 13 INT C COMM EL M
   Ismail Raneem, 2021, New Approaches for Multidimensional Signal Processing. Proceedings of International Workshop, NAMSP 2020. Smart Innovation, Systems and Technologies (SIST 216), P137, DOI 10.1007/978-981-33-4676-5_10
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nagy Szilvia, 2020, International Journal of Reasoning-based Intelligent Systems, V12, P200
   Nagy Sz, 2017, IEEE AFRICON 2017
   Nguyen NQ, 2020, IEEE ACCESS, V8, P99495, DOI 10.1109/ACCESS.2020.2995630
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PIPEK J, 1992, PHYS REV A, V46, P3148, DOI 10.1103/PhysRevA.46.3148
   Renyi A., 1961, S MATH STAT PROB, P547
   Sasmal P, 2018, INT CONF CIRC SYST S, P201, DOI 10.1109/ICSIGSYS.2018.8372666
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Yang XJ, 2020, INT J AMBIENT COMPUT, V11, P87, DOI 10.4018/IJACI.2020010105
NR 32
TC 1
Z9 1
U1 1
U2 4
PU INT SOC STEREOLOGY
PI LJUBJANA
PA INST ANATOMY, MEDICAL FACULTY, KORYTKOVA 2, LJUBJANA, SL-1000, SLOVENIA
SN 1580-3139
J9 IMAGE ANAL STEREOL
JI Image Anal. Stereol.
PY 2022
VL 41
IS 1
BP 7
EP 23
DI 10.5566/ias.2604
PG 17
WC Materials Science, Multidisciplinary; Mathematics, Applied; Mechanics;
   Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Materials Science; Mathematics; Mechanics; Imaging Science &
   Photographic Technology
GA 0S5LH
UT WOS:000786314600002
OA gold
DA 2023-08-21
ER

PT J
AU Lee, CH
   Lin, TH
   Lin, CJ
   Kuo, CF
   Pai, BCJ
   Cheng, HT
   Lai, CC
   Chen, TH
AF Lee, Chieh
   Lin, Tsung-Hsing
   Lin, Chen-Ju
   Kuo, Chang-Fu
   Pai, Betty Chien-Jung
   Cheng, Hao-Tsai
   Lai, Cheng-Chou
   Chen, Tsung-Hsing
TI A Noninvasive Risk Stratification Tool Build Using an Artificial
   Intelligence Approach for Colorectal Polyps Based on Annual Checkup Data
SO HEALTHCARE
LA English
DT Article
DE Helicobacter pylori infection; colorectal polyp; teeth disease;
   precancerous lesions; non-invasive; risk stratifying tool; random forest
ID HELICOBACTER-PYLORI INFECTION; METABOLIC SYNDROME; GASTRIC POLYPS;
   CANCER; ADENOMA; COLONOSCOPY; DIAGNOSIS; HYPERGASTRINEMIA;
   ADENOCARCINOMA; INFLAMMATION
AB Colorectal cancer is the leading cause of cancer-related deaths worldwide, and early detection has proven to be an effective method for reducing mortality. The machine learning method can be implemented to build a noninvasive stratifying tool that helps identify patients with potential colorectal precancerous lesions (polyps). This study aimed to develop a noninvasive risk-stratified tool for colorectal polyps in asymptomatic, healthy participants. A total of 20,129 consecutive asymptomatic patients who underwent a health checkup between January 2005 and August 2007 were recruited. Positive relationships between noninvasive risk factors, such as age, Helicobacter pylori infection, hypertension, gallbladder polyps/stone, and BMI and colorectal polyps were observed (p < 0.0001), regardless of sex, whereas significant findings were noted in men with tooth disease (p = 0.0053). A risk stratification tool was developed, for colorectal polyps, that considers annual checkup results from noninvasive examinations. For the noninvasive stratified tool, the area under the receiver operating characteristic curve (AUC) of obese females (males) aged <50 years was 91% (83%). In elderly patients (>50 years old), the AUCs of the stratifying tools were >85%. Our results indicate that the risk stratification tool can be built by using random forest and serve as an efficient noninvasive tool to identify patients requiring colonoscopy.
C1 [Lee, Chieh] Sun Yat Sen Univ, Dept Informat Management, Kaohsiung 804, Taiwan.
   [Lin, Tsung-Hsing] Kuang Tien Gen Hosp, Dept Emergency Med, Taichung 433, Taiwan.
   [Lin, Chen-Ju] Yuan Ze Univ, Coll Engn, Dept Ind Engn & Management, Chungli 320, Taiwan.
   [Kuo, Chang-Fu] Chang Gung Univ, Linkou Chang Gung Mem Hosp, Coll Med, Div Rheumatol Allergy & Immunol, Taoyuan 333, Taiwan.
   [Pai, Betty Chien-Jung] Chang Gung Univ, Chang Gung Mem Hosp, Craniofacial Res Ctr, Craniofacial Orthodont, Taoyuan 333, Taiwan.
   [Cheng, Hao-Tsai] New Taipei Municipal TuCheng Hosp, Dept Internal Med, Div Gastroenterol & Hepatol, New Taipei 236, Taiwan.
   [Lai, Cheng-Chou] Chang Gung Mem Hosp, Dept Colon & Rectal Surg, Linkou Med Ctr, Taoyuan 333, Taiwan.
   [Chen, Tsung-Hsing] Chang Gung Univ, Linkou Chang Gung Mem Hosp, Dept Gastroenterol & Hepatol, Coll Med, Taoyuan 333, Taiwan.
C3 National Sun Yat Sen University; Yuan Ze University; Chang Gung Memorial
   Hospital; Chang Gung University; Chang Gung Memorial Hospital; Chang
   Gung University; Chang Gung Memorial Hospital; Chang Gung Memorial
   Hospital; Chang Gung University
RP Chen, TH (通讯作者)，Chang Gung Univ, Linkou Chang Gung Mem Hosp, Dept Gastroenterol & Hepatol, Coll Med, Taoyuan 333, Taiwan.
EM chiehlee850427@gmail.com; drsixmg@gmail.com;
   chenju.lin@saturn.yzu.edu.tw; zandis@gmail.com; pai0072@cgmh.org.tw;
   hautai@cloud.cgmh.org.tw; lai5556@cgmh.org.tw; itochenyu@gmail.com
RI Kuo, Chang-Fu/Q-1714-2016
OI Kuo, Chang-Fu/0000-0002-9770-5730; Chen, Tsung-Hsing/0000-0001-8888-7985
FU Chang Gung Memorial Hospital, Taoyuan, Taiwan [CORPG3F0261]
FX FundingThis work was supported by grants from Chang Gung Memorial
   Hospital, Taoyuan, Taiwan (CORPG3F0261).
CR Abdulqader DM., 2020, MACH LEARN, V62, P233
   Almadi MA, 2015, CAN J GASTROENTEROL, V29, P304, DOI 10.1155/2015/789038
   Andren-Sandberg A, 2012, N AM J MED SCI, V4, P203, DOI 10.4103/1947-2714.95897
   Anjiki H, 2017, CLIN J GASTROENTEROL, V10, P128, DOI 10.1007/s12328-017-0714-7
   Bevan R, 2018, CLIN ENDOSC, V51, P37, DOI 10.5946/ce.2017.141
   Brim H, 2014, BMC CANCER, V14, DOI 10.1186/1471-2407-14-296
   Calderwood AH, 2016, WORLD J GASTRO ONCOL, V8, P826, DOI 10.4251/wjgo.v8.i12.826
   Cao WJ, 2018, IMMUNOPHARM IMMUNOT, V40, P338, DOI 10.1080/08923973.2018.1490317
   Cappell MS, 2005, MED CLIN N AM, V89, P1, DOI 10.1016/j.mcna.2004.08.011
   Carmack SW, 2009, NAT REV GASTRO HEPAT, V6, P331, DOI 10.1038/nrgastro.2009.70
   Chen HD, 2019, GUT, V68, P1450, DOI 10.1136/gutjnl-2018-317124
   Chou SH, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000011386
   Citarda F, 2001, GUT, V48, P812, DOI 10.1136/gut.48.6.812
   Epplein M, 2013, CANCER EPIDEM BIOMAR, V22, P1964, DOI 10.1158/1055-9965.EPI-13-0702
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Fialoke Suruchi, 2018, AMIA Annu Symp Proc, V2018, P430
   Ford I, 2015, INT J CARDIOL, V184, P163, DOI 10.1016/j.ijcard.2015.02.001
   Gao ZG, 2015, FRONT MICROBIOL, V6, DOI 10.3389/fmicb.2015.00020
   Georgopoulos SD, 2006, DIGESTION, V74, P42, DOI 10.1159/000096593
   Goldman O, 2021, J MED SYST, V45, DOI 10.1007/s10916-020-01693-5
   Graham DY, 2018, J ADV RES, V13, P51, DOI 10.1016/j.jare.2018.01.006
   Greenspan M, 2015, AM J GASTROENTEROL, V110, pS601, DOI 10.14309/00000434-201510001-01391
   Grundy SM, 2004, CIRCULATION, V109, P433, DOI 10.1161/01.CIR.0000111245.75752.C6
   Islam Rafiul Sameer, 2013, Gastroenterol Hepatol (N Y), V9, P640
   Jain R, 2018, J NUTR BIOCHEM, V59, P1, DOI 10.1016/j.jnutbio.2018.02.015
   Kamareddine MH, 2018, BMJ OPEN GASTROENTER, V5, DOI 10.1136/bmjgast-2018-000253
   Kang Kyu Ho, 2018, Korean J Gastroenterol, V71, P213, DOI 10.4166/kjg.2018.71.4.213
   Khalilia M, 2011, BMC MED INFORM DECIS, V11, DOI 10.1186/1472-6947-11-51
   Kim SY, 2019, WORLD J GASTROENTERO, V25, P190, DOI 10.3748/wjg.v25.i2.190
   Kumar A, 2018, INDIAN J GASTROENTER, V37, P235, DOI 10.1007/s12664-018-0855-8
   Lauritano D, 2017, Oral Implantol (Rome), V10, P229, DOI 10.11138/orl/2017.10.3.229
   Lim SH, 2007, GUT LIVER, V1, P138, DOI 10.5009/gnl.2007.1.2.138
   Liu YL, 2018, J GASTROEN HEPATOL, V33, P800, DOI 10.1111/jgh.14006
   Markowski AR, 2016, WORLD J GASTROENTERO, V22, P8883, DOI 10.3748/wjg.v22.i40.8883
   Meira LB, 2008, J CLIN INVEST, V118, P2516, DOI 10.1172/JCI35073
   Momen-Heravi F, 2017, INT J CANCER, V140, P646, DOI 10.1002/ijc.30486
   Moutsopoulos NM, 2006, ANN NY ACAD SCI, V1088, P251, DOI 10.1196/annals.1366.032
   Nam JH, 2017, CANCER CAUSE CONTROL, V28, P107, DOI 10.1007/s10552-016-0839-x
   Okada H, 2013, DIABETES CARE, V36, P1908, DOI 10.2337/dc12-2087
   Park W, 2012, J GASTROEN HEPATOL, V27, P1490, DOI 10.1111/j.1440-1746.2012.07128.x
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Ren HG, 2016, ANN ONCOL, V27, P1329, DOI 10.1093/annonc/mdw172
   Schmitz J M, 1997, Gastrointest Endosc Clin N Am, V7, P29
   Schreuders EH, 2015, GUT, V64, P1637, DOI 10.1136/gutjnl-2014-309086
   Sey MSL, 2012, CAN J GASTROENTEROL, V26, P894, DOI 10.1155/2012/494797
   Shmuely H, 2001, AM J GASTROENTEROL, V96, P3406
   Stergios K, 2016, INT J SURG, V33, P23, DOI 10.1016/j.ijsu.2016.06.048
   Tanwar S., 2020, J COMPUT THEOR NANOS, V17, P2354
   Thorburn CM, 1998, GASTROENTEROLOGY, V115, P275, DOI 10.1016/S0016-5085(98)70193-3
   Togo K, 2016, WORLD J GASTROENTERO, V22, P9028, DOI 10.3748/wjg.v22.i40.9028
   Tongtawee T, 2018, TURK J GASTROENTEROL, V29, P555, DOI 10.5152/tjg.2018.17608
   Wan Y, 2020, CLIN NUTR, V39, P3189, DOI 10.1016/j.clnu.2020.02.014
   Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457
   Xiao SY, 2017, INT J ONCOL, V51, P5, DOI 10.3892/ijo.2017.4000
   Zheng ED, 2015, TURK J GASTROENTEROL, V26, P474, DOI 10.5152/tjg.2015.0099
NR 55
TC 1
Z9 2
U1 4
U2 9
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-9032
J9 HEALTHCARE-BASEL
JI Healthcare
PD JAN
PY 2022
VL 10
IS 1
AR 169
DI 10.3390/healthcare10010169
PG 12
WC Health Care Sciences & Services; Health Policy & Services
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services
GA YN3VI
UT WOS:000747188500001
PM 35052332
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Luca, M
   Ciobanu, A
AF Luca, Mihaela
   Ciobanu, Adrian
TI Polyp detection in video colonoscopy using deep learning
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Video colonoscopy; polyp detection; deep learning; real time
ID COMPUTER-AIDED DIAGNOSIS; CLASSIFICATION
AB Video colonoscopy automatic processing is a challenge and further development of computer assisted diagnosis is very helpful in correctness assessment of the exam, in e-learning and training, for statistics on polyps' malignity or in polyps' survey. New devices and programming languages are emerging and deep learning begun already to furnish astonishing results, in the quest for high speed and optimal polyp detection software. This paper presents a successful attempt in detecting the intestinal polyps in real time video colonoscopy with deep learning, using Mobile Net.
C1 [Luca, Mihaela; Ciobanu, Adrian] Romanian Acad, Inst Comp Sci, Iasi Branch, 8 Bd Carol I, Iasi, Romania.
C3 Romanian Academy of Sciences
RP Luca, M (通讯作者)，Romanian Acad, Inst Comp Sci, Iasi Branch, 8 Bd Carol I, Iasi, Romania.
EM mihaela.luca@iitacademiaromana-is.ro
OI Ciobanu, Adrian/0000-0003-4473-6645
CR Aadam AA, 2014, AM J GASTROENTEROL, V109, P1312, DOI 10.1038/ajg.2014.95
   Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Ameling S., 2009, 11th International Congress of the IUPESM. World Congress on Medical Physics and Biomedical Engineering. Image Processing, Biosignal Processing, Modelling and Simulation, Biomechanics, P995, DOI 10.1007/978-3-642-03882-2_265
   [Anonymous], 2015, DEEP LEARNING NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], ARGUS TECHNOLOGY SUP
   [Anonymous], COLORECTAL COLON CAN
   Arnold M., 2016, GLOBAL PATTERNS TREN
   ASGE, AM SOC GASTR END
   Attardo S, 2020, WORLD J GASTROENTERO, V26, P5606, DOI 10.3748/wjg.v26.i37.5606
   Azer SA, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55080473
   Bagheri M, 2019, IEEE ENG MED BIO, P6742, DOI 10.1109/EMBC.2019.8856793
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bilal M, 2020, AM J GASTROENTEROL, V115, P963, DOI 10.14309/ajg.0000000000000646
   Borgli H., HYPERKVASIR DATASET, DOI 10.17605/OSF.IO/MH9SJ
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Ciobanu A, 2020, E-HEALTH BIOENG CONF
   Ciobanu A, 2017, E-HEALTH BIOENG CONF, P535, DOI 10.1109/EHB.2017.7995479
   Ciresan D.C., 2011, COMPUT RES REPOSITOR
   D'Acunto M, 2019, J INTELL FUZZY SYST, V37, P7199, DOI 10.3233/JIFS-179332
   Deep Lizard, US
   Geman O., 2016, INT WORKSHOP SOFT CO, V633, P265
   GI GENIUS, US
   github, US
   github, 2020, US
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   k Geetha, 2016, Asian Pac J Cancer Prev, V17, P4869
   Ketkar N., 2017, DEEP LEARNING PYTHON, P195, DOI [10.1007/978-1-4842-2766-4_12, DOI 10.1007/978-1-4842-2766-4_12]
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Le Roy F, 2016, ENDOSCOPY, V48, P263, DOI 10.1055/s-0034-1392976
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Li TB, 2016, GASTROINTEST ENDOSC, V83, pAB482, DOI 10.1016/j.gie.2016.03.671
   Luca M, 2020, LECT NOTE NETW SYST, V101, P288, DOI 10.1007/978-3-030-36841-8_28
   Luca M., SOFT COMPUTING APPL, V1222, DOI [10.1007/978-3-030-52190-5_1, DOI 10.1007/978-3-030-52190-5_1]
   Ma C, 2019, AM J GASTROENTEROL, V114, P1802, DOI 10.14309/ajg.0000000000000407
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Manivannan S., 2013, IEEE 10 INT S BIOMED
   MICCAI, 2015, AUT POL DET COL VID
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Muthukudage J.K., 2013, THESIS U N TEXAS COM
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   nvidia, US
   OLYMPUS, US
   Petruzziello L, 2012, J CLIN GASTROENTEROL, V46, P590, DOI 10.1097/MCG.0b013e3182370b7b
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sanchez-Montes C, 2020, GASTROENT HEPAT-BARC, V43, P222, DOI 10.1016/j.gastrohep.2019.11.004
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8676, P151, DOI 10.1007/978-3-319-13692-9_14
   Varalatchoumy M., 2020, International Journal of Advanced Intelligence Paradigms, V16, P355
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WHO-World Health Organization, FACT SHEETS CANC KEY
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 60
TC 0
Z9 0
U1 2
U2 9
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2022
VL 43
IS 2
SI SI
BP 1751
EP 1759
DI 10.3233/JIFS-219276
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2D3EP
UT WOS:000811435100008
DA 2023-08-21
ER

PT J
AU Natarajan, K
   Balusamy, S
AF Natarajan, Kirthika
   Balusamy, Sargunam
TI Transfer Learning Based Deep Neural Network for Detecting Artefacts in
   Endoscopic Images
SO INTERNATIONAL JOURNAL OF ELECTRICAL AND COMPUTER ENGINEERING SYSTEMS
LA English
DT Article
DE Deep learning; Artefacts; Endoscopy; Transfer learning
AB Endoscopy is typically used to visualize various parts of the digestive tract. The technique is well suited to detect abnormalities like cancer/polyp, taking sample tissue called a biopsy, or cauterizing a bleeding vessel. During the procedure, video/ images are generated. It is affected by eight different artefacts: saturation, specularity, blood, blur, bubbles, contrast, instrument and miscellaneous artefacts like floating debris, chromatic aberration etc. The frames affected by artefacts are mostly discarded as the clinician could extract no valuable information from them. It affects post-processing steps. Based on the transfer learning approach, three state-of-the-art deep learning models, namely YOLOv3, YOLOv4 and Faster R-CNN, were trained with images from EAD public datasets and a custom dataset of endoscopic images of Indian patients annotated for artefacts mentioned above. The training set of images are data augmented and used to train all the three-artefact detectors. The predictions of the artefact detectors are combined to form an ensemble model whose results outperformed well compared to existing literature works by obtaining a mAP score of 0.561 and an IoU score of 0.682. The inference time of 80.4ms was recorded, which stands out best in the literature.
C1 [Natarajan, Kirthika; Balusamy, Sargunam] Avinashilingam Inst Home Sci & Higher Educ Women, Sch Engn, Coimbatore 641108, India.
C3 Avinashilingam University for Women
RP Natarajan, K (通讯作者)，Avinashilingam Inst Home Sci & Higher Educ Women, Sch Engn, Coimbatore 641108, India.
EM prof.kirthika@gmail.com; sargunamb@gmail.com
FU DST -CURIE -AI Fa- cility, Avinashilingam Institute for Home Science and
   Higher Education for Women, Coimbatore
FX This research work is supported by DST -CURIE -AI Fa- cility,
   Avinashilingam Institute for Home Science and Higher Education for
   Women, Coimbatore.
CR Ali S., 2021, COCHRANE DB SYST REV, VV4
   Ali S., 2019, MENDELEY DATA, pV2
   Ali S, 2019, ARXIV PREPRINT ARXIV
   Ali S, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101900
   [Anonymous], VGG IMAGE ANNOTATOR
   [Anonymous], MICROSOFT COMMON OBJ
   [Anonymous], CVC CLINICSPEC DATAS
   [Anonymous], IMAGENET DATASET
   [Anonymous], FACEBOOK RES DETECTR
   Bochkovskiy A, 2020, Arxiv, DOI [arXiv:2004.10934, 10.48550/arXiv.2004.10934]
   Darknet, YOLOV3
   Darknet, YOLOV4
   Darknet, YOLOV4 MOD ZOO
   Gao X., 2020, P 2 INT WORKSHOP CHA, P80
   Google colaboratory, US
   Hu H., 2020, ENDOCV ISBI, P78
   Hung H. M., 2020, P 2 INT WORKSHOP CHA, P47
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lopez F., CLASS IMBALANCE RAND
   Oksuz I., 2019, P CHALLENGE ENDOSCOP
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren S., 2015, NIPS, P91
   Research Group CAMMA, CHOL 80 DAT
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simula Research Laboratory, KVAS INSTR DAT
   Subramanian A., 2020, P 2 INT WORKSHOP CHA, P51
   Wang X., 2019, P CHALLENGE ENDOSCOP
   Wikipedia, ARTIFACT ERROR
   Yu Z., 2020, P 2 INT WORKSHOP CHA, P42
   Zhang P., 2019, P CHALLENGE ENDOSCOP
   Zhang YY, 2019, J ZHEJIANG UNIV-SC B, V20, P1014, DOI 10.1631/jzus.B1900340
NR 31
TC 0
Z9 0
U1 0
U2 0
PU J J STROSSMAYER UNIV OSIJEK, FAC ELECTRICAL ENGINEERING
PI OSIJEK
PA KNEZA TRPIMIRA 2B, OSIJEK, 31000, CROATIA
SN 1847-6996
EI 1847-7003
J9 INT J ELECTR COMPUT
JI Int. J. Electr. Comput. Eng. Syst.
PY 2022
VL 13
IS 8
BP 633
EP 641
PG 9
WC Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA 8Z6WW
UT WOS:000933517500003
DA 2023-08-21
ER

PT J
AU An, NS
   Lan, PN
   Hang, DV
   Long, DV
   Trung, TQ
   Thuy, NT
   Sang, DV
AF Nguyen S An
   Phan N Lan
   Dao V Hang
   Dao V Long
   Tran Q Trung
   Nguyen T Thuy
   Dinh V Sang
TI BlazeNeo: Blazing Fast Polyp Segmentation and Neoplasm Detection
SO IEEE ACCESS
LA English
DT Article
DE Image segmentation; Neoplasms; Task analysis; Biomedical imaging; Neural
   networks; Computer architecture; Deep learning; Semantic segmentation;
   polyp segmentation; deep learning; colonoscopy
ID MISS RATE; COLONOSCOPY
AB In recent years, computer-aided automatic polyp segmentation and neoplasm detection have been an emerging topic in medical image analysis, providing valuable support to colonoscopy procedures. Attentions have been paid to improving the accuracy of polyp detection and segmentation. However, not much focus has been given to latency and throughput for performing these tasks on dedicated devices, which can be crucial for practical applications. This paper introduces a novel deep neural network architecture called BlazeNeo, for the task of polyp segmentation and neoplasm detection with an emphasis on compactness and speed while maintaining high accuracy. The model leverages the highly efficient HarDNet backbone alongside lightweight Receptive Field Blocks and a feature aggregation mechanism for computational efficiency. An auxiliary training strategy is proposed to take full advantage of the training data for the segmentation quality. Our experiments on a challenging dataset show that BlazeNeo achieves improvements in latency and model size while maintaining comparable accuracy against state-of-the-art methods. We obtain over 155 fps while outperforming all compared models in terms of accuracy in INT8 precision when deploying on a dedicated edge device with a conventional configuration.
C1 [Nguyen S An; Phan N Lan; Dinh V Sang] Hanoi Univ Sci & Technol, Sch Informat & Commun Technol, Hanoi 10000, Vietnam.
   [Dao V Hang; Dao V Long] Hanoi Med Univ, Internal Med Fac, Hanoi 11520, Vietnam.
   [Dao V Hang; Dao V Long] Inst Gastroenterol & Hepatol, Hanoi 11522, Vietnam.
   [Tran Q Trung] Hue Univ, Univ Med & Pharm, Dept Internal Med, Hue 53000, Vietnam.
   [Nguyen T Thuy] Vietnam Natl Univ Agr, Fac Informat Technol, Hanoi 12406, Vietnam.
C3 Hanoi University of Science & Technology (HUST); Hanoi Medical
   University; Hue University; Vietnam National University of Agriculture
   (VNUA)
RP Sang, DV (通讯作者)，Hanoi Univ Sci & Technol, Sch Informat & Commun Technol, Hanoi 10000, Vietnam.
EM sangdv@soict.hust.edu.vn
RI Tran, Quang Trung/AEO-1997-2022; Dao, Hang/HLW-2050-2023; Sang,
   Dinh/R-7975-2018
OI Tran, Quang Trung/0000-0001-8347-1614; Dao, Hang/0000-0002-3685-9496;
   Dao Van, Long/0000-0002-7162-9557; Nguyen, Thuy/0000-0002-9358-6201;
   Sang, Dinh/0000-0002-9254-1327
FU Vingroup Innovation Foundation (VINIF) [VINIF.2020]
FX This work was supported by the Vingroup Innovation Foundation (VINIF)
   under Project VINIF.2020.DA17.
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   [Anonymous], 2018, NVIDIA NVIDIA TENS
   Armin MA, 2015, LECT NOTES COMPUT SC, V9349, P396, DOI 10.1007/978-3-319-24553-9_49
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chennupati S., ARXIV190105808
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang C.-H., ARXIV210107172
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Issa IA, 2017, WORLD J GASTROENTERO, V23, P5086, DOI 10.3748/wjg.v23.i28.5086
   Iwahori Y., 2013, PROC INT C MACH VIS, P21
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee SH, 2008, GASTROINTEST ENDOSC, V67, P683, DOI 10.1016/j.gie.2007.10.018
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li KD, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255809
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Oktay O., 2018, P MIDL, P1, DOI DOI 10.48550/ARXIV.1804.03999
   Lan PN, 2021, LECT NOTES COMPUT SC, V13018, P15, DOI 10.1007/978-3-030-90436-4_2
   Qadir HA, 2019, IEEE ACCESS, V7, P169537, DOI 10.1109/ACCESS.2019.2954675
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ronneberger O., 2015, P INT C MED IM COMP, P234
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang Z., 2019, P 29 BRIT MACH VIS C, P305
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xie E., 2021, P ADV NEUR INF PROC, V34, P12077
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang LF, 2020, PROC CVPR IEEE, P369, DOI 10.1109/CVPR42600.2020.00045
   Zhang Y., ARXIV210208005
   Zhang YH, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), P38, DOI 10.1109/ITOEC49072.2020.9141844
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 47
TC 6
Z9 6
U1 1
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 43669
EP 43684
DI 10.1109/ACCESS.2022.3168693
PG 16
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 0W3PG
UT WOS:000788942500001
OA gold, Green Submitted
DA 2023-08-21
ER

PT J
AU Duc, NT
   Oanh, NT
   Thuy, NT
   Triet, TM
   Sang, DV
AF Nguyen Thanh Duc
   Nguyen Thi Oanh
   Nguyen Thi Thuy
   Tran Minh Triet
   Dinh Viet Sang
TI ColonFormer: An Efficient Transformer Based Method for Colon Polyp
   Segmentation
SO IEEE ACCESS
LA English
DT Article
DE Transformers; Image segmentation; Computer architecture; Decoding;
   Feature extraction; Convolutional neural networks; Computational
   modeling; Polyp segmentation; deep learning; encoder-decoder network;
   hierarchical multi-scale CNN; computer-aided diagnosis
ID CLASSIFICATION; VALIDATION
AB Identifying polyps is challenging for automatic analysis of endoscopic images in computer-aided clinical support systems. Models based on convolutional networks (CNN), transformers, and their combinations have been proposed to segment polyps with promising results. However, those approaches have limitations either in modeling the local appearance of the polyps only or lack of multi-level feature representation for spatial dependency in the decoding process. This paper proposes a novel network, namely ColonFormer, to address these limitations. ColonFormer is an encoder-decoder architecture capable of modeling long-range semantic information at both encoder and decoder branches. The encoder is a lightweight architecture based on transformers for modeling global semantic relations at multi scales. The decoder is a hierarchical network structure designed for learning multi-level features to enrich feature representation. Besides, a refinement module is added with a new skip connection technique to refine the boundary of polyp objects in the global map for accurate segmentation. Extensive experiments have been conducted on five popular benchmark datasets for polyp segmentation, including Kvasir, CVC-Clinic DB, CVC-ColonDB, CVC-T, and ETIS-Larib. Experimental results show that our ColonFormer outperforms other state-of-the-art methods on all benchmark datasets. Our code is available at: https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/ducnt9907/ColonFormer.
C1 [Nguyen Thanh Duc; Nguyen Thi Oanh; Dinh Viet Sang] Hanoi Univ Sci & Technol, Sch Informat & Commun Technol, Hanoi 10000, Vietnam.
   [Nguyen Thi Thuy] Univ Sci VNU HCM, Fac Informat Technol, Ho Chi Minh City 70000, Vietnam.
   [Nguyen Thi Thuy] Univ Sci VNU HCM, Software Engn Lab, Ho Chi Minh City 70000, Vietnam.
   [Tran Minh Triet] Univ Sci VNU HCM, Ho Chi Minh City 70000, Vietnam.
   [Tran Minh Triet] Viet Nam Natl Univ Ho Chi Minh City, John Von Neumann Inst, Ho Chi Minh City 70000, Vietnam.
C3 Hanoi University of Science & Technology (HUST); Vietnam National
   University Hochiminh City; Vietnam National University Hochiminh City;
   Vietnam National University Hochiminh City; Vietnam National University
   Hochiminh City
RP Sang, DV (通讯作者)，Hanoi Univ Sci & Technol, Sch Informat & Commun Technol, Hanoi 10000, Vietnam.
EM sangdv@soict.hust.edu.vn
RI Tran, Minh-Triet/HTO-6586-2023; Sang, Dinh/R-7975-2018
OI Tran, Minh-Triet/0000-0003-3046-3041; Nguyen, Thuy/0000-0002-9358-6201;
   Sang, Dinh/0000-0002-9254-1327; Nguyen, Thi-Oanh/0000-0002-6166-2011
FU Vingroup Innovation Foundation (VINIF) [VINIF.2020]
FX This work was supported by the Vingroup Innovation Foundation (VINIF)
   under Project VINIF.2020.DA17.
CR Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Chen J., 2021, ARXIV
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ho JAT, 2019, Arxiv, DOI arXiv:1912.12180
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C.-H., 2021, ARXIV210107172, DOI 10.48550/arXiv.2101.07172
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hung N. B., 2021, PROC INT C COMPUT CO, P1
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kolesnikov A., 2021, P ICLR
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lou A., 2021, ARXIV PREPRINT ARXIV
   Lou AE, 2022, Arxiv, DOI arXiv:2108.07368
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   An NS, 2022, IEEE ACCESS, V10, P43669, DOI 10.1109/ACCESS.2022.3168693
   Lan PN, 2021, LECT NOTES COMPUT SC, V13018, P15, DOI 10.1007/978-3-030-90436-4_2
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tomar Nikhil Kumar, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P307, DOI 10.1007/978-3-030-68793-9_23
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Sang DV, 2022, Arxiv, DOI arXiv:2105.00402
   Wang W., 2021, P IEEE CVF INT C COM, P568
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Xie E., 2021, P ADV NEUR INF PROC, V34, P1
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou GY, 2019, GASTROENTEROLOGY, V156, pS1511
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 53
TC 11
Z9 11
U1 3
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 80575
EP 80586
DI 10.1109/ACCESS.2022.3195241
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 3R0NJ
UT WOS:000838617100001
OA Green Submitted, gold
DA 2023-08-21
ER

PT J
AU Racz, I
   Horvath, A
   Kranitz, N
   Kiss, G
   Regoczi, H
   Horvath, Z
AF Racz, Istvan
   Horvath, Andras
   Kranitz, Noemi
   Kiss, Gyongyi
   Regoczi, Henriett
   Horvath, Zoltan
TI Artificial Intelligence-Based Colorectal Polyp Histology Prediction by
   Using Narrow-Band Image-Magnifying Colonoscopy
SO CLINICAL ENDOSCOPY
LA English
DT Article
DE Artificial intelligence; Colorectal polyps; Histology prediction; Narrow
   band imaging; Narrow-band imaging international colorectal endoscopic
   classification
ID VALUABLE ENDOSCOPIC INNOVATIONS; COMPUTER-AIDED SYSTEM; REAL-TIME;
   GASTROINTESTINAL ENDOSCOPY; CLASSIFICATION; TUMORS; DIFFERENTIATION;
   PRESERVATION; VALIDATION; DIAGNOSIS
AB Background/Aims: We have been developing artificial intelligence based polyp histology prediction (AIPHP) method to classify Narrow Band Imaging (NBI) magnifying colonoscopy images to predict the hyperplastic or neoplastic histology of polyps. Our aim was to analyze the accuracy of AIPHP and narrow-band imaging international colorectal endoscopic (NICE) classification based histology predictions and also to compare the results of the two methods.
   Methods: We studied 373 colorectal polyp samples taken by polypectomy from 279 patients. The documented NBI still images were analyzed by the AIPHP method and by the NICE classification parallel The AIPHP software was created by machine learning method. The software measures five geometrical and color features on the endoscopic image.
   Results: The accuracy of AIPHP was 86.6% (323/373) in total of polyps. We compared the AIPHP accuracy results for diminutive and non-diminutive polyps (82.1% vs. 92.2%; p=0.0032). The accuracy of the hyperplastic histology prediction was significantly better by NICE compared to AIPHP method both in the diminutive polyps (n=207) (95.2% vs. 82.1%) (p<0.001) and also in all evaluated polyps (n=373) (97.1% vs. 86.6%) (p<0.001)
   Conclusions: Our artificial intelligence based polyp histology prediction software could predict histology with high accuracy only the large size polyp subgroup.
C1 [Racz, Istvan; Kiss, Gyongyi; Regoczi, Henriett] Petz Aladar Univ Teaching Hosp, Dept Internal Med & Gastroenterol, Vasvari P U 2, H-9024 Gyor, Hungary.
   [Horvath, Andras] Szechenyi Istvan Univ, Dept Phys & Chem, Gyor, Hungary.
   [Kranitz, Noemi] Petz Aladar Univ Teaching Hosp, Dept Pathol, Gyor, Hungary.
   [Horvath, Zoltan] Szechenyi Istvan Univ, Dept Math & Informat, Gyor, Hungary.
C3 University of Istvan Szechenyi; University of Istvan Szechenyi
RP Racz, I (通讯作者)，Petz Aladar Univ Teaching Hosp, Dept Internal Med & Gastroenterol, Vasvari P U 2, H-9024 Gyor, Hungary.
EM raczi@petz.gyor.hu
OI Regoczi, Henriett/0000-0001-9157-3004
FU  [GINOP-2.3.4-15-2016-00003]
FX Funding This study was supported by the GINOP-2.3.4-15-2016-00003 grant.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Ahadi M, 2021, PATHOLOGY, V53, P454, DOI 10.1016/j.pathol.2020.10.010
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Cohen J, 2012, GASTROINTEST ENDOSC, V76, P471, DOI 10.1016/j.gie.2012.03.248
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, ENDOSCOPY, V52, P52, DOI 10.1055/a-0995-0084
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hewett DG, 2012, GASTROINTEST ENDOSC, V76, P374, DOI 10.1016/j.gie.2012.04.446
   Horv┬u├th A., 2016, ACTA TECHNICA JAURIN, V9, P65, DOI [10.14513/actatechjaur.v9.n1.397, DOI 10.14513/ACTATECHJAUR.V9.N1.397]
   Ignjatovic A, 2011, GASTROINTEST ENDOSC, V73, P128, DOI 10.1016/j.gie.2010.09.021
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Kanao H, 2009, GASTROINTEST ENDOSC, V69, P631, DOI 10.1016/j.gie.2008.08.028
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   McGill SK, 2013, GUT, V62, P1704, DOI 10.1136/gutjnl-2012-303965
   Neumann H, 2013, GASTROINTEST ENDOSC, V78, P115, DOI 10.1016/j.gie.2013.02.001
   Oba S, 2011, DIGESTION, V83, P167, DOI 10.1159/000321807
   Racz I, 2015, GASTROINTEST ENDOSC, V81, pAB259, DOI 10.1016/j.gie.2015.03.1345
   Rastogi A, 2014, GASTROINTEST ENDOSC, V79, P390, DOI 10.1016/j.gie.2013.07.032
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tanaka S, 2006, GASTROINTEST ENDOSC, V64, P604, DOI 10.1016/j.gie.2006.06.007
   Tanaka S, 2011, DIGEST ENDOSC, V23, P131, DOI 10.1111/j.1443-1661.2011.01106.x
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   van den Broek FJC, 2009, GASTROINTEST ENDOSC, V69, P124, DOI 10.1016/j.gie.2008.09.040
NR 27
TC 4
Z9 4
U1 0
U2 5
PU KOREAN SOC GASTROINTESTINAL ENDOSCOPY
PI SEOUL
PA 2003 LG PALACE, 165-8 DONGGYO-DONG, MAPO-GU, SEOUL, 121-754, SOUTH KOREA
SN 2234-2400
EI 2234-2443
J9 CLIN ENDOSC
JI Clin. Endosc.
PD JAN
PY 2022
VL 55
IS 1
BP 113
EP 121
DI 10.5946/ce.2021.149
PG 9
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA YS4VO
UT WOS:000750676800017
PM 34551512
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Tran, ST
   Nguyen, MH
   Dang, HP
   Nguyen, TT
AF Song-Toan Tran
   Minh-Hoa Nguyen
   Huu-Phuc Dang
   Thanh-Tan Nguyen
TI Automatic Polyp Segmentation Using Modified Recurrent Residual Unet
   Network
SO IEEE ACCESS
LA English
DT Article
DE Convolution; Image segmentation; Colonoscopy; Computer architecture;
   Cancer; Deep learning; Deconvolution; Colonoscopy image; medical image
   segmentation; polyp segmentation; recurrent residual structure; Unet
   architecture
ID U-NET; IMAGE; VALIDATION
AB Colorectal cancer is a dangerous disease with a high mortality rate. To increase the likelihood of successful treatment, early detection of polyps is a useful solution. The Unet-architecture network model is showing success in medical image segmentation including analysis of polyps from colonoscopy images. Traditional Unet and Unet-based models are often huge, requiring training and deployment with a high-performance system. Designing models with compact size and high-performance would be an important goal. In this study, we proposed to modify the Residual Recurrent Unet architecture to improve the size of the model while ensuring the model performance. The proposed model has flexibility in changing the number of filters in convolution units. By taking advantage of the strengths of residual and recurrent structures in terms of reuse of convolutional functions, the new model, therefore, was not only smaller in size but also has superior performance compared to the traditional Unet model and the others. The evaluations were performed on three public Colonoscopy image datasets: CVC-ClinicDB, ETIS-LaribPolypDB, and CVC-ColonDB. The Dice score on CVC-ClinicDB reached 94.59%, ETIS-LaribPolypDB reached 92.73%, and 93.31% on CVC-ColonDB dataset. The experimental results obtained from the proposed network on datasets were better than those in recent related studies. The introduced model has a smaller size than the traditional model nevertheless has outstanding performance, therefore, it would be extremely productive for developing applications on low-performance devices.
C1 [Song-Toan Tran; Minh-Hoa Nguyen; Huu-Phuc Dang; Thanh-Tan Nguyen] Tra Vinh Univ, Dept Elect & Elect Engn, Tra Vinh 87000, Vietnam.
C3 Tra Vinh University
RP Tran, ST (通讯作者)，Tra Vinh Univ, Dept Elect & Elect Engn, Tra Vinh 87000, Vietnam.
EM tstoan1512@tvu.edu.vn
RI Tran, Song-Toan/AAA-8196-2021
OI Tran, Song-Toan/0000-0002-8329-0036; PHUC DANG,
   HUU-/0000-0002-9643-7287; Nguyen, Minh-Hoa/0000-0001-6494-7779
FU Tra Vinh University [55/2022/HD]
FX This work was supported by Tra Vinh University under Grant
   55/2022/HD.HDKH&DT-DHTV.
CR Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   LIANG M, 2015, PROC CVPR IEEE, P3367, DOI [DOI 10.1109/CVPR.2015.7298958, 10.1109/CVPR.2015.7298958]
   Lin DY, 2020, PATTERN RECOGN LETT, V138, P267, DOI 10.1016/j.patrec.2020.07.013
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Nguyen NQ, 2020, IEEE ACCESS, V8, P99495, DOI 10.1109/ACCESS.2020.2995630
   Panayides AS, 2020, IEEE J BIOMED HEALTH, V24, P1837, DOI 10.1109/JBHI.2020.2991043
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Sasmal P, 2022, PATTERN RECOGN LETT, V154, P7, DOI 10.1016/j.patrec.2021.12.014
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Szegedy C., 2015, PROC IEEE C COMPUT V, DOI DOI 10.1109/CVPR.2015.7298594
   Tran ST, 2021, IEEE ACCESS, V9, P3752, DOI 10.1109/ACCESS.2020.3047861
   Tran ST, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9010054
   Trinh Q.-H., 2021, ARXIV210514848
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yeung M, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104815
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 44
TC 3
Z9 3
U1 8
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 65951
EP 65961
DI 10.1109/ACCESS.2022.3184773
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 2J2UR
UT WOS:000815519200001
OA gold
DA 2023-08-21
ER

PT J
AU Souaidi, M
   Ansari, ME
AF Souaidi, Meryem
   Ansari, Mohamed El
TI A New Automated Polyp Detection Network MP-FSSD in WCE and Colonoscopy
   Images Based Fusion Single Shot Multibox Detector and Transfer Learning
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Detectors; Colonoscopy; Object detection; Deep
   learning; Task analysis; Training; Deep transfer learning; edge pooling;
   feature maps fusion; image augmentation; polyp; single-shot multibox
   detector (SSD); wireless capsule endoscopy images (WCE)
ID VALIDATION; DIAGNOSIS; VIDEOS
AB Small polyp region detection in wireless capsule endoscopy (WCE) images is a challenging task in computer vision owing to two major problems: its variation in terms of shape, texture, and size, and the low illumination in the gastrointestinal tract. This study proposes a multiscale pyramidal fusion single-shot multibox detector network (MP-FSSD) to detect small polyp regions in WCE or colonoscopy frames, or both, with respect to the precision-vs-speed trade-off as the base architecture. We investigated deep transfer learning by transferring knowledge to polyp images, thereby enabling the extraction of highly representative features and contextual information from the FSSD. First, an edge-pooling layer was embedded in the shallow part of the network. Subsequently, the feature maps from different layers and scales were transformed to match their sizes. A concatenation module was introduced to integrate the feature maps from different layers, which were delivered to the next layer, followed by downsampling blocks to generate new pyramidal layers. Finally, the feature maps were fed to the multibox detectors to predict the final detection results. Experimentally, we maintained the same hyperparameters for both datasets for a fair comparison. The proposed MP-FSSD network exceeded FSSD by 3.62% in terms of mean average precision (mAP). The testing speed of 62.5 FPS is superior to that of the competitor detection methods. The proposal demonstrates that deep learning has much room for development in the field of gastrointestinal image detection.
C1 [Souaidi, Meryem; Ansari, Mohamed El] Univ Ibn Zohr, Fac Sci, Comp Sci Dept, LabSIV, Agadir 80000, Morocco.
   [Ansari, Mohamed El] Univ Moulay Ismail, Fac Sci, Comp Sci Dept, Informat & Applicat Lab, Meknes 50050, Morocco.
C3 Ibn Zohr University of Agadir; Moulay Ismail University of Meknes
RP Souaidi, M (通讯作者)，Univ Ibn Zohr, Fac Sci, Comp Sci Dept, LabSIV, Agadir 80000, Morocco.
EM souaidi.meryem@gmail.com
RI El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066
FU Ministry of National Education by Vocational Training; Higher Education
   and Scientific Research through the Ministry of Industry, Trade, and
   Green and Digital Economy; Digital Development Agency (ADD); National
   Center for Scientific and Technical Research (CNRST)
   [ALKHAWARIZMI/2020/20]
FX This work was supported in part by the Ministry of National Education by
   Vocational Training; in part by the Higher Education and Scientific
   Research through the Ministry of Industry, Trade, and Green and Digital
   Economy; in part by the Digital Development Agency (ADD); and in part by
   the National Center for Scientific and Technical Research (CNRST) under
   Project ALKHAWARIZMI/2020/20.
CR Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Bagheri M, 2019, IEEE ENG MED BIO, P6742, DOI 10.1109/EMBC.2019.8856793
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Charfi S, 2020, SOFT COMPUT, V24, P4469, DOI 10.1007/s00500-019-04208-8
   Charfi S, 2019, IET IMAGE PROCESS, V13, P1023, DOI 10.1049/iet-ipr.2018.6232
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Chat~eld K., 2014, ARXIV14053531
   Chen BL, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103019
   Chen X., 2021, COMPUT MATH METHOD M, V2021
   Choi HT, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082842
   Dai J., 2016, P ADV NEUR INF PROC, V29, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Dai JF, 2016, ADV NEUR IN, V29
   Dulf EH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175704
   Ellahyani A, 2021, SIGNAL IMAGE VIDEO P, V15, P877, DOI 10.1007/s11760-020-01809-x
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu CY, 2017, DSSD DECONVOLUTIONAL, DOI DOI 10.48550/ARXIV.1701.06659
   Garrido A, 2021, IEEE ACCESS, V9, P148048, DOI 10.1109/ACCESS.2021.3124019
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S., 2015, PROC INT C MACH LEAR, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Jeong J, 2017, ENHANCEMENT SSD CONC
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li Z., 2017, ARXIV171200960
   Li Zhengqi, 2019, PROC CVPR IEEE
   Liang X, 2020, IEEE T CIRC SYST VID, V30, P1758, DOI 10.1109/TCSVT.2019.2905881
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Liu XY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102052
   Lu XC, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3052575
   Ma W, 2020, IEEE ACCESS, V8, P188577, DOI 10.1109/ACCESS.2020.3031990
   Mash Robert, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P113, DOI 10.1007/978-3-319-50835-1_11
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Pacal I., 2021, COMPUT BIOL MED, V141
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   PICARD RR, 1984, J AM STAT ASSOC, V79, P575, DOI 10.2307/2288403
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sasmal P, 2021, IEEE ACCESS, V9, P92629, DOI 10.1109/ACCESS.2021.3092263
   Sasmal P, 2018, INT CONF CIRC SYST S, P201, DOI 10.1109/ICSIGSYS.2018.8372666
   Shin HC, 2015, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2015.7298712
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Solhusvik J., 2021, MED IMAGE ANAL, V68
   Souaidi M., 2020, ADV INTELLIGENT SYST, P870
   Souaidi M., 2017, P 2017 INT C ADV TEC, P1
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tashk A, 2020, IEEE C EVOL COMPUTAT
   Tong W, 2020, IEEE J-STARS, V13, P4121, DOI 10.1109/JSTARS.2020.3009352
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang L, 2016, AUTOMAT CONSTR, V72, P294, DOI 10.1016/j.autcon.2016.05.008
   We O, 1962, WEO CLIN ENDOSCOPY A
   We O., 2015, ETIS LARIB POLYP DB
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yin QJ, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116402
   Yu Tian, 2019, 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), P70, DOI 10.1109/ISBI.2019.8759521
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zhai SP, 2020, IEEE ACCESS, V8, P24344, DOI 10.1109/ACCESS.2020.2971026
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zheng H, 2019, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2019.8759180
NR 72
TC 9
Z9 9
U1 3
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 47124
EP 47140
DI 10.1109/ACCESS.2022.3171238
PG 17
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 1D4NZ
UT WOS:000793780100001
OA gold
DA 2023-08-21
ER

PT J
AU Xu, JW
   Zhang, QW
   Yu, YZ
   Zhao, R
   Bian, XZ
   Liu, XQ
   Wang, J
   Ge, ZZ
   Qian, DH
AF Xu, Jianwei
   Zhang, Qingwei
   Yu, Yizhou
   Zhao, Ran
   Bian, Xianzhang
   Liu, Xiaoqing
   Wang, Jun
   Ge, Zhizheng
   Qian, Dahong
TI Deep reconstruction-recoding network for unsupervised domain adaptation
   and multi-center generalization in colonoscopy polyp detection
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE Polyp detection; Domain adaptation; Multi center generalization;
   Adversarial learning
ID COLORECTAL-CANCER; POLYPECTOMY
AB Background and objective: Currently, the best performing methods in colonoscopy polyp detection are primarily based on deep neural networks (DNNs), which are usually trained on large amounts of labeled data. However, different hospitals use different endoscope models and set different imaging parameters, which causes the collected endoscopic images and videos to vary greatly in style. There may be variations in the color space, brightness, contrast, and resolution, and there are also differences between white light endoscopy (WLE) and narrow band image endoscopy (NBIE). We call these variations the domain shift. The DNN performance may decrease when the training data and the testing data come from different hospitals or different endoscope models. Additionally, it is quite difficult to collect enough new labeled data and retrain a new DNN model before deploying that DNN to a new hospital or endoscope model.
   Methods: To solve this problem, we propose a domain adaptation model called Deep Reconstruction-Recoding Network (DRRN), which jointly learns a shared encoding representation for two tasks: i) a supervised object detection network for labeled source data, and ii) an unsupervised reconstruction-recoding network for unlabeled target data. Through the DRRN, the object detection network's encoder not only learns the features from the labeled source domain, but also encodes useful information from the unlabeled target domain. Therefore, the distribution difference of the two domains' feature spaces can be reduced.
   Results: We evaluate the performance of the DRRN on a series of cross-domain datasets. Compared with training the polyp detection network using only source data, the performance of the DRRN on the target domain is improved. Through feature statistics and visualization, it is demonstrated that the DRRN can learn the common distribution and feature invariance of the two domains. The distribution difference between the feature spaces of the two domains can be reduced.
   Conclusion: The DRRN can improve cross-domain polyp detection. With the DRRN, the generalization performance of the DNN-based polyp detection model can be improved without additional labeled data. This improvement allows the polyp detection model to be easily transferred to datasets from different hospitals or different endoscope models. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Xu, Jianwei; Bian, Xianzhang; Wang, Jun; Qian, Dahong] Shanghai Jiao Tong Univ, Sch Biomed Engn, Inst Med Robot, Deepwise Healthcare Joint Res Lab, Shanghai, Peoples R China.
   [Zhang, Qingwei; Zhao, Ran; Ge, Zhizheng] Shanghai Jiao Tong Univ, Renji Hosp, Sch Med,Key Lab Gastroenterol & Hepatol,Minist Hl, Shanghai Inst Digest Dis,Div Gastroenterol & Hepa, Shanghai, Peoples R China.
   [Yu, Yizhou; Liu, Xiaoqing] Deepwise Artificial Intelligence Lab, Beijing, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Qian, DH (通讯作者)，Shanghai Jiao Tong Univ, Sch Biomed Engn, Inst Med Robot, Deepwise Healthcare Joint Res Lab, Shanghai, Peoples R China.; Ge, ZZ (通讯作者)，Shanghai Jiao Tong Univ, Renji Hosp, Sch Med,Key Lab Gastroenterol & Hepatol,Minist Hl, Shanghai Inst Digest Dis,Div Gastroenterol & Hepa, Shanghai, Peoples R China.
EM jianwei_xu@sjtu.edu.cn; zhangqingweif@hotmail.com;
   zhizhengge@aliyun.com; dahong.qian@sjtu.edu.cn
RI liu, xiao/HMD-7454-2023
FU National Natural Science Foundation of China [81974276]; Chongqing Key
   Technology and Application Demonstration of Medical Imaging Depth
   Intelligent Diagnostic Platform [cstc2018jszx-cyztzxX0017]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 81974276, Chongqing Key Technology and
   Application Demonstration of Medical Imaging Depth Intelligent
   Diagnostic Platform under Grant cstc2018jszx-cyztzxX0017. The authors
   would like to thank to the endoscopists in Renji Hospital affiliated to
   Shanghai Jiaotong University School of Medicine for their helpful
   contribution in collecting the colonoscopy datasets and providing the
   annotations.
CR Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bousmalis K, 2016, ADV NEUR INFORM PROC, P343, DOI DOI 10.48550/ARXIV.1608.06019
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Brenner H, 2011, ANN INTERN MED, V154, P22, DOI 10.7326/0003-4819-154-1-201101040-00004
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2009, NEURAL INF PROCESS S, P131
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hou XX, 2019, LECT NOTES COMPUT SC, V11765, P101, DOI 10.1007/978-3-030-32245-8_12
   Jun-Yan Zhu, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2242, DOI 10.1109/ICCV.2017.244
   Kamnitsas K, 2017, LECT NOTES COMPUT SC, V10265, P597, DOI 10.1007/978-3-319-59050-9_47
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Liu M.-.Y., 2016, ADV NEURAL INFORM PR, V29, P469, DOI DOI 10.5555/3157096.3157149
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P471, DOI 10.1016/S0002-9270(02)05928-2
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Seebock P, 2019, I S BIOMED IMAGING, P605, DOI 10.1109/ISBI.2019.8759158
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   TORRALBA A, 2011, PROC CVPR IEEE, P1521, DOI DOI 10.1109/CVPR.2011.5995347
   Tzeng E, 2014, COMPUT SCI
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Yilin Liu, 2019, Domain Adaptation and Representation Transfer and Medical Image Learning with Less Labels and Imperfect Data. First MICCAI Workshop, DART 2019 and First International Workshop, MIL3ID 2019 Shenzhen, Held in Conjunction with MICCAI 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11795), P81, DOI 10.1007/978-3-030-33391-1_10
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 41
TC 5
Z9 5
U1 8
U2 20
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD FEB
PY 2022
VL 214
AR 106576
DI 10.1016/j.cmpb.2021.106576
EA DEC 2021
PG 10
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA YY3KO
UT WOS:000754690000006
PM 34915425
DA 2023-08-21
ER

PT J
AU Houwen, BBSL
   Hassan, C
   Coupe, VMH
   Greuter, MJE
   Hazewinkel, Y
   Vleugels, JLA
   Antonelli, G
   Bustamante-Balen, M
   Coron, E
   Cortas, GA
   Dinis-Ribeiro, M
   Dobru, DE
   East, JE
   Lacucci, M
   Jover, R
   Kuvaev, R
   Neumann, H
   Pellise, M
   Puig, I
   Rutter, MD
   Saunders, B
   Tate, DJ
   Mori, Y
   Longcroft-Wheaton, G
   Bisschops, R
   Dekker, E
AF Houwen, Britt B. S. L.
   Hassan, Cesare
   Coupe, Veerle M. H.
   Greuter, Marjolein J. E.
   Hazewinkel, Yark
   Vleugels, Jasper L. A.
   Antonelli, Giulio
   Bustamante-Balen, Marco
   Coron, Emmanuel
   Cortas, George A.
   Dinis-Ribeiro, Mario
   Dobru, Daniela E.
   East, James E.
   Lacucci, Marietta
   Jover, Rodrigo
   Kuvaev, Roman
   Neumann, Helmut
   Pellise, Maria
   Puig, Ignasi
   Rutter, Matthew D.
   Saunders, Brian
   Tate, David J.
   Mori, Yuichi
   Longcroft-Wheaton, Gaius
   Bisschops, Raf
   Dekker, Evelien
TI Definition of competence standards for optical diagnosis of diminutive
   colorectal polyps: European Society of Gastrointestinal Endoscopy (ESGE)
   Position Statement
SO ENDOSCOPY
LA English
DT Article
ID CT COLONOGRAPHY; CANCER; DISCARD; COLONOSCOPY; MANAGEMENT; STRATEGY;
   RESECT; POLYPECTOMY; IMPACT; SIZE
AB Background The European Society of Gastrointestinal Endoscopy (ESGE) has developed a core curriculum for high quality optical diagnosis training for practice across Europe. The development of easy-to-measure competence standards for optical diagnosis can optimize clinical decision-making in endoscopy. This manuscript represents an official Position Statement of the ESGE aiming to define simple, safe, and easy-to-measure competence standards for endoscopists and artificial intelligence systems performing optical diagnosis of diminutive colorectal polyps (1 - 5 mm). Methods A panel of European experts in optical diagnosis participated in a modified Delphi process to reach consensus on Simple Optical Diagnosis Accuracy (SODA) competence standards for implementation of the optical diagnosis strategy for diminutive colorectal polyps. In order to assess the clinical benefits and harms of implementing optical diagnosis with different competence standards, a systematic literature search was performed. This was complemented with the results from a recently performed simulation study that provides guidance for setting alternative competence standards for optical diagnosis. Proposed competence standards were based on literature search and simulation study results. Competence standards were accepted if at least 80 % agreement was reached after a maximum of three voting rounds. Recommendation 1 In order to implement the leave-in-situ strategy for diminutive colorectal lesions (1-5 mm), it is clinically acceptable if, during real-time colonoscopy, at least 90 % sensitivity and 80 % specificity is achieved for high confidence endoscopic characterization of colorectal neoplasia of 1-5 mm in the rectosigmoid. Histopathology is used as the gold standard. Level of agreement 95 %. Recommendation 2 In order to implement the resect-and-discard strategy for diminutive colorectal lesions (1-5 mm), it is clinically acceptable if, during real-time colonoscopy, at least 80 % sensitivity and 80 % specificity is achieved for high confidence endoscopic characterization of colorectal neoplasia of 1-5 mm. Histopathology is used as the gold standard. Level of agreement 100 %. Conclusion The developed SODA competence standards define diagnostic performance thresholds in relation to clinical consequences, for training and for use when auditing the optical diagnosis of diminutive colorectal polyps.
C1 [Houwen, Britt B. S. L.; Vleugels, Jasper L. A.; Dekker, Evelien] Univ Amsterdam, Dept Gastroenterol & Hepatol, Amsterdam Univ Med Ctr, Locat AMC, Amsterdam, Netherlands.
   [Hassan, Cesare] Humanitas Univ, Dept Biomed Sci, Milan, Italy.
   [Hassan, Cesare] IRCCS Humanitas Clin & Res Ctr, Endoscopy Unit, Milan, Italy.
   [Coupe, Veerle M. H.; Greuter, Marjolein J. E.] Amsterdam Univ Med Ctr, Locat VUmc, Dept Epidemiol & Data Sci, Amsterdam, Netherlands.
   [Hazewinkel, Yark] Radboud Univ Nijmegen, Radboud Univ Med Ctr, Dept Gastroenterol & Hepatol, Nijmegen, Netherlands.
   Sapienza Univ Rome, Dept Anat Histol Forens Med & Orthoped Sci, Rome, Italy.
   [Antonelli, Giulio] Osped Castelli Hosp, Gastroenterol & Digest Endoscopy Unit, Rome, Italy.
   [Bustamante-Balen, Marco] La Fe Polytech Univ Hosp, Digest Dis Dept, Gastrointestinal Endoscopy Unit, Valencia, Spain.
   [Bustamante-Balen, Marco] La Fe Hlth Res Inst, Gastrointestinal Endoscopy Res Grp, Valencia, Spain.
   [Coron, Emmanuel] Inst Malad Appareil Digestif, Nantes, France.
   [Cortas, George A.] Univ Balamand, Div Gastroenterol, Fac Med, St George Hosp Univ Med Ctr, Beirut, Lebanon.
   [Dinis-Ribeiro, Mario] Porto Comprehens Canc Ctr Porto CCC, Porto, Portugal.
   [Dinis-Ribeiro, Mario] RISE CI IPOP Hlth Res Network, Porto, Portugal.
   [Dobru, Daniela E.] George Emil Palade Univ Med Pharm Sci & Technol T, Gastroenterol Dept, Targu Mures, Romania.
   [East, James E.] Univ Oxford, John Radcliffe Hosp, Translat Gastroenterol Unit, Nuffield Dept Med,Expt Med Div, Oxford, England.
   [East, James E.] Mayo Clin Healthcare, Div Gastroenterol & Hepatol, London, England.
   [Lacucci, Marietta] Univ Birmingham, Inst Translat Med, Birmingham, W Midlands, England.
   [Lacucci, Marietta] Univ Birmingham, Inst Immunol & Lmmunotherapy, Birmingham, W Midlands, England.
   [Lacucci, Marietta] Univ Birmingham, NIHR Biomed Res Ctr, Birmingham, W Midlands, England.
   [Lacucci, Marietta] Univ Hosp Birmingham NHS Fdn Trust, Birmingham, W Midlands, England.
   [Jover, Rodrigo] Univ Miguel Hernandez, Serv Med Digest, Inst Invest Sanitaria ISABIAL, Hosp Gen Univ Alicante, Alicante, Spain.
   [Kuvaev, Roman] Yaroslavl Reg Canc Hosp, Endoscopy Dept, Yaroslavl, Russia.
   [Kuvaev, Roman] NA Pirogov Russian Natl Res Med Univ, Fac Addit Profess Educ, Dept Gastroenterol, Moscow, Russia.
   [Neumann, Helmut] Univ Med Ctr Mainz, Dept Med 1, Mainz, Germany.
   [Neumann, Helmut] GastroZentrum, Lippe, Germany.
   [Pellise, Maria] Hosp Clin Barcelona, Dept Gastroenterol, Barcelona, Spain.
   [Pellise, Maria] Univ Barcelona, Inst Invest Biomed August Pi & Sunyer IDIBAP, Ctr Invest Biomed Red Enfermedades Hepat & Digest, Barcelona, Spain.
   [Puig, Ignasi] Althaia Xarxa Assistencial Univ Manresa, Digest Dis Dept, Manresa, Spain.
   [Puig, Ignasi] Univ Vic Univ Cent Catalunya UVic UCC, Fac Ciencies Salut, Dept Med, Manresa, Spain.
   [Rutter, Matthew D.] Newcastle Univ, Fac Med Sci, Newcastle Upon Tyne, Tyne & Wear, England.
   [Rutter, Matthew D.] Univ Hosp North Tees, Stockton On Tees, England.
   [Saunders, Brian] St Marks Hosp & Acad Inst, Dept Gastroenterol, Harrow, Middx, England.
   [Tate, David J.] Univ Ghent, Dept Gastroenterol & Hepatol, Ghent, Belgium.
   [Tate, David J.] Univ Hosp Ghent, Ghent, Belgium.
   [Mori, Yuichi] Univ Oslo, Inst Hlth & Soc, Clin Effectiveness Res Grp, Oslo, Norway.
   [Mori, Yuichi] Oslo Univ Hosp, Dept Transplantat Med, Sect Gastroenterol, Oslo, Norway.
   [Mori, Yuichi] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Yokohama, Kanagawa, Japan.
   [Longcroft-Wheaton, Gaius] Portsmouth Hosp Univ NHS Trust, Portsmouth, Hants, England.
   [Bisschops, Raf] Katholieke Univ Leuven, Dept Gastroenterol & Hepatol, KUL, TARGID,Univ Hosp Leuven, Leuven, Belgium.
C3 University of Amsterdam; Humanitas University; Radboud University
   Nijmegen; Sapienza University Rome; Nantes Universite; CHU de Nantes;
   University Balamand; George Emil Palade University of Medicine,
   Pharmacy, Science, & Technology of Targu Mures; University of Oxford;
   University of Birmingham; University of Birmingham; University of
   Birmingham; University of Birmingham; General University Hospital of
   Alicante; Universidad Miguel Hernandez de Elche; Universitat d'Alacant;
   Instituto de Investigacion Sanitaria y Biomedica de Alicante (ISABIAL);
   Johannes Gutenberg University of Mainz; University of Barcelona;
   Hospital Clinic de Barcelona; CIBER - Centro de Investigacion Biomedica
   en Red; CIBEREHD; University of Barcelona; Hospital Clinic de Barcelona;
   IDIBAPS; Newcastle University - UK; University Hospital of North Tees;
   Ghent University; Ghent University; Ghent University Hospital;
   University of Oslo; University of Oslo; Showa University; KU Leuven;
   University Hospital Leuven
RP Dekker, E (通讯作者)，Amsterdam Univ Med Ctr, Locat Acad Med Ctr, Dept Gastroenterol & Hepatol, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.
EM e.dekker@amsterdamumc.nl
RI Dekker, Evelien/HOH-9015-2023; Coron, Emmanuel/HZH-6760-2023; Houwen,
   Britt/IVH-6320-2023; Puig, Ignasi/N-1208-2014; Vleugels,
   Jasper/AAX-4659-2021; Hazewinkel, Yark/AAD-6593-2019; hassan,
   cesare/H-2844-2012; Dinis-Ribeiro, Mario/A-9248-2010; Bustamante-Balen,
   Marco/E-2123-2013
OI Puig, Ignasi/0000-0002-9059-8602; hassan, cesare/0000-0001-7167-1459;
   Dinis-Ribeiro, Mario/0000-0003-0121-6850; Bustamante-Balen,
   Marco/0000-0003-2019-0158; Dekker, Evelien/0000-0002-4363-0745;
   Antonelli, Giulio/0000-0003-1797-3864; Houwen,
   Britt/0000-0003-1920-8947; Bisschops, Raf/0000-0002-9994-8226
CR Bisschops R., 2019, ENDOSCOPY, V51, P1179
   Bisschops R, 2019, ENDOSCOPY, V51, P976, DOI 10.1055/a-1000-5603
   Bleijenberg AGC, 2020, GUT, V69, P2150, DOI 10.1136/gutjnl-2019-319804
   Boulkedid R, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020476
   Dekker E, 2020, ENDOSCOPY, V52, P899, DOI 10.1055/a-1231-5123
   Gellad ZF, 2013, AM J GASTROENTEROL, V108, P873, DOI 10.1038/ajg.2012.316
   Gupta S, 2020, GASTROENTEROLOGY, V158, P1131, DOI 10.1053/j.gastro.2019.10.026
   Hassan C, 2010, ALIMENT PHARM THER, V31, P210, DOI 10.1111/j.1365-2036.2009.04160.x
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   HOUWEN B, 2021, ENDOSCOPY
   Houwen BBSL, 2021, GASTROINTEST ENDOSC, V94, P812, DOI 10.1016/j.gie.2021.04.008
   Humphrey-Murto S, 2019, J CLIN EPIDEMIOL, V106, P136, DOI 10.1016/j.jclinepi.2018.10.011
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jass JR, 2007, HISTOPATHOLOGY, V50, P113, DOI 10.1111/j.1365-2559.2006.02549.x
   JONES J, 1995, BRIT MED J, V311, P376, DOI 10.1136/bmj.311.7001.376
   Kaltenbach T, 2015, GUT, V64, P1569, DOI 10.1136/gutjnl-2014-307742
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Mahajan D, 2013, AM J SURG PATHOL, V37, P427, DOI 10.1097/PAS.0b013e31826cf50f
   National Institute for Health and Care Excellence, 2017, VIRT CHROM ASS COL P
   Ninomiya Y, 2017, DIGEST ENDOSC, V29, P773, DOI 10.1111/den.12877
   Oka S, 2014, DIGEST ENDOSC, V26, P78, DOI 10.1111/den.12275
   Payne SR, 2014, CLIN GASTROENTEROL H, V12, P1119, DOI 10.1016/j.cgh.2013.11.034
   Pickhardt PJ, 2009, AM J ROENTGENOL, V193, P40, DOI 10.2214/AJR.08.1709
   Picot J, 2017, HEALTH TECHNOL ASSES, V21, P1, DOI 10.3310/hta21790
   Rex DK, 2015, GASTROINTEST ENDOSC, V82, P376, DOI 10.1016/j.gie.2015.04.029
   Rutter MD, 2020, GUT, V69, P201, DOI 10.1136/gutjnl-2019-319858
   Schachschal G, 2016, INT J COLORECTAL DIS, V31, P675, DOI 10.1007/s00384-016-2523-8
   Sekiguchi M, 2019, AM J GASTROENTEROL, V114, P964, DOI 10.14309/ajg.0000000000000261
   Soudagar AS, 2016, J CLIN GASTROENTEROL, V50, pE45, DOI 10.1097/MCG.0000000000000382
   Stoop EM, 2012, LANCET ONCOL, V13, P55, DOI 10.1016/S1470-2045(11)70283-2
   Toes-Zoutendijk E, 2017, GASTROENTEROLOGY, V152, P767, DOI 10.1053/j.gastro.2016.11.022
   Toyota M, 1999, P NATL ACAD SCI USA, V96, P8681, DOI 10.1073/pnas.96.15.8681
   Vleugels JLA, 2019, GASTROENTEROLOGY, V156, P623, DOI 10.1053/j.gastro.2018.10.050
   Vleugels JLA, 2018, GASTROENTEROLOGY, V154, P1682, DOI 10.1053/j.gastro.2018.01.063
   Vleugels JLA, 2017, ENDOSC INT OPEN, V5, pE1197, DOI 10.1055/s-0043-113565
   Vleugels JLA, 2017, GASTROINTEST ENDOSC, V85, P1169, DOI 10.1016/j.gie.2016.12.014
   von Renteln D, 2018, ENDOSCOPY, V50, P221, DOI 10.1055/s-0043-121221
   Vu HT, 2015, GASTROINTEST ENDOSC, V82, P381, DOI 10.1016/j.gie.2015.01.042
   Wang LM, 2015, GASTROINTEST ENDOSC, V82, P385, DOI 10.1016/j.gie.2015.02.036
   Willems P, 2020, ENDOSC INT OPEN, V8, pE684, DOI 10.1055/a-1132-5371
NR 41
TC 18
Z9 18
U1 0
U2 1
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD JAN
PY 2022
VL 54
IS 01
BP 88
EP 99
DI 10.1055/a-1689-5130
EA DEC 2021
PG 12
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA XP5PS
UT WOS:000726980700001
PM 34872120
OA Bronze
DA 2023-08-21
ER

PT J
AU Ahmad, OF
   Puyal, JGB
   Brandao, P
   Kader, R
   Abbasi, F
   Hussein, M
   Haidry, RJ
   Toth, D
   Mountney, P
   Seward, E
   Vega, R
   Stoyanov, D
   Lovat, LB
AF Ahmad, Omer F.
   Puyal, Juana Gonzalez-Bueno
   Brandao, Patrick
   Kader, Rawen
   Abbasi, Faisal
   Hussein, Mohamed
   Haidry, Rehan J.
   Toth, Daniel
   Mountney, Peter
   Seward, Ed
   Vega, Roser
   Stoyanov, Danail
   Lovat, Laurence B.
TI Performance of artificial intelligence for detection of subtle and
   advanced colorectal neoplasia
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE artificial intelligence; colonic polyps; colonoscopy; colorectal
   neoplasms; deep learning
ID COLONOSCOPY; VALIDATION; POLYPS
AB Objectives There is uncertainty regarding the efficacy of artificial intelligence (AI) software to detect advanced subtle neoplasia, particularly flat lesions and sessile serrated lesions (SSLs), due to low prevalence in testing datasets and prospective trials. This has been highlighted as a top research priority for the field. Methods An AI algorithm was evaluated on four video test datasets containing 173 polyps (35,114 polyp-positive frames and 634,988 polyp-negative frames) specifically enriched with flat lesions and SSLs, including a challenging dataset containing subtle advanced neoplasia. The challenging dataset was also evaluated by eight endoscopists (four independent, four trainees, according to the Joint Advisory Group on gastrointestinal endoscopy [JAG] standards in the UK). Results In the first two video datasets, the algorithm achieved per-polyp sensitivities of 100% and 98.9%. Per-frame sensitivities were 84.1% and 85.2%. In the subtle dataset, the algorithm detected a significantly higher number of polyps (P < 0.0001), compared to JAG-independent and trainee endoscopists, achieving per-polyp sensitivities of 79.5%, 37.2% and 11.5%, respectively. Furthermore, when considering subtle polyps detected by both the algorithm and at least one endoscopist, the AI detected polyps significantly faster on average. Conclusions The AI based algorithm achieved high per-polyp sensitivities for advanced colorectal neoplasia, including flat lesions and SSLs, outperforming both JAG independent and trainees on a very challenging dataset containing subtle lesions that could have been overlooked easily and contribute to interval colorectal cancer. Further prospective trials should evaluate AI to detect subtle advanced neoplasia in higher risk populations for colorectal cancer.
C1 [Ahmad, Omer F.; Puyal, Juana Gonzalez-Bueno; Brandao, Patrick; Kader, Rawen; Hussein, Mohamed; Stoyanov, Danail; Lovat, Laurence B.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, London, England.
   [Ahmad, Omer F.; Kader, Rawen; Abbasi, Faisal; Hussein, Mohamed; Haidry, Rehan J.; Lovat, Laurence B.] UCL, Div Surg & Intervent Sci, London, England.
   [Ahmad, Omer F.; Haidry, Rehan J.; Seward, Ed; Vega, Roser; Lovat, Laurence B.] Univ Coll London Hosp, Gastrointestinal Serv, London, England.
   [Puyal, Juana Gonzalez-Bueno; Brandao, Patrick; Toth, Daniel; Mountney, Peter] Odin Vis Ltd, London, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London; University of London; University College London; University
   College London Hospitals NHS Foundation Trust
RP Ahmad, OF (通讯作者)，Wellcome EPSRC Ctr Intervent & Surg Sci, Charles Bell House,43-45 Foley St, London W1W 7TS, England.
EM ofahmad123@gmail.com
RI Lovat, Laurence/C-1986-2009; Kader, Rawen/ABI-2203-2020; hussein,
   mohamed/GYU-6912-2022
OI Lovat, Laurence/0000-0003-4542-3915; Kader, Rawen/0000-0001-9133-0838; 
FU National Institute for Health Research University College London
   Hospitals Biomedical Research Centre; Wellcome/EPSRC Centre for
   Interventional and Surgical Sciences (WEISS) at UCL [203145Z/16/Z]
FX L.B.L. IS SUPPORTED by the National Institute for Health Research
   University College London Hospitals Biomedical Research Centre. This
   work was supported by the Wellcome/EPSRC Centre for Interventional and
   Surgical Sciences (WEISS) at UCL [203145Z/16/Z].
CR Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Guo Z, 2021, DIGEST ENDOSC, V33, P162, DOI 10.1111/den.13670
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, DIGEST ENDOSC, V33, P285, DOI 10.1111/den.13807
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Livovsky DM, 2021, GASTROINTEST ENDOSC, V94, P1099, DOI 10.1016/j.gie.2021.06.021
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2021, GASTROENTEROLOGY, V161, P774, DOI 10.1053/j.gastro.2021.04.078
   Mori Y, 2021, J GASTROEN HEPATOL, V36, P7, DOI 10.1111/jgh.15339
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
NR 21
TC 6
Z9 6
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD MAY
PY 2022
VL 34
IS 4
BP 862
EP 869
DI 10.1111/den.14187
EA DEC 2021
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 1A1UF
UT WOS:000724570800001
PM 34748665
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Madalinski, M
   Prudham, R
AF Madalinski, Mariusz
   Prudham, Roger
TI Can Real-time Computer-Aided Detection Systems Diminish the Risk of
   Postcolonoscopy Colorectal Cancer?
SO JMIR MEDICAL INFORMATICS
LA English
DT Article
DE artificial intelligence; colonoscopy; adenoma; real-time computer-aided
   detection; colonic polyp
ID QUALITY; INDICATORS
AB The adenoma detection rate is the constant subject of research and the main marker of quality in bowel cancer screening. However, by improving the quality of endoscopy via artificial intelligence methods, all polyps, including those with the potential for malignancy, can be removed, thereby reducing interval colorectal cancer rates. As such, the removal of all polyps may become the best marker of endoscopy quality. Thus, we present a viewpoint on integrating the computer-aided detection (CADe) of polyps with high-accuracy, real-time colonoscopy to challenge quality improvements in the performance of colonoscopy. Colonoscopy for bowel cancer screening involving the integration of a deep learning methodology (ie, integrating artificial intelligence with CADe systems) has been assessed in an effort to increase the adenoma detection rate. In this viewpoint, a few studies are described, and their results show that CADe systems are able to increase screening sensitivity. The detection of adenomatous polyps, which are associated with a potential risk of progression to colorectal cancer, and their removal are expected to reduce cancer incidence and mortality rates. However, so far, artificial intelligence methods do not increase the detection of cancer or large adenomatous polyps but contribute to the detection of small precancerous polyps.
C1 [Madalinski, Mariusz] Royal Oldham Hosp, Northern Care Alliance, Rochdale Rd, Oldham OL1 2JH, England.
   [Prudham, Roger] Northern Care Alliance, Bury, England.
RP Madalinski, M (通讯作者)，Royal Oldham Hosp, Northern Care Alliance, Rochdale Rd, Oldham OL1 2JH, England.
EM mariusz.madalinski@googlemail.com
OI Prudham, Roger/0000-0002-4040-3926; Madalinski,
   Mariusz/0000-0002-2272-2333
CR Aniwan S, 2016, AM J GASTROENTEROL, V111, P723, DOI 10.1038/ajg.2015.440
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Madalinski M., 2018, UNITED EUROPEAN GAST, pA192
   Rees CJ, 2016, GUT, V65, P1923, DOI 10.1136/gutjnl-2016-312044
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wong MCS, 2019, INTEST RES, V17, P317
NR 8
TC 0
Z9 0
U1 0
U2 1
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
EI 2291-9694
J9 JMIR MED INF
JI JMIR Med. Inf.
PD DEC
PY 2021
VL 9
IS 12
AR e25328
DI 10.2196/25328
PG 3
WC Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Medical Informatics
GA YA8SQ
UT WOS:000738596600005
PM 34571490
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Pfeifer, L
   Neufert, C
   Leppkes, M
   Waldner, MJ
   Hafner, M
   Beyer, A
   Hoffman, A
   Siersema, PD
   Neurath, MF
   Rath, T
AF Pfeifer, Lukas
   Neufert, Clemens
   Leppkes, Moritz
   Waldner, Maximilian J.
   Hafner, Michael
   Beyer, Albert
   Hoffman, Arthur
   Siersema, Peter D.
   Neurath, Markus F.
   Rath, Timo
TI Computer-aided detection of colorectal polyps using a newly generated
   deep convolutional neural network: from development to first clinical
   experience
SO EUROPEAN JOURNAL OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Article
DE adenoma detection rate; artificial intelligence; colorectal cancer;
   computer-aided detection; screening colonoscopy
ID SOCIETY TASK-FORCE; ADENOMA DETECTION; GASTROINTESTINAL ENDOSCOPY;
   SCREENING RECOMMENDATIONS; ARTIFICIAL-INTELLIGENCE; TRAINEE
   PARTICIPATION; COLONOSCOPY; CANCER; PREVENTION; PREVALENCE
AB Aim The use of artificial intelligence represents an objective approach to increase endoscopist's adenoma detection rate (ADR) and limit interoperator variability. In this study, we evaluated a newly developed deep convolutional neural network (DCNN) for automated detection of colorectal polyps ex vivo as well as in a first in-human trial.
   Methods For training of the DCNN, 116 529 colonoscopy images from 278 patients with 788 different polyps were collected. A subset of 10 467 images containing 504 different polyps were manually annotated and treated as the gold standard. An independent set of 45 videos consisting of 15 534 single frames was used for ex vivo performance testing. In vivo realtime detection of colorectal polyps during routine colonoscopy by the DCNN was tested in 42 patients in a back-to-back approach.
   Results When analyzing the test set of 15 534 single frames, the DCNN's sensitivity and specificity for polyp detection and localization within the frame was 90% and 80%, respectively, with an area under the curve of 0.92. In vivo, baseline polyp detection rate and ADR were 38% and 26% and significantly increased to 50% (P = 0.023) and 36% (P = 0.044), respectively, with the use of the DCNN. Of the 13 additionally with the DCNN detected lesions, the majority were diminutive and flat, among them three sessile serrated adenomas.
   Conclusion This newly developed DCNN enables highly sensitive automated detection of colorectal polyps both ex vivo and during first in-human clinical testing and could potentially increase the detection of colorectal polyps during colonoscopy. Copyright (C) 2021 The Author(s). Published by Wolters Kluwer Health, Inc.
C1 [Pfeifer, Lukas; Neufert, Clemens; Leppkes, Moritz; Waldner, Maximilian J.; Neurath, Markus F.; Rath, Timo] Friedrich Alexander Univ, Ludwig Demling Endoscopy Ctr Excellence, Dept Internal Med 1, Div Gastroenterol, Erlangen, Germany.
   [Hafner, Michael] Cent Hosp Bolzano, Dept Gastroenterol Physiopathol & Endoscopy Gastr, Bolzano, Italy.
   [Beyer, Albert] Gastroenterol Outpatient Clin, Altottingjh, Germany.
   [Hoffman, Arthur] Klinikum Aschaffenburg, Div Gastroenterol, Dept Internal Med 3, Aschaffenburg, Germany.
   [Siersema, Peter D.] Radboud Univ Nijmegen, Med Ctr, Dept Gastroenterol & Hepatol, Nijmegen, Netherlands.
C3 University of Erlangen Nuremberg; Krankenhaus Bozen; Radboud University
   Nijmegen
RP Rath, T (通讯作者)，Friedrich Alexander Univ, Div Gastroenterol, Ludwig Demling Endoscopy Ctr Excellence, Endoscopy, Ulmenweg 18, D-91054 Erlangen, Germany.
EM timo.rath@uk-erlangen.de
RI Siersema, Peter/V-1636-2019
OI Rath, Timo/0000-0002-7728-9338
FU Deutsche Forschungsgemeinschaft; Friedrich-Alexander-Universitat
   Erlangen-Nurnberg (FAU)
FX We acknowledge support by Deutsche Forschungsgemeinschaft and
   Friedrich-Alexander-Universitat Erlangen-Nurnberg (FAU) within the
   funding programme Open Access Publishing.
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kim TS, 2012, GUT LIVER, V6, P344, DOI 10.5009/gnl.2012.6.3.344
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Nishizawa T, 2011, DIGESTION, V84, P245, DOI 10.1159/000330736
   OBRIEN MJ, 1990, GASTROENTEROLOGY, V98, P371, DOI 10.1016/0016-5085(90)90827-N
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Simons DJ, 1997, TRENDS COGN SCI, V1, P261, DOI 10.1016/S1364-6613(97)01080-2
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Simonyan K., INT C LEARN REPR 201, DOI 10.1.1.746.3713
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 42
TC 6
Z9 6
U1 0
U2 9
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0954-691X
EI 1473-5687
J9 EUR J GASTROEN HEPAT
JI Eur. J. Gastroenterol. Hepatol.
PD DEC
PY 2021
VL 33
SU 1
BP E662
EP E669
DI 10.1097/MEG.0000000000002209
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA ZO8XO
UT WOS:000766011800089
PM 34034272
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Wan, JJ
   Chen, BL
   Yu, YT
AF Wan, Jingjing
   Chen, Bolun
   Yu, Yongtao
TI Polyp Detection from Colorectum Images by Using Attentive YOLOv5
SO DIAGNOSTICS
LA English
DT Article
DE colorectal cancer; polyp detection; YOLOv5; attention mechanism
ID TASK-FORCE; CANCER; COLONOSCOPY; RISK; VALIDATION
AB Background: High-quality colonoscopy is essential to prevent the occurrence of colorectal cancers. The data of colonoscopy are mainly stored in the form of images. Therefore, artificial intelligence-assisted colonoscopy based on medical images is not only a research hotspot, but also one of the effective auxiliary means to improve the detection rate of adenomas. This research has become the focus of medical institutions and scientific research departments and has important clinical and scientific research value. Methods: In this paper, we propose a YOLOv5 model based on a self-attention mechanism for polyp target detection. This method uses the idea of regression, using the entire image as the input of the network and directly returning the target frame of this position in multiple positions of the image. In the feature extraction process, an attention mechanism is added to enhance the contribution of information-rich feature channels and weaken the interference of useless channels; Results: The experimental results show that the method can accurately identify polyp images, especially for the small polyps and the polyps with inconspicuous contrasts, and the detection speed is greatly improved compared with the comparison algorithm. Conclusions: This study will be of great help in reducing the missed diagnosis of clinicians during endoscopy and treatment, and it is also of great significance to the development of clinicians' clinical work.
C1 [Wan, Jingjing] Xuzhou Med Univ, Peoples Hosp Huaian 2, Dept Gastroenterol, Affiliated Huaian Hosp, Huaian 223002, Peoples R China.
   [Chen, Bolun; Yu, Yongtao] Huaiyin Inst Technol, Dept Comp Sci, Huaiyin 223001, Peoples R China.
   [Chen, Bolun] Univ Fribourg, Dept Phys, CH-1700 Fribourg, Switzerland.
C3 Xuzhou Medical University; Huaiyin Institute of Technology; University
   of Fribourg
RP Chen, BL (通讯作者)，Huaiyin Inst Technol, Dept Comp Sci, Huaiyin 223001, Peoples R China.; Chen, BL (通讯作者)，Univ Fribourg, Dept Phys, CH-1700 Fribourg, Switzerland.
EM 11000419@hyit.edu.cn; chenbolun@hyit.edu.cn; allennessy@hyit.edu.cn
OI Chen, Bolun/0000-0002-1341-4187; Yu, Yongtao/0000-0001-7204-9346
CR Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Antonelli G, 2021, BEST PRACT RES CL GA, V52-53, DOI 10.1016/j.bpg.2020.101713
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bernal J., 2021, COMPUTER AIDED ANAL, P163, DOI 10.1007/978-3-030-64340-9_21
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED, DOI DOI 10.48550/ARXIV.2004.10934
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Cao CT, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250632
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Doubeni CA, 2013, ANN INTERN MED, V158, P312, DOI 10.7326/0003-4819-158-5-201303050-00003
   Guo Z, 2020, I S BIOMED IMAGING, P1655, DOI 10.1109/ISBI45749.2020.9098500
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   Kang J, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1469
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Le Alexander, 2021, Int J Clin Res Trials, V6, DOI 10.15344/2456-8007/2021/157
   Li P, 2005, PROC CVPR IEEE, P670
   Li W., 2021, CEUR WORKSHOP PROC, P69
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Maida M, 2019, EXPERT REV ANTICANC, V19, P223, DOI 10.1080/14737140.2019.1565999
   Mostafiz R, 2020, INT J IMAG SYST TECH, V30, P224, DOI 10.1002/ima.22350
   Mulliqi N, 2020, IEEE IMAGE PROC, P380, DOI 10.1109/ICIP40778.2020.9191310
   Ng S, 2020, DIGEST DIS SCI, V65, P2229, DOI 10.1007/s10620-020-06049-0
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Rex DK, 2017, GASTROENTEROLOGY, V153, P307, DOI 10.1053/j.gastro.2017.05.013
   Shen P, 2021, J DIGEST DIS, V22, P256, DOI 10.1111/1751-2980.12985
   Shen Z., 2021, ARXIV
   Siegel RL., 2020, CA-CANCER J CLIN, V70, P145, DOI [DOI 10.3322/caac.21590, 10.3322/caac.21601]
   Sinonquel P, 2021, GUT, V70, P641, DOI 10.1136/gutjnl-2020-322491
   Stoffel EM, 2020, GASTROENTEROLOGY, V158, P341, DOI 10.1053/j.gastro.2019.07.055
   Tang CP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165315
   Tas M, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2020.106959
   Tashk A, 2020, IEEE C EVOL COMPUTAT
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Yang XY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038011
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 46
TC 20
Z9 20
U1 10
U2 57
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD DEC
PY 2021
VL 11
IS 12
AR 2264
DI 10.3390/diagnostics11122264
PG 15
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA XY2IH
UT WOS:000736802300001
PM 34943501
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Hori, K
   Ikematsu, H
   Yamamoto, Y
   Matsuzaki, H
   Takeshita, N
   Shinmura, K
   Yoda, Y
   Kiuchi, T
   Takemoto, S
   Yokota, H
   Yano, T
AF Hori, Keisuke
   Ikematsu, Hiroaki
   Yamamoto, Yoichi
   Matsuzaki, Hiroki
   Takeshita, Nobuyoshi
   Shinmura, Kensuke
   Yoda, Yusuke
   Kiuchi, Takayoshi
   Takemoto, Satoko
   Yokota, Hideo
   Yano, Tomonori
TI Detecting colon polyps in endoscopic images using artificial
   intelligence constructed with automated collection of annotated images
   from an endoscopy reporting system
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE artificial intelligence; automated collection system; colon polyps;
   endoscopic images
ID MISS RATES; CONVENTIONAL COLONOSCOPY; TANDEM COLONOSCOPY; NEOPLASTIC
   LESIONS; COLORECTAL LESIONS; ADENOMA DETECTION; MULTICENTER;
   CLASSIFICATION; ENDOCYTOSCOPY; EFFICIENCY
AB Background Artificial intelligence (AI) has made considerable progress in image recognition, especially in the analysis of endoscopic images. The availability of large-scale annotated datasets has contributed to the recent progress in this field. Datasets of high-quality annotated endoscopic images are widely available, particularly in Japan. A system for collecting annotated data reported daily could aid in accumulating a significant number of high-quality annotated datasets. Aim We assessed the validity of using daily annotated endoscopic images in a constructed reporting system for a prototype AI model for polyp detection. Methods We constructed an automated collection system for daily annotated datasets from an endoscopy reporting system. The key images were selected and annotated for each case only during daily practice, not to be performed retrospectively. We automatically extracted annotated endoscopic images of diminutive colon polyps that had been diagnosed (study period March-September 2018) using the keywords of diagnostic information, and additionally collect the normal colon images. The collected dataset was devised into training and validation to build and evaluate the AI system. The detection model was developed using a deep learning algorithm, RetinaNet. Results The automated system collected endoscopic images (47,391) from colonoscopies (745), and extracted key colon polyp images (1356) with localized annotations. The sensitivity, specificity, and accuracy of our AI model were 97.0%, 97.7%, and 97.3% (n = 300), respectively. Conclusion The automated system enabled the development of a high-performance colon polyp detector using images in endoscopy reporting system without the efforts of retrospective annotation works.
C1 [Hori, Keisuke; Ikematsu, Hiroaki; Yamamoto, Yoichi; Shinmura, Kensuke; Yoda, Yusuke; Yano, Tomonori] Natl Canc Ctr Hosp East, Dept Gastroenterol & Endoscopy, 6-5-1 Kashiwanoha, Kashiwa, Chiba 2778577, Japan.
   [Hori, Keisuke; Ikematsu, Hiroaki] Natl Canc Ctr Hosp East, Div Sci & Technol Endoscopy, Exploratory Oncol Res & Clin Trial Ctr, Chiba, Japan.
   [Matsuzaki, Hiroki; Takeshita, Nobuyoshi; Yoda, Yusuke; Yano, Tomonori] Natl Canc Ctr Hosp East, Med Device Innovat Ctr, Chiba, Japan.
   [Kiuchi, Takayoshi] FUJIFILM Med IT Solut Co Ltd, Syst Engn Div, Tokyo, Japan.
   [Takemoto, Satoko; Yokota, Hideo] RIKEN Ctr Adv Photon, Image Proc Res Team, Saitama, Japan.
   [Yokota, Hideo] RIKEN Informat R&D & Strategy Headquarters, Adv Data Sci Project, Saitama, Japan.
C3 National Cancer Center - Japan; National Cancer Center - Japan; National
   Cancer Center - Japan; RIKEN
RP Yano, T (通讯作者)，Natl Canc Ctr Hosp East, Dept Gastroenterol & Endoscopy, 6-5-1 Kashiwanoha, Kashiwa, Chiba 2778577, Japan.
EM toyano@east.ncc.go.jp
OI Shinmura, Kensuke/0000-0001-8786-4634; Ikematsu,
   Hiroaki/0000-0001-9840-4588; Takemoto, Satoko/0000-0003-0258-6589
FU National Cancer Center research and development fund [29-A-10]; Japan
   Agency for Medical Research and Development (ICT infrastructure
   establishment for R&D on AI Prototype based on Gastroenterological
   Endoscopic clinical integrated database) [18lk1010026h0001]
FX THIS STUDY IS supported by the National Cancer Center research and
   development fund (29-A-10) and the fund of the Japan Agency for Medical
   Research and Development (ICT infrastructure establishment for R&D on AI
   Prototype based on Gastroenterological Endoscopic clinical integrated
   database, 18lk1010026h0001). The sponsor had no role in study design,
   data collection, data analysis and interpretation, manuscript
   preparation, or the decision to publish.
CR Adler A, 2008, GUT, V57, P59, DOI 10.1136/gut.2007.123539
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Deenadayalu VP, 2004, AM J GASTROENTEROL, V99, P2138, DOI 10.1111/j.1572-0241.2004.40430.x
   DeMarco DC, 2010, GASTROINTEST ENDOSC, V71, P542, DOI 10.1016/j.gie.2009.12.021
   Dinesen L, 2012, GASTROINTEST ENDOSC, V75, P604, DOI 10.1016/j.gie.2011.10.017
   Fujimoto D, 2018, ENDOSC INT OPEN, V6, pE322, DOI 10.1055/s-0043-124469
   Gralnek IM, 2014, LANCET ONCOL, V15, P353, DOI 10.1016/S1470-2045(14)70020-8
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Ikematsu H, 2017, GASTROINTEST ENDOSC, V86, P386, DOI 10.1016/j.gie.2017.01.017
   Kato M, 2020, DIGEST ENDOSC, V32, P494, DOI 10.1111/den.13495
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Leung WK, 2014, AM J GASTROENTEROL, V109, P855, DOI 10.1038/ajg.2014.83
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Matsuda K, 2018, DIGEST ENDOSC, V30, P5, DOI 10.1111/den.12964
   Matsushita M, 1998, ENDOSCOPY, V30, P444, DOI 10.1055/s-2007-1001305
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Munroe CA, 2012, GASTROINTEST ENDOSC, V75, P561, DOI 10.1016/j.gie.2011.11.037
   Paggi S, 2018, ENDOSCOPY, V50, P396, DOI 10.1055/a-0580-7405
   Pasha SF, 2012, AM J GASTROENTEROL, V107, P363, DOI 10.1038/ajg.2011.436
   Rex DK, 2003, AM J GASTROENTEROL, V98, P2000, DOI 10.1016/S0002-9270(03)00625-7
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Saito Y, 2022, DIGEST ENDOSC, V34, P144, DOI 10.1111/den.13980
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Triadafilopoulos G, 2007, GASTROINTEST ENDOSC, V65, P139, DOI 10.1016/j.gie.2006.07.044
   Uraoka T, 2013, GASTROINTEST ENDOSC, V77, P480, DOI 10.1016/j.gie.2012.08.037
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Young J, 2007, GUT, V56, P1453, DOI 10.1136/gut.2007.126870
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 34
TC 1
Z9 1
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JUL
PY 2022
VL 34
IS 5
BP 1021
EP 1029
DI 10.1111/den.14185
EA NOV 2021
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA 2Q4PY
UT WOS:000723914400001
PM 34748658
DA 2023-08-21
ER

PT J
AU Nasir-Moin, M
   Suriawinata, AA
   Ren, B
   Liu, XY
   Robertson, DJ
   Bagchi, S
   Tomita, N
   Wei, JW
   MacKenzie, TA
   Rees, JR
   Hassanpour, S
AF Nasir-Moin, Mustafa
   Suriawinata, Arief A.
   Ren, Bing
   Liu, Xiaoying
   Robertson, Douglas J.
   Bagchi, Srishti
   Tomita, Naofumi
   Wei, Jason W.
   MacKenzie, Todd A.
   Rees, Judy R.
   Hassanpour, Saeed
TI Evaluation of an Artificial Intelligence-Augmented Digital System for
   Histologic Classification of Colorectal Polyps
SO JAMA NETWORK OPEN
LA English
DT Article
ID INTEROBSERVER AGREEMENT; COLONOSCOPY; DIAGNOSIS; DYSPLASIA; ADENOMAS;
   RECOMMENDATIONS; PATHOLOGISTS; SURVEILLANCE; VARIABILITY; POLYPECTOMY
AB IMPORTANCE Colorectal polyps are common, and their histopathologic classification is used in the planning of follow-up surveillance. Substantial variation has been observed in pathologists' classification of colorectal polyps, and improved assessment by pathologists may be associated with reduced subsequent underuse and overuse of colonoscopy.
   OBJECTIVE To compare standard microscopic assessment with an artificial intelligence (AI)-augmented digital system that annotates regions of interest within digitized polyp tissue and predicts polyp type using a deep learning model to assist pathologists in colorectal polyp classification.
   DESIGN, SETTING, AND PARTICIPANTS In this diagnostic study conducted at a tertiary academic medical center and a community hospital in New Hampshire, 100 slides with colorectal polyp samples were read by 15 pathologists using a microscope and an AI-augmented digital system, with a washout period of at least 12 weeks between use of each modality. The study was conducted from February 10 to July 10, 2020.
   MAIN OUTCOMES AND MEASURES Accuracy and time of evaluation were used to compare pathologists' performance when a microscope was used with their performance when the AI-augmented digital system was used. Outcomes were compared using paired t tests and mixed-effects models.
   RESULTS In assessments of 100 slides with colorectal polyp specimens, use of the AI-augmented digital system significantly improved pathologists' classification accuracy compared with microscopic assessment from 73.9% (95% CI, 71.7%-76.2%) to 80.8% (95% CI, 78.8%-82.8%) (P < .001). The overall difference in the evaluation time per slide between the digital system (mean, 21.7 seconds; 95% CI, 20.8-22.7 seconds) and microscopic examination (mean, 13.0 seconds; 95% CI, 12.4-13.5 seconds) was -8.8 seconds (95% CI, -9.8 to -7.7 seconds), but this difference decreased as pathologists became more familiar and experienced with the digital system; the difference between the time of evaluation on the last set of 20 slides for all pathologists when using the microscope and the digital system was 4.8 seconds (95% CI, 3.0-6.5 seconds).
   CONCLUSIONS AND RELEVANCE In this diagnostic study, an AI-augmented digital system significantly improved the accuracy of pathologic interpretation of colorectal polyps compared with microscopic assessment. If applied broadly to clinical practice, this tool may be associated with decreases in subsequent overuse and underuse of colonoscopy and thus with improved patient outcomes and reduced health care costs.
C1 [Nasir-Moin, Mustafa; Bagchi, Srishti; Wei, Jason W.; MacKenzie, Todd A.; Hassanpour, Saeed] Geisel Sch Med, Dept Biomed Data Sci, Hanover, NH USA.
   [Nasir-Moin, Mustafa; Bagchi, Srishti; Tomita, Naofumi; Wei, Jason W.; Hassanpour, Saeed] Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.
   [Suriawinata, Arief A.; Ren, Bing; Liu, Xiaoying] Dartmouth Hitchcock Med Ctr, Dept Pathol & Lab Med, Lebanon, NH 03766 USA.
   [Robertson, Douglas J.; MacKenzie, Todd A.] Dartmouth Inst Hlth Policy & Clin Practice, Lebanon, NH USA.
   [Robertson, Douglas J.; MacKenzie, Todd A.] Geisel Sch Med, Dept Med, Hanover, NH USA.
   [Robertson, Douglas J.] Vet Affairs Med Ctr, Sect Gastroenterol, White River Jct, VT USA.
   [Rees, Judy R.] Geisel Sch Med, Dept Community & Family Med, Hanover, NH USA.
   [Rees, Judy R.; Hassanpour, Saeed] Geisel Sch Med, Dept Epidemiol, Hanover, NH USA.
C3 Dartmouth College; Dartmouth College; Dartmouth College; Dartmouth
   College; Dartmouth College; US Department of Veterans Affairs; Veterans
   Health Administration (VHA); Dartmouth College; Dartmouth College
RP Hassanpour, S (通讯作者)，Geisel Sch Med, Dept Biomed Data Sci, One Med Ctr Dr,HB 7261, Lebanon, NH 03756 USA.
EM Saeed.Hassanpour@dartmouth.edu
OI Nasir-Moin, Mustafa/0000-0002-0389-1852
FU National Cancer Institute [R01CA249758]; National Library of Medicine
   [R01LM012837]
FX This research was supported in part by grant R01CA249758 from the
   National Cancer Institute (Dr Hassanpour) and grant R01LM012837 from the
   National Library of Medicine (Dr Hassanpour).
CR Baldin Rosimeri Kuhl Svoboda, 2015, J. Coloproctol. (Rio J.), V35, P193, DOI 10.1016/j.jcol.2015.06.008
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Campanella G, 2019, NAT MED, V25, P1301, DOI 10.1038/s41591-019-0508-1
   Costantini M, 2003, J CLIN EPIDEMIOL, V56, P209, DOI 10.1016/S0895-4356(02)00587-5
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Foss FA, 2012, HISTOPATHOLOGY, V61, P47, DOI 10.1111/j.1365-2559.2011.04154.x
   Gupta S, 2020, GASTROENTEROLOGY, V158, P1131, DOI 10.1053/j.gastro.2019.10.026
   Hamilton SR, 2019, WHO CLASSIFICATION T, P170
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Johnson MR, 2015, GASTROENTEROLOGY, V149, P938, DOI 10.1053/j.gastro.2015.06.026
   Joseph DA, 2016, CANCER-AM CANCER SOC, V122, P2479, DOI 10.1002/cncr.30070
   Kahi CJ, 2010, AM J GASTROENTEROL, V105, P1301, DOI 10.1038/ajg.2010.51
   Kiani A, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0232-8
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Lasisi F, 2013, DIGEST LIVER DIS, V45, P1049, DOI 10.1016/j.dld.2013.05.014
   Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3
   Mahajan D, 2013, AM J SURG PATHOL, V37, P427, DOI 10.1097/PAS.0b013e31826cf50f
   Mysliwiec PA, 2004, ANN INTERN MED, V141, P264, DOI 10.7326/0003-4819-141-4-200408170-00006
   Osmond A, 2014, J CLIN PATHOL, V67, P781, DOI 10.1136/jclinpath-2014-202177
   PAAS FGWC, 1992, J EDUC PSYCHOL, V84, P429, DOI 10.1037/0022-0663.84.4.429
   Pai RK., 2019, WHO CLASSIFICATION T, P163
   Petriceks AH, 2018, ACAD PATHOL, V5, DOI 10.1177/2374289518765457
   Ransohoff DF, 2011, DIGEST DIS SCI, V56, P2623, DOI 10.1007/s10620-011-1791-y
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2009, AM J GASTROENTEROL, V104, P739, DOI 10.1038/ajg.2009.104
   Steiner DF, 2018, AM J SURG PATHOL, V42, P1636, DOI 10.1097/PAS.0000000000001151
   Turner JK, 2013, HISTOPATHOLOGY, V62, P916, DOI 10.1111/his.12110
   US General Services Administration Technology Transformation Services, SYST US SCAL SUS
   van Putten PG, 2011, HISTOPATHOLOGY, V58, P974, DOI 10.1111/j.1365-2559.2011.03822.x
   Vennelaganti S, 2021, GASTROENTEROLOGY, V160, P452, DOI 10.1053/j.gastro.2020.09.015
   Wei JW, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.3398
   Wei JW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40041-7
   Zhang ZZ, 2019, NAT MACH INTELL, V1, P236, DOI 10.1038/s42256-019-0052-1
   Zhao Boyang, 2019, JCO Clin Cancer Inform, V3, P1, DOI 10.1200/CCI.19.00057
   Zhou S., 2020, INTELL BASED MED, V1, P100004, DOI DOI 10.1016/J.IBMED.2020.100004
   Zhu MD, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-86540-4
NR 36
TC 5
Z9 5
U1 0
U2 0
PU AMER MEDICAL ASSOC
PI CHICAGO
PA 330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA
SN 2574-3805
J9 JAMA NETW OPEN
JI JAMA Netw. Open
PD NOV 18
PY 2021
VL 4
IS 11
AR e2135271
DI 10.1001/jamanetworkopen.2021.35271
PG 12
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA XA2TA
UT WOS:000720504900010
PM 34792588
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Livovsky, DM
   Veikherman, D
   Golany, T
   Aides, A
   Dashinsky, V
   Rabani, N
   Ben Shimol, D
   Blau, Y
   Katzir, L
   Shimshoni, I
   Liu, Y
   Segol, O
   Goldin, E
   Corrado, G
   Lachter, J
   Matias, Y
   Rivlin, E
   Freedman, D
AF Livovsky, Dan M.
   Veikherman, Danny
   Golany, Tomer
   Aides, Amit
   Dashinsky, Valentin
   Rabani, Nadav
   Ben Shimol, David
   Blau, Yochai
   Katzir, Liran
   Shimshoni, Ilan
   Liu, Yun
   Segol, Ori
   Goldin, Eran
   Corrado, Greg
   Lachter, Jesse
   Matias, Yossi
   Rivlin, Ehud
   Freedman, Daniel
TI Detection of elusive polyps using a large-scale artificial intelligence
   system
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID ADENOMA DETECTION; COLONOSCOPY; CLASSIFICATION; ASSOCIATION; VALIDATION
AB Background and Aims: Colorectal cancer is a leading cause of death. Colonoscopy is the criterion standard for detection and removal of precancerous lesions and has been shown to reduce mortality. The polyp miss rate during colonoscopies is 22% to 28%. DEEP DEtection of Elusive Polyps (DEEP2) is a new polyp detection system based on deep learning that alerts the operator in real time to the presence and location of polyps. The primary outcome was the performance of DEEP2 on the detection of elusive polyps.
   Methods: The DEEP2 system was trained on 3611 hours of colonoscopy videos derived from 2 sources and was validated on a set comprising 1393 hours from a third unrelated source. Ground truth labeling was provided by offline gastroenterologist annotators who were able to watch the video in slow motion and pause and rewind as required. To assess applicability, stability, and user experience and to obtain some preliminary data on performance in a real-life scenario, a preliminary prospective clinical validation study was performed comprising 100 procedures.
   Results: DEEP2 achieved a sensitivity of 97.1% at 4.6 false alarms per video for all polyps and of 88.5% and 84.9% for polyps in the field of view for less than 5 and 2 seconds, respectively. DEEP2 was able to detect polyps not seen by live real-time endoscopists or offline annotators in an average of .22 polyps per sequence. In the clinical validation study, the system detected an average of .89 additional polyps per procedure. No adverse events occurred.
   Conclusions: DEEP2 has a high sensitivity for polyp detection and was effective in increasing the detection of polyps both in colonoscopy videos and in real procedures with a low number of false alarms.
C1 [Livovsky, Dan M.; Goldin, Eran] Hebrew Univ Jerusalem, Fac Med, Jerusalem, Israel.
   [Livovsky, Dan M.; Goldin, Eran] Shaare Zedek Med Ctr, Digest Dis Inst, 12 Bayit St, IL-90301 Jerusalem, Israel.
   [Veikherman, Danny; Golany, Tomer; Aides, Amit; Dashinsky, Valentin; Rabani, Nadav; Blau, Yochai; Katzir, Liran; Matias, Yossi; Rivlin, Ehud; Freedman, Daniel] Google Res, Jerusalem, Israel.
   [Ben Shimol, David; Liu, Yun; Corrado, Greg] Google Hlth, Palo Alto, CA USA.
   [Shimshoni, Ilan] Univ Haifa, Dept Informat Syst, Haifa, Israel.
   [Segol, Ori] Carmel Hosp, Gastroenterol Dept, Haifa, Israel.
   [Lachter, Jesse] Technion Israel Inst Technol, Fac Med, Haifa, Israel.
   [Lachter, Jesse] United Healthcare Serv, Gastroenterol Dept, Northern Region, Israel.
C3 Hebrew University of Jerusalem; Hebrew University of Jerusalem; Shaare
   Zedek Medical Center; Google Incorporated; University of Haifa; Clalit
   Health Services; Carmel Medical Center; Technion Israel Institute of
   Technology; Rappaport Faculty of Medicine
RP Livovsky, DM (通讯作者)，Shaare Zedek Med Ctr, Digest Dis Inst, 12 Bayit St, IL-90301 Jerusalem, Israel.
OI Liu, Yun/0000-0003-4079-8275
CR Ahmad OF, 2020, TECHN INNOV GASTROIN, V22, P80
   Anderson R, 2020, GASTROENTEROLOGY, V158, P1287, DOI 10.1053/j.gastro.2019.12.031
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brandao P, FULLY CONVOLUTIONAL, DOI [10.1117/12, DOI 10.1117/12]
   Byrne MF, 2018, GASTROINTEST ENDOSC, V87, pAB475
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen R.J., SLAM ENDOSCOPY ENHAN
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Ferlay JEM., 2020, GLOBAL CANC OBSERVAT
   Forbes N, 2020, CLIN GASTROENTEROL H, V18, P2192, DOI 10.1016/j.cgh.2020.03.046
   Freedman D, 2020, IEEE T MED IMAGING, V39, P3451, DOI 10.1109/TMI.2020.2994221
   Gross SA, 2020, GASTROINTEST ENDOSC, V91, P425, DOI 10.1016/j.gie.2019.10.027
   Guren MG, 2019, LANCET GASTROENTEROL, V4, P894, DOI 10.1016/S2468-1253(19)30329-2
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   He K., 2016, 2016 IEEE C COMPUTER
   Howard A. G., MOBILENETS EFFICIENT
   Kim A., IDATA RES
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Lam AY, 2020, GASTROINTEST ENDOSC, V92, P355, DOI 10.1016/j.gie.2020.02.016
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu M, MOBILE VIDEO OBJECT
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma RB, 2019, LECT NOTES COMPUT SC, V11768, P573, DOI 10.1007/978-3-030-32254-0_64
   Mathews SC, 2019, GASTROINTEST ENDOSC, V90, P651, DOI 10.1016/j.gie.2019.06.004
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mohammed A, Y NET DEEP CONVOLUTI
   Patraucean V, SPATIOTEMPORAL VIDEO
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sanchez-Montes C, 2020, GASTROENT HEPAT-BARC, V43, P222, DOI 10.1016/j.gastrohep.2019.11.004
   Shi X., CONVOLUTIONAL LSTM N
   Tan MX, 2019, PR MACH LEARN RES, V97
   Turan M, UNSUPERVISED ODOMETR
   Turan M, 2018, NEUROCOMPUTING, V275, P1861, DOI 10.1016/j.neucom.2017.10.014
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wadhwa V, 2020, ENDOSC INT OPEN, V08, pE1379, DOI 10.1055/a-1223-1926
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wichakam I, 2018, LECT NOTES COMPUT SC, V10704, P393, DOI 10.1007/978-3-319-73603-7_32
   Wikipedia, Q FUNCT
   Wu HP, 2019, IEEE I CONF COMP VIS, P9216, DOI 10.1109/ICCV.2019.00931
   Zhou DJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16777-6
   Zhou GY, 2019, GASTROENTEROLOGY, V156, pS1511
   ZHOU X, OBJECTS POINTS
   Zhu X, 2018, GASTROINTEST ENDOSC, V87, pAB251
NR 55
TC 11
Z9 11
U1 2
U2 6
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD DEC
PY 2021
VL 94
IS 6
BP 1099
EP +
DI 10.1016/j.gie.2021.06.021
EA NOV 2021
PG 21
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA WY5FV
UT WOS:000719304900010
PM 34216598
OA hybrid
DA 2023-08-21
ER

PT J
AU Wang, AL
   Mo, JH
   Zhong, CL
   Wu, SH
   Wei, SF
   Tu, BQ
   Liu, C
   Chen, DM
   Xu, Q
   Cai, MY
   Li, ZY
   Xie, WT
   Xie, M
   Kato, M
   Xi, XJ
   Zhang, BP
AF Wang, Aling
   Mo, Jiahao
   Zhong, Cailing
   Wu, Shaohua
   Wei, Sufen
   Tu, Binqi
   Liu, Chang
   Chen, Daman
   Xu, Qing
   Cai, Mengyi
   Li, Zhuoyao
   Xie, Wenting
   Xie, Miao
   Kato, Motohiko
   Xi, Xujie
   Zhang, Beiping
TI Artificial intelligence-assisted detection and classification of
   colorectal polyps under colonoscopy: a systematic review and
   meta-analysis
SO ANNALS OF TRANSLATIONAL MEDICINE
LA English
DT Review
DE Artificial intelligence (AI); colorectal polyps; colonoscopy;
   meta-analysis
ID ADENOMA DETECTION; CANCER; DIAGNOSIS; ALGORITHM; MORTALITY; LESIONS;
   IMPACT; RISK
AB Background: Artificial intelligence (AI) is used to solve the problem of missed diagnosis of polyps in colonoscopy, which has been proved to improve the detection rate of adenomas. The aim of this review was to evaluate the diagnostic performance of AI-assisted detection and classification of polyps in colonoscopy.
   Methods: The literature search was undertaken on 4 electronic databases (PubMed, Web of Science, Embase, and Cochrane Library). The inclusion criteria were as follows: studies reporting AI- assisted detection and classification of polyps; studies containing patients, images, or videos receiving AI-assisted diagnosis; studies which included AI-assisted diagnosis and reported classification based on histopathology; and studies providing accurate diagnostic data. Non-English language studies, case-reports, reviews, meeting abstracts and so on were excluded. The Quality Assessment of Diagnostic Accuracy Studies-2 scale was used to evaluate the quality of literature and the Stata 13.0 software was used to perform meta-analysis.
   Results: Twenty-six articles were included with all of medium quality. Meta-analysis showed none of literature had any obvious publication bias. The application of AI in detection of colorectal polyps achieved a sensitivity of 0.95 [95% confidence interval (CI): 0.89-0.98] and an area under the curve (AUC) of 0.79 (95% CI: 0.79-0.82). the AI-assisted classification, the sensitivity was 0.92 (95% CI: 0.88-0.95) with a specificity of 0.82 (95% CI: 0.71-0.89) and an AUC of 0.94 (95% CI: 0.92-0.96). For the classification of diminutive polyps, the AI-assisted technique yielded a sensitivity of 0.95 (95% CI: 0.94-0.97), a specificity of 0.88 (95% CI: 0.74-0.95), and an AUC of 0.97 (95% CI: 0.95-0.98). For AI-assisted classification under magnifying endoscopy, the sensitivity was 0.954 (95% CI: 0.92-0.96) with a specificity of 0.95 (95% CI: 0.80-0.99) and an AUC of 0.97 (95% CI: 0.95-0.98).
   Discussion: The AI- assisted technique demonstrates impressive accuracy for the detection and characterization of colorectal polyps and can be expected to be a novel auxiliary diagnosis method. Our study has inevitable limitations including heterogeneity due to different AI systems and the inability to further analyze the specificity and sensitivity of AI for different types of endoscopes.
C1 [Wang, Aling; Mo, Jiahao; Wu, Shaohua; Tu, Binqi; Liu, Chang] Guangzhou Univ Chinese Med, Clin Med Sch 2, Guangzhou, Peoples R China.
   [Zhong, Cailing; Wei, Sufen; Xi, Xujie; Zhang, Beiping] Guangzhou Univ Chinese Med, Dept Gastroenterol, Affiliated Hosp 2, 111 Dade Rd, Guangzhou 510120, Peoples R China.
   [Chen, Daman; Xu, Qing; Cai, Mengyi; Li, Zhuoyao; Xie, Wenting; Xie, Miao] Guangzhou Univ Chinese Med, Guangzhou, Peoples R China.
   [Kato, Motohiko] Keio Univ, Div Gastroenterol & Hepatol, Dept Internal Med, Sch Med, Tokyo, Japan.
C3 Guangzhou University of Chinese Medicine; Guangzhou University of
   Chinese Medicine; Guangzhou University of Chinese Medicine; Keio
   University
RP Xi, XJ; Zhang, BP (通讯作者)，Guangzhou Univ Chinese Med, Dept Gastroenterol, Affiliated Hosp 2, 111 Dade Rd, Guangzhou 510120, Peoples R China.
EM xixujiemuzi@qq.com; doctorzbp@163.com
RI Kato, Motohiko/AAB-2655-2022
OI Kato, Motohiko/0000-0002-7579-1316
FU Guangdong Provincial Hospital of Traditional Chinese Medicine
   [YN10101914]; Guangzhou University of Chinese Medicine "Double First
   -Class"; High-level University Discipline Collaborative Innovation Team
   [2021xk58]
FX Special funding for this study was received from the Guangdong
   Provincial Hospital of Traditional Chinese Medicine (No. YN10101914) and
   the Guangzhou University of Chinese Medicine "Double First -Class" and
   High-level University Discipline Collaborative Innovation Team (No.
   2021xk58).
CR Ahmed Z, 2020, DATABASE-OXFORD, DOI 10.1093/database/baaa010
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cantisani V, 2020, ULTRASCHALL MED, V41, P356, DOI 10.1055/a-1173-4315
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Guo Z, 2021, DIGEST ENDOSC, V33, P162, DOI 10.1111/den.13670
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kim KO, 2021, GUT LIVER, V15, P346, DOI 10.5009/gnl20186
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Li JL, 2021, EUR J GASTROEN HEPAT, V33, P1041, DOI 10.1097/MEG.0000000000001906
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Misawa M, 2021, DIGEST ENDOSC, V33, P273, DOI 10.1111/den.13847
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Poon CCY, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0281-z
   Rees CJ, 2019, NAT REV GASTRO HEPAT, V16, P584, DOI 10.1038/s41575-019-0178-y
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Shaukat A, 2021, AM J GASTROENTEROL, V116, P458, DOI 10.14309/ajg.0000000000001122
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Xu YX, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0246892
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 46
TC 3
Z9 3
U1 1
U2 11
PU AME PUBLISHING COMPANY
PI SHATIN
PA FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG
   00000, PEOPLES R CHINA
SN 2305-5839
EI 2305-5847
J9 ANN TRANSL MED
JI ANN. TRANSL. MED.
PD NOV
PY 2021
VL 9
IS 22
AR 1662
DI 10.21037/atm-21-5081
EA NOV 2021
PG 19
WC Oncology; Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology; Research & Experimental Medicine
GA ZN8SE
UT WOS:000722201600001
PM 34988171
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Huang, D
   Shen, JY
   Hong, JZ
   Zhang, Y
   Dai, SJ
   Du, NN
   Zhang, MT
   Guo, DX
AF Huang, Ding
   Shen, Jingyi
   Hong, Jiaze
   Zhang, Yi
   Dai, Senjie
   Du, Nannan
   Zhang, Mengting
   Guo, Daxin
TI Effect of artificial intelligence-aided colonoscopy for adenoma and
   polyp detection: a meta-analysis of randomized clinical trials
SO INTERNATIONAL JOURNAL OF COLORECTAL DISEASE
LA English
DT Review
DE Artificial intelligence; Colonoscopy; Adenoma detection; Polyp
   detection; Meta-analysis
ID COLORECTAL-CANCER; QUALITY INDICATORS; TIME; RISK; PARTICIPATION; SYSTEM
AB Background This meta-analysis aimed to determine whether artificial intelligence (AI) improves colonoscopy outcome metrics i.e. adenoma detection rate (ADR) and polyp detection rate (PDR). Methods Two authors independently searched Web of Science, PubMed, Science Direct, and Cochrane Library to find all published research before July 2021 that has compared AI-aided colonoscopy with routine colonoscopy (RC) for detection of adenoma and polyp. Results This meta-analysis included 10 RCTs with 6629 individuals in AI-aided (n = 3300) and routine (n = 3329) groups. The results showed that both ADR (RR, 1.43; P < 0.001) and PDR (RR, 1.44; P < 0.001) using AI-aided endoscopy were significantly greater when compared with RC. The adenomas detected per colonoscopy (APC) (WMD, 0.25; P = 0.009), polyps detected per colonoscopy (PPC) (WMD, 0.52; P < 0.001), and sessile serrated lesions detected per colonoscopy (SSLPC) (RR, 1.53; P < 0.001) were significantly higher in the AI-aided group compared with the RC group. Subgroup analysis based on size, location, and shape of adenomas and polyps demonstrated that, except for in the cecum and pedunculated adenomas or polyps, the AI-aided groups of the other subgroups are more advantageous. Withdrawal time was longer in the AI-aided group when biopsies were included, while withdrawal time excluding biopsy time showed no significant difference. Conclusions AI-aided polyp detection system significantly increases lesion detection rate. In addition, lesion detection by AI is hardly affected by factors such as size, location, and shape.
C1 [Huang, Ding] Ningbo Anorectal Hosp, Med Dept, Ningbo, Zhejiang, Peoples R China.
   [Shen, Jingyi; Hong, Jiaze; Zhang, Yi; Dai, Senjie; Du, Nannan; Zhang, Mengting] Zhejiang Chinese Med Univ, Clin Med Coll 2, Hangzhou, Zhejiang, Peoples R China.
   [Guo, Daxin] Univ Chinese Acad Sci, HwaMei Hosp, Dept Gastroenterol, Northwest St 41, Ningbo 315010, Zhejiang, Peoples R China.
C3 Zhejiang Chinese Medical University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS
RP Guo, DX (通讯作者)，Univ Chinese Acad Sci, HwaMei Hosp, Dept Gastroenterol, Northwest St 41, Ningbo 315010, Zhejiang, Peoples R China.
EM hhddd_1985@163.com; shenjingyi202102@126.com; 1653384834@qq.com;
   570497847@qq.com; 1944348479@qq.com; 2097815997@qq.com;
   1353392430@qq.com; airgzn666@163.com
RI Guo, Daxin/GPG-0754-2022
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Aziz M, 2020, DIGEST DIS SCI, V65, P1586, DOI 10.1007/s10620-019-05997-6
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Click B, 2018, JAMA-J AM MED ASSOC, V319, P2021, DOI 10.1001/jama.2018.5809
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deliwala SS, 2021, INT J COLORECTAL DIS, V36, P2291, DOI 10.1007/s00384-021-03929-3
   Fletcher RH, 2017, ANN INTERN MED, V167, pJC65, DOI 10.7326/ACPJC-2017-167-12-065
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Higgins JPT, 2002, STAT MED, V21, P1539, DOI 10.1002/sim.1186
   Higgins Julian P T, 2011, BMJ, V343, pd5928, DOI 10.1136/bmj.d5928
   Kamba S, 2021, J GASTROENTEROL, V56, P746, DOI 10.1007/s00535-021-01808-w
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kang XY, 2018, AM J GASTROENTEROL, V113, P601, DOI 10.1038/ajg.2018.25
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Leggett B, 2010, GASTROENTEROLOGY, V138, P2088, DOI 10.1053/j.gastro.2009.12.066
   Li JL, 2021, EUR J GASTROEN HEPAT, V33, P1041, DOI 10.1097/MEG.0000000000001906
   Liberati A, 2009, ANN INTERN MED, V151, pW65, DOI [10.7326/0003-4819-151-4-200908180-00136, 10.1371/journal.pmed.1000097, 10.1136/bmj.b4037, 10.1136/bmj.b2700]
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Meester RGS, 2020, LANCET GASTROENTEROL, V5, P516, DOI 10.1016/S2468-1253(20)30074-1
   Mohan BP, 2020, ECLINICALMEDICINE, V29-30, DOI 10.1016/j.eclinm.2020.100622
   Nazarian S, 2021, J MED INTERNET RES, V23, DOI 10.2196/27370
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Shaukat A, 2015, GASTROENTEROLOGY, V149, P952, DOI 10.1053/j.gastro.2015.06.044
   Shen P, 2021, J DIGEST DIS, V22, P256, DOI 10.1111/1751-2980.12985
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457
   Wu F, 2021, ANTICANCER AGENTS ME
   Xu YX, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0246892
   Zhang YC, 2021, J LAPAROENDOSC ADV S, V31, P1143, DOI 10.1089/lap.2020.0777
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
   Zippelius C, 2022, ENDOSCOPY, V54, P465, DOI 10.1055/a-1556-5984
NR 42
TC 11
Z9 11
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0179-1958
EI 1432-1262
J9 INT J COLORECTAL DIS
JI Int. J. Colorectal Dis.
PD MAR
PY 2022
VL 37
IS 3
BP 495
EP 506
DI 10.1007/s00384-021-04062-x
EA NOV 2021
PG 12
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA ZJ5DD
UT WOS:000717416700002
PM 34762157
DA 2023-08-21
ER

PT J
AU Chen, XL
   Zhang, KL
   Lin, SY
   Dai, KF
   Yun, Y
AF Chen, Xiaoling
   Zhang, Kuiling
   Lin, Shuying
   Dai, Kai Feng
   Yun, Yang
TI Single Shot Multibox Detector Automatic Polyp Detection Network Based on
   Gastrointestinal Endoscopic Images
SO COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE
LA English
DT Article
AB Purpose. In order to resolve the situation of high missed diagnosis rate and high misdiagnosis rate of the pathological analysis of the gastrointestinal endoscopic images by experts, we propose an automatic polyp detection algorithm based on Single Shot Multibox Detector (SSD). Method. In the paper, SSD is based on VGG-16, the fully connected layer is changed to a convolutional layer, and four convolutional layers with successively decreasing scales are added as a new network structure. In order to verify the practicability, it is not only compared with manual polyp detection but also with Mask R-CNN. Results. Multiple experimental results show that the mean Average Precision (m AP) of the SSD network is 95.74%, which is 12.4% higher than the manual detection and 5.7% higher than the Mask R-CNN. When detecting a single frame of image, the detection speed of SSD is 8.41 times that of manual detection. Conclusion. Based on the traditional pattern recognition algorithm and the target detection algorithm using deep learning, we select a variety of algorithms to identify and classify polyps to achieve efficient detection results. Our research demonstrates that deep learning has a lot of room for development in the field of gastrointestinal image recognition.
C1 [Chen, Xiaoling; Zhang, Kuiling] Fujian Med Univ, Dept Gastroenterol, Quanzhou Hosp 1, Quanzhou 362000, Fujian, Peoples R China.
   [Lin, Shuying] Fujian Med Univ, Dept Endoscope Room, Quanzhou Hosp 1, Quanzhou 362000, Fujian, Peoples R China.
   [Dai, Kai Feng] Fujian Med Univ, Imaging Dept, Quanzhou Hosp 1, Quanzhou 362000, Fujian, Peoples R China.
   [Yun, Yang] Joint Serv Support Force 910 Hosp, Dept Hlth Med, Quanzhou 362000, Fujian, Peoples R China.
C3 Fujian Medical University; Fujian Medical University; Fujian Medical
   University
RP Chen, XL (通讯作者)，Fujian Med Univ, Dept Gastroenterol, Quanzhou Hosp 1, Quanzhou 362000, Fujian, Peoples R China.
EM 156314270@qq.com
CR Asari KV, 1999, IEEE T MED IMAGING, V18, P345, DOI 10.1109/42.768843
   Bangalore SS, 2008, SCHIZOPHR RES, V99, P1, DOI 10.1016/j.schres.2007.11.029
   Bindu R. A., 2020, COMPUTER SCI ENG, V25, P42
   Burschka D, 2005, MED IMAGE ANAL, V9, P413, DOI 10.1016/j.media.2005.05.005
   Chagas-Paula DA, 2015, PLANTA MED, V81, P450, DOI 10.1055/s-0034-1396206
   Diamantis D.E., 2019 IEEE 19 INT C B
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girshick R., IEEE COMPUTER SOC, V88, P132
   Hu Q, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540260
   Jin Hongyu, 2019, 2019 INT JOINT C INF
   Liu Y, 2018, INT SYM COMPUT INTEL, P119, DOI 10.1109/ISCID.2018.10128
   Okamoto T., 2019 2 INT S DEVICES
   Ono S, 2008, GASTROINTEST ENDOSC, V68, P624, DOI 10.1016/j.gie.2008.02.066
   Reghukumar A., INT J UNCERTAIN FUZZ, V25, P2021
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi J., 2019, CHINESE J SCI INSTRU, V11, P40
   Shibuya T., 2014, JUNTENDO MED J, V60, P94
   Srivastava S, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00434-w
   Tang ZH, 2021, RENEW ENERG, V173, P1005, DOI 10.1016/j.renene.2021.04.041
   Wang D, 2018, COMPUT ELECTRON AGR, V154, P443, DOI 10.1016/j.compag.2018.09.030
   Wang P., 2001 C P 23 ANN INT
   Wang Y, 2019, 2019 INT C ART INT A
   Xu BB, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105300
   Yong Y., 2011, J MILITARY SURG SW C, V56, P45
   Zhang D., 2021, NEURAL COMPUT APPL, V1, P128
   Zhao Q. Y., 2014, J LANZHOU U MEDICAL, V1, P42
   Zheng J., IGARSS 2019 IEEE INT
   Zheng W., 2019, CLIN TRANSL GASTROEN, V10, P157
NR 28
TC 3
Z9 3
U1 0
U2 3
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1748-670X
EI 1748-6718
J9 COMPUT MATH METHOD M
JI Comput. Math. Method Med.
PD NOV 5
PY 2021
VL 2021
AR 2144472
DI 10.1155/2021/2144472
PG 6
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA 2T7SD
UT WOS:000822668700002
PM 34777559
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Goyal, H
   Sherazi, SAA
   Mann, R
   Gandhi, Z
   Perisetti, A
   Aziz, M
   Chandan, S
   Kopel, J
   Tharian, B
   Sharma, N
   Thosani, N
AF Goyal, Hemant
   Sherazi, Syed A. A.
   Mann, Rupinder
   Gandhi, Zainab
   Perisetti, Abhilash
   Aziz, Muhammad
   Chandan, Saurabh
   Kopel, Jonathan
   Tharian, Benjamin
   Sharma, Neil
   Thosani, Nirav
TI Scope of Artificial Intelligence in Gastrointestinal Oncology
SO CANCERS
LA English
DT Review
DE artificial intelligence; colorectal cancer; gastrointestinal cancer;
   hepatocellular cancer; pancreaticobiliary cancer; gastric cancer;
   esophageal cancer
ID COMPUTER-AIDED DIAGNOSIS; CONVOLUTIONAL NEURAL-NETWORK;
   HELICOBACTER-PYLORI INFECTION; SQUAMOUS-CELL CARCINOMA; NARROW-BAND;
   COLORECTAL-CANCER; GASTRIC-CANCER; DIFFERENTIAL-DIAGNOSIS; BARRETTS
   NEOPLASIA; PANCREATIC-CANCER
AB Simple Summary: Gastrointestinal cancers cause over 2.8 million deaths annually worldwide. Currently, the diagnosis of various gastrointestinal cancer mainly relies on manual interpretation of radiographic images by radiologists and various endoscopic images by endoscopists. Artificial intelligence (AI) may be useful in screening, diagnosing, and treating various cancers by accurately analyzing diagnostic clinical images, identifying therapeutic targets, and processing large datasets. The use of AI in endoscopic procedures is a significant breakthrough in modern medicine. Although the diagnostic accuracy of AI systems has markedly increased, it still needs collaboration with physicians. In the near future, AI-assisted systems will become a vital tool for the management of these cancer patients.Gastrointestinal cancers are among the leading causes of death worldwide, with over 2.8 million deaths annually. Over the last few decades, advancements in artificial intelligence technologies have led to their application in medicine. The use of artificial intelligence in endoscopic procedures is a significant breakthrough in modern medicine. Currently, the diagnosis of various gastrointestinal cancer relies on the manual interpretation of radiographic images by radiologists and various endoscopic images by endoscopists. This can lead to diagnostic variabilities as it requires concentration and clinical experience in the field. Artificial intelligence using machine or deep learning algorithms can provide automatic and accurate image analysis and thus assist in diagnosis. In the field of gastroenterology, the application of artificial intelligence can be vast from diagnosis, predicting tumor histology, polyp characterization, metastatic potential, prognosis, and treatment response. It can also provide accurate prediction models to determine the need for intervention with computer-aided diagnosis. The number of research studies on artificial intelligence in gastrointestinal cancer has been increasing rapidly over the last decade due to immense interest in the field. This review aims to review the impact, limitations, and future potentials of artificial intelligence in screening, diagnosis, tumor staging, treatment modalities, and prediction models for the prognosis of various gastrointestinal cancers.
C1 [Goyal, Hemant] Wright Ctr Grad Med Educ, Dept Internal Med, 501 S Washington Ave, Scranton, PA 18505 USA.
   [Sherazi, Syed A. A.] John H Stroger Jr Hosp Cook Cty, Dept Med, 1950 W Polk St, Chicago, IL 60612 USA.
   [Mann, Rupinder] St Agnes Med Ctr, Dept Med, 1303 E Herndon Ave, Fresno, CA 93720 USA.
   [Gandhi, Zainab] Geisinger Wyoming Valley Med Ctr, Dept Med, 1000 E Mt Dr, Wilkes Barre, PA 18711 USA.
   [Perisetti, Abhilash; Sharma, Neil] Parkview Canc Inst, Div Intervent Oncol & Surg Endoscopy IOSE, 11050 Parkview Circle, Ft Wayne, IN 46845 USA.
   [Aziz, Muhammad] Univ Toledo, Med Ctr, Dept Gastroenterol & Hepatol, 3000 Arlington Ave, Toledo, OH 43614 USA.
   [Chandan, Saurabh] Creighton Univ, Med Ctr, CHI Hlth, Div Gastroenterol & Hepatol, 7500 Mercy Rd, Omaha, NE 68124 USA.
   [Kopel, Jonathan] Texas Tech Univ, Hlth Sci Ctr, Dept Med, 3601 4th St, Lubbock, TX 79430 USA.
   [Tharian, Benjamin] Univ Arkansas Med Sci, Dept Gastroenterol & Hepatol, 4301 W Markham St, Little Rock, AR 72205 USA.
   [Thosani, Nirav] UTHealth, McGovern Med Sch, Div Gastroenterol Hepatol & Nutr, 6410 Fannin St 1014, Houston, TX 77030 USA.
C3 John H Stroger Junior Hospital Cook County; University of Illinois
   System; University of Illinois Chicago; University of Illinois Chicago
   Hospital; University System of Ohio; University of Toledo; Creighton
   University; Texas Tech University System; Texas Tech University Health
   Science Center; University of Arkansas System; University of Arkansas
   Medical Sciences; University of Texas System; University of Texas Health
   Science Center Houston
RP Goyal, H (通讯作者)，Wright Ctr Grad Med Educ, Dept Internal Med, 501 S Washington Ave, Scranton, PA 18505 USA.
EM doc.hemant@yahoo.com; syedaliamir.sherazi@cookcountyhhs.org;
   rupindrmann@yahoo.com; drzainabgandhi@gmail.com;
   abhilash.perisetti@gmail.com; marajani@hotmail.com;
   saurabhchandan@gmail.com; jonathan.kopel@ttuhsc.edu; btharian@uams.edu;
   neil.sharma@parkview.com; nirav.thosani@uth.tmc.edu
RI Perisetti, Abhilash/ISU-8946-2023; Goyal, Hemant/E-3153-2012; Perisetti,
   Abhilash/L-2619-2019
OI Goyal, Hemant/0000-0002-9433-9042; Gandhi, Zainab/0000-0002-7214-4981;
   Kopel, Jonathan/0000-0001-5934-2695; Perisetti,
   Abhilash/0000-0003-4074-6395; Chandan, Saurabh/0000-0002-2661-6693;
   Aziz, Muhammad/0000-0001-5620-8597
CR Ali H, 2018, COMPUT METH PROG BIO, V157, P39, DOI 10.1016/j.cmpb.2018.01.013
   [Anonymous], SURV EP END RES SEER
   Bang CS, 2021, GASTROINTEST ENDOSC, V93, P1006, DOI 10.1016/j.gie.2020.11.025
   Bang CS, 2020, J MED INTERNET RES, V22, DOI 10.2196/21983
   Bharti P, 2018, ULTRASONIC IMAGING, V40, P357, DOI 10.1177/0161734618787447
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Cao SE, 2020, WORLD J GASTROENTERO, V26, P3660, DOI 10.3748/wjg.v26.i25.3660
   Cho BJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061858
   Chu LC, 2019, AM J ROENTGENOL, V213, P349, DOI 10.2214/AJR.18.20901
   Colom Roberto, 2010, Dialogues Clin Neurosci, V12, P489
   Corral JE, 2019, PANCREAS, V48, P805, DOI 10.1097/MPA.0000000000001327
   de Groof AJ, 2020, GASTROINTEST ENDOSC, V91, P1242, DOI 10.1016/j.gie.2019.12.048
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   Deo RC, 2015, CIRCULATION, V132, P1920, DOI 10.1161/CIRCULATIONAHA.115.001593
   Ebigbo A, 2021, ENDOSCOPY, V53, P878, DOI 10.1055/a-1311-8570
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   Enzinger PC, 2003, NEW ENGL J MED, V349, P2241, DOI 10.1056/NEJMra035010
   Everson M, 2019, UNITED EUR GASTROENT, V7, P297, DOI 10.1177/2050640618821800
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Goggins M, 2005, J CLIN ONCOL, V23, P4524, DOI 10.1200/JCO.2005.19.711
   Goodwin CS, 1997, CLIN INFECT DIS, V25, P1017, DOI 10.1086/516077
   Guimaraes P, 2020, GUT, V69, P4, DOI 10.1136/gutjnl-2019-319347
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   Hamm CA, 2019, EUR RADIOL, V29, P3338, DOI 10.1007/s00330-019-06205-9
   Hashimoto R, 2020, GASTROINTEST ENDOSC, V91, P1264, DOI 10.1016/j.gie.2019.12.049
   He YS, 2019, J DIGEST DIS, V20, P623, DOI 10.1111/1751-2980.12827
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Horiuchi Y, 2020, DIGEST DIS SCI, V65, P1355, DOI 10.1007/s10620-019-05862-6
   Horiuchi Y, 2020, GASTROINTEST ENDOSC, V92, P856, DOI 10.1016/j.gie.2020.04.079
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Huynh JC, 2020, CANCERS, V12, DOI 10.3390/cancers12051168
   Ichimasa Katsuro, 2018, Endoscopy, V50, pC2, DOI 10.1055/s-0044-100290
   Iizuka O, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58467-9
   Institute NC. Surveillance Epidemiology and End Results (SEER) database, SURV EP END RES SEER
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Japanese Gastr Canc Assoc, 2021, GASTRIC CANCER, V24, P1, DOI 10.1007/s10120-020-01042-y
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Joo M, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20246276
   Jiang KL, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.629080
   Kaissis GA, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030724
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kondo H, 2001, GASTROINTEST ENDOSC, V53, P199, DOI 10.1067/mge.2001.110730
   Kudo S, 2021, GASTROENTEROLOGY, V160, P1075, DOI 10.1053/j.gastro.2020.09.027
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kuntz S, 2021, EUR J CANCER, V155, P200, DOI 10.1016/j.ejca.2021.07.012
   Kuraoka K, 2009, HEPATO-GASTROENTEROL, V56, P63
   Kuwahara T, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000045
   Kuwano H, 2015, ESOPHAGUS-TOKYO, V12, P1, DOI 10.1007/s10388-014-0465-1
   Lai LL, 2021, J BIOMED OPT, V26, DOI 10.1117/1.JBO.26.1.015001
   Laiz P, 2020, COMPUT MED IMAG GRAP, V86, DOI 10.1016/j.compmedimag.2020.101794
   Laoveeravat P., 2021, ARTIF INTELL GASTROE, V2, P56, DOI [10.35712/aig.v2.i2.56, DOI 10.35712/AIG.V2.I2.56]
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Lech G, 2016, WORLD J GASTROENTERO, V22, P1745, DOI 10.3748/wjg.v22.i5.1745
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee WL, 2013, APPL SOFT COMPUT, V13, P3683, DOI 10.1016/j.asoc.2013.03.009
   Li B, 2021, WORLD J GASTROENTERO, V27, P281, DOI 10.3748/wjg.v27.i3.281
   Li HW, 2019, IEEE ENG MED BIO, P2095, DOI 10.1109/EMBC.2019.8856745
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Li SQ, 2018, COMPUT METH PROG BIO, V165, P205, DOI 10.1016/j.cmpb.2018.09.001
   Lippi G, 2020, ARCH MED SCI, V16, P820, DOI 10.5114/aoms.2020.94845
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Liu SL, 2019, CHINESE MED J-PEKING, V132, P2795, DOI 10.1097/CM9.0000000000000544
   Liu XQ, 2018, IEEE IMAGE PROC, P1388, DOI 10.1109/ICIP.2018.8451067
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Macha MA, 2014, CURR PHARM DESIGN, V20, P5287, DOI 10.2174/1381612820666140128213117
   Marya NB, 2021, GUT, V70, P1335, DOI 10.1136/gutjnl-2020-322821
   Mendel R., 2017, BARRETTS ESOPHAGUS A
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mitsala A, 2021, CURR ONCOL, V28, P1581, DOI 10.3390/curroncol28030149
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Momeni-Boroujeni A, 2017, CANCER CYTOPATHOL, V125, P926, DOI 10.1002/cncy.21915
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nagami Y, 2014, AM J GASTROENTEROL, V109, P845, DOI 10.1038/ajg.2014.94
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Nakajima Y, 2020, ENDOSC INT OPEN, V08, pE1341, DOI 10.1055/a-1220-6596
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Naveed M, 2018, CURR ONCOL REP, V20, DOI 10.1007/s11912-018-0713-y
   Nazarian S, 2021, J MED INTERNET RES, V23, DOI 10.2196/27370
   Oestmann PM, 2021, EUR RADIOL, V31, P4981, DOI 10.1007/s00330-020-07559-1
   Ohmori M, 2020, GASTROINTEST ENDOSC, V91, P301, DOI 10.1016/j.gie.2019.09.034
   Otsuji E, 2020, ARTIF INTELL GASTROE, V1, P71, DOI [10.35712/aig.v1.i4.71, DOI 10.35712/AIG.V1.I4.71]
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Ozkan M, 2016, ENDOSC ULTRASOUND, V5, P101, DOI 10.4103/2303-9027.180473
   Pannala Rahul, 2020, VideoGIE, V5, P598, DOI 10.1016/j.vgie.2020.08.013
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Qu J, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8961781
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   Que SJ, 2019, WORLD J GASTROENTERO, V25, P6451, DOI 10.3748/wjg.v25.i43.6451
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Robertson AR, 2021, THER ADV GASTROINTES, V14, DOI 10.1177/26317745211020277
   Ruffle JK, 2019, AM J GASTROENTEROL, V114, P422, DOI 10.1038/s41395-018-0268-4
   Russell SJ, 2021, ARTIF INTELL, V4th
   Saftoiu A, 2008, GASTROINTEST ENDOSC, V68, P1086, DOI 10.1016/j.gie.2008.04.031
   Saftoiu A, 2015, GASTROINTEST ENDOSC, V82, P59, DOI 10.1016/j.gie.2014.11.040
   Saftoiu A, 2012, CLIN GASTROENTEROL H, V10, P84, DOI 10.1016/j.cgh.2011.09.014
   Savareh BA, 2020, PANCREATOLOGY, V20, P1195, DOI 10.1016/j.pan.2020.07.399
   Schmauch B, 2019, DIAGN INTERV IMAG, V100, P227, DOI 10.1016/j.diii.2019.02.009
   Shalev-Shwartz S., 2014, UNDERSTANDING MACHIN
   Sharma H, 2017, COMPUT MED IMAG GRAP, V61, P2, DOI 10.1016/j.compmedimag.2017.06.001
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin D, 2015, CLIN GASTROENTEROL H, V13, P272, DOI 10.1016/j.cgh.2014.07.030
   Shiroma S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87405-6
   Sinkala M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58290-2
   Struyvenberg MR, 2020, DIS ESOPHAGUS, V33, DOI 10.1093/dote/doz065
   Suzuki H, 2021, DIGEST ENDOSC, V33, P254, DOI 10.1111/den.13897
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Tokai Y, 2020, ESOPHAGUS-TOKYO, V17, P250, DOI 10.1007/s10388-020-00716-x
   Tonozuka R, 2021, J HEPATO-BIL-PAN SCI, V28, P95, DOI 10.1002/jhbp.825
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Virmani J, 2013, J DIGIT IMAGING, V26, P530, DOI 10.1007/s10278-012-9537-8
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wei R, 2019, TECHNOL CANCER RES T, V18, DOI 10.1177/1533033818824339
   Wu CC, 2012, EXPERT SYST APPL, V39, P9389, DOI 10.1016/j.eswa.2012.02.128
   Wu LL, 2021, ENDOSCOPY, V53, P1199, DOI 10.1055/a-1350-5583
   Xia J, 2021, GASTROINTEST ENDOSC, V93, P133, DOI 10.1016/j.gie.2020.05.027
   Yan QL, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00379
   Yang XX, 2021, DIGEST ENDOSC, V33, P1075, DOI 10.1111/den.13908
   Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706
   Yasuda T, 2020, DIGEST ENDOSC, V32, P373, DOI 10.1111/den.13509
   Yu CR, 2021, ANN TRANSL MED, V9, DOI 10.21037/atm-20-6337
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang MM, 2010, GASTROINTEST ENDOSC, V72, P978, DOI 10.1016/j.gie.2010.06.042
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zheng WF, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000109
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 138
TC 4
Z9 4
U1 9
U2 29
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-6694
J9 CANCERS
JI Cancers
PD NOV
PY 2021
VL 13
IS 21
AR 5494
DI 10.3390/cancers13215494
PG 23
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA WY3QL
UT WOS:000719194900001
PM 34771658
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Hann, A
   Meining, A
AF Hann, Alexander
   Meining, Alexander
TI Artificial Intelligence in Endoscopy
SO VISCERAL MEDICINE
LA English
DT Review; Early Access
DE Artificial intelligence; Deep learning; Endoscopy
ID COMPUTER-AIDED DETECTION; COLORECTAL-CANCER; ADENOMA DETECTION;
   GASTROINTESTINAL ENDOSCOPY; PERFORMANCE-MEASURES; EUROPEAN-SOCIETY;
   COLONOSCOPY; TIME; POLYPS; SYSTEM
AB Background: Owing to their rapid development, artificial intelligence (AI) technologies offer a great promise for gastroenterology practice and research. At present, AI-guided image interpretation has already been used with success for endoscopic detection of early malignant lesions. Nonetheless, there are complex challenges and possible shortcomings that must be considered before full implementation can be realized. Summary: In this review, the current status of AI in endoscopy is summarized. Future perspectives and open questions for further studies are stressed. Key Messages: The usage of AI algorithms for polyp detection in screening colonoscopy results in a significant increase in the adenoma detection rate, mainly attributed to the identification of diminutive polyps. Computer-aided characterization of colorectal polyps accompanies the detection, but further studies are needed to evaluate the clinical benefit. In contrast to colonoscopy, usage of AI in gastroscopy is currently rather limited. Regarding other fields of endoscopic imaging, capsule endoscopy is the ideal imaging platform for AI, due to the potential of saving time in the video analysis. </p>
C1 [Hann, Alexander; Meining, Alexander] Univ Hosp Wurzburg, Dept Internal Med 2, Intervent & Expt Endoscopy InExEn, Gastroenterol, Wurzburg, Germany.
C3 University of Wurzburg
RP Meining, A (通讯作者)，Univ Hosp Wurzburg, Dept Internal Med 2, Intervent & Expt Endoscopy InExEn, Gastroenterol, Wurzburg, Germany.
EM meining_a@ukw.de
OI Hann, Alexander/0000-0001-8035-3559
FU state government of Baden-Wurttemberg, Germany
FX The author AH receives public funding from the state government of
   Baden-Wurttemberg, Germany (Funding cluster Forum Gesundheitsstandort
   Baden-Wurttemberg) to research and develop artificial intelligence
   applications for polyp detection in screening colonoscopy. The sponsor
   had no influence on drafting the manuscript.
CR Allwood G, 2019, IEEE REV BIOMED ENG, V12, P240, DOI 10.1109/RBME.2018.2874037
   Aoki T, 2020, J GASTROEN HEPATOL, V35, P1196, DOI 10.1111/jgh.14941
   Arribas J, 2021, GUT, V70, P1458, DOI 10.1136/gutjnl-2020-321922
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Bateman AC, 2015, J CLIN PATHOL, V68, P585, DOI 10.1136/jclinpath-2015-203016
   Bisschops R, 2016, ENDOSCOPY, V48, P843, DOI 10.1055/s-0042-113128
   Brenner H, 2017, GASTROINTEST ENDOSC, V85, P1177, DOI 10.1016/j.gie.2017.02.004
   Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Click B, 2018, JAMA-J AM MED ASSOC, V319, P2021, DOI 10.1001/jama.2018.5809
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   Deliwala SS, 2021, INT J COLORECTAL DIS, V36, P2291, DOI 10.1007/s00384-021-03929-3
   dos Santos CEO, 2018, EUR J GASTROEN HEPAT, V30, P1514, DOI 10.1097/MEG.0000000000001278
   Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   Farris AB, 2008, AM J SURG PATHOL, V32, P30, DOI 10.1097/PAS.0b013e318093e40a
   Freedman D, 2020, IEEE T MED IMAGING, V39, P3451, DOI 10.1109/TMI.2020.2994221
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hackner R, 2021, BILDVERARBEITUNG MED, P298
   Hassan C, 2019, ENDOSCOPY, V51, P775, DOI 10.1055/a-0959-0505
   Huang L, 2021, ENDOSCOPY, V53, P491, DOI 10.1055/a-1244-5698
   Kaminski MF, 2020, GASTROENTEROLOGY, V158, P404, DOI 10.1053/j.gastro.2019.11.026
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Li RM, 2019, JMIR MED INF, V7, DOI 10.2196/10788
   Liu PX, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820979165
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Minoda Y, 2020, J GASTROENTEROL, V55, P1119, DOI 10.1007/s00535-020-01725-4
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Ni XY, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2026610118
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Roelandt P, 2019, ENDOSCOPY, V51, P237, DOI 10.1055/a-0755-7471
   Sabater A, 2020, IEEE INT C INT ROBOT, P10536, DOI 10.1109/IROS45743.2020.9341600
   Shichijo S, 2019, SCAND J GASTROENTERO, V54, P158, DOI 10.1080/00365521.2019.1577486
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tonozuka R, 2021, J HEPATO-BIL-PAN SCI, V28, P95, DOI 10.1002/jhbp.825
   Wang CC, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18052428
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang WH, 2018, INT J COLORECTAL DIS, V33, P561, DOI 10.1007/s00384-018-3003-0
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Zhang J, 2020, GASTROINTEST ENDOSC, V92, P874, DOI 10.1016/j.gie.2020.04.071
   Zhou J, 2020, GASTROINTEST ENDOSC, V91, P428, DOI 10.1016/j.gie.2019.11.026
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 48
TC 4
Z9 4
U1 4
U2 25
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 2297-4725
EI 2297-475X
J9 VISC MED
JI Visc. Med.
PD 2021 NOV 1
PY 2021
DI 10.1159/000519407
EA NOV 2021
PG 5
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA WU2YZ
UT WOS:000716417200001
PM 35083312
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Kroner, PT
   Engels, MM
   Glicksberg, BS
   Johnson, KW
   Mzaik, O
   van Hooft, JE
   Wallace, MB
   El-Serag, HB
   Krittanawong, C
AF Kroner, Paul T.
   Engels, Megan Ml
   Glicksberg, Benjamin S.
   Johnson, Kipp W.
   Mzaik, Obaie
   van Hooft, Jeanin E.
   Wallace, Michael B.
   El-Serag, Hashem B.
   Krittanawong, Chayakrit
TI Artificial intelligence in gastroenterology: A state-of-the-art review
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Artificial intelligence; Machine learning; Deep learning; Clinical
   applications; Gastroenterology
ID COMPUTER-AIDED DIAGNOSIS; CAPSULE ENDOSCOPY IMAGES; FATTY LIVER-DISEASE;
   CONVOLUTIONAL NEURAL-NETWORKS; PANCREATIC DUCTAL ADENOCARCINOMA;
   LEARNING-BASED CLASSIFICATION; LONG-TERM SURVIVAL; NARROW-BAND;
   COLORECTAL-CANCER; DIFFERENTIAL-DIAGNOSIS
AB The development of artificial intelligence (AI) has increased dramatically in the last 20 years, with clinical applications progressively being explored for most of the medical specialties. The field of gastroenterology and hepatology, substantially reliant on vast amounts of imaging studies, is not an exception. The clinical applications of AI systems in this field include the identification of premalignant or malignant lesions (e.g., identification of dysplasia or esophageal adenocarcinoma in Barrett's esophagus, pancreatic malignancies), detection of lesions (e.g., polyp identification and classification, small-bowel bleeding lesion on capsule endoscopy, pancreatic cystic lesions), development of objective scoring systems for risk stratification, predicting disease prognosis or treatment response [e.g., determining survival in patients post-resection of hepatocellular carcinoma), determining which patients with inflammatory bowel disease (IBD) will benefit from biologic therapy], or evaluation of metrics such as bowel preparation score or quality of endoscopic examination. The objective of this comprehensive review is to analyze the available AI-related studies pertaining to the entirety of the gastrointestinal tract, including the upper, middle and lower tracts; IBD; the hepatobiliary system; and the pancreas, discussing the findings and clinical applications, as well as outlining the current limitations and future directions in this field.
C1 [Kroner, Paul T.; Engels, Megan Ml; Mzaik, Obaie; Wallace, Michael B.] Mayo Clin, Div Gastroenterol & Hepatol, Jacksonville, FL 32224 USA.
   [Engels, Megan Ml] Amsterdam UMC, Dept Gastroenterol & Hepatol, Locat AMC, Canc Ctr Amsterdam, NL-1105 Amsterdam, Netherlands.
   [Glicksberg, Benjamin S.; Johnson, Kipp W.] Icahn Sch Med Mt Sinai, Hasso Plattner Inst Digital Hlth, New York, NY 10029 USA.
   [van Hooft, Jeanin E.] Leiden Univ, Dept Gastroenterol & Hepatol, Med Ctr, NL-2300 Amsterdam, Netherlands.
   [Wallace, Michael B.] Sheikh Shakhbout Med City, Div Gastroenterol & Hepatol, Abu Dhabi 11001, U Arab Emirates.
   [El-Serag, Hashem B.] Michael E DeBakey VA Med Ctr, Sect Gastroenterol & Hepatol, Houston, TX 77030 USA.
   [El-Serag, Hashem B.; Krittanawong, Chayakrit] Baylor Coll Med, 1 Baylor Plaza, Houston, TX 77030 USA.
   [El-Serag, Hashem B.; Krittanawong, Chayakrit] Michael E DeBakey VA Med Ctr, Sect Hlth Serv Res, 1 Baylor Plaza, Houston, TX 77030 USA.
   [Krittanawong, Chayakrit] Michael E DeBakey VA Med Ctr, Sect Cardiol, Houston, TX 77030 USA.
C3 Mayo Clinic; Icahn School of Medicine at Mount Sinai; Leiden University;
   Leiden University - Excl LUMC; Baylor College of Medicine; Baylor
   College of Medicine; Baylor College of Medicine; Baylor College of
   Medicine
RP Krittanawong, C (通讯作者)，Baylor Coll Med, 1 Baylor Plaza, Houston, TX 77030 USA.; Krittanawong, C (通讯作者)，Michael E DeBakey VA Med Ctr, Sect Hlth Serv Res, 1 Baylor Plaza, Houston, TX 77030 USA.
EM chayakrit.krittanawong@bcm.edu
RI van hooft, Jeanin/AAT-3600-2020; Wallace, Michael/GZL-9731-2022;
   Glicksberg, Benjamin/I-9500-2019
OI van hooft, Jeanin/0000-0002-4424-0079; Wallace,
   Michael/0000-0002-6446-5785; Glicksberg, Benjamin/0000-0003-4515-8090
CR Abajian A, 2018, J VASC INTERV RADIOL, V29, P850, DOI 10.1016/j.jvir.2018.01.769
   Abd El-Salam Shimaa M., 2019, Informatics in Medicine Unlocked, V17, P213, DOI 10.1016/j.imu.2019.100267
   Ahmed Y, 2020, NMR BIOMED, V33, DOI 10.1002/nbm.4215
   Ahn JC, 2021, HEPATOLOGY, V73, P2546, DOI 10.1002/hep.31603
   Ai HX, 2018, TOXICOL SCI, V165, P100, DOI 10.1093/toxsci/kfy121
   Al-Haddad MA, 2010, HPB, V12, P688, DOI 10.1111/j.1477-2574.2010.00235.x
   Morita FHA, 2017, BMC CANCER, V17, DOI 10.1186/s12885-016-3011-9
   Andersson B, 2011, PANCREATOLOGY, V11, P328, DOI 10.1159/000327903
   Andres A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193523
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Aoki T, 2020, DIGEST ENDOSC, V32, P585, DOI 10.1111/den.13517
   Aoki T, 2020, J GASTROEN HEPATOL, V35, P1196, DOI 10.1111/jgh.14941
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Ayaru L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132485
   Banerjee Imon, 2018, AMIA Annu Symp Proc, V2018, P215
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bertsimas D, 2019, AM J TRANSPLANT, V19, P1109, DOI 10.1111/ajt.15172
   Bhat V, 2018, MAYO CLIN PROC, V93, P1794, DOI 10.1016/j.mayocp.2018.06.020
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Blyuss O, 2020, BRIT J CANCER, V122, P692, DOI 10.1038/s41416-019-0694-0
   Borg-Bartolo Simon P, 2020, F1000Res, V9, DOI 10.12688/f1000research.20928.1
   Bossuyt P, 2020, GUT, V69, P788, DOI 10.1136/gutjnl-2019-318235
   Bressler B, 2007, GASTROENTEROLOGY, V132, P96, DOI 10.1053/j.gastro.2006.10.027
   Briceno J, 2014, J HEPATOL, V61, P1020, DOI 10.1016/j.jhep.2014.05.039
   Byra M, 2018, INT J COMPUT ASS RAD, V13, P1895, DOI 10.1007/s11548-018-1843-2
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Calderaro J, 2021, GUT, V70, P1183, DOI 10.1136/gutjnl-2020-322880
   Canbay A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214436
   Chakraborty J, 2018, MED PHYS, V45, P5019, DOI 10.1002/mp.13159
   Chang EK, 2016, J CLIN GASTROENTEROL, V50, P889, DOI 10.1097/MCG.0000000000000583
   Charisis VS, 2016, WORLD J GASTROENTERO, V22, P8641, DOI 10.3748/wjg.v22.i39.8641
   Chaudhary Kumardeep, 2018, Clin Cancer Res, V24, P1248, DOI 10.1158/1078-0432.CCR-17-0853
   Chen HH, 2013, INT CONF BIOMED, P116, DOI 10.1109/BMEI.2013.6746918
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chen T, 2019, BMC GENOMICS, V20, DOI 10.1186/s12864-019-6135-x
   Chen T, 2020, COMPUT METH PROG BIO, V185, DOI [10.1016/j.cmph.2019.105118, 10.1016/j.cmpb.2019.105118]
   Chen Y, 2017, COMPUT BIOL MED, V89, P18, DOI 10.1016/j.compbiomed.2017.07.012
   Choi KJ, 2018, RADIOLOGY, V289, P688, DOI 10.1148/radiol.2018180763
   Chu LC, 2019, AM J ROENTGENOL, V213, P349, DOI 10.2214/AJR.18.20901
   Corral JE, 2019, PANCREAS, V48, P805, DOI 10.1097/MPA.0000000000001327
   Cui EM, 2021, ABDOM RADIOL, V46, P3866, DOI 10.1007/s00261-021-03051-6
   Das A, 2003, LANCET, V362, P1261, DOI 10.1016/S0140-6736(03)14568-0
   Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036
   Das A, 2008, GASTROENTEROLOGY, V134, P65, DOI 10.1053/j.gastro.2007.10.037
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   de Groof J, 2019, UNITED EUR GASTROENT, V7, P538, DOI 10.1177/2050640619837443
   Deo RC, 2015, CIRCULATION, V132, P1920, DOI 10.1161/CIRCULATIONAHA.115.001593
   Dickerson LK, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0179-9
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Dmitriev Konstantin, 2017, Med Image Comput Comput Assist Interv, V10435, P150, DOI 10.1007/978-3-319-66179-7_18
   Docherty M, 2021, J AM MED INFORM ASSN, V28, P1235, DOI 10.1093/jamia/ocab003
   Doherty MK, 2018, MBIO, V9, DOI [10.1128/mBio.02120-17, 10.1128/mbio.02120-17]
   Ayllon MD, 2018, LIVER TRANSPLANT, V24, P192, DOI 10.1002/lt.24870
   Dong TS, 2019, CLIN GASTROENTEROL H, V17, P1894, DOI 10.1016/j.cgh.2019.01.025
   Douglas GM, 2018, MICROBIOME, V6, DOI 10.1186/s40168-018-0398-3
   Eaton JE, 2020, HEPATOLOGY, V71, P214, DOI 10.1002/hep.30085
   Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   Echle A, 2020, GASTROENTEROLOGY, V159, P1406, DOI 10.1053/j.gastro.2020.06.021
   Facciorusso A, 2019, PANCREATOLOGY, V19, P866, DOI 10.1016/j.pan.2019.07.038
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fei Y, 2017, J THROMB HAEMOST, V15, P439, DOI 10.1111/jth.13588
   Fei Y, 2019, HPB, V21, P891, DOI 10.1016/j.hpb.2018.11.009
   Fei Y, 2018, PANCREATOLOGY, V18, P892, DOI 10.1016/j.pan.2018.09.007
   Fenwick A, 2012, PUBLIC HEALTH, V126, P233, DOI 10.1016/j.puhe.2011.11.015
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Fialoke Suruchi, 2018, AMIA Annu Symp Proc, V2018, P430
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Firouzi F, 2007, EUR J GASTROEN HEPAT, V19, P1075, DOI 10.1097/MEG.0b013e3282202bb8
   Forlano R, 2020, CLIN GASTROENTEROL H, V18, P2081, DOI 10.1016/j.cgh.2019.12.025
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Fukuda H, 2020, GASTROINTEST ENDOSC, V92, P848, DOI 10.1016/j.gie.2020.05.043
   Gao X, 2020, DIAGN INTERV IMAG, V101, P91, DOI 10.1016/j.diii.2019.07.002
   Gao X, 2019, INT J COMPUT ASS RAD, V14, P1981, DOI 10.1007/s11548-019-02070-5
   Gao Y, 2019, CHINESE MED J-PEKING, V132, P2804, DOI 10.1097/CM9.0000000000000532
   Garcia MS, 2019, IEEE ENG MED BIO, P1371, DOI 10.1109/EMBC.2019.8857239
   Garcia-Carretero R, 2019, METAB SYNDR RELAT D, V17, P444, DOI 10.1089/met.2019.0052
   Gatos I, 2019, MED PHYS, V46, P2298, DOI 10.1002/mp.13521
   Gatos I, 2017, ULTRASOUND MED BIOL, V43, P1797, DOI 10.1016/j.ultrasmedbio.2017.05.002
   Gatos I, 2016, MED PHYS, V43, P1428, DOI 10.1118/1.4942383
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gorris M, 2021, DIGEST ENDOSC, V33, P231, DOI 10.1111/den.13875
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Guimaraes P, 2020, GUT, V69, P4, DOI 10.1136/gutjnl-2019-319347
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   Hamm CA, 2019, EUR RADIOL, V29, P3338, DOI 10.1007/s00330-019-06205-9
   Hashimoto R, 2020, GASTROINTEST ENDOSC, V91, P1264, DOI 10.1016/j.gie.2019.12.049
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hayward J, 2010, ARTIF INTELL MED, V49, P187, DOI 10.1016/j.artmed.2010.04.009
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He LL, 2019, AM J ROENTGENOL, V213, P592, DOI 10.2214/AJR.19.21082
   Heinemann F, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54904-6
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hong WD, 2013, CLINICS, V68, P27, DOI 10.6061/clinics/2013(01)RC01
   Hong WD, 2011, HEPAT MON, V11, P544
   Hoogenboom SA, 2020, TECH INNOVAT GASTROI, V22, P42, DOI 10.1016/j.tgie.2019.150634
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Hou JK, 2013, DIGEST DIS SCI, V58, P936, DOI 10.1007/s10620-012-2433-8
   Huang HJ, 2007, HEPATOLOGY, V46, P297, DOI 10.1002/hep.21695
   Iacucci M, 2019, GUT, V68, P562, DOI 10.1136/gutjnl-2017-315235
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Ibragimov B, 2018, MED PHYS, V45, P4763, DOI 10.1002/mp.13122
   Ikehara H, 2010, J GASTROEN HEPATOL, V25, P905, DOI 10.1111/j.1440-1746.2010.06275.x
   Isakov O, 2017, INFLAMM BOWEL DIS, V23, P1516, DOI 10.1097/MIB.0000000000001222
   Ishioka M, 2019, DIGEST ENDOSC, V31, pe34, DOI 10.1111/den.13306
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Jagric T, 2010, DIGEST DIS SCI, V55, P3252, DOI 10.1007/s10620-010-1155-z
   Jiang YM, 2018, CLIN CANCER RES, V24, P5574, DOI 10.1158/1078-0432.CCR-18-0848
   Jovanovic P, 2014, GASTROINTEST ENDOSC, V80, P260, DOI 10.1016/j.gie.2014.01.023
   Jover R, 2013, GASTROINTEST ENDOSC, V77, P381, DOI 10.1016/j.gie.2012.09.027
   Kaissis G, 2019, EUR RADIOL EXP, V3, DOI 10.1186/s41747-019-0119-0
   Kaissis G, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0218642
   Kaissis GA, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030724
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kanwal F, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.23780
   Kather JN, 2020, NAT REV GASTRO HEPAT, V17, P591, DOI 10.1038/s41575-020-0343-3
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Kazemi A, 2019, EXP CLIN TRANSPLANT, V17, P775, DOI 10.6002/ect.2018.0170
   Keogan MT, 2002, ACAD RADIOL, V9, P410, DOI 10.1016/S1076-6332(03)80186-1
   Khan S, 2018, PHOTODIAGN PHOTODYN, V23, P89, DOI 10.1016/j.pdpdt.2018.05.010
   Khorasani HM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70583-0
   Kim DW, 2021, EUR RADIOL, V31, P7047, DOI 10.1007/s00330-021-07803-2
   Kim JW, 2004, HEPATOLOGY, V39, P518, DOI 10.1002/hep.20053
   Kimura-Tsuchiya R, 2017, GASTROENT RES PRACT, V2017, DOI 10.1155/2017/8303046
   Kitajima K, 2004, J GASTROENTEROL, V39, P534, DOI 10.1007/s00535-004-1339-4
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Konerman MA, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0208141
   Konerman MA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187344
   Konerman MA, 2015, HEPATOLOGY, V61, P1832, DOI 10.1002/hep.27750
   Korhani Kangi Azam, 2018, Asian Pac J Cancer Prev, V19, P487
   Krittanawong C, 2019, EUR HEART J, V40, P2058, DOI 10.1093/eurheartj/ehz056
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Kuppili V, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0797-1
   Kurita Y, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43314-3
   Kuwahara T, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000045
   Lara J, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-S8-S5
   Lau L, 2017, TRANSPLANTATION, V101, pE125, DOI 10.1097/TP.0000000000001600
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee HC, 2018, J CLIN MED, V7, DOI 10.3390/jcm7110428
   Lee JH, 2020, EUR RADIOL, V30, P1264, DOI 10.1007/s00330-019-06407-1
   Leenhardt R, 2021, ENDOSCOPY, V53, P932, DOI 10.1055/a-1301-3841
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Li B, 2021, WORLD J GASTROENTERO, V27, P281, DOI 10.3748/wjg.v27.i3.281
   Li HW, 2019, IEEE ENG MED BIO, P2095, DOI 10.1109/EMBC.2019.8856745
   Li K, 2019, AM J TRANSL RES, V11, P4491
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Li SQ, 2018, COMPUT METH PROG BIO, V165, P205, DOI 10.1016/j.cmpb.2018.09.001
   Li W, 2019, EUR RADIOL, V29, P1496, DOI 10.1007/s00330-018-5680-z
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Linning E, 2020, J COMPUT ASSIST TOMO, V44, P511, DOI 10.1097/RCT.0000000000001049
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   Liu GS, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.03.24
   Liu SL, 2019, CHINESE MED J-PEKING, V132, P2795, DOI 10.1097/CM9.0000000000000544
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Liu XX, 2020, BMJ-BRIT MED J, V370, DOI 10.1136/bmj.m3164
   Liu YN, 2020, CLIN GASTROENTEROL H, V18, P2998, DOI 10.1016/j.cgh.2020.03.034
   Loftus TJ, 2017, J SURG RES, V212, P42, DOI 10.1016/j.jss.2016.12.032
   Luo HY, 2019, LANCET ONCOL, V20, P1645, DOI 10.1016/S1470-2045(19)30637-0
   Luo YJ, 2020, NEUROENDOCRINOLOGY, V110, P338, DOI 10.1159/000503291
   Lv GL, 2011, IEEE ENG MED BIO, P6643, DOI 10.1109/IEMBS.2011.6091638
   Ma H, 2018, BIOMED RES INT-UK, V2018, DOI 10.1155/2018/4304376
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Mahapatra D, 2016, COMPUT METH PROG BIO, V128, P75, DOI 10.1016/j.cmpb.2016.01.014
   Marozas M, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/6183714
   Martin DR, 2020, ARCH PATHOL LAB MED, V144, P370, DOI 10.5858/arpa.2019-0004-OA
   Marya NB, 2021, GUT, V70, P1335, DOI 10.1136/gutjnl-2020-322821
   Mashayekhi R, 2020, EUR J RADIOL, V123, DOI 10.1016/j.ejrad.2019.108778
   Matalka II, 2013, DIAGN PATHOL, V8, DOI 10.1186/1746-1596-8-156
   Matsuda T, 2011, TECH GASTROINTEST EN, V13, P24, DOI 10.1016/j.tgie.2011.01.004
   Meffert PJ, 2014, AM J GASTROENTEROL, V109, P1404, DOI 10.1038/ajg.2014.155
   Mehrabi S, 2015, STUD HEALTH TECHNOL, V216, P604, DOI 10.3233/978-1-61499-564-7-604
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Moccia S, 2018, INT J COMPUT ASS RAD, V13, P1357, DOI 10.1007/s11548-018-1787-6
   Mofidi R, 2007, SURGERY, V141, P59, DOI 10.1016/j.surg.2006.07.022
   Momeni-Boroujeni A, 2017, CANCER CYTOPATHOL, V125, P926, DOI 10.1002/cncy.21915
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Morshid A, 2019, RADIOL ARTIF INTELL, V1, DOI [10.1148/ryai.2019180021, DOI 10.1148/RYAI.2019180021]]
   Mossotto E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02606-2
   Mouri R, 2009, GASTROINTEST ENDOSC, V69, P1052, DOI 10.1016/j.gie.2008.08.032
   Mueller-Breckenridge AJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55445-8
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Nakahira H, 2020, JGH OPEN, V4, P466, DOI 10.1002/jgh3.12281
   Nakashima H, 2020, GASTRIC CANCER, V23, P1033, DOI 10.1007/s10120-020-01077-1
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Namikawa K, 2020, ENDOSCOPY, V52, P1077, DOI 10.1055/a-1194-8771
   Niehaus KE, 2015, IEEE ENG MED BIO, P7023, DOI 10.1109/EMBC.2015.7320009
   Noorbakhsh-Sabet N, 2019, AM J MED, V132, P795, DOI 10.1016/j.amjmed.2019.01.017
   Noorda R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74668-8
   Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644
   Noya F, 2017, IEEE ENG MED BIO, P3158, DOI 10.1109/EMBC.2017.8037527
   Ohmori M, 2020, GASTROINTEST ENDOSC, V91, P301, DOI 10.1016/j.gie.2019.09.034
   Okon K, 2001, ANAL CELL PATHOL, V23, P129
   Olivera P, 2019, NAT REV GASTRO HEPAT, V16, P312, DOI 10.1038/s41575-019-0102-5
   Otani K, 2020, ENDOSCOPY, V52, P786, DOI 10.1055/a-1167-8157
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Ozkan M, 2016, ENDOSC ULTRASOUND, V5, P101, DOI 10.4103/2303-9027.180473
   Pan G., 2009, Journal of Medical Engineering & Technology, V33, P575, DOI 10.1080/03091900903111974
   Pannala Rahul, 2020, VideoGIE, V5, P598, DOI 10.1016/j.vgie.2020.08.013
   Parasa S, 2020, GASTROINTEST ENDOSC, V92, P938, DOI 10.1016/j.gie.2020.04.044
   Pearce CB, 2006, PANCREATOLOGY, V6, P123, DOI 10.1159/000090032
   Perakakis N, 2019, METABOLISM, V101, DOI 10.1016/j.metabol.2019.154005
   Perveen S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20166-x
   Pimentel-Nunes P, 2016, ENDOSCOPY, V48, P723, DOI 10.1055/s-0042-108435
   Piscaglia F, 2006, EUR J GASTROEN HEPAT, V18, P1255, DOI 10.1097/01.meg.0000243885.55562.7e
   Pofahl WE, 1998, AM SURGEON, V64, P868
   Qi XL, 2019, RADIOLOGY, V290, P370, DOI 10.1148/radiol.2018180425
   Qiu Q, 2019, J DIGEST DIS, V20, P486, DOI 10.1111/1751-2980.12796
   Qiu Q, 2019, BMC GASTROENTEROL, V19, DOI 10.1186/s12876-019-1016-y
   Qiu WL, 2019, CANCER MANAG RES, V11, P9253, DOI 10.2147/CMAR.S218414
   Que SJ, 2019, WORLD J GASTROENTERO, V25, P6451, DOI 10.3748/wjg.v25.i43.6451
   Raoufy MR, 2011, J MED SYST, V35, P121, DOI 10.1007/s10916-009-9348-8
   Reddy BK, 2019, HEALTH INFORM J, V25, P1201, DOI 10.1177/1460458217751015
   Redman JS, 2017, DIGEST DIS SCI, V62, P2713, DOI 10.1007/s10620-017-4721-9
   Reichling C, 2020, GUT, V69, P681, DOI 10.1136/gutjnl-2019-319292
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Riaz F, 2013, IEEE ENG MED BIO, P3714, DOI 10.1109/EMBC.2013.6610350
   Roch AM, 2015, HPB, V17, P447, DOI 10.1111/hpb.12375
   Roth HR, 2018, MED IMAGE ANAL, V45, P94, DOI 10.1016/j.media.2018.01.006
   Saftoiu A, 2008, GASTROINTEST ENDOSC, V68, P1086, DOI 10.1016/j.gie.2008.04.031
   Saftoiu A, 2015, GASTROINTEST ENDOSC, V82, P59, DOI 10.1016/j.gie.2014.11.040
   Saftoiu A, 2012, CLIN GASTROENTEROL H, V10, P84, DOI 10.1016/j.cgh.2011.09.014
   Saillard C, 2020, HEPATOLOGY, V72, P2000, DOI 10.1002/hep.31207
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Sakai Y, 2018, IEEE ENG MED BIO, P4138, DOI 10.1109/EMBC.2018.8513274
   Samadder NJ, 2014, GASTROENTEROLOGY, V146, P950, DOI 10.1053/j.gastro.2014.01.013
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Schmauch B, 2019, DIAGN INTERV IMAG, V100, P227, DOI 10.1016/j.diii.2019.02.009
   Seo DW, 2020, J CLIN MED, V9, DOI 10.3390/jcm9082603
   Shan QY, 2019, CANCER IMAGING, V19, DOI 10.1186/s40644-019-0197-5
   Shichijo S, 2019, SCAND J GASTROENTERO, V54, P158, DOI 10.1080/00365521.2019.1577486
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shimamoto Y, 2020, J GASTROENTEROL, V55, P1037, DOI 10.1007/s00535-020-01716-5
   Shousha HI, 2018, JPN J INFECT DIS, V71, P51, DOI 10.7883/yoken.JJID.2017.089
   Shung DL, 2020, GASTROENTEROLOGY, V158, P160, DOI 10.1053/j.gastro.2019.09.009
   Singal AG, 2013, AM J GASTROENTEROL, V108, P1723, DOI 10.1038/ajg.2013.332
   Skrede OJ, 2020, LANCET, V395, P350, DOI 10.1016/S0140-6736(19)32998-8
   Soffer S, 2020, GASTROINTEST ENDOSC, V92, P831, DOI 10.1016/j.gie.2020.04.039
   Song JW, 2013, COMPUT BIOL MED, V43, P1, DOI 10.1016/j.compbiomed.2012.10.009
   Sowa JP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101444
   Sowa JP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062439
   Spann A, 2020, HEPATOLOGY, V71, P1093, DOI 10.1002/hep.31103
   Speiser JL, 2019, COMPUT METH PROG BIO, V175, P111, DOI 10.1016/j.cmpb.2019.04.012
   Speiser JL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122929
   Springer S, 2019, SCI TRANSL MED, V11, DOI 10.1126/scitranslmed.aav4772
   Stidham RW, 2020, INFLAMM BOWEL DIS, V26, P734, DOI 10.1093/ibd/izz196
   Stidham RW, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3963
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Sun CL, 2020, IEEE J BIOMED HEALTH, V24, P1643, DOI 10.1109/JBHI.2019.2949837
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Tabib NSS, 2020, GUT, V69, P1520, DOI 10.1136/gutjnl-2019-320065
   Takenaka K, 2020, GASTROENTEROLOGY, V158, P2150, DOI 10.1053/j.gastro.2020.02.012
   Tan MMC, 2021, GASTROINTEST ENDOSC, V93, P831, DOI 10.1016/j.gie.2020.07.007
   Taylor-Weiner A, 2021, HEPATOLOGY, V74, P133, DOI 10.1002/hep.31750
   Tenorio JM, 2011, INT J MED INFORM, V80, P793, DOI 10.1016/j.ijmedinf.2011.08.001
   Thakkar S, 2020, GASTROENTEROLOGY, V158, P1219, DOI 10.1053/j.gastro.2019.12.035
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Togo R, 2019, J GASTROENTEROL, V54, P321, DOI 10.1007/s00535-018-1514-7
   Tonozuka R, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11010018
   Trindade AJ, 2019, GASTROENTEROLOGY, V157, P303, DOI 10.1053/j.gastro.2019.04.048
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Ueyama H, 2021, J GASTROEN HEPATOL, V36, P482, DOI 10.1111/jgh.15190
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van den Heever M, 2014, PANCREATOLOGY, V14, P9, DOI 10.1016/j.pan.2013.11.010
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   van Doorn SC, 2015, AM J GASTROENTEROL, V110, P180, DOI 10.1038/ajg.2014.326
   Van Vleck TT, 2019, INT J MED INFORM, V129, P334, DOI 10.1016/j.ijmedinf.2019.06.028
   Vanderbeck S, 2015, HUM PATHOL, V46, P767, DOI 10.1016/j.humpath.2015.01.019
   Vanderbeck S, 2014, HUM PATHOL, V45, P785, DOI 10.1016/j.humpath.2013.11.011
   Walczak S, 2017, J GASTROINTEST SURG, V21, P1606, DOI 10.1007/s11605-017-3518-7
   Waljee AK, 2018, ALIMENT PHARM THER, V47, P763, DOI 10.1111/apt.14510
   Waljee AK, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3721
   Waljee AK, 2018, INFLAMM BOWEL DIS, V24, P45, DOI 10.1093/ibd/izx007
   Waljee AK, 2017, J CROHNS COLITIS, V11, P801, DOI 10.1093/ecco-jcc/jjx014
   Waljee AK, 2010, CLIN GASTROENTEROL H, V8, P143, DOI 10.1016/j.cgh.2009.09.031
   Wang CJ, 2019, EUR RADIOL, V29, P3348, DOI 10.1007/s00330-019-06214-8
   Wang K, 2019, GUT, V68, P729, DOI 10.1136/gutjnl-2018-316204
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang S, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab5086
   Wang SJ, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101549
   Wang TD, 2004, CLIN GASTROENTEROL H, V2, P744, DOI 10.1016/S1542-3565(04)00345-3
   Wang XL, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105236
   Wei R, 2019, TECHNOL CANCER RES T, V18, DOI 10.1177/1533033818824339
   Wei RM, 2018, EBIOMEDICINE, V35, P124, DOI 10.1016/j.ebiom.2018.07.041
   Wei Z, 2013, AM J HUM GENET, V92, P1008, DOI 10.1016/j.ajhg.2013.05.002
   White JR, 2018, SCAND J GASTROENTERO, V53, P1611, DOI 10.1080/00365521.2018.1542455
   Williams DP, 2020, CHEM RES TOXICOL, V33, P239, DOI 10.1021/acs.chemrestox.9b00264
   Wimmer G, 2016, INT CONF IMAG PROC
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Wu CC, 2019, COMPUT METH PROG BIO, V170, P23, DOI 10.1016/j.cmpb.2018.12.032
   Wu J, 2021, J CLIN GASTROENTEROL, V55, P110, DOI 10.1097/MCG.0000000000001423
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Xing XH, 2018, IEEE ENG MED BIO, P3594, DOI 10.1109/EMBC.2018.8513012
   Xu W, 2013, WORLD J GASTROENTERO, V19, P6479, DOI 10.3748/wjg.v19.i38.6479
   Yang D, 2019, FRONT ONCOL, V9, DOI 10.3389/fonc.2019.00494
   Yang YJ, 2020, CLIN ENDOSC, V53, P387, DOI 10.5946/ce.2020.133
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yao HM, 2021, GASTROINTEST ENDOSC, V93, P728, DOI 10.1016/j.gie.2020.08.011
   Yasaka K, 2018, RADIOLOGY, V287, P146, DOI 10.1148/radiol.2017171928
   Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706
   Yeaton P, 1998, CYTOMETRY, V32, P309, DOI 10.1002/(SICI)1097-0320(19980801)32:4<309::AID-CYTO8>3.0.CO;2-C
   Yip TCF, 2017, ALIMENT PHARM THER, V46, P447, DOI 10.1111/apt.14172
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Zezos P, 2018, GASTROENTEROLOGY, V154, pS99
   Zhang J, 2020, GASTROINTEST ENDOSC, V92, P874, DOI 10.1016/j.gie.2020.04.071
   Zhang MM, 2010, GASTROINTEST ENDOSC, V72, P978, DOI 10.1016/j.gie.2010.06.042
   Zhang YQ, 2020, DIGEST LIVER DIS, V52, P566, DOI 10.1016/j.dld.2019.12.146
   Zhang Y, 2020, BMC CANCER, V20, DOI 10.1186/s12885-020-06740-5
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zheng HY, 2020, MAGN RESON IMAGING, V68, P45, DOI 10.1016/j.mri.2020.01.008
   Zheng WF, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000109
   Zhou CM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81188-6
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu JW, 2015, GASTROINTEST ENDOSC, V82, P831, DOI 10.1016/j.gie.2015.02.043
   Zhu ML, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063820
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 342
TC 14
Z9 15
U1 3
U2 21
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD OCT 28
PY 2021
VL 27
IS 40
BP 6794
EP 6824
DI 10.3748/wjg.v27.i40.6794
PG 31
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA YU6VV
UT WOS:000752179000005
PM 34790008
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Taha, D
   Alzu'bi, A
   Abuarqoub, A
   Hammoudeh, M
   Elhoseny, M
AF Taha, Dima
   Alzu'bi, Ahmad
   Abuarqoub, Abdelrahman
   Hammoudeh, Mohammad
   Elhoseny, Mohamed
TI Automated Colorectal Polyp Classification Using Deep Neural Networks
   with Colonoscopy Images
SO INTERNATIONAL JOURNAL OF FUZZY SYSTEMS
LA English
DT Article
DE Colorectal cancer; Polyp classification; Deep learning; Colonoscopy
   diagnosis; CNNs
ID CANCER; POLYPECTOMY; ENDOSCOPY; DIAGNOSIS
AB Colonoscopy screening test plays a crucial role in identifying and classifying possible cancerous polyps. The automation of polyp classification is challenging due to the limitations associated with the traditional handcrafted image features. This paper proposes a deep learning model for colorectal polyp classification, referred to as DeepCPC. This model consists of three main stages: image pre-processing using patch extraction and data augmentation; model initialization using six pre-trained CNNs to generate the fine-tuned baseline model; and formulating and learning generic yet discriminating image descriptors extracted and fused from the convolutional layers of two efficient CNNs architectures to classify colorectal polyps. The DeepCPC architecture has been fine-tuned on the CVC-Clinic dataset through a complete end-to-end training in which the patch extraction and image augmentation have been applied to generate more colonoscopy images for the patients. The experimental results show that the baseline fine-tuned model achieves an accuracy of 97.6%, and the final DeepCPC model achieves an accuracy of 98.4%. The reported results also demonstrate the capability of the proposed approach in identifying polyps in terms of precision, recall, and f-score. The DeepCPC helps the endoscopic physicians in classifying polyps and decreasing the colorectal polyp miss rate.
C1 [Taha, Dima] Middle East Univ, Dept Comp Sci, Amman 11831, Jordan.
   [Alzu'bi, Ahmad] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid 22110, Jordan.
   [Abuarqoub, Abdelrahman] Cardiff Metropolitan Univ, Cardiff Sch Technol, Cardiff, Wales.
   [Hammoudeh, Mohammad] Manchester Metropolitan Univ, Dept Comp & Math, Manchester, Lancs, England.
   [Elhoseny, Mohamed] Amer Univ Emirates, Coll Comp Informat Technol, Dubai, U Arab Emirates.
   [Elhoseny, Mohamed] Mansoura Univ, Fac Comp & Informat, Mansoura, Egypt.
C3 Middle East University; Jordan University of Science & Technology;
   Cardiff Metropolitan University; Manchester Metropolitan University;
   Egyptian Knowledge Bank (EKB); Mansoura University
RP Alzu'bi, A (通讯作者)，Jordan Univ Sci & Technol, Dept Comp Sci, Irbid 22110, Jordan.
EM dimataha@ymail.com; agalzubi@just.edu.jo; aabuarqoub@cardiffmet.ac.uk;
   m.hammoudeh@mmu.ac.uk; melhoseny@ieee.org
RI Elhoseny, Mohamed/Q-5591-2017; Hammoudeh, Mohammad/A-5797-2012; Alzu'bi,
   Ahmad/Y-4113-2019
OI Elhoseny, Mohamed/0000-0001-6347-8368; Hammoudeh,
   Mohammad/0000-0003-1058-0996; Alzu'bi, Ahmad/0000-0001-5466-0379
CR AIzu'bi Ahmad, 2019, IAENG International Journal of Computer Science, V46, P637
   Alzu'bi A, 2020, ENG SCI TECHNOL, V23, P911, DOI 10.1016/j.jestch.2019.12.004
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Barancin C, 2011, CLIN GASTROENTEROL H, V9, P443, DOI 10.1016/j.cgh.2011.01.020
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bisong E., 2019, APRESS, P7
   Brenner H, 2014, NEW ENGL J MED, V371, P184, DOI [10.1056/NEJMc1405215, 10.1056/NEJMoa1311194]
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dekker E, 2018, GASTROENTEROLOGY, V154, P1970, DOI 10.1053/j.gastro.2018.01.069
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Groff Rachel J, 2008, Curr Gastroenterol Rep, V10, P490, DOI 10.1007/s11894-008-0090-z
   Hilsden RJ, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207848
   Horv┬u├th A., 2016, ACTA TECHNICA JAURIN, V9, P65, DOI [10.14513/actatechjaur.v9.n1.397, DOI 10.14513/ACTATECHJAUR.V9.N1.397]
   Huang YL, 2012, DIGESTION, V86, P148, DOI 10.1159/000338680
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Jerebko AK, 2005, ACAD RADIOL, V12, P479, DOI 10.1016/j.acra.2004.04.024
   Kahi CJ, 2015, DIGEST DIS SCI, V60, P773, DOI 10.1007/s10620-014-3449-z
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Komeda Y., 2019, ENDOSCOPY, V51, pOP2, DOI [10.1055/a-0877-0509, DOI 10.1055/A-0877-0509]
   Li P, 2004, INT C PATT RECOG, P774, DOI 10.1109/ICPR.2004.1334643
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Manivannan S, 2013, I S BIOMED IMAGING, P644
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Mir A, 2021, LIFE-BASEL, V11, DOI 10.3390/life11070602
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Nair M., 2015, PATHOPHYSIOLOGY NURS
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Obuch Joshua C, 2015, Curr Treat Options Gastroenterol, V13, P156, DOI 10.1007/s11938-015-0046-y
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Pogorelov K, 2019, J APPL CLIN MED PHYS, V20, P141, DOI 10.1002/acm2.12662
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Srivastava AN., 2016, MACHINE LEARNING KNO
   Stehle T., 2009, MED IMAGING 2009 COM, V7260
   Summers RM, 2005, GASTROENTEROLOGY, V129, P1832, DOI 10.1053/j.gastro.2005.08.054
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tholoor S, 2013, ANN GASTROENTEROL, V26, P114
   Tian Y, 2019, I S BIOMED IMAGING, P70
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang LS, 2019, IEEE ACCESS, V7, P44676, DOI 10.1109/ACCESS.2019.2908386
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wimmer G, 2016, INT CONF IMAG PROC
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 51
TC 1
Z9 1
U1 6
U2 15
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1562-2479
EI 2199-3211
J9 INT J FUZZY SYST
JI Int. J. Fuzzy Syst.
PD JUL
PY 2022
VL 24
IS 5
SI SI
BP 2525
EP 2537
DI 10.1007/s40815-021-01182-y
EA OCT 2021
PG 13
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA 3K5RR
UT WOS:000710831200002
DA 2023-08-21
ER

PT J
AU Xiao, ZL
   Ji, DNA
   Li, F
   Li, ZL
   Bao, ZJ
AF Xiao, Zili
   Ji, Danian
   Li, Feng
   Li, Zhengliang
   Bao, Zhijun
TI Application of Artificial Intelligence in Early Gastric Cancer Diagnosis
SO DIGESTION
LA English
DT Review
DE Artificial intelligence; Convolutional neural network; Early gastric
   cancer; Esophagogastroduodenoscopy; Diagnosis
ID CONVOLUTIONAL NEURAL-NETWORK; ENDOSCOPY; GASTROSCOPY; ACCURACY;
   INVASION; DEPTH
AB Background: With the development of new technologies such as magnifying endoscopy with narrow band imaging, endoscopists achieved better accuracy for diagnosis of gastric cancer (GC) in various aspects. However, to master such skill takes substantial effort and could be difficult for inexperienced doctors. Therefore, a novel diagnostic method based on artificial intelligence (AI) was developed and its effectiveness was confirmed in many studies. AI system using convolutional neural network has showed marvelous results in the ongoing trials of computer-aided detection of colorectal polyps. Summary: With AI's efficient computational power and learning capacities, endoscopists could improve their diagnostic accuracy and avoid the overlooking or over-diagnosis of gastric neoplasm. Several systems have been reported to achieved decent accuracy. Thus, AI-assisted endoscopy showed great potential on more accurate and sensitive ways for early detection, differentiation, and invasion depth prediction of gastric lesions. However, the feasibility, effectiveness, and safety in daily practice remain to be tested. Key messages: This review summarizes the current status of different AI applications in early GC diagnosis. More randomized controlled trails will be needed before AI could be widely put into clinical practice.
C1 [Xiao, Zili; Ji, Danian; Li, Feng; Li, Zhengliang; Bao, Zhijun] Fudan Univ, Huadong Hosp, Dept Gastroenterol, Shanghai, Peoples R China.
C3 Fudan University
RP Xiao, ZL (通讯作者)，Fudan Univ, Huadong Hosp, Dept Gastroenterol, Shanghai, Peoples R China.
EM xinyi8681@sina.com
FU scientific research programs of Shanghai Municipal Commission of science
   and technology [19411951504]
FX This review was supported by a grant from the scientific research
   programs of Shanghai Municipal Commission of science and technology (No.
   19411951504).
CR Abe S, 2011, GASTRIC CANCER, V14, P35, DOI 10.1007/s10120-011-0002-z
   Amin MB, 2017, CA-CANCER J CLIN, V67, P93, DOI 10.3322/caac.21388
   Cho BJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061858
   Ebigbo A, 2019, ENDOSC INT OPEN, V7, pE1616, DOI 10.1055/a-1010-5705
   Hirasawa T, 2021, DIGEST ENDOSC, V33, P263, DOI 10.1111/den.13890
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horiuchi Y, 2020, DIGEST DIS SCI, V65, P1355, DOI 10.1007/s10620-019-05862-6
   Horiuchi Y, 2020, GASTROINTEST ENDOSC, V92, P856, DOI 10.1016/j.gie.2020.04.079
   Hosokawa O, 2007, HEPATO-GASTROENTEROL, V54, P442
   HSIAO YJ, WORLD J GASTROENTERO, V27, P2979
   Ikenoyama Y, 2021, DIGEST ENDOSC, V33, P141, DOI 10.1111/den.13688
   Jin P, 2020, J CANCER RES CLIN, V146, P2339, DOI 10.1007/s00432-020-03304-9
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Luo HY, 2019, LANCET ONCOL, V20, P1645, DOI 10.1016/S1470-2045(19)30637-0
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Nagao S, 2020, GASTROINTEST ENDOSC, V92, P866, DOI 10.1016/j.gie.2020.06.047
   National Library of Medicine (NLM) at the National Institutes of Health (NIH), SEARCH RES
   Pei QS, 2015, J GASTROEN HEPATOL, V30, P1566, DOI 10.1111/jgh.13014
   Sakai Y, 2018, IEEE ENG MED BIO, P4138, DOI 10.1109/EMBC.2018.8513274
   Song ZG, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18147-8
   Tang DH, 2020, EBIOMEDICINE, V62, DOI 10.1016/j.ebiom.2020.103146
   Ueyama H, 2021, J GASTROEN HEPATOL, V36, P482, DOI 10.1111/jgh.15190
   Voutilainen ME, 2005, EUR J GASTROEN HEPAT, V17, P1345, DOI 10.1097/00042737-200512000-00013
   Wang KW, 2020, WORLD J GASTROENTERO, V26, P5090, DOI 10.3748/wjg.v26.i34.5090
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Xia J, 2021, GASTROINTEST ENDOSC, V93, P133, DOI 10.1016/j.gie.2020.05.027
   Yoon HJ, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091310
   Zhang LM, 2021, DIGEST ENDOSC, V33, P788, DOI 10.1111/den.13844
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 31
TC 9
Z9 9
U1 1
U2 14
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0012-2823
EI 1421-9867
J9 DIGESTION
JI Digestion
PD JAN
PY 2022
VL 103
IS 1
BP 69
EP 75
DI 10.1159/000519601
EA OCT 2021
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 0E3YI
UT WOS:000710818600001
PM 34666330
OA Bronze
DA 2023-08-21
ER

PT J
AU Viscaino, M
   Bustos, JT
   Munoz, P
   Cheein, CA
   Cheein, FA
AF Viscaino, Michelle
   Torres Bustos, Javier
   Munoz, Pablo
   Auat Cheein, Cecilia
   Cheein, Fernando Auat
TI Artificial intelligence for the early detection of colorectal cancer: A
   comprehensive review of its advantages and misconceptions
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Artificial intelligence; Machine learning; Deep learning; Medical
   images; Colorectal cancer; Colorectal polyps
ID POLYP DETECTION; CLASSIFICATION; COLONOSCOPY; VALIDATION; COLON; SMOTE
AB Colorectal cancer (CRC) was the second-ranked worldwide type of cancer during 2020 due to the crude mortality rate of 12.0 per 100000 inhabitants. It can be prevented if glandular tissue (adenomatous polyps) is detected early. Colonoscopy has been strongly recommended as a screening test for both early cancer and adenomatous polyps. However, it has some limitations that include the high polyp miss rate for smaller (< 10 mm) or flat polyps, which are easily missed during visual inspection. Due to the rapid advancement of technology, artificial intelligence (AI) has been a thriving area in different fields, including medicine. Particularly, in gastroenterology AI software has been included in computer-aided systems for diagnosis and to improve the assertiveness of automatic polyp detection and its classification as a preventive method for CRC. This article provides an overview of recent research focusing on AI tools and their applications in the early detection of CRC and adenomatous polyps, as well as an insightful analysis of the main advantages and misconceptions in the field.
C1 [Viscaino, Michelle; Torres Bustos, Javier; Cheein, Fernando Auat] Univ Tecn Federico Santa Maria, Dept Elect Engn, Ave Espana 1680, Valparaiso 2340000, Chile.
   [Munoz, Pablo] Univ Chile, Hosp Clin, Santiago 8380456, Chile.
   [Auat Cheein, Cecilia] Univ Nacl Santiago del Estero, Fac Med, RA-4200 Santiago Del Estero, Argentina.
C3 Universidad Tecnica Federico Santa Maria; Universidad de Chile
RP Cheein, FA (通讯作者)，Univ Tecn Federico Santa Maria, Dept Elect Engn, Ave Espana 1680, Valparaiso 2340000, Chile.
EM fernando.auat@usm.cl
RI Cheein, Fernando Auat/H-7817-2012
OI Cheein, Fernando Auat/0000-0002-6347-7696; Viscaino,
   Michelle/0000-0001-6693-7865
FU Chilean National Agency for Research and Development (ANID) [FB0008];
   CONICYT-PCHA/Doctorado Nacional [2018-21181420]
FX Chilean National Agency for Research and Development (ANID), No. FB0008;
   and CONICYT-PCHA/Doctorado Nacional, No. 2018-21181420.
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], MACH LEARN
   Araghi M, 2019, INT J CANCER, V144, P2992, DOI 10.1002/ijc.32055
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brown SR, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006439.pub4
   Cano F, 15 INT S MED INF PRO, V11330
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Deng CY, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101656
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deo RC, 2015, CIRCULATION, V132, P1920, DOI 10.1161/CIRCULATIONAHA.115.001593
   East JE, 2008, GASTROENTEROL CLIN N, V37, P25, DOI 10.1016/j.gtc.2007.12.014
   Ferlay J, 2010, BREAST CANCER EPIDEMIOLOGY, P1, DOI 10.1007/978-1-4419-0685-4_1
   Fonolla R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155040
   Gal Y, 2017, PR MACH LEARN RES, V70
   Gal Y, 2016, PR MACH LEARN RES, V48
   Giger ML, 2018, J AM COLL RADIOL, V15, P512, DOI 10.1016/j.jacr.2017.12.028
   Glasmachers T., 2017, AS C MACH LEARN, P17
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   Hu YF, 2016, IEEE T MED IMAGING, V35, P1522, DOI 10.1109/TMI.2016.2518958
   Hwang M, 2020, COMPUT MED IMAG GRAP, V84, DOI 10.1016/j.compmedimag.2020.101763
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Jo T., 2004, SIGKDD EXPLORATIONS, V6, P40, DOI DOI 10.1145/1007730.1007737
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Kendall A., 2017, PROC ADV NEURAL INF, V30, P5574
   Kubat M, 1997, P 14 INT C MACH LEAR, V97, P179
   Laique SN, 2021, GASTROINTEST ENDOSC, V93, P750, DOI 10.1016/j.gie.2020.08.038
   Lebwohl B, 2011, GASTROINTEST ENDOSC, V73, P1207, DOI 10.1016/j.gie.2011.01.051
   Lee SH, 2008, GASTROINTEST ENDOSC, V67, P683, DOI 10.1016/j.gie.2007.10.018
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Levin B, 2008, CA-CANCER J CLIN, V58, P130, DOI 10.3322/CA.2007.0018
   Lin J.S., 2016, US PREVENTIVE SERVIC
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Moreira L, 2012, GASTROENTEROLOGIA HE, V2nd, P607
   Mostavi M., 2020, CANCERSIAMESE ONE SH
   Nalepa J., 2019, ARTIF INTELL REV, V52, P857
   National ComprehensiveCancerNetwork, 2013, NCCN CLIN PRACTICE G
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Park HC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051650
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Ruiz L, 2019, SYMP IMAG SIG PROC A
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Schootman M, 2016, DIS COLON RECTUM, V59, P1011, DOI 10.1097/DCR.0000000000000688
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Singh R, 2020, TRANSL GASTROENT HEP, V5, DOI 10.21037/tgh.2019.12.06
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tan JX, 2020, IEEE T MED IMAGING, V39, P2013, DOI 10.1109/TMI.2019.2963177
   Thai-Nghe N., 2010, 2010 INT JOINT C NEU, P1, DOI 10.1109/IJCNN.2010.5596486
   Van der Laan JJH, 2021, EXPERT REV GASTROENT, V15, P115, DOI [10.1080/17474124.2021.1840352, 10.1145/3393672.3398490]
   Van Hulse J., 2007, ACM INT C P SERIES, P935, DOI [DOI 10.1145/1273496.1273614, 10.1145/1273496.1273614]
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Vinyals O., 2016, P ADV NEUR INF PROC, P3630
   Viscaino M, 2019 41 ANN INT C IE, V23, P961
   Viscaino M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229226
   Walsh JME, 2003, JAMA-J AM MED ASSOC, V289, P1288, DOI 10.1001/jama.289.10.1288
   Wang KW, 2020, WORLD J GASTROENTERO, V26, P5090, DOI 10.3748/wjg.v26.i34.5090
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   WHO, 2020, GLOB HLTH EST 2019 D
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Winawer S., 2008, South African Gastroenterology Review, V6, P13
   Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457
   Woodward M., 2016, NIPS DEEP REINF LEAR
   Yarlagadda DVK, 2019, PROC SPIE, V10956, DOI 10.1117/12.2512963
   Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z
   Zhang J., 2003, P ICML 2003 WORKSH L
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 81
TC 8
Z9 8
U1 6
U2 16
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD OCT 14
PY 2021
VL 27
IS 38
BP 6399
EP 6414
DI 10.3748/wjg.v27.i38.6399
PG 16
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA XT6SK
UT WOS:000733714700005
PM 34720530
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Wang, ST
   Yin, YQ
   Wang, DJ
   Lv, ZH
   Wang, YZ
   Jin, YC
AF Wang, Sutong
   Yin, Yunqiang
   Wang, Dujuan
   Lv, Zehui
   Wang, Yanzhang
   Jin, Yaochu
TI An interpretable deep neural network for colorectal polyp diagnosis
   under colonoscopy
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Colorectal polyp diagnosis; Deep neural network; Yamada classification
   guidance; Polyp segmentation
ID AUTOMATIC DETECTION; VALIDATION; IMAGE
AB Colorectal cancer (CRC) is the third leading cause of cancer deaths in the world, which mostly stems from precancerous polyps. Early detection and accurate classification of polyps play a vital role in colonoscopy. It makes sense to automatically detect the polyp and give a real-time classification feedback according to popular Yamada classification guidance during colonoscopy progress. We propose an interpretable deep neural network method, called multi-task real-time deep neural network with Shapley additive explanations, for polyp detection, polyp classification and polyp segmentation under colonoscopy. To the best of our knowledge, this is the first time to perform polyp classification according to Yamada classification guidance under colonoscopy with a deep learning method. To validate the performance of our proposed method, we conduct various comparative experiments on popular CVC-CLINIC and CVC-COLON datasets. We adopt various performance indicators, including area under receiver operating characteristics curve (AUC), precision, recall, F1 score, accuracy, and mean intersection over union (mIoU). The proposed method achieves satisfactory real-time performance in terms of polyp detection module, polyp classification module and polyp segmentation module. The experimental results show the overwhelming performance of our proposed method compared with other deep learning methods. We have achieved satisfying operating efficiency and interpretable feedback to meet the requirements of the colorectal surgeon, which provides an valuable decision support and reduces the rate of missed diagnosis and misdiagnosis of polyps in the process of colonoscopy. (c) 2021 Published by Elsevier B.V.
C1 [Wang, Sutong; Wang, Yanzhang] Dalian Univ Technol, Inst Informat & Decis Technol, Dalian 116023, Peoples R China.
   [Yin, Yunqiang] Univ Elect Sci & Technol China, Sch Management & Econ, Chengdu 611731, Peoples R China.
   [Wang, Dujuan] Sichuan Univ, Business Sch, Chengdu 610064, Peoples R China.
   [Lv, Zehui] Dalian Univ, Affiliated Xinhua Hosp, Dalian 116000, Peoples R China.
   [Jin, Yaochu] Univ Surrey, Dept Comp Sci, Guildford GU2 7XH, Surrey, England.
C3 Dalian University of Technology; University of Electronic Science &
   Technology of China; Sichuan University; Dalian University; University
   of Surrey
RP Wang, DJ (通讯作者)，Sichuan Univ, Business Sch, Chengdu 610064, Peoples R China.; Jin, YC (通讯作者)，Univ Surrey, Dept Comp Sci, Guildford GU2 7XH, Surrey, England.
EM wangdujuan@dlut.edu.cn; yaochu.jin@surrey.ac.uk
RI Jin, Yaochu/GRY-7004-2022; Wang, Sutong/HNO-8634-2023
OI Jin, Yaochu/0000-0003-1100-0631; Wang, Sutong/0000-0001-6603-6047; Wang,
   Dujuan/0000-0003-1617-7057
CR Ahlawat SK, 2011, J CLIN GASTROENTEROL, V45, P347, DOI 10.1097/MCG.0b013e3181f3a2e0
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Arya N, 2021, KNOWL-BASED SYST, V221, DOI 10.1016/j.knosys.2021.106965
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Cai YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3065438
   Capizzi G, 2020, IEEE T FUZZY SYST, V28, P1178, DOI 10.1109/TFUZZ.2019.2952831
   Chen T, 2020, COMPUT METH PROG BIO, V185, DOI [10.1016/j.cmph.2019.105118, 10.1016/j.cmpb.2019.105118]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Gao CL, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2021.106754
   Grahn Sarah W, 2008, Clin Colon Rectal Surg, V21, P247, DOI 10.1055/s-0028-1089939
   Gross S, 2009, PROC SPIE, V7260, DOI 10.1117/12.810996
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Hendricks LA, 2016, LECT NOTES COMPUT SC, V9908, P3, DOI 10.1007/978-3-319-46493-0_1
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Kampffmeyer M., 2018, IEEE INT WORKS MACH, P1
   Lan LB, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106971
   Lee HD, 2018, KNOWL-BASED SYST, V158, P9, DOI 10.1016/j.knosys.2018.05.016
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Lundberg SM, 2018, NAT BIOMED ENG, V2, P749, DOI 10.1038/s41551-018-0304-0
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Monderer D, 1996, GAME ECON BEHAV, V14, P124, DOI 10.1006/game.1996.0044
   Nagai Y, 2016, DIGESTION, V93, P272, DOI 10.1159/000446344
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Sevo I, 2016, COMPUT BIOL MED, V72, P138, DOI 10.1016/j.compbiomed.2016.03.017
   Shapley L., 1953, CONTRIBUTIONS THEORY, VII, P307, DOI [DOI 10.1515/9781400881970-018, 10.1515/9781400881970-018]
   Shu YC, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106950
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song KH, 2021, KNOWL-BASED SYST, V221, DOI 10.1016/j.knosys.2021.106835
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Stanich PP, 2019, CLIN GASTROENTEROL H, V17, P2008, DOI 10.1016/j.cgh.2018.12.008
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tian YJ, 2020, KNOWL-BASED SYST, V210, DOI 10.1016/j.knosys.2020.106445
   Tomizawa M, 2014, BIOMED REP, V2, P633, DOI [10.3892/br.2014.309, 10.3892/br.2015.487]
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang R., SHAPLEY EXPLANATION, V2021, P1
   Wichakam I, 2018, LECT NOTES COMPUT SC, V10704, P393, DOI 10.1007/978-3-319-73603-7_32
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Wozniak M, 2021, NEURAL COMPUT APPL, DOI 10.1007/s00521-021-05841-x
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 58
TC 6
Z9 6
U1 7
U2 47
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD DEC 25
PY 2021
VL 234
AR 107568
DI 10.1016/j.knosys.2021.107568
EA OCT 2021
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK8HW
UT WOS:000709963300011
DA 2023-08-21
ER

PT J
AU Peterson, E
   May, FP
   Kachikian, O
   Soroudi, C
   Naini, B
   Kang, YN
   Myint, A
   Guyant, G
   Elmore, J
   Bastani, R
   Maehara, C
   Hsu, W
AF Peterson, Emma
   May, Folasade P.
   Kachikian, Odet
   Soroudi, Camille
   Naini, Bita
   Kang, Yuna
   Myint, Anthony
   Guyant, Gordon
   Elmore, Joann
   Bastani, Roshan
   Maehara, Cleo
   Hsu, William
TI Automated identification and assignment of colonoscopy surveillance
   recommendations for individuals with colorectal polyps
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID QUALITY; POLYPECTOMY; ADHERENCE; RATES
AB Background and Aims: Determining surveillance intervals for patients with colorectal polyps is critical but time-consuming and challenging to do reliably. We present the development and assessment of a pipeline that leverages natural language processing techniques to automatically extract and analyze relevant polyp findings from free-text colonoscopy and pathology reports. Using this information, we categorized individual patients into 6 postcolonoscopy surveillance intervals defined by the U.S. Multi-Society Task Force on Colorectal Cancer.
   Methods: Using a set of 546 randomly selected colonoscopy and pathology reports from 324 patients in a single health system, we used a combination of statistical classifiers and rule-based methods to extract polyp properties from each report type, associate properties with unique polyps, and classify a patient into 1 of 6 risk categories by integrating information from both report types. We then assessed the pipeline's performance by determining the positive predictive value (PPV), sensitivity, and F-score of the algorithm, compared with the determination of surveillance intervals by a gastroenterologist.
   Results: The pipeline was developed using 346 reports (224 colonoscopy and 122 pathology) from 224 patients and evaluated on an independent test set of 200 reports (100 colonoscopy and 100 pathology) from 100 patients. We achieved an average PPV, sensitivity, and F-score of .92, .95, and .93, respectively, across targeted entities for colonoscopy. Pathology extraction achieved a PPV, sensitivity, and F-score of .95, .97, and .96. The system achieved an overall accuracy of 92% in assigning the recommended interval for surveillance colonoscopy.
   Conclusions: This study demonstrates the feasibility of using machine learning to automatically extract findings and classify patients to appropriate risk categories and corresponding surveillance intervals. Incorporating this system can facilitate proactive and timely follow-up after screening colonoscopy and enable real-time quality assessment of prevention programs and providers.
C1 [Peterson, Emma; Kachikian, Odet; Guyant, Gordon; Maehara, Cleo; Hsu, William] Univ Calif Los Angeles, Dept Radiol Sci, Data Integrat Architecture & Analyt Grp, Los Angeles, CA 90024 USA.
   [May, Folasade P.; Soroudi, Camille; Myint, Anthony] Univ Calif Los Angeles, David Geffen Sch Med, Dept Med, Vatche & Tamar Manoukian Div Digest Dis, Los Angeles, CA 90024 USA.
   [Naini, Bita; Kang, Yuna] Univ Calif Los Angeles, David Geffen Sch Med, Dept Pathol, Los Angeles, CA 90024 USA.
   [Elmore, Joann] Univ Calif Los Angeles, David Geffen Sch Med, Dept Med, Div Gen Internal Med & Hlth Serv Res, Los Angeles, CA 90024 USA.
   [May, Folasade P.; Bastani, Roshan] UCLA Kaiser Permanente Ctr Hlth Equ, UCLA Ctr Canc Prevent & Control Res, Los Angeles, CA USA.
   [May, Folasade P.; Bastani, Roshan] Fielding Sch Publ Hlth, Dept Hlth Policy & Management, Los Angeles, CA USA.
   [May, Folasade P.; Bastani, Roshan] Jonsson Comprehens Canc Ctr, Los Angeles, CA 90034 USA.
   [May, Folasade P.] Vet Affairs Greater Los Angeles Healthcare Syst, Dept Med, Div Gastroenterol, Los Angeles, CA USA.
C3 University of California System; University of California Los Angeles;
   University of California System; University of California Los Angeles;
   University of California Los Angeles Medical Center; David Geffen School
   of Medicine at UCLA; University of California System; University of
   California Los Angeles; University of California Los Angeles Medical
   Center; David Geffen School of Medicine at UCLA; University of
   California System; University of California Los Angeles; University of
   California Los Angeles Medical Center; David Geffen School of Medicine
   at UCLA; Kaiser Permanente; UCLA Jonsson Comprehensive Cancer Center; US
   Department of Veterans Affairs; Veterans Health Administration (VHA); VA
   Greater Los Angeles Healthcare System
RP Hsu, W (通讯作者)，Univ Calif Los Angeles, David Geffen Sch Med, 924 Westwood Blvd,Ste 420, Los Angeles, CA 90024 USA.
EM whsu@mednet.ucla.edu
RI Hsu, William/AAA-1935-2021
OI Hsu, William/0000-0002-5168-070X
FU Melvin and Bren Simon Gastroenterology Quality Improvement Program; UCLA
   Health Innovation Grant; National Science Foundation [1722516]; Div Of
   Information & Intelligent Systems; Direct For Computer & Info Scie &
   Enginr [1722516] Funding Source: National Science Foundation
FX The following authors disclosed financial relationships: J. Elmore:
   Editor in Chief, UpToDate. All other authors disclosed no financial
   relationships. Research support for this study was provided by the
   Melvin and Bren Simon Gastroenterology Quality Improvement Program
   (F.P.M., C.S., A.M.), UCLA Health Innovation Grant (E.P., F.P.M., O.K.,
   G.G., C.M.), andNational Science Foundation (W.H.) (grant 1722516).
CR Abdul-Baki H, 2015, GASTROINTEST ENDOSC, V82, P676, DOI 10.1016/j.gie.2014.12.058
   Braschi Caitlyn, 2014, J Gastrointest Cancer, V45, P500, DOI 10.1007/s12029-014-9653-4
   Chubak J, 2019, CANCER EPIDEM BIOMAR, V28, P91, DOI 10.1158/1055-9965.EPI-18-0452
   Gawron AJ, 2014, AM J GASTROENTEROL, V109, P1844, DOI 10.1038/ajg.2014.147
   Gupta S, 2020, AM J GASTROENTEROL, V115, P415, DOI 10.14309/ajg.0000000000000544
   He XS, 2020, GASTROENTEROLOGY, V158, P852, DOI 10.1053/j.gastro.2019.06.039
   Honnibal M., 2020, SPACY IND STRENGTH N, DOI 10.5281/zenodo
   Imler TD, 2015, AM J GASTROENTEROL, V110, P543, DOI 10.1038/ajg.2015.51
   Imler TD, 2014, CLIN GASTROENTEROL H, V12, P1130, DOI 10.1016/j.cgh.2013.11.025
   Imler TD, 2013, CLIN GASTROENTEROL H, V11, P689, DOI 10.1016/j.cgh.2012.11.035
   Iskandar H, 2015, DIGEST DIS SCI, V60, P971, DOI 10.1007/s10620-014-3403-0
   Joseph DA, 2016, CANCER-AM CANCER SOC, V122, P2479, DOI 10.1002/cncr.30070
   Karwa A, 2020, CLIN GASTROENTEROL H, V18, P2038, DOI 10.1016/j.cgh.2019.10.013
   Laiyemo AO, 2009, CLIN GASTROENTEROL H, V7, P562, DOI 10.1016/j.cgh.2008.12.009
   May F, 2019, AM J GASTROENTEROL, V114, pS161, DOI 10.14309/01.ajg.0000590636.07850.dc
   Mehrotra A, 2012, GASTROINTEST ENDOSC, V75, P1233, DOI 10.1016/j.gie.2012.01.045
   Myint A, SCI REP-UK, V11, P8764
   Nayor J, 2018, DIGEST DIS SCI, V63, P1794, DOI 10.1007/s10620-018-5078-4
   Pannala R, 2020, GASTROINTEST ENDOSC, V92, P1151, DOI 10.1016/j.gie.2020.09.022
   Patel N, 2015, DIGEST DIS SCI, V60, P2937, DOI 10.1007/s10620-015-3685-x
   Raju GS, 2015, GASTROINTEST ENDOSC, V82, P512, DOI 10.1016/j.gie.2015.01.049
   Schoen RE, 2010, GASTROENTEROLOGY, V138, P73, DOI 10.1053/j.gastro.2009.09.062
   Siegel RL., 2020, CA-CANCER J CLIN, V70, P145, DOI [DOI 10.3322/caac.21590, 10.3322/caac.21601]
   Skinner CS, 2016, J AM MED INFORM ASSN, V23, P402, DOI 10.1093/jamia/ocv081
   Stenetorp P., 2012, P DEMONSTRATIONS 13, P102
   Zauber AG, 2015, DIGEST DIS SCI, V60, P681, DOI 10.1007/s10620-015-3600-5
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 27
TC 3
Z9 3
U1 1
U2 3
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD NOV
PY 2021
VL 94
IS 5
BP 978
EP 987
DI 10.1016/j.gie.2021.05.036
EA OCT 2021
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA WH0ZQ
UT WOS:000707417800015
PM 34087201
DA 2023-08-21
ER

PT J
AU Fonolla, R
   van der Zander, QEW
   Schreuder, RM
   Subramaniam, S
   Bhandari, P
   Masclee, AAM
   Schoon, EJ
   van Der Sommen, F
   de With, PHN
AF Fonolla, Roger
   van der Zander, Quirine E. W.
   Schreuder, Ramon M.
   Subramaniam, Sharmila
   Bhandari, Pradeep
   Masclee, Ad A. M.
   Schoon, Erik J.
   van Der Sommen, Fons
   de With, Peter H. N.
TI Automatic image and text-based description for colorectal polyps using
   BASIC classification
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Blue light imaging; Linked color imaging; BASIC; Image captioning;
   Artificial intelligence; Deep learning; CADx
ID COMPUTER-AIDED DIAGNOSIS; OPTICAL DIAGNOSIS; CHROMOENDOSCOPY; LESIONS;
   SYSTEM
AB Colorectal polyps (CRP) are precursor lesions of colorectal cancer (CRC). Correct identification of CRPs during in-vivo colonoscopy is supported by the endoscopist's expertise and medical classification models. A recent developed classification model is the Blue light imaging Adenoma Serrated International Classification (BASIC) which describes the differences between non-neoplastic and neoplastic lesions acquired with blue light imaging (BLI). Computer-aided detection (CADe) and diagnosis (CADx) systems are efficient at visually assisting with medical decisions but fall short at translating decisions into relevant clinical information. The communication between machine and medical expert is of crucial importance to improve diagnosis of CRP during in-vivo procedures. In this work, the combination of a polyp image classification model and a language model is proposed to develop a CADx system that automatically generates text comparable to the human language employed by endoscopists. The developed system generates equivalent sentences as the human-reference and describes CRP images acquired with white light (WL), blue light imaging (BLI) and linked color imaging (LCI). An image feature encoder and a BERT module are employed to build the AI model and an external test set is used to evaluate the results and compute the linguistic metrics. The experimental results show the construction of complete sentences with an established metric scores of BLEU-1 = 0.67, ROUGE-L = 0.83 and METEOR = 0.50. The developed CADx system for automatic CRP image captioning facilitates future advances towards automatic reporting and may help reduce time-consuming histology assessment.
C1 [Fonolla, Roger; van Der Sommen, Fons; de With, Peter H. N.] Eindhoven Univ Technol, Dept Elect Engn, Video Coding & Architectures VCA, Eindhoven, Noord Brabant, Netherlands.
   [van der Zander, Quirine E. W.; Masclee, Ad A. M.] Maastricht Univ, Div Gastroenterol & Hepatol, Med Ctr, Maastricht, Netherlands.
   [van der Zander, Quirine E. W.] Maastricht Univ, Sch Oncol & Dev Biol, GROW, Maastricht, Netherlands.
   [Schreuder, Ramon M.; Schoon, Erik J.] Catharina Hosp, Dept Gastroenterol & Hepatol, Eindhoven, Noord Brabant, Netherlands.
   [Masclee, Ad A. M.] Maastricht Univ, Sch Nutr & Translat Res Metab, NUTRIM, Maastricht, Netherlands.
   [Subramaniam, Sharmila; Bhandari, Pradeep] Portsmouth Hosp Univ NHS Trust, Dept Gastroenterol, Portsmouth, Hants, England.
C3 Eindhoven University of Technology; Maastricht University; Maastricht
   University; Catharina Hospital; Maastricht University
RP Fonolla, R (通讯作者)，Eindhoven Univ Technol, Dept Elect Engn, Video Coding & Architectures VCA, Eindhoven, Noord Brabant, Netherlands.
EM r.fonolla.navarro@tue.nl
OI van der Sommen, Fons/0000-0002-3593-2356; van der Zander, Quirine
   E.W./0000-0002-8640-5521
FU European Union's Horizon 2020 research and innovation program under the
   Marie Sklodowska-Curie grant [721766]; NVIDIA Corporation
FX This project has received funding from the European Union's Horizon 2020
   research and innovation program under the Marie Sklodowska-Curie grant
   agreement No. 721766. We gratefully acknowledge thesupport of NVIDIA
   Corporation with the donation of the Titan Xp GPU used for this
   research.
CR Allaouzi I., P 3 INT C SMART CIT
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Bisschops R, 2018, ENDOSCOPY, V50, P211, DOI 10.1055/s-0043-121570
   Bouwens MWE, 2013, WORLD J GASTROENTERO, V19, P4334, DOI 10.3748/wjg.v19.i27.4334
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Demner-Fushman Dina, 2012, Journal of Computing Science and Engineering, V6, P168, DOI 10.5626/JCSE.2012.6.2.168
   Devlin J., 2018, NAACL HLT
   East JE, 2007, GUT, V56, P1168
   Fonolla R, 2019, I S BIOMED IMAGING, P74, DOI 10.1109/ISBI.2019.8759320
   Har-Noy O, 2017, DIGEST DIS SCI, V62, P2982, DOI 10.1007/s10620-017-4772-y
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   IJspeert JEG, 2016, GUT, V65, P963, DOI 10.1136/gutjnl-2014-308411
   Iwatate M, 2018, ENDOSCOPY EARLY GAST, V1, P69
   Jass JR, 2007, HISTOPATHOLOGY, V50, P113, DOI 10.1111/j.1365-2559.2006.02549.x
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kandel P, 2019, CLIN ENDOSC, V52, P239, DOI 10.5946/ce.2018.136
   Kisilev P, 2016, THE CNN
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Lavie A., 2007, PROC STATMT, P228
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74
   Mishra Sanjukta, 2020, Advanced Computing and Systems for Security. Volume Twelve. Advances in Intelligent Systems and Computing (AISC 1136), P1, DOI 10.1007/978-981-15-2930-6_1
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Neumann H, 2018, UNITED EUR GASTROENT, V6, P1099, DOI 10.1177/2050640618769731
   Pannala R., VIDEOGIE
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pelka O, 2018, LECT NOTES COMPUT SC, V11043, P180, DOI 10.1007/978-3-030-01364-6_20
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Rojas-Munoz E, 2020, IMAGING VISUAL, P1
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Scheeve T, 2019, PROC SPIE, V10950, DOI 10.1117/12.2508223
   Shin HC, 2016, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2016.274
   Shung Dennis L, 2020, Gastrointest Endosc Clin N Am, V30, P585, DOI 10.1016/j.giec.2020.02.010
   Subramaniam S, 2019, UNITED EUR GASTROENT, V7, P316, DOI 10.1177/2050640618822402
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tsuji S, 2018, ENDOSC INT OPEN, V6, pE1382, DOI 10.1055/a-0650-4362
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2020, GUT, V69, P2035, DOI 10.1136/gutjnl-2019-320466
   van der Zander Q. E., ENDOSCOPY AAM
   Visovan II, 2017, BOSNIAN J BASIC MED, V17, P152, DOI 10.17305/bjbms.2017.1686
   Weigt J., ENDOSCOPY
   Yoshida N, 2019, GUT LIVER, V13, P140, DOI 10.5009/gnl18276
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhou DJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16777-6
NR 50
TC 5
Z9 5
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD NOV
PY 2021
VL 121
AR 102178
DI 10.1016/j.artmed.2021.102178
EA OCT 2021
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA WH1CM
UT WOS:000707425200004
PM 34763800
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Hoang, MC
   Nguyen, KT
   Kim, J
   Park, JO
   Kim, CS
AF Hoang, Manh Cuong
   Kim Tien Nguyen
   Kim, Jayoung
   Park, Jong-Oh
   Kim, Chang-Sei
TI Automated Bowel Polyp Detection Based on Actively Controlled Capsule
   Endoscopy: Feasibility Study
SO DIAGNOSTICS
LA English
DT Article
DE active locomotion capsule endoscope; magnetic capsule endoscope; capsule
   localization; polyp detection; deep learning
ID LOCALIZATION; MECHANISM; INTESTINE; TUMORS
AB This paper presents an active locomotion capsule endoscope system with 5D position sensing and real-time automated polyp detection for small-bowel and colon applications. An electromagnetic actuation system (EMA) consisting of stationary electromagnets is utilized to remotely control a magnetic capsule endoscope with multi-degree-of-freedom locomotion. For position sensing, an electronic system using a magnetic sensor array is built to track the position and orientation of the magnetic capsule during movement. The system is integrated with a deep learning model, named YOLOv3, which can automatically identify colorectal polyps in real-time with an average precision of 85%. The feasibility of the proposed method concerning active locomotion and localization is validated and demonstrated through in vitro experiments in a phantom duodenum. This study provides a high-potential solution for automatic diagnostics of the bowel and colon using an active locomotion capsule endoscope, which can be applied for a clinical site in the future.</p>
C1 [Hoang, Manh Cuong; Kim, Chang-Sei] Chonnam Natl Univ, Sch Mech Engn, Gwangju 61186, South Korea.
   [Kim Tien Nguyen; Kim, Jayoung; Park, Jong-Oh] Korea Inst Med Microrobot, Gwangju 61011, South Korea.
C3 Chonnam National University
RP Kim, CS (通讯作者)，Chonnam Natl Univ, Sch Mech Engn, Gwangju 61186, South Korea.
EM hmcuong.hust@gmail.com; kimtiennguyen@chonnam.ac.kr; jaya@kimiro.re.kr;
   jop@kimiro.re.kr; ckim@jnu.ac.kr
RI Nguyen, Kim Tien/ITU-8151-2023; Kim, Chang-Sei/ITW-1904-2023; Nguyen,
   Kim Tien/J-2137-2015
OI Nguyen, Kim Tien/0000-0003-1260-3610; Nguyen, Kim
   Tien/0000-0003-1260-3610; Kim, Chang-Sei/0000-0003-4532-2006; Hoang,
   Manh Cuong/0000-0001-6816-339X
FU Korea Health Technology Development R&D Project through the Korea Health
   Industry Development Institute (KHIDI) - Ministry of Health and Welfare,
   Republic of Korea [HI19C0642]
FX FundingThis research was supported by a grant of the Korea Health
   Technology Development R&D Project through the Korea Health Industry
   Development Institute (KHIDI), funded by the Ministry of Health and
   Welfare, Republic of Korea (grant number: HI19C0642).
CR Accoto D., 2001, WORLD TRIB C, P728
   Akce M, 2018, J CLIN ONCOL, V36, DOI 10.1200/JCO.2018.36.15_suppl.e16262
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Blanchard DK, 2000, WORLD J SURG, V24, P421, DOI 10.1007/s002689910067
   Cheung DY, 2010, J GASTROEN HEPATOL, V25, P1079, DOI 10.1111/j.1440-1746.2010.06292.x
   CHOW WH, 1993, CANCER CAUSE CONTROL, V4, P163, DOI 10.1007/BF00053158
   Dey Nilanjan, 2017, IEEE Rev Biomed Eng, V10, P2, DOI 10.1109/RBME.2017.2697950
   Goh ST, 2014, IEEE SENS J, V14, P3819, DOI 10.1109/JSEN.2014.2342720
   Hale MF, 2014, WORLD J GASTROENTERO, V20, P7752, DOI 10.3748/wjg.v20.i24.7752
   Hara AK, 2006, RADIOLOGY, V238, P128, DOI 10.1148/radiol.2381050296
   Hoang MC, 2021, IEEE T SYST MAN CY-S, V51, P3040, DOI 10.1109/TSMC.2019.2917298
   Hoang MC, 2019, IEEE ACCESS, V7, P93364, DOI 10.1109/ACCESS.2019.2927894
   Hoang MC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219740
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Joe S, 2019, MECHATRONICS, V62, DOI 10.1016/j.mechatronics.2019.102259
   Kim JS, 2006, TRIBOL LETT, V22, P143, DOI 10.1007/s11249-006-9073-0
   Nguyen KT, 2020, INT J CONTROL AUTOM, V18, P65, DOI 10.1007/s12555-019-0240-0
   Kok RD, 2004, MAGN RESON IMAGING, V22, P851, DOI 10.1016/j.mri.2004.01.047
   Kong K, 2012, J MED DEVICES, V6, DOI 10.1115/1.4007100
   Koulaouzidis A, 2013, WORLD J GASTROENTERO, V19, P3726, DOI 10.3748/wjg.v19.i24.3726
   Le Zhang, 2010, 2010 International Conference on Body Sensor Networks (BSN), P255, DOI 10.1109/BSN.2010.54
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lim YJ, 2015, CLIN ENDOSC, V48, P399, DOI 10.5946/ce.2015.48.5.399
   Liu SL, 2020, IEEE ACCESS, V8, P141159, DOI 10.1109/ACCESS.2020.3012533
   Hoang MC, 2020, MICROMACHINES-BASEL, V11, DOI 10.3390/mi11010098
   Cami MM, 2021, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.600095
   Munoz F, 2014, ADV DRUG DELIVER REV, V71, P77, DOI 10.1016/j.addr.2013.12.007
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pedersen KS, 2019, J NATL COMPR CANC NE, V17, P1135, DOI 10.6004/jnccn.2019.7344
   Pogorelov K, 2019, J APPL CLIN MED PHYS, V20, P141, DOI 10.1002/acm2.12662
   Rahman I., 2014, GASTROINTEST ENDOSC, V79, pAB122, DOI [10.1016/j.gie.2014.02.059, DOI 10.1016/J.GIE.2014.02.059]
   Redmon J., 2018, YOLOV3 INCREMENTAL I
   Rey JF, 2012, GASTROINTEST ENDOSC, V75, P373, DOI 10.1016/j.gie.2011.09.030
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Simi M, 2013, J MED DEVICES, V7, DOI 10.1115/1.4025185
   Son D, 2019, IEEE T ROBOT, V35, P343, DOI 10.1109/TRO.2018.2885218
   Song S., 2021, IEEE T INSTRUMENTATI, V70, P1, DOI 10.1109/TIM.2021.3069488
   Swain P, 2010, GASTROINTEST ENDOSC, V71, P1290, DOI 10.1016/j.gie.2010.01.064
   Vasilakakis M, 2019, EXPERT REV GASTROENT, V13, P129, DOI 10.1080/17474124.2019.1553616
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wang M, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3075776
   Wang X, 2006, 1 IEEERAS EMBS INT C, P124, DOI DOI 10.1109/BIOROB.2006.1639071
   Woods SP, 2013, IEEE T BIO-MED ENG, V60, P945, DOI 10.1109/TBME.2012.2228647
   Ye YX, 2012, INT J WIREL INF NETW, V19, P229, DOI 10.1007/s10776-012-0193-1
   Yim S, 2014, IEEE T BIO-MED ENG, V61, P513, DOI 10.1109/TBME.2013.2283369
   Yim S, 2013, IEEE-ASME T MECH, V18, P1413, DOI 10.1109/TMECH.2012.2235077
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 51
TC 6
Z9 6
U1 2
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD OCT
PY 2021
VL 11
IS 10
AR 1878
DI 10.3390/diagnostics11101878
PG 16
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA WT7LY
UT WOS:000716044300001
PM 34679575
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Yang, C
   Guo, XQ
   Zhu, ML
   Ibragimov, B
   Yuan, YX
AF Yang, Chen
   Guo, Xiaoqing
   Zhu, Meilu
   Ibragimov, Bulat
   Yuan, Yixuan
TI Mutual-Prototype Adaptation for Cross-Domain Polyp Segmentation
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Prototypes; Image segmentation; Image reconstruction; Semantics; Feature
   extraction; Adaptation models; Colonoscopy; Polyp segmentation; domain
   adaptation; prototype; self-training; reconstruction
ID IMAGE
AB Accurate segmentation of the polyps from colonoscopy images provides useful information for the diagnosis and treatment of colorectal cancer. Despite deep learning methods advance automatic polyp segmentation, their performance often degrades when applied to new data acquired from different scanners or sequences (target domain). As manual annotation is tedious and labor-intensive for new target domain, leveraging knowledge learned from the labeled source domain to promote the performance in the unlabeled target domain is highly demanded. In this work, we propose a mutual-prototype adaptation network to eliminate domain shifts in multi-centers and multi-devices colonoscopy images. We first devise a mutual-prototype alignment (MPA) module with the prototype relation function to refine features through self-domain and cross-domain information in a coarse-to-fine process. Then two auxiliary modules: progressive self-training (PST) and disentangled reconstruction (DR) are proposed to improve the segmentation performance. The PST module selects reliable pseudo labels through a novel uncertainty guided self-training loss to obtain accurate prototypes in the target domain. The DR module reconstructs original images jointly utilizing prediction results and private prototypes to maintain semantic consistency and provide complement supervision information. We extensively evaluate the proposed model in polyp segmentation performance on three conventional colonoscopy datasets: CVC-DB, Kvasir-SEG, and ETIS-Larib. The comprehensive experimental results demonstrate that the proposed model outperforms state-of-the-art methods.
C1 [Yang, Chen; Guo, Xiaoqing; Zhu, Meilu; Yuan, Yixuan] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Ibragimov, Bulat] Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen, Denmark.
C3 City University of Hong Kong; University of Copenhagen
RP Yuan, YX (通讯作者)，City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM cyang.ee@my.cityu.edu.hk; xqguo.ee@my.cityu.edu.hk;
   meiluzhu2@cityu.edu.hk; ibbulat@gmail.com; yxyuan.ee@cityu.edu.hk
RI Zhu, Meilu/CAI-0127-2022
OI Zhu, Meilu/0000-0002-5563-7282; Yuan, Yixuan/0000-0002-0853-6948; GUO,
   Xiaoqing/0000-0002-9476-521X; YANG, Chen/0000-0001-7841-5300; Ibragimov,
   Bulat/0000-0001-7739-7788
FU Hong Kong Research Grants Council (RGC) Early Career Scheme [21207420
   (CityU 9048179)]; Hong Kong RGC Collaborative Research Fund [C4063-18 G
   (CityU 8739029)]; National Natural Science Foundation of China
   [62001410]
FX This work was supported in part by Hong Kong Research Grants Council
   (RGC) Early Career Scheme under Grant 21207420 (CityU 9048179), in part
   by Hong Kong RGC Collaborative Research Fund under Grant C4063-18 G
   (CityU 8739029), and in part by the National Natural Science Foundation
   of China under Grant 62001410.
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Chang WL, 2019, PROC CVPR IEEE, P1900, DOI 10.1109/CVPR.2019.00200
   Chen CQ, 2019, PROC CVPR IEEE, P627, DOI 10.1109/CVPR.2019.00072
   Chen C, 2020, IEEE T MED IMAGING, V39, P2494, DOI 10.1109/TMI.2020.2972701
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen MH, 2019, IEEE I CONF COMP VIS, P2090, DOI 10.1109/ICCV.2019.00218
   Chen YH, 2019, PROC CVPR IEEE, P1841, DOI 10.1109/CVPR.2019.00194
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Ganin Y, 2016, J MACH LEARN RES, V17
   Guo XQ, 2019, LECT NOTES COMPUT SC, V11764, P293, DOI 10.1007/978-3-030-32239-7_33
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Huo YK, 2019, IEEE T MED IMAGING, V38, P1016, DOI 10.1109/TMI.2018.2876633
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Jinyu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P480, DOI 10.1007/978-3-030-58583-9_29
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Pan F, 2020, PROC CVPR IEEE, P3763, DOI 10.1109/CVPR42600.2020.00382
   Pan YW, 2019, PROC CVPR IEEE, P2234, DOI 10.1109/CVPR.2019.00234
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P3752, DOI 10.1109/CVPR.2018.00395
   Shu Y., 2019, AAAI CONF ARTIF INTE, V33, P4951
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI [DOI 10.3322/CAAC.21442, 10.3322/caac.21332]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tran L, 2019, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2019.00278
   Tsai YH, 2019, IEEE I CONF COMP VIS, P1456, DOI 10.1109/ICCV.2019.00154
   Xie X., P INT C MED IM COMP, P516
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yang YC, 2020, PROC CVPR IEEE, P4084, DOI 10.1109/CVPR42600.2020.00414
   Yuan YX, 2018, LECT NOTES COMPUT SC, V11071, P620, DOI 10.1007/978-3-030-00934-2_69
   Yunsheng Li, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P6929, DOI 10.1109/CVPR.2019.00710
   Zhang YF, 2019, LECT NOTES COMPUT SC, V11764, P360, DOI 10.1007/978-3-030-32239-7_40
   Zhang ZZ, 2018, PROC CVPR IEEE, P9242, DOI 10.1109/CVPR.2018.00963
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_18, 10.1007/978-3-030-01219-9_]
NR 42
TC 9
Z9 9
U1 3
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD OCT
PY 2021
VL 25
IS 10
BP 3886
EP 3897
DI 10.1109/JBHI.2021.3077271
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA WC2SH
UT WOS:000704111100025
PM 33945490
DA 2023-08-21
ER

PT J
AU Yao, P
   Usman, M
   Chen, YH
   German, A
   Andreadis, K
   Mages, K
   Rameau, A
AF Yao, Peter
   Usman, Moon
   Chen, Yu H.
   German, Alexander
   Andreadis, Katerina
   Mages, Keith
   Rameau, Anais
TI Applications of Artificial Intelligence to Office Laryngoscopy: A
   Scoping Review
SO LARYNGOSCOPE
LA English
DT Review
DE Laryngology; artificial intelligence; laryngoscopy; scoping review
ID DEEP; CLASSIFICATION; FUTURE
AB Objectives/Hypothesis This scoping review aims to provide a broad overview of the applications of artificial intelligence (AI) to office laryngoscopy to identify gaps in knowledge and guide future research. Study Design Scoping Review. Methods Searches for studies on AI and office laryngoscopy were conducted in five databases. Title and abstract and then full-text screening were performed. Primary research studies published in English of any date were included. Studies were summarized by: AI applications, targeted conditions, imaging modalities, author affiliations, and dataset characteristics. Results Studies focused on vocal fold vibration analysis (43%), lesion recognition (24%), and vocal fold movement determination (19%). The most frequently automated tasks were recognition of vocal fold nodules (19%), polyp (14%), paralysis (11%), paresis (8%), and cyst (7%). Imaging modalities included high-speed laryngeal videos (45%), stroboscopy (29%), and narrow band imaging endoscopy (7%). The body of literature was primarily authored by science, technology, engineering, and math (STEM) specialists (76%) with only 30 studies (31%) involving co-authorship by STEM specialists and otolaryngologists. Datasets were mostly from single institution (84%) and most commonly originated from Germany (23%), USA (16%), Spain (9%), Italy (8%), and China (8%). Demographic information was only reported in 39 studies (40%), with age and sex being the most commonly reported, whereas race/ethnicity and gender were not reported in any studies. Conclusion More interdisciplinary collaboration between STEM and otolaryngology research teams improved demographic reporting especially of race and ethnicity to ensure broad representation, and larger and more geographically diverse datasets will be crucial to future research on AI in office laryngoscopy. Level of Evidence N/A Laryngoscope, 2021
C1 [Yao, Peter; Usman, Moon; Chen, Yu H.; German, Alexander; Andreadis, Katerina; Mages, Keith; Rameau, Anais] Weill Cornell Med, Dept Otolaryngol Head & Neck Surg, Sean Parker Inst Voice, 240 East 59th St, New York, NY 10022 USA.
C3 Cornell University; Weill Cornell Medicine
RP Rameau, A (通讯作者)，Weill Cornell Med, Dept Otolaryngol Head & Neck Surg, Sean Parker Inst Voice, 240 East 59th St, New York, NY 10022 USA.
EM anr2783@med.cornell.edu
RI Andreadis, Katerina/ITU-0700-2023; Mages, Keith/HJA-7849-2022
OI Andreadis, Katerina/0000-0001-8586-450X; Yao, Peter/0000-0002-1127-9030
CR Adamian N, 2021, LARYNGOSCOPE, V131, pE219, DOI 10.1002/lary.28669
   Blasimme A, 2018, HEALTH AFFAIR, V37, P702, DOI 10.1377/hlthaff.2017.1558
   Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230
   Crowson MG, 2020, LARYNGOSCOPE, V130, P45, DOI 10.1002/lary.27850
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fagan JJ, 2009, GLOBAL HEALTH ACTION, V2, DOI 10.3402/gha.v2i0.1932
   FDA, FDA AUTH MARK 1 DEV
   Galdran A, 2019, I S BIOMED IMAGING, P87, DOI 10.1109/ISBI.2019.8759511
   Gomez P, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0526-3
   Gomez P, 2019, MED BIOL ENG COMPUT, V57, P1451, DOI 10.1007/s11517-019-01965-4
   Gonzalez RC., 2017, DIGITAL IMAGE PROCES
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hughes CA, 2016, LARYNGOSCOPE, V126, pS5, DOI 10.1002/lary.26238
   Larrazabal AJ, 2020, P NATL ACAD SCI USA, V117, P12592, DOI 10.1073/pnas.1919012117
   Lohscheller J, 2007, MED IMAGE ANAL, V11, P400, DOI 10.1016/j.media.2007.04.005
   Moccia S, 2018, COMPUT METH PROG BIO, V158, P21, DOI 10.1016/j.cmpb.2018.01.030
   Obermeyer Z, 2016, NEW ENGL J MED, V375, P1216, DOI 10.1056/NEJMp1606181
   Paderno A, 2021, CURR OPIN OTOLARYNGO, V29, P143, DOI 10.1097/MOO.0000000000000697
   Ren JJ, 2020, LARYNGOSCOPE, V130, pE686, DOI 10.1002/lary.28539
   Shankar S, 2017, NO CLASSIFICATION RE
   Ta NH, 2019, ANN ROY COLL SURG, V101, P93, DOI 10.1308/rcsann.2018.0138
   Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850
   Vickery TW, 2016, ENT-EAR NOSE THROAT, V95, P218, DOI 10.1177/014556131609500607
   Wang F, 2019, JAMA INTERN MED, V179, P293, DOI 10.1001/jamainternmed.2018.7117
   Xiong H, 2019, EBIOMEDICINE, V48, P92, DOI 10.1016/j.ebiom.2019.08.075
   Zou J, 2018, NATURE, V559, P324, DOI 10.1038/d41586-018-05707-8
NR 27
TC 11
Z9 11
U1 2
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-852X
EI 1531-4995
J9 LARYNGOSCOPE
JI Laryngoscope
PD OCT
PY 2022
VL 132
IS 10
BP 1993
EP 2016
DI 10.1002/lary.29886
EA SEP 2021
PG 24
WC Medicine, Research & Experimental; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine; Otorhinolaryngology
GA 4L5UV
UT WOS:000700508000001
PM 34582043
DA 2023-08-21
ER

PT J
AU Kader, R
   Hadjinicolaou, AV
   Georgiades, F
   Stoyanov, D
   Lovat, LB
AF Kader, Rawen
   Hadjinicolaou, Andreas, V
   Georgiades, Fanourios
   Stoyanov, Danail
   Lovat, Laurence B.
TI Optical diagnosis of colorectal polyps using convolutional neural
   networks
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Artificial intelligence; Deep learning; Convolutional neural networks;
   Computer aided diagnosis; Optical diagnosis; Colorectal polyps
ID ARTIFICIAL-INTELLIGENCE; GASTROINTESTINAL ENDOSCOPY; ACCURACY;
   CLASSIFICATION; POLYPECTOMY; COLONOSCOPY; HISTOLOGY; MAGNIFICATION;
   RESECTION; RISK
AB Colonoscopy remains the gold standard investigation for colorectal cancer screening as it offers the opportunity to both detect and resect pre-malignant and neoplastic polyps. Although technologies for image-enhanced endoscopy are widely available, optical diagnosis has not been incorporated into routine clinical practice, mainly due to significant inter-operator variability. In recent years, there has been a growing number of studies demonstrating the potential of convolutional neural networks (CNN) to enhance optical diagnosis of polyps. Data suggest that the use of CNNs might mitigate the inter-operator variability amongst endoscopists, potentially enabling a "resect and discard " or "leave in " strategy to be adopted in real-time. This would have significant financial benefits for healthcare systems, avoid unnecessary polypectomies of non-neoplastic polyps and improve the efficiency of colonoscopy. Here, we review advances in CNN for the optical diagnosis of colorectal polyps, current limitations and future directions.
C1 [Kader, Rawen; Stoyanov, Danail; Lovat, Laurence B.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, Charles Bell House,43-45 Foley St, London W1W 7TY, England.
   [Kader, Rawen; Lovat, Laurence B.] UCL, Div Surg & Intervent Sci, London W1W 7TY, England.
   [Hadjinicolaou, Andreas, V] Univ Cambridge, MRC Canc Unit, Dept Gastroenterol, Cambridge CB2 0QQ, England.
   [Georgiades, Fanourios] Univ Cambridge, Dept Surg, Cambridge CB2 0QQ, England.
   [Stoyanov, Danail] UCL, Dept Comp Sci, London W1W 7TY, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London; University of London; University College London; University of
   Cambridge; University of Cambridge; University of London; University
   College London
RP Kader, R (通讯作者)，UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, Charles Bell House,43-45 Foley St, London W1W 7TY, England.
EM r.kader@nhs.net
RI Georgiades, Fanourios/ABE-3638-2020; Kader, Rawen/ABI-2203-2020; Lovat,
   Laurence/C-1986-2009
OI Georgiades, Fanourios/0000-0003-0440-2720; Kader,
   Rawen/0000-0001-9133-0838; Lovat, Laurence/0000-0003-4542-3915;
   Hadjinicolaou, Andreas V/0000-0002-6520-443X
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Ahmad OF, 2021, ENDOSCOPY, V53, P893, DOI 10.1055/a-1306-7590
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   El Hajjar A, 2020, CHINESE MED J-PEKING, V133, P326, DOI 10.1097/CM9.0000000000000623
   Ignjatovic A, 2011, GASTROINTEST ENDOSC, V73, P128, DOI 10.1016/j.gie.2010.09.021
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Namikawa K, 2020, EXPERT REV GASTROENT, V14, P689, DOI 10.1080/17474124.2020.1779058
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Pannala Rahul, 2020, VideoGIE, V5, P598, DOI 10.1016/j.vgie.2020.08.013
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Repici A, 2013, GASTROINTEST ENDOSC, V78, P106, DOI 10.1016/j.gie.2013.01.035
   Rex DK., 2019, TECH GASTROINTEST EN
   Rex DK, 2009, AM J GASTROENTEROL, V104, P149, DOI 10.1038/ajg.2008.35
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Rutter MD, 2020, GUT, V69, P201, DOI 10.1136/gutjnl-2019-319858
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Sharma P, 2020, GASTROINTEST ENDOSC, V91, P925, DOI 10.1016/j.gie.2019.12.018
   Singh R, 2013, DIGEST ENDOSC, V25, P16, DOI 10.1111/den.12075
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Song MY, 2020, LANCET GASTROENTEROL, V5, P537, DOI 10.1016/S2468-1253(20)30009-1
   Vakli P, 2018, GIGASCIENCE, V7, DOI 10.1093/gigascience/giy130
   van der Sommen F, 2020, GUT, V69, P2035, DOI 10.1136/gutjnl-2019-320466
   van der Zander QEW, 2021, ENDOSCOPY, V53, P1219, DOI 10.1055/a-1343-1597
   Wallace MB, 2014, GASTROINTEST ENDOSC, V80, P1072, DOI 10.1016/j.gie.2014.05.305
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 39
TC 3
Z9 3
U1 3
U2 10
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD SEP 21
PY 2021
VL 27
IS 35
DI 10.3748/wjg.v27.i35.5908
PG 12
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA UZ9LA
UT WOS:000702519000006
PM 34629808
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Nogueira-Rodriguez, A
   Dominguez-Carbajales, R
   Campos-Tato, F
   Herrero, J
   Puga, M
   Remedios, D
   Rivas, L
   Sanchez, E
   Iglesias, A
   Cubiella, J
   Fdez-Riverola, F
   Lopez-Fernandez, H
   Reboiro-Jato, M
   Glez-Pena, D
AF Nogueira-Rodriguez, Alba
   Dominguez-Carbajales, Ruben
   Campos-Tato, Fernando
   Herrero, Jesus
   Puga, Manuel
   Remedios, David
   Rivas, Laura
   Sanchez, Eloy
   Iglesias, Agueda
   Cubiella, Joaquin
   Fdez-Riverola, Florentino
   Lopez-Fernandez, Hugo
   Reboiro-Jato, Miguel
   Glez-Pena, Daniel
TI Real-time polyp detection model using convolutional neural networks
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Colorectal cancer; Polyp detection; Deep learning; Real time
ID COMPUTER-AIDED DETECTION; COLORECTAL-CANCER; ADENOMA DETECTION;
   ARTIFICIAL-INTELLIGENCE; DETECTION SYSTEM; COLONOSCOPY; PERFORMANCE;
   VALIDATION; INCREASES
AB Colorectal cancer is a major health problem, where advances towards computer-aided diagnosis (CAD) systems to assist the endoscopist can be a promising path to improvement. Here, a deep learning model for real-time polyp detection based on a pre-trained YOLOv3 (You Only Look Once) architecture and complemented with a post-processing step based on an object-tracking algorithm to reduce false positives is reported. The base YOLOv3 network was fine-tuned using a dataset composed of 28,576 images labelled with locations of 941 polyps that will be made public soon. In a frame-based evaluation using isolated images containing polyps, a general F-1 score of 0.88 was achieved (recall = 0.87, precision = 0.89), with lower predictive performance in flat polyps, but higher for sessile, and pedunculated morphologies, as well as with the usage of narrow band imaging, whereas polyp size < 5 mm does not seem to have significant impact. In a polyp-based evaluation using polyp and normal mucosa videos, with a positive criterion defined as the presence of at least one 50-frames-length (window size) segment with a ratio of 75% of frames with predicted bounding boxes (frames positivity), 72.61% of sensitivity (95% CI 68.99-75.95) and 83.04% of specificity (95% CI 76.70-87.92) were achieved (Youden = 0.55, diagnostic odds ratio (DOR) = 12.98). When the positive criterion is less stringent (window size = 25, frames positivity = 50%), sensitivity reaches around 90% (sensitivity = 89.91%, 95% CI 87.20-91.94; specificity = 54.97%, 95% CI 47.49-62.24; Youden = 0.45; DOR = 10.76). The object-tracking algorithm has demonstrated a significant improvement in specificity whereas maintaining sensitivity, as well as a marginal impact on computational performance. These results suggest that the model could be effectively integrated into a CAD system.
C1 [Nogueira-Rodriguez, Alba; Campos-Tato, Fernando; Fdez-Riverola, Florentino; Lopez-Fernandez, Hugo; Reboiro-Jato, Miguel; Glez-Pena, Daniel] Univ Vigo, CINBIO, Dept Comp Sci, ESEI Escuela Super Ingn Informat, Orense 32004, Spain.
   [Nogueira-Rodriguez, Alba; Fdez-Riverola, Florentino; Lopez-Fernandez, Hugo; Reboiro-Jato, Miguel; Glez-Pena, Daniel] SERGAS UVIGO, Galicia Sur Hlth Res Inst IIS Galicia Sur, SING Res Grp, Vigo, Spain.
   [Dominguez-Carbajales, Ruben] Complexo Hosp Univ Ourense, Serv Sistemas & Tecnol Informac, Orense, Spain.
   [Herrero, Jesus; Puga, Manuel; Remedios, David; Rivas, Laura; Sanchez, Eloy; Iglesias, Agueda; Cubiella, Joaquin] Complexo Hosp Univ Ourense, Ctr Invest Biomed Red Enfermedades Hepat & Digest, Inst Invest Sanitaria Galicia Sur, Dept Gastroenterol, Orense, Spain.
   [Lopez-Fernandez, Hugo] Univ Porto, Inst Invest & Inovaedo Saude I3S, Rua Alfredo Allen 208, P-4200135 Porto, Portugal.
   [Lopez-Fernandez, Hugo] Inst Biol Mol & Celular IBMC, Rua Alfredo Allen 208, P-4200135 Porto, Portugal.
C3 Universidade de Vigo; Complexo Hospitalario Universitario de Ourense,
   Verin e O Barco de Valdeorras; CIBER - Centro de Investigacion Biomedica
   en Red; CIBEREHD; Complexo Hospitalario Universitario de Ourense, Verin
   e O Barco de Valdeorras; Universidade do Porto; i3S - Instituto de
   Investigacao e Inovacao em Saude, Universidade do Porto; Universidade do
   Porto
RP Glez-Pena, D (通讯作者)，Univ Vigo, CINBIO, Dept Comp Sci, ESEI Escuela Super Ingn Informat, Orense 32004, Spain.; Glez-Pena, D (通讯作者)，SERGAS UVIGO, Galicia Sur Hlth Res Inst IIS Galicia Sur, SING Res Grp, Vigo, Spain.
EM dgpena@uvigo.es
RI Fdez-Riverola, Florentino/G-1411-2011; CUBIELLA, JOAQUIN/G-7692-2017;
   Rodríguez, Alba Nogueira/AAO-9957-2020; Reboiro-Jato,
   Miguel/AAB-8453-2022; Glez-Peña, Daniel/D-5922-2014; Reboiro-Jato,
   Miguel/G-1102-2011; Lopez-Fernandez, Hugo/H-7558-2017
OI Fdez-Riverola, Florentino/0000-0002-3943-8013; CUBIELLA,
   JOAQUIN/0000-0002-9994-4831; Rodríguez, Alba
   Nogueira/0000-0001-5991-7698; Reboiro-Jato, Miguel/0000-0001-8749-2703;
   Glez-Peña, Daniel/0000-0002-6129-7245; Reboiro-Jato,
   Miguel/0000-0001-8749-2703; Sanchez Hernandez, Eloy/0000-0003-2493-8303;
   Lopez-Fernandez, Hugo/0000-0002-6476-7206; Puga,
   Manuel/0000-0003-4898-3889; , IIS Galicia Sur/0000-0003-3812-7413; Rivas
   Moral, Laura/0000-0001-5486-8727; Dominguez Carbajales,
   Ruben/0000-0003-3405-2389
FU Ministerio de Economia, Industria y Competitividad, Gobierno de Espana
   [DPI2017-87494-R]; Conselleria de Educacion, Universidades e Formacion
   Profesional (Xunta de Galicia) [ED431C2018/55-GRC]; Competitive
   Reference Group; individual scientific employment program-contract with
   Hugo Lopez-Fernandez [2020.00515.CEECIND]; pre-doctoral fellowship from
   Xunta de Galicia [ED481A-2019/299]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. Funding for open access charge: Universidade de
   Vigo/CISUG. This work was partially supported by Ministerio de Economia,
   Industria y Competitividad, Gobierno de Espana under the scope of the
   PolyDeep project (DPI2017-87494-R), by Conselleria de Educacion,
   Universidades e Formacion Profesional (Xunta de Galicia) under the scope
   of the strategic funding ED431C2018/55-GRC Competitive Reference Group,
   and through the individual scientific employment program-contract with
   Hugo Lopez-Fernandez (2020.00515.CEECIND). A. Nogueira-Rodriguez is
   supported by a pre-doctoral fellowship from Xunta de Galicia
   (ED481A-2019/299). SING group thanks the CITI (Centro de Investigacion,
   Transferencia e Innovacion) from the University of Vigo for hosting its
   IT infrastructure.
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Ashat M, 2021, ENDOSC INT OPEN, V09, pE513, DOI 10.1055/a-1341-0457
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Azer SA, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55080473
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED, DOI DOI 10.48550/ARXIV.2004.10934
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Cubiella J, 2020, RES SQ, DOI 10.21203/rs.3.rs-113901/v1
   Cubiella J, 2020, CANCERS, V12, DOI 10.3390/cancers12092530
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Liu X, 2019, SPRINGER THESES-RECO, P1, DOI 10.1007/978-981-13-8703-6
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Lopez-Fernandez H, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.593
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Ma M, 2020, I S BIOMED IMAGING, P1360, DOI 10.1109/ISBI45749.2020.9098663
   Ma Y., 2019, PROC 8 INT S NEXT GE, P1, DOI [10.1109/ISNE.2019.8896576, DOI 10.1109/ISNE.2019.8896576]
   Misawa M, 2019, GASTROINTEST ENDOSC, V89, pAB646, DOI 10.1016/j.gie.2019.03.1134
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Nelson, JUN 10 JS READ 2020
   Nogueira-Rodriguez A., 2021, PRACTICAL APPL COMPU, P51, DOI DOI 10.1007/978-3-030-54568-0_6
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Pannala R., 2020, ARTIF INTELL GASTROI, V5, P598, DOI [10.1016/j.vgie.2020.08.013, DOI 10.1016/J.VGIE.2020.08.013]
   Paszke A, 2019, ADV NEUR IN, V32
   QADIR H, 2021, MED IMAGE ANAL, V68
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Redmon J, 2018, ARXIV180402767CS
   REDMON J, 2016, PROC CVPR IEEE, P779, DOI DOI 10.1109/CVPR.2016.91
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Sanchez-Montes C, 2020, GASTROENT HEPAT-BARC, V43, P222, DOI 10.1016/j.gastrohep.2019.11.004
   Sanchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Seide F, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2135, DOI 10.1145/2939672.2945397
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tian Y, 2019, I S BIOMED IMAGING, P70
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang LS, 2018, GUT, V67, pA85, DOI 10.1136/gutjnl-2018-IDDFabstracts.182
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wiegering A, 2016, INT J COLORECTAL DIS, V31, P1039, DOI 10.1007/s00384-015-2501-6
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI [10.1109/TNNLS.2018.2876865, 10.23977/icamcs.2018.001]
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 67
TC 18
Z9 18
U1 3
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUL
PY 2022
VL 34
IS 13
SI SI
BP 10375
EP 10396
DI 10.1007/s00521-021-06496-4
EA SEP 2021
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2J4QQ
UT WOS:000698042500001
OA hybrid
DA 2023-08-21
ER

PT J
AU Yeung, M
   Sala, E
   Schonlieb, CB
   Rundo, L
AF Yeung, Michael
   Sala, Evis
   Schonlieb, Carola-Bibiane
   Rundo, Leonardo
TI Focus U-Net: A novel dual attention-gated CNN for polyp segmentation
   during colonoscopy
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp segmentation; Colorectal cancer; Colonoscopy; Computer-aided
   diagnosis; Focus U-Net; Attention mechanisms; Loss function
ID COLORECTAL-CANCER; MISS RATE; NETWORKS; RISK
AB Background: Colonoscopy remains the gold-standard screening for colorectal cancer. However, significant miss rates for polyps have been reported, particularly when there are multiple small adenomas. This presents an opportunity to leverage computer-aided systems to support clinicians and reduce the number of polyps missed. Method: In this work we introduce the Focus U-Net, a novel dual attention-gated deep neural network, which combines efficient spatial and channel-based attention into a single Focus Gate module to encourage selective learning of polyp features. The Focus U-Net incorporates several further architectural modifications, including the addition of short-range skip connections and deep supervision. Furthermore, we introduce the Hybrid Focal loss, a new compound loss function based on the Focal loss and Focal Tversky loss, designed to handle classimbalanced image segmentation. For our experiments, we selected five public datasets containing images of polyps obtained during optical colonoscopy: CVC-ClinicDB, Kvasir-SEG, CVC-ColonDB, ETIS-Larib PolypDB and EndoScene test set. We first perform a series of ablation studies and then evaluate the Focus U-Net on the CVCClinicDB and Kvasir-SEG datasets separately, and on a combined dataset of all five public datasets. To evaluate model performance, we use the Dice similarity coefficient (DSC) and Intersection over Union (IoU) metrics. Results: Our model achieves state-of-the-art results for both CVC-ClinicDB and Kvasir-SEG, with a mean DSC of 0.941 and 0.910, respectively. When evaluated on a combination of five public polyp datasets, our model similarly achieves state-of-the-art results with a mean DSC of 0.878 and mean IoU of 0.809, a 14% and 15% improvement over the previous state-of-the-art results of 0.768 and 0.702, respectively. Conclusions: This study shows the potential for deep learning to provide fast and accurate polyp segmentation results for use during colonoscopy. The Focus U-Net may be adapted for future use in newer non-invasive colorectal cancer screening and more broadly to other biomedical image segmentation tasks similarly involving class imbalance and requiring efficiency.
C1 [Yeung, Michael; Sala, Evis; Rundo, Leonardo] Univ Cambridge, Dept Radiol, Box 218,Cambridge Biomed Campus, Cambridge CB2 0QQ, England.
   [Yeung, Michael] Univ Cambridge, Sch Clin Med, Cambridge CB2 0SP, England.
   [Sala, Evis; Rundo, Leonardo] Univ Cambridge, Canc Res UK Cambridge Ctr, Cambridge CB2 0RE, England.
   [Schonlieb, Carola-Bibiane] Univ Cambridge, Dept Appl Math & Theoret Phys, Cambridge CB3 0WA, England.
C3 University of Cambridge; University of Cambridge; Cancer Research UK;
   CRUK Cambridge Institute; University of Cambridge; University of
   Cambridge
RP Yeung, M; Rundo, L (通讯作者)，Univ Cambridge, Dept Radiol, Box 218,Cambridge Biomed Campus, Cambridge CB2 0QQ, England.
EM mjyy2@cam.ac.uk; es220@medschl.cam.ac.uk; cbs31@cam.ac.uk;
   lr495@cam.ac.uk
RI Rundo, Leonardo/AAF-3999-2019
OI Rundo, Leonardo/0000-0003-3341-5483; Yeung, Michael/0000-0001-8700-9144
FU Mark Foundation for Cancer Research [C9685/A25177]; Cancer Research UK
   Cambridge Centre [C9685/A25177]; CRUK National Cancer Imaging
   Translational Accelerator (NCITA) [C42780/A27066]; Wellcome Trust
   Innovator Award, United Kingdom [215733/Z/19/Z]; National Institute of
   Health Research (NIHR) Cambridge Biomedical Research Centre
   [BRC-1215-20014]; Cambridge Mathematics of Information in Healthcare
   (CMIH) [EPSRC] [EP/T017961/1]; Leverhulme Trust; Philip Leverhulme
   Prize; Royal Society Wolfson Fellowship; EPSRC [EP/S026045/1,
   EP/N014588/1]; European Union Horizon 2020 research and innovation
   programmes under the Marie Skodowska-Curie grant [777826, 691070];
   Cantab Capital Institute for the Mathematics of Information; Alan Turing
   Institute; Engineering and Physical Sciences Research Council
   [EP/P020259/1]; Science and Technology Facilities Council; Engineering
   and Physical Sciences Research Council [EP/T017961/1, EP/S026045/1,
   EP/N014588/1, EP/P020259/1] Funding Source: researchfish; Wellcome Trust
   [215733/Z/19/Z] Funding Source: Wellcome Trust
FX This work was partially supported by The Mark Foundation for Cancer
   Research and Cancer Research UK Cambridge Centre [C9685/A25177], the
   CRUK National Cancer Imaging Translational Accelerator (NCITA)
   [C42780/A27066] and the Wellcome Trust Innovator Award, United Kingdom
   [215733/Z/19/Z]. Additional support was also provided by the National
   Institute of Health Research (NIHR) Cambridge Biomedical Research Centre
   [BRC-1215-20014] and the Cambridge Mathematics of Information in
   Healthcare (CMIH) [funded by the EPSRC grant EP/T017961/1]. The views
   expressed are those of the authors and not necessarily those of the NHS,
   the NIHR, or the Department of Health and Social Care.; CBS in addition
   acknowledges support from the Leverhulme Trust project on 'Breaking the
   non-convexity barrier', the Philip Leverhulme Prize, the Royal Society
   Wolfson Fellowship, the EPSRC grants EP/S026045/1, EP/N014588/1,
   European Union Horizon 2020 research and innovation programmes under the
   Marie Skodowska-Curie grant agreement No. 777826 NoMADS and No. 691070
   CHiPS, the Cantab Capital Institute for the Mathematics of Information
   and the Alan Turing Institute.; This work was performed using resources
   provided by the Cambridge Service for Data Driven Discovery (CSD3)
   operated by the University of Cambridge Research Computing Service
   (www.csd3.cam.ac.uk), provided by Dell EMC and Intel using Tier-2
   funding from the Engineering and Physical Sciences Research Council
   (capital grant EP/P020259/1), and DiRAC funding from the Science and
   Technology Facilities Council (www.dirac.ac.uk).
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Bahdanau D., ARXIV PREPRINT ARXIV
   Banik Debapriya, 2020, Advanced Computing and Systems for Security. Volume Twelve. Advances in Intelligent Systems and Computing (AISC 1136), P109, DOI 10.1007/978-981-15-2930-6_9
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brauer C, 2018, EUR RADIOL, V28, P4766, DOI 10.1007/s00330-018-5416-0
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Brenner H, 2007, GUT, V56, P1585, DOI 10.1136/gut.2007.122739
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Chen S., COMPUT BIOL MED
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dou Q, 2017, MED IMAGE ANAL, V41, P40, DOI 10.1016/j.media.2017.05.001
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao Z., 2019, P IEEE CVF C COMP VI, P3024
   Glorot X., 2010, PROC 13 INT C ARTIFI, V9, P249, DOI DOI 10.1177/1753193409103364.
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Han CHE, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-020-03936-1
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C.H., 2021, ARXIV PREPRINT ARXIV
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Issa IA, 2017, WORLD J GASTROENTERO, V23, P5086, DOI 10.3748/wjg.v23.i28.5086
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Ji G.-P., ARXIV PREPRINT ARXIV
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   Kuntz KM, 2011, MED DECIS MAKING, V31, P530, DOI 10.1177/0272989X11408730
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Liang-Chieh Chen, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11211), P833, DOI 10.1007/978-3-030-01234-2_49
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luong M.-T., 2015, ARXIV
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Mori Y., 2020, CURR TREAT OPTIONS G, V18, P200, DOI [10.1007/s11938-020-00287-x, DOI 10.1007/S11938-020-00287-X]
   Muller D, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-020-00543-7
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Oktay O., 2018, ARXIV
   Pascanu R., 2013, P INT C MACHINE LEAR, P1310
   Poorneshwaran JM, 2019, IEEE ENG MED BIO, P7201, DOI 10.1109/EMBC.2019.8857958
   Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155
   Rawla P, 2019, GASTROENTEROL REV, V14, P89, DOI 10.5114/pg.2018.81072
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Rundo L, 2019, NEUROCOMPUTING, V365, P31, DOI 10.1016/j.neucom.2019.07.006
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Salehi SSM, 2017, LECT NOTES COMPUT SC, V10541, P379, DOI 10.1007/978-3-319-67389-9_44
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Schreuders EH, 2015, GUT, V64, P1637, DOI 10.1136/gutjnl-2014-309086
   Shen T, 2018, AAAI CONF ARTIF INTE, P5446
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Summers RM, 2005, GASTROENTEROLOGY, V129, P1832, DOI 10.1053/j.gastro.2005.08.054
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tagliarini G., 1987, P ADV NEUR INF PROC, P775
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Thakkar S, 2020, GASTROENTEROLOGY, V158, P1219, DOI 10.1053/j.gastro.2019.12.035
   Tomar N. K., ARXIV PREPRINT ARXIV
   Torr, 2018, ARXIV PREPRINT ARXIV
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vaswani A, 2017, ADV NEUR IN, V30
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang J., IEEE T PATTERN ANAL
   Wang ZK, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104449
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yeung M., ARXIV PREPRINT ARXIV
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 83
TC 45
Z9 45
U1 7
U2 30
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD OCT
PY 2021
VL 137
AR 104815
DI 10.1016/j.compbiomed.2021.104815
EA SEP 2021
PG 11
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA WC6EK
UT WOS:000704349100004
PM 34507156
OA hybrid, Green Published, Green Submitted
DA 2023-08-21
ER

PT J
AU Xu, L
   He, XJ
   Zhou, JB
   Zhang, J
   Mao, XL
   Ye, GL
   Chen, Q
   Xu, F
   Sang, JZ
   Wang, J
   Ding, Y
   Li, YM
   Yu, CH
AF Xu, Lei
   He, Xinjue
   Zhou, Jianbo
   Zhang, Jie
   Mao, Xinli
   Ye, Guoliang
   Chen, Qiang
   Xu, Feng
   Sang, Jianzhong
   Wang, Jun
   Ding, Yong
   Li, Youming
   Yu, Chaohui
TI Artificial intelligence-assisted colonoscopy: A prospective,
   multicenter, randomized controlled trial of polyp detection
SO CANCER MEDICINE
LA English
DT Article
DE artificial intelligence; cancer prevention; colorectal polyps;
   endoscopy; image analysis
ID ADENOMA DETECTION; MISS RATE; COLORECTAL ADENOMAS; QUALITY INDICATORS;
   CANCER; POLYPECTOMY; SYSTEM; RISK
AB Background Artificial intelligence (AI) assistance has been considered as a promising way to improve colonoscopic polyp detection, but there are limited prospective studies on real-time use of AI systems. Methods We conducted a prospective, multicenter, randomized controlled trial of patients undergoing colonoscopy at six centers. Eligible patients were randomly assigned to conventional colonoscopy (control group) or AI-assisted colonoscopy (AI group). AI assistance was our newly developed AI system for real-time colonoscopic polyp detection. Primary outcome is polyp detection rate (PDR). Secondary outcomes include polyps per positive patient (PPP), polyps per colonoscopy (PPC), and non-first polyps per colonoscopy (PPC-Plus). Results A total of 2352 patients were included in the final analysis. Compared with the control, AI group did not show significant increment in PDR (38.8% vs. 36.2%, p = 0.183), but its PPC-Plus was significantly higher (0.5 vs. 0.4, p < 0.05). In addition, AI group detected more diminutive polyps (76.0% vs. 68.8%, p < 0.01) and flat polyps (5.9% vs. 3.3%, p < 0.05). The effects varied somewhat between centers. In further logistic regression analysis, AI assistance independently contributed to the increment of PDR, and the impact was more pronounced for male endoscopists, shorter insertion time but longer withdrawal time, and elderly patients with larger waist circumference. Conclusion The intervention of AI plays a limited role in overall polyp detection, but increases detection of easily missed polyps; ChiCTR.org.cn number, ChiCTR1800015607.
C1 [Xu, Lei] Zhejiang Univ, Ningbo Hosp, Dept Gastroenterol, Ningbo, Peoples R China.
   [He, Xinjue; Zhang, Jie; Li, Youming; Yu, Chaohui] Zhejiang Univ, Affiliated Hosp 1, Coll Med, Dept Gastroenterol, 79 Qingchun Rd, Hangzhou 310003, Zhejiang, Peoples R China.
   [Zhou, Jianbo; Sang, Jianzhong] Yuyao Peoples Hosp Zhejiang Prov, Dept Gastroenterol, Yuyao, Peoples R China.
   [Mao, Xinli; Wang, Jun] Taizhou Hosp Zhejiang Prov, Dept Gastroenterol, Linhai, Peoples R China.
   [Ye, Guoliang; Ding, Yong] Ningbo Univ, Affiliated Hosp, Med Sch, Dept Gastroenterol, Ningbo, Peoples R China.
   [Chen, Qiang] Sanmen Peoples Hosp, Dept Gastroenterol, Taizhou, Peoples R China.
   [Xu, Feng] Ningbo Yinzhou Peoples Hosp, Dept Gastroenterol, Ningbo, Peoples R China.
C3 Zhejiang University; Zhejiang University; Ningbo University
RP Yu, CH (通讯作者)，Zhejiang Univ, Affiliated Hosp 1, Coll Med, Dept Gastroenterol, 79 Qingchun Rd, Hangzhou 310003, Zhejiang, Peoples R China.
EM zyyyych@zju.edu.cn
FU Medical Health Science and Technology Project of Zhejiang Provincial
   Health Commission [2017KY581, 2020KY125]
FX This study was supported by Medical Health Science and Technology
   Project of Zhejiang Provincial Health Commission [No. 2017KY581, to Lei
   Xu; No. 2020KY125, to Xinjue He].
CR Anderson JC, 2015, CLIN TRANSL GASTROEN, V6, DOI 10.1038/ctg.2015.5
   Aniwan S, 2016, AM J GASTROENTEROL, V111, P723, DOI 10.1038/ajg.2015.440
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Ezaz G, 2019, CLIN GASTROENTEROL H, V17, P1571, DOI 10.1016/j.cgh.2018.10.019
   Fliss-Isakov N, 2017, OBESITY, V25, pS72, DOI 10.1002/oby.22001
   Gingold-Belfer R, 2021, CLIN GASTROENTEROL H, V19, P202, DOI 10.1016/j.cgh.2019.11.016
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gupta S, 2020, GASTROENTEROLOGY, V158, P1131, DOI 10.1053/j.gastro.2019.10.026
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Heitman SJ, 2009, CLIN GASTROENTEROL H, V7, P1272, DOI 10.1016/j.cgh.2009.05.032
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Jung Y, 2019, GASTROINTEST ENDOSC, V89, P523, DOI 10.1016/j.gie.2018.09.016
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Maratt JK, 2017, DIGEST DIS SCI, V62, P3579, DOI 10.1007/s10620-017-4792-7
   Peters SL, 2010, CLIN GASTROENTEROL H, V8, P439, DOI 10.1016/j.cgh.2010.01.013
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Sanaka MR, 2009, AM J GASTROENTEROL, V104, P1659, DOI 10.1038/ajg.2009.249
   Schramm C, 2017, UNITED EUR GASTROENT, V5, P742, DOI 10.1177/2050640616675220
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tanaka S, 2015, J GASTROENTEROL, V50, P252, DOI 10.1007/s00535-014-1021-4
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 30
TC 8
Z9 9
U1 2
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2045-7634
J9 CANCER MED-US
JI Cancer Med.
PD OCT
PY 2021
VL 10
IS 20
BP 7184
EP 7193
DI 10.1002/cam4.4261
EA SEP 2021
PG 10
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA WI7CF
UT WOS:000692459900001
PM 34477306
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Hsu, CM
   Hsu, CC
   Hsu, ZM
   Shih, FY
   Chang, ML
   Chen, TH
AF Hsu, Chen-Ming
   Hsu, Chien-Chang
   Hsu, Zhe-Ming
   Shih, Feng-Yu
   Chang, Meng-Lin
   Chen, Tsung-Hsing
TI Colorectal Polyp Image Detection and Classification through Grayscale
   Images and Deep Learning
SO SENSORS
LA English
DT Article
DE colorectal polyp; grayscale image; colonoscopy; convolutional neural
   network; computer-assisted colorectal polyp analysis
ID PIT-PATTERN-CLASSIFICATION; COMPUTER-AIDED DIAGNOSIS; VALIDATION;
   SYSTEM; HISTOLOGY
AB Colonoscopy screening and colonoscopic polypectomy can decrease the incidence and mortality rate of colorectal cancer (CRC). The adenoma detection rate and accuracy of diagnosis of colorectal polyp which vary in different experienced endoscopists have impact on the colonoscopy protection effect of CRC. The work proposed a colorectal polyp image detection and classification system through grayscale images and deep learning. The system collected the data of CVC-Clinic and 1000 colorectal polyp images of Linkou Chang Gung Medical Hospital. The red-green-blue (RGB) images were transformed to 0 to 255 grayscale images. Polyp detection and classification were performed by convolutional neural network (CNN) model. Data for polyp detection was divided into five groups and tested by 5-fold validation. The accuracy of polyp detection was 95.1% for grayscale images which is higher than 94.1% for RGB and narrow-band images. The diagnostic accuracy, precision and recall rates were 82.8%, 82.5% and 95.2% for narrow-band images, respectively. The experimental results show that grayscale images achieve an equivalent or even higher accuracy of polyp detection than RGB images for lightweight computation. It is also found that the accuracy of polyp detection and classification is dramatically decrease when the size of polyp images small than 1600 pixels. It is recommended that clinicians could adjust the distance between the lens and polyps appropriately to enhance the system performance when conducting computer-assisted colorectal polyp analysis.
C1 [Hsu, Chen-Ming; Chen, Tsung-Hsing] Linkou Chang Gung Mem Hosp, Dept Gastroenterol & Hepatol, 5 Fuxing St, Taoyuan 333, Taiwan.
   [Hsu, Chen-Ming; Chen, Tsung-Hsing] Chang Gung Univ, Coll Med, 5 Fuxing St, Taoyuan 333, Taiwan.
   [Hsu, Chien-Chang; Hsu, Zhe-Ming; Shih, Feng-Yu] Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, 510 Chung Cheng Rd, New Taipei 242, Taiwan.
   [Hsu, Chien-Chang; Chang, Meng-Lin] Fu Jen Catholic Univ, Grad Inst Appl Sci & Engn, 510 Chung Cheng Rd, New Taipei 242, Taiwan.
C3 Chang Gung Memorial Hospital; Chang Gung University; Fu Jen Catholic
   University; Fu Jen Catholic University
RP Hsu, CC (通讯作者)，Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, 510 Chung Cheng Rd, New Taipei 242, Taiwan.; Hsu, CC (通讯作者)，Fu Jen Catholic Univ, Grad Inst Appl Sci & Engn, 510 Chung Cheng Rd, New Taipei 242, Taiwan.
EM hsu3060e@cgmh.org.tw; cch@csie.fju.edu.tw; 405261382@mail.fju.edu.tw;
   403261443@mail.fju.edu.tw; oro.tidyscoundrel@gmail.com;
   q122583@cgmh.org.tw
OI Hsu, Chen-Ming/0000-0001-5838-8886; Hsu, Chien-Chang/0000-0002-1714-9122
FU Chang Gung Medical Research Program [CMRPG3H1541]
FX Grant supporting this work was obtained from the Chang Gung Medical
   Research Program (CMRPG3H1541). The funders had no role in the study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   [Anonymous], 2016, P SPIE
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chiu HM, 2014, DIGEST ENDOSC, V26, P64, DOI 10.1111/den.12260
   Gross S., 2013, BILDVERARBEITUNG MED
   Hafner M, 2007, COMP MED SY, P159, DOI 10.1109/CBMS.2007.85
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   IJspeert JEG, 2016, GUT, V65, P963, DOI 10.1136/gutjnl-2014-308411
   ITU, ITU R RECOMMENDATION
   Kaltenbach T, 2008, GASTROENTEROLOGY, V134, P327, DOI 10.1053/j.gastro.2007.10.062
   Kang YK, 2014, CLIN ENDOSC, V47, P404, DOI 10.5946/ce.2014.47.5.404
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Korbar B, 2017, IEEE COMPUT SOC CONF, P821, DOI 10.1109/CVPRW.2017.114
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Q.`, 2017, DEEP LEARNING APPL A
   Lu L, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-42999-1
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Paggi S, 2012, ENDOSCOPY, V44, P899, DOI 10.1055/s-0032-1309891
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Subramanian V, 2014, CLIN GASTROENTEROL H, V12, P368, DOI 10.1016/j.cgh.2013.06.015
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Suzuki H, 2020, DIGESTION, V101, P339, DOI 10.1159/000499856
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Tamaki T, 2011, LECT NOTES COMPUT SC, V6493, P452
   Tan JX, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI)
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Xie YT, 2019, LECT NOTES COMPUT SC, V11134, P476, DOI 10.1007/978-3-030-11024-6_37
   Yoshida N, 2014, J GASTROENTEROL, V49, P73, DOI 10.1007/s00535-013-0772-7
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang YD, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102439
   Zhang YD, 2020, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01128-8
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 51
TC 12
Z9 12
U1 13
U2 24
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD SEP
PY 2021
VL 21
IS 18
AR 5995
DI 10.3390/s21185995
PG 18
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA UX9WH
UT WOS:000701185600001
PM 34577209
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Itoh, H
   Oda, M
   Jiang, K
   Mori, Y
   Misawa, M
   Kudo, SE
   Imai, K
   Ito, S
   Hotta, K
   Mori, K
AF Itoh, Hayato
   Oda, Masahiro
   Jiang, Kai
   Mori, Yuichi
   Misawa, Masashi
   Kudo, Shin-Ei
   Imai, Kenichiro
   Ito, Sayo
   Hotta, Kinichi
   Mori, Kensaku
TI Binary polyp-size classification based on deep-learned spatial
   information
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Colonoscopy; Polyp-size classification; Depth estimation; Polyp
   localisation; Computer-aided diagnosis; Deep learning
ID COLONOSCOPY SURVEILLANCE; POLYPECTOMY; ENDOSCOPY; SOCIETY
AB Purpose The size information of detected polyps is an essential factor for diagnosis in colon cancer screening. For example, adenomas and sessile serrated polyps that are = 10 mm are considered advanced, and shorter surveillance intervals are recommended for smaller polyps. However, sometimes the subjective estimations of endoscopists are incorrect and overestimate the sizes. To circumvent these difficulties, we developed a method for automatic binary polyp-size classification between two polyp sizes: from 1 to 9 mm and >= 10 mm. Method We introduce a binary polyp-size classification method that estimates a polyp's three-dimensional spatial information. This estimation is comprised of polyp localisation and depth estimation. The combination of location and depth information expresses a polyp's three-dimensional shape. In experiments, we quantitatively and qualitatively evaluate the proposed method using 787 polyps of both protruded and flat types. Results The proposed method's best classification accuracy outperformed the fine-tuned state-of-the-art image classification methods. Post-processing of sequential voting increased the classification accuracy and achieved classification accuracy of 0.81 and 0.88 for polyps ranging from 1 to 9 mm and others that are = 10 mm. Qualitative analysis revealed the importance of polyp localisation even in polyp-size classification. Conclusions We developed a binary polyp-size classification method by utilising the estimated three-dimensional shape of a polyp. Experiments demonstrated accurate classification for both protruded- and flat-type polyps, even though the flat type have ambiguous boundary between a polyp and colon wall.
C1 [Itoh, Hayato; Oda, Masahiro; Jiang, Kai; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Mori, Yuichi] Univ Oslo, Clin Effectiveness Res Grp, Gaustad Sykehus, Bygg 20,Sognsvannsveien 21, N-0372 Oslo, Norway.
   [Mori, Yuichi; Misawa, Masashi; Kudo, Shin-Ei] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Tsuzuki Ku, Chigasaki Chuo 35-1, Yokohama, Kanagawa 2248503, Japan.
   [Imai, Kenichiro; Ito, Sayo; Hotta, Kinichi] Shizuoka Canc Ctr, Div Endoscopy, 1007 Shimonagakubo, Nagaizumi, Shizuoka 4118777, Japan.
C3 Nagoya University; University of Oslo; Showa University; Shizuoka Cancer
   Center
RP Itoh, H (通讯作者)，Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM hitoh@mori.m.is.nagoya-u.ac.jp; mods@mori.m.is.nagoya-u.ac.jp;
   kensaku@is.nagoya-u.ac.jp
RI Misawa, Masashi/H-9004-2019; Itoh, Hayato/AAM-4022-2021
OI Misawa, Masashi/0000-0002-8520-2036; Itoh, Hayato/0000-0002-1410-1078;
   Oda, Masahiro/0000-0001-7714-422X
FU AMED [445 (19hs0110006h0003)]; JSPS MEXT KAKENHI [26108006, 17H00867,
   446 17K20099]; JST CREST [JPMJCR20D5]; JSPS Bilateral Joint Research
   Project [447]
FX This study was funded by Grants from AMED 445 (19hs0110006h0003), JSPS
   MEXT KAKENHI (26108006, 17H00867, 446 17K20099), JST CREST (JPMJCR20D5),
   and the JSPS Bilateral Joint Research Project. 447.
CR Anderson BW, 2016, GASTROINTEST ENDOSC, V83, P201, DOI 10.1016/j.gie.2015.06.058
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Hassan C, 2016, ENDOSCOPY, V48, P881, DOI 10.1055/s-0042-112580
   Hassan C, 2013, ENDOSCOPY, V45, P842, DOI 10.1055/s-0033-1344548
   Hyun YS, 2011, DIGEST LIVER DIS, V43, P391, DOI 10.1016/j.dld.2010.12.015
   Itoh H., 2020, SUN COLONOSCOPY VIDE
   Itoh H, 2021, INT J COMPUT ASS RAD, V16, P989, DOI 10.1007/s11548-021-02398-x
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Kaz AM, 2016, GASTROINTEST ENDOSC, V83, P812, DOI 10.1016/j.gie.2015.08.082
   Lausberg H, 2009, BEHAV RES METHODS, V41, P841, DOI 10.3758/BRM.41.3.841
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Mori K, 2003, PROC SPIE, V5031, P111, DOI 10.1117/12.480417
   Plumb AA, 2016, ENDOSCOPY, V48, P899, DOI 10.1055/s-0042-108727
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Rex DK, 2014, GASTROINTEST ENDOSC, V79, P402, DOI 10.1016/j.gie.2013.08.030
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 18
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD OCT
PY 2021
VL 16
IS 10
SI SI
BP 1817
EP 1828
DI 10.1007/s11548-021-02477-z
EA SEP 2021
PG 12
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA WV1HC
UT WOS:000691967100001
PM 34468971
DA 2023-08-21
ER

PT J
AU Jain, S
   Seal, A
   Ojha, A
   Yazidi, A
   Bures, J
   Tacheci, I
   Krejcar, O
AF Jain, Samir
   Seal, Ayan
   Ojha, Aparajita
   Yazidi, Anis
   Bures, Jan
   Tacheci, Ilja
   Krejcar, Ondrej
TI A deep CNN model for anomaly detection and localization in wireless
   capsule endoscopy images
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Deep convolutional neural network; Attention mechanism; Wireless capsule
   endoscopy; Anomaly detection; Localization
ID POLYP DETECTION; FEATURES; NETWORK
AB Wireless capsule endoscopy (WCE) is one of the most efficient methods for the examination of gastrointestinal tracts. Computer-aided intelligent diagnostic tools alleviate the challenges faced during manual inspection of long WCE videos. Several approaches have been proposed in the literature for the automatic detection and localization of anomalies in WCE images. Some of them focus on specific anomalies such as bleeding, polyp, lesion, etc. However, relatively fewer generic methods have been proposed to detect all those common anomalies simultaneously. In this paper, a deep convolutional neural network (CNN) based model 'WCENet' is proposed for anomaly detection and localization in WCE images. The model works in two phases. In the first phase, a simple and efficient attention-based CNN classifies an image into one of the four categories: polyp, vascular, inflammatory, or normal. If the image is classified in one of the abnormal categories, it is processed in the second phase for the anomaly localization. Fusion of Grad-CAM++ and a custom SegNet is used for anomalous region segmentation in the abnormal image. WCENet classifier attains accuracy and area under receiver operating characteristic of 98% and 99%. The WCENet segmentation model obtains a frequency weighted intersection over union of 81%, and an average dice score of 56% on the KID dataset. WCENet outperforms nine different state-of-the-art conventional machine learning and deep learning models on the KID dataset. The proposed model demonstrates potential for clinical applications.
C1 [Jain, Samir; Seal, Ayan; Ojha, Aparajita] PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, India.
   [Yazidi, Anis] OsloMet Oslo Metropolitan Univ, Dept Comp Sci, Oslo, Norway.
   [Yazidi, Anis] Oslo Univ Hosp, Dept Plast & Reconstruct Surg, Oslo, Norway.
   [Yazidi, Anis] Norwegian Univ Sci & Technol, Dept Comp Sci, Trondheim, Norway.
   [Bures, Jan; Tacheci, Ilja] Charles Univ Prague, Fac Med Hradec Kralove, Dept Internal Med Gastroenterol 2, Sokolska 581, Hradec Kralove 50005, Czech Republic.
   [Bures, Jan; Tacheci, Ilja] Univ Hosp Hradec Kralove, Sokolska 581, Hradec Kralove 50005, Czech Republic.
   [Krejcar, Ondrej] Univ Hradec Kralove, Fac Informat & Management, Ctr Basic & Appl Res, Hradecka 1249, Hradec Kralove 50003, Czech Republic.
   [Krejcar, Ondrej] Univ Teknol Malaysia, Malaysia Japan Int Inst Technol, Jalan Sultan Yahya Petra, Kuala Lumpur 54100, Malaysia.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Oslo Metropolitan University (OsloMet); University of Oslo;
   Norwegian University of Science & Technology (NTNU); Charles University
   Prague; University Hospital Hradec Kralove; University Hospital Hradec
   Kralove; University of Hradec Kralove; Universiti Teknologi Malaysia
RP Seal, A (通讯作者)，PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, India.
EM ayan@iiitdmj.ac.in
RI Seal, Ayan/AAI-1929-2020; Bures, Jan/ISS-0176-2023; Krejcar,
   Ondrej/A-8639-2008; Tacheci, Ilja/N-3802-2016
OI Seal, Ayan/0000-0002-9939-2926; Bures, Jan/0000-0003-0326-117X; Krejcar,
   Ondrej/0000-0002-5992-2574; Tacheci, Ilja/0000-0003-3583-2651; Ojha,
   Aparajita/0000-0003-1567-8378
FU project "Prediction of diseases through computer assisted diagnosis
   system using images captured by minimally-invasive and non-invasive
   modalities", Computer Science and Engineering, PDPM Indian Institute of
   Information Technology, Design and Manufacturing [SPARC-MHRD-231];
   project IT4Neuro [CZ.02.1.01/0.0/0.0/18 069/0010054]; project "Smart
   Solutions in Ubiquitous Computing Environments", Grant Agency of
   Excellence, University of Hradec Kralove, Faculty of Informatics and
   Management, Czech Republic [UHK-FIM-GE-2021]
FX This work is partially supported by the project "Prediction of diseases
   through computer assisted diagnosis system using images captured by
   minimally-invasive and non-invasive modalities", Computer Science and
   Engineering, PDPM Indian Institute of Information Technology, Design and
   Manufacturing, Jabalpur India (under ID: SPARC-MHRD-231) . This work is
   also partially supported by the project IT4Neuro (degeneration) , reg.
   nr. CZ.02.1.01/0.0/0.0/18 069/0010054 and by the project "Smart
   Solutions in Ubiquitous Computing Environments", Grant Agency of
   Excellence, University of Hradec Kralove, Faculty of Informatics and
   Management, Czech Republic (under ID: UHK-FIM-GE-2021) .
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Banik D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3015607
   Barbosa DJC, 2008, IEEE ENG MED BIO, P3012, DOI 10.1109/IEMBS.2008.4649837
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bhattacharjee D, 2012, COMPUT INTEL NEUROSC, V2012, DOI 10.1155/2012/261089
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen HD, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/8147632
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Dolz J, 2016, COMPUT MED IMAG GRAP, V52, P8, DOI 10.1016/j.compmedimag.2016.03.003
   Gao Y, 2020, IEEE ACCESS, V8, P81621, DOI 10.1109/ACCESS.2020.2991115
   Georgakopoulos SV, 2016, IEEE CONF IMAGING SY, P510, DOI 10.1109/IST.2016.7738279
   Ghosh T, 2021, J DIGIT IMAGING, V34, P404, DOI 10.1007/s10278-021-00428-3
   Ghosh T, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2017.2756034
   Habibzadeh M, 2018, PROC SPIE, V10696, DOI 10.1117/12.2311282
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, PREPRINT
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jain S., 2021, SMART COMPUTING, P423, DOI [10.1201/9781003167488-49, DOI 10.1201/9781003167488-49]
   Jain S, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104094
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Karkanis SA, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P833, DOI 10.1109/ICIP.2001.958623
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Kundu AK, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/9423062
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li XL, 2017, IEEE ENG MED BIO, P1994, DOI 10.1109/EMBC.2017.8037242
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lv GL, 2011, IEEE ENG MED BIO, P6643, DOI 10.1109/IEMBS.2011.6091638
   Novozamsky A, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.12.126007
   Rahim T, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102654
   Rahim T, 2020, COMPUT MED IMAG GRAP, V85, DOI 10.1016/j.compmedimag.2020.101767
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sadasivan VS, 2019, I S BIOMED IMAGING, P96, DOI 10.1109/ISBI.2019.8759324
   Sainju S, 2013, CAN CON EL COMP EN, P539
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shah S.K., 2007, URI NE ASEE 2007 C
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sindhu CP, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Szegedy C., ARXIV PREPRINT ARXIV
   Vani V, 2015, 2015 INTERNATIONAL CONFERENCE ON TRENDS IN AUTOMATION, COMMUNICATIONS AND COMPUTING TECHNOLOGY (I-TACT-15)
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xing XH, 2020, IEEE T MED IMAGING, V39, P4047, DOI 10.1109/TMI.2020.3010102
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 63
TC 15
Z9 16
U1 1
U2 11
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD OCT
PY 2021
VL 137
AR 104789
DI 10.1016/j.compbiomed.2021.104789
EA AUG 2021
PG 14
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA WB3JZ
UT WOS:000703473200004
PM 34455302
DA 2023-08-21
ER

PT J
AU Neumann, H
   Kreft, A
   Sivanathan, V
   Rahman, F
   Galle, PR
AF Neumann, Helmut
   Kreft, Andreas
   Sivanathan, Visvakanth
   Rahman, Fareed
   Galle, Peter R.
TI Evaluation of novel LCI CAD EYE system for real time detection of colon
   polyps
SO PLOS ONE
LA English
DT Article
ID SCREENING COLONOSCOPY; COLORECTAL-CANCER; NARROW-BAND; MISS RATE
AB Background Linked color imaging (LCI) has been shown to be effective in multiple randomized controlled trials for enhanced colorectal polyp detection. Recently, artificial intelligence (AI) with deep learning through convolutional neural networks has dramatically improved and is increasingly recognized as a promising new technique for enhancing colorectal polyp detection.
   Aim This study aims to evaluate a newly developed computer-aided detection (CAD) system in combination with LCI for colorectal polyp detection.
   Methods First, a convolutional neural network was trained for colorectal polyp detection in combination with the LCI technique using a dataset of anonymized endoscopy videos. For validation, 240 polyps within fully recorded endoscopy videos in LCI mode, covering the entire spectrum of adenomatous histology, were used. Sensitivity (true-positive rate per lesion) and false-positive frames in a full procedure were assessed.
   Results The new CAD system used in LCI mode could process at least 60 frames per second, allowing for real-time video analysis. Sensitivity (true-positive rate per lesion) was 100%, with no lesion being missed. The calculated false-positive frame rate was 0.001%. Among the 240 polyps, 34 were sessile serrated lesions. The detection rate for sessile serrated lesions with the CAD system used in LCI mode was 100%.
   Conclusions The new CAD system used in LCI mode achieved a 100% sensitivity per lesion and a negligible false-positive frame rate. Note that the new CAD system used in LCI mode also specifically allowed for detection of serrated lesions in all cases. Accordingly, the AI algorithm introduced here for the first time has the potential to dramatically improve the quality of colonoscopy.
C1 [Neumann, Helmut; Sivanathan, Visvakanth; Rahman, Fareed; Galle, Peter R.] Univ Hosp, Med Klin & Poliklin 1, Dept Interdisciplinary Endoscopy, Mainz, Germany.
   [Neumann, Helmut] GastroZentrum Lippe, Bad Salzuflen, Germany.
   [Kreft, Andreas] Univ Hosp, Inst Pathol, Mainz, Germany.
C3 University Hospital Mainz; University Hospital Mainz
RP Neumann, H (通讯作者)，Univ Hosp, Med Klin & Poliklin 1, Dept Interdisciplinary Endoscopy, Mainz, Germany.; Neumann, H (通讯作者)，GastroZentrum Lippe, Bad Salzuflen, Germany.
EM helmut.neumann@unimedizin-mainz.de
RI Galle, Peter R/T-5292-2018; Galle, Peter/ABE-2872-2021
OI Galle, Peter R/0000-0001-8294-0992; Galle, Peter/0000-0001-8294-0992
FU Fujifilm
FX Material support from Fujifilm. No other funding was raised for his
   study. The funders had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript. None of
   the others received a salary from any of the funders.
CR Adler A, 2013, GUT, V62, P236, DOI 10.1136/gutjnl-2011-300167
   Adler A, 2009, GASTROENTEROLOGY, V136, P410, DOI 10.1053/j.gastro.2008.10.022
   Atkinson NSS, 2019, GASTROENTEROLOGY, V157, P462, DOI 10.1053/j.gastro.2019.04.014
   Castaneda D, 2018, GASTROINTEST ENDOSC, V88, P209, DOI 10.1016/j.gie.2018.03.022
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   East JE, 2017, GUT, V66, P1181, DOI 10.1136/gutjnl-2017-314005
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gulati S, 2020, DIGEST ENDOSC, V32, P512, DOI 10.1111/den.13481
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Levin TR, 2018, GASTROENTEROLOGY, V155, P1383, DOI 10.1053/j.gastro.2018.07.017
   Min M, 2017, GASTROINTEST ENDOSC, V86, P724, DOI 10.1016/j.gie.2017.02.035
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Neumann H, 2019, DIGEST ENDOSC, V31, P389, DOI 10.1111/den.13391
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Paggi S, 2018, ENDOSCOPY, V50, P396, DOI 10.1055/a-0580-7405
   Paggi S, 2015, ENDOSCOPY, V47, P808, DOI 10.1055/s-0034-1392042
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 20
TC 10
Z9 10
U1 0
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD AUG 26
PY 2021
VL 16
IS 8
AR e0255955
DI 10.1371/journal.pone.0255955
PG 8
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA US1HA
UT WOS:000697186000026
PM 34437563
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Bang, CS
   Lee, JJ
   Baik, GH
AF Bang, Chang Seok
   Lee, Jae Jun
   Baik, Gwang Ho
TI Computer-Aided Diagnosis of Diminutive Colorectal Polyps in Endoscopic
   Images: Systematic Review and Meta-analysis of Diagnostic Test Accuracy
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE artificial intelligence; deep learning; polyps; colon; colonoscopy;
   diminutive
ID SOCIETY TASK-FORCE; ARTIFICIAL-INTELLIGENCE; HISTOLOGY; CANCER;
   CLASSIFICATION; RECOMMENDATIONS; PREVALENCE; LESIONS
AB Background: Most colorectal polyps are diminutive and benign, especially those in the rectosigmoid colon, and the resection of these polyps is not cost-effective. Advancements in image-enhanced endoscopy have improved the optical prediction of colorectal polyp histology. However, subjective interpretability and inter- and intraobserver variability prohibits widespread implementation. The number of studies on computer-aided diagnosis (CAD) is increasing; however, their small sample sizes limit statistical significance.
   Objective: This review aims to evaluate the diagnostic test accuracy of CAD models in predicting the histology of diminutive colorectal polyps by using endoscopic images.
   Methods: Core databases were searched for studies that were based on endoscopic imaging, used CAD models for the histologic diagnosis of diminutive colorectal polyps, and presented data on diagnostic performance. A systematic review and diagnostic test accuracy meta-analysis were performed.
   Results: Overall, 13 studies were included. The pooled area under the curve, sensitivity, specificity, and diagnostic odds ratio of CAD models for the diagnosis of diminutive colorectal polyps (adenomatous or neoplastic vs nonadenomatous or nonneoplastic) were 0.96 (95% CI 0.93-0.97), 0.93 (95% CI 0.91-0.95), 0.87 (95% CI 0.76-0.93), and 87 (95% CI 38-201), respectively. The meta-regression analysis showed no heterogeneity, and no publication bias was detected. Subgroup analyses showed robust results. The negative predictive value of CAD models for the diagnosis of adenomatous polyps in the rectosigmoid colon was 0.96 (95% CI 0.95-0.97), and this value exceeded the threshold of the diagnosis and leave strategy.
   Conclusions: CAD models show potential for the optical histological diagnosis of diminutive colorectal polyps via the use of endoscopic images.
C1 [Bang, Chang Seok; Baik, Gwang Ho] Hallym Univ, Coll Med, Dept Internal Med, Sakju Ro 77, Chunchon 24253, South Korea.
   [Bang, Chang Seok; Baik, Gwang Ho] Hallym Univ, Coll Med, Inst Liver & Digest Dis, Chunchon, South Korea.
   [Bang, Chang Seok; Lee, Jae Jun] Hallym Univ, Coll Med, Inst New Frontier Res, Chunchon, South Korea.
   [Bang, Chang Seok; Lee, Jae Jun] Chuncheon Sacred Heart Hosp, Div Big Data & Artificial Intelligence, Chunchon, South Korea.
   [Lee, Jae Jun] Hallym Univ, Coll Med, Dept Anesthesiol & Pain Med, Chunchon, South Korea.
C3 Hallym University; Hallym University; Hallym University; Hallym
   University
RP Bang, CS (通讯作者)，Hallym Univ, Coll Med, Dept Internal Med, Sakju Ro 77, Chunchon 24253, South Korea.
EM csbang@hallym.ac.kr
RI Bang, Chang SEOK/I-9689-2019
OI Bang, Chang Seok/0000-0003-4908-5431; Baik, Gwang Ho/0000-0003-1419-7484
FU Technology Development Program - Ministry of SMEs and Startups (Korea)
   [S2931703]; Korea Technology & Information Promotion Agency for SMEs
   (TIPA) [S2931703] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This work was supported by the Technology Development Program (S2931703)
   and funded by the Ministry of SMEs and Startups (Korea).
CR Abadir AP, 2020, CLIN ENDOSC, V53, P132, DOI 10.5946/ce.2020.038
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Bang CS, 2021, GASTROINTEST ENDOSC, V93, P1006, DOI 10.1016/j.gie.2020.11.025
   Bang CS, 2020, J MED INTERNET RES, V22, DOI 10.2196/21983
   Bang CS, 2020, KOR J GASTROENTEROL, V75, P120, DOI 10.4166/kjg.2020.75.3.120
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cho BJ, 2020, AM J GASTROENTEROL, V115, P70, DOI 10.14309/ajg.0000000000000476
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Harbord RM, 2009, STATA J, V9, P211, DOI 10.1177/1536867X0900900203
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kaltenbach T, 2020, GASTROENTEROLOGY, V158, P1095, DOI 10.1053/j.gastro.2019.12.018
   Kandel P, 2019, CLIN ENDOSC, V52, P239, DOI 10.5946/ce.2018.136
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Li JL, 2021, EUR J GASTROEN HEPAT, V33, P1041, DOI 10.1097/MEG.0000000000001906
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   LITTENBERG B, 1993, MED DECIS MAKING, V13, P313, DOI 10.1177/0272989X9301300408
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Mason SE, 2019, AM J GASTROENTEROL, V114, P1219, DOI 10.14309/ajg.0000000000000156
   McInnes MDF, 2018, JAMA-J AM MED ASSOC, V319, P388, DOI 10.1001/jama.2017.19163
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Qumseya BJ, 2012, CLIN TRANSL GASTROEN, V3, DOI 10.1038/ctg.2012.14
   Reitsma JB, 2005, J CLIN EPIDEMIOL, V58, P982, DOI 10.1016/j.jclinepi.2005.02.022
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Rutter CM, 2001, STAT MED, V20, P2865, DOI 10.1002/sim.942
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Wong MCS, 2020, CLIN GASTROENTEROL H, V18, P553, DOI 10.1016/j.cgh.2019.07.016
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang YC, 2021, J LAPAROENDOSC ADV S, V31, P1143, DOI 10.1089/lap.2020.0777
NR 44
TC 6
Z9 6
U1 1
U2 7
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD AUG 25
PY 2021
VL 23
IS 8
AR e29682
DI 10.2196/29682
PG 21
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA UH1QM
UT WOS:000689714100002
PM 34432643
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Qin, KW
   Li, JM
   Fang, YX
   Xu, YY
   Wu, JH
   Zhang, HN
   Li, HL
   Liu, SD
   Li, QY
AF Qin, Kaiwen
   Li, Jianmin
   Fang, Yuxin
   Xu, Yuyuan
   Wu, Jiahao
   Zhang, Haonan
   Li, Haolin
   Liu, Side
   Li, Qingyuan
TI Convolution neural network for the diagnosis of wireless capsule
   endoscopy: a systematic review and meta-analysis
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
LA English
DT Review
DE Deep learning; Convolutional neural network; Capsule endoscopy
ID ARTIFICIAL-INTELLIGENCE; EUROPEAN-SOCIETY; LESIONS; COLONOSCOPY;
   PERFORMANCE; PRIMER; CANCER; IMAGES; ESGE
AB Background Wireless capsule endoscopy (WCE) is considered to be a powerful instrument for the diagnosis of intestine diseases. Convolution neural network (CNN) is a type of artificial intelligence that has the potential to assist the detection of WCE images. We aimed to perform a systematic review of the current research progress to the CNN application in WCE. Methods A search in PubMed, SinoMed, and Web of Science was conducted to collect all original publications about CNN implementation in WCE. Assessment of the risk of bias was performed by Quality Assessment of Diagnostic Accuracy Studies-2 risk list. Pooled sensitivity and specificity were calculated by an exact binominal rendition of the bivariate mixed-effects regression model. I-2 was used for the evaluation of heterogeneity. Results 16 articles with 23 independent studies were included. CNN application to WCE was divided into detection on erosion/ulcer, gastrointestinal bleeding (GI bleeding), and polyps/cancer. The pooled sensitivity of CNN for erosion/ulcer is 0.96 [95% CI 0.91, 0.98], for GI bleeding is 0.97 (95% CI 0.93-0.99), and for polyps/cancer is 0.97 (95% CI 0.82-0.99). The corresponding specificity of CNN for erosion/ulcer is 0.97 (95% CI 0.93-0.99), for GI bleeding is 1.00 (95% CI 0.99-1.00), and for polyps/cancer is 0.98 (95% CI 0.92-0.99). Conclusion Based on our meta-analysis, CNN-dependent diagnosis of erosion/ulcer, GI bleeding, and polyps/cancer approached a high-level performance because of its high sensitivity and specificity. Therefore, future perspective, CNN has the potential to become an important assistant for the diagnosis of WCE.
C1 [Qin, Kaiwen; Li, Haolin] Southern Med Univ, Nanfang Hosp, Sch Clin Med 1, Guangzhou, Guangdong, Peoples R China.
   [Li, Jianmin; Wu, Jiahao] Guangzhou SiDe MedTech Co Ltd, Guangzhou, Guangdong, Peoples R China.
   [Fang, Yuxin; Zhang, Haonan; Li, Haolin; Liu, Side; Li, Qingyuan] Southern Med Univ, Nanfang Hosp, Dept Gastroenterol, Guangdong Prov Key Lab Gastroenterol, 1838 Guangzhou Ave North, Guangzhou, Guangdong, Peoples R China.
   [Xu, Yuyuan] Southern Med Univ, Nanfang Hosp, Dept Hepatol Unit & Infect Dis, Guangdong Prov Key Lab Viral Hepatitis Res,State, Guangzhou, Guangdong, Peoples R China.
C3 Southern Medical University - China; Southern Medical University -
   China; Southern Medical University - China
RP Li, QY (通讯作者)，Southern Med Univ, Nanfang Hosp, Dept Gastroenterol, Guangdong Prov Key Lab Gastroenterol, 1838 Guangzhou Ave North, Guangzhou, Guangdong, Peoples R China.
EM liqingyuan09@smu.edu.cn
RI li, jian/GSE-0245-2022; Liu, Jing/IQX-0664-2023; LI, JIAN/GRY-2197-2022;
   li, jy/HTT-1535-2023; li, jian/IAQ-2794-2023; Li, Jing/GYU-5036-2022;
   LI, Jing/HNB-5575-2023
OI li, jian/0009-0006-8677-8113; 
FU National Natural Science Funds of China [12026605]; Guangdong Basic and
   Applied Basic Research Fund [2020A1515110916, 2021A1515010992];
   Guangdong Medical Science and Technology Research Fund Project
   [A2020143]; College Students' Innovative Entrepreneurial Training Plan
   Program [202012121035X]; President Foundation of Nanfang Hospital,
   Southern Medical University [2018C027]; Guangdong Science and Technology
   Plan Project [2017B020209003]; Pazhou Lab, Guangzhou
FX This work was supported by the National Natural Science Funds of China
   (12026605), Guangdong Basic and Applied Basic Research Fund
   (2020A1515110916, 2021A1515010992), the Guangdong Medical Science and
   Technology Research Fund Project (A2020143), the College Students'
   Innovative Entrepreneurial Training Plan Program (202012121035X), the
   President Foundation of Nanfang Hospital, Southern Medical University
   (2018C027), and the Guangdong Science and Technology Plan Project
   (2017B020209003). We would like to acknowledge Pazhou Lab, Guangzhou for
   its support of this research.
CR Aoki T, 2020, J GASTROEN HEPATOL, V35, P1196, DOI 10.1111/jgh.14941
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Aractingi S, 2019, EUR J DERMATOL, V29, P4, DOI 10.1684/ejd.2019.3538
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Caroppo A, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101852
   Chahal D, 2020, GASTROINTEST ENDOSC, V92, P813, DOI 10.1016/j.gie.2020.04.074
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Choi JY, 2020, IEEE T IMAGE PROCESS, V29, P3270, DOI 10.1109/TIP.2019.2958404
   Chu HT, 2006, J CLIN EPIDEMIOL, V59, P1331, DOI 10.1016/j.jclinepi.2006.06.011
   Deeks JJ, 2005, J CLIN EPIDEMIOL, V58, P882, DOI 10.1016/j.jclinepi.2005.01.016
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Doherty GA, 2011, GASTROINTEST ENDOSC, V74, P167, DOI 10.1016/j.gie.2011.01.067
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   Enns RA, 2017, GASTROENTEROLOGY, V152, P497, DOI 10.1053/j.gastro.2016.12.032
   Erickson BJ, 2017, J DIGIT IMAGING, V30, P400, DOI 10.1007/s10278-017-9965-6
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Gan T, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-60969-5
   Giger ML, 2018, J AM COLL RADIOL, V15, P512, DOI 10.1016/j.jacr.2017.12.028
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guyatt GH, 2008, BRIT MED J, V336, P924, DOI 10.1136/bmj.39489.470347.AD
   Harkey K, 2021, JAMA SURG, V156, P221, DOI [10.1001/jamasurg.2020.6265, 10.1186/s13643-021-01626-4, 10.1016/j.jclinepi.2021.03.001, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n71, 10.1016/j.rec.2021.07.010]
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Ioannidis JPA, 2007, BMJ-BRIT MED J, V335, P914, DOI 10.1136/bmj.39343.408449.80
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Klang E, 2018, J THORAC DIS, V10, P1325, DOI 10.21037/jtd.2018.02.76
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Koulaouzidis A, 2013, ANN GASTROENTEROL, V26, P365
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Leenhardt R, 2021, ENDOSCOPY, V53, P932, DOI 10.1055/a-1301-3841
   Liao ZA, 2010, GASTROINTEST ENDOSC, V71, P280, DOI 10.1016/j.gie.2009.09.031
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Mishkin DS, 2006, GASTROINTEST ENDOSC, V63, P539, DOI 10.1016/j.gie.2006.01.014
   Mohan BP, 2021, GASTROINTEST ENDOSC, V93, P356, DOI 10.1016/j.gie.2020.07.038
   Niel O, 2019, AM J KIDNEY DIS, V74, P803, DOI 10.1053/j.ajkd.2019.05.020
   Niv Y, 2008, WORLD J GASTROENTERO, V14, P1313, DOI 10.3748/wjg.14.1313
   Noorda R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74668-8
   Otani K, 2020, ENDOSCOPY, V52, P786, DOI 10.1055/a-1167-8157
   Pennazio M, 2015, ENDOSCOPY, V47, P352, DOI 10.1055/s-0034-1391855
   Soffer S, 2020, GASTROINTEST ENDOSC, V92, P831, DOI 10.1016/j.gie.2020.04.039
   Spada C, 2021, EUR RADIOL, V31, P2967, DOI 10.1007/s00330-020-07413-4
   Trasolini R, 2021, DIGEST ENDOSC, V33, P290, DOI 10.1111/den.13896
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   VANHOUWELINGEN HC, 1993, STAT MED, V12, P2273, DOI 10.1002/sim.4780122405
   Wang S, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab5086
   Wang S, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/7546215
   Whiting Penny, 2003, BMC Med Res Methodol, V3, P25, DOI 10.1186/1471-2288-3-25
   Xia J, 2021, GASTROINTEST ENDOSC, V93, P133, DOI 10.1016/j.gie.2020.05.027
   Yamada A, 2021, ENDOSCOPY, V53, P832, DOI 10.1055/a-1266-1066
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
NR 55
TC 5
Z9 5
U1 4
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0930-2794
EI 1432-2218
J9 SURG ENDOSC
JI Surg. Endosc.
PD JAN
PY 2022
VL 36
IS 1
BP 16
EP 31
DI 10.1007/s00464-021-08689-3
EA AUG 2021
PG 16
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA YD3WN
UT WOS:000687492800002
PM 34426876
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Zhao, SB
   Yang, W
   Wang, SL
   Pan, P
   Wang, RD
   Chang, X
   Sun, ZQ
   Fu, XH
   Shang, H
   Wu, JR
   Chen, LZ
   Chang, J
   Song, P
   Miao, YL
   He, SX
   Miao, L
   Jiang, HQ
   Wang, W
   Yang, X
   Dong, YH
   Lin, H
   Chen, Y
   Gao, J
   Meng, QQ
   Jin, ZD
   Li, ZS
   Bai, Y
AF Zhao, Sheng-Bing
   Yang, Wei
   Wang, Shu-Ling
   Pan, Peng
   Wang, Run-Dong
   Chang, Xin
   Sun, Zhong-Qian
   Fu, Xing-Hui
   Shang, Hong
   Wu, Jian-Rong
   Chen, Li-Zhu
   Chang, Jia
   Song, Pu
   Miao, Ying-Lei
   He, Shui-Xiang
   Miao, Lin
   Jiang, Hui-Qing
   Wang, Wen
   Yang, Xia
   Dong, Yuan-Hang
   Lin, Han
   Chen, Yan
   Gao, Jie
   Meng, Qian-Qian
   Jin, Zhen-Dong
   Li, Zhao-Shen
   Bai, Yu
TI Establishment and validation of a computer-assisted colonic polyp
   localization system based on deep learning
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Computer-assisted detection; Artificial intelligence; Deep learning;
   Colonoscopy; Clinical validation; Colorectal polyp
ID ADENOMA MISS RATE; AIDED DETECTION; COLORECTAL-CANCER; COLONOSCOPY;
   CLASSIFICATION; ALGORITHM; RATES
AB BACKGROUND
   Artificial intelligence in colonoscopy is an emerging field, and its application may help colonoscopists improve inspection quality and reduce the rate of missed polyps and adenomas. Several deep learning-based computer-assisted detection (CADe) techniques were established from small single-center datasets, and unrepresentative learning materials might confine their application and generalization in wide practice. Although CADes have been reported to identify polyps in colonoscopic images and videos in real time, their diagnostic performance deserves to be further validated in clinical practice.
   AIM
   To train and test a CADe based on multicenter high-quality images of polyps and preliminarily validate it in clinical colonoscopies.
   METHODS
   With high-quality screening and labeling from 55 qualified colonoscopists, a dataset consisting of over 71000 images from 20 centers was used to train and test a deep learning-based CADe. In addition, the real-time diagnostic performance of CADe was tested frame by frame in 47 unaltered full-ranged videos that contained 86 histologically confirmed polyps. Finally, we conducted a self-controlled observational study to validate the diagnostic performance of CADe in real-world colonoscopy with the main outcome measure of polyps per colonoscopy in Changhai Hospital.
   RESULTS
   The CADe was able to identify polyps in the test dataset with 95.0% sensitivity and 99.1% specificity. For colonoscopy videos, all 86 polyps were detected with 92.2% sensitivity and 93.6% specificity in frame-by-frame analysis. In the prospective validation, the sensitivity of CAD in identifying polyps was 98.4% (185/188). Folds, reflections of light and fecal fluid were the main causes of false positives in both the test dataset and clinical colonoscopies. Colonoscopists can detect more polyps (0.90 vs 0.82, P < 0.001) and adenomas (0.32 vs 0.30, P = 0.045) with the aid of CADe, particularly polyps < 5 mm and flat polyps (0.65 vs 0.57, P < 0.001; 0.74 vs 0.67, P = 0.001, respectively). However, high efficacy is not realized in colonoscopies with inadequate bowel preparation and withdrawal time (P = 0.32; P = 0.16, respectively).
   CONCLUSION
   CADe is feasible in the clinical setting and might help endoscopists detect more polyps and adenomas, and further confirmation is warranted.
C1 [Zhao, Sheng-Bing] Second Mil Med Univ, Naval Med Univ, Changhai Hosp, Shanghai 200433, Peoples R China.
   [Yang, Wei; Sun, Zhong-Qian; Fu, Xing-Hui; Shang, Hong] Tencent AI Lab, Natl Open Innovat Platform Next Generat Artificia, Shenzhen 518063, Guangdong, Peoples R China.
   [Wang, Shu-Ling; Pan, Peng; Wang, Run-Dong; Chang, Xin; Dong, Yuan-Hang; Lin, Han; Chen, Yan; Gao, Jie; Meng, Qian-Qian; Jin, Zhen-Dong; Li, Zhao-Shen; Bai, Yu] Second Mil Med Univ, Naval Med Univ, Changhai Hosp, Dept Gastroenterol, 168 Changhai Rd, Shanghai 200433, Peoples R China.
   [Wu, Jian-Rong; Chen, Li-Zhu; Chang, Jia; Song, Pu] Tencent Healthcare Shenzhen Co LTD, Shenzhen 518063, Guangdong, Peoples R China.
   [Miao, Ying-Lei] Kunming Med Univ, Affiliated Hosp 1, Dept Gastroenterol, Kunming 650000, Yunnan, Peoples R China.
   [He, Shui-Xiang] Xi An Jiao Tong Univ, Dept Gastroenterol, Affiliated Hosp 1, Xian 710061, Shaanxi, Peoples R China.
   [Miao, Lin] Nanjing Med Univ, Affiliated Hosp 2, Inst Digest Endoscopy, Nanjing 210011, Jiangsu, Peoples R China.
   [Miao, Lin] Nanjing Med Univ, Affiliated Hosp 2, Med Ctr Digest Dis, Nanjing 210011, Jiangsu, Peoples R China.
   [Jiang, Hui-Qing] Hebei Med Univ, Hebei Inst Gastroenterol, Hosp 2, Dept Gastroenterol,Hebei Key Lab Gastroenterol, Shijiazhuang 050000, Hebei, Peoples R China.
   [Wang, Wen] 900th Hosp Joint Logist Support Force, Dept Gastroenterol, Fuzhou 350025, Fujian, Peoples R China.
   [Yang, Xia] 905 Hosp Chinese Peoples Liberat Army, Dept Gastroenterol, Shanghai 200050, Peoples R China.
C3 Naval Medical University; Tencent; Naval Medical University; Kunming
   Medical University; Xi'an Jiaotong University; Nanjing Medical
   University; Nanjing Medical University; Hebei Medical University
RP Bai, Y (通讯作者)，Second Mil Med Univ, Naval Med Univ, Changhai Hosp, Dept Gastroenterol, 168 Changhai Rd, Shanghai 200433, Peoples R China.
EM baiyu1998@hotmail.com
RI 胜兵, 赵/IWV-4506-2023; Pan, Feng/IXN-2297-2023; wang,
   shuling/IST-4676-2023
FU National Key R&D Program of China [2018YFC1313103]; National Natural
   Science Foundation of China [81670473, 81873546]; "Shu Guang" Project of
   Shanghai Municipal Education Commission; Shanghai Education Development
   Foundation [19SG30]; Key Area Research and Development Program of
   Guangdong Province, China [2018B010111001]
FX the National Key R&D Program of China, No. 2018YFC1313103; the National
   Natural Science Foundation of China, No. 81670473 and No. 81873546; the
   "Shu Guang" Project of Shanghai Municipal Education Commission and
   Shanghai Education Development Foundation, No. 19SG30; and the Key Area
   Research and Development Program of Guangdong Province, China,
   No.2018B010111001.
CR Adler J, 2015, AM J GASTROENTEROL, V110, P1657, DOI 10.1038/ajg.2015.365
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Aniwan S, 2016, AM J GASTROENTEROL, V111, P723, DOI 10.1038/ajg.2015.440
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Atkins L, 2016, GASTROINTEST ENDOSC, V83, P617, DOI 10.1016/j.gie.2015.08.075
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Castaneda D, 2018, GASTROINTEST ENDOSC, V88, P209, DOI 10.1016/j.gie.2018.03.022
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Jaeger P. F., 2018, ARXIV181108661
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Robertson DJ, 2014, GUT, V63, P949, DOI 10.1136/gutjnl-2012-303796
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Zhao SB, 2022, CLIN GASTROENTEROL H, V20, pE168, DOI 10.1016/j.cgh.2020.11.019
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 34
TC 5
Z9 6
U1 1
U2 3
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD AUG 21
PY 2021
VL 27
IS 31
BP 5232
EP 5246
DI 10.3748/wjg.v27.i31.5232
PG 15
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA ZB6BW
UT WOS:000756926200001
PM 34497447
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Yoshida, N
   Inoue, K
   Tomita, Y
   Kobayashi, R
   Hashimoto, H
   Sugino, S
   Hirose, R
   Dohi, O
   Yasuda, H
   Morinaga, Y
   Inada, Y
   Murakami, T
   Zhu, X
   Itoh, Y
AF Yoshida, Naohisa
   Inoue, Ken
   Tomita, Yuri
   Kobayashi, Reo
   Hashimoto, Hikaru
   Sugino, Satoshi
   Hirose, Ryohei
   Dohi, Osamu
   Yasuda, Hiroaki
   Morinaga, Yukiko
   Inada, Yutaka
   Murakami, Takaaki
   Zhu, Xin
   Itoh, Yoshito
TI An analysis about the function of a new artificial intelligence, CAD EYE
   with the lesion recognition and diagnosis for colorectal polyps in
   clinical practice
SO INTERNATIONAL JOURNAL OF COLORECTAL DISEASE
LA English
DT Article
DE Artificial intelligence; BLI; CADe; CADx; CAD EYE
ID MISS RATE; CANCER; POLYPECTOMY; MULTICENTER; COLONOSCOPY; SOCIETY
AB Objectives Recently, CAD EYE (Fujifilm, Tokyo, Japan), an artificial intelligence for the lesion recognition (CADe) and the optical diagnosis (CADx) of colorectal polyps, was released. We evaluated the function of CADe and CADx of CAD EYE. Methods In this single-center retrospective study, we examined consecutive polyps <= 10 mm detected from March to April 2021 to determine whether CAD EYE could recognize them live with both normal- and high-speed observation using white-light imaging (WLI) and linked-color imaging (LCI). We then examined whether the polyps were neoplastic or hyperplastic live with magnified or non-magnified blue-laser imaging (BLI-LASER) or blue-light imaging (BLI-LED) under CAD EYE, comparing the retrospective evaluations with 5 experts and 5 trainees using still images. All polyps were histopathologically examined. Results We analyzed 100 polyps (mean size 3.9 +/- 2.6 mm; 55 neoplastic and 45 hyperplastic lesions) in 25 patients. Regarding CADe, the respective detection rates of CAD EYE with normal- and high-speed observation were 85.0% and 67.0% for WLI (p = 0.002) and 89.0% and 75.0% for LCI (p = 0.009). Regarding CADx for differentiating neoplastic and hyperplastic lesions, the diagnostic accuracy values of CAD EYE with non-magnified and magnified BLI-LASER/LED were 88.8% and 87.8%. Regarding magnified BLI-LASER/LED, the diagnostic accuracy value of CAD EYE was not significantly different from that of experts (92.0%, p = 0.17), but that of trainees (79.0%, p = 0.04). We also found no significant differences in CADe or CADx between LED (53 lesions) and LASER (47 lesions). Conclusions CAD EYE was a helpful tool for CADe and CADx in clinical practice.
C1 [Yoshida, Naohisa; Inoue, Ken; Tomita, Yuri; Kobayashi, Reo; Hashimoto, Hikaru; Sugino, Satoshi; Hirose, Ryohei; Dohi, Osamu; Yasuda, Hiroaki; Itoh, Yoshito] Kyoto Prefectural Univ Med, Grad Sch Med Sci, Dept Mol Gastroenterol & Hepatol, Kamigyo Ku, 465 Kajii Cho,Kawaramachi Hirokoji, Kyoto 6028566, Japan.
   [Morinaga, Yukiko] Kyoto Prefectural Univ Med, Grad Sch Med Sci, Dept Surg Pathol, Kyoto, Japan.
   [Inada, Yutaka] Kyoto First Red Cross Hosp, Dept Gastroenterol, Kyoto, Japan.
   [Murakami, Takaaki] Aiseikai Yamashina Hosp, Dept Gastroenterol, Kyoto, Japan.
   [Zhu, Xin] Univ Aizu, Biomed Informat Engn Lab, Fukushima, Japan.
C3 Kyoto Prefectural University of Medicine; Kyoto Prefectural University
   of Medicine; University of Aizu
RP Yoshida, N (通讯作者)，Kyoto Prefectural Univ Med, Grad Sch Med Sci, Dept Mol Gastroenterol & Hepatol, Kamigyo Ku, 465 Kajii Cho,Kawaramachi Hirokoji, Kyoto 6028566, Japan.
EM naohisa@koto.kpu-m.ac.jp
RI Inoue, Ken/ABH-1868-2021; Yasuda, Hiroaki/ABA-8525-2021
OI Inoue, Ken/0000-0002-6383-0576; Yasuda, Hiroaki/0000-0002-8346-9853;
   Yoshida, Naohisa/0000-0001-6167-9705
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ferlitsch M, 2017, ENDOSCOPY, V49, P270, DOI 10.1055/s-0043-102569
   Guo Z, 2021, DIGEST ENDOSC, V33, P162, DOI 10.1111/den.13670
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Ikematsu H, 2017, GASTROINTEST ENDOSC, V86, P386, DOI 10.1016/j.gie.2017.01.017
   Ikenoyama Y, 2021, DIGEST ENDOSC, V33, P141, DOI 10.1111/den.13688
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Nakajima Y, 2020, ENDOSC INT OPEN, V08, pE1341, DOI 10.1055/a-1220-6596
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   dos Santos CEO, 2019, GASTROINTEST ENDOSC, V90, P826, DOI 10.1016/j.gie.2019.06.045
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Shaukat A, 2020, GASTROENTEROLOGY, V159, P1916, DOI [10.1053/gastro.2020.08.050, 10.1053/j.gastro.2020.08.050]
   Shimoda R, 2017, ENDOSCOPY, V49, P186, DOI 10.1055/s-0042-118450
   Tanaka S, 2021, J GASTROENTEROL, V56, P323, DOI 10.1007/s00535-021-01776-1
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   WHO, 2019, CLASSIFICATION TUMOU, P532
   Yoshida N, 2020, INT J COLORECTAL DIS, V35, P815, DOI 10.1007/s00384-020-03532-y
   Yoshida N, 2020, DIGEST DIS SCI, V65, P2054, DOI 10.1007/s10620-019-05930-x
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zimmermann-Fraedrich K, 2019, GASTROENTEROLOGY, V157, P660, DOI 10.1053/j.gastro.2019.05.011
NR 26
TC 10
Z9 10
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0179-1958
EI 1432-1262
J9 INT J COLORECTAL DIS
JI Int. J. Colorectal Dis.
PD OCT
PY 2021
VL 36
IS 10
BP 2237
EP 2245
DI 10.1007/s00384-021-04006-5
EA AUG 2021
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA UP6II
UT WOS:000686027600002
PM 34406437
DA 2023-08-21
ER

PT J
AU Sakamoto, T
   Nakashima, H
   Nakamura, K
   Nagahama, R
   Saito, Y
AF Sakamoto, Taku
   Nakashima, Hirotaka
   Nakamura, Keiko
   Nagahama, Ryuji
   Saito, Yutaka
TI Performance of Computer-Aided Detection and Diagnosis of Colorectal
   Polyps Compares to That of Experienced Endoscopists
SO DIGESTIVE DISEASES AND SCIENCES
LA English
DT Article
DE Artificial intelligence; Computer-aided detection; Computer-aided
   diagnosis; Endoscopist
ID BAND; CHROMOENDOSCOPY; SYSTEM; COLONOSCOPY
AB Background Differential diagnosis of neoplasms and non-neoplasms is crucial in ensuring appropriate and proper medical management for patients undergoing colonoscopy. Diagnostic ability can vary, depending on the colonoscopist's experience. To overcome this issue, artificial intelligence (AI) may be effective. Aims To assess the performance of a computer-aided detection (CADe) and a computer-aided diagnosis (CADx) system for the detection and characterization of colorectal polyps by comparing their data with those of experienced endoscopists. Methods This retrospective, still image-based validation study was conducted at three Japanese medical centers. A total of 579 white-light images (WLIs) and 605 linked color images (LCIs) were used for testing the CADe and 308 WLIs and 296 blue laser/light images (BLIs) for testing the CADx. The performances of the CADe and CADx systems were assessed and compared with the correct answers provided by three experienced endoscopists. Results CADe in WLI demonstrated a sensitivity of 94.5% (95% confidence interval (CI), 92.0-96.9%) and a specificity of 87.2% (84.5-89.9%). CADe in LCI demonstrated a sensitivity of 96.0% (93.9-98.1%) and a specificity of 85.1% (82.3-87.9%). CADx in WLI demonstrated a sensitivity of 95.5% (92.9-98.1%) and a specificity of 84.4% (73.4-91.5%), resulting in an accuracy of 93.2% (90.4-96.0%). CADx in BLI showed a sensitivity of 96.3% (93.9-98.7%) and a specificity of 88.7% (77.1-95.1%), resulting in an accuracy of 94.9% (92.4-97.4%). Conclusions CADe and CADx demonstrated sufficient diagnostic performance to support the use of an AI system.
C1 [Sakamoto, Taku; Nakamura, Keiko; Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.
   [Nakashima, Hirotaka] Fdn Detect Early Gastr Carcinoma, Dept Endoscopy, Chuo Ku, 2-6-12 Nihombashi Kayabacho, Tokyo 1030025, Japan.
   [Nagahama, Ryuji] Chiba Tokushukai Hosp, Dept Endoscopy, 2-11-1 Takanedai, Funabashi, Chiba 2748503, Japan.
   [Nagahama, Ryuji] New Tokyo Hosp, Dept Gastroenterol, 1271 Wanagaya, Matsudo, Chiba 2702232, Japan.
C3 National Cancer Center - Japan
RP Sakamoto, T (通讯作者)，Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.
EM tasakamo@ncc.go.jp
FU FUJIFILM Corporation
FX LThe primary funding source was FUJIFILM Corporation.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Guo TJ, 2018, J GASTROENTEROL, V53, P701, DOI 10.1007/s00535-018-1436-4
   Hassan C, 2020, ENDOSCOPY, V52, P687, DOI 10.1055/a-1185-3109
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Ikematsu H, 2017, GASTROINTEST ENDOSC, V86, P386, DOI 10.1016/j.gie.2017.01.017
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Shinozaki S, 2020, DIGEST ENDOSC, V32, P874, DOI 10.1111/den.13613
   Su MY, 2006, AM J GASTROENTEROL, V101, P2711, DOI 10.1111/j.1572-0241.2006.00932.x
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   Togashi K, 2009, GASTROINTEST ENDOSC, V69, P734, DOI 10.1016/j.gie.2008.10.063
   Uraoka T, 2015, J GASTROENTEROL, V50, P555, DOI 10.1007/s00535-014-0999-y
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   Yamada M, 2015, GASTROINTEST ENDOSC, V82, P108, DOI 10.1016/j.gie.2014.12.037
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 20
TC 7
Z9 7
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0163-2116
EI 1573-2568
J9 DIGEST DIS SCI
JI Dig. Dis. Sci.
PD AUG
PY 2022
VL 67
IS 8
BP 3976
EP 3983
DI 10.1007/s10620-021-07217-6
EA AUG 2021
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 2Y6KM
UT WOS:000685590400001
PM 34403031
DA 2023-08-21
ER

PT J
AU Li, JW
   Chia, T
   Fock, KM
   Chong, KD
   Wong, YJ
   Ang, TL
AF Li, James Weiquan
   Chia, Tiongsun
   Fock, Kwong Ming
   Chong, Kenny De Wei
   Wong, Yu Jun
   Ang, Tiing Leong
TI Artificial intelligence and polyp detection in colonoscopy: Use of a
   single neural network to achieve rapid polyp localization for clinical
   use
SO JOURNAL OF GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE Gastroenterology; artificial intelligence; polyp detection;
   Gastroenterology; colorectal cancer; clinical research;
   Gastroenterology; endoscopy; colon
ID COLORECTAL-CANCER; VALIDATION; SOCIETY; SYSTEM; RISK
AB Background and Aim: Artificial intelligence has been extensively studied to assist clinicians in polyp detection, but such systems usually require expansive processing power, making them prohibitively expensive and hindering wide adaption. The current study used a fast object detection algorithm, known as the YOLOv3 algorithm, to achieve real-time polyp detection on a laptop. In addition, we evaluated and classified the causes of false detections to further improve accuracy.
   Methods: The YOLOv3 algorithm was trained and validated with 6038 and 2571 polyp images, respectively. Videos from live colonoscopies in a tertiary center and those obtained from public databases were used for the training and validation sets. The algorithm was tested on 10 unseen videos from the CVC-Video ClinicDB dataset. Only bounding boxes with an intersection over union area of > 0.3 were considered positive predictions.
   Results: Polyp detection rate in our study was 100%, with the algorithm able to detect every polyp in each video. Sensitivity, specificity, and F1 score were 74.1%, 85.1%, and 83.3, respectively. The algorithm achieved a speed of 61.2 frames per second (fps) on a desktop RTX2070 GPU and 27.2 fps on a laptop GTX2060 GPU. Nearly a quarter of false negatives happened when the polyps were at the corner of an image. Image blurriness accounted for approximately 3% and 9% of false positive and false negative detections, respectively.
   Conclusion: The YOLOv3 algorithm can achieve real-time poly detection with high accuracy and speed on a desktop GPU, making it low cost and accessible to most endoscopy centers worldwide.
C1 [Li, James Weiquan; Fock, Kwong Ming; Wong, Yu Jun; Ang, Tiing Leong] Singapore Hlth Serv, Changi Gen Hosp, Dept Gastroenterol & Hepatol, 2 Simei St 3, Singapore 529889, Singapore.
   [Li, James Weiquan; Fock, Kwong Ming; Ang, Tiing Leong] Natl Univ Singapore, Yong Loo Lin Sch Med, Singapore, Singapore.
   [Li, James Weiquan; Fock, Kwong Ming; Wong, Yu Jun; Ang, Tiing Leong] ShgHlth Duke NUS, Med Acad Clin Programme, Singapore, Singapore.
   [Chia, Tiongsun; Chong, Kenny De Wei] GI Tech Ltd, Singapore, Singapore.
C3 Changi General Hospital; National University of Singapore
RP Li, JW (通讯作者)，Singapore Hlth Serv, Changi Gen Hosp, Dept Gastroenterol & Hepatol, 2 Simei St 3, Singapore 529889, Singapore.
EM james.li.w.q@singhealth.com.sg
RI Li, James Weiquan/AGK-7514-2022; Wong, Yu Jun/AAO-8030-2020; Li, James
   Weiquan/HCI-6598-2022
OI Li, James Weiquan/0000-0002-5241-4278; Wong, Yu Jun/0000-0002-0727-1183;
   Li, James Weiquan/0000-0002-5241-4278
CR Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Araghi M, 2019, INT J CANCER, V144, P2992, DOI 10.1002/ijc.32055
   Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bray F, 2012, LANCET ONCOL, V13, P790, DOI 10.1016/S1470-2045(12)70211-5
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Li JW, 2021, ARTIF INTELL GASTROI, V2, P36
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Russakovsky O, 2015, PROC CVPR IEEE, P2121, DOI 10.1109/CVPR.2015.7298824
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Zhou J, 2020, GASTROINTEST ENDOSC, V91, P428, DOI 10.1016/j.gie.2019.11.026
NR 30
TC 8
Z9 9
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0815-9319
EI 1440-1746
J9 J GASTROEN HEPATOL
JI J. Gastroenterol. Hepatol.
PD DEC
PY 2021
VL 36
IS 12
BP 3298
EP 3307
DI 10.1111/jgh.15642
EA AUG 2021
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA XQ7AE
UT WOS:000685574200001
PM 34327729
DA 2023-08-21
ER

PT J
AU Chen, BL
   Wan, JJ
   Chen, TY
   Yu, YT
   Ji, M
AF Chen, Bo-Lun
   Wan, Jing-Jing
   Chen, Tai-Yue
   Yu, Yong-Tao
   Ji, Min
TI A self-attention based faster R-CNN for polyp detection from colonoscopy
   images
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Colorectal cancer; Polyp detection; Contrast enhancement; Feature
   extraction network
ID COLORECTAL-CANCER; NEURAL-NETWORK; COLON; SEGMENTATION; VISION
AB At present, the incidence rate of colorectal cancer (CRC) is increasing year by year. It has always affected people's physical and mental health and quality of life. How to improve the detection ability of polyp plays a key role in colonoscopy. In order to solve these problems, in this paper, we first enhance the contrast of the input image by well distinguishing the foreground from the background in order to improve the saliency of the polyp regions. Then, we feed the enhanced image into an improved Faster R-CNN architecture comprised three processing modules for feature extraction, region proposal generation, and polyp detection, respectively. In order to further improve the quality, as well as the feature abstraction capability of the feature maps produced by the feature extraction network, we append an attention module to attend to the useful feature channels and weaken the contributions of the helpless feature channels. The experimental results demonstrate that the accuracy of the proposed polyp detection network is greatly improved compared with the existing algorithms, and the network not only can accurately identify polyps of varying sizes and conditions in single polyp images, but also can achieve excellent performance in handling multiple polyp images. This paper will be greatly helpful to alleviate the missed diagnosis of clinicians in the process of endoscopic examination and disease treatment, as well as providing effective assistance for the early diagnosis, treatment and prevention of the CRC, which is also of great significance to the clinical work of physicians.
C1 [Chen, Bo-Lun; Chen, Tai-Yue; Yu, Yong-Tao; Ji, Min] Huaiyin Inst Technol, Dept Comp Sci, Huaiyin 223001, Peoples R China.
   [Wan, Jing-Jing] Xuzhou Med Univ, Peoples Hosp Huaian 2, Affiliated Huaian Hosp, Dept Gastroenterol, Huaian 223002, Peoples R China.
   [Chen, Bo-Lun] Univ Fribourg, Dept Phys, CH-1700 Fribourg, Switzerland.
C3 Huaiyin Institute of Technology; Xuzhou Medical University; University
   of Fribourg
RP Chen, BL (通讯作者)，Huaiyin Inst Technol, Dept Comp Sci, Huaiyin 223001, Peoples R China.; Chen, BL (通讯作者)，Univ Fribourg, Dept Phys, CH-1700 Fribourg, Switzerland.
EM chenbolun1986@163.com
OI Chen, Bolun/0000-0002-1341-4187
FU National Natural Science Foundation of China [61602202, 62076107];
   Natural Science Foundation of Jiangsu Province [BK20160428]; Natural
   Science Foundation of Education Department of Jiangsu Province
   [20KJA520008]; Six talent peaks project in Jiangsu Province [XYDXX-034];
   China Scholarship Council
FX This research was supported in part by the National Natural Science
   Foundation of China under grant No. 61602202 and 62076107, Natural
   Science Foundation of Jiangsu Province under contracts No. BK20160428
   and Natural Science Foundation of Education Department of Jiangsu
   Province under contract No. 20KJA520008. Six talent peaks project in
   Jiangsu Province (Grant No. XYDXX-034). China ScholarshipCouncil also
   supported this work.
CR Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   American Cancer Society, 2017, CANC FACTS FIGURES 2
   Bagheri M, 2019, IEEE ENG MED BIO, P6742, DOI 10.1109/EMBC.2019.8856793
   Bailey CE, 2015, JAMA SURG, V150, P17, DOI 10.1001/jamasurg.2014.1756
   Bardhi O, 2017, IEEE INT SYMP SIGNAL, P445, DOI 10.1109/ISSPIT.2017.8388684
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Billah M, 2020, MULTIMED TOOLS APPL, V79, P23633, DOI 10.1007/s11042-020-09151-7
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Burke Carol, 2017, Gastroenterol Hepatol (N Y), V13, P1
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Henriksen FL, 2019, COMP MED SY, P287, DOI 10.1109/CBMS.2019.00067
   Hwang S., 2007, 2007 IEEE INT C IM P
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Liang ZT, 2018, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2018.00500
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Ma Y., 2020, 2020 IEEE 17 INT S B
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Martinez F., 2019, 2019 22 S IM SIGN PR, P1
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Pozdeev AA, 2019, IEEE NW RUSS YOUNG, P1216, DOI 10.1109/EIConRus.2019.8657018
   Qadir HA, 2019, IEEE ACCESS, V7, P169537, DOI 10.1109/ACCESS.2019.2954675
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Sasmal P, 2018, INT CONF CIRC SYST S, P201, DOI 10.1109/ICSIGSYS.2018.8372666
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tashk A, 2020, IEEE C EVOL COMPUTAT
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Yang JJ, 2020, INT J COMPUT ASS RAD, V15, P1291, DOI 10.1007/s11548-020-02190-3
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yu Tian, 2019, 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), P70, DOI 10.1109/ISBI.2019.8759521
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zheng H, 2019, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2019.8759180
NR 40
TC 9
Z9 10
U1 2
U2 6
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD SEP
PY 2021
VL 70
AR 103019
DI 10.1016/j.bspc.2021.103019
EA AUG 2021
PG 9
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA UU3FE
UT WOS:000698684500006
DA 2023-08-21
ER

PT J
AU Joseph, J
   LePage, EM
   Cheney, CP
   Pawa, R
AF Joseph, Joel
   LePage, Ella Marie
   Cheney, Catherine Phillips
   Pawa, Rishi
TI Artificial intelligence in colonoscopy
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Colonoscopy; Artificial intelligence; Computer-aided detection;
   Detection; Characterization; Computer-aided diagnosis
ID COMPUTER-AIDED DETECTION; DETECTION-ASSISTED COLONOSCOPY; CONFOCAL LASER
   ENDOMICROSCOPY; COLORECTAL POLYP HISTOLOGY; WHITE-LIGHT COLONOSCOPY;
   REAL-TIME; OPTICAL DIAGNOSIS; QUANTITATIVE-ANALYSIS; DETECTION SYSTEM;
   CLASSIFICATION
AB Colorectal cancer remains a leading cause of morbidity and mortality in the United States. Advances in artificial intelligence (AI), specifically computer aided detection and computer-aided diagnosis offer promising methods of increasing adenoma detection rates with the goal of removing more pre-cancerous polyps. Conversely, these methods also may allow for smaller non-cancerous lesions to be diagnosed in vivo and left in place, decreasing the risks that come with unnecessary polypectomies. This review will provide an overview of current advances in the use of AI in colonoscopy to aid in polyp detection and characterization as well as areas of developing research.
C1 [Joseph, Joel; LePage, Ella Marie] Wake Forest Baptist Med Ctr, Dept Internal Med, Winston Salem, NC 27157 USA.
   [Cheney, Catherine Phillips] Wake Forest Sch Med, Dept Internal Med, Winston Salem, NC 27157 USA.
   [Pawa, Rishi] Wake Forest Baptist Med Ctr, Dept Internal Med, Sect Gastroenterol & Hepatol, Med Ctr Blvd, Winston Salem, NC 27157 USA.
C3 Wake Forest University; Wake Forest Baptist Medical Center; Wake Forest
   University; Wake Forest University; Wake Forest Baptist Medical Center
RP Pawa, R (通讯作者)，Wake Forest Baptist Med Ctr, Dept Internal Med, Sect Gastroenterol & Hepatol, Med Ctr Blvd, Winston Salem, NC 27157 USA.
EM rpawa@wakehealth.edu
OI Cheney, Catherine/0000-0001-8168-9572
CR Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   American Cancer Society, 2020, COL CANC FACTS FIG 2
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Arita K, 2011, ONCOL REP, V26, P43, DOI 10.3892/or.2011.1287
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Brown SR, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006439.pub4
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chauhan SS, 2014, GASTROINTEST ENDOSC, V80, P928, DOI 10.1016/j.gie.2014.06.021
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Eickhoff A, 2007, AM J GASTROENTEROL, V102, P261, DOI 10.1111/j.1572-0241.2006.01002.x
   Fisher DA, 2011, GASTROINTEST ENDOSC, V74, P745, DOI 10.1016/j.gie.2011.07.025
   Formosa GA, 2020, IEEE T ROBOT, V36, P545, DOI 10.1109/TRO.2019.2949466
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hafner M, 2009, LECT NOTES COMPUT SC, V5761, P247, DOI 10.1007/978-3-642-04268-3_31
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Imperatore N, 2019, J CROHNS COLITIS, V13, P714, DOI 10.1093/ecco-jcc/jjy218
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Kahi CJ, 2009, CLIN GASTROENTEROL H, V7, P770, DOI 10.1016/j.cgh.2008.12.030
   Kanao H, 2008, WORLD J GASTROENTERO, V14, P211, DOI 10.3748/wjg.14.211
   KAPADIA CR, 1990, GASTROENTEROLOGY, V99, P150, DOI 10.1016/0016-5085(90)91242-X
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kim KO, 2021, GUT LIVER, V15, P346, DOI 10.5009/gnl20186
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Klare P, 2016, ENDOSCOPY, V48, P909, DOI 10.1055/s-0042-110650
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Kudo S, 2014, J GASTROEN HEPATOL, V29, P83, DOI 10.1111/jgh.12374
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   McGill SK, 2013, GUT, V62, P1704, DOI 10.1136/gutjnl-2012-303965
   Min M, 2017, GASTROINTEST ENDOSC, V86, P724, DOI 10.1016/j.gie.2017.02.035
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Pullens HJM, 2016, ENDOSCOPY, V48, P286, DOI 10.1055/s-0034-1392550
   Qi X, 2008, J BIOMED OPT, V13, DOI 10.1117/1.2993323
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Renkoski TE, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.1.016005
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2016, GASTROINTEST ENDOSC, V83, P166, DOI 10.1016/j.gie.2015.03.1915
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Slawinski PR, 2018, GASTROENTEROLOGY, V154, P1577, DOI 10.1053/j.gastro.2018.02.037
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Takeuchi Y, 2019, GASTROINTEST ENDOSC, V89, P460, DOI 10.1016/j.gie.2018.11.012
   Taunk P, 2019, INT J COLORECTAL DIS, V34, P2043, DOI 10.1007/s00384-019-03406-y
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wanders LK, 2013, LANCET ONCOL, V14, P1337, DOI 10.1016/S1470-2045(13)70509-6
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Yang DH, 2019, AM J GASTROENTEROL, V114, P1642, DOI 10.14309/ajg.0000000000000341
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 67
TC 4
Z9 4
U1 4
U2 13
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD AUG 7
PY 2021
VL 27
IS 29
BP 4802
EP 4817
DI 10.3748/wjg.v27.i29.4802
PG 16
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA UJ2AZ
UT WOS:000691096200004
PM 34447227
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Eu, CY
   Tang, TB
   Lin, CH
   Lee, LH
   Lu, CK
AF Eu, Chin Yii
   Tang, Tong Boon
   Lin, Cheng-Hung
   Lee, Lok Hua
   Lu, Cheng-Kai
TI Automatic Polyp Segmentation in Colonoscopy Images Using a Modified Deep
   Convolutional Encoder-Decoder Architecture
SO SENSORS
LA English
DT Article
DE colorectal cancer; computer-aided diagnosis (CAD); SegNet Visual
   Geometry Group-19 (VGG-19); convolutional neural network (CNN); polyp
   segmentation
AB Colorectal cancer has become the third most commonly diagnosed form of cancer, and has the second highest fatality rate of cancers worldwide. Currently, optical colonoscopy is the preferred tool of choice for the diagnosis of polyps and to avert colorectal cancer. Colon screening is time-consuming and highly operator dependent. In view of this, a computer-aided diagnosis (CAD) method needs to be developed for the automatic segmentation of polyps in colonoscopy images. This paper proposes a modified SegNet Visual Geometry Group-19 (VGG-19), a form of convolutional neural network, as a CAD method for polyp segmentation. The modifications include skip connections, 5 x 5 convolutional filters, and the concatenation of four dilated convolutions applied in parallel form. The CVC-ClinicDB, CVC-ColonDB, and ETIS-LaribPolypDB databases were used to evaluate the model, and it was found that our proposed polyp segmentation model achieved an accuracy, sensitivity, specificity, precision, mean intersection over union, and dice coefficient of 96.06%, 94.55%, 97.56%, 97.48%, 92.3%, and 95.99%, respectively. These results indicate that our model performs as well as or better than previous schemes in the literature. We believe that this study will offer benefits in terms of the future development of CAD tools for polyp segmentation for colorectal cancer diagnosis and management. In the future, we intend to embed our proposed network into a medical capsule robot for practical usage and try it in a hospital setting with clinicians.
C1 [Eu, Chin Yii; Tang, Tong Boon; Lee, Lok Hua; Lu, Cheng-Kai] Univ Teknol PETRONAS, Dept Elect & Elect Engn, Seri Iskandar 32610, Perak, Malaysia.
   [Lin, Cheng-Hung] Yuan Ze Univ, Res Ctr, Dept Elect Engn & Biomed Engn, Jhongli 32003, Taiwan.
C3 Universiti Teknologi Petronas; Yuan Ze University
RP Lu, CK (通讯作者)，Univ Teknol PETRONAS, Dept Elect & Elect Engn, Seri Iskandar 32610, Perak, Malaysia.
EM chin_19000297@utp.edu.my; tongboon.tang@utp.edu.my;
   chlin@saturn.yzu.edu.tw; lee.lok_24987@utp.edu.my;
   chengkai.lu@utp.edu.my
RI Tang, Tong Boon/G-5610-2011; Lin, Cheng-Hung/V-5553-2019
OI Tang, Tong Boon/0000-0002-5721-6828; Lin,
   Cheng-Hung/0000-0001-8373-2271; Lu, ChengKai/0000-0002-5819-0754; LEE,
   LOK HUA/0000-0002-9762-7226
FU Ministry of Higher Education, Malaysia [FRGS/1/2020/TK0/UTP/02/23];
   Ministry of Science and Technology, Taiwan [110-2221-E-155-013]
FX This work was supported by the Ministry of Higher Education, Malaysia,
   under Grant FRGS/1/2020/TK0/UTP/02/23. It was also partially funded by
   the Ministry of Science and Technology, Taiwan, under Grant
   110-2221-E-155-013.
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   [Anonymous], TESTS DETECT COLOREC
   [Anonymous], MAJORITY CANC CASES
   Azimi SM, 2019, IEEE T GEOSCI REMOTE, V57, P2920, DOI 10.1109/TGRS.2018.2878510
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bagheri M, 2019, IEEE ENG MED BIO, P6742, DOI 10.1109/EMBC.2019.8856793
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Cao Yu, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P2349
   Dutta S, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   Hamaguchi R, 2018, IEEE WINT CONF APPL, P1442, DOI 10.1109/WACV.2018.00162
   Han CY, 2019, IEEE ACCESS, V7, P43369, DOI 10.1109/ACCESS.2019.2908685
   Huang CH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP)
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar P, 2018, IEEE IMAGE PROC, P3503, DOI 10.1109/ICIP.2018.8451295
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Liew WS, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106114
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Meng J, 2020, OPEN LIFE SCI, V15, P588, DOI 10.1515/biol-2020-0055
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Nguyen NQ, 2019, IEEE ACCESS, V7, P33795, DOI 10.1109/ACCESS.2019.2904094
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Sanchez-Peralta LF, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8081316
   Sasmal P, 2018, INT CONF CIRC SYST S, P201, DOI 10.1109/ICSIGSYS.2018.8372666
   Sengar N, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P529, DOI 10.1109/TSP.2016.7760936
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K., ARXIV
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Szegedy, 2015, ICML, DOI DOI 10.1080/17512786.2015.1058180
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   YU F, 2015, 1511 ARXIV, V1511, DOI DOI 10.1109/CVPR.2017.660
   Yu JY, 2019, I C DATA ENGIN WORKS, P306, DOI 10.1109/ICDEW.2019.00010
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 41
TC 1
Z9 1
U1 3
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD AUG
PY 2021
VL 21
IS 16
AR 5630
DI 10.3390/s21165630
PG 24
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA UH6WJ
UT WOS:000690068100001
PM 34451072
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Li, JL
   Lu, JX
   Yan, J
   Tan, YY
   Liu, DL
AF Li, Jianglei
   Lu, Jiaxi
   Yan, Jin
   Tan, Yuyong
   Liu, Deliang
TI Artificial intelligence can increase the detection rate of colorectal
   polyps and adenomas: a systematic review and meta-analysis
SO EUROPEAN JOURNAL OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Review
DE adenoma; artificial intelligence; colonoscopy; detection rate;
   meta-analysis; polyp
ID COMPUTER-AIDED DETECTION; DIAGNOSIS; CANCER
AB Colonoscopy is an important method to diagnose polyps, especially adenomatous polyps. However, the rate of missed diagnoses is relatively high. In this study, we aimed to determine whether artificial intelligence (AI) improves the polyp detection rate (PDR) and adenoma detection rate (ADR) with colonoscopy. We performed a systematic search in PubMed, Cochrane Library, Embase, and Web of Science databases; the search included entries in the databases up to and including 29 February 2020. Five articles that involved a total of 4311 patients fulfilled the selection criteria. The results of these studies showed that both PDR and ADR increased with the assistance of AI compared with those in control groups {pooled odds ratio (OR) = 1.91 [95% confidence interval (CI) 1.68-2.16] and 1.75 (95% CI 1.52-2.01), respectively}. Good bowel preparation reduced the impact of AI, but significant differences were still apparent in PDR and ADR [pooled OR = 1.69 (95% CI 1.32-2.16) and 1.36 (95% CI 1.04-1.78), respectively]. The characteristics of polyps and adenomas also influenced the results. The average number of polyps and adenomas detected varied significantly by location, and small polyps and adenomas were more likely to be missed. However, the effect of the morphology of polyps and AI-assisted detection needs further studies. In conclusion, AI increases the detection rates of polyps and adenomas in colonoscopy. Without AI assistance, detection rates can be improved with better bowel preparation and training for small polyp and adenoma detection.
C1 [Li, Jianglei; Lu, Jiaxi; Yan, Jin; Tan, Yuyong; Liu, Deliang] Cent South Univ, Second Xiangya Hosp, Dept Gastroenterol, Changsha, Hunan, Peoples R China.
   [Li, Jianglei; Lu, Jiaxi; Yan, Jin; Tan, Yuyong; Liu, Deliang] Cent South Univ, Res Ctr Digest Dis, Changsha, Hunan, Peoples R China.
C3 Central South University; Central South University
RP Liu, DL (通讯作者)，Second Xiangya Hosp, Dept Gastroenterol, 139 Middle Renmin Rd, Changsha 410011, Hunan, Peoples R China.
EM deliangliu@csu.edu.cn
RI Tan, Yuyong/GRX-2029-2022
OI Tan, Yuyong/0000-0002-0571-3136
FU Key Research Project of Hunan Province [2018SK21311]
FX The study is supported by the Key Research Project of Hunan Province
   (2018SK21311).
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   [Anonymous], CA CANCER J CLIN, DOI [10.3322/CAAC.21254, DOI 10.3322/caac.21254]
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Brody H, 2015, NATURE, V526, pS1, DOI [10.1038/526S1a, 10.1038/521S1a]
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Malhotra Ashish, 2017, Am J Gastroenterol, V112, P1031, DOI 10.1038/ajg.2017.191
   Marmol I, 2017, INT J MOL SCI, V18, DOI 10.3390/ijms18010197
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Pan JQ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63827-6
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 28
TC 6
Z9 6
U1 0
U2 9
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0954-691X
EI 1473-5687
J9 EUR J GASTROEN HEPAT
JI Eur. J. Gastroenterol. Hepatol.
PD AUG
PY 2021
VL 33
IS 8
BP 1041
EP 1048
DI 10.1097/MEG.0000000000001906
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA TE5FI
UT WOS:000670036400001
PM 32804846
DA 2023-08-21
ER

PT J
AU Sziova, B
   Nagy, S
   Fazekas, Z
AF Sziova, Brigita
   Nagy, Szilvia
   Fazekas, Zoltan
TI Application of Structural Entropy and Spatial Filling Factor in
   Colonoscopy Image Classification
SO ENTROPY
LA English
DT Article
DE computer-aided diagnostics; colour spaces; colonoscopy; Renyi entropies;
   structural entropy; fuzzy classification
ID COLORECTAL NEOPLASIA; VALIDATION; DIAGNOSIS; POLYPS
AB For finding colorectal polyps the standard method relies on the techniques and devices of colonoscopy and the medical expertise of the gastroenterologist. In case of images acquired through colonoscopes the automatic segmentation of the polyps from their environment (i.e., from the bowel wall) is an essential task within computer aided diagnosis system development. As the number of the publicly available polyp images in various databases is still rather limited, it is important to develop metaheuristic methods, such as fuzzy inference methods, along with the deep learning algorithms to improve and validate detection and classification techniques. In the present manuscript firstly a fuzzy rule set is generated and validated. The former process is based on a statistical approach and makes use of histograms of the antecedents. Secondly, a method for selecting relevant antecedent variables is presented. The selection is based on the comparision of the histograms computed from the measured values for the training set. Then the inclusion of the Renyi-entropy-based structural entropy and the spatial filling factor into the set of input variables is proposed and assessed. The beneficial effect of including the mentioned structural entropy of the entropies from the hue and saturation (H and S) colour channels resulted in 65% true positive and 60% true negative rate of the classification for an advantageously selected set of antecedents when working with HSV images.
C1 [Sziova, Brigita] Szechenyi Istvan Univ, Dept Comp Sci, Egyet Ter 1, H-9026 Gyor, Hungary.
   [Nagy, Szilvia] Szechenyi Istvan Univ, Dept Telecommun, Egyet Ter 1, H-9026 Gyor, Hungary.
   [Fazekas, Zoltan] Eotvos Lorand Res Network ELKH, Inst Comp Sci & Control SZTAKI, 13-17 Kende Utca, H-1111 Budapest, Hungary.
C3 University of Istvan Szechenyi; University of Istvan Szechenyi; Eotvos
   Lorand Research Network; Hungarian Academy of Sciences; Hungarian
   Institute for Computer Science & Control
RP Sziova, B (通讯作者)，Szechenyi Istvan Univ, Dept Comp Sci, Egyet Ter 1, H-9026 Gyor, Hungary.
EM szi.brigitta@sze.hu; nagysz@sze.hu; zoltan.fazekas@sztaki.hu
RI Nagy, Szilvia/HLG-6619-2023
OI Sziova, Brigita/0000-0001-6400-2767; Nagy, Szilvia/0000-0001-9556-5095;
   Fazekas, Zoltan/0000-0001-5159-4476
FU uNKP-20-4-II-SZE-69 New National Excellence Program of the Ministry for
   Innovation and Technology from the source of the National Research,
   Development and Innovation Fund
FX Supported by the uNKP-20-4-II-SZE-69 New National Excellence Program of
   the Ministry for Innovation and Technology from the source of the
   National Research, Development and Innovation Fund.
CR Amigo JM, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110813
   [Anonymous], 1927, GOTTINGEN NACHRICHTE
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bonyar A, 2016, MICRON, V87, P1, DOI 10.1016/j.micron.2016.05.002
   Bonyar A, 2012, MICRON, V43, P305, DOI 10.1016/j.micron.2011.09.005
   Bosman F.T., 2014, WORLD CANC REPORT IN
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Enns RA, 2017, GASTROENTEROLOGY, V152, P497, DOI 10.1053/j.gastro.2016.12.032
   Fenlon HM, 1999, NEW ENGL J MED, V341, P1496, DOI 10.1056/NEJM199911113412003
   FODOR JC, 1991, FUZZY SET SYST, V41, P195, DOI 10.1016/0165-0114(91)90223-D
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Jass JR, 2007, HISTOPATHOLOGY, V50, P113, DOI 10.1111/j.1365-2559.2006.02549.x
   KOCZY LT, 1993, INFORM SCIENCES, V71, P169, DOI 10.1016/0020-0255(93)90070-3
   KOCZY LT, 1993, INT J APPROX REASON, V9, P197, DOI 10.1016/0888-613X(93)90010-B
   Kudo S, 2001, ENDOSCOPY, V33, P367
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   Menardo G, 2004, Tech Coloproctol, V8 Suppl 2, ps273, DOI 10.1007/s10151-004-0175-0
   Mojzes I, 2007, APPL PHYS LETT, V91, DOI 10.1063/1.2768911
   Nagy S.Z., 2018, P FUZZIEEE 2018 RIO, P1
   Nagy S.Z., 2017, P 5 INT WORKSH ADV C
   Nagy S, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030256
   Nagy S, 2017, IEEE INT CONF FUZZY
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   PIPEK J, 1992, PHYS REV A, V46, P3148, DOI 10.1103/PhysRevA.46.3148
   Renyi A., 1961, S MATH STAT PROB, P547
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song HJ, 2016, INTEST RES, V14, P21, DOI 10.5217/ir.2016.14.1.21
   Soreide K, 2009, EXPERT REV MOL DIAGN, V9, P125, DOI 10.1586/14737159.9.2.125
   Soumelidis A., 2005, P 44 IEEE C DEC CONT
   Stantchev I., 1986, CYBERNETICS SYSTEMS, P139, DOI [10.1007/978-94-009-4634-7_19, DOI 10.1007/978-94-009-4634-7_19]
   Sziova B., 2018, RECENT DEV NEW DIREC, P347
   Sziova B, 2020, IEEE INT CONF FUZZY, DOI 10.1109/fuzz48607.2020.9177839
   Takacs O, 2002, IEEE T INSTRUM MEAS, V51, P217, DOI 10.1109/19.997815
   Tikk D, 2002, FUZZY SET SYST, V125, P105, DOI 10.1016/S0165-0114(00)00104-4
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   Varga I, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.026202
   WEBER S, 1983, FUZZY SET SYST, V11, P115, DOI 10.1016/S0165-0114(83)80073-6
   Wu F., 2017, P 10 INT C IM SIGN P, DOI [10.1109/CISP-BMEI.2017.8301957, DOI 10.1109/CISP-BMEI.2017.8301957]
   ZADEH LA, 1968, INFORM CONTROL, V12, P94, DOI 10.1016/S0019-9958(68)90211-8
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 46
TC 3
Z9 3
U1 1
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1099-4300
J9 ENTROPY-SWITZ
JI Entropy
PD AUG
PY 2021
VL 23
IS 8
AR 936
DI 10.3390/e23080936
PG 30
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA UI2WB
UT WOS:000690473100001
PM 34441076
OA Green Accepted, Green Published, gold
DA 2023-08-21
ER

PT J
AU Tang, CP
   Chen, KH
   Lin, TL
AF Tang, Chia-Pei
   Chen, Kai-Hong
   Lin, Tu-Liang
TI Computer-Aided Colon Polyp Detection on High Resolution Colonoscopy
   Using Transfer Learning Techniques
SO SENSORS
LA English
DT Article
DE object detection; medical information systems; colon polyp detection;
   colonoscopy; transfer learning
ID COLORECTAL-CANCER; MISS RATE; CLASSIFICATION; PREVENTION; VALIDATION
AB Colonoscopies reduce the incidence of colorectal cancer through early recognition and resecting of the colon polyps. However, the colon polyp miss detection rate is as high as 26% in conventional colonoscopy. The search for methods to decrease the polyp miss rate is nowadays a paramount task. A number of algorithms or systems have been developed to enhance polyp detection, but few are suitable for real-time detection or classification due to their limited computational ability. Recent studies indicate that the automated colon polyp detection system is developing at an astonishing speed. Real-time detection with classification is still a yet to be explored field. Newer image pattern recognition algorithms with convolutional neuro-network (CNN) transfer learning has shed light on this topic. We proposed a study using real-time colonoscopies with the CNN transfer learning approach. Several multi-class classifiers were trained and mAP ranged from 38% to 49%. Based on an Inception v2 model, a detector adopting a Faster R-CNN was trained. The mAP of the detector was 77%, which was an improvement of 35% compared to the same type of multi-class classifier. Therefore, our results indicated that the polyp detection model could attain a high accuracy, but the polyp type classification still leaves room for improvement.
C1 [Tang, Chia-Pei] Dalin Tzu Chi Hosp, Buddhist Tzu Chi Med Fdn, Dept Internal Med, Div Gastroenterol, Chiayi 62247, Taiwan.
   [Tang, Chia-Pei] Tzu Chi Univ, Sch Med, Hualien 97004, Taiwan.
   [Chen, Kai-Hong; Lin, Tu-Liang] Natl Chiayi Univ, Dept Management Informat Syst, Chiayi 60054, Taiwan.
C3 Buddhist Tzu Chi General Hospital; Dalin Tzu Chi Hospital; Tzu Chi
   University; National Chiayi University
RP Lin, TL (通讯作者)，Natl Chiayi Univ, Dept Management Informat Syst, Chiayi 60054, Taiwan.
EM franktg@hotmail.com; kaihong@mis.ncyu.edu.tw; tuliang@mail.ncyu.edu.tw
OI Lin, Tu-Liang/0000-0002-5008-7736
FU Ministry of Science and Technology (MOST) of Taiwan; MOST
   [109-2321-B-415-007, 109-2314-B-303-013]
FX This paper is supported by the Ministry of Science and Technology (MOST)
   of Taiwan. MOST provides the research funding and devices. The related
   project number of this work is 109-2321-B-415-007 and
   109-2314-B-303-013.
CR [Anonymous], 2015, ADV NEURAL INF PROCE
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Craven MW, 1997, FUTURE GENER COMP SY, V13, P211, DOI 10.1016/S0167-739X(97)00022-8
   Dai JF, 2016, ADV NEUR IN, V29
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Girshick R., 2015, PROC IEEE INT C COMP, P1440, DOI DOI 10.1109/ICCV.2015.169
   Girshick R. B., 2013, P IEEE C COMP VIS PA, DOI 10.1109/CVPR.2014.81
   He K, 2017, IEEE INT WORKSH MULT
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hsieh YH, 2019, EXPERT REV GASTROENT, V13, P1153, DOI 10.1080/17474124.2019.1694903
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maisonneuve P, 2008, GASTROENTEROLOGY, V135, P710, DOI 10.1053/j.gastro.2008.04.039
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Peters SL, 2010, CLIN GASTROENTEROL H, V8, P439, DOI 10.1016/j.cgh.2010.01.013
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Simonyan K., ARXIV
   Szegedy C., 2015, PROC IEEE C COMPUT V, DOI DOI 10.1109/CVPR.2015.7298594
   Tang CP, 2021, TZU CHI MED J, V33, P108, DOI 10.4103/tcmj.tcmj_88_20
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 40
TC 5
Z9 6
U1 1
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD AUG
PY 2021
VL 21
IS 16
AR 5315
DI 10.3390/s21165315
PG 14
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA UH6TY
UT WOS:000690061800001
PM 34450756
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Yen, HH
   Wu, PY
   Chen, MF
   Lin, WC
   Tsai, CL
   Lin, KP
AF Yen, Hsu-Heng
   Wu, Ping-Yu
   Chen, Mei-Fen
   Lin, Wen-Chen
   Tsai, Cheng-Lun
   Lin, Kang-Ping
TI Current Status and Future Perspective of Artificial Intelligence in the
   Management of Peptic Ulcer Bleeding: A Review of Recent Literature
SO JOURNAL OF CLINICAL MEDICINE
LA English
DT Review
DE peptic ulcer; bleeding; deep learning; artificial intelligence
ID GLASGOW-BLATCHFORD; AIMS65 SCORE; ENDOSCOPY; RISK; DIAGNOSIS
AB With the decreasing incidence of peptic ulcer bleeding (PUB) over the past two decades, the clinician experience of managing patients with PUB has also declined, especially for young endoscopists. A patient with PUB management requires collaborative care involving the emergency department, gastroenterologist, radiologist, and surgeon, from initial assessment to hospital discharge. The application of artificial intelligence (AI) methods has remarkably improved people's lives. In particular, AI systems have shown great potential in many areas of gastroenterology to increase human performance. Colonoscopy polyp detection or diagnosis by an AI system was recently introduced for commercial use to improve endoscopist performance. Although PUB is a longstanding health problem, these newly introduced AI technologies may soon impact endoscopists' clinical practice by improving the quality of care for these patients. To update the current status of AI application in PUB, we reviewed recent relevant literature and provided future perspectives that are required to integrate such AI tools into real-world practice.
C1 [Yen, Hsu-Heng] Changhua Christian Hosp, Dept Internal Med, Div Gastroenterol, Changhua 500, Taiwan.
   [Yen, Hsu-Heng] Chien Kuo Technol Univ, Gen Educ Ctr, Changhua 500, Taiwan.
   [Yen, Hsu-Heng; Wu, Ping-Yu; Chen, Mei-Fen; Lin, Kang-Ping] Chung Yuan Christian Univ, Dept Elect Engn, Taoyuan 320, Taiwan.
   [Yen, Hsu-Heng] Changhua Christian Hosp, Artificial Intelligence Dev Ctr, Changhua 500, Taiwan.
   [Chen, Mei-Fen; Lin, Wen-Chen; Tsai, Cheng-Lun; Lin, Kang-Ping] Chung Yuan Christian Univ, Technol Translat Ctr Med Device, Taoyuan 320, Taiwan.
   [Tsai, Cheng-Lun] Chung Yuan Christian Univ, Dept Biomed Engn, Taoyuan 320, Taiwan.
C3 Changhua Christian Hospital; Chienkuo Technology University; Chung Yuan
   Christian University; Changhua Christian Hospital; Chung Yuan Christian
   University; Chung Yuan Christian University
RP Lin, KP (通讯作者)，Chung Yuan Christian Univ, Dept Elect Engn, Taoyuan 320, Taiwan.; Lin, KP (通讯作者)，Chung Yuan Christian Univ, Technol Translat Ctr Med Device, Taoyuan 320, Taiwan.
EM 91646@cch.org.tw; pingyu841215@gmail.com; mei549@gmail.com;
   lin_wenchen@cycu.edu.tw; clt@cycu.edu.tw; kplin@cycu.edu.tw
OI Yen, Hsu-Heng/0000-0002-3494-2245
FU Changhua Christian Hospital [109-CCH-CYCU-001, 109CCH-IRP-008,
   110-CCH-IRP-20]
FX This research was funded by Changhua Christian Hospital
   (109-CCH-CYCU-001, 109CCH-IRP-008, and 110-CCH-IRP-20).
CR Barkun AN, 2019, ANN INTERN MED, V171, P805, DOI 10.7326/M19-1795
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Brullet E, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020408
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   Deshmukh F, 2020, AM J GASTROENTEROL, V115, P1657, DOI 10.14309/ajg.0000000000000632
   El Hajjar A, 2020, CHINESE MED J-PEKING, V133, P326, DOI 10.1097/CM9.0000000000000623
   FORREST JAH, 1974, LANCET, V2, P394
   Garcia-Peraza-Herrera LC, 2020, INT J COMPUT ASS RAD, V15, P651, DOI 10.1007/s11548-020-02127-w
   Gralnek IM, 2015, ENDOSCOPY, V47, pA1, DOI 10.1055/s-0034-1393172
   Hyett BH, 2013, GASTROINTEST ENDOSC, V77, P551, DOI 10.1016/j.gie.2012.11.022
   Kiang E, 2021, CLIN EXP GASTROENTER, V14, P155, DOI 10.2147/CEG.S292857
   Kim MS, 2019, BMC GASTROENTEROL, V19, DOI 10.1186/s12876-019-1051-8
   LAINE L, 1994, GASTROINTEST ENDOSC, V40, P411, DOI 10.1016/S0016-5107(94)70202-0
   Laine L, 2021, AM J GASTROENTEROL, V116, P899, DOI 10.14309/ajg.0000000000001245
   Lau OHS, 2021, DIGEST ENDOSC, V33, P83, DOI 10.1111/den.13674
   Levi R, 2021, BMJ HEALTH CARE INFO, V28, DOI 10.1136/bmjhci-2020-100245
   Loffroy R, 2019, BEST PRACT RES CL GA, V42-43, DOI 10.1016/j.bpg.2019.04.005
   Loffroy R, 2013, CARDIOVASC INTER RAD, V36, P867, DOI 10.1007/s00270-013-0585-3
   Lu YD, 2014, CAN J GASTROENTEROL, V28, P495, DOI 10.1155/2014/252307
   Mohan BP, 2021, ANN GASTROENTEROL, V34, P20, DOI 10.20524/aog.2020.0542
   Mondardini A, 1998, ENDOSCOPY, V30, P508, DOI 10.1055/s-2007-1001335
   Moon JH, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105819
   Namikawa K, 2020, ENDOSCOPY, V52, P1077, DOI 10.1055/a-1194-8771
   Penny HA, 2016, FRONTLINE GASTROENTE, V7, P67, DOI 10.1136/flgastro-2014-100537
   Robertson M, 2016, GASTROINTEST ENDOSC, V83, P1151, DOI 10.1016/j.gie.2015.10.021
   Rockall TA, 1996, GUT, V38, P316, DOI 10.1136/gut.38.3.316
   Seo DW, 2020, J CLIN MED, V9, DOI 10.3390/jcm9082603
   Shivaraju A, 2011, AM HEART J, V162, P1062, DOI 10.1016/j.ahj.2011.09.009
   Shung D, 2021, J GASTROEN HEPATOL, V36, P1590, DOI 10.1111/jgh.15313
   Shung D, 2019, DIGEST DIS SCI, V64, P2078, DOI 10.1007/s10620-019-05645-z
   Shung DL, 2020, GASTROENTEROLOGY, V158, P160, DOI 10.1053/j.gastro.2019.09.009
   Siau K, 2020, FRONTLINE GASTROENTE, V11, P311, DOI 10.1136/flgastro-2019-101395
   Stanley AJ, 2009, LANCET, V373, P42, DOI 10.1016/S0140-6736(08)61769-9
   Sung JJY, 2018, GUT, V67, P1757, DOI 10.1136/gutjnl-2018-316276
   Tan Qingxing, 2018, AMIA Annu Symp Proc, V2018, P998
   Tan QX, 2021, J AM MED INFORM ASSN, V28, P713, DOI 10.1093/jamia/ocaa306
   Thompson WH, 2020, ELIFE, V9, DOI 10.7554/eLife.53498
   Waddell KM, 2017, FRONTLINE GASTROENTE, V8, P94, DOI 10.1136/flgastro-2016-100791
   Wong GLH, 2020, GUT, V69, P652, DOI 10.1136/gutjnl-2019-318715
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Wu LL, 2022, GASTROINTEST ENDOSC, V95, P92, DOI 10.1016/j.gie.2021.06.033
   Yen HH, 2021, J MED BIOL ENG, V41, P504, DOI 10.1007/s40846-021-00608-0
   Yen HH, 2012, BMC GASTROENTEROL, V12, DOI 10.1186/1471-230X-12-66
   Yen HH, 2011, SURG LAPARO ENDO PER, V21, P380, DOI 10.1097/SLE.0b013e3182303007
   Yoon HJ, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091310
   Yu Q, 2021, AM J ROENTGENOL, V216, P880, DOI 10.2214/AJR.20.23151
   Zhao Q, 2021, BMC GASTROENTEROL, V21, DOI 10.1186/s12876-021-01836-z
NR 47
TC 9
Z9 9
U1 6
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0383
J9 J CLIN MED
JI J. Clin. Med.
PD AUG
PY 2021
VL 10
IS 16
AR 3527
DI 10.3390/jcm10163527
PG 10
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA UI4VL
UT WOS:000690606700001
PM 34441823
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Yang, K
   Chang, SL
   Tian, ZX
   Gao, C
   Du, Y
   Zhang, XF
   Liu, K
   Meng, J
   Xue, LY
AF Yang, Kun
   Chang, Shilong
   Tian, Zhaoxing
   Gao, Cong
   Du, Yu
   Zhang, Xiongfeng
   Liu, Kun
   Meng, Jie
   Xue, Linyan
TI Automatic polyp detection and segmentation using shuffle efficient
   channel attention network
SO ALEXANDRIA ENGINEERING JOURNAL
LA English
DT Article
DE Colorectal cancer; Polyps; Colonoscopy; Mask R-CNN; sECANet
ID VALIDATION; DIAGNOSIS
AB Colorectal cancer (CRC) represents one of the common malignancies of the gastrointestinal tract. The CRC incidence and mortality rates can be significantly reduced through early detection and resection of the precursor lesions, also known the colorectal polyps. However, such polyps can be missed during manual colonoscopy screening. With recent advances in artificial intelligence, numerous computer-aided diagnosis (CAD) methods have been proposed for colonoscopy applications. In particular, deep learning algorithms have been recently designed to incorporate sophisticated attention mechanisms into convolutional blocks and hence demonstrate a great potential for enhancing the performance of convolutional neural networks (CNNs). Nevertheless, most current deep learning techniques suffer from the high model complexity and excessive computational burden. In this paper, we introduce a deep learning approach for colorectal polyp detection and segmentation. Specifically, we propose a new shuffle efficient channel attention network (sECANet) with no dimensionality reduction. This network can be exploited to learn effective channel attention by obtaining cross-channel interactions. A total of 2112 manually-labeled images were collected from 1197 patients in a local hospital using colonoscopy screening. Additional data samples were collected from the CVC-ClinicDB, the ETIS-Larib Polyp DB and the Kvasir-SEG data set. The captured images were partitioned into 3590 training images and 330 testing images, and each image was labeled as a polyp or non-polyp image. We assessed our framework on the testing images and achieved a precision of 94.9%, a recall of 96.9%, a F1 score of 95.9%, and a F2 score of 96.5%. In conclusion, our proposed framework has a great potential of assisting endoscopists in tracking polyps during colonoscopy and therefore performing early and timely resection of such polyps before they evolve into invasive cancer types. (c) 2021 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Engineering, Alexandria University.
C1 [Yang, Kun; Chang, Shilong; Tian, Zhaoxing; Gao, Cong; Du, Yu; Zhang, Xiongfeng; Liu, Kun; Xue, Linyan] Hebei Univ, Coll Qual & Tech Supervis, Baoding 071002, Peoples R China.
   [Yang, Kun; Liu, Kun; Xue, Linyan] Hebei Univ, Natl & Local Joint Engn Res Ctr Metrol Instrument, Baoding 071002, Peoples R China.
   [Meng, Jie] Hebei Univ, Affiliated Hosp, Dept Gastroenterol, Baoding 071000, Peoples R China.
C3 Hebei University; Hebei University; Hebei University
RP Liu, K; Xue, LY (通讯作者)，Hebei Univ, Coll Qual & Tech Supervis, Baoding 071002, Peoples R China.; Meng, J (通讯作者)，Hebei Univ, Affiliated Hosp, Dept Gastroenterol, Baoding 071000, Peoples R China.
EM liukun15166@hbu.edu.cn; cenci@163.com; lyxue@hbu.edu.cn
FU Research Fund for Foundation of Hebei University [DXK201914]; President
   of Hebei University [XZJJ201914]; Natural Science Foundation of Hebei
   Province [H2019201378]; Pstdoctoral Fund Project of Hebei Province
   [B20190030010]; Science and Technol-ogy Project of Hebei Province
   [20377781D]; Post-graduate's Innovation Fund Project of Hebei University
   [HBU2021ss078, HBU2021ss079]; Innovation and Entrepreneurship Training
   Program for College Students [2020317]
FX This work was funded by the Research Fund for Foundation of Hebei
   University (DXK201914) , the President of Hebei University (XZJJ201914)
   , the Natural Science Foundation of Hebei Province (H2019201378) , the
   Pstdoctoral Fund Project of Hebei Province (B20190030010) , the Science
   and Technol-ogy Project of Hebei Province (20377781D) , the
   Post-graduate's Innovation Fund Project of Hebei University
   (HBU2021ss078 & HBU2021ss079) , and the Innovation and Entrepreneurship
   Training Program for College Students (2020317) .
CR Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bolya D, 2022, IEEE T PATTERN ANAL, V44, P1108, DOI 10.1109/TPAMI.2020.3014297
   Bottou L., 2012, NEURAL NETWORKS TRIC, P421
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cubiella J, 2018, GASTROENT HEPAT-BARC, V41, P585, DOI 10.1016/j.gastrohep.2018.07.012
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Fan TL, 2020, IEEE ACCESS, V8, P179656, DOI 10.1109/ACCESS.2020.3025372
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li TB, 2016, GASTROINTEST ENDOSC, V83, pAB482, DOI 10.1016/j.gie.2016.03.671
   Liu F., 2020, SURVEY CONVOLUTIONAL
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Meng J, 2020, OPEN LIFE SCI, V15, P588, DOI 10.1515/biol-2020-0055
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sung H., 2021, CA-CANCER J CLIN, V71, P209, DOI [10.3322/caac.21660, DOI 10.3322/caac.21660]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Weng WH, 2021, IEEE ACCESS, V9, P16591, DOI 10.1109/ACCESS.2021.3053408
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhiye Xia, 2010, 2010 International Workshop on Chaos-Fractals Theories and Applications (IWCFTA 2010), P411, DOI 10.1109/IWCFTA.2010.22
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zisserman A., 2014, ICLR, DOI DOI 10.2146/AJHP170251
NR 40
TC 11
Z9 11
U1 2
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1110-0168
EI 2090-2670
J9 ALEX ENG J
JI Alex. Eng. J.
PD JAN
PY 2022
VL 61
IS 1
BP 917
EP 926
DI 10.1016/j.aej.2021.04.072
EA JUL 2021
PG 10
WC Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA WC5ZL
UT WOS:000704336100015
OA gold
DA 2023-08-21
ER

PT J
AU Song, YQ
   Mao, XL
   Zhou, XB
   He, SQ
   Chen, YH
   Zhang, LH
   Xu, SW
   Yan, LL
   Tang, SP
   Ye, LP
   Li, SW
AF Song, Ya-Qi
   Mao, Xin-Li
   Zhou, Xian-Bin
   He, Sai-Qin
   Chen, Ya-Hong
   Zhang, Li-Hui
   Xu, Shi-Wen
   Yan, Ling-Ling
   Tang, Shen-Ping
   Ye, Li-Ping
   Li, Shao-Wei
TI Use of Artificial Intelligence to Improve the Quality Control of
   Gastrointestinal Endoscopy
SO FRONTIERS IN MEDICINE
LA English
DT Review
DE application; artificial intelligence; quality control; improving;
   gastrointestinal endoscopy
ID COMPUTER-AIDED DIAGNOSIS; SYSTEM; ESOPHAGUS; FEEDBACK; CANCERS; PRIMER
AB With the rapid development of science and technology, artificial intelligence (AI) systems are becoming ubiquitous, and their utility in gastroenteroscopy is beginning to be recognized. Digestive endoscopy is a conventional and reliable method of examining and diagnosing digestive tract diseases. However, with the increase in the number and types of endoscopy, problems such as a lack of skilled endoscopists and difference in the professional skill of doctors with different degrees of experience have become increasingly apparent. Most studies thus far have focused on using computers to detect and diagnose lesions, but improving the quality of endoscopic examination process itself is the basis for improving the detection rate and correctly diagnosing diseases. In the present study, we mainly reviewed the role of AI in monitoring systems, mainly through the endoscopic examination time, reducing the blind spot rate, improving the success rate for detecting high-risk lesions, evaluating intestinal preparation, increasing the detection rate of polyps, automatically collecting maps and writing reports. AI can even perform quality control evaluations for endoscopists, improve the detection rate of endoscopic lesions and reduce the burden on endoscopists.
C1 [Song, Ya-Qi; Ye, Li-Ping] Zhejiang Univ, Taizhou Hosp, Linhai, Peoples R China.
   [Mao, Xin-Li; Zhou, Xian-Bin; He, Sai-Qin; Yan, Ling-Ling; Ye, Li-Ping; Li, Shao-Wei] Wenzhou Med Univ, Key Lab Minimally Invas Tech & Rapid Rehabil Dige, Taizhou Hosp, Linhai, Peoples R China.
   [Mao, Xin-Li; Zhou, Xian-Bin; He, Sai-Qin; Yan, Ling-Ling; Ye, Li-Ping; Li, Shao-Wei] Wenzhou Med Univ, Dept Gastroenterol, Taizhou Hosp Zhejiang Prov, Linhai, Peoples R China.
   [Chen, Ya-Hong] Wenzhou Med Univ, Hlth Management Ctr, Taizhou Hosp Zhejiang Prov, Linhai, Peoples R China.
   [Zhang, Li-Hui] Wuhan Univ, Dept Gastroenterol, Renmin Hosp, Wuhan, Peoples R China.
   [Xu, Shi-Wen; Tang, Shen-Ping] Wenzhou Med Univ, Taizhou Hosp Zhejiang Prov, Linhai, Peoples R China.
   [Ye, Li-Ping; Li, Shao-Wei] Wenzhou Med Univ, Inst Digest Dis, Taizhou Hosp Zhejiang Prov, Linhai, Peoples R China.
C3 Zhejiang University; Wenzhou Medical University; Wenzhou Medical
   University; Wenzhou Medical University; Wuhan University; Wenzhou
   Medical University; Wenzhou Medical University
RP Ye, LP (通讯作者)，Zhejiang Univ, Taizhou Hosp, Linhai, Peoples R China.; Ye, LP; Li, SW (通讯作者)，Wenzhou Med Univ, Key Lab Minimally Invas Tech & Rapid Rehabil Dige, Taizhou Hosp, Linhai, Peoples R China.; Ye, LP; Li, SW (通讯作者)，Wenzhou Med Univ, Dept Gastroenterol, Taizhou Hosp Zhejiang Prov, Linhai, Peoples R China.; Ye, LP; Li, SW (通讯作者)，Wenzhou Med Univ, Inst Digest Dis, Taizhou Hosp Zhejiang Prov, Linhai, Peoples R China.
EM yelp@enzemed.com; li_shaowei81@hotmail.com
RI Li, Shaowei/ABC-1102-2020
FU Program of Inner Mongolia Autonomous Region Tumor Biotherapy
   Collaborative Innovation Center, Medical Science and Technology Project
   of Zhejiang Province [2021PY083]; Program of Taizhou Science and
   Technology Grant [20ywb29]; Major Research Program of Taizhou Enze
   Medical Center Grant [19EZZDA2]; Open Project Program of Key Laboratory
   of Minimally Invasive Techniques and Rapid Rehabilitation of Digestive
   System Tumor of Zhejiang Province [21SZDSYS01, 21SZDSYS09]; Key
   Technology Research and Development Program of Zhejiang Province
   [2019C03040]
FX This work was supported in part by Program of Inner Mongolia Autonomous
   Region Tumor Biotherapy Collaborative Innovation Center, Medical Science
   and Technology Project of Zhejiang Province (2021PY083), Program of
   Taizhou Science and Technology Grant (20ywb29), Major Research Program
   of Taizhou Enze Medical Center Grant (19EZZDA2), Open Project Program of
   Key Laboratory of Minimally Invasive Techniques and Rapid Rehabilitation
   of Digestive System Tumor of Zhejiang Province (21SZDSYS01, 21SZDSYS09)
   and Key Technology Research and Development Program of Zhejiang Province
   (2019C03040).
CR Abadir AP, 2020, CLIN ENDOSC, V53, P132, DOI 10.5946/ce.2020.038
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Anirvan Prajna, 2020, Euroasian J Hepatogastroenterol, V10, P92, DOI 10.5005/jp-journals-10018-1322
   Arribas J, 2021, GUT, V70, P1458, DOI 10.1136/gutjnl-2020-321922
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chahal D, 2020, GASTROINTEST ENDOSC, V92, P813, DOI 10.1016/j.gie.2020.04.074
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Chen D, 2020, GASTROINTEST ENDOSC, V91, P332, DOI 10.1016/j.gie.2019.09.016
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Choi SJ, 2022, SURG ENDOSC, V36, P57, DOI 10.1007/s00464-020-08236-6
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   Falk GW, 1999, GASTROINTEST ENDOSC, V49, P170, DOI 10.1016/S0016-5107(99)70482-7
   Filip D, 2012, WORLD J GASTROENTERO, V18, P4270, DOI 10.3748/wjg.v18.i32.4270
   Frazzoni L, 2022, ENDOSCOPY, V54, P403, DOI 10.1055/a-1500-3730
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gulati S, 2020, DIGEST ENDOSC, V32, P512, DOI 10.1111/den.13481
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Ishihara R, 2010, DIS ESOPHAGUS, V23, P480, DOI 10.1111/j.1442-2050.2009.01039.x
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Mohammadian Taher, 2019, Monoclonal Antibodies in Immunodiagnosis and Immunotherapy, V38, P1, DOI 10.1089/mab.2018.0032
   Muto M, 2010, J CLIN ONCOL, V28, P1566, DOI 10.1200/JCO.2009.25.4680
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Parasa S, 2020, GASTROINTEST ENDOSC, V92, P938, DOI 10.1016/j.gie.2020.04.044
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Reid BJ, 2000, AM J GASTROENTEROL, V95, P3089, DOI 10.1111/j.1572-0241.2000.03182.x
   Requa J, 2018, AM J GASTROENTEROL, V113, pS158
   Rey JF, 2001, ENDOSCOPY, V33, P901
   Ruffle JK, 2019, AM J GASTROENTEROL, V114, P422, DOI 10.1038/s41395-018-0268-4
   Sharma P, 2012, GASTROINTEST ENDOSC, V76, P252, DOI 10.1016/j.gie.2012.05.007
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Sinonquel P, 2021, DIGEST ENDOSC, V33, P242, DOI 10.1111/den.13888
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Thakkar S, 2020, GASTROENTEROLOGY, V158, P1219, DOI 10.1053/j.gastro.2019.12.035
   Tokai Y, 2020, ESOPHAGUS-TOKYO, V17, P250, DOI 10.1007/s10388-020-00716-x
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Zhou J, 2020, GASTROINTEST ENDOSC, V91, P428, DOI 10.1016/j.gie.2019.11.026
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 44
TC 2
Z9 2
U1 0
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-858X
J9 FRONT MED-LAUSANNE
JI Front. Med.
PD JUL 22
PY 2021
VL 8
AR 709347
DI 10.3389/fmed.2021.709347
PG 8
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA UG4XM
UT WOS:000689257300001
PM 34368199
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Guo, XY
   Gao, H
   Sun, XF
   Li, SR
AF Guo, Xiangyan
   Gao, Hui
   Sun, Xiaofang
   Li, Surong
TI Deep Learning for Detection of Colonic Polyps from Computed Tomography
   Colonoscopy Images Combined with Colonoscopy
SO SCIENTIFIC PROGRAMMING
LA English
DT Article
AB The objective of this study was to investigate the diagnosis of colonic polyps (CP) through the computed tomography (CT) images combined with colonoscopy based on Fourier central slice theorem algorithm. In this study, 86 patients with CP admitted to hospital were selected as research objects. CT imaging and colonoscopy were applied to diagnose the patients based on the algorithm of Fourier central slice theorem. The results showed that the diagnostic detection rates of CP and colon cancer (CC) were 88.2% and 94.2%, respectively. The occurrence site of CP was the sigmoid and ascending colon. 38 patients were positive for serosal invasion of CP while 42 patients were negative for serosal invasion of CP, and there were no statistical differences (P>0.05). The lesion positions of remaining 6 cases were hard to find and could not be detected accurately. Besides, the diagnostic accuracy of preoperative and postoperative stages III and IV was all 100.00%. The combination of CT imaging and colonoscopy was employed to diagnose CP, which was found to be able to accurately locate the lesions, to effectively evaluate the tumor stage before and after surgery, and to have a good diagnostic efficacy in detecting tumor serosal layer.
C1 [Guo, Xiangyan; Gao, Hui] Xingtai Peoples Hosp, Dept Emergency, Xingtai 054000, Hebei, Peoples R China.
   [Sun, Xiaofang] Xingtai Peoples Hosp, Dept Endoscopy, Xingtai 054000, Hebei, Peoples R China.
   [Li, Surong] Xingtai Peoples Hosp, Dept Anesthesiol, Xingtai 054000, Hebei, Peoples R China.
RP Gao, H (通讯作者)，Xingtai Peoples Hosp, Dept Emergency, Xingtai 054000, Hebei, Peoples R China.
EM 14020123@zjnu.edu.cn
CR Abu Baker F, 2019, GASTROENT RES PRACT, V2019, DOI 10.1155/2019/2507848
   Boraschi P, 2016, JPN J RADIOL, V34, P585, DOI 10.1007/s11604-016-0552-4
   Dekker KH, 2016, PHYS MED BIOL, V61, P2910, DOI 10.1088/0031-9155/61/7/2910
   East JE, 2017, GUT, V66, P1181, DOI 10.1136/gutjnl-2017-314005
   Fusaroli P, 2016, PANCREAS, V45, P265, DOI 10.1097/MPA.0000000000000441
   Horvat N, 2019, AM J ROENTGENOL, V212, P94, DOI 10.2214/AJR.18.19928
   Inamura K, 2018, CANCERS, V10, DOI 10.3390/cancers10010026
   Jin BR, 2020, BIOLOGY-BASEL, V9, DOI 10.3390/biology9020024
   Li DS, 2020, KOREAN J RADIOL, V21, P505, DOI 10.3348/kjr.2020.0146
   Lindholm CR, 2019, CURR OPIN GASTROEN, V35, P34, DOI 10.1097/MOG.0000000000000495
   Nallathambi R, 2018, CANNABIS CANNABINOID, V3, P120, DOI 10.1089/can.2018.0010
   Numbere N, 2019, HISTOPATHOLOGY, V74, P424, DOI 10.1111/his.13771
   Oda M, 2017, INT J COMPUT ASS RAD, V12, P39, DOI 10.1007/s11548-016-1456-6
   Taguchi K, 2017, RADIOL PHYS TECHNOL, V10, P8, DOI 10.1007/s12194-017-0390-9
   Wang P, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000011177
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Zhang YM, 2019, J BIOMED OPT, V24, DOI 10.1117/1.JBO.24.8.086002
NR 17
TC 0
Z9 0
U1 1
U2 3
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1058-9244
EI 1875-919X
J9 SCI PROGRAMMING-NETH
JI Sci. Program.
PD JUL 20
PY 2021
VL 2021
AR 1238805
DI 10.1155/2021/1238805
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TX8UX
UT WOS:000683362800006
OA gold
DA 2023-08-21
ER

PT J
AU Durak, S
   Bayram, B
   Bakirman, T
   Erkut, M
   Dogan, M
   Gurturk, M
   Akpinar, B
AF Durak, Serdar
   Bayram, Bulent
   Bakirman, Tolga
   Erkut, Murat
   Dogan, Metehan
   Gurturk, Mert
   Akpinar, Burak
TI Deep neural network approaches for detecting gastric polyps in
   endoscopic images
SO MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING
LA English
DT Article
DE Deep learning; YOLOv4; Gastric polyp; Gastrointestinal endoscopy; CAD
   system
ID ARTIFICIAL-INTELLIGENCE; CANCER
AB Gastrointestinal endoscopy is the primary method used for the diagnosis and treatment of gastric polyps. The early detection and removal of polyps is vitally important in preventing cancer development. Many studies indicate that a high workload can contribute to misdiagnosing gastric polyps, even for experienced physicians. In this study, we aimed to establish a deep learning-based computer-aided diagnosis system for automatic gastric polyp detection. A private gastric polyp dataset was generated for this purpose consisting of 2195 endoscopic images and 3031 polyp labels. Retrospective gastrointestinal endoscopy data from the Karadeniz Technical University, Farabi Hospital, were used in the study. YOLOv4, CenterNet, EfficientNet, Cross Stage ResNext50-SPP, YOLOv3, YOLOv3-SPP, Single Shot Detection, and Faster Regional CNN deep learning models were implemented and assessed to determine the most efficient model for precancerous gastric polyp detection. The dataset was split 70% and 30% for training and testing all the implemented models. YOLOv4 was determined to be the most accurate model, with an 87.95% mean average precision. We also evaluated all the deep learning models using a public gastric polyp dataset as the test data. The results show that YOLOv4 has significant potential applicability in detecting gastric polyps and can be used effectively in gastrointestinal CAD systems.
C1 [Durak, Serdar; Erkut, Murat] Karadeniz Tech Univ, Fac Med, Dept Gastroenterol, Trabzon, Turkey.
   [Bayram, Bulent; Bakirman, Tolga; Dogan, Metehan; Gurturk, Mert; Akpinar, Burak] Yildiz Tech Univ, Dept Geoinformat, Istanbul, Turkey.
C3 Karadeniz Technical University; Yildiz Technical University
RP Bakirman, T (通讯作者)，Yildiz Tech Univ, Dept Geoinformat, Istanbul, Turkey.
EM serdardurak@ktu.edu.tr; bayram@yildiz.edu.tr; bakirman@yildiz.edu.tr;
   merkut@ktu.edu.tr; 14616015@std.yildiz.edu.tr; mgurturk@yildiz.edu.tr;
   bakpinar@yildiz.edu.tr
RI Bakirman, Tolga/C-3959-2015; Akpınar, Burak/AGY-8648-2022
OI Bakirman, Tolga/0000-0001-7828-9666; Durak, Serdar/0000-0002-8175-9611;
   Bayram, Bulent/0000-0002-4248-116X
CR Abadir AP, 2020, CLIN ENDOSC, V53, P132, DOI 10.5946/ce.2020.038
   [Anonymous], SLIMYOLOV3 NARROWER
   Bai YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P229, DOI 10.1145/2647868.2656402
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bochkovskiy A., 2020, ARXIV PREPRINT
   Borch K, 2003, DIGEST DIS SCI, V48, P1292, DOI 10.1023/A:1024150924457
   Burt RW, 2003, GASTROENTEROLOGY, V125, P1462, DOI 10.1016/j.gastro.2003.07.017
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cantor, 1984, UNENDLICHE LINEARE P, DOI 10.1007/978-3-7091-9516-1
   Cao CT, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250632
   Choi J, 2020, CLIN ENDOSC, V53, P117, DOI 10.5946/ce.2020.054
   Dirschmid K, 2006, VIRCHOWS ARCH, V448, P80, DOI 10.1007/s00428-005-0068-2
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   El Hajjar A, 2020, CHINESE MED J-PEKING, V133, P326, DOI 10.1097/CM9.0000000000000623
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   GLOBOCAN, 2018, GLOBAL CANC OBSERVAT
   Gotoda T, 2006, CURR OPIN GASTROEN, V22, P561, DOI 10.1097/01.mog.0000239873.06243.00
   Hasan M, 2020, IN PRESS
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hoogenboom SA, 2020, TECH INNOVAT GASTROI, V22, P42, DOI 10.1016/j.tgie.2019.150634
   Katai H, 2018, GASTRIC CANCER, V21, P144, DOI 10.1007/s10120-017-0716-7
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Laddha M., 2019, P 2019 4 INT C BIOME, P55, DOI [10.1145/3366174.3366185, DOI 10.1145/3366174.3366185, 10.1145/3366174.3366185.]
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Le Duy Huynh, CEUR WORKSHOP PROC, V2595, P13
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   LYNCH HT, 1995, CANCER, V76, P2427, DOI 10.1002/1097-0142(19951215)76:12<2427::AID-CNCR2820761205>3.0.CO;2-B
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Pacal I, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104003
   Pham MT, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207068
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vogt S, 2009, GASTROENTEROLOGY, V137, P1976, DOI 10.1053/j.gastro.2009.08.052
   Voutilainen M, 2003, SCAND J GASTROENTERO, V38, P109, DOI 10.1080/00365521.2018.12027894
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang R, 2019, P 2019 8 NTERN C COM
   Worthley DL, 2012, GUT, V61, P774, DOI 10.1136/gutjnl-2011-300348
   Xia J, 2021, GASTROINTEST ENDOSC, V93, P133, DOI 10.1016/j.gie.2020.05.027
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yanase J, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.112821
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 48
TC 7
Z9 8
U1 5
U2 36
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0140-0118
EI 1741-0444
J9 MED BIOL ENG COMPUT
JI Med. Biol. Eng. Comput.
PD AUG
PY 2021
VL 59
IS 7-8
BP 1563
EP 1574
DI 10.1007/s11517-021-02398-8
EA JUL 2021
PG 12
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Mathematical & Computational Biology;
   Medical Informatics
GA TP6YM
UT WOS:000673430200001
PM 34259974
DA 2023-08-21
ER

PT J
AU Nazarian, S
   Glover, B
   Ashrafian, H
   Darzi, A
   Teare, J
AF Nazarian, Scarlet
   Glover, Ben
   Ashrafian, Hutan
   Darzi, Ara
   Teare, Julian
TI Diagnostic Accuracy of Artificial Intelligence and Computer-Aided
   Diagnosis for the Detection and Characterization of Colorectal Polyps:
   Systematic Review and Meta-analysis
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Review
DE artificial intelligence; colonoscopy; computer-aided diagnosis; machine
   learning; polyp
ID WHITE-LIGHT COLONOSCOPY; ADENOMA DETECTION; MISS RATE; ASSISTED
   COLONOSCOPY; CLASSIFICATION; QUALITY; LESIONS; HISTOLOGY; CANCER; RISK
AB Background: Colonoscopy reduces the incidence of colorectal cancer (CRC) by allowing detection and resection of neoplastic polyps. Evidence shows that many small polyps are missed on a single colonoscopy. There has been a successful adoption of artificial intelligence (AI) technologies to tackle the issues around missed polyps and as tools to increase the adenoma detection rate (ADR).
   Objective: The aim of this review was to examine the diagnostic accuracy of AI-based technologies in assessing colorectal polyps.
   Methods: A comprehensive literature search was undertaken using the databases of Embase, MEDLINE, and the Cochrane Library. PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines were followed. Studies reporting the use of computer-aided diagnosis for polyp detection or characterization during colonoscopy were included. Independent proportions and their differences were calculated and pooled through DerSimonian and Laird random-effects modeling.
   Results: A total of 48 studies were included. The meta-analysis showed a significant increase in pooled polyp detection rate in patients with the use of AI for polyp detection during colonoscopy compared with patients who had standard colonoscopy (odds ratio [OR] 1.75, 95% CI 1.56-1.96; P<.001). When comparing patients undergoing colonoscopy with the use of AI to those without, there was also a significant increase in ADR (OR 1.53, 95% CI 1.32-1.77; P<.001).
   Conclusions: With the aid of machine learning, there is potential to improve ADR and, consequently, reduce the incidence of CRC. The current generation of AI-based systems demonstrate impressive accuracy for the detection and characterization of colorectal polyps. However, this is an evolving field and before its adoption into a clinical setting, AI systems must prove worthy to patients and clinicians.
C1 [Nazarian, Scarlet; Glover, Ben; Ashrafian, Hutan; Darzi, Ara; Teare, Julian] Imperial Coll London, Dept Surg & Canc, London, England.
C3 Imperial College London
RP Ashrafian, H (通讯作者)，Imperial Coll London, Dept Surg & Canc, St Marys Hosp, 10th Floor,QEQM Bldg,Praed St, London W2 1NY, England.
EM h.ashrafian@imperial.ac.uk
OI Glover, Benjamin/0000-0003-3043-0012; teare, Julian/0000-0003-3551-9139;
   Ashrafian, Hutan/0000-0003-1668-0672
CR Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Clark BT, 2014, AM J GASTROENTEROL, V109, P1714, DOI 10.1038/ajg.2014.232
   Coe SG, 2013, AM J GASTROENTEROL, V108, P219, DOI 10.1038/ajg.2012.417
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   DeCamp M, 2020, J AM MED INFORM ASSN, V27, P2020, DOI 10.1093/jamia/ocaa094
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Figueiredo IN, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101577
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Fu JJC, 2014, COMPUT MED IMAG GRAP, V38, P267, DOI 10.1016/j.compmedimag.2013.12.009
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gao JB, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/8374317
   Globocan, 2018, GLOB 2018 COL CANC N
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Guo Z, 2021, DIGEST ENDOSC, V33, P162, DOI 10.1111/den.13670
   Hur J, 2017, ANN COLOPROCTOL, V33, P81, DOI 10.3393/ac.2017.33.3.81
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jadad AR, 1996, CONTROL CLIN TRIALS, V17, P1, DOI 10.1016/0197-2456(95)00134-4
   Kaminski MF, 2016, GUT, V65, P616, DOI 10.1136/gutjnl-2014-307503
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Killock D, 2020, NAT REV CLIN ONCOL, V17, P134, DOI 10.1038/s41571-020-0329-7
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1186/s13643-015-0087-2, 10.1136/bmj.b2535]
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2018, DIGEST ENDOSC, V30, P52, DOI 10.1111/den.13005
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   National Health Service, 2019, TOPOL REV PREPARING
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Poon CCY, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0281-z
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rees CJ, 2016, GUT, V65, P1923, DOI 10.1136/gutjnl-2016-312044
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rigby MJ., 2019, AMA J ETHICS, V21, P121, DOI [10.1001/amajethics.2019.121, DOI 10.1001/AMAJETHICS.2019.121]
   Rodriguez-Diaz E, 2020, GASTROENTEROLOGY, V158, pS369
   Shaukat A, 2015, GASTROENTEROLOGY, V149, P952, DOI 10.1053/j.gastro.2015.06.044
   Sounderajah V, 2020, NAT MED, V26, P807, DOI 10.1038/s41591-020-0941-1
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 76
TC 19
Z9 19
U1 2
U2 13
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD JUL 14
PY 2021
VL 23
IS 7
AR e27370
DI 10.2196/27370
PG 18
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA TI5NT
UT WOS:000672850100004
PM 34259645
OA gold, Green Submitted, Green Published
DA 2023-08-21
ER

PT J
AU Su, HC
   Lin, B
   Huang, XS
   Li, J
   Jiang, KL
   Duan, XL
AF Su, Houcheng
   Lin, Bin
   Huang, Xiaoshuang
   Li, Jiao
   Jiang, Kailin
   Duan, Xuliang
TI MBFFNet: Multi-Branch Feature Fusion Network for Colonoscopy
SO FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY
LA English
DT Article
DE multi-branch feature; fusion network; colonoscopy; medical image
   segmentation; MBFFNet
AB Colonoscopy is currently one of the main methods for the detection of rectal polyps, rectal cancer, and other diseases. With the rapid development of computer vision, deep learning-based semantic segmentation methods can be applied to the detection of medical lesions. However, it is challenging for current methods to detect polyps with high accuracy and real-time performance. To solve this problem, we propose a multi-branch feature fusion network (MBFFNet), which is an accurate real-time segmentation method for detecting colonoscopy. First, we use UNet as the basis of our model architecture and adopt stepwise sampling with channel multiplication to integrate features, which decreases the number of flops caused by stacking channels in UNet. Second, to improve model accuracy, we extract features from multiple layers and resize feature maps to the same size in different ways, such as up-sampling and pooling, to supplement information lost in multiplication-based up-sampling. Based on mIOU and Dice loss with cross entropy (CE), we conduct experiments in both CPU and GPU environments to verify the effectiveness of our model. The experimental results show that our proposed MBFFNet is superior to the selected baselines in terms of accuracy, model size, and flops. mIOU, F score, and Dice loss with CE reached 0.8952, 0.9450, and 0.1602, respectively, which were better than those of UNet, UNet++, and other networks. Compared with UNet, the flop count decreased by 73.2%, and the number of participants also decreased. The actual segmentation effect of MBFFNet is only lower than that of PraNet, the number of parameters is 78.27% of that of PraNet, and the flop count is 0.23% that of PraNet. In addition, experiments on other types of medical tasks show that MBFFNet has good potential for general application in medical image segmentation.
C1 [Su, Houcheng; Lin, Bin; Huang, Xiaoshuang; Li, Jiao; Duan, Xuliang] Sichuan Agr Univ, Coll Informat Engn, Yaan, Peoples R China.
   [Jiang, Kailin] Sichuan Agr Univ, Coll Sci, Yaan, Peoples R China.
C3 Sichuan Agricultural University; Sichuan Agricultural University
RP Duan, XL (通讯作者)，Sichuan Agr Univ, Coll Informat Engn, Yaan, Peoples R China.
EM duanxuliang@sicau.edu.cn
OI Su, Houcheng/0000-0001-6558-4244
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Akbari M., 2018, P 2018 40 ANN INT C
   [Anonymous], 2017, RETHINKING ATROUS CO
   Armato S.G., 2017, P MED IM 2017 COMP A P MED IM 2017 COMP A
   Arnold M, 2020, GASTROENTEROLOGY, V159, P335, DOI 10.1053/j.gastro.2020.02.068
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Breier M, 2011, PROC SPIE, V7963, DOI 10.1117/12.877986
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Flach P., 2015, P 28 INT C NEUR INF, P838
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Howard A.G., 2017, PREPRINT
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang H., 2020, P ICASSP 2020 2020 I
   Jha D., 2019, P 21 IEEE INT S MULT
   Kingma D., 2015, ARXIV
   Kirillov A., 2019, ARXIV PREPRINT ARXIV
   Li J, 2021, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.620257
   Li X., 2020, P 58 ANN M ASS COMP P 58 ANN M ASS COMP
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Minghao Yin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P191, DOI 10.1007/978-3-030-58555-6_12
   Nguyen NQ, 2020, IEEE ACCESS, V8, P99495, DOI 10.1109/ACCESS.2020.2995630
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Xia K.J., 2020, STUDY ASSISTED DIAGN
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 42
TC 1
Z9 1
U1 6
U2 17
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-4185
J9 FRONT BIOENG BIOTECH
JI Front. Bioeng. Biotechnol.
PD JUL 14
PY 2021
VL 9
AR 696251
DI 10.3389/fbioe.2021.696251
PG 14
WC Biotechnology & Applied Microbiology; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Science & Technology - Other
   Topics
GA TR0RK
UT WOS:000678680400001
PM 34336808
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Kamba, S
   Tamai, N
   Saitoh, I
   Matsui, H
   Horiuchi, H
   Kobayashi, M
   Sakamoto, T
   Ego, M
   Fukuda, A
   Tonouchi, A
   Shimahara, Y
   Nishikawa, M
   Nishino, H
   Saito, Y
   Sumiyama, K
AF Kamba, Shunsuke
   Tamai, Naoto
   Saitoh, Iduru
   Matsui, Hiroaki
   Horiuchi, Hideka
   Kobayashi, Masakuni
   Sakamoto, Taku
   Ego, Mai
   Fukuda, Akihiro
   Tonouchi, Aya
   Shimahara, Yuki
   Nishikawa, Masako
   Nishino, Haruo
   Saito, Yutaka
   Sumiyama, Kazuki
TI Reducing adenoma miss rate of colonoscopy assisted by artificial
   intelligence: a multicenter randomized controlled trial
SO JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Computer-aided detection; Deep learning; Adenoma miss rate; Adenoma
   detection rate; Colonoscopy
ID COMPUTER-AIDED DETECTION; COLORECTAL-CANCER
AB Background We have developed the computer-aided detection (CADe) system using an original deep learning algorithm based on a convolutional neural network for assisting endoscopists in detecting colorectal lesions during colonoscopy. The aim of this study was to clarify whether adenoma miss rate (AMR) could be reduced with CADe assistance during screening and surveillance colonoscopy. Methods This study was a multicenter randomized controlled trial. Patients aged 40 to 80 years who were referred for colorectal screening or surveillance at four sites in Japan were randomly assigned at a 1:1 ratio to either the "standard colonoscopy (SC)-first group" or the "CADe-first group" to undergo a back-to-back tandem procedure. Tandem colonoscopies were performed on the same day for each participant by the same endoscopist in a preassigned order. All polyps detected in each pass were histopathologically diagnosed after biopsy or resection. Results A total of 358 patients were enrolled and 179 patients were assigned to the SC-first group or CADe-first group. The AMR of the CADe-first group was significantly lower than that of the SC-first group (13.8% vs. 36.7%, P < 0.0001). Similar results were observed for the polyp miss rate (14.2% vs. 40.6%, P < 0.0001) and sessile serrated lesion miss rate (13.0% vs. 38.5%, P = 0.03). The adenoma detection rate of CADe-assisted colonoscopy was 64.5%, which was significantly higher than that of standard colonoscopy (53.6%; P = 0.036). Conclusion Our study results first showed a reduction in the AMR when assisting with CADe based on deep learning in a multicenter randomized controlled trial.
C1 [Kamba, Shunsuke; Tamai, Naoto; Saitoh, Iduru; Matsui, Hiroaki; Horiuchi, Hideka; Sumiyama, Kazuki] Jikei Univ, Sch Med, Dept Endoscopy, Minato Ku, 3-25-8 Nishi Shimbashi, Tokyo 1058461, Japan.
   [Nishikawa, Masako] Jikei Univ, Sch Med, Clin Res Support Ctr, Minato Ku, 3-25-8 Nishi Shimbashi, Tokyo 1058461, Japan.
   [Kobayashi, Masakuni] Jikei Univ, Sch Med, Hosp 3, Dept Endoscopy, 4-11-1 Izumihoncho, Komae, Tokyo 2018601, Japan.
   [Sakamoto, Taku; Ego, Mai; Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.
   [Fukuda, Akihiro; Tonouchi, Aya; Shimahara, Yuki] LPIXEL Inc, Chiyoda Ku, 1-6-1 Otemachi, Tokyo 1000004, Japan.
   [Nishino, Haruo] Matsushima Hosp, Coloproctol Ctr, Nishi Ku, 3-138 Isecho, Yokohama, Kanagawa 2200045, Japan.
C3 Jikei University; Jikei University; Jikei University; National Cancer
   Center - Japan
RP Kamba, S (通讯作者)，Jikei Univ, Sch Med, Dept Endoscopy, Minato Ku, 3-25-8 Nishi Shimbashi, Tokyo 1058461, Japan.
EM kanba@jikei.ac.jp
OI KAMBA, SHUNSUKE/0000-0002-8491-7224
FU Japan Agency for Medical Research and Development [18ck0106272h0002]
FX This research was supported by Japan Agency for Medical Research and
   Development under Grant Number 18ck0106272h0002.
CR Aniwan S, 2016, AM J GASTROENTEROL, V111, P723, DOI 10.1038/ajg.2015.440
   Atkinson NSS, 2019, GASTROENTEROLOGY, V157, P462, DOI 10.1053/j.gastro.2019.04.014
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dik VK, 2015, ENDOSCOPY, V47, P1151, DOI 10.1055/s-0034-1392421
   East JE, 2017, GUT, V66, P1181, DOI 10.1136/gutjnl-2017-314005
   Gralnek IM, 2014, LANCET ONCOL, V15, P353, DOI 10.1016/S1470-2045(14)70020-8
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kudo T, 2018, GASTROINTEST ENDOSC, V88, P854, DOI 10.1016/j.gie.2018.06.011
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   MATSUDA T, 2020, GUT
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Redmon J., 2018, YOLOV3 INCREMENTAL I
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Saltzman JR, 2015, GASTROINTEST ENDOSC, V81, P781, DOI 10.1016/j.gie.2014.09.048
   Takeuchi Y, 2019, GASTROINTEST ENDOSC, V89, P460, DOI 10.1016/j.gie.2018.11.012
   Tziatzios G, 2020, GASTROINTEST ENDOSC, V91, P1027, DOI 10.1016/j.gie.2019.12.052
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Williet N, 2018, ENDOSCOPY, V50, P846, DOI 10.1055/a-0577-3500
   Winawer Sidney J, 2002, Gastrointest Endosc Clin N Am, V12, P1, DOI 10.1016/S1052-5157(03)00053-9
   Wong JCT, 2019, GASTROINTEST ENDOSC, V89, P607, DOI 10.1016/j.gie.2018.11.014
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
   Zimmermann-Fraedrich K, 2021, GUT, V70, P268, DOI 10.1136/gutjnl-2020-320984
NR 31
TC 32
Z9 33
U1 1
U2 6
PU SPRINGER JAPAN KK
PI TOKYO
PA SHIROYAMA TRUST TOWER 5F, 4-3-1 TORANOMON, MINATO-KU, TOKYO, 105-6005,
   JAPAN
SN 0944-1174
EI 1435-5922
J9 J GASTROENTEROL
JI J. Gastroenterol.
PD AUG
PY 2021
VL 56
IS 8
BP 746
EP 757
DI 10.1007/s00535-021-01808-w
EA JUL 2021
PG 12
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA TQ1MS
UT WOS:000669299500002
PM 34218329
DA 2023-08-21
ER

PT J
AU Wang, Y
   Feng, ZX
   Song, LP
   Liu, XB
   Liu, S
AF Wang, Yan
   Feng, Zixuan
   Song, Liping
   Liu, Xiangbin
   Liu, Shuai
TI Multiclassification of Endoscopic Colonoscopy Images Based on Deep
   Transfer Learning
SO COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE
LA English
DT Article
ID CLASSIFICATION; COVID-19; FUSION
AB With the continuous improvement of human living standards, dietary habits are constantly changing, which brings various bowel problems. Among them, the morbidity and mortality rates of colorectal cancer have maintained a significant upward trend. In recent years, the application of deep learning in the medical field has become increasingly spread aboard and deep. In a colonoscopy, Artificial Intelligence based on deep learning is mainly used to assist in the detection of colorectal polyps and the classification of colorectal lesions. But when it comes to classification, it can lead to confusion between polyps and other diseases. In order to accurately diagnose various diseases in the intestines and improve the classification accuracy of polyps, this work proposes a multiclassification method for medical colonoscopy images based on deep learning, which mainly classifies the four conditions of polyps, inflammation, tumor, and normal. In view of the relatively small number of data sets, the network firstly trained by transfer learning on ImageNet was used as the pretraining model, and the prior knowledge learned from the source domain learning task was applied to the classification task about intestinal illnesses. Then, we fine-tune the model to make it more suitable for the task of intestinal classification by our data sets. Finally, the model is applied to the multiclassification of medical colonoscopy images. Experimental results show that the method in this work can significantly improve the recognition rate of polyps while ensuring the classification accuracy of other categories, so as to assist the doctor in the diagnosis of surgical resection.
C1 [Wang, Yan] Jilin Univ, China Japan Union Hosp, Dept Gen Surg, Changchun 130033, Peoples R China.
   [Wang, Yan] Shenyang Pharmaceut Univ, Coll Pharm, Dept Pharmaceut, Shenyang 110116, Peoples R China.
   [Feng, Zixuan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Song, Liping; Liu, Xiangbin; Liu, Shuai] Hunan Normal Univ, Coll Informat Sci & Engn, Changsha 410081, Peoples R China.
   [Song, Liping; Liu, Xiangbin; Liu, Shuai] Hunan Xiangjiang Artificial Intelligence Acad, Changsha 410081, Peoples R China.
C3 Jilin University; Shenyang Pharmaceutical University; Jilin University;
   Hunan Normal University
RP Liu, S (通讯作者)，Hunan Normal Univ, Coll Informat Sci & Engn, Changsha 410081, Peoples R China.; Liu, S (通讯作者)，Hunan Xiangjiang Artificial Intelligence Acad, Changsha 410081, Peoples R China.
EM cs.liu.shuai@gmail.com
RI Liu, Shuai/AAX-1239-2021; Feng, Zixuan/ABA-5859-2020
OI Liu, Shuai/0000-0001-9909-0664; 
FU Scientific Research Project of Education Department of Jilin Province
   [JJKH20211062KJ]; Natural Science Foundation of Hunan Province
   [2020JJ4434]; Key Scientific Research Projects of Department of
   Education in Hunan Province [19A312]; Hunan Provincial Science &
   Technology Project Foundation [2018TP1018, 2018RS3065]; Innovation and
   Entrepreneurship Training Program of Hunan Xiangjiang Artificial
   Intelligence Academy, and Educational Reform Project of Hunan Xiangjiang
   Artificial Intelligence Academy
FX This work is partly funded by the Scientific Research Project of
   Education Department of Jilin Province with No. JJKH20211062KJ, Natural
   Science Foundation of Hunan Province with No. 2020JJ4434, Key Scientific
   Research Projects of Department of Education in Hunan Province with No.
   19A312, Hunan Provincial Science & Technology Project Foundation
   (2018TP1018 and 2018RS3065), Innovation and Entrepreneurship Training
   Program of Hunan Xiangjiang Artificial Intelligence Academy, and
   Educational Reform Project of Hunan Xiangjiang Artificial Intelligence
   Academy.
CR Alfian G, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072183
   Chang H, 2018, IEEE T PATTERN ANAL, V40, P1182, DOI 10.1109/TPAMI.2017.2656884
   Choi JY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187336
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Frid-Adar M, 2018, I S BIOMED IMAGING, P289, DOI 10.1109/ISBI.2018.8363576
   Gao XT, 2015, IEEE T BIO-MED ENG, V62, P2693, DOI 10.1109/TBME.2015.2444389
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060
   Kaur Taranjit, 2019, 2019 International Conference on Information Technology (ICIT), P94, DOI 10.1109/ICIT48102.2019.00023
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin JCW, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107422
   Lin JCW, 2021, IEEE INTERNET THINGS, V8, P5340, DOI 10.1109/JIOT.2020.3032896
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Ma L, 2020, MED BIOL ENG COMPUT, V58, P1251, DOI 10.1007/s11517-020-02163-3
   Madani A, 2018, I S BIOMED IMAGING, P1038, DOI 10.1109/ISBI.2018.8363749
   Simonyan K., 3 INT C LEARN REPR S, P1
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Suk HI, 2013, LECT NOTES COMPUT SC, V8150, P583, DOI 10.1007/978-3-642-40763-5_72
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Talo M, 2019, COGN SYST RES, V54, P176, DOI 10.1016/j.cogsys.2018.12.007
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Wang SH, 2020, INT J COMPUT INT SYS, V13, P1332, DOI 10.2991/ijcis.d.200828.001
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Zaremba W., 2014, ARXIV
   Zhang YD, 2020, INFORM FUSION, V64, P149, DOI 10.1016/j.inffus.2020.07.006
NR 36
TC 12
Z9 12
U1 3
U2 23
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1748-670X
EI 1748-6718
J9 COMPUT MATH METHOD M
JI Comput. Math. Method Med.
PD JUL 3
PY 2021
VL 2021
AR 2485934
DI 10.1155/2021/2485934
PG 12
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA TL1UQ
UT WOS:000674640700001
PM 34306173
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Sakamoto, T
   Cho, HR
   Saito, Y
AF Sakamoto, Taku
   Cho, Hourin
   Saito, Yutaka
TI Clinical Applications of Linked Color Imaging and Blue Laser/Light
   Imaging in the Screening, Diagnosis, and Treatment of Superficial
   Colorectal Tumors
SO CLINICAL ENDOSCOPY
LA English
DT Review
DE Blue laser/light imaging; Colonoscopy; Linked color imaging; Superficial
   colorectal tumor
ID MAGNIFYING CHROMOENDOSCOPY; COLONOSCOPY SURVEILLANCE; NEOPLASTIC
   LESIONS; MISS RATE; ABILITY; SYSTEM; POLYPECTOMY; MULTICENTER; SOCIETY;
   POLYPS
AB Considering its contribution to reducing colorectal cancer morbidity and mortality, the most important task of colonoscopy is to find all existing polyps. Moreover, the accurate detection of existing polyps determines the risk of colorectal cancer morbidity and is an important factor in deciding the appropriate surveillance program for patients. Image-enhanced endoscopy is an easy-touse modality with improved lesion detection. Linked color imaging (LCI) and blue laser/light imaging (BLI) are useful modalities for improving colonoscopy quality. Each mode has unique optical features; therefore, their intended use differs. LCI contributes to improved polyp detection due to its brightness and high color contrast between the lesion and normal mucosa. while BLI contributes to the characterization of detected polyps by evaluating the vessel and surface patterns of detected lesions. The proper use of these observation modes allows for more efficient endoscopic diagnosis. Moreover, recent developments in artificial intelligence will soon change the clinical practice of colonoscopy and this system will provide an efficient education modality fir novice endoscopists.
C1 [Sakamoto, Taku; Cho, Hourin; Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Tokyo, Japan.
C3 National Cancer Center - Japan
RP Sakamoto, T (通讯作者)，Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.
EM tasakamo@ncc.go.jp
CR Ang TL, 2019, ENDOSC INT OPEN, V7, pE1207, DOI 10.1055/a-0982-3111
   Bisschops R, 2018, ENDOSCOPY, V50, P211, DOI 10.1055/s-0043-121570
   Brand EC, 2017, GASTROINTEST ENDOSC, V86, P376, DOI 10.1016/j.gie.2016.12.025
   Desai M, 2021, J GASTROEN HEPATOL, V36, P2728, DOI 10.1111/jgh.15529
   Hassan C, 2013, ENDOSCOPY, V45, P842, DOI 10.1055/s-0033-1344548
   Ikematsu H, 2017, GASTROINTEST ENDOSC, V86, P386, DOI 10.1016/j.gie.2017.01.017
   Kaneko K, 2014, ENDOSC INT OPEN, V2, pE212, DOI 10.1055/s-0034-1390707
   Kudo T, 2021, COLORECTAL DIS, V23, P1414, DOI 10.1111/codi.15605
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Min M, 2017, GASTROINTEST ENDOSC, V86, P724, DOI 10.1016/j.gie.2017.02.035
   Nakano A, 2017, ENDOSC INT OPEN, V5, pE224, DOI 10.1055/s-0043-102400
   Osawa H, 2018, CLIN ENDOSC, V51, P513, DOI 10.5946/ce.2018.132
   Paggi S, 2018, ENDOSCOPY, V50, P396, DOI 10.1055/a-0580-7405
   Pan J, 2016, AM J GASTROENTEROL, V111, P355, DOI 10.1038/ajg.2015.418
   Rondonotti E, 2020, CLIN GASTROENTEROL H, V18, P2357, DOI 10.1016/j.cgh.2019.12.028
   Sakamoto T, 2019, ENDOSC INT OPEN, V7, pE1448, DOI 10.1055/a-0982-2904
   Sakamoto T, 2019, INT J COLORECTAL DIS, V34, P1341, DOI 10.1007/s00384-019-03323-0
   Sakamoto T, 2018, GASTROINTEST ENDOSC, V87, P1318, DOI 10.1016/j.gie.2017.12.021
   Shimoda R, 2017, ENDOSCOPY, V49, P186, DOI 10.1055/s-0042-118450
   Shinozaki S, 2020, DIGEST ENDOSC, V32, P874, DOI 10.1111/den.13613
   Subramaniam S, 2019, UNITED EUR GASTROENT, V7, P316, DOI 10.1177/2050640618822402
   Weigt J, 2022, ENDOSCOPY, V54, P180, DOI 10.1055/a-1372-0419
   Yoshida N, 2019, GUT LIVER, V13, P140, DOI 10.5009/gnl18276
   Yoshida N, 2014, DIGEST ENDOSC, V26, P250, DOI 10.1111/den.12127
   Yoshida N, 2014, J GASTROENTEROL, V49, P73, DOI 10.1007/s00535-013-0772-7
NR 25
TC 3
Z9 3
U1 0
U2 1
PU KOREAN SOC GASTROINTESTINAL ENDOSCOPY
PI SEOUL
PA 2003 LG PALACE, 165-8 DONGGYO-DONG, MAPO-GU, SEOUL, 121-754, SOUTH KOREA
SN 2234-2400
EI 2234-2443
J9 CLIN ENDOSC
JI Clin. Endosc.
PD JUL
PY 2021
VL 54
IS 4
BP 488
EP 493
DI 10.5946/ce.2021.157
PG 6
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA TU2CY
UT WOS:000680848600007
PM 34261208
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Repici, A
   Spadaccini, M
   Antonelli, G
   Correale, L
   Maselli, R
   Galtieri, PA
   Pellegatta, G
   Capogreco, A
   Milluzzo, SM
   Lollo, G
   Di Paolo, D
   Badalamenti, M
   Ferrara, E
   Fugazza, A
   Carrara, S
   Anderloni, A
   Rondonotti, E
   Amato, A
   De Gottardi, A
   Spada, C
   Radaelli, F
   Savevski, V
   Wallace, MB
   Sharma, P
   Rosch, T
   Hassan, C
AF Repici, Alessandro
   Spadaccini, Marco
   Antonelli, Giulio
   Correale, Loredana
   Maselli, Roberta
   Galtieri, Piera Alessia
   Pellegatta, Gaia
   Capogreco, Antonio
   Milluzzo, Sebastian Manuel
   Lollo, Gianluca
   Di Paolo, Dhanai
   Badalamenti, Matteo
   Ferrara, Elisa
   Fugazza, Alessandro
   Carrara, Silvia
   Anderloni, Andrea
   Rondonotti, Emanuele
   Amato, Arnaldo
   De Gottardi, Andrea
   Spada, Cristiano
   Radaelli, Franco
   Savevski, Victor
   Wallace, Michael B.
   Sharma, Prateek
   Roesch, Thomas
   Hassan, Cesare
TI Artificial intelligence and colonoscopy experience: lessons from two
   randomised trials
SO GUT
LA English
DT Article
DE colonoscopy; adenoma; artificial Intelligence; colorectal cancer;
   screening
ID COMPUTER-AIDED DETECTION; ADENOMA DETECTION; DETECTION RATES; QUALITY
   INDICATORS; COLORECTAL-CANCER; SCREENING-PROGRAM; PERFORMANCE;
   COMPETENCE; SYSTEM; TRENDS
AB Background and aims Artificial intelligence has been shown to increase adenoma detection rate (ADR) as the main surrogate outcome parameter of colonoscopy quality. To which extent this effect may be related to physician experience is not known. We performed a randomised trial with colonoscopists in their qualification period (AID-2) and compared these data with a previously published randomised trial in expert endoscopists (AID-1). Methods In this prospective, randomised controlled non-inferiority trial (AID-2), 10 non-expert endoscopists (<2000 colonoscopies) performed screening/surveillance/diagnostic colonoscopies in consecutive 40-80 year-old subjects using high-definition colonoscopy with or without a real-time deep-learning computer-aided detection (CADe) (GI Genius, Medtronic). The primary outcome was ADR in both groups with histology of resected lesions as reference. In a post-hoc analysis, data from this randomised controlled trial (RCT) were compared with data from the previous AID-1 RCT involving six experienced endoscopists in an otherwise similar setting. Results In 660 patients (62.3 +/- 10 years; men/women: 330/330) with equal distribution of study parameters, overall ADR was higher in the CADe than in the control group (53.3% vs 44.5%; relative risk (RR): 1.22; 95% CI: 1.04 to 1.40; p<0.01 for non-inferiority and p=0.02 for superiority). Similar increases were seen in adenoma numbers per colonoscopy and in small and distal lesions. No differences were observed with regards to detection of non-neoplastic lesions. When pooling these data with those from the AID-1 study, use of CADe (RR 1.29; 95% CI: 1.16 to 1.42) and colonoscopy indication, but not the level of examiner experience (RR 1.02; 95% CI: 0.89 to 1.16) were associated with ADR differences in a multivariate analysis. Conclusions In less experienced examiners, CADe assistance during colonoscopy increased ADR and a number of related polyp parameters as compared with the control group. Experience appears to play a minor role as determining factor for ADR.
C1 [Repici, Alessandro; Spadaccini, Marco; Maselli, Roberta; Capogreco, Antonio] Humanitas Univ, Dept Biomed Sci, Milan, Italy.
   [Repici, Alessandro; Spadaccini, Marco; Correale, Loredana; Maselli, Roberta; Galtieri, Piera Alessia; Pellegatta, Gaia; Capogreco, Antonio; Badalamenti, Matteo; Ferrara, Elisa; Fugazza, Alessandro; Carrara, Silvia; Anderloni, Andrea] IRCCS, Endoscopy Unit, Humanitas Clin & Res Ctr, Rozzano, Italy.
   [Antonelli, Giulio; Hassan, Cesare] Osped Nuovo Regina Margherita, Gastroenterol & Digest Endoscopy Unit, Rome, Italy.
   [Antonelli, Giulio] Sapienza Univ Rome, Dept Translat & Precis Med, Rome, Italy.
   [Milluzzo, Sebastian Manuel; Spada, Cristiano] Poliambulanza Brescia Hosp, Digest Endoscopy Unit, Brescia, Lombardia, Italy.
   [Lollo, Gianluca; De Gottardi, Andrea] Univ Svizzera Italiana, Dept Gastroenterol & Hepatol, Lugano, Switzerland.
   [Di Paolo, Dhanai; Rondonotti, Emanuele; Amato, Arnaldo; Radaelli, Franco] Valduce Hosp, Div Digest Endoscopy & Gastroenterol, Como, Italy.
   [Savevski, Victor] IRCCS, Humanitas Clin & Res Ctr, Artificial Intelligence Res, Rozzano, Italy.
   [Wallace, Michael B.] Mayo Clin, Endoscopy Unit, Jacksonville, FL 32224 USA.
   [Sharma, Prateek] Univ Kansas, Kansas City, KS USA.
   [Sharma, Prateek] Univ Kansas, Endoscopy Unit, Kansas City, KS USA.
   [Roesch, Thomas] Univ Hosp Hamburg Eppendorf, Interdisciplinary Endoscopy, Hamburg, Germany.
C3 Humanitas University; IRCCS Humanitas Research Hospital; Poliambulatorio
   Nuovo Regina Margherita; Sapienza University Rome; Universita della
   Svizzera Italiana; IRCCS Humanitas Research Hospital; Mayo Clinic;
   University of Kansas; University of Kansas; University of Hamburg;
   University Medical Center Hamburg-Eppendorf
RP Repici, A (通讯作者)，IRCCS, Gastroenerol & Endoscopy Unit, Humanitas Res Hosp, Rozzano, Lombardia, Italy.
EM alessandro.repici@hunimed.eu
RI Spadaccini, Marco/HOH-7613-2023; Fugazza, Alessandro/ABG-9381-2021;
   Sharma, Prateek/IZE-3910-2023; Wallace, Michael/GZL-9731-2022; Carrara,
   Silvia/AAC-5298-2022; Repici, Alessandro/HFH-8162-2022; hassan,
   cesare/H-2844-2012; Maselli, Roberta/HJY-6995-2023
OI Spadaccini, Marco/0000-0003-3909-9012; Fugazza,
   Alessandro/0000-0003-0485-4903; Wallace, Michael/0000-0002-6446-5785;
   Repici, Alessandro/0000-0002-1621-6450; hassan,
   cesare/0000-0001-7167-1459; Maselli, Roberta/0000-0001-7291-9110; Amato,
   Arnaldo/0000-0002-4397-4142; Andrea, De Gottardi/0000-0002-4401-2340;
   Antonelli, Giulio/0000-0003-1797-3864; Pellegatta,
   Gaia/0000-0003-0235-4905; Carrara, Silvia/0000-0003-4206-9463; Galtieri,
   Piera/0000-0002-3253-6972
CR [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   Arribas J, 2021, GUT, V70, P1458, DOI 10.1136/gutjnl-2020-321922
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012
   Chung SJ, 2014, GUT, V63, P785, DOI 10.1136/gutjnl-2013-304578
   Cross AJ, 2022, CLIN GASTROENTEROL H, V20, pE148, DOI 10.1016/j.cgh.2020.09.020
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dekker E, 2020, ENDOSCOPY, V52, P899, DOI 10.1055/a-1231-5123
   Forbes N, 2020, CLIN GASTROENTEROL H, V18, P2192, DOI 10.1016/j.cgh.2020.03.046
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gupta S, 2011, GASTROINTEST ENDOSC, V73, P1232, DOI 10.1016/j.gie.2011.01.069
   Hassan C., DIGEST ENDOSC
   Hassan C, 2021, DIGEST ENDOSC, V33, P285, DOI 10.1111/den.13807
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   le Clercq CMC, 2016, ENDOSCOPY, V48, P248, DOI 10.1055/s-0041-111117
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Liu XX, 2020, NAT MED, V26, P1364, DOI 10.1038/s41591-020-1034-x
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Qayed E, 2017, WORLD J GASTRO ENDOS, V9, P540, DOI 10.4253/wjge.v9.i11.540
   Rees CJ, 2016, GUT, V65, P1923, DOI 10.1136/gutjnl-2016-312044
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Repici A, 2019, GASTROENTEROLOGY, V156, P2198, DOI 10.1053/j.gastro.2019.02.001
   Rex DK, 2000, GASTROINTEST ENDOSC, V51, P33, DOI 10.1016/S0016-5107(00)70383-X
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Schulz KF, 2010, J CLIN EPIDEMIOL, V63, P834, DOI [10.1136/bmj.c869, 10.1016/j.jclinepi.2010.02.005, 10.4103/0976-500X.72352, 10.1186/1741-7015-8-18, 10.1016/j.ijsu.2011.09.004, 10.1016/j.jclinepi.2010.03.004]
   Solis-Munoz P, 2014, J GASTROEN HEPATOL, V29, P1237, DOI 10.1111/jgh.12537
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Waldmann E, 2021, GUT, V70, P1309, DOI 10.1136/gutjnl-2019-319427
   Walsh CM, 2021, GASTROINTEST ENDOSC, V93, P297, DOI 10.1016/j.gie.2020.06.054
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Ward ST, 2014, GUT, V63, P1746, DOI 10.1136/gutjnl-2013-305973
   Zimmermann-Fraedrich K, 2021, GUT, V70, P268, DOI 10.1136/gutjnl-2020-320984
   Zorzi M, 2015, GUT, V64, P1389, DOI 10.1136/gutjnl-2014-307954
NR 38
TC 53
Z9 55
U1 0
U2 17
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0017-5749
EI 1468-3288
J9 GUT
JI Gut
PD APR
PY 2022
VL 71
IS 4
BP 757
EP 765
DI 10.1136/gutjnl-2021-324471
EA JUN 2021
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA ZT7TH
UT WOS:000728864500001
PM 34187845
DA 2023-08-21
ER

PT J
AU Antonelli, G
   Badalamenti, M
   Hassan, C
   Repici, A
AF Antonelli, Giulio
   Badalamenti, Matteo
   Hassan, Cesare
   Repici, Alessandro
TI Impact of artificial intelligence on colorectal polyp detection
SO BEST PRACTICE & RESEARCH CLINICAL GASTROENTEROLOGY
LA English
DT Article
DE Artificial intelligence; CADe system; Adenoma detection rate;
   Colonoscopy
ID ADENOMA DETECTION; COLONOSCOPY; RISK; CANCER; SYSTEM
AB Since colonoscopy and polypectomy were introduced, Colorectal Cancer (CRC) incidence and mortality decreased significantly. Although we have entered the era of quality measurement and improvement, literature shows that a considerable amount of colorectal neoplasia is still missed by colonoscopists up to 25%, leading to an high rate of interval colorectal cancer that account for nearly 10% of all diagnosed CRC. Two main reasons have been recognised: recognition failure and mucosal exposure. For this purpose, Artificial Intelligence (AI) systems have been recently developed that identify a "hot" area during the endoscopic examination. In retrospective studies, where the systems are tested with a batch of unknown images, deep learning systems have shown very good performances, with high levels of accuracy. Of course, this setting may not reflect actual clinical practice where different pitfalls can occur, like sub -optimal bowel preparation or poor examination technique. For this reason, a number of randomised clinical trials have recently been published where AI was tested in real time during endoscopic exami-nations. We present here an overview on recent literature addressing the performance of Computer Assisted Detection (CADe) of colorectal polyps in colonoscopy. (c) 2020 Elsevier Ltd. All rights reserved.
C1 [Antonelli, Giulio; Hassan, Cesare] Nuovo Regina Margherita Hosp, Gastroenterol Unit, Rome, Italy.
   [Badalamenti, Matteo; Repici, Alessandro] Humanitas Clin & Res Ctr IRCCS, Div Gastroenterol, Digest Endoscopy Unit, I-20089 Rozzano, Italy.
   [Repici, Alessandro] Humanitas Univ, Dept Biomed Sci, Pieve Emanuele, MI, Italy.
C3 Poliambulatorio Nuovo Regina Margherita
RP Badalamenti, M (通讯作者)，Humanitas Clin & Res Ctr IRCCS, Div Gastroenterol, Digest Endoscopy Unit, I-20089 Rozzano, Italy.
EM badalamenti.matteo@gmail.com
RI hassan, cesare/H-2844-2012; Repici, Alessandro/HFH-8162-2022
OI hassan, cesare/0000-0001-7167-1459; Repici,
   Alessandro/0000-0002-1621-6450; Badalamenti, Matteo/0000-0002-9543-9862;
   Antonelli, Giulio/0000-0003-1797-3864
CR Arribas J, 2021, GUT, V70, P1458, DOI 10.1136/gutjnl-2020-321922
   Atkin W, 2017, LANCET ONCOL, V18, P823, DOI 10.1016/S1470-2045(17)30187-0
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Brenner H, 2001, BRIT J CANCER, V85, P972, DOI 10.1038/sj.bjc.6692023
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Groen PC, 2020, TECH INNOVAT GASTROI, V22, P71, DOI 10.1016/j.tgie.2019.150640
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, DIGEST ENDOSC, V33, P285, DOI 10.1111/den.13807
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Holzwanger EA, 2021, ENDOSCOPY, V53, P937, DOI 10.1055/a-1302-2942
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Robertson DJ, 2014, GUT, V63, P949, DOI 10.1136/gutjnl-2012-303796
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   VANDERSOMMEN F, 2020, GUT, DOI DOI 10.1136/GUTJNL-2019-320466.GUTJNL-2019-320466
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
NR 32
TC 6
Z9 7
U1 1
U2 5
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1521-6918
EI 1532-1916
J9 BEST PRACT RES CL GA
JI Best Pract. Res. Clin. Gastroenterol.
PD JUN-AUG
PY 2021
VL 52-53
AR 101713
DI 10.1016/j.bpg.2020.101713
EA JUN 2021
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA SX0UM
UT WOS:000664928200004
PM 34172246
DA 2023-08-21
ER

PT J
AU Barua, I
   Mori, Y
   Bretthauer, M
AF Barua, Ishita
   Mori, Yuichi
   Bretthauer, Michael
TI Colorectal polyp characterization with endocytoscopy: Ready for
   widespread implementation with artificial intelligence?
SO BEST PRACTICE & RESEARCH CLINICAL GASTROENTEROLOGY
LA English
DT Article
DE Endocytoscopy; Artificial intelligence (AI); Computer aided diagnosis;
   Optical diagnosis
ID CONFOCAL LASER ENDOMICROSCOPY; AIDED DIAGNOSTIC SYSTEM; GASTROINTESTINAL
   ENDOSCOPY; OPTICAL DIAGNOSIS; EUROPEAN-SOCIETY; LESIONS; ACCURACY;
   IMPACT; CLASSIFICATION; MAGNIFICATION
AB Endocytoscopy provides an in-vivo visualization of nuclei and micro-vessels at the cellular level in realtime, facilitating so-called "optical biopsy" or "virtual histology" of colorectal polyps/neoplasms. This functionality is enabled by 520-fold magnification power with endocytoscopy and recent breakthroughs in artificial intelligence (AI) allowing a great advance in endocytoscopic imaging; interpretation of images is now fully supported by AI tool which outputs predictions of polyp histopathology during colonoscopy. The advantage of the use of AI during optical biopsy can be appreciated especially by non expert endoscopists who to increase performance. This paper provides an overview of the latest evidence on colorectal polyp characterization with endocytoscopy combined with AI and identify the barriers to its widespread implementation. (c) 2020 Elsevier Ltd. All rights reserved.
C1 [Barua, Ishita; Mori, Yuichi; Bretthauer, Michael] Univ Oslo, Inst Hlth & Soc, Clin Effect Res Grp, Oslo, Norway.
   [Barua, Ishita; Mori, Yuichi; Bretthauer, Michael] Oslo Univ Hosp, Dept Transplantat Med, Oslo, Norway.
   [Mori, Yuichi] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Yokohama, Kanagawa, Japan.
C3 University of Oslo; University of Oslo; Showa University
RP Mori, Y (通讯作者)，Univ Oslo, Inst Hlth & Soc, Clin Effect Res Grp, Oslo, Norway.
EM ibusiginjp@gmail.com
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Adami, DOS DONTS EVALUATION, DOI [10.1055/s-0034-1393094, DOI 10.1055/S-0034-1393094]
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   [Anonymous], REV COMMENT N STATE, DOI DOI 10.1148/RADIOL.11091710
   [Anonymous], 2020, ENDOSC INT OPEN, DOI DOI 10.1055/A-1223-1926.08
   Barua I, 2020, ENDOSCOPY, DOI [10.1055/a-1201-7165.0, DOI 10.1055/A-1201-7165.0]
   Burnett-Hartman AN, 2013, AM J EPIDEMIOL, V177, P625, DOI 10.1093/aje/kws282
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cohen J, 2019, GASTROINTEST ENDOSC, V90, P35, DOI 10.1016/j.gie.2019.03.020
   Davila RE, 2006, GASTROINTEST ENDOSC, V63, P546, DOI 10.1016/j.gie.2006.02.002
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Hassan C, 2019, ENDOSCOPY, V51, P266, DOI 10.1055/a-0831-2522
   Ichimasa K, 2013, DOUBLE STAINING CRYS, DOI [10.1111/den.12164, DOI 10.1111/DEN.12164]
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Inoue H, 2005, NAT CLIN PRACT GASTR, V2, P31, DOI 10.1038/ncpgasthep0072
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kiesslich R, 2004, GASTROENTEROLOGY, V127, P706, DOI 10.1053/j.gastro.2004.06.050
   Kodashima S, 2006, ENDOSCOPY, V38, P1115, DOI 10.1055/s-2006-944915
   Kudo S, 2001, ENDOSCOPY, V33, P367
   Kudo SE, 2011, ENDOSCOPY, V43, P869, DOI 10.1055/s-0030-1256663
   Kudo T, 2015, DIGEST ENDOSC, V27, P754, DOI 10.1111/den.12469
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2013, ENDOSCOPY, V45, P98, DOI 10.1055/s-0032-1325932
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Murino A, 2016, CURR OPIN GASTROEN, V32, P38, DOI 10.1097/MOG.0000000000000230
   Neumann H, 2010, GASTROENTEROLOGY, V139, P388, DOI 10.1053/j.gastro.2010.06.029
   Raghavendra M, 2010, GASTROINTEST ENDOSC, V72, P572, DOI 10.1016/j.gie.2010.03.1124
   Rastogi A, 2014, GASTROINTEST ENDOSC, V79, P390, DOI 10.1016/j.gie.2013.07.032
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Rex DK, 2009, AM J GASTROENTEROL, V104, P149, DOI 10.1038/ajg.2008.35
   Ruffle JK, 2019, AM J GASTROENTEROL, V114, P422, DOI 10.1038/s41395-018-0268-4
   Sakata S, 2017, GASTROINTEST ENDOSC, V86, P372, DOI 10.1016/j.gie.2016.11.031
   Sasajima K, 2006, GASTROINTEST ENDOSC, V63, P1010, DOI 10.1016/j.gie.2006.01.021
   Schreuders EH, 2015, GUT, V64, P1637, DOI 10.1136/gutjnl-2014-309086
   Siegel RL., 2020, CA-CANCER J CLIN, V70, P145, DOI [DOI 10.3322/caac.21590, 10.3322/caac.21601]
   Takamaru H, 2020, TRANSL GASTROENT HEP, V5, DOI 10.21037/tgh.2019.12.04
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Utsumi T, 2018, WORLD J GASTRO ONCOL, V10, P96, DOI 10.4251/wjgo.v10.i4.96
   Wanders LK, 2013, LANCET ONCOL, V14, P1337, DOI 10.1016/S1470-2045(13)70509-6
   WINAWER SJ, 1993, NEW ENGL J MED, V328, P901, DOI 10.1056/NEJM199304013281301
   Yoshida S, 2005, DIGEST ENDOSC, V17, pS43, DOI [10.1111/j.1443-1661.2005.00511.x, DOI 10.1111/J.1443-1661.2005.00511.X]
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 46
TC 2
Z9 2
U1 0
U2 3
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1521-6918
EI 1532-1916
J9 BEST PRACT RES CL GA
JI Best Pract. Res. Clin. Gastroenterol.
PD JUN-AUG
PY 2021
VL 52-53
AR 101721
DI 10.1016/j.bpg.2020.101721
EA JUN 2021
PG 4
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA SX0UM
UT WOS:000664928200010
PM 34172248
DA 2023-08-21
ER

PT J
AU Komeda, Y
   Handa, H
   Matsui, R
   Hatori, S
   Yamamoto, R
   Sakurai, T
   Takenaka, M
   Hagiwara, S
   Nishida, N
   Kashida, H
   Watanabe, T
   Kudo, M
AF Komeda, Yoriaki
   Handa, Hisashi
   Matsui, Ryoma
   Hatori, Shohei
   Yamamoto, Riku
   Sakurai, Toshiharu
   Takenaka, Mamoru
   Hagiwara, Satoru
   Nishida, Naoshi
   Kashida, Hiroshi
   Watanabe, Tomohiro
   Kudo, Masatoshi
TI Artificial intelligence-based endoscopic diagnosis of colorectal polyps
   using residual networks
SO PLOS ONE
LA English
DT Article
ID BAND IMAGING NBI; CLASSIFICATION; CANCER; SYSTEM; PREVENTION; LESIONS
AB Convolutional neural networks (CNNs) are widely used for artificial intelligence (AI)-based image classification. Residual network (ResNet) is a new technology that facilitates the accuracy of image classification by CNN-based AI. In this study, we developed a novel AI model combined with ResNet to diagnose colorectal polyps. In total, 127,610 images consisting of 62,510 images with adenomatous polyps, 30,443 with non-adenomatous hyperplastic polyps, and 34,657 with healthy colorectal normal mucosa were subjected to deep learning after annotation. Each validation process was performed using 12,761 stored images of colorectal polyps by a 10-fold cross validation. The efficacy of the ResNet system was evaluated by sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and diagnostic accuracy. The sensitivity, specificity, PPV, NPV, and diagnostic accuracy for adenomatous polyps at WLIs were 98.8%, 94.3%, 90.5%, 87.4%, and 92.8%, respectively. Similar results were obtained for adenomatous polyps at narrow-band imagings (NBIs) and chromoendoscopy images (CEIs) (NBIs vs. CEIs: sensitivity, 94.9% vs. 98.2%; specificity, 93.9% vs. 85.8%; PPV, 92.5% vs. 81.7%; NPV, 93.5% vs. 99.9%; and overall accuracy, 91.5% vs. 90.1%). The ResNet model is a powerful tool that can be used for AI-based accurate diagnosis of colorectal polyps.
C1 [Komeda, Yoriaki; Sakurai, Toshiharu; Takenaka, Mamoru; Hagiwara, Satoru; Nishida, Naoshi; Kashida, Hiroshi; Watanabe, Tomohiro; Kudo, Masatoshi] Kindai Univ, Fac Med, Dept Gastroenterol & Hepatol, Osaka, Japan.
   [Handa, Hisashi; Matsui, Ryoma; Hatori, Shohei; Yamamoto, Riku] Kindai Univ, Fac Sci & Engn, Osaka, Japan.
   [Handa, Hisashi] Kindai Univ, Res Inst Sci & Technol, Osaka, Japan.
   [Handa, Hisashi] Kindai Univ, Cyber Informat Res Inst, Osaka, Japan.
C3 Kindai University (Kinki University); Kindai University (Kinki
   University); Kindai University (Kinki University); Kindai University
   (Kinki University)
RP Komeda, Y (通讯作者)，Kindai Univ, Fac Med, Dept Gastroenterol & Hepatol, Osaka, Japan.
EM y-komme@mvb.biglobe.ne.jp
RI Watanabe, Tomohiro/ABA-4712-2021
CR Bour A, 2019 IEEE INT S SIGN
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P49, DOI 10.1159/000481230
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Krizhevsky Alex, 2012, NEURIPS
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 22
TC 5
Z9 5
U1 2
U2 5
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JUN 22
PY 2021
VL 16
IS 6
AR e0253585
DI 10.1371/journal.pone.0253585
PG 13
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA TG9BH
UT WOS:000671691200035
PM 34157030
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Parsa, N
   Rex, DK
   Byrne, MF
AF Parsa, Nasim
   Rex, Douglas K.
   Byrne, Michael F.
TI Colorectal polyp characterization with standard endoscopy: Will
   Artificial Intelligence succeed where human eyes failed?
SO BEST PRACTICE & RESEARCH CLINICAL GASTROENTEROLOGY
LA English
DT Article
DE Computer-aided diagnosis; Convolutional neural network; Resect and
   discard; Diminutive polyps
ID COMPUTER-AIDED DIAGNOSIS; GASTROINTESTINAL ENDOSCOPY; OPTICAL BIOPSY;
   CLASSIFICATION; HISTOLOGY; CANCER; SYSTEM
AB The American Society for Gastrointestinal Endoscopy (ASGE) has proposed the "resect-and-discard" and "diagnose-and-leave" strategies for diminutive colorectal polyps to reduce the costs of unnecessary polyp resection and pathology evaluation. However, the diagnostic thresholds set by these guidelines are not always met in community practice. To overcome this sub-optimal performance, artificial intelligence (AI) has been applied to the field of endoscopy. The incorporation of deep learning algorithms with AI models resulted in highly accurate systems that match the expert endoscopists' optical biopsy and exceed the ASGE recommended thresholds. Recent studies have demonstrated that the integration of AI in clinical practice results in significant improvement in endoscopists' diagnostic accuracy while reducing the time to make a diagnosis. Yet, several points need to be addressed before AI models can be successfully implemented in clinical practice. In this review, we summarize the recent literature on the application of AI for characterization of colorectal polyps, and review the current limitation and future directions for this field. (c) 2021 Published by Elsevier Ltd.
C1 [Parsa, Nasim] Univ Missouri, Dept Med, Div Gastroenterol & Hepatol, Columbia, MO USA.
   [Rex, Douglas K.] Indiana Univ Sch Med, Dept Med, Div Gastroenterol & Hepatol, Indianapolis, IN 46202 USA.
   [Byrne, Michael F.] Univ British Columbia, Dept Med, Div Gastroenterol & Hepatol, Vancouver, BC, Canada.
   [Byrne, Michael F.] Satisfai Hlth, Vancouver, BC, Canada.
   [Byrne, Michael F.] AI4GI Joint Venture, Vancouver, BC, Canada.
C3 University of Missouri System; University of Missouri Columbia; Indiana
   University System; Indiana University Bloomington; University of British
   Columbia
RP Byrne, MF (通讯作者)，Univ British Columbia, Vancouver Gen Hosp, 5153-2775 Laurel St, Vancouver, BC, Canada.
EM michael.byrne@vch.ca
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Bae JH, 2019, CLIN GASTROENTEROL H, V17, P2479, DOI 10.1016/j.cgh.2019.02.019
   Bisschops R, 2018, ENDOSCOPY, V50, P211, DOI 10.1055/s-0043-121570
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dube R., 2019, CURR TREAT OPTIONS G, V31, P363
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Guizard N, 2019, GASTROENTEROLOGY, V156, pS48
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Iwatate M, 2018, DIGEST ENDOSC, V30, P642, DOI 10.1111/den.13065
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Ponugoti P, 2019, ENDOSCOPY, V51, P221, DOI 10.1055/a-0831-2348
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Singh R, 2013, DIGEST ENDOSC, V25, P16, DOI 10.1111/den.12075
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Vleugels JLA, 2018, GASTROENTEROLOGY, V154, P1682, DOI 10.1053/j.gastro.2018.01.063
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yang, 2020, SCI REP-UK, V10, P1
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
NR 34
TC 0
Z9 0
U1 1
U2 2
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1521-6918
EI 1532-1916
J9 BEST PRACT RES CL GA
JI Best Pract. Res. Clin. Gastroenterol.
PD JUN-AUG
PY 2021
VL 52-53
AR 101736
DI 10.1016/j.bpg.2021.101736
EA JUN 2021
PG 5
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA SX0UM
UT WOS:000664928200012
PM 34172255
DA 2023-08-21
ER

PT J
AU Sinonquel, P
   Bisschops, R
AF Sinonquel, P.
   Bisschops, R.
TI Striving for quality improvement: can artificial intelligence help?
SO BEST PRACTICE & RESEARCH CLINICAL GASTROENTEROLOGY
LA English
DT Article
DE Artificial intelligence; Computer-aided diagnosis; Computer-aided
   detection; Quality; Upper and lower gastrointestinal tract
ID HELICOBACTER-PYLORI INFECTION; COMPUTER-AIDED DETECTION; UPPER
   GASTROINTESTINAL ENDOSCOPY; CONVOLUTIONAL NEURAL-NETWORKS; CAPSULE
   ENDOSCOPY; ADENOMA DETECTION; PERFORMANCE-MEASURES; 3D RECONSTRUCTION;
   EUROPEAN-SOCIETY; DETECTION SYSTEM
AB Artificial intelligence (AI) is of keen interest for global health development as potential support for current human shortcomings. Gastrointestinal (GI) endoscopy is an excellent substrate for AI, since it holds the genuine potential to improve quality in GI endoscopy and overall patient care by improving detection and diagnosis guiding the endoscopists in performing endoscopy to the highest quality standards. The possibility of large data acquisitioning to refine algorithms makes implementation of AI into daily practice a potential reality. With the start of a new era adopting deep learning, large amounts of data can easily be processed, resulting in better diagnostic performances. In the upper gastrointestinal tract, research currently focusses on the detection and characterization of neoplasia, including Barrett's, squamous cell and gastric carcinoma, with an increasing amount of AI studies demonstrating the potential and benefit of AIeaugmented endoscopy. Deep learning applied to small bowel video capsule endoscopy also appears to enhance pathology detection and reduce capsule reading time. In the colon, multiple prospective trials including five randomized trials, showed a consistent improvement in polyp and adenoma detection rates, one of the main quality indicators in endoscopy. There are however potential additional roles for AI to assist in quality improvement of endoscopic procedures, training and therapeutic decision making. Further large-scale, multicenter validation trials are required before AI eaugmented diagnostic gastrointestinal endoscopy can be integrated into our routine clinical practice. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Sinonquel, P.; Bisschops, R.] Univ Hosp Leuven, Dept Gastroenterol & Hepatol, Herestr 49, B-3000 Leuven, Belgium.
   [Sinonquel, P.; Bisschops, R.] Katholieke Univ Leuven, Dept Translat Res Gastrointestinal Dis TARGID, Herestr 49, B-3000 Leuven, Belgium.
C3 1EUROPE; KU Leuven; University Hospital Leuven; 1EUROPE; KU Leuven
RP Bisschops, R (通讯作者)，Univ Hosp Leuven, Dept Gastroenterol & Hepatol, Herestr 49, B-3000 Leuven, Belgium.
EM pieter.sinonquel@uzleuven.be; raf.bisschops@uzleuven.be
OI Sinonquel, Pieter/0000-0001-7750-5064; Bisschops,
   Raf/0000-0002-9994-8226
FU Research Foundation Flanders
FX RB/PS are both supported by a grant of Research Foundation Flanders.
CR Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Arribas J, 2021, GUT, V70, P1458, DOI 10.1136/gutjnl-2020-321922
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bisschops R, 2016, ENDOSCOPY, V48, P843, DOI 10.1055/s-0042-113128
   Bossuyt P, 2021, GASTROENTEROLOGY, V160, P23, DOI 10.1053/j.gastro.2020.09.053
   Bossuyt P, 2020, GUT, V69, P1778, DOI 10.1136/gutjnl-2019-320056
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Cao Y, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P2839
   Charisis VS, 2016, WORLD J GASTROENTERO, V22, P8641, DOI 10.3748/wjg.v22.i39.8641
   Chen D, 2020, GASTROINTEST ENDOSC, V91, P332, DOI 10.1016/j.gie.2019.09.016
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   CHO C, 1993, COMPUT MED IMAG GRAP, V17, P301, DOI 10.1016/0895-6111(93)90021-E
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   De Silva AP, 2009, J GASTROEN HEPATOL, V24, P1095, DOI 10.1111/j.1440-1746.2009.05782.x
   Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gulati S, 2020, THER ADV GASTROINTES, V13, DOI 10.1177/2631774520935220
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   Gupta N, 2012, GASTROINTEST ENDOSC, V76, P531, DOI 10.1016/j.gie.2012.04.470
   Hassan C, 2020, ENDOSC INT OPEN, V08, pE1387, DOI 10.1055/a-1214-5937
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kaminski MF, 2017, UNITED EUR GASTROENT, V5, P309, DOI 10.1177/2050640617700014
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Koeppe AT, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-158
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Lee TJW, 2013, ENDOSCOPY, V45, P20, DOI 10.1055/s-0032-1325803
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Maeda Y, 2020, DIGEST ENDOSC, V32, P1082, DOI 10.1111/den.13655
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Misawa M, 2019, GASTROINTEST ENDOSC, V89, pAB646, DOI 10.1016/j.gie.2019.03.1134
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Miyaki R, 2013, J GASTROEN HEPATOL, V28, P841, DOI 10.1111/jgh.12149
   Mohammadian Taher, 2019, Monoclonal Antibodies in Immunodiagnosis and Immunotherapy, V38, P1, DOI 10.1089/mab.2018.0032
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Namikawa K, 2020, ENDOSCOPY, V52, P1077, DOI 10.1055/a-1194-8771
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Qi X, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2337314
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rombaoa C, 2019, GASTROINTEST ENDOSC, V89, pAB619, DOI 10.1016/j.gie.2019.03.1076
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Saurin JC, 2012, DIGEST LIVER DIS, V44, P477, DOI 10.1016/j.dld.2011.12.021
   Scholvinck DW, 2017, ENDOSCOPY, V49, P113, DOI 10.1055/s-0042-118312
   Sehgal V, 2018, GASTROENT RES PRACT, V2018, DOI 10.1155/2018/1872437
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin D, 2016, GASTROINTEST ENDOSC, V83, P107, DOI 10.1016/j.gie.2015.06.045
   Simmons DT, 2006, ALIMENT PHARM THERAP, V24, P965, DOI 10.1111/j.1365-2036.2006.03080.x
   Sinonquel P, 2020, GUT, P1, DOI [10.1136/gutjnl-2020-322491.0, DOI 10.1136/GUTJNL-2020-322491.0]
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Suykens J, 2020, SA2012 AUTOMATED POL
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Takenaka K, 2020, GASTROENTEROLOGY, V158, P2150, DOI 10.1053/j.gastro.2020.02.012
   Tokai Y, 2020, ESOPHAGUS-TOKYO, V17, P250, DOI 10.1007/s10388-020-00716-x
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Valori R, 2019, UNITED EUR GASTROENT, V7, P21, DOI 10.1177/2050640618810242
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Widya AR, 2019, IEEE ENG MED BIO, P3900, DOI 10.1109/EMBC.2019.8857964
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Xia J, 2021, GASTROINTEST ENDOSC, V93, P133, DOI 10.1016/j.gie.2020.05.027
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P43, DOI 10.1080/17474124.2017.1257384
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zheng WF, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000109
   Zhou J, 2020, GASTROINTEST ENDOSC, V91, P428, DOI 10.1016/j.gie.2019.11.026
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 94
TC 2
Z9 3
U1 0
U2 4
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1521-6918
EI 1532-1916
J9 BEST PRACT RES CL GA
JI Best Pract. Res. Clin. Gastroenterol.
PD JUN-AUG
PY 2021
VL 52-53
AR 101722
DI 10.1016/j.bpg.2020.101722
EA JUN 2021
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA SX0UM
UT WOS:000664928200009
PM 34172249
DA 2023-08-21
ER

PT J
AU Tontini, GE
   Neumann, H
AF Tontini, Gian Eugenio
   Neumann, Helmut
TI Artificial intelligence: Thinking outside the box
SO BEST PRACTICE & RESEARCH CLINICAL GASTROENTEROLOGY
LA English
DT Article
DE AI; Artificial intelligence; Learning; Advanced imaging
ID COMPUTER-AIDED DETECTION; ENDOSCOPIC SCORING SYSTEMS;
   BARRETTS-ESOPHAGUS; CAPSULE ENDOSCOPY; LASER ENDOMICROSCOPY;
   ULCERATIVE-COLITIS; MISS RATE; SURVEILLANCE; COLONOSCOPY; DIAGNOSIS
AB Artificial intelligence (AI) for luminal gastrointestinal endoscopy is rapidly evolving. To date, most ap-plications have focused on colon polyp detection and characterization. However, the potential of AI to revolutionize our current practice in endoscopy is much more broadly positioned. In this review article, the Authors provide new ideas on how AI might help endoscopists in the future to rediscover endoscopy practice. (c) 2020 Published by Elsevier Ltd.
C1 [Tontini, Gian Eugenio] Fdn IRCCS Ca Granda Osped Maggiore Policlin, Gastroenterol & Endoscopy Unit, Milan, Italy.
   [Tontini, Gian Eugenio] Univ Milan, Dept Pathophysiol & Transplantat, Milan, Italy.
   [Neumann, Helmut] Univ Hosp Mainz, Dept Interdisciplinary Endoscopy, D-55131 Mainz, Germany.
C3 IRCCS Ca Granda Ospedale Maggiore Policlinico; University of Milan;
   University Hospital Mainz
RP Neumann, H (通讯作者)，Univ Hosp Mainz, Dept Interdisciplinary Endoscopy, D-55131 Mainz, Germany.
EM Helmut.Neumann@unimedizin-mainz.de
RI tontini, gian eugenio/J-9841-2018
OI tontini, gian eugenio/0000-0002-8964-5686
CR Abrams JA, 2009, CLIN GASTROENTEROL H, V7, P736, DOI 10.1016/j.cgh.2008.12.027
   Aoki T, 2020, DIGEST ENDOSC, V32, P585, DOI 10.1111/den.13517
   Bisschops R, 2019, ENDOSCOPY, V51, P976, DOI 10.1055/a-1000-5603
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Bondesson D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232847
   Bossuyt P, 2020, GUT, V69, P1778, DOI 10.1136/gutjnl-2019-320056
   Burgess NG, 2017, GUT, V66, P1779, DOI 10.1136/gutjnl-2015-309848
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Canakis A, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820941662
   Rodriguez MAC, 2019, ENDOSC INT OPEN, V7, pE1078, DOI 10.1055/a-0965-6487
   Codipilly DC, 2018, GASTROENTEROLOGY, V154, P2068, DOI 10.1053/j.gastro.2018.02.022
   Daperno M, 2017, J CROHNS COLITIS, V11, P556, DOI 10.1093/ecco-jcc/jjw181
   de Groof AJ, 2020, GASTROINTEST ENDOSC, V91, P1242, DOI 10.1016/j.gie.2019.12.048
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   Fard MJ, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1850
   Ghaus S, 2016, DIGEST DIS SCI, V61, P2185, DOI 10.1007/s10620-016-4138-x
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gruner M, 2021, ENDOSCOPY, V53, P674, DOI 10.1055/a-1224-6822
   Hur C, 2013, CANCER-AM CANCER SOC, V119, P1149, DOI 10.1002/cncr.27834
   Iacucci M, 2019, LANCET GASTROENTEROL, V4, P971, DOI 10.1016/S2468-1253(19)30194-3
   Ishaq S, 2017, DIGEST LIVER DIS, V49, P721, DOI 10.1016/j.dld.2017.03.030
   Jin P, 2020, J CANCER RES CLIN, V146, P2339, DOI 10.1007/s00432-020-03304-9
   Kastelein F, 2016, GUT, V65, P548, DOI 10.1136/gutjnl-2014-308802
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P821, DOI 10.1016/j.gie.2020.06.034
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Morris EJA, 2015, GUT, V64, P1248, DOI 10.1136/gutjnl-2014-308362
   Nagao S, 2020, GASTROINTEST ENDOSC
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Queneherve L, 2019, GASTROINTEST ENDOSC, V89, P626, DOI 10.1016/j.gie.2018.08.006
   Qumseya B, 2019, GASTROINTEST ENDOSC, V90, P335, DOI 10.1016/j.gie.2019.05.012
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Roumans CAM, 2020, ENDOSCOPY, V52, P17, DOI 10.1055/a-0995-0134
   Scholvinck DW, 2017, ENDOSCOPY, V49, P113, DOI 10.1055/s-0042-118312
   Sinonquel P, 2021, DIGEST ENDOSC, V33, P242, DOI 10.1111/den.13888
   Soffer S, 2020, GASTROINTEST ENDOSC
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Takenaka K, 2020, GASTROENTEROLOGY, V158, P2150, DOI 10.1053/j.gastro.2020.02.012
   Taunk P, 2019, INT J COLORECTAL DIS, V34, P2043, DOI 10.1007/s00384-019-03406-y
   Thosani N, 2016, GASTROINTEST ENDOSC, V83, P684, DOI 10.1016/j.gie.2016.01.007
   Tokai Y, 2020, ESOPHAGUS-TOKYO, V17, P250, DOI 10.1007/s10388-020-00716-x
   Tontini GE, 2019, DIGEST ENDOSC, V31, P627, DOI 10.1111/den.13429
   Tontini GE, 2018, GASTROINTEST ENDOSC, V87, P1505, DOI 10.1016/j.gie.2017.10.033
   Tontini GE, 2017, EXPERT REV GASTROENT, V11, P427, DOI 10.1080/17474124.2017.1297705
   Tontini GE, 2015, ENDOSCOPY, V47, P437, DOI 10.1055/s-0034-1391226
   Tontini GE, 2014, EXPERT REV GASTROENT, V8, P543, DOI 10.1586/17474124.2014.899899
   Trindade AJ, 2019, GASTROENTEROLOGY, V157, P303, DOI 10.1053/j.gastro.2019.04.048
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vasilakakis M, 2019, EXPERT REV GASTROENT, V13, P129, DOI 10.1080/17474124.2019.1553616
   Verbeek RE, 2014, AM J GASTROENTEROL, V109, P1215, DOI 10.1038/ajg.2014.156
   Visrodia K, 2016, GASTROENTEROLOGY, V150, P599, DOI 10.1053/j.gastro.2015.11.040
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Yasuda T, 2020, DIGEST ENDOSC, V32, P373, DOI 10.1111/den.13509
   Zhang YQ, 2020, DIGEST LIVER DIS, V52, P566, DOI 10.1016/j.dld.2019.12.146
   Zheng WF, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000109
NR 64
TC 4
Z9 4
U1 2
U2 17
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1521-6918
EI 1532-1916
J9 BEST PRACT RES CL GA
JI Best Pract. Res. Clin. Gastroenterol.
PD JUN-AUG
PY 2021
VL 52-53
AR 101720
DI 10.1016/j.bpg.2020.101720
EA JUN 2021
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA SX0UM
UT WOS:000664928200001
PM 34172247
DA 2023-08-21
ER

PT J
AU Okagawa, Y
   Abe, S
   Yamada, M
   Oda, I
   Saito, Y
AF Okagawa, Yutaka
   Abe, Seiichiro
   Yamada, Masayoshi
   Oda, Ichiro
   Saito, Yutaka
TI Artificial Intelligence in Endoscopy
SO DIGESTIVE DISEASES AND SCIENCES
LA English
DT Review
DE Artificial intelligence; Computer-assisted diagnosis; Endoscopy;
   Detection; Classification; Deep learning
ID COMPUTER-AIDED DIAGNOSIS; HELICOBACTER-PYLORI INFECTION; CONVOLUTIONAL
   NEURAL-NETWORK; DEEP-LEARNING ALGORITHM; INVASIVE COLORECTAL-CANCER;
   BOWEL CAPSULE ENDOSCOPY; SQUAMOUS-CELL CARCINOMA; REAL-TIME DETECTION;
   GASTRIC-CANCER; BARRETTS-ESOPHAGUS
AB Artificial intelligence (AI) is rapidly developing in various medical fields, and there is an increase in research performed in the field of gastrointestinal (GI) endoscopy. In particular, the advent of convolutional neural network, which is a class of deep learning method, has the potential to revolutionize the field of GI endoscopy, including esophagogastroduodenoscopy (EGD), capsule endoscopy (CE), and colonoscopy. A total of 149 original articles pertaining to AI (27 articles in esophagus, 30 articles in stomach, 29 articles in CE, and 63 articles in colon) were identified in this review. The main focuses of AI in EGD are cancer detection, identifying the depth of cancer invasion, prediction of pathological diagnosis, and prediction of Helicobacter pylori infection. In the field of CE, automated detection of bleeding sites, ulcers, tumors, and various small bowel diseases is being investigated. AI in colonoscopy has advanced with several patient-based prospective studies being conducted on the automated detection and classification of colon polyps. Furthermore, research on inflammatory bowel disease has also been recently reported. Most studies of AI in the field of GI endoscopy are still in the preclinical stages because of the retrospective design using still images. Video-based prospective studies are needed to advance the field. However, AI will continue to develop and be used in daily clinical practice in the near future. In this review, we have highlighted the published literature along with providing current status and insights into the future of AI in GI endoscopy.
C1 [Okagawa, Yutaka; Abe, Seiichiro; Yamada, Masayoshi; Oda, Ichiro; Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.
   [Okagawa, Yutaka] Tonan Hosp, Dept Gastroenterol, Sapporo, Hokkaido, Japan.
C3 National Cancer Center - Japan
RP Abe, S (通讯作者)，Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.
EM seabe@ncc.go.jp
RI Okagawa, Yutaka/AEG-8368-2022; Abe, Seiichiro/AAC-3685-2020
CR Abrams JA, 2009, CLIN GASTROENTEROL H, V7, P736, DOI 10.1016/j.cgh.2008.12.027
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   An P, 2020, GASTRIC CANCER, V23, P884, DOI 10.1007/s10120-020-01071-7
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Aoki T, 2020, DIGEST ENDOSC, V32, P585, DOI 10.1111/den.13517
   Aoki T, 2021, GASTROINTEST ENDOSC, V93, P165, DOI 10.1016/j.gie.2020.04.080
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Becq A, 2017, GASTROINTEST ENDOSC, V86, P792, DOI 10.1016/j.gie.2017.05.018
   Bibault JE, 2016, CANCER LETT, V382, P110, DOI 10.1016/j.canlet.2016.05.033
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bossuyt P, 2020, GUT, V69, P1778, DOI 10.1136/gutjnl-2019-320056
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Brenner H, 2011, ANN INTERN MED, V154, P22, DOI 10.7326/0003-4819-154-1-201101040-00004
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Charisis VS, 2016, WORLD J GASTROENTERO, V22, P8641, DOI 10.3748/wjg.v22.i39.8641
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cho BJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061858
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   Ciaccio EJ, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-44
   Constantinescu AF, 2016, ROM J MORPHOL EMBRYO, V57, P979
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Groof AJ, 2020, GASTROINTEST ENDOSC, V91, P1242, DOI 10.1016/j.gie.2019.12.048
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   de Groof J, 2019, UNITED EUR GASTROENT, V7, P538, DOI 10.1177/2050640619837443
   Dent J, 2011, J GASTROEN HEPATOL, V26, P11, DOI 10.1111/j.1440-1746.2010.06535.x
   Dinevari VF, 2016, APPL BIONICS BIOMECH, V2016, DOI 10.1155/2016/3678913
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Dokoutsidou H, 2011, EUR J GASTROEN HEPAT, V23, P166, DOI 10.1097/MEG.0b013e3283433abf
   EBIGBO A, 2020, ENDOSCOPY
   Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Everson M, 2019, UNITED EUR GASTROENT, V7, P297, DOI 10.1177/2050640618821800
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Fukuda H, 2020, GASTROINTEST ENDOSC, V92, P848, DOI 10.1016/j.gie.2020.05.043
   Gao JB, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/8374317
   Ghatwary N, 2019, INT J COMPUT ASS RAD, V14, P611, DOI 10.1007/s11548-019-01914-4
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   Hashimoto R, 2020, GASTROINTEST ENDOSC, V91, P1264, DOI 10.1016/j.gie.2019.12.049
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hong JS, 2017, IEEE ENG MED BIO, P2892, DOI 10.1109/EMBC.2017.8037461
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Horiuchi Y, 2020, DIGEST DIS SCI, V65, P1355, DOI 10.1007/s10620-019-05862-6
   Horiuchi Y, 2020, GASTROINTEST ENDOSC, V92, P856, DOI 10.1016/j.gie.2020.04.079
   Hwang Y, 2021, DIGEST ENDOSC, V33, P598, DOI 10.1111/den.13787
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Ishihara R, 2010, DIS ESOPHAGUS, V23, P480, DOI 10.1111/j.1442-2050.2009.01039.x
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Iwagami H, 2021, J GASTROEN HEPATOL, V36, P131, DOI 10.1111/jgh.15136
   *JAP GASTR CANC AS, 2020, JAPANESE GASTRIC CAN
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kaji K, 2019, AM J GASTROENTEROL, V114, P71, DOI 10.1038/s41395-018-0259-5
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Katai H, 2018, GASTRIC CANCER, V21, P144, DOI 10.1007/s10120-017-0716-7
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kodashima S, 2018, DIGEST ENDOSC, V30, P20, DOI 10.1111/den.12963
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Lee JH, 2019, SURG ENDOSC, V33, P3790, DOI 10.1007/s00464-019-06677-2
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li BP, 2015, MED PHYS, V42, P645, DOI 10.1118/1.4905164
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Li TB, 2020, ENDOSC INT OPEN, V08, pE1448, DOI 10.1055/a-1229-3927
   Ling TS, 2021, ENDOSCOPY, V53, P469, DOI 10.1055/a-1229-0920
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   Liu GS, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.03.24
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2021, GASTROINTEST ENDOSC, V93, P193, DOI 10.1016/j.gie.2020.04.066
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Luo HY, 2019, LANCET ONCOL, V20, P1645, DOI 10.1016/S1470-2045(19)30637-0
   Luo YC, 2021, J GASTROINTEST SURG, V25, P2011, DOI 10.1007/s11605-020-04802-4
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Misawa M, 2021, DIGEST ENDOSC, V33, P273, DOI 10.1111/den.13847
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Miyaki R, 2013, J GASTROEN HEPATOL, V28, P841, DOI 10.1111/jgh.12149
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Muto M, 2010, J CLIN ONCOL, V28, P1566, DOI 10.1200/JCO.2009.25.4680
   Nagao S, 2020, GASTROINTEST ENDOSC, V92, P866, DOI 10.1016/j.gie.2020.06.047
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Nakajima Y, 2020, ENDOSC INT OPEN, V08, pE1341, DOI 10.1055/a-1220-6596
   Nakashima H, 2020, GASTRIC CANCER, V23, P1033, DOI 10.1007/s10120-020-01077-1
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Namikawa K, 2020, ENDOSCOPY, V52, P1077, DOI 10.1055/a-1194-8771
   Niikura R, 2021, J GASTROEN HEPATOL, V36, P112, DOI 10.1111/jgh.15110
   Niv Y, 2005, DIGEST DIS SCI, V50, P2121, DOI 10.1007/s10620-005-3017-7
   Nomura S, 2013, DIGEST ENDOSC, V25, P136, DOI 10.1111/j.1443-1661.2012.01357.x
   Ohmori M, 2020, GASTROINTEST ENDOSC, V91, P301, DOI 10.1016/j.gie.2019.09.034
   Otani K, 2020, ENDOSCOPY, V52, P786, DOI 10.1055/a-1167-8157
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Park J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241474
   Pennazio M, 2015, ENDOSCOPY, V47, P352, DOI 10.1055/s-0034-1391855
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   Queneherve L, 2019, GASTROINTEST ENDOSC, V89, P626, DOI 10.1016/j.gie.2018.08.006
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rodriguez-Diaz E, 2021, GASTROINTEST ENDOSC, V93, P662, DOI 10.1016/j.gie.2020.09.018
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Sakai Y, 2018, IEEE ENG MED BIO, P4138, DOI 10.1109/EMBC.2018.8513274
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sano T, 2017, GASTRIC CANCER, V20, P217, DOI 10.1007/s10120-016-0601-9
   Sehgal V, 2018, GASTROENT RES PRACT, V2018, DOI 10.1155/2018/1872437
   Sharma P, 2013, GUT, V62, P15, DOI 10.1136/gutjnl-2011-300962
   Shichijo S, 2019, SCAND J GASTROENTERO, V54, P158, DOI 10.1080/00365521.2019.1577486
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shimamoto Y, 2020, J GASTROENTEROL, V55, P1037, DOI 10.1007/s00535-020-01716-5
   Shimizu Y, 2008, J GASTROEN HEPATOL, V23, P546, DOI 10.1111/j.1440-1746.2007.04990.x
   Shin D, 2015, CLIN GASTROENTEROL H, V13, P272, DOI 10.1016/j.cgh.2014.07.030
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Stidham RW, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3963
   SUGIMACHI K, 1989, SURGERY, V105, P706
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Takenaka K, 2020, GASTROENTEROLOGY, V158, P2150, DOI 10.1053/j.gastro.2020.02.012
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tang DH, 2020, EBIOMEDICINE, V62, DOI 10.1016/j.ebiom.2020.103146
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Tokai Y, 2020, ESOPHAGUS-TOKYO, V17, P250, DOI 10.1007/s10388-020-00716-x
   Tokunaga M, 2021, GASTROINTEST ENDOSC, V93, P647, DOI 10.1016/j.gie.2020.07.053
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   Ueyama H, 2021, J GASTROEN HEPATOL, V36, P482, DOI 10.1111/jgh.15190
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   van der Zander QEW, 2021, ENDOSCOPY, V53, P1219, DOI 10.1055/a-1343-1597
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang DD, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242535
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang S, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/7546215
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Xu L, 2020, SCAND J GASTROENTERO, V55, P376, DOI 10.1080/00365521.2020.1736618
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yang XX, 2021, DIGEST ENDOSC, V33, P1075, DOI 10.1111/den.13908
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Yoon HJ, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091310
   Yoshida H, 2018, GASTRIC CANCER, V21, P249, DOI 10.1007/s10120-017-0731-8
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   ZHANG Q, 2015, MEDICINE, V94
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zheng WF, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000109
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 186
TC 19
Z9 20
U1 4
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0163-2116
EI 1573-2568
J9 DIGEST DIS SCI
JI Dig. Dis. Sci.
PD MAY
PY 2022
VL 67
IS 5
SI SI
BP 1553
EP 1572
DI 10.1007/s10620-021-07086-z
EA JUN 2021
PG 20
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 1N7UO
UT WOS:000663993400002
PM 34155567
DA 2023-08-21
ER

PT J
AU Yoon, J
   Joseph, J
   Waterhouse, DJ
   Borzy, C
   Siemens, K
   Diamond, S
   Tsikitis, VL
   Bohndiek, SE
AF Yoon, Jonghee
   Joseph, James
   Waterhouse, Dale J.
   Borzy, Charlie
   Siemens, Kyla
   Diamond, Sarah
   Tsikitis, Vassiliki Liana
   Bohndiek, Sarah E.
TI First experience in clinical application of hyperspectral endoscopy for
   evaluation of colonic polyps
SO JOURNAL OF BIOPHOTONICS
LA English
DT Article
DE colonoscopy; hyperspectral endoscope; hyperspectral imaging; machine
   learning
ID COLORECTAL-CANCER; SPECTROSCOPY
AB Early detection and resection of adenomatous polyps prevents their progression to colorectal cancer (CRC), significantly improving patient outcomes. Polyps are typically identified and removed during white-light colonoscopy. Unfortunately, the rate of interval cancers that arise between CRC screening events remains high, linked to poor visualization of polyps during screening and incomplete polyp removal. Here, we sought to evaluate the potential of a hyperspectral endoscope (HySE) to enhance polyp discrimination for detection and resection. We designed, built and tested a new compact HySE in a proof-of-concept clinical study. We successfully collected spectra from three tissue types in seven patients undergoing routine colonoscopy screening. The acquired spectral data from normal tissue and polyps, both pre- and post- resection, were subjected to quantitative analysis using spectral angle mapping and machine learning, which discriminated the data by tissue type, meriting further investigation of HySE as a clinical tool.
C1 [Yoon, Jonghee; Joseph, James; Waterhouse, Dale J.; Bohndiek, Sarah E.] Univ Cambridge, Dept Phys, JJ Thomson Ave, Cambridge CB3 0HE, England.
   [Yoon, Jonghee; Joseph, James; Waterhouse, Dale J.; Bohndiek, Sarah E.] Univ Cambridge, Canc Res UK Cambridge Inst, Cambridge, England.
   [Joseph, James] Univ Dundee, Sch Sci & Engn, Fulton Bldg, Dundee, Scotland.
   [Borzy, Charlie; Siemens, Kyla; Tsikitis, Vassiliki Liana] Oregon Hlth & Sci Univ, Dept Surg, Portland, OR 97239 USA.
   [Diamond, Sarah] Oregon Hlth & Sci Univ, Dept Med, Portland, OR 97239 USA.
   [Yoon, Jonghee] Ajou Univ, Dept Phys, Suwon, South Korea.
C3 University of Cambridge; Cancer Research UK; CRUK Cambridge Institute;
   University of Cambridge; University of Dundee; Oregon Health & Science
   University; Oregon Health & Science University; Ajou University
RP Bohndiek, SE (通讯作者)，Univ Cambridge, Dept Phys, JJ Thomson Ave, Cambridge CB3 0HE, England.; Tsikitis, VL (通讯作者)，Oregon Hlth & Sci Univ, Dept Surg, Portland, OR 97239 USA.
EM tsikitis@ohsu.edu; seb53@cam.ac.uk
RI Bohndiek, Sarah/S-9416-2019; Waterhouse, Dale/AAJ-8913-2021; Joseph,
   James/J-9149-2014
OI Bohndiek, Sarah/0000-0003-0371-8635; Waterhouse,
   Dale/0000-0001-5530-6857; Yoon, Jonghee/0000-0003-3886-2792; Joseph,
   James/0000-0001-6270-2559
FU Cancer Research UK [C14303/A17197, C47594/A16267, C47594/A21102,
   C47594/A26851, C55962/A24669, C9545/A29580]; Engineering and Physical
   Sciences Research Council [EP/N014588/1, EP/R003599/1]; EPSRC
   [EP/R003599/1, EP/N014588/1] Funding Source: UKRI
FX Cancer Research UK, Grant/Award Numbers: C14303/A17197, C47594/A16267,
   C47594/A21102, C47594/A26851, C55962/A24669, C9545/A29580; Engineering
   and Physical Sciences Research Council, Grant/Award Numbers:
   EP/N014588/1, EP/R003599/1
CR Bohndiek S.E, 2020, SCI REP-UK, V10, P1
   Clancy NT, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101699
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Glover B, 2020, CLIN TRANSL GASTROEN, V11, DOI 10.14309/ctg.0000000000000130
   HAN ZM, 2016, J BIOMED OPT, V21, DOI DOI 10.1117/1.JBO.21.1.016001
   Hsiung PL, 2008, NAT MED, V14, P454, DOI 10.1038/nm1692
   Kumashiro R, 2016, ANTICANCER RES, V36, P3925
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901
   Martinez ME, 2009, GASTROENTEROLOGY, V136, P832, DOI 10.1053/j.gastro.2008.12.007
   Molckovsky A, 2003, GASTROINTEST ENDOSC, V57, P396, DOI 10.1067/mge.2003.105
   Park SK, 2016, GASTROINTEST ENDOSC, V83, P527, DOI 10.1016/j.gie.2015.08.053
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   Rivenson Y, 2019, NAT BIOMED ENG, V3, P466, DOI 10.1038/s41551-019-0362-y
   Sanduleanu S, 2015, GUT, V64, P1257, DOI 10.1136/gutjnl-2014-307992
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI [10.3322/caac.21220, 10.3322/caac.21208, 10.3322/caac.21395]
   Yoon J., 2019, NAT COMMUN, V10, P1
   Zonios G, 1999, APPL OPTICS, V38, P6628, DOI 10.1364/AO.38.006628
NR 18
TC 6
Z9 6
U1 0
U2 5
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 1864-063X
EI 1864-0648
J9 J BIOPHOTONICS
JI J. Biophotonics
PD SEP
PY 2021
VL 14
IS 9
AR e202100078
DI 10.1002/jbio.202100078
EA JUN 2021
PG 9
WC Biochemical Research Methods; Biophysics; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biophysics; Optics
GA UQ9TH
UT WOS:000663954500001
PM 34047490
OA hybrid, Green Submitted, Green Published
DA 2023-08-21
ER

PT J
AU Girdler, B
   Moon, H
   Bae, MR
   Ryu, SS
   Bae, J
   Yu, MS
AF Girdler, Benton
   Moon, Hyun
   Bae, Mi Rye
   Ryu, Sung Seok
   Bae, Jihye
   Yu, Myeong Sang
TI Feasibility of a deep learning-based algorithm for automated detection
   and classification of nasal polyps and inverted papillomas on nasal
   endoscopic images
SO INTERNATIONAL FORUM OF ALLERGY & RHINOLOGY
LA English
DT Article
DE artificial intelligence; clinical visual assessment; convolutional
   neural network; deep learning; inverted papilloma; nasal endoscopy;
   nasal polyp
ID SINONASAL; DISEASE
AB Background Discrimination of nasal cavity mass lesions is a challenging work requiring extensive experience. A deep learning-based automated diagnostic system may help clinicians to classify nasal cavity mass lesions. We demonstrated the feasibility of a convolutional neural network (CNN)-based diagnosis system for automatic detection and classification of nasal polyps (NP) and inverted papillomas (IP). Methods We developed a CNN-based algorithm using a transfer learning strategy and trained it on nasal endoscopic images. A total of 99 nasal endoscopic images with normal findings, 98 images with NP, and 100 images with IP were analyzed using the developed CNN. Six otolaryngologists participated in clinical visual assessment. Image-based classification performance was measured by calculating the accuracy and area under the receiver operating characteristic curve (AUC). The diagnostic performance was compared between the CNN and clinical visual assessment by human experts. Results The algorithm achieved an overall accuracy of 0.742 +/- 0.058 with the following class accuracies: normal, 0.81 +/- 0.14; IP, 0.57 +/- 0.07; and NP, 0.83 +/- 0.21. The AUC values for normal, IP, and NP were 0.91 +/- 0.06, 0.82 +/- 0.09, and 0.84 +/- 0.06, respectively. The overall accuracy of the CNN model was comparable with the average performance of human experts (0.742 vs. 0.749; p = 0.11). Conclusions The trained CNN model appears to reliably classify NP and IP of the nasal cavity from nasal endoscopic images; it also yields a reliable reference for diagnosing nasal cavity mass lesions during nasal endoscopy. However, further studies with more test data are warranted to improve the diagnostic accuracy of our CNN model.
C1 [Girdler, Benton; Bae, Jihye] Univ Kentucky, Dept Elect & Comp Engn, 512 Adm Dr 467C,Paul F Anderson Tower, Lexington, KY 40506 USA.
   [Moon, Hyun] Univ Ulsan, Coll Med, Dept Otolaryngol, Gangneung Asan Hosp, Kangnung, South Korea.
   [Bae, Mi Rye] Bundang Jesaeng Gen Hosp, Dept Otolaryngol Head & Neck Surg, Seongnam, South Korea.
   [Ryu, Sung Seok; Yu, Myeong Sang] Univ Ulsan, Coll Med, Dept Otorhinolaryngol Head & Neck Surg, Asan Med Ctr, Seoul, South Korea.
C3 University of Kentucky; University of Ulsan; University of Ulsan
RP Bae, J (通讯作者)，Univ Kentucky, Dept Elect & Comp Engn, 512 Adm Dr 467C,Paul F Anderson Tower, Lexington, KY 40506 USA.; Yu, MS (通讯作者)，Univ Ulsan, Coll Med, Dept Otolaryngol, Asan Med Ctr, 88,Olymp Ro 43 Gil, Seoul 05505, South Korea.
EM jihye.bae@uky.edu; dryums@gmail.com
OI lyu, seongseog/0000-0001-5861-7386
FU Department of Electrical and Computer Engineering at the University of
   Kentucky
FX This project is partially supported by Dr. J. Bae's Start Up fund from
   the Department of Electrical and Computer Engineering at the University
   of Kentucky.
CR Agarwal P, 2017, INDIA J SURG ONCOL, V8, P123, DOI 10.1007/s13193-016-0570-9
   Anari S, 2010, J LARYNGOL OTOL, V124, P705, DOI 10.1017/S0022215110000599
   [Anonymous], 2015, P MIC 2015 11 METAHE
   Bachert C, 2015, J ALLERGY CLIN IMMUN, V136, P1431, DOI 10.1016/j.jaci.2015.10.010
   Bengio S., 2019, ARXIV190207208
   Brock A., 2021, ARXIV210206171
   Canziani A, 2016, ANAL DEEP NEURAL NET
   Cheng CT, 2019, EUR RADIOL, V29, P5469, DOI 10.1007/s00330-019-06167-y
   Chowdhury NI., 2019, INT FORUM ALLERGY RH
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du WJ, 2019, IEEE ACCESS, V7, P142053, DOI 10.1109/ACCESS.2019.2944676
   Geirhos R., 2017, COMP DEEP NEURAL NET
   Hameed N., 2018, 10 COMP SCI EL ENG C
   Harvey RJ, 2009, OTOLARYNG CLIN N AM, V42, P353, DOI 10.1016/j.otc.2009.01.006
   Hedman J, 1999, INT J EPIDEMIOL, V28, P717, DOI 10.1093/ije/28.4.717
   Huang J, 2020, J LARYNGOL OTOL, V134, P52, DOI 10.1017/S0022215119002536
   Humphries S.M., 2020, INT FORUM ALLERGY RH
   Jiang J, 2010, COMPUT MED IMAG GRAP, V34, P617, DOI 10.1016/j.compmedimag.2010.07.003
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Lisan Q, 2016, EUR ANN OTORHINOLARY, V133, P337, DOI 10.1016/j.anorl.2016.03.006
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Mascharak S, 2018, LARYNGOSCOPE, V128, P2514, DOI 10.1002/lary.27159
   McNeely-White DG., 2019, BIOLOGICALLY INSPIRE, P352
   Newton Jonathan Ray, 2008, Ther Clin Risk Manag, V4, P507
   Palaskar R., 2020, ARXIV201111610
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parmar P, 2020, J LARYNGOL OTOL, V134, P328, DOI 10.1017/S0022215120000444
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rahim T., 2020, ARXIV200806721
   Ren JJ, 2020, LARYNGOSCOPE, V130, pE686, DOI 10.1002/lary.28539
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva MP, 2015, INT FORUM ALLERGY RH, V5, P590, DOI 10.1002/alr.21526
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wu QW, 2020, J ALLERGY CLIN IMMUN, V145, P698, DOI 10.1016/j.jaci.2019.12.002
   Xiong H, 2019, EBIOMEDICINE, V48, P92, DOI 10.1016/j.ebiom.2019.08.075
   Zhang JP, 2018, IEEE J BIOMED HEALTH, V22, P1521, DOI 10.1109/JBHI.2017.2775662
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 41
TC 8
Z9 8
U1 1
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2042-6976
EI 2042-6984
J9 INT FORUM ALLERGY RH
JI Int. Forum Allergy Rhinol.
PD DEC
PY 2021
VL 11
IS 12
BP 1637
EP 1646
DI 10.1002/alr.22854
EA JUN 2021
PG 10
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology
GA XG3JG
UT WOS:000663929500001
PM 34148298
DA 2023-08-21
ER

PT J
AU Cao, WW
   Zheng, J
   Xiang, DH
   Ding, SS
   Sun, HT
   Yang, XD
   Liu, ZB
   Dai, YK
AF Cao, Weiwei
   Zheng, Jian
   Xiang, Dehui
   Ding, Saisai
   Sun, Haotian
   Yang, Xiaodong
   Liu, Zhaobang
   Dai, Yakang
TI Edge and neighborhood guidance network for 2D medical image segmentation
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Medical image segmentation; Weak edge; Edge and neighborhood guidance
   module; Multi-scale adaptive selection module
AB Accurate automatic image segmentation is important in medical image analysis. A perfect segmentation using fully convolutional network (FCN) means an accurate classification of each pixel. However, it is still a great challenge to accurately differentiate edge pixels from neighborhood pixels in weak edge regions. Many previous segmentation methods have focused on edge information to mitigate weak edge problems, but the more important neighborhood information is undervalued. To tackle this problem, in this paper, we propose a novel yet effective Edge and Neighborhood Guidance Network (ENGNet). Specifically, instead of just utilizing the edge information as the shape constraints, the edge and neighborhood guidance (ENG) module is designed to exploit the edge information and fine-grained neighborhood spatial information simultaneously, so as to improve the ability of network to classify edge pixels and neighborhood pixels in weak edge regions. Moreover, the ENG modules are adopted in different scales to learn sufficient feature representations of edge and neighborhood. To extract complementary features more effectively in channel dimension, we also design a multi-scale adaptive selection (MAS) module at channel-wise to extract multi-scale context information and adaptively fuse differentscale features. Two 2D public segmentation datasets including skin lesion dataset and endoscopic polyp dataset are used to evaluate the performance of the proposed ENGNet. Experimental results demonstrated that by exploiting edge information and neighborhood spatial information in different scales simultaneously, the proposed ENGNet can effectively alleviate the misclassification in weak edge regions and achieve better performance than other state-of-the-art methods.
C1 [Cao, Weiwei; Zheng, Jian; Sun, Haotian; Yang, Xiaodong; Liu, Zhaobang; Dai, Yakang] Univ Sci & Technol China, Sch Biomed Engn Suzhou, Div Life Sci & Med, Hefei 230026, Peoples R China.
   [Cao, Weiwei; Zheng, Jian; Ding, Saisai; Sun, Haotian; Yang, Xiaodong; Liu, Zhaobang; Dai, Yakang] Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Dept Med Imaging, Suzhou 215163, Peoples R China.
   [Xiang, Dehui] Soochow Univ, Sch Elect & Informat Engn, Jiangsu 215006, Peoples R China.
   [Dai, Yakang] Jinan Guoke Med Technol Dev Co Ltd, Jinan 250101, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Suzhou Institute of Biomedical
   Engineering & Technology, CAS; Soochow University - China
RP Liu, ZB; Dai, YK (通讯作者)，Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Dept Med Imaging, Suzhou 215163, Peoples R China.
EM liuzb@sibet.ac.cn; daiyk@sibet.ac.cn
RI JIAN, ZHENG/ABC-1339-2021; Xiang, Dehui/B-1938-2016
OI Xiang, Dehui/0000-0001-7873-9778
FU Natural Science Foundation of China [61971298]; Key Laboratory of Suzhou
   [SZS201818]; Quancheng 5150 Project, Jinan Innovation Team [2018GXRC017]
FX This work was supported in part by the Natural Science Foundation of
   China under grant No. 61971298, in part by the Key Laboratory of Suzhou
   under grant No.SZS201818, in part by the Quancheng 5150 Project, Jinan
   Innovation Team under grant No.2018GXRC017.
CR [Anonymous], 2019, ARXIV PREPRINT ARXIV
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Fallah F., 2018, IEEE J BIOMED HLTH I, V4, P1692
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fang Y., 2019, MED IMAGE COMPUT COM
   Feng RW, 2020, I S BIOMED IMAGING, P225, DOI 10.1109/ISBI45749.2020.9098492
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   King DB, 2015, ACS SYM SER, V1214, P1
   Lei BY, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101716
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Paszke A., 2019, NEURIPS, V32, P8024
   Paul S, 2020, I S BIOMED IMAGING, P221, DOI 10.1109/ISBI45749.2020.9098634
   Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155
   Razzak MI, 2019, IEEE J BIOMED HEALTH, V23, P1911, DOI 10.1109/JBHI.2018.2874033
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sarker MMK, 2018, LECT NOTES COMPUT SC, V11071, P21, DOI 10.1007/978-3-030-00934-2_3
   Shankaranarayana SM, 2019, IEEE J BIOMED HEALTH, V23, P1417, DOI 10.1109/JBHI.2019.2899403
   Song L, 2019, LECT NOTES COMPUT SC, V11861, P319, DOI 10.1007/978-3-030-32692-0_37
   Tang Peng, 2020, IEEE J BIOMED HLTH I
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Wang S., 2020, IEEE J BIOMED HLTH I, P1
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Xie YT, 2020, IEEE T MED IMAGING, V39, P2482, DOI 10.1109/TMI.2020.2972964
   Zhang ZJ, 2019, LECT NOTES COMPUT SC, V11764, P442, DOI 10.1007/978-3-030-32239-7_49
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
   Zhu QK, 2020, IEEE T MED IMAGING, V39, P753, DOI 10.1109/TMI.2019.2935018
NR 32
TC 12
Z9 12
U1 0
U2 24
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD AUG
PY 2021
VL 69
AR 102856
DI 10.1016/j.bspc.2021.102856
EA JUN 2021
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA UB1VA
UT WOS:000685637600008
DA 2023-08-21
ER

PT J
AU Hann, A
   Troya, J
   Fitting, D
AF Hann, Alexander
   Troya, Joel
   Fitting, Daniel
TI Current status and limitations of artificial intelligence in colonoscopy
SO UNITED EUROPEAN GASTROENTEROLOGY JOURNAL
LA English
DT Review
DE colonic polyps; colonoscopy; colorectal neoplasms; computer-assisted;
   deep learning; diagnosis; endoscopy; gastrointestinal
ID COMPUTER-AIDED DETECTION; DETECTION-ASSISTED COLONOSCOPY; SMALL
   COLORECTAL POLYPS; ADENOMA DETECTION RATE; GASTROINTESTINAL ENDOSCOPY;
   EUROPEAN-SOCIETY; CLASSIFICATION; DIAGNOSIS; SYSTEM; QUALITY
AB Background Artificial intelligence (AI) using deep learning methods for polyp detection (CADe) and characterization (CADx) is on the verge of clinical application. CADe already implied its potential use in randomized controlled trials. Further efforts are needed to take CADx to the next level of development.
   Aim This work aims to give an overview of the current status of AI in colonoscopy, without going into too much technical detail.
   Methods A literature search to identify important studies exploring the use of AI in colonoscopy was performed.
   Results This review focuses on AI performance in screening colonoscopy summarizing the first prospective trials for CADe, the state of research in CADx as well as current limitations of those systems and legal issues.
C1 [Hann, Alexander; Troya, Joel; Fitting, Daniel] Univ Hosp Wuerzburg, Intervent & Expt Endoscopy InExEn, Dept Internal Med 2, Wurzburg, Germany.
C3 University of Wurzburg
RP Hann, A (通讯作者)，Uniklin Wurzburg, Med Klin & Poliklin 2, Oberdurrbacher Str 6, D-97080 Wurzburg, Germany.
EM hann_a@ukw.de
OI Hann, Alexander/0000-0001-8035-3559
FU state government of Baden-Wurttemberg, Germany
FX The authors Alexander Hann and Daniel Fitting receive public funding
   from the state government of Baden-Wurttemberg, Germany (Funding cluster
   "Forum Gesundheitsstandort Baden-Wurttemberg") to research and develop
   artificial intelligence applications for polyp detection in screening
   colonoscopy.
CR Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012
   Bretthauer M, 2016, JAMA INTERN MED, V176, P894, DOI 10.1001/jamainternmed.2016.0960
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai B, 2015, ONCOL LETT, V9, P2073, DOI 10.3892/ol.2015.3005
   Calderwood AH, 2010, GASTROINTEST ENDOSC, V72, P686, DOI 10.1016/j.gie.2010.06.068
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cohen LB, 2010, GASTROINTEST ENDOSC, V72, P406, DOI 10.1016/j.gie.2010.04.001
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Denzer U, 2015, Z Gastroenterol, V53, pE1, DOI 10.1055/s-0041-109598
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   European Commission, WHIT PAP ART INT EUR
   Ferlitsch M, 2017, ENDOSCOPY, V49, P270, DOI 10.1055/s-0043-102569
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2020, GASTROINTEST ENDOSC, V92, P900, DOI 10.1016/j.gie.2020.06.021
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Kaminski MF, 2017, UNITED EUR GASTROENT, V5, P309, DOI 10.1177/2050640617700014
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Radaelli F, 2017, GUT, V66, P270, DOI 10.1136/gutjnl-2015-310685
   Rembacken B, 2012, ENDOSCOPY, V44, P957, DOI 10.1055/s-0032-1325686
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Schmiegel, 2019, S3 LEITLINIE KOLOREK
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tanaka H, 2019, J ANUS RECTUM COLON, V3, P128, DOI 10.23922/jarc.2018-042
   Thakkar S, 2020, GASTROENTEROLOGY, V158, P1219, DOI 10.1053/j.gastro.2019.12.035
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   van der Sommen F, 2020, GUT, V69, P2035, DOI 10.1136/gutjnl-2019-320466
   Vleugels JLA, 2019, GASTROENTEROLOGY, V156, P623, DOI 10.1053/j.gastro.2018.10.050
   Wadhwa V, 2020, ENDOSC INT OPEN, V08, pE1379, DOI 10.1055/a-1223-1926
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhou J, 2020, GASTROINTEST ENDOSC, V91, P428, DOI 10.1016/j.gie.2019.11.026
NR 50
TC 14
Z9 14
U1 0
U2 4
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2050-6406
EI 2050-6414
J9 UNITED EUR GASTROENT
JI United European Gastroenterol. J.
PD JUN
PY 2021
VL 9
IS 5
BP 527
EP 533
DI 10.1002/ueg2.12108
EA JUN 2021
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA TA4RO
UT WOS:000658429700001
PM 34617420
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Ma, RB
   Wang, R
   Zhang, YB
   Pizer, S
   McGill, SK
   Rosenman, J
   Frahm, JM
AF Ma, Ruibin
   Wang, Rui
   Zhang, Yubo
   Pizer, Stephen
   McGill, Sarah K.
   Rosenman, Julian
   Frahm, Jan-Michael
TI RNNSLAM: Reconstructing the 3D colon to visualize missing regions during
   a colonoscopy
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Colonoscopy; Missing region; SLAM; Recurrent neural network
ID SLAM
AB Colonoscopy is the gold standard for pre-cancerous polyps screening and treatment. The polyp detection rate is highly tied to the percentage of surveyed colonic surface. However, current colonoscopy technique cannot guarantee that all the colonic surface is well examined because of incomplete camera orientations and of occlusions. The missing regions can hardly be noticed in a continuous first-person perspective. Therefore, a useful contribution would be an automatic system that can compute missing regions from an endoscopic video in real-time and alert the endoscopists when a large missing region is detected. We present a novel method that reconstructs dense chunks of a 3D colon in real time, leaving the unsurveyed part unreconstructed. The method combines a standard SLAM system with a depth and pose prediction network to achieve much more robust tracking and less drift. It addresses the difficulties for colonoscopic images of existing simultaneous localization and mapping (SLAM) systems and end-to-end deep learning methods. 0 2021 Elsevier B.V. All rights reserved.
C1 [Ma, Ruibin; Wang, Rui; Zhang, Yubo; Pizer, Stephen; McGill, Sarah K.; Rosenman, Julian; Frahm, Jan-Michael] Univ N Carolina, Chapel Hill, NC 27705 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Ma, RB (通讯作者)，Univ N Carolina, Chapel Hill, NC 27705 USA.
EM ruibinma@cs.unc.edu
OI Zhang, Yubo/0000-0002-8942-5253; McGill, Sarah/0000-0002-4006-2703
CR Chen PY, 2019, PROC CVPR IEEE, P2619, DOI 10.1109/CVPR.2019.00273
   Chen Richard J, 2019, KDD WORKSH APPL DAT
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Engel J, 2013, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2013.183
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Grasa Oscar G., 2011, IEEE International Conference on Robotics and Automation, P4816
   Grasa OG, 2014, IEEE T MED IMAGING, V33, P135, DOI 10.1109/TMI.2013.2282997
   Grupp M., 2017, EVO PYTHON PACKAGE E
   Hong W., 2007, PROCSPIE
   Jaderberg M, 2015, ADV NEUR IN, V28
   Keller M, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P1, DOI 10.1109/3DV.2013.9
   Klein George, 2007, P1
   Kumar A. C., 2018, 1 INT WORKSH DEEP LE, V2
   Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma RB, 2019, LECT NOTES COMPUT SC, V11768, P573, DOI 10.1007/978-3-030-32254-0_64
   Mathew S, 2020, PROC CVPR IEEE, P4695, DOI [10.1109/cvpr42600.2020.00475, 10.1109/CVPR42600.2020.00475]
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nadeem S., 2016, ABS160901329 CORR
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schops T., 2018, ABS181000729 CORR
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695
   Wang R., 2019, P IEEE C COMP VIS PA
   Wang R, 2017, IEEE I CONF COMP VIS, P3923, DOI 10.1109/ICCV.2017.421
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Xingjian S., 2015, ADV NEURAL INFORM PR, P802, DOI DOI 10.5555/2969239.2969329
   Yang N., 2018, DEEP VIRTUAL STEREO
   Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18
NR 41
TC 8
Z9 8
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD AUG
PY 2021
VL 72
AR 102100
DI 10.1016/j.media.2021.102100
EA JUN 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA TU8YB
UT WOS:000681315400010
PM 34102478
OA Green Accepted
DA 2023-08-21
ER

PT J
AU Pacal, I
   Karaboga, D
AF Pacal, Ishak
   Karaboga, Dervis
TI A robust real-time deep learning based automatic polyp detection system
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp detection; Real-time polyp detection; Deep learning; Medical image
   analysis; YOLOv4; Scaled YOLOv4; Rectal cancer; Colorectal cancer; Colon
   cancer; Colonoscopy; Convolutional neural networks
ID COLONOSCOPY
AB Colorectal cancer (CRC) is globally the third most common type of cancer. Colonoscopy is considered the gold standard in colorectal cancer screening and allows for the removal of polyps before they become cancerous. Computer-aided detection systems (CADs) have been developed to detect polyps. Unfortunately, these systems have limited sensitivity and specificity. In contrast, deep learning architectures provide better detection by extracting the different properties of polyps. However, the desired success has not yet been achieved in real-time polyp detection. Here, we propose a new structure for real-time polyp detection by scaling the YOLOv4 algorithm to overcome these obstacles. For this, we first replace the whole structure with Cross Stage Partial Networks (CSPNet), then substitute the Mish activation function for the Leaky ReLu activation function and also substituted the Distance Intersection over Union (DIoU) loss for the Complete Intersection over Union (CIoU) loss. We improved performance of YOLOv3 and YOLOv4 architectures using different structures such as ResNet, VGG, DarkNet53, and Transformers. To increase success of the proposed method, we utilized a variety of data augmentation approaches for preprocessing, an ensemble learning model, and NVIDIA TensorRT for post processing. In order to compare our study with other studies more objectively, we only employed public data sets and followed MICCAI Sub-Challenge on Automatic Polyp Detection in Colonoscopy. The proposed method differs from other methods with its real-time performance and state-of-the-art detection accuracy. The proposed method (without ensemble learning) achieved higher results than those found in the literature, precision: 91.62%, recall: 82.55%, F1-score: 86.85% on public ETIS-LARIB data set and precision: 96.04%, recall: 96.68%, F1-score: 96.36% on public CVC-ColonDB data set, respectively.
C1 [Pacal, Ishak] Igdir Univ, Fac Engn, Dept Comp Engn, Igdir, Turkey.
   [Karaboga, Dervis] Erciyes Univ, Fac Engn, Dept Comp Engn, Kayseri, Turkey.
   [Karaboga, Dervis] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Syst, Jeddah, Saudi Arabia.
C3 Igdir University; Erciyes University; King Abdulaziz University
RP Pacal, I (通讯作者)，Igdir Univ, Fac Engn, Dept Comp Engn, Igdir, Turkey.
EM ishak.pacal@igdir.edu.tr
CR Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Colorectal cancer statistics, COMM IS COL CANC
   Dosovitskiy A., 2020, IMAGE IS WORTH 16X16, P1
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Issa IA, 2017, WORLD J GASTROENTERO, V23, P5086, DOI 10.3748/wjg.v23.i28.5086
   Jha D., 2020, REAL TIME POLYP DETE, P1
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Karagoz MA, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102539
   Kingma D., 2015, ARXIV
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102052
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Misra D., 2019, MISH SELF REGULARIZE
   Pacal I, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104003
   Qadir H. A., 2019, 2019 13 INT S MEDICA, P1, DOI [10.1109/ISMICT.2019.8743694, DOI 10.1109/ISMICT.2019.8743694]
   Ramachandran Prajit, 2017, ABS171005941 CORR
   Redmon J., 2018, TOLOV3 INCREMENTAL I
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruder S., 2016, ARXIV160904747, V2016, p1609.04747, DOI DOI 10.48550/ARXIV.1609.04747
   Shin Y., 2019, AUTOMATIC COLON POLY
   Solhusvik J., 2021, MED IMAGE ANAL, V68
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang C.-Y., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Wang C.-Y., 2020, SCALED YOLOV4 SCALIN
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Xu JW, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102503
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 37
TC 39
Z9 39
U1 9
U2 40
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD JUL
PY 2021
VL 134
AR 104519
DI 10.1016/j.compbiomed.2021.104519
EA JUN 2021
PG 13
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA TI1XX
UT WOS:000672580500008
PM 34090014
DA 2023-08-21
ER

PT J
AU Bardhi, O
   Sierra-Sosa, D
   Garcia-Zapirain, B
   Bujanda, L
AF Bardhi, Ornela
   Sierra-Sosa, Daniel
   Garcia-Zapirain, Begonya
   Bujanda, Luis
TI Deep Learning Models for Colorectal Polyps
SO INFORMATION
LA English
DT Article
DE colon cancer; deep learning; detection; classification; localization;
   CNN; autoencoders
ID CANCER-MORTALITY; COLONOSCOPY; DIAGNOSIS
AB Colorectal cancer is one of the main causes of cancer incident cases and cancer deaths worldwide. Undetected colon polyps, be them benign or malignant, lead to late diagnosis of colorectal cancer. Computer aided devices have helped to decrease the polyp miss rate. The application of deep learning algorithms and techniques has escalated during this last decade. Many scientific studies are published to detect, localize, and classify colon polyps. We present here a brief review of the latest published studies. We compare the accuracy of these studies with our results obtained from training and testing three independent datasets using a convolutional neural network and autoencoder model. A train, validate and test split was performed for each dataset, 75%, 15%, and 15%, respectively. An accuracy of 0.937 was achieved for CVC-ColonDB, 0.951 for CVC-ClinicDB, and 0.967 for ETIS-LaribPolypDB. Our results suggest slight improvements compared to the algorithms used to date.
C1 [Bardhi, Ornela; Garcia-Zapirain, Begonya] Univ Deusto, Fac Engn, eVIDA Lab, Bilbao 48007, Spain.
   [Sierra-Sosa, Daniel] Hood Coll, Dept Comp Sci & Informat Technol, Frederick, MD 21701 USA.
   [Bujanda, Luis] Univ Basque Country, Ctr Invest Biomed Red Enfermedades Hepat & Digest, Inst Biodonostia, Dept Gastroenterol,UPV EHU, San Sebastian 20014, Spain.
C3 University of Deusto; CIBER - Centro de Investigacion Biomedica en Red;
   CIBEREHD; Instituto de Investigacion Sanitaria Biodonostia; University
   of Basque Country
RP Bardhi, O (通讯作者)，Univ Deusto, Fac Engn, eVIDA Lab, Bilbao 48007, Spain.
EM ornela.bardhi@deusto.es; sierra-sosa@hood.edu; mbgarciazapi@deusto.es;
   luis.bujandafernandezdepierola@osakidetza.eus
RI Bujanda, Luis/AAB-2485-2021; Zapirain, Begoña Garcia/L-5619-2014;
   Sierra-Sosa, Daniel/AAP-4610-2020; Bardhi, Ornela/C-9545-2017
OI Bujanda, Luis/0000-0002-4353-9968; Zapirain, Begoña
   Garcia/0000-0002-9356-1186; Sierra-Sosa, Daniel/0000-0003-1326-0867;
   Bardhi, Ornela/0000-0001-9092-8299
FU European Union [722012]; Marie Curie Actions (MSCA) [722012] Funding
   Source: Marie Curie Actions (MSCA)
FX O.B. received funding from the European Union's Horizon 2020 CATCH ITN
   project under the Marie Sklodowska-Curie grant agreement no. 722012.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bonnington SN, 2016, WORLD J GASTROENTERO, V22, P1925, DOI 10.3748/wjg.v22.i6.1925
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Carioli G, 2020, ANN ONCOL, V31, P650, DOI 10.1016/j.annonc.2020.02.009
   Carneiro G, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101653
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Ferlay J, 2020, CANC TODAY
   Gao JB, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/8374317
   Jung A., 2017, IMGAUG 0 2 5
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Lee J, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000007468
   Lieberman D, 2005, GASTROINTEST ENDOSC, V61, P392, DOI 10.1016/S0016-5107(05)00133-1
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mohammed A.K., 2018, Y NET DEEP CONVOLUTI
   Poon CCY, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0281-z
   Ribeiro E., 2017, P 2017 IEEE 14 INT S
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ribeiro J, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTERS IN EDUCATION (SIIE)
   Shin Y., 2017, P 39 ANN INT C IEEE
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI [DOI 10.3322/CAAC.21442, 10.3322/caac.21332]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zauber AG, 2015, DIGEST DIS SCI, V60, P681, DOI 10.1007/s10620-015-3600-5
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 35
TC 4
Z9 4
U1 1
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2078-2489
J9 INFORMATION
JI Information
PD JUN
PY 2021
VL 12
IS 6
AR 245
DI 10.3390/info12060245
PG 13
WC Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SZ1DA
UT WOS:000666313800001
OA gold
DA 2023-08-21
ER

PT J
AU Jha, D
   Smedsrud, PH
   Johansen, D
   de Lange, T
   Johansen, HD
   Halvorsen, P
   Riegler, MA
AF Jha, Debesh
   Smedsrud, Pia H.
   Johansen, Dag
   de Lange, Thomas
   Johansen, Havard D.
   Halvorsen, Pal
   Riegler, Michael A.
TI A Comprehensive Study on Colorectal Polyp Segmentation With ResUNet plus
   plus , Conditional Random Field and Test-Time Augmentation
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Image segmentation; Colonoscopy; Cancer; Hospitals; Computer
   architecture; Training; Task analysis; Colonoscopy; polyp segmentation;
   ResUNet plus plus; conditional random field; test-time augmentation;
   generalization
ID MISS RATE; COLONOSCOPY; VALIDATION
AB Colonoscopy is considered the gold standard for detection of colorectal cancer and its precursors. Existing examination methods are, however, hampered by high overall miss-rate, and many abnormalities are left undetected. Computer-Aided Diagnosis systems based on advanced machine learning algorithms are touted as a game-changer that can identify regions in the colon overlooked by the physicians during endoscopic examinations, and help detect and characterize lesions. In previous work, we have proposed the ResUNet++ architecture and demonstrated that it produces more efficient results compared with its counterparts U-Net and ResUNet. In this paper, we demonstrate that further improvements to the overall prediction performance of the ResUNet++ architecture can be achieved by using Conditional Random Field (CRF) and Test-Time Augmentation (TTA). We have performed extensive evaluations and validated the improvements using six publicly available datasets: Kvasir-SEG, CVC-ClinicDB, CVC-ColonDB, ETIS-Larib Polyp DB, ASU-Mayo Clinic Colonoscopy Video Database, and CVC-VideoClinicDB. Moreover, we compare our proposed architecture and resulting model with other state-of-the-art methods. To explore the generalization capability of ResUNet++ on different publicly available polyp datasets, so that it could be used in a real-world setting, we performed an extensive cross-dataset evaluation. The experimental results show that applying CRF and TTA improves the performance on various polyp segmentation datasets both on the same dataset and cross-dataset. To check the model's performance on difficult to detect polyps, we selected, with the help of an expert gastroenterologist, 196 sessile or flat polyps that are less than ten millimeters in size. This additional data has been made available as a subset of Kvasir-SEG. Our approaches showed good results for flat or sessile and smaller polyps, which are known to be one of the major reasons for high polyp miss-rates. This is one of the significant strengths of our work and indicates that our methods should be investigated further for use in clinical practice.
C1 [Jha, Debesh; Smedsrud, Pia H.; Halvorsen, Pal; Riegler, Michael A.] SimulaMet, N-0167 Oslo, Norway.
   [Jha, Debesh; Johansen, Dag; Johansen, Havard D.] UiT Arctic Univ Norway, N-9037 Tromso, Norway.
   [Smedsrud, Pia H.] Univ Oslo, N-0315 Oslo, Norway.
   [de Lange, Thomas] Sahlgrenska Univ Hosp Molndal, Med Dept, S-43130 Molndal, Region Vastra G, Sweden.
   [de Lange, Thomas] Vestre Viken, Brum Hosp, Dept Med Res, N-1346 Gjettum, Norway.
   [de Lange, Thomas] Univ Gothenburg, Sahlgrenska Acad, Dept Mol & Clin Med, S-40530 Gothenburg, Sweden.
   [Halvorsen, Pal] Oslo Metropolitan Univ, N-0167 Oslo, Norway.
C3 UiT The Arctic University of Tromso; University of Oslo; Sahlgrenska
   University Hospital; University of Gothenburg; Oslo Metropolitan
   University (OsloMet)
RP Jha, D (通讯作者)，SimulaMet, N-0167 Oslo, Norway.
EM debesh@simula.no; pia@simula.no; dag.johansen@uit.no;
   t.de.lange@medisin.uio.no; havard.johansen@uit.no; paalh@simula.no;
   michael@simula.no
RI Riegler, Michael A/E-5443-2015; de Lange, Thomas/Q-9063-2016
OI Riegler, Michael A/0000-0002-3153-2064; de Lange,
   Thomas/0000-0003-3989-7487; Jha, Debesh/0000-0002-8078-6730; Dagenborg,
   Havard Johansen/0000-0002-1637-7262
FU Research Council of Norway [270053, 263248]
FX This work was supported in part by the Research Council of Norway
   Project 263248 and has benefited from the Experimental Infrastructure
   for Exploration of Exascale Computing (eX3), which is financially
   supported by the Research Council of Norway under contract 270053.
CR Abadi M., 2015, P 12 USENIX C OPERAT, DOI [DOI 10.5555/3026877.3026899, DOI 10.1038/NN.3331]
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Alam FI, 2019, IEEE T GEOSCI REMOTE, V57, P1612, DOI 10.1109/TGRS.2018.2867679
   Ali S, 2019, ARXIV PREPRINT ARXIV
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Banik Debapriya, 2020, Advanced Computing and Systems for Security. Volume Twelve. Advances in Intelligent Systems and Computing (AISC 1136), P109, DOI 10.1007/978-981-15-2930-6_9
   Bernal, 2018, P CARS C
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chen L.-C., 2015, PROC INT C LEARN REP, P1, DOI DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chollet F., 2015, KERAS PROBABILISTIC
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   Gwak J, 2019, IEEE ACCESS, V7, p26 440
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Matsuda T, 2017, NAT REV GASTRO HEPAT, V14, P305, DOI 10.1038/nrgastro.2017.18
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Nguyen NQ, 2019, IEEE ACCESS, V7, P33795, DOI 10.1109/ACCESS.2019.2904094
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Nie D, 2018, LECT NOTES COMPUT SC, V11073, P370, DOI 10.1007/978-3-030-00937-3_43
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   POOMESHWARAN J, 2019, P INT ENG MED BIOL C, P7201
   Pozdeev AA, 2019, IEEE NW RUSS YOUNG, P1216, DOI 10.1109/EIConRus.2019.8657018
   RoB T., 2020, ARXIV200310299V1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shaukat A, 2015, GASTROENTEROLOGY, V149, P952, DOI 10.1053/j.gastro.2015.06.044
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sinha A, 2021, IEEE J BIOMED HEALTH, V25, P121, DOI 10.1109/JBHI.2020.2986926
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Thomaz VD, 2019, COMP MED SY, P192, DOI 10.1109/CBMS.2019.00047
   Vaswani A, 2017, ADV NEUR IN, V30
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang LD, 2019, IEEE ACCESS, V7, P152429, DOI 10.1109/ACCESS.2019.2948073
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2018, LECT NOTES COMPUT SC, V11073, P523, DOI 10.1007/978-3-030-00937-3_60
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yamakawa M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44035-3
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   2019, GASTROENTEROL, V157, P660
NR 60
TC 65
Z9 68
U1 4
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD JUN
PY 2021
VL 25
IS 6
BP 2029
EP 2040
DI 10.1109/JBHI.2021.3049304
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA SN5TP
UT WOS:000658352100017
PM 33400658
OA Green Submitted, Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Parsa, N
   Byrne, MF
AF Parsa, Nasim
   Byrne, Michael F.
TI Artificial intelligence for identification and characterization of
   colonic polyps
SO THERAPEUTIC ADVANCES IN GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
DE artificial intelligence; computer-aided detection; computer-aided
   diagnosis; convolutional neural network; deep learning
ID COMPUTER-AIDED DETECTION; COLORECTAL POLYPS; GASTROINTESTINAL ENDOSCOPY;
   DIAGNOSTIC SYSTEM; ADENOMA DETECTION; CLASSIFICATION; COLONOSCOPY;
   ENDOCYTOSCOPY; HISTOLOGY; PATTERNS
AB Colonoscopy remains the gold standard exam for colorectal cancer screening due to its ability to detect and resect pre-cancerous lesions in the colon. However, its performance is greatly operator dependent. Studies have shown that up to one-quarter of colorectal polyps can be missed on a single colonoscopy, leading to high rates of interval colorectal cancer. In addition, the American Society for Gastrointestinal Endoscopy has proposed the "resect-and-discard" and "diagnose-and-leave" strategies for diminutive colorectal polyps to reduce the costs of unnecessary polyp resection and pathology evaluation. However, the performance of optical biopsy has been suboptimal in community practice. With recent improvements in machine-learning techniques, artificial intelligence-assisted computer-aided detection and diagnosis have been increasingly utilized by endoscopists. The application of computer-aided design on real-time colonoscopy has been shown to increase the adenoma detection rate while decreasing the withdrawal time and improve endoscopists' optical biopsy accuracy, while reducing the time to make the diagnosis. These are promising steps toward standardization and improvement of colonoscopy quality, and implementation of "resect-and-discard" and "diagnose-and-leave" strategies. Yet, issues such as real-world applications and regulatory approval need to be addressed before artificial intelligence models can be successfully implemented in clinical practice. In this review, we summarize the recent literature on the application of artificial intelligence for detection and characterization of colorectal polyps and review the limitation of existing artificial intelligence technologies and future directions for this field.
C1 [Parsa, Nasim] Univ Missouri, Div Gastroenterol & Hepatol, Dept Med, Columbia, MO 65211 USA.
   [Byrne, Michael F.] Univ British Columbia, Div Gastroenterol, Dept Med, Vancouver, BC, Canada.
   [Byrne, Michael F.] Satisfai Hlth, Vancouver, BC, Canada.
C3 University of Missouri System; University of Missouri Columbia;
   University of British Columbia
RP Parsa, N (通讯作者)，Univ Missouri, Div Gastroenterol & Hepatol, Dept Med, Columbia, MO 65211 USA.
EM parsan@health.missouri.edu
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Djinbachian Roupen, 2019, Curr Treat Options Gastroenterol, V17, P99, DOI 10.1007/s11938-019-00220-x
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Guizard N, 2019, GASTROENTEROLOGY, V156, pS48
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Misawa M, 2021, GASTROINTEST ENDOSC, V93, P960, DOI 10.1016/j.gie.2020.07.060
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2013, ENDOSCOPY, V45, P98, DOI 10.1055/s-0032-1325932
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Ponugoti P, 2019, ENDOSCOPY, V51, P221, DOI 10.1055/a-0831-2348
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Robertson DJ, 2014, GUT, V63, P949, DOI 10.1136/gutjnl-2012-303796
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Singh R, 2013, DIGEST ENDOSC, V25, P16, DOI 10.1111/den.12075
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 49
TC 5
Z9 5
U1 3
U2 8
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 2631-7745
J9 THER ADV GASTROINTES
JI Ther. Adv. Gastrointest. Endosc.
PD JUN
PY 2021
VL 14
AR 26317745211014698
DI 10.1177/26317745211014698
PG 12
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA UF3FP
UT WOS:000688462800001
PM 34263163
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Wu, XD
   Li, SX
   Xu, QY
   Yan, XL
   Fu, QY
   Fu, XX
   Fang, XL
   Zhang, YJ
AF Wu, Xingda
   Li, Shaoxin
   Xu, Qiuyan
   Yan, Xinliang
   Fu, Qiuyue
   Fu, Xinxin
   Fang, Xianglin
   Zhang, Yanjiao
TI Rapid and accurate identification of colon cancer by Raman spectroscopy
   coupled with convolutional neural networks
SO JAPANESE JOURNAL OF APPLIED PHYSICS
LA English
DT Article
DE Raman spectra; Convolutional neural networks; Colon tissues; Early
   diagnosis
ID DIAGNOSIS; CELLS; MICROSPECTROSCOPY; CLASSIFICATION; TOOL
AB Colonoscopy is regarded as the gold standard in colorectal tumor diagnosis, but it is costly and time-consuming. Raman spectroscopy has shown promise for differentiating cancerous from non-cancerous tissue and is expected to be a new tool for oncological diagnosis. However, traditional Raman spectroscopy analysis requires tedious preprocessing, and the classification accuracy needs to be improved. In this work, a novel Raman spectral qualitative classification method based on convolutional neural network (CNN) is proposed for the identification of three different colon tissue samples, including adenomatous polyp, adenocarcinoma and normal tissues. Experimental results show that this CNN model has superior feature extraction ability. For the spectral data of new individuals, the trained CNN model presents much better classification performance than traditional machine learning methods, such as the k-nearest neighbor, random forest, and support vector machine. Raman spectroscopy combined with CNN can be used as an effective auxiliary tool for the early diagnosis of colon cancer.
C1 [Wu, Xingda; Li, Shaoxin; Yan, Xinliang; Fang, Xianglin] Guangdong Med Univ, Sch Biomed Engn, Dongguan 523808, Peoples R China.
   [Xu, Qiuyan] Cent Peoples Hosp Zhanjiang, Dept Crit Care Med, Zhanjiang 524045, Peoples R China.
   [Fu, Qiuyue] Guangdong Med Univ, Sch Med Technol, Dongguan 523808, Peoples R China.
   [Fu, Xinxin] Guangdong Med Univ, Clin Med Coll 2, Dongguan 523808, Peoples R China.
   [Zhang, Yanjiao] Guangdong Med Univ, Sch Basic Med, Dongguan 523808, Peoples R China.
C3 Guangdong Medical University; Guangdong Medical University; Guangdong
   Medical University; Guangdong Medical University
RP Fang, XL (通讯作者)，Guangdong Med Univ, Sch Biomed Engn, Dongguan 523808, Peoples R China.; Zhang, YJ (通讯作者)，Guangdong Med Univ, Sch Basic Med, Dongguan 523808, Peoples R China.
EM xlfang@gdmu.edu.cn; yyzhang@gdmu.edu.cn
RI Xianglin, Fang/ABE-8838-2021; Fu, Xinxin/ABC-8428-2020
OI Xianglin, Fang/0000-0002-7066-7500; Li, Shaoxin/0000-0001-8187-9421
FU Discipline Construction Project of Guangdong Medical University
   [4SG21022G]
FX We acknowledge the support from the Discipline Construction Project of
   Guangdong Medical University (4SG21022G).
CR Abramczyk H, 2017, J MOL LIQ, V245, P52, DOI 10.1016/j.molliq.2017.05.142
   Abramczyk H, 2018, SPECTROCHIM ACTA A, V188, P8, DOI 10.1016/j.saa.2017.06.037
   Brozek-Pluska B, 2019, RSC ADV, V9, P40445, DOI 10.1039/c9ra06831g
   Brozek-Pluska B, 2016, ANAL METHODS-UK, V8, P8542, DOI 10.1039/c6ay02559e
   Chen XY, 2019, ANAL METHODS-UK, V11, P5118, DOI [10.1039/C9AY01531K, 10.1039/c9ay01531k]
   Christian K, 2014, BIOMED OPT EXPRESS, V5, P3252, DOI 10.1364/BOE.5.003252
   Cui CH, 2018, CHEMOMETR INTELL LAB, V182, P9, DOI 10.1016/j.chemolab.2018.07.008
   Ding H, 2017, J RAMAN SPECTROSC, V48, P902, DOI 10.1002/jrs.5140
   Fan XQ, 2019, ANALYST, V144, P1789, DOI 10.1039/c8an02212g
   Feng SY, 2010, BIOSENS BIOELECTRON, V25, P2414, DOI 10.1016/j.bios.2010.03.033
   Ishigaki M, 2016, ANALYST, V141, P1027, DOI 10.1039/c5an01323b
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Lee W, 2018, ANAL CHEM, V90, P11290, DOI 10.1021/acs.analchem.8b01831
   Li QB, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030627
   Liu J, 2017, ANALYST, V142, P4067, DOI 10.1039/c7an01371j
   Liu WJ, 2017, BIOSENS BIOELECTRON, V97, P70, DOI 10.1016/j.bios.2017.05.045
   Lopes PC, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3658756
   Luo SW, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.6.067004
   Malek S, 2018, J CHEMOMETR, V32, DOI 10.1002/cem.2977
   Mamian-Lopez MB, 2013, ANAL CHIM ACTA, V760, P53, DOI 10.1016/j.aca.2012.11.023
   Marro M, 2018, ANAL CHEM, V90, P5594, DOI 10.1021/acs.analchem.7b04527
   Qiu SF, 2016, ONCOL LETT, V11, P2590, DOI 10.3892/ol.2016.4239
   Schie IW, 2013, APPL SPECTROSC, V67, P813, DOI 10.1366/12-06971
   Shimobaba T, 2017, APPL OPTICS, V56, P7327, DOI 10.1364/AO.56.007327
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Synytsya A, 2014, J RAMAN SPECTROSC, V45, P903, DOI 10.1002/jrs.4581
   Teh SK, 2010, BRIT J SURG, V97, P550, DOI 10.1002/bjs.6913
   Uraoka T, 2015, EXPERT REV GASTROENT, V9, P129, DOI 10.1586/17474124.2015.960397
   Viswanathan K, 2019, LASER PHYS, V29, DOI 10.1088/1555-6611/ab05bb
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Widjaja E, 2008, INT J ONCOL, V32, P653
   Yamakawa M, 2020, JPN J APPL PHYS, V59, DOI 10.35848/1347-4065/ab80dd
   Yan X, 2020, SPECTROCHIM ACTA A, V226, DOI 10.1016/j.saa.2019.117589
   Zhang J, 2017, ONCOTARGET, V8, P36824, DOI 10.18632/oncotarget.15975
   Zhao J, 2007, APPL SPECTROSC, V61, P1225, DOI 10.1366/000370207782597003
NR 36
TC 9
Z9 9
U1 1
U2 30
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0021-4922
EI 1347-4065
J9 JPN J APPL PHYS
JI Jpn. J. Appl. Phys.
PD JUN 1
PY 2021
VL 60
IS 6
AR 067001
DI 10.35848/1347-4065/ac0005
PG 7
WC Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA SJ1SR
UT WOS:000655309200001
DA 2023-08-21
ER

PT J
AU Jiang, JW
   Xie, QR
   Cheng, Z
   Cai, JQ
   Xia, T
   Yang, H
   Yang, B
   Peng, H
   Bai, XS
   Yan, MQ
   Li, X
   Zhou, J
   Huang, X
   Wang, L
   Long, HY
   Wang, PX
   Chu, YP
   Zeng, FW
   Zhang, XQ
   Wang, GY
   Zeng, FX
AF Jiang, Jiawei
   Xie, Qianrong
   Cheng, Zhuo
   Cai, Jianqiang
   Xia, Tian
   Yang, Hang
   Yang, Bo
   Peng, Hui
   Bai, Xuesong
   Yan, Mingque
   Li, Xue
   Zhou, Jun
   Huang, Xuan
   Wang, Liang
   Long, Haiyan
   Wang, Pingxi
   Chu, Yanpeng
   Zeng, Fan-Wei
   Zhang, Xiuqin
   Wang, Guangyu
   Zeng, Fanxin
TI AI based colorectal disease detection using real-time screening
   colonoscopy
SO PRECISION CLINICAL MEDICINE
LA English
DT Article
DE artificial intelligence (AI); colorectal disease; real-time colonoscopy
ID MISS RATE; TASK-FORCE; CANCER; POLYPS; CLASSIFICATION; POLYPECTOMY;
   DIAGNOSIS
AB Colonoscopy is an effective tool for early screening of colorectal diseases. However, the application of colonoscopy in distinguishing different intestinal diseases still faces great challenges of efficiency and accuracy. Here we constructed and evaluated a deep convolution neural network (CNN) model based on 117 055 images from 16 004 individuals, which achieved a high accuracy of 0.933 in the validation dataset in identifying patients with polyp, colitis, colorectal cancer (CRC) from normal. The proposed approach was further validated on multi-center real-time colonoscopy videos and images, which achieved accurate diagnostic performance on detecting colorectal diseases with high accuracy and precision to generalize across external validation datasets. The diagnostic performance of the model was further compared to the skilled endoscopists and the novices. In addition, our model has potential in diagnosis of adenomatous polyp and hyperplastic polyp with an area under the receiver operating characteristic curve of 0.975. Our proposed CNN models have potential in assisting clinicians in making clinical decisions with efficiency during application.
C1 [Jiang, Jiawei; Xie, Qianrong; Yang, Hang; Li, Xue; Zhou, Jun; Wang, Pingxi; Chu, Yanpeng; Zeng, Fan-Wei; Zeng, Fanxin] Dazhou Cent Hosp, Dept Clin Res Ctr, Dazhou 635000, Peoples R China.
   [Jiang, Jiawei] Eidgenoss Tech Hsch Zurich, Dept Comp Sci, CH-999034 Zurich, Switzerland.
   [Cheng, Zhuo; Yang, Bo; Bai, Xuesong; Yan, Mingque] Dazhou Cent Hosp, Digest Endoscopy Ctr, Dazhou 635000, Peoples R China.
   [Cai, Jianqiang] Chinese Acad Med Sci & Peking Union Med Coll, Canc Hosp, Natl Canc Ctr, Dept Hepatobiliary Surg, Beijing 100730, Peoples R China.
   [Xia, Tian] Natl Ctr Biomed Anal, Beijing 100850, Peoples R China.
   [Peng, Hui] Huazhong Agr Univ, Coll Informat, Wuhan 430070, Peoples R China.
   [Huang, Xuan] Capital Med Univ, Beijing Chao Yang Hosp, Dept Ophthalmol, Med Res Ctr, Beijing 100020, Peoples R China.
   [Wang, Liang] Dazhou Cent Hosp, Informat Dept, Dazhou 635000, Peoples R China.
   [Long, Haiyan] Quxian Peoples Hosp, Digest Endoscopy Ctr, Dazhou 635000, Peoples R China.
   [Zhang, Xiuqin] Peking Univ, Inst Mol Med, Beijing 100871, Peoples R China.
   [Wang, Guangyu] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Zeng, Fanxin] Sichuan Univ Arts & Sci, Dept Med, Dazhou 635000, Peoples R China.
C3 Chinese Academy of Medical Sciences - Peking Union Medical College;
   Cancer Institute & Hospital - CAMS; Peking Union Medical College;
   Huazhong Agricultural University; Capital Medical University; Peking
   University; Beijing University of Posts & Telecommunications; Sichuan
   University of Arts & Science
RP Zeng, FX (通讯作者)，Dazhou Cent Hosp, Dept Clin Res Ctr, Dazhou 635000, Peoples R China.; Zhang, XQ (通讯作者)，Peking Univ, Inst Mol Med, Beijing 100871, Peoples R China.; Wang, GY (通讯作者)，Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.; Zeng, FX (通讯作者)，Sichuan Univ Arts & Sci, Dept Med, Dazhou 635000, Peoples R China.
EM zhangxq@pku.edu.cn; guangyu.wang24@gmail.com; zengfx@pku.edu.cn
OI Zhang, Xiuqin/0000-0001-8692-7146
FU National Natural Science Foundation of China [81902861, 32000485];
   Xinglin Scholars" Scientific Research Project Fund of Chengdu University
   of Traditional Chinese Medicine [YYZX2019012]; Scientific Research Fund
   of Technology Bureau in Dazhou [17YYJC0004]; Key Research and
   Development Project Fund of Science and Technology Bureau in Dazhou,
   Sichuan Province [20ZDYF0001]
FX This study was funded by the National Natural Science Foundation of
   China (Grant No. 81902861 to F.Z. and 32000485 to X.H.), "Xinglin
   Scholars" Scientific Research Project Fund of Chengdu University of
   Traditional Chinese Medicine (Grant No. YYZX2019012 to F.Z.), the
   Scientific Research Fund of Technology Bureau in Dazhou (Grant No.
   17YYJC0004 to F.-W.Z.), the Key Research and Development Project Fund of
   Science and Technology Bureau in Dazhou, Sichuan Province (Grant No.
   20ZDYF0001 to F.-W.Z.). We express our deepest appreciation to J.Z, Y.C.
   for organizing the raw data and G.Y. for the revising the manuscript.
CR Abadi M., 2016, TENSORFLOW LARGE SCA, P265
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Citarda F, 2001, GUT, V48, P812, DOI 10.1136/gut.48.6.812
   Das N, 2020, NEURAL NETWORKS, V128, P47, DOI 10.1016/j.neunet.2020.05.003
   FEARON ER, 1990, CELL, V61, P759, DOI 10.1016/0092-8674(90)90186-I
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Jimenez-Sanchez A, 2020, INT J COMPUT ASS RAD, V15, P847, DOI 10.1007/s11548-020-02150-x
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Liang GB, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.06.023
   Lu LQ, 2020, PEERJ, V8, DOI 10.7717/peerj.8668
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Manna C, 2013, REPROD BIOMED ONLINE, V26, P42, DOI 10.1016/j.rbmo.2012.09.015
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   MULLER B, 1986, ZBL CHIR, V111, P1091
   MUTO T, 1975, CANCER, V36, P2251, DOI 10.1002/cncr.2820360944
   Nowacki TM, 2015, DIGEST DIS SCI, V60, P492, DOI 10.1007/s10620-014-3373-2
   Pasha SF, 2009, GASTROINTEST ENDOSC, V69, pAB363, DOI 10.1016/j.gie.2009.03.1079
   Qi XF, 2019, MED IMAGE ANAL, V52, P185, DOI 10.1016/j.media.2018.12.006
   Rajkomar A, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0029-1
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Siu AL, 2016, ANN INTERN MED, V164, P279, DOI 10.7326/M15-2886
   Than M, 2015, ANN GASTROENTEROL, V28, P94
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Winawer SJ, 2006, CA-CANCER J CLIN, V56, P143, DOI 10.3322/canjclin.56.3.143
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhang K, 2020, CELL, V181, P1423, DOI 10.1016/j.cell.2020.04.045
   Zhang XH, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1457-4
NR 38
TC 0
Z9 0
U1 0
U2 0
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 2096-5303
EI 2516-1571
J9 PRECIS CLIN MED
JI Precis. Clin. Med.
PD JUN
PY 2021
VL 4
IS 2
BP 109
EP 118
DI 10.1093/pcmedi/pbab013
EA MAY 2021
PG 10
WC Medicine, Research & Experimental
WE Emerging Sources Citation Index (ESCI)
SC Research & Experimental Medicine
GA WG6QN
UT WOS:000707119200005
PM 35694157
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Itoh, H
   Oda, M
   Mori, Y
   Misawa, M
   Kudo, SE
   Imai, K
   Ito, S
   Hotta, K
   Takabatake, H
   Mori, M
   Natori, H
   Mori, K
AF Itoh, Hayato
   Oda, Masahiro
   Mori, Yuichi
   Misawa, Masashi
   Kudo, Shin-Ei
   Imai, Kenichiro
   Ito, Sayo
   Hotta, Kinichi
   Takabatake, Hirotsugu
   Mori, Masaki
   Natori, Hiroshi
   Mori, Kensaku
TI Unsupervised colonoscopic depth estimation by domain translations with a
   Lambertian-reflection keeping auxiliary task
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Colonoscopy; Depth estimation; Medical image understanding;
   Computer-aided diagnosis; Domain translation; Lambertian reflection
AB Purpose A three-dimensional (3D) structure extraction technique viewed from a two-dimensional image is essential for the development of a computer-aided diagnosis (CAD) system for colonoscopy. However, a straightforward application of existing depth-estimation methods to colonoscopic images is impossible or inappropriate due to several limitations of colonoscopes. In particular, the absence of ground-truth depth for colonoscopic images hinders the application of supervised machine learning methods. To circumvent these difficulties, we developed an unsupervised and accurate depth-estimation method. Method We propose a novel unsupervised depth-estimation method by introducing a Lambertian-reflection model as an auxiliary task to domain translation between real and virtual colonoscopic images. This auxiliary task contributes to accurate depth estimation by maintaining the Lambertian-reflection assumption. In our experiments, we qualitatively evaluate the proposed method by comparing it with state-of-the-art unsupervised methods. Furthermore, we present two quantitative evaluations of the proposed method using a measuring device, as well as a new 3D reconstruction technique and measured polyp sizes. Results Our proposed method achieved accurate depth estimation with an average estimation error of less than 1 mm for regions close to the colonoscope in both of two types of quantitative evaluations. Qualitative evaluation showed that the introduced auxiliary task reduces the effects of specular reflections and colon wall textures on depth estimation and our proposed method achieved smooth depth estimation without noise, thus validating the proposed method. Conclusions We developed an accurate depth-estimation method with a new type of unsupervised domain translation with the auxiliary task. This method is useful for analysis of colonoscopic images and for the development of a CAD system since it can extract accurate 3D information.
C1 [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Mori, Yuichi] Univ Oslo, Gaustad Sykehus, Clin Effectiveness Res Grp, Bygg 20,Sognsvannsveien 21, N-0372 Oslo, Norway.
   [Mori, Yuichi; Misawa, Masashi; Kudo, Shin-Ei] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Tsuzuki Ku, Chigasaki Chuo 35-1, Yokohama, Kanagawa 2248503, Japan.
   [Imai, Kenichiro; Ito, Sayo; Hotta, Kinichi] Shizuoka Canc Ctr, Div Endoscopy, 1007 Shimonagakubo, Nagaizumi, Shizuoka 4118777, Japan.
   [Takabatake, Hirotsugu] Sapporo Minami Sanjo Hosp, Dept Resp Med, Chuo Ku, Nishi 6 Chome,Minami 3 Jo, Sapporo, Hokkaido 0600063, Japan.
   [Mori, Masaki] Sapporo Kosei Gen Hosp, Dept Resp Med, Chuo Ku, Higashi 8 Chome,Kita 3 Jo, Sapporo, Hokkaido 0600033, Japan.
   [Natori, Hiroshi] Keiwakai Nishioka Hosp, Dept Resp Med, Toyohira Ku, 1-52,4 Jo 4 Chome, Sapporo, Hokkaido 0620034, Japan.
C3 Nagoya University; University of Oslo; Showa University; Shizuoka Cancer
   Center; Sapporo Kosei General Hospital
RP Itoh, H (通讯作者)，Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM hitoh@mori.m.is.nagoya-u.ac.jp; moda@mori.m.is.nagoya-u.ac.jp;
   kensaku@is.nagoya-u.ac.jp
RI Misawa, Masashi/H-9004-2019; Itoh, Hayato/AAM-4022-2021
OI Misawa, Masashi/0000-0002-8520-2036; Itoh, Hayato/0000-0002-1410-1078;
   Oda, Masahiro/0000-0001-7714-422X
FU AMED [19hs0110006h0003]; JSPS MEXT KAKENHI [26108006, 17H00867,
   17K20099]; JSPS Bilateral Joint Research Project; Grants-in-Aid for
   Scientific Research [17K20099, 17H00867] Funding Source: KAKEN
FX This study was funded by Grants from AMED (19hs0110006h0003), JSPS MEXT
   KAKENHI (26108006, 17H00867, 17K20099), and the JSPS Bilateral Joint
   Research Project.
CR [Anonymous], 2008, EUR IT CHAPT C, P129, DOI DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136
   Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611
   Durr NJ, 2019, P KDDD 19 WORKSH APP
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hartley R. I., 2004, MULTIPLE VIEW GEOMET, V2nd, DOI 10.1016/S0143-8166(01)00145-2
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Kaufman, 2016, P SOC PHOTO-OPT INS, V9785, P549
   Ma FC, 2018, IEEE INT CONF ROBOT, P4796
   Ma RB, 2019, LECT NOTES COMPUT SC, V11768, P573, DOI 10.1007/978-3-030-32254-0_64
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Mathew S, 2020, PROC CVPR IEEE, P4695, DOI [10.1109/cvpr42600.2020.00475, 10.1109/CVPR42600.2020.00475]
   Mori K, 2003, PROC SPIE, V5031, P111, DOI 10.1117/12.480417
   Oda M, 2019, HEALTHC TECHNOL LETT, V6, P214, DOI 10.1049/htl.2019.0071
   Prados E, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P375, DOI 10.1007/0-387-28831-7_23
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Sandler M, 2017, P NIPS 2017 WORKSH M
   Saxena A., 2006, PROCEEDINS ADV NEURA, P1161, DOI [10.1109/TPAMI.2015.2505283a, DOI 10.1109/TPAMI.2015.2505283A]
   Wang CY, 2018, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2018.00216
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 24
TC 5
Z9 5
U1 1
U2 3
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD JUN
PY 2021
VL 16
IS 6
BP 989
EP 1001
DI 10.1007/s11548-021-02398-x
EA MAY 2021
PG 13
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA SK8ZM
UT WOS:000651338700002
PM 34002340
DA 2023-08-21
ER

PT J
AU Fang, YQ
   Zhu, DL
   Yao, JH
   Yuan, YX
   Tong, KY
AF Fang, Yuqi
   Zhu, Delong
   Yao, Jianhua
   Yuan, Yixuan
   Tong, Kai-Yu
TI ABC-Net: Area-Boundary Constraint Network With Dynamical Feature
   Selection for Colorectal Polyp Segmentation
SO IEEE SENSORS JOURNAL
LA English
DT Article
DE Feature extraction; Image segmentation; Decoding; Shape; Sensors;
   Machine learning; Colonoscopy; Area-boundary constraint; colorectal
   polyp segmentation; deep learning
ID SEMANTIC SEGMENTATION
AB Untreated colorectal polyps can develop into colorectal cancer, which is a leading cause of cancer-related deaths. Colonoscopy is a commonly-used method for colorectal polyp scanning, but limited to the experience and subjectivity of clinicians, one out of four polyps cannot be correctly recognized. In this article, we propose an automatic colorectal polyp segmentation system based on the deep convolutional neural network, aiming to improve the accuracy of colorectal polyp scanning. The proposed ABC-Net is comprised of a shared encoder and two novel mutually-constrained decoders for simultaneous polyp area and boundary segmentation. To sufficiently exploit multi-scale image information, the selective feature modules are embedded into the network and used for dynamically learning and fusing multi-scale feature representations. Furthermore, a new boundary-sensitive loss is proposed to model the interdependencies between the area and boundary branches, the information of the two branches are reciprocally propagated and constrained, yielding a significant improvement in segmentation accuracy. Extensive experiments are conducted on three public colorectal polyp datasets, and the results, e.g., F1 scores are 0.866, 0.915, 0.874 in EndoScene, Kvasir-SEG, and ETIS-Larib datasets, demonstrate the advantages of the proposed method.
C1 [Fang, Yuqi; Zhu, Delong; Yuan, Yixuan] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Fang, Yuqi; Yao, Jianhua] Tencent AI Lab, AI Healthcare, Shenzhen 518057, Peoples R China.
   [Tong, Kai-Yu] Chinese Univ Hong Kong, Dept Biomed Engn, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong; Tencent; Chinese University of Hong
   Kong
RP Yuan, YX (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.; Tong, KY (通讯作者)，Chinese Univ Hong Kong, Dept Biomed Engn, Hong Kong, Peoples R China.
EM fangyuqi@link.cuhk.edu.hk; zhudelong@link.cuhk.edu.hk;
   jianhuayao@tencent.com; yxyuan.ee@cityu.edu.hk; kytong@cuhk.edu.hk
RI Yao, Jianhua/GQZ-6627-2022; Tong, Raymond Kai-yu/C-3546-2009; Fang,
   Yuqi/GXN-3593-2022
OI Yao, Jianhua/0000-0001-9157-9596; Tong, Raymond
   Kai-yu/0000-0003-4375-653X; Yuan, Yixuan/0000-0002-0853-6948; Zhu,
   Delong/0000-0002-1143-7860
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], 2007, P ICIP
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen LC, 2018, ADV NEUR IN, V31
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cui XM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192220
   Dou Q, 2017, MED IMAGE ANAL, V41, P40, DOI 10.1016/j.media.2017.05.001
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Haocheng Shen, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P433, DOI 10.1007/978-3-319-66185-8_49
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kumeda B, 2019, I C COMM SOFTW NET, P682, DOI 10.1109/ICCSN.2019.8905362
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Ni JJ, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2019.105121
   Oda H, 2018, LECT NOTES COMPUT SC, V11071, P228, DOI 10.1007/978-3-030-00934-2_26
   Qi Dou, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P149, DOI 10.1007/978-3-319-46723-8_18
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Sun X., 2019, ARXIV191211947
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tan CW, 2018, I S BIOMED IMAGING, P1221, DOI 10.1109/ISBI.2018.8363791
   Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324
   Vazquez D., 2017, J HEALTHC ENG, P1
   Wicke Kai, 2018, 2018 AIAA Aerospace Sciences Meeting, P1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yang Y, 2019, IEEE SIGNAL PROC LET, V26, P1877, DOI 10.1109/LSP.2019.2952047
   Yuan Y., 2018, OCNET OBJECT CONTEXT
   Zhang M, 2020, IEEE J BIOMED HEALTH, V24, P3095, DOI 10.1109/JBHI.2020.3000484
   Zhang M, 2020, I S BIOMED IMAGING, P144, DOI 10.1109/ISBI45749.2020.9098354
   Zhao J, 2019, I S BIOMED IMAGING, P1514, DOI 10.1109/ISBI.2019.8759262
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 45
TC 13
Z9 14
U1 6
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1530-437X
EI 1558-1748
J9 IEEE SENS J
JI IEEE Sens. J.
PD MAY 15
PY 2021
VL 21
IS 10
BP 11799
EP 11809
DI 10.1109/JSEN.2020.3015831
PG 11
WC Engineering, Electrical & Electronic; Instruments & Instrumentation;
   Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation; Physics
GA RP8ZO
UT WOS:000642012400057
DA 2023-08-21
ER

PT J
AU Qian, ZQ
   Lv, Y
   Lv, DY
   Gu, HJ
   Wang, KY
   Zhang, WJ
   Gupta, MM
AF Qian, Zhiqin
   Lv, Yi
   Lv, Dongyuan
   Gu, Huijun
   Wang, Kunyu
   Zhang, Wenjun
   Gupta, Madan M.
TI A New Approach to Polyp Detection by Pre-Processing of Images and
   Enhanced Faster R-CNN
SO IEEE SENSORS JOURNAL
LA English
DT Article
DE Reflection; Image color analysis; Colonoscopy; Cancer; Feature
   extraction; Colonic polyps; Deep learning; Colonoscopy; image
   pre-processing; polyp detection; faster region-based convolutional
   neural network (faster R-CNN)
ID BIG DATA; VALIDATION; DIAGNOSIS
AB Colon cancer is the third most common cancer in the world, and it is increasingly threatening people's health. Early diagnosis is crucial to reducing the threat; however, the chance of missed polyps in today's colonoscopy examination is still high (about 10%) due to limitations in diagnosis techniques and data analysis methods. The colonoscope is a kind of robot and on its tip there is a camera to acquire images. This paper presents a study aimed to improve the rate of successful diagnosis with a new image data analysis approach based on the faster regional convolutional neural network (faster R-CNN). This new approach has two steps for data analysis: (i) pre-processing of images to characterize polyps, and (ii) incorporating of the result of the pre-processing into the faster R-CNN. Specifically, the pre-processing of colonoscopy was expected to reduce the influence of specular reflections, resulting in an improved image, upon which the faster R-CNN algorithm was aplied. There are several improvements of the faster r-CNN tailoring to the task of colon polyps detection. To confirm the superiority of this new approach, the mean average precision (mAP) was used to compare the results obtained with the new approach and the faster R-CNN algorithm. The experimental result shows that the mAP of the new approach is 91.43%, as opposed to 90.57% with the faster R-CNN, which shows a significant improvement.
C1 [Qian, Zhiqin; Lv, Yi; Lv, Dongyuan; Gu, Huijun; Wang, Kunyu] East China Univ Sci & Technol, Complex & Intelligent Syst Res Lab CISRL, Sch Mech & Power Engn, Shanghai 200237, Peoples R China.
   [Zhang, Wenjun; Gupta, Madan M.] Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai 200444, Peoples R China.
   [Zhang, Wenjun; Gupta, Madan M.] Univ Saskatchewan, Dept Mech Engn, Saskatoon, SK S7N 5A2, Canada.
C3 East China University of Science & Technology; Shanghai University;
   University of Saskatchewan
RP Qian, ZQ (通讯作者)，East China Univ Sci & Technol, Complex & Intelligent Syst Res Lab CISRL, Sch Mech & Power Engn, Shanghai 200237, Peoples R China.; Zhang, WJ (通讯作者)，Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai 200444, Peoples R China.
EM qianzhiqin@ecust.edu.cn; lv15325155581@163.com; dongyuanlv@126.com;
   freda1421@163.com; 849545512@qq.com; chris.zhang@usask.ca;
   madan.gupta@usask.ca
RI Zhang, WJ/A-8248-2010; Zhang, Wanying/IXD-8104-2023; Zhang,
   wen/ITT-1192-2023; Gupta, Madan M/D-3607-2009
OI Zhang, Wenjun/0000-0001-7973-8769; Lv, Dongyuan/0000-0003-4109-5491;
   Qian, Zhiqin/0000-0002-3460-2806
FU SHRF Grant of Canada; Program of Production, Research and Development of
   Minhang District of Shanghai [2019MHC107]
FX The involvement of Wenjun Zhang on this work has been partially
   supported by SHRF Grant of Canada. This article has also been partially
   supported by the Program of Production, Research and Development of
   Minhang District of Shanghai through a funding Grant (Grant No:
   2019MHC107) to Zhiqin Qian. The associate editor coordinating the review
   of this article and approving it for publication was Dr. Julio C.
   Rodriguez-Quinonez.
CR Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bi ZM, 2017, ENTERP INF SYST-UK, V11, P949, DOI 10.1080/17517575.2016.1258734
   Bi ZM, 2014, J MANAG ANAL, V1, P249, DOI 10.1080/23270012.2014.992985
   Cheng WB, 2012, DIGEST ENDOSC, V24, P1, DOI 10.1111/j.1443-1661.2011.01181.x
   Cheng WB, 2013, ANN BIOMED ENG, V41, P1084, DOI 10.1007/s10439-013-0746-1
   El Khatib A, 2015, IEEE ENG MED BIO, P2669, DOI 10.1109/EMBC.2015.7318941
   Hu XH, 2019, IEEE-ASME T MECH, V24, P1785, DOI 10.1109/TMECH.2019.2928786
   Hu XH, 2018, COMPUT ASSIST SURG, V23, P21, DOI 10.1080/24699322.2018.1526972
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61760-2
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Modi S, 2011, IEEE-ASME T MECH, V16, P874, DOI 10.1109/TMECH.2011.2161094
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Sargent D, 2016, PROC SPIE, V9784, DOI 10.1117/12.2217123
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Vaduva C, 2012, EUR SIGNAL PR CONF, P2506
   von Karsa L, 2013, ENDOSCOPY, V45, P51, DOI 10.1055/s-0032-1325997
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang WJ, 2011, CIRP ANN-MANUF TECHN, V60, P469, DOI 10.1016/j.cirp.2011.03.041
   Zhang WJ, 2010, ENTERP INF SYST-UK, V4, P99, DOI 10.1080/17517571003763380
   Zhang W, 2019, AGING MENT HEALTH, V23, P1113, DOI 10.1080/13607863.2018.1480705
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 33
TC 10
Z9 10
U1 1
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1530-437X
EI 1558-1748
J9 IEEE SENS J
JI IEEE Sens. J.
PD MAY 15
PY 2021
VL 21
IS 10
BP 11374
EP 11381
DI 10.1109/JSEN.2020.3036005
PG 8
WC Engineering, Electrical & Electronic; Instruments & Instrumentation;
   Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation; Physics
GA RP8ZO
UT WOS:000642012400016
DA 2023-08-21
ER

PT J
AU Liew, WS
   Tang, TB
   Lin, CH
   Lu, CK
AF Liew, Win Sheng
   Tang, Tong Boon
   Lin, Cheng-Hung
   Lu, Cheng-Kai
TI Automatic colonic polyp detection using integration of modified deep
   residual convolutional neural network and ensemble learning approaches
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE colorectal cancer (CRC); polyps; deep residual network; principal
   component analysis; AdaBoost ensemble learning
ID COLONOSCOPY
AB Background and Objective: The increased incidence of colorectal cancer (CRC) and its mortality rate have attracted interest in the use of artificial intelligence (AI) based computer-aided diagnosis (CAD) tools to detect polyps at an early stage. Although these CAD tools have thus far achieved a good accuracy level to detect polyps, they still have room to improve further (e.g. sensitivity). Therefore, a new CAD tool is developed in this study to detect colonic polyps accurately. Methods: In this paper, we propose a novel approach to distinguish colonic polyps by integrating several techniques, including a modified deep residual network, principal component analysis and AdaBoost ensemble learning. A powerful deep residual network architecture, ResNet-50, was investigated to reduce the computational time by altering its architecture. To keep the interference to a minimum, median filter, image thresholding, contrast enhancement, and normalisation techniques were exploited on the endoscopic images to train the classification model. Three publicly available datasets, i.e., Kvasir, ETISLaribPolypDB, and CVC-ClinicDB, were merged to train the model, which included images with and without polyps. Results: The proposed approach trained with a combination of three datasets achieved Matthews Correlation Coefficient (MCC) of 0.9819 with accuracy, sensitivity, precision, and specificity of 99.10%, 98.82%, 99.37%, and 99.38%, respectively. Conclusions: These results show that our method could repeatedly classify endoscopic images automatically and could be used to effectively develop computer-aided diagnostic tools for early CRC detection. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liew, Win Sheng; Tang, Tong Boon; Lu, Cheng-Kai] Univ Teknol PETRONAS, Dept Elect & Elect Engn, Seri Iskandar 32610, Perak, Malaysia.
   [Lin, Cheng-Hung] Yuan Ze Univ, Dept Elect Engn, Jhongli 32003, Taiwan.
   [Lin, Cheng-Hung] Yuan Ze Univ, Biomed Engn Res Ctr, Jhongli 32003, Taiwan.
C3 Universiti Teknologi Petronas; Yuan Ze University; Yuan Ze University
RP Lu, CK (通讯作者)，Univ Teknol PETRONAS, Dept Elect & Elect Engn, Seri Iskandar 32610, Perak, Malaysia.
EM chengkai.lu@utp.edu.my
RI Tang, Tong Boon/G-5610-2011; Lin, Cheng-Hung/V-5553-2019
OI Tang, Tong Boon/0000-0002-5721-6828; Lin,
   Cheng-Hung/0000-0001-8373-2271; Lu, ChengKai/0000-0002-5819-0754
FU Ministry of Higher Education, Malaysia [FRGS/1/2020/TK0/UTP/02/23]
FX This work was supported by Ministry of Higher Education, Malaysia, under
   Grant FRGS/1/2020/TK0/UTP/02/23.
CR [Anonymous], 2019, ADABOOST ALG QUICK S
   [Anonymous], PERFORMANCE COMP DIM
   Ansari A, 2014, PROCEEDINGS 2014 4TH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE WITH APPLICATIONS IN ENGINEERING AND TECHNOLOGY ICAIET 2014, P31, DOI 10.1109/ICAIET.2014.15
   Azer SA, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55080473
   Benkaddour MK, 2017, TRAIT SIGNAL, V34, P77, DOI 10.3166/TS.34.77-91
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bour A, 2019, IEEE INT SYMP SIGNAL, DOI [10.1109/CLEOE-EQEC.2019.8872891, 10.1109/isspit47144.2019.9001816]
   Canziani Alfredo, 2016, ARXIV
   Chandan S, 2021, GASTROINTEST ENDOSC, V93, P68, DOI 10.1016/j.gie.2020.06.015
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ethem A, 2009, INTRO MACHINE LEARNI
   Gueye L, 2015, IEEE IMAGE PROC, P1061, DOI 10.1109/ICIP.2015.7350962
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heitman SJ, 2009, CLIN GASTROENTEROL H, V7, P1272, DOI 10.1016/j.cgh.2009.05.032
   Ibrahim MFI, 2016, CAIRO INT BIOM ENG, P68, DOI 10.1109/CIBEC.2016.7836122
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kim DH, 2007, AM J ROENTGENOL, V188, P940, DOI 10.2214/AJR.06.0764
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumar G, 2014, INT C ADV COMPUT COM, P5, DOI 10.1109/ACCT.2014.74
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Lieberman DA, 2000, NEW ENGL J MED, V343, P162, DOI 10.1056/NEJM200007203430301
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu X, 2019, SPRINGER THESES-RECO, P1, DOI 10.1007/978-981-13-8703-6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HJ, 2019, COGN SYST RES, V53, P111, DOI 10.1016/j.cogsys.2018.01.006
   Lu HJ, 2017, NEUROCOMPUTING, V228, P270, DOI 10.1016/j.neucom.2016.09.077
   Mahendra KV., 2019, EC GASTROENTEROL DIG, V6, P663
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Meng J, 2020, OPEN LIFE SCI, V15, P588, DOI 10.1515/biol-2020-0055
   Nadimi ES, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106531
   Nagendran M, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m689
   Nelikanti A, 2014, COLORECTAL CANC MRI, V6, P7
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Paik DS, 2004, IEEE T MED IMAGING, V23, P661, DOI 10.1109/TMI.2004.826362
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Pandian A.A, 2016, SURVEY ANAL PREPROCE
   Pang SC, 2020, IEEE ACCESS, V8, P4799, DOI 10.1109/ACCESS.2019.2962862
   Park HC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051650
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pouriyeh S, 2017, IEEE SYMP COMP COMMU, P204, DOI 10.1109/ISCC.2017.8024530
   Rabinovich A, ARXIV14094842CS2014
   Ren YC, 2018, IEEE ACCESS, V6, P74506, DOI 10.1109/ACCESS.2018.2874803
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Sareena, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 1, P96
   Shakir H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45053-x
   Sharon H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010167
   Shi LM, 2010, NAT BIOTECHNOL, V28, P827, DOI 10.1038/nbt.1665
   Shie CK, 2015, IEEE ENG MED BIO, P711, DOI 10.1109/EMBC.2015.7318461
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Simonyan K., ARXIV
   Sivarajah S., 2020, DIMENSIONALITY REDUC
   Stoitsis J, 2006, NUCL INSTRUM METH A, V569, P591, DOI 10.1016/j.nima.2006.08.134
   Su ZQ, 2014, NAT BIOTECHNOL, V32, P903, DOI 10.1038/nbt.2957
   Sumiyama K, 2021, DIGEST ENDOSC, V33, P218, DOI 10.1111/den.13837
   Tajbakhsh N, 2014, I S BIOMED IMAGING, P97, DOI 10.1109/ISBI.2014.6867818
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vink JP, 2015, ARTIF INTELL REV, V43, P125, DOI 10.1007/s10462-012-9366-7
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Wei JW, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.3398
   Whitley D., 1995, SCIENCE, V3, P203
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Xiao Dong Zeng, 2011, Proceedings of the 2011 International Conference on System Science and Engineering (ICSSE), P320, DOI 10.1109/ICSSE.2011.5961921
   Yu Han Liu, 2018, Journal of Physics: Conference Series, V1087, DOI 10.1088/1742-6596/1087/6/062032
   Yuan HX, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.01719
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang WS, 2009, 2009 INTERNATIONAL JOINT CONFERENCE ON BIOINFORMATICS, SYSTEMS BIOLOGY AND INTELLIGENT COMPUTING, PROCEEDINGS, P242, DOI 10.1109/IJCBS.2009.23
   Zhang WW, 2015, GENOME BIOL, V16, DOI 10.1186/s13059-015-0581-9
   Zhou DJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16777-6
   Zhu MZ, 2017, I C MECH MACH VIS PR, P12
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
NR 74
TC 18
Z9 18
U1 1
U2 12
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD JUL
PY 2021
VL 206
AR 106114
DI 10.1016/j.cmpb.2021.106114
EA MAY 2021
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA SU8XR
UT WOS:000663415100005
PM 33984661
DA 2023-08-21
ER

PT J
AU Kliegis, L
   Obst, W
   Bruns, J
   Weigt, J
AF Kliegis, Leon
   Obst, Wilfried
   Bruns, Johannes
   Weigt, Jochen
TI Can a Polyp Detection and Characterization System Predict Complete
   Resection?
SO DIGESTIVE DISEASES
LA English
DT Article
DE Artificial intelligence; Polyp detection software; Polypectomy; Polyp
   resection
AB Introduction: Artificial Intelligence (AI) is one of the most evolving fields in endoscopy. We aimed to test if a system for polyp detection and polyp characterization can be used to predict complete endoscopic resection of colon adenomas. Methods: We used the CAD-Eye AI system (Fujifilm Europe) in consecutive patients who received polypectomy using a cold snare. After resection, the submucosal space was flushed with water using an irrigation pump. Images were obtained using the CAD Eye system, and the characterization of the system was noted and afterward compared to histology of the removed specimen. Results: In total, 17 polypectomies were observed, and in no case the AI was able to give information about resection status. First, the resection plane itself was classified as being adenomatous in all cases, while, second, all adenomas were resected completely, thus harboring no potential for overlying misinterpretations in the images. Conclusion: An AI system trained to characterize polyps in healthy surrounding colorectal mucosa cannot predict the state of resection after removal of the adenoma. This is explained by the training and programming. Endoscopists using AI from now on should learn about the basics of AI and the pitfalls in interpreting results from AI.
C1 [Kliegis, Leon; Obst, Wilfried; Bruns, Johannes; Weigt, Jochen] Otto von Guericke Univ, Dept Gastroenterol Hepatol & Infect Dis, Magdeburg, Germany.
C3 Otto von Guericke University
RP Weigt, J (通讯作者)，Otto von Guericke Univ, Dept Gastroenterol Hepatol & Infect Dis, Magdeburg, Germany.
EM jochen.weigt@med.ovgu.de
OI Weigt, Jochen/0000-0002-3334-2168
CR Cho BJ, 2020, AM J GASTROENTEROL, V115, P70, DOI 10.14309/ajg.0000000000000476
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
NR 3
TC 1
Z9 1
U1 0
U2 1
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0257-2753
EI 1421-9875
J9 DIGEST DIS
JI Dig. Dis.
PY 2022
VL 40
IS 1
BP 115
EP 118
DI 10.1159/000516974
EA MAY 2021
PG 4
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA 3D9HJ
UT WOS:000700023500001
PM 33940578
OA hybrid
DA 2023-08-21
ER

PT J
AU Deliwala, SS
   Hamid, K
   Barbarawi, M
   Lakshman, H
   Zayed, Y
   Kandel, P
   Malladi, S
   Singh, A
   Bachuwa, G
   Gurvits, GE
   Chawla, S
AF Deliwala, Smit S.
   Hamid, Kewan
   Barbarawi, Mahmoud
   Lakshman, Harini
   Zayed, Yazan
   Kandel, Pujan
   Malladi, Srikanth
   Singh, Adiraj
   Bachuwa, Ghassan
   Gurvits, Grigoriy E.
   Chawla, Saurabh
TI Artificial intelligence (AI) real-time detection vs. routine colonoscopy
   for colorectal neoplasia: a meta-analysis and trial sequential analysis
SO INTERNATIONAL JOURNAL OF COLORECTAL DISEASE
LA English
DT Review
DE Deep learning; Automatic detection; CADe; CADx; Computer-aided detection
ID COMPUTER-AIDED DETECTION; FUTURE
AB Goals and background Studies analyzing artificial intelligence (AI) in colonoscopies have reported improvements in detecting colorectal cancer (CRC) lesions, however its utility in the realworld remains limited. In this systematic review and meta-analysis, we evaluate the efficacy of AI-assisted colonoscopies against routine colonoscopy (RC). Study We performed an extensive search of major databases (through January 2021) for randomized controlled trials (RCTs) reporting adenoma and polyp detection rates. Odds ratio (OR) and standardized mean differences (SMD) with 95% confidence intervals (CIs) were reported. Additionally, trial sequential analysis (TSA) was performed to guard against errors. Results Six RCTs were included (4996 participants). The mean age (SD) was 51.99 (4.43) years, and 49% were females. Detection rates favored AI over RC for adenomas (OR 1.77; 95% CI: 1.570-2.08) and polyps (OR 1.91; 95% CI: 1.68-2.16). Secondary outcomes including mean number of adenomas (SMD 0.23; 95% CI: 0.18-0.29) and polyps (SMD 0.23; 95% CI: 0.17-0.29) detected per procedure favored AI. However, RC outperformed AI in detecting pedunculated polyps. Withdrawal times (WTs) favored AI when biopsies were included, while WTs without biopsies, cecal intubation times, and bowel preparation adequacy were similar. Conclusions Colonoscopies equipped with AI detection algorithms could significantly detect previously missed adenomas and polyps while retaining the ability to self-assess and improve periodically. More effective clearance of diminutive adenomas may allow lengthening in surveillance intervals, reducing the burden of surveillance colonoscopies, and increasing its accessibility to those at higher risk. TSA ruled out the risk for false-positive results and confirmed a sufficient sample size to detect the observed effect. Currently, these findings suggest that AI-assisted colonoscopy can serve as a useful proxy to address critical gaps in CRC identification.
C1 [Deliwala, Smit S.; Barbarawi, Mahmoud; Lakshman, Harini; Zayed, Yazan; Kandel, Pujan; Bachuwa, Ghassan] Michigan State Univ, Hurley Med Ctr, Dept Internal Med, Two Hurley Plaza,Ste 212, Flint, MI 48503 USA.
   [Hamid, Kewan; Malladi, Srikanth; Singh, Adiraj] Michigan State Univ, Hurley Med Ctr, Dept Internal Med Pediat, Flint, MI USA.
   [Gurvits, Grigoriy E.] NYU, Langone Med Ctr, Dept Internal Med, Div Gastroenterol, New York, NY USA.
   [Chawla, Saurabh] Emory Univ, Dept Internal Med, Div Gastroenterol, Atlanta, GA 30322 USA.
C3 Michigan State University; Michigan State University; New York
   University; NYU Langone Medical Center; Emory University
RP Deliwala, SS (通讯作者)，Michigan State Univ, Hurley Med Ctr, Dept Internal Med, Two Hurley Plaza,Ste 212, Flint, MI 48503 USA.
EM deliwal1@msu.edu
OI Deliwala, Smit/0000-0001-5239-9533
CR Adler A, 2012, CLIN GASTROENTEROL H, V10, P155, DOI 10.1016/j.cgh.2011.10.026
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   ASGE Endoscopy Unit Quality Indicator Taskforce, 2017, VideoGIE, V2, P119, DOI 10.1016/j.vgie.2017.02.007
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Azer SA, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55080473
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bharadwaj S., 2019, J CLIN GASTROENTEROL, P1
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Carneiro G, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101653
   Cheung D, 2016, GASTROINTEST ENDOSC, V84, P287, DOI 10.1016/j.gie.2016.01.047
   Crockett SD, 2018, ENDOSCOPY, V50, P984, DOI 10.1055/a-0597-1740
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   Hassan C, 2021, GASTROINTEST ENDOSC, V93, P77, DOI 10.1016/j.gie.2020.06.059
   Kang XY, 2018, AM J GASTROENTEROL, V113, P601, DOI 10.1038/ajg.2018.25
   Ketwaroo GA, 2015, CURR OPIN GASTROEN, V31, P56, DOI 10.1097/MOG.0000000000000140
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Liu D, 2020, EUR J GASTROEN HEPAT
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   McGill SK, 2015, GUT, V64, P184, DOI 10.1136/gutjnl-2013-305743
   Mohan BP, 2020, ECLINICALMEDICINE, V29-30, DOI 10.1016/j.eclinm.2020.100622
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1186/s13643-015-0087-2, 10.1136/bmj.b2535]
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   SIEGEL RL, 2020, CA-CANCER J CLIN, P1
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2022, NEUROCRIT CARE, V37, P424, DOI 10.1007/s12028-021-01421-y
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 34
TC 18
Z9 18
U1 0
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0179-1958
EI 1432-1262
J9 INT J COLORECTAL DIS
JI Int. J. Colorectal Dis.
PD NOV
PY 2021
VL 36
IS 11
BP 2291
EP 2303
DI 10.1007/s00384-021-03929-3
EA MAY 2021
PG 13
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA WF2VM
UT WOS:000647547200001
PM 33934173
OA Bronze
DA 2023-08-21
ER

PT J
AU Grosu, S
   Wesp, P
   Graser, A
   Maurus, S
   Schulz, C
   Knosel, T
   Cyran, CC
   Ricke, J
   Ingrisch, M
   Kazmierczak, PM
AF Grosu, Sergio
   Wesp, Philipp
   Graser, Anno
   Maurus, Stefan
   Schulz, Christian
   Knoesel, Thomas
   Cyran, Clemens C.
   Ricke, Jens
   Ingrisch, Michael
   Kazmierczak, Philipp M.
TI Machine Learning-based Differentiation of Benign and Premalignant
   Colorectal Polyps Detected with CT Colonography in an Asymptomatic
   Screening Population: A Proof-of-Concept Study
SO RADIOLOGY
LA English
DT Article
ID CANCER; COLONOSCOPY; RADIOMICS; PARTICIPATION; PREVENTION; DIAGNOSIS;
   ADENOMA; IMAGES; RATES; RISK
AB Background: CT colonography does not enable definite differentiation between benign and premalignant colorectal polyps.
   Purpose: To perform machine learning-based differentiation of benign and premalignant colorectal polyps detected with CT colonography in an average-risk asymptomatic colorectal cancer screening sample with external validation using radiomics.
   Materials and Methods: In this secondary analysis of a prospective trial, colorectal polyps of all size categories and morphologies were manually segmented on CT colonographic images and were classified as benign (hyperplastic polyp or regular mucosa) or premalignant (adenoma) according to the histopathologic reference standard. Quantitative image features characterizing shape (n = 14), gray level histogram statistics (n = 18), and image texture (n = 68) were extracted from segmentations after applying 22 image filters, resulting in 1906 feature-filter combinations. Based on these features, a random forest classification algorithm was trained to predict the individual polyp character. Diagnostic performance was validated in an external test set.
   Results: The random forest model was fitted using a training set consisting of 107 colorectal polyps in 63 patients (mean age, 63 years +/- 8 [standard deviation]; 40 men) comprising 169 segmentations on CT colonographic images. The external test set included 77 polyps in 59 patients comprising 118 segmentations. Random forest analysis yielded an area under the receiver operating characteristic curve of 0.91 (95% CI: 0.85, 0.96), a sensitivity of 82% (65 of 79) (95% CI: 74%, 91%), and a specificity of 85% (33 of 39) (95% CI: 72%, 95%) in the external test set. In two subgroup analyses of the external test set, the area under the receiver operating characteristic curve was 0.87 in the size category of 6-9 mm and 0.90 in the size category of 10 mm or larger. The most important image feature for decision making (relative importance of 3.7%) was quantifying first-order gray level histogram statistics.
   Conclusion: In this proof-of-concept study, machine learning-based image analysis enabled noninvasive differentiation of benign and premalignant colorectal polyps with CT colonography. (C) RSNA, 2021
C1 [Grosu, Sergio; Wesp, Philipp; Maurus, Stefan; Cyran, Clemens C.; Ricke, Jens; Ingrisch, Michael; Kazmierczak, Philipp M.] Ludwig Maximilians Univ Munchen, Univ Hosp, Dept Radiol, Marchioninistr 15, D-81377 Munich, Germany.
   [Schulz, Christian] Ludwig Maximilians Univ Munchen, Univ Hosp, Dept Med 2, Marchioninistr 15, D-81377 Munich, Germany.
   [Knoesel, Thomas] Ludwig Maximilians Univ Munchen, Univ Hosp, Dept Pathol, Marchioninistr 15, D-81377 Munich, Germany.
   [Graser, Anno] Radiol Munchen, Munich, Germany.
C3 University of Munich; University of Munich; University of Munich
RP Grosu, S (通讯作者)，Ludwig Maximilians Univ Munchen, Univ Hosp, Dept Radiol, Marchioninistr 15, D-81377 Munich, Germany.
EM sergio.grosu@med.uni-muenchem.de
RI Wesp, Philipp/HNO-9426-2023; Wesp, Philipp/AAW-2195-2021
OI Wesp, Philipp/0000-0001-7356-3371; Wesp, Philipp/0000-0001-7356-3371;
   Grosu, Sergio/0000-0002-9093-6499; Schulz, Christian/0000-0003-1841-1337
FU FoFoLe, Faculty of Medicine, Ludwig-Maximilians-Universitat Munchen
FX Supported by FoFoLe, Faculty of Medicine, Ludwig-Maximilians-Universitat
   Munchen (S.G., P.W.).
CR Aman JM, 2010, PROC SPIE, V7624, DOI 10.1117/12.844571
   Atkin W, 2013, LANCET, V381, P1194, DOI 10.1016/S0140-6736(12)62186-2
   Baessler B, 2019, INVEST RADIOL, V54, P221, DOI 10.1097/RLI.0000000000000530
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Carpenter J, 2000, STAT MED, V19, P1141, DOI 10.1002/(SICI)1097-0258(20000515)19:9<1141::AID-SIM479>3.0.CO;2-F
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Ferlay J, 2018, EUR J CANCER, V103, P356, DOI 10.1016/j.ejca.2018.07.005
   Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169
   Graser A, 2009, GUT, V58, P241, DOI 10.1136/gut.2008.156448
   Hastie T., 2017, ELEMENTS STAT LEARNI, DOI DOI 10.1007/978-0-387-84858-7
   Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996
   Kim DH, 2007, NEW ENGL J MED, V357, P1403, DOI 10.1056/NEJMoa070543
   Kumar V., 2013, ROBBINS BASIC PATHOL
   Laghi A, 2015, RADIOL MED, V120, P1021, DOI 10.1007/s11547-015-0537-x
   Liu ZY, 2019, THERANOSTICS, V9, P1303, DOI 10.7150/thno.30309
   MANDEL JS, 1993, NEW ENGL J MED, V328, P1365, DOI 10.1056/NEJM199305133281901
   Meyer M, 2019, RADIOLOGY, V293, P583, DOI 10.1148/radiol.2019190928
   Nolden M, 2013, INT J COMPUT ASS RAD, V8, P607, DOI 10.1007/s11548-013-0840-8
   Parekh V, 2016, EXPERT REV PRECIS ME, V1, P207, DOI 10.1080/23808993.2016.1164013
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pooler BD, 2016, RADIOLOGY, V278, P422, DOI 10.1148/radiol.2015150294
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   SALI L, 2015, JNCI-J NATL CANCER I, V108, P319, DOI DOI 10.1093/JNCI/DJV319
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Song BW, 2014, INT J COMPUT ASS RAD, V9, P1021, DOI 10.1007/s11548-014-0991-2
   Stoop EM, 2012, LANCET ONCOL, V13, P55, DOI 10.1016/S1470-2045(11)70283-2
   Summers RM, 2009, AM J ROENTGENOL, V193, P1305, DOI 10.2214/AJR.09.2442
   van der Meulen MP, 2018, RADIOLOGY, V287, P901, DOI 10.1148/radiol.2017162359
   van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yang L, 2018, EUR RADIOL, V28, P2058, DOI 10.1007/s00330-017-5146-8
   YOUDEN WJ, 1950, BIOMETRICS, V6, P172, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zwanenburg A, 2020, RADIOLOGY, V295, P328, DOI 10.1148/radiol.2020191145
NR 38
TC 12
Z9 12
U1 3
U2 14
PU RADIOLOGICAL SOC NORTH AMERICA (RSNA)
PI OAK BROOK
PA 820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES
SN 0033-8419
J9 RADIOLOGY
JI Radiology
PD MAY
PY 2021
VL 299
IS 2
BP 326
EP 335
DI 10.1148/radiol.2021202363
PG 10
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA RT6IL
UT WOS:000644562200033
PM 33620287
DA 2023-08-21
ER

PT J
AU Kim, KO
   Kim, EY
AF Kim, Kyeong Ok
   Kim, Eun Young
TI Application of Artificial Intelligence in the Detection and
   Characterization of Colorectal Neoplasm
SO GUT AND LIVER
LA English
DT Review
DE Polyp; Colon; Colonoscopy; Artificial intelligence; Convolutional neural
   network
ID COMPUTER-AIDED DIAGNOSIS; QUANTITATIVE-ANALYSIS; QUALITY INDICATORS;
   POLYP HISTOLOGY; SYSTEM; CLASSIFICATION; LESIONS; ENDOSCOPY; CANCER;
   ENDOCYTOSCOPY
AB Endoscpists always have tried to pursue a perfect colonoscopy, and application of artificial intelligence (AI) using deep-learning algorithms is one of the promising supportive options for detection and characterization of colorectal polyps during colonoscopy. Many retrospective studies conducted with real-time application of AI using convolutional neural networks have shown improved colorectal polyp detection. Moreover, a recent randomized clinical trial reported additional polyp detection with shorter analysis time. Studies conducted regarding polyp characterization provided additional promising results. Application of AI with narrow band imaging in real-time prediction of the pathology of diminutive polyps resulted in high diagnostic accuracy. In addition, application of AI with endocytoscopy or confocal laser endomicroscopy was investigated for real-time cellular diagnosis, and the diagnostic accuracy of some studies was comparable to that of pathologists. With AI technology, we can expect a higher polyp detection rate with reduced time and cost by avoiding unnecessary procedures, resulting in enhanced colonoscopy efficiency. However, for AI application in actual daily clinical practice, more prospective studies with minimized selection bias, consensus on standardized utilization, and regulatory approval are needed.
C1 [Kim, Kyeong Ok] Yeungnam Univ, Dept Internal Med, Div Gastroenterol & Hepatol, Coll Med, Daegu, South Korea.
   [Kim, Eun Young] Daegu Catholic Univ, Dept Internal Med, Div Gastroenterol & Hepatol, Sch Med, Daegu, South Korea.
C3 Yeungnam University; Catholic University of Daegu
RP Kim, EY (通讯作者)，Daegu Catholic Univ, Dept Internal Med, Div Gastroenterol & Hepatol, Sch Med, Daegu, South Korea.
EM kimey@cu.ac.kr
RI Kim, Eun Young/AGV-8193-2022
OI Kim, Kyeong Ok/0000-0001-5799-7436; Kim, Eun Young/0000-0003-3965-9964
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   American Cancer Society, 2019, CANC FACTS FIGURES 2
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], 2015, DEEP LEARNING NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   Arita K, 2011, ONCOL REP, V26, P43, DOI 10.3892/or.2011.1287
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Castaneda D, 2018, GASTROINTEST ENDOSC, V88, P209, DOI 10.1016/j.gie.2018.03.022
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chinzei K, 2018, ADV BIOMED ENG, V7, P118, DOI 10.14326/abe.7.118
   Choi J, 2020, CLIN ENDOSC, V53, P117, DOI 10.5946/ce.2020.054
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hoerter Nicholas, 2020, Curr Treat Options Gastroenterol, DOI 10.1007/s11938-020-00274-2
   Ichimasa K, 2018, ENDOSCOPY, V50, P230, DOI 10.1055/s-0043-122385
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kiesslich R, 2004, GASTROENTEROLOGY, V127, P706, DOI 10.1053/j.gastro.2004.06.050
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2001, ENDOSCOPY, V33, P367
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Kudo S, 2014, J GASTROEN HEPATOL, V29, P83, DOI 10.1111/jgh.12374
   Kudo Shin-ei, 2008, Gastrointest Endosc Clin N Am, V18, P581, DOI 10.1016/j.giec.2008.05.013
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Martinez ME, 2009, GASTROENTEROLOGY, V136, P832, DOI 10.1053/j.gastro.2008.12.007
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2013, ENDOSCOPY, V45, P98, DOI 10.1055/s-0032-1325932
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Noshirwani KC, 2000, GASTROINTEST ENDOSC, V51, P433, DOI 10.1016/S0016-5107(00)70444-5
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Prieto SP, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.2.024502
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Renkoski TE, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.1.016005
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Russell Stuart, 2009, ARTIFICIAL INTELLIGE
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Tafreshi MK, 2014, LECT NOTES COMPUT SC, V8673, P89, DOI 10.1007/978-3-319-10404-1_12
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Tanaka S, 2011, DIGEST ENDOSC, V23, P131, DOI 10.1111/j.1443-1661.2011.01106.x
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wikipedia, 2020, ARTIF INTELL
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yoon HJ, 2020, CLIN ENDOSC, V53, P127, DOI 10.5946/ce.2020.046
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 62
TC 2
Z9 2
U1 2
U2 9
PU EDITORIAL OFFICE GUT & LIVER
PI SEOUL
PA 305 LOTTE GOLD ROSE II, 890-59, DAECHI 4-DONG, GANGNAM-GU, SEOUL,
   135-839, SOUTH KOREA
SN 1976-2283
EI 2005-1212
J9 GUT LIVER
JI Gut Liver
PD MAY
PY 2021
VL 15
IS 3
BP 346
EP 353
DI 10.5009/gnl20186
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA SF0FK
UT WOS:000652440500005
PM 32773386
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Milluzzo, SM
   Cesaro, P
   Grazioli, LM
   Olivari, N
   Spada, C
AF Milluzzo, Sebastian Manuel
   Cesaro, Paola
   Grazioli, Leonardo Minelli
   Olivari, Nicola
   Spada, Cristiano
TI Artificial Intelligence in Lower Gastrointestinal Endoscopy: The Current
   Status and Future Perspective
SO CLINICAL ENDOSCOPY
LA English
DT Review
DE Artificial intelligence; Colon capsule endoscopy; Colonoscopy; Endoscopy
ID ADENOMA DETECTION RATE; DEEP NEURAL-NETWORK; COLORECTAL-CANCER; POLYP
   DETECTION; COLONOSCOPY; SYSTEM; RISK; CLASSIFICATION
AB The present manuscript aims to review the history, recent advances, evidence, and challenges of artificial intelligence (AI) in colonoscopy. Although it is mainly focused on polyp detection and characterization, it also considers other potential applications (i.e., inflammatory bowel disease) and future perspectives. Some of the most recent algorithms show promising results that are similar to human expert performance. The integration of AI in routine clinical practice will be challenging, with significant issues to overcome (i.e., regulatory, reimbursement). Medico-legal issues will also need to be addressed. With the exception of an AI system that is already available in selected countries (GI Genius; Medtronic, Minneapolis, MN, USA), the majority of the technology is still in its infancy and has not yet been proven to reach a sufficient diagnostic performance to be adopted in the clinical practice. However, larger players will enter the arena of AI in the next few months.
C1 [Milluzzo, Sebastian Manuel; Cesaro, Paola; Grazioli, Leonardo Minelli; Olivari, Nicola; Spada, Cristiano] Fdn Poliambulanza, Digest Endoscopy Unit, Via L Bissolati 57, I-25125 Brescia, Italy.
   [Milluzzo, Sebastian Manuel; Cesaro, Paola; Grazioli, Leonardo Minelli; Olivari, Nicola; Spada, Cristiano] Fdn Poliambulanza, Gastroenterol, Via L Bissolati 57, I-25125 Brescia, Italy.
   [Milluzzo, Sebastian Manuel; Spada, Cristiano] Univ Cattolica Sacro Cuore, Dept Gastroenterol, Fdn Policlin Univ A Gemelli IRCCS, Rome, Italy.
C3 Catholic University of the Sacred Heart; IRCCS Policlinico Gemelli
RP Spada, C (通讯作者)，Fdn Poliambulanza, Digest Endoscopy Unit, Via L Bissolati 57, I-25125 Brescia, Italy.; Spada, C (通讯作者)，Fdn Poliambulanza, Gastroenterol, Via L Bissolati 57, I-25125 Brescia, Italy.
EM cristiano.spada@poliam-bulanza.it
OI Milluzzo, Sebastian Manuel/0000-0002-6786-1783
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Burt RW, 2013, J NATL COMPR CANC NE, V11, P1538, DOI 10.6004/jnccn.2013.0180
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gkolfakis P, 2018, EUR J GASTROEN HEPAT, V30, P1482, DOI 10.1097/MEG.0000000000001245
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   KRISHNAN SM, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P610, DOI 10.1109/IEMBS.1994.411878
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Marcondes FO, 2018, DIGEST DIS SCI, V63, P856, DOI 10.1007/s10620-018-4947-1
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Morris EJA, 2015, GUT, V64, P1248, DOI 10.1136/gutjnl-2014-308362
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Seibt H, 2020, GASTROINTEST ENDOSC, V91, pAB249
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Stidham RW, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3963
   Takenaka K, 2020, GASTROENTEROLOGY, V158, P2150, DOI 10.1053/j.gastro.2020.02.012
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Tziatzios G, 2019, DIGEST LIVER DIS, V51, P1079, DOI 10.1016/j.dld.2019.05.012
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 38
TC 13
Z9 13
U1 0
U2 4
PU KOREAN SOC GASTROINTESTINAL ENDOSCOPY
PI SEOUL
PA 2003 LG PALACE, 165-8 DONGGYO-DONG, MAPO-GU, SEOUL, 121-754, SOUTH KOREA
SN 2234-2400
EI 2234-2443
J9 CLIN ENDOSC
JI Clin. Endosc.
PD MAY
PY 2021
VL 54
IS 3
BP 329
EP 339
DI 10.5946/ce.2020.082
PG 11
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA SL9VM
UT WOS:000657262500008
PM 33434961
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Podlasek, J
   Heesch, M
   Podlasek, R
   Kilisinski, W
   Filip, R
AF Podlasek, Jeremi
   Heesch, Mateusz
   Podlasek, Robert
   Kilisinski, Wojciech
   Filip, Rafal
TI Real-time deep learning-based colorectal polyp localization on clinical
   video footage achievable with a wide array of hardware configurations
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID COLONOSCOPY; CANCER; VALIDATION; RISK; IMAGES
AB Background and study aims Several computer-assisted polyp detection systems have been proposed, but they have various limitations, from utilizing outdated neural network architectures to a requirement for multi-graphics processing unit (GPU) processing, to validating on small or non-robust datasets. To address these problems, we developed a system based on a state-of-the-art convolutional neural network architecture able to detect polyps in real time on a single GPU and tested on both public datasets and full clinical examination recordings. Methods The study comprised 165 colonoscopy procedure recordings and 2678 still photos gathered retrospectively. The system was trained on 81,962 polyp frames in total and then tested on footage from 42 colonoscopies and CVC-ClinicDB, CVC-ColonDB, Hyper-Kvasir, and ETIS-Larib public datasets. Clinical videos were evaluated for polyp detection and false-positive rates whereas the public datasets were assessed for F1 score. The system was tested for runtime performance on a wide array of hardware. Results The performance on public datasets varied from an F1 score of 0.727 to 0.942. On full examination videos, it detected 94% of the polyps found by the endoscopist with a 3% false-positive rate and identified additional polyps that were missed during initial video assessment. The system's runtime fits within the real-time constraints on all but one of the hardware configurations. Conclusions We have created a polyp detection system with a post-processing pipeline that works in real time on a wide array of hardware. The system does not require extensive computational power, which could help broaden the adaptation of new commercially available systems.
C1 [Podlasek, Jeremi; Heesch, Mateusz] Moretho Ltd, Dept Technol, Manchester, Lancs, England.
   [Heesch, Mateusz] AGH Univ Sci & Technol, Dept Robot & Mechatron, Al Adama Mickiewicza 30, PL-30059 Krakow, Poland.
   [Podlasek, Robert] Dist Hosp Strzyzow, Trauma & Orthoped Div, Dept Surg, Strzyzow, Poland.
   [Kilisinski, Wojciech; Filip, Rafal] Voivodship Hosp 2 Rzeszow, IBD Unit, Dept Gastroenterol, Rzeszow, Poland.
   [Filip, Rafal] Univ Rzeszow, Fac Med, Rzeszow, Poland.
C3 AGH University of Krakow; University of Rzeszow
RP Heesch, M (通讯作者)，AGH Univ Sci & Technol, Dept Robot & Mechatron, Al Adama Mickiewicza 30, PL-30059 Krakow, Poland.
EM heesch@agh.edu.pl
RI Podlasek, Robert/AAN-9665-2021
CR Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Angermann Q, 2016, PROCEDIA COMPUT SCI, V90, P182, DOI 10.1016/j.procs.2016.07.017
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   Dahms Sylwia, 2015, Pol Przegl Chir, V87, P598, DOI 10.1515/pjs-2016-0009
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dijkstra W, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P616, DOI 10.5220/0007694906160625
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   Guo Z, 2021, DIGEST ENDOSC, V33, P162, DOI 10.1111/den.13670
   Gurudu SR, 2018, J GASTROEN HEPATOL, V33, P645, DOI 10.1111/jgh.13984
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Otani K, 2020, ENDOSCOPY, V52, P786, DOI 10.1055/a-1167-8157
   Pogorelov K, 2018, COMP MED SY, P381, DOI 10.1109/CBMS.2018.00073
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Saftoiu A, 2020, ENDOSCOPY, V52, P293, DOI 10.1055/a-1104-5245
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI [10.3322/caac.21220, 10.3322/caac.21208, 10.3322/caac.21395]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Smedsrud PH., 2019, HYPERKVASIR COMPREHE
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Tan M., 2019, PR MACH LEARN RES
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wilkins A. J., 1995, VISUAL STRESS
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
NR 35
TC 6
Z9 6
U1 1
U2 1
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD MAY
PY 2021
VL 09
IS 05
BP E741
EP E748
DI 10.1055/a-1388-6735
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA RQ3AE
UT WOS:000642292800014
PM 33937516
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Su, RZ
   Liu, J
   Wu, BF
   Xie, Y
   Zhang, Y
   Zhang, W
   Zhang, YX
   Wan, M
   Tian, ZX
   Hu, YQ
AF Su, Ruizhang
   Liu, Jie
   Wu, Bifang
   Xie, Yun
   Zhang, Yi
   Zhang, Wen
   Zhang, Yongxiu
   Wan, Man
   Tian, Zhaoxu
   Hu, Yiqun
TI Accurate measurement of colorectal polyps using computer-aided analysis
SO EUROPEAN JOURNAL OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Article
DE colorectal cancer; computer-aided diagnosis; image segmentation
   technique; polyps
ID GUIDELINES; MANAGEMENT; CANCER
AB Introduction
   As we know, the majority of colorectal cancers are thought to evolve from colorectal adenomas. In this study, we explored the use of Computer-aided diagnosis (CAD) in the detection of colorectal polyps and the estimation of their sizes, which is important for the diagnosis and management of colorectal cancer.
   Materials and methods
   As the distance between colonoscopy and lesion increases, magnification tends to decrease. Therefore, the size of colorectal polyps can be calculated by taking into account the captured image and the shooting distance. In this study, the fitting curve of the magnification of electronic colonoscopy was obtained by simulating intestinal tract and polyps in vitro. Then, the distance was artificially controlled in the endoscopic operation, and the image was taken at a preset distance. The CAD system was then trained on the overall shape of colorectal polyps. Image segmentation was employed to accurately identify colorectal polyps. Finally, on the basis of the magnification factor, the real value of polyps was predicted from the shooting distance and the segmentation image size.
   Results
   The CAD system can automatically calculate the range of colorectal polyps and calculate the true size of the colorectal polyps according to the magnification of the corresponding distance.
   Conclusions
   In this study, we developed a method of accurately estimating the size of colorectal polyps. This approach is compatible with many devices, which would expand its range of applications. This method has the potential for application in other areas of clinical diagnosis.
C1 [Su, Ruizhang; Liu, Jie; Wu, Bifang] Fujian Med Univ, Sch Clin Med, Fuzhou, Peoples R China.
   [Xie, Yun; Wan, Man; Hu, Yiqun] Xiamen Univ, Dept Gastroenterol, Zhongshan Hosp, Xiamen, Fujian, Peoples R China.
   [Zhang, Yi] Pucheng Cty Hosp Tradit Chinese Med, Pucheng, Fujian, Peoples R China.
   [Zhang, Wen; Zhang, Yongxiu] Icahn Sch Med Mt Sinai, Friedman Brain Inst, New York, NY 10029 USA.
   [Tian, Zhaoxu] Shenzhen Longgang Dist Peoples Hosp, Dept Gastroenterol, Shenzhen, Guangdong, Peoples R China.
C3 Fujian Medical University; Xiamen University; Icahn School of Medicine
   at Mount Sinai
RP Hu, YQ (通讯作者)，Xiamen Univ, Dept Gastroenterol, Zhongshan Hosp, Xiamen, Fujian, Peoples R China.
EM hyq0826@xmu.edu.com
RI Zhang, Wen/I-7086-2018; Jie, Liu/IXX-0109-2023
OI Zhang, Wen/0000-0001-7370-4306; Jie, Liu/0000-0003-3307-1975
FU Medical innovation project of Fujian Province [2019-cxb-31]; project of
   health research personnel training in Fujian Province
FX Authors thank the associate editor and anonymous reviewers for their
   good suggestion which have helped to improve this study.; This work is
   supported by Medical innovation project of Fujian Province
   (2019-cxb-31), funded by the project of health research personnel
   training in Fujian Province.
CR Beck AH, DEEP LEARNING IDENTI
   Bi WL, 2019, CA-CANCER J CLIN, V69, P127, DOI 10.3322/caac.21552
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hu Z, 2019, NAT GENET, V51, P1113, DOI 10.1038/s41588-019-0423-x
   Hua KL, 2015, ONCOTARGETS THER, V8, P2015, DOI 10.2147/OTT.S80733
   Keum N, 2019, NAT REV GASTRO HEPAT, V16, P713, DOI 10.1038/s41575-019-0189-8
   Kumar D, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P133, DOI 10.1109/CRV.2015.25
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Lin JS, 2016, JAMA-J AM MED ASSOC, V315, P2576, DOI 10.1001/jama.2016.3332
   Luo HY, 2019, LANCET ONCOL, V20, P1645, DOI 10.1016/S1470-2045(19)30637-0
   NCCN Clinical Practice Guidelines in Oncology, NEUR ADR TUM VERS 1
   Ohmori M, 2020, GASTROINTEST ENDOSC, V91, P301, DOI 10.1016/j.gie.2019.09.034
   Philpotts LE, 2009, RADIOLOGY, V253, P17, DOI 10.1148/radiol.2531090689
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Tanaka S, 2015, J GASTROENTEROL, V50, P252, DOI 10.1007/s00535-014-1021-4
   Tinmouth J, 2016, CAN J GASTROENTEROL, V2016, DOI 10.1155/2016/2878149
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Williams JG, 2013, COLORECTAL DIS, V15, P1, DOI 10.1111/codi.12262
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yang JW, 2015, GUANGDONG SCI TECHNO
NR 25
TC 0
Z9 0
U1 0
U2 10
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0954-691X
EI 1473-5687
J9 EUR J GASTROEN HEPAT
JI Eur. J. Gastroenterol. Hepatol.
PD MAY
PY 2021
VL 33
IS 5
BP 701
EP 708
DI 10.1097/MEG.0000000000002162
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA RL9TF
UT WOS:000639305200016
PM 33787542
DA 2023-08-21
ER

PT J
AU Cao, CT
   Wang, RL
   Yu, Y
   Zhang, H
   Yu, Y
   Sun, CY
AF Cao, Chanting
   Wang, Ruilin
   Yu, Yao
   Zhang, Hui
   Yu, Ying
   Sun, Changyin
TI Gastric polyp detection in gastroscopic images using deep neural network
SO PLOS ONE
LA English
DT Article
ID COLONOSCOPY; VALIDATION
AB This paper presents the research results of detecting gastric polyps with deep learning object detection method in gastroscopic images. Gastric polyps have various sizes. The difficulty of polyp detection is that small polyps are difficult to detect from the background. We propose a feature extraction and fusion module and combine it with the YOLOv3 network to form our network. This method performs better than other methods in the detection of small polyps because it can fuse the semantic information of high-level feature maps with low-level feature maps to help small polyps detection. In this work, we use a dataset of gastric polyps created by ourselves, containing 1433 training images and 508 validation images. We train and validate our network on our dataset. In comparison with other methods of polyps detection, our method has a significant improvement in precision, recall rate, F1, and F2 score. The precision, recall rate, F1 score, and F2 score of our method can achieve 91.6%, 86.2%, 88.8%, and 87.2%.
C1 [Cao, Chanting; Wang, Ruilin; Yu, Yao] Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing Engn Res Ctr Ind Spectrum Imaging, Beijing, Peoples R China.
   [Zhang, Hui] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Yu, Ying] Beijing An Zhen Hosp, Beijing, Peoples R China.
   [Sun, Changyin] Southeast Univ, Sch Automat, Nanjing, Peoples R China.
C3 University of Science & Technology Beijing; Chinese Academy of Sciences;
   Institute of Automation, CAS; Southeast University - China
RP Yu, Y (通讯作者)，Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing Engn Res Ctr Ind Spectrum Imaging, Beijing, Peoples R China.
EM yuyao@ustb.edu.cn
RI SUN, CHANG/GXM-3680-2022; wang, rui/JAC-6240-2023; sun,
   chang/ITV-6759-2023
FU National Natural Science Foundation of China [61931020, 62033010]
FX Yao Yu is supported by National Natural Science Foundation of China
   (grant number 61931020, 62033010). The URL is
   https://hfbic021dcb05d8e549bdh0qkw69uxxc656nn5fiac.eds.tju.edu.cn/.There was no additional external funding
   received for this study. The funders had no role in study design, data
   collection, and analysis, decision to publish, or preparation of the
   manuscript.
CR Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bilal M, 2020, AM J GASTROENTEROL, V115, P963, DOI 10.14309/ajg.0000000000000646
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bochkovskiy Alexey, 2020, ARXIVORG
   Brosens LAA, 2016, INT J SURG PATHOL, V24, P185, DOI 10.1177/1066896915620013
   Carmack SW, 2009, NAT REV GASTRO HEPAT, V6, P331, DOI 10.1038/nrgastro.2009.70
   Dalal N., 2005, 2005 IEEE COMP SOC C, V1, P886, DOI DOI 10.1109/CVPR.2005.177
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Eggert C, 2017, IEEE INT CON MULTI, P421, DOI 10.1109/ICME.2017.8019550
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo XD, 2019, MED PHYS, V46, P5666, DOI 10.1002/mp.13865
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Joseph R, ARXIV PREPRINT ARXIV
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Li Zuoxin, 2017, ARXIV PREPRINT ARXIV
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma Z, 2015, PROC CVPR IEEE, P3689, DOI 10.1109/CVPR.2015.7298992
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Olmez S, 2018, NORTH CLIN ISTANB, V5, P41, DOI 10.14744/nci.2017.50480
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Pang SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217647
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song T, 2019, IEEE ACCESS, V7, P166823, DOI 10.1109/ACCESS.2019.2953934
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wan JJ, 2020, CMC-COMPUT MATER CON, V63, P1263, DOI 10.32604/cmc.2020.010098
   Yan JQ, 2020, AAAI CONF ARTIF INTE, V34, P12573
   Yann LeCun, 2015, Nature, V521, P436, DOI 10.1038/nature14539
   Yasser H, 2013, CLIN GASTROENTEROL H, V11, P1374
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 52
TC 8
Z9 8
U1 1
U2 10
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD APR 28
PY 2021
VL 16
IS 4
AR e0250632
DI 10.1371/journal.pone.0250632
PG 18
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA ST0XL
UT WOS:000662174400063
PM 33909671
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Ozyoruk, KB
   Gokceler, GI
   Bobrow, TL
   Coskun, G
   Incetan, K
   Almalioglu, Y
   Mahmood, F
   Curto, E
   Perdigoto, L
   Oliveira, M
   Sahin, H
   Araujo, H
   Alexandrino, H
   Durr, NJ
   Gilbert, HB
   Turan, M
AF Ozyoruk, Kutsev Bengisu
   Gokceler, Guliz Irem
   Bobrow, Taylor L.
   Coskun, Gulfize
   Incetan, Kagan
   Almalioglu, Yasin
   Mahmood, Faisal
   Curto, Eva
   Perdigoto, Luis
   Oliveira, Marina
   Sahin, Hasan
   Araujo, Helder
   Alexandrino, Henrique
   Durr, Nicholas J.
   Gilbert, Hunter B.
   Turan, Mehmet
TI EndoSLAM dataset and an unsupervised monocular visual odometry and depth
   estimation approach for endoscopic videos
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE SLAM dataset; Capsule endoscopy; Standard endoscopy; Monocular depth
   estimation; Visual odometry; Spatial attention module
ID CAPSULE ENDOSCOPY; LOCALIZATION; VALIDATION; TRACKING
AB Deep learning techniques hold promise to develop dense topography reconstruction and pose estimation methods for endoscopic videos. However, currently available datasets do not support effective quanti- tative benchmarking. In this paper, we introduce a comprehensive endoscopic SLAM dataset consisting of 3D point cloud data for six porcine organs, capsule and standard endoscopy recordings, synthetically generated data as well as clinically in use conventional endoscope recording of the phantom colon with computed tomography(CT) scan ground truth. A Panda robotic arm, two commercially available capsule endoscopes, three conventional endoscopes with different camera properties, two high precision 3D scan- ners, and a CT scanner were employed to collect data from eight ex-vivo porcine gastrointestinal (GI) tract organs and a silicone colon phantom model. In total, 35 sub-datasets are provided with 6D pose ground truth for the ex-vivo part: 18 sub-datasets for colon, 12 sub-datasets for stomach, and 5 sub- datasets for small intestine, while four of these contain polyp-mimicking elevations carried out by an expert gastroenterologist. To verify the applicability of this data for use with real clinical systems, we recorded a video sequence with a state-of-the-art colonoscope from a full representation silicon colon phantom. Synthetic capsule endoscopy frames from stomach, colon, and small intestine with both depth and pose annotations are included to facilitate the study of simulation-to-real transfer learning algo- rithms. Additionally, we propound Endo-SfMLearner, an unsupervised monocular depth and pose estima- tion method that combines residual networks with a spatial attention module in order to dictate the network to focus on distinguishable and highly textured tissue regions. The proposed approach makes use of a brightness-aware photometric loss to improve the robustness under fast frame-to-frame illu- mination changes that are commonly seen in endoscopic videos. To exemplify the use-case of the En-doSLAM dataset, the performance of Endo-SfMLearner is extensively compared with the state-of-the-art: SC-SfMLearner, Monodepth2, and SfMLearner. The codes and the link for the dataset are publicly available at https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/CapsuleEndoscope/EndoSLAM . A video demonstrating the experimental setup and procedure is accessible as Supplementary Video 1.& nbsp; (c) 2021 Elsevier B.V. All rights reserved.
C1 [Ozyoruk, Kutsev Bengisu; Gokceler, Guliz Irem; Coskun, Gulfize; Incetan, Kagan; Sahin, Hasan; Turan, Mehmet] Bogazici Univ, Inst Biomed Engn, Istanbul, Turkey.
   [Almalioglu, Yasin] Univ Oxford, Comp Sci Dept, Oxford, England.
   [Mahmood, Faisal] Harvard Med Sch, Brigham & Womens Hosp, Boston, MA 02115 USA.
   [Mahmood, Faisal] Dana Farber Canc Inst, Canc Data Sci, Boston, MA 02115 USA.
   [Mahmood, Faisal] Broad Inst MIT & Harvard, Canc Program, Cambridge, MA 02142 USA.
   [Curto, Eva; Perdigoto, Luis; Oliveira, Marina; Araujo, Helder] Univ Coimbra, Inst Syst & Robot, Coimbra, Portugal.
   [Bobrow, Taylor L.; Durr, Nicholas J.] Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD USA.
   [Gilbert, Hunter B.] Louisiana State Univ, Dept Mech & Ind Engn, Baton Rouge, LA 70803 USA.
   [Alexandrino, Henrique] Univ Coimbra, Clin Acad Ctr Coimbra, Fac Med, Coimbra, Portugal.
C3 Bogazici University; University of Oxford; Harvard University; Brigham &
   Women's Hospital; Harvard Medical School; Harvard University;
   Dana-Farber Cancer Institute; Harvard University; Massachusetts
   Institute of Technology (MIT); Broad Institute; Universidade de Coimbra;
   Johns Hopkins University; Louisiana State University System; Louisiana
   State University; Universidade de Coimbra
RP Ozyoruk, KB; Turan, M (通讯作者)，Bogazici Univ, Inst Biomed Engn, Istanbul, Turkey.
EM bengisu.ozyoruk@boun.edu.tr; mehmet.turan@boun.edu.tr
RI Ozyoruk, Kutsev Bengisu/HRA-3061-2023; Turan, Mehmet/AGZ-7356-2022;
   Araujo, Helder/B-3554-2008; Alexandrino, Henrique/AHC-7148-2022; Durr,
   Nicholas/W-5517-2018; Mahmood, Faisal/C-1021-2015
OI Ozyoruk, Kutsev Bengisu/0000-0001-5943-7440; Araujo,
   Helder/0000-0002-9544-424X; Durr, Nicholas/0000-0001-9808-7383;
   GOKCELER, GULIZ IREM/0000-0002-5994-5020; Mahmood,
   Faisal/0000-0001-7587-1562; Oliveira, Marina/0000-0001-9271-0357;
   Bobrow, Taylor/0000-0002-3708-4565; Incetan, Kagan/0000-0001-5114-8142;
   Gilbert, Hunter/0000-0001-8590-2596; Curto, Eva/0000-0002-0477-0091;
   Almalioglu, Yasin/0000-0002-9251-7853; Alexandrino,
   Henrique/0000-0002-0279-9659
FU Scientific and Technological Research Council of Turkey (TUBITAK) [2232]
FX This work was supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK) with grant 2232The International Fellowship
   for Outstanding Researchers.
CR [Anonymous], 2018, ASTOUNDING 19 MILLIO
   [Anonymous], Robust medical instrument segmentation (robust-mis) challenge 2019
   [Anonymous], 2018, GLOBAL CANC FACTS FI, V4th
   Araujo H., 2017, ABS170806822 CORR
   Arnold M, 2020, GASTROENTEROLOGY, V159, P335, DOI 10.1053/j.gastro.2020.02.068
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bian J W, 2019, ARXIV190810553
   Borgli H., 2019, HYPERK KVASIR COMPRE, DOI [10.31219/osf.io/mkzcq, DOI 10.31219/OSF.IO/MKZCQ]
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Chen R., 2019, SLAM ENDOSCOPY ENHAN
   Ciuti G, 2016, J MICRO-BIO ROBOT, V11, P1, DOI 10.1007/s12213-016-0087-x
   Dey Nilanjan, 2017, IEEE Rev Biomed Eng, V10, P2, DOI 10.1109/RBME.2017.2697950
   Durr N. J., 2017, ABS171011216 CORR
   Eigen D, 2014, ADV NEUR IN, V27
   Garg Ravi, 2016, ABS160304992 CORR
   Godard C., 2018, DIGGING SELF SUPERVI
   Grasa OG, 2014, IEEE T MED IMAGING, V33, P135, DOI 10.1109/TMI.2013.2282997
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI DOI 10.1017/CBO9780511811685
   Ho HW, 2017, INT J MICRO AIR VEH, V9, P198, DOI 10.1177/1756829317695566
   Honegger D, 2012, IEEE INT C INT ROBOT, P5177, DOI 10.1109/IROS.2012.6385530
   Hong SP, 2012, HEPATO-GASTROENTEROL, V59, P778, DOI 10.5754/hge10472
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Incetan K., 2020, ARXIV200812949
   Jha D., 2020, KVASIR SEG DATASET
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Kuth R, 2007, US Patent, Vapp, Patent No. [11/481,935, 11481935]
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Leonard S, 2018, IEEE T MED IMAGING, V37, P2185, DOI 10.1109/TMI.2018.2833868
   Lin BX, 2013, LECT NOTES COMPUT SC, V8090, P35, DOI 10.1007/978-3-642-40843-4_5
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu G, 2002, P AMER CONTR CONF, V1-6, P1115, DOI 10.1109/ACC.2002.1023168
   Liu W., 2018, ABS181110964 CORR
   Liu XT, 2020, IEEE T MED IMAGING, V39, P1438, DOI 10.1109/TMI.2019.2950936
   Lu YW, 2019, IEEE IMAGE PROC, P2571, DOI 10.1109/ICIP.2019.8803247
   Lucas B. D, 1981, P 7 INT JOINT C ART
   Mahmood F., 2019, ARXIVABS190700283
   Mahmood F, 2018, IEEE T MED IMAGING, V37, P2572, DOI 10.1109/TMI.2018.2842767
   McCarthy C, 2008, IEEE T ROBOT, V24, P832, DOI 10.1109/TRO.2008.926871
   Ming Y., 2018, 413 EASYCHAIR, DOI [10.29007/mf57, DOI 10.29007/MF57]
   Mirota DJ, 2012, IEEE T MED IMAGING, V31, P963, DOI 10.1109/TMI.2011.2176500
   Moccia S, 2018, COMPUT METH PROG BIO, V158, P21, DOI 10.1016/j.cmpb.2018.01.030
   Mountney P, 2006, LECT NOTES COMPUT SC, V4190, P347
   Penza V, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1926
   Pertuz S., 2020, MATLAB CENTRAL FILE
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P170, DOI 10.1145/3083187.3083216
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Puglisi LJ, 2015, CONTROL ENG APPL INF, V17, P30
   Redondo-Cerezo E, 2014, WORLD J GASTROENTERO, V20, P15664, DOI 10.3748/wjg.v20.i42.15664
   Shah T, 2006, ICECE 2006: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, P173
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simaan N, 2015, MECH ENG, V137, DOI 10.1115/1.2015-Sep-6
   Son D, 2016, IEEE-ASME T MECH, V21, P708, DOI 10.1109/TMECH.2015.2488361
   Spyrou E, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/1/015002
   Stoyanov D, 2010, LECT NOTES COMPUT SC, V6361, P275
   Sun D., 2018, ABS180509806 CORR
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Than TD, 2014, IEEE T ROBOT, V30, P1174, DOI 10.1109/TRO.2014.2333111
   TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7
   TSAI RY, 1989, IEEE T ROBOTIC AUTOM, V5, P345, DOI 10.1109/70.34770
   Turan M., 2018, ARXIV PREPRINT ARXIV
   Turan M., 2017, FULLY DENSE GLOBALLY
   Turan M, 2017, INT J INTELL ROBOT, V1, P399, DOI 10.1007/s41315-017-0036-4
   Yano T, 2009, BEST PRACT RES CL GA, V23, P61, DOI 10.1016/j.bpg.2008.12.001
   Ye M., 2017, ARXIV PREPRINT ARXIV
   Ye ML, 2016, MED IMAGE ANAL, V30, P144, DOI 10.1016/j.media.2015.10.003
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Zhang YY, 2020, IEEE T IMAGE PROCESS, V29, P7019, DOI 10.1109/TIP.2020.2997247
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 73
TC 34
Z9 34
U1 13
U2 47
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD JUL
PY 2021
VL 71
AR 102058
DI 10.1016/j.media.2021.102058
EA APR 2021
PG 26
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA SM1TH
UT WOS:000657393700003
PM 33930829
DA 2023-08-21
ER

PT J
AU Rahim, T
   Hassan, SA
   Shin, SY
AF Rahim, Tariq
   Hassan, Syed Ali
   Shin, Soo Young
TI A deep convolutional neural network for the detection of polyps in
   colonoscopy images
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Colonoscopy; Convolutional neural network; MISH; Polyp; Precision;
   Rectified linear unit; Sensitivity
ID VALIDATION; CNN
AB Colonic polyps detection remains an unsolved issue because of the wide variation in the appearance, texture, color, size, and appearance of the multiple polyp-like imitators during the colonoscopy process. In this paper, a deep convolutional neural network (CNN) based model for the computerized detection of polyps within colonoscopy images is proposed. The proposed deep CNN model employs a unique way of adopting different convolutional kernels having different window sizes within the same hidden layer for deeper feature extraction. A lightweight model comprising 16 convolutional layers with 2 fully connected layers (FCN), and a Softmax layer as output layer is implemented. For achieving a deeper propagation of information, self-regularized smooth nonmonotonicity, and to avoid saturation during training, MISH as an activation function is used in the first 15 layers followed by the rectified linear unit activation (ReLU) function. Moreover, a generalized intersection of the union (GIoU) approach is employed, overcoming issues such as scale invariance, rotation, and shape encountering with IoU. Data augmentation techniques such as photometric and geometric distortions are employed to overcome the scarcity of the data set of the colonic polyp. Detailed experimental results are provided that are bench-marked with the MICCAI 2015 challenge and other publicly available data set reflecting better performance in terms of precision, sensitivity, F1-score, F2-score, and Dice-coefficient, thus proving the efficacy of the proposed model.
C1 [Rahim, Tariq; Hassan, Syed Ali; Shin, Soo Young] Kumoh Natl Inst Technol, Gumi 39177, Gyeongbuk, South Korea.
C3 Kumoh National University Technology
RP Shin, SY (通讯作者)，Kumoh Natl Inst Technol, Gumi 39177, Gyeongbuk, South Korea.
EM tariqrahim@ieee.org; Syedali@kumoh.ac.kr; wdragon@kumoh.ac.kr
RI Hassan, Syed Ali/GRY-4413-2022; Shin, Soo Young/ABG-4608-2021
OI Shin, Soo Young/0000-0002-2526-2395
FU Priority Research Centers Program through the National Research
   Foundation of Korea (NRF) - Ministry of Education, Science and
   Technology [2018R1A6A1A03024003]; MSIT (Ministry of Science and ICT),
   Korea, under the Grand Information Technology Research Center support
   program [IITP-2021-2020-001612]; National Research Foundation of Korea
   [5199990114003] Funding Source: Korea Institute of Science & Technology
   Information (KISTI), National Science & Technology Information Service
   (NTIS)
FX This work was supported by Priority Research Centers Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education, Science and Technology"(2018R1A6A1A03024003). This research
   was supported by the MSIT (Ministry of Science and ICT), Korea, under
   the Grand Information Technology Research Center support program
   (IITP-2021-2020-001612) supervised by the IITP (Institute for
   Information & communications Technology Planning & Evaluation).
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Banerjee K., 2020, ARXIV201111538
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bravo D, 2020, PROC SPIE, V11314, DOI 10.1117/12.2549736
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Chen W.J., 2020, IEEE T RADIAT PLASMA
   Chuquimia O, 2019, BIOMED CIRC SYST C
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Jha D., IEEE ACCESS, V9, P40496
   Junliang Li, 2018, IEEE Signal Processing Letters, V25, P288, DOI 10.1109/LSP.2017.2789325
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kosub S, 2019, PATTERN RECOGN LETT, V120, P36, DOI 10.1016/j.patrec.2018.12.007
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Misra D., 2019, ARXIV PREPRINT
   Park S., 2015, POLYP DETECTION COLO
   Park S.Y., 2016, MED IMAGING 2016 COM, V9785
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Qadir H., 2019, IEEE J BIOMED HLTH I
   Rahim T., 2019, ARXIV191000265
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shin HC, 2015, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2015.7298712
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Tajbakhsh N., 2018, US Patent, Patent No. [10,055,843, 10055843]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tashk Ashkan, 2019, 2019 International Conference on Control, Artificial Intelligence, Robotics & Optimization (ICCAIRO). Proceedings, P37, DOI 10.1109/ICCAIRO47923.2019.00015
   Tian Y., ARXIV210103285, P2021
   Wang W, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00482-3
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Zhang Q, 2020, IEEE T IMAGE PROCESS, V29, P3321, DOI 10.1109/TIP.2019.2959253
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 44
TC 23
Z9 24
U1 1
U2 11
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD JUL
PY 2021
VL 68
AR 102654
DI 10.1016/j.bspc.2021.102654
EA APR 2021
PG 9
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA TF0AA
UT WOS:000670368600008
OA Green Submitted
DA 2023-08-21
ER

PT J
AU Srivastava, G
   Srivastava, R
AF Srivastava, Gargi
   Srivastava, Rajeev
TI Colon tumor localization using three input variants to Faster
   Region-based Convolutional Neural Network and lazy snapping
SO INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE colon tumor detection; deep learning; medical image processing
ID GASTROINTESTINAL-DISEASES; CLASSIFICATION; FRAMEWORK
AB Automated polyp localization in colon endoscopy images helps minimize human errors in localizing polyps. In our method, we use Faster Region-based Convolutional Neural Network (R-CNN) on Resnet 50 network to form a tight bounding box around the polyp. The bounding box is then used as input for the lazy snapping technique to determine polyps correctly. Three input variants-RGB images, histogram equalized images, and luminance images-are fed to the network. The output obtained from each variant is combined to form the final result. We have used the CVC-Clinical DB database, which has 612 images with 672 polyp instances for our study. Thirteen different combinations for obtaining the result are studied, and the best among them is identified. The result is evaluated for all combinations and against a state-of-the-art method for precision, recall, and F-measure. The proposed model achieves a precision of 80.51% and a recall value of 80.33%.
C1 [Srivastava, Gargi; Srivastava, Rajeev] Indian Inst Technol BHU Varanasi, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Srivastava, G (通讯作者)，Indian Inst Technol BHU Varanasi, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM gargis.rs.cse16@iitbhu.ac.in
RI Srivastava, Rajeev/C-7906-2016
OI Srivastava, Rajeev/0000-0002-0165-1556; Srivastava,
   Gargi/0000-0001-6770-561X
CR Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bardhi O, 2017, IEEE INT SYMP SIGNAL, P445, DOI 10.1109/ISSPIT.2017.8388684
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YF, 2016, IEEE T MED IMAGING, V35, P1522, DOI 10.1109/TMI.2016.2518958
   Ismail M, 2015, IET COMPUT VIS, V9, P511, DOI 10.1049/iet-cvi.2014.0177
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2020, IEEE ACCESS, V8, P197969, DOI 10.1109/ACCESS.2020.3034217
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, MULTIMED TOOLS APPL, V78, P27743, DOI 10.1007/s11042-019-07875-9
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Liaqat A, 2020, CURR MED IMAGING, V16, P1229, DOI 10.2174/1573405616666200425220513
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Rashid M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125037
   Rehman A, 2021, MICROSC RES TECHNIQ, V84, P133, DOI 10.1002/jemt.23597
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren YC, 2018, IEEE ACCESS, V6, P74506, DOI 10.1109/ACCESS.2018.2874803
   Ren YC, 2019, IEEE J BIOMED HEALTH, V23, P324, DOI 10.1109/JBHI.2018.2808199
   Ren YC, 2017, IEEE T BIO-MED ENG, V64, P1924, DOI 10.1109/TBME.2016.2631245
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Xie XL, 2018, IEEE ROBOT AUTOM LET, V3, P434, DOI 10.1109/LRA.2017.2746918
   Xu JW, 2014, IEEE J BIOMED HEALTH, V18, P585, DOI 10.1109/JBHI.2013.2278023
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 39
TC 0
Z9 0
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-9457
EI 1098-1098
J9 INT J IMAG SYST TECH
JI Int. J. Imaging Syst. Technol.
PD DEC
PY 2021
VL 31
IS 4
BP 2123
EP 2135
DI 10.1002/ima.22581
EA APR 2021
PG 13
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA WP8DO
UT WOS:000644423700001
DA 2023-08-21
ER

PT J
AU Liu, XY
   Guo, XQ
   Liu, YJ
   Yuan, YX
AF Liu, Xinyu
   Guo, Xiaoqing
   Liu, Yajie
   Yuan, Yixuan
TI Consolidated domain adaptive detection and localization framework for
   cross-device colonoscopic images
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Colonoscopic polyp detection; Domain adaptation; Style transfer;
   Adversarial training
ID POLYP DETECTION; VALIDATION
AB Automatic polyp detection has been proven to be crucial in improving the diagnosis accuracy and re-ducing colorectal cancer mortality during the precancerous stage. However, the performance of deep neural networks may degrade severely when being deployed to polyp data in a distinct domain. This domain distinction can be caused by different scanners, hospitals, or imaging protocols. In this paper, we propose a consolidated domain adaptive detection and localization framework to bridge the domain gap between different colonosopic datasets effectively, consisting of two parts: the pixel-level adaptation and the hierarchical feature-level adaptation. For the pixel-level adaptation part, we propose a Gaus-sian Fourier Domain Adaptation (GFDA) method to sample the matched source and target image pairs from Gaussian distributions then unify their styles via the low-level spectrum replacement, which can reduce the domain discrepancy of the cross-device polyp datasets in appearance level without distorting their contents. The hierarchical feature-level adaptation part comprising a Hierarchical Attentive Adap-tation (HAA) module to minimize the domain discrepancy in high-level semantics and an Iconic Con-centrative Adaptation (ICA) module to perform reliable instance alignment. These two modules are reg-ularized by a Generalized Consistency Regularizer (GCR) for maintaining the consistency of their do-main predictions. We further extend our framework to the polyp localization task and present a Cen-tre Besiegement (CB) loss for better location optimization. Experimental results show that our frame-work outperforms other domain adaptation detectors by a large margin in the detection task meanwhile achieves the state-of-the-art recall rate of 87.5% in the localization task. The source code is available at https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/CityU- AIM-Group/ConsolidatedPolypDA .
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Xinyu; Guo, Xiaoqing; Yuan, Yixuan] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Liu, Yajie] Peking Univ, Shenzhen Hosp, Dept Radiat Oncol, Shenzhen, Peoples R China.
C3 City University of Hong Kong; Peking University
RP Yuan, YX (通讯作者)，City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM yxyuan.ee@cityu.edu.hk
OI Yuan, Yixuan/0000-0002-0853-6948; Liu, Xinyu/0000-0002-5180-6958; GUO,
   Xiaoqing/0000-0002-9476-521X
FU Hong Kong Research Grants Council (RGC) Early Career Scheme [21207420
   (CityU 9048179)]; Hong Kong RGC Collaborative Research Fund [C4063-18G
   (CityU 8739029)]; Shenzhen-Hong Kong Innovation Circle Category D
   Project [SGDX2019081623300177 (CityU 9240008)]
FX This work was supported by Hong Kong Research Grants Council (RGC) Early
   Career Scheme grant 21207420 (CityU 9048179), Hong Kong RGC
   Collaborative Research Fund grant C4063-18G (CityU 8739029), and
   Shenzhen-Hong Kong Innovation Circle Category D Project
   SGDX2019081623300177 (CityU 9240008).
CR American Cancer Society, 2020, CANC FACTS FIGURES 2, P1
   [Anonymous], INT J COMPUT VISION, DOI DOI 10.1007/s11263-009-0275-4
   [Anonymous], 2017, P IEEE INT C COMPUTE
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Arruda V.F., 2019, INT JOINT C NEURAL N, P1
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Cheng-Chun Hsu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P733, DOI 10.1007/978-3-030-58545-7_42
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Deng J., 2009, PROC CVPR IEEE, P248, DOI DOI 10.1109/CVPR.2009.5206848
   Devaguptapu C, 2019, IEEE COMPUT SOC CONF, P1029, DOI 10.1109/CVPRW.2019.00135
   Edwards BK, 2010, CANCER-AM CANCER SOC, V116, P544, DOI 10.1002/cncr.24760
   Freedman D, 2020, IEEE T MED IMAGING, V39, P3451, DOI 10.1109/TMI.2020.2994221
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Goodfellow I., 2014, ADV NEUR IN, P2672
   Guo X, 2020, IEEE T MED IMAGING
   Guo XQ, 2019, LECT NOTES COMPUT SC, V11764, P293, DOI 10.1007/978-3-030-32239-7_33
   He K., 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   He Z, 2020, ARXIV200701571
   He ZW, 2019, IEEE I CONF COMP VIS, P6667, DOI 10.1109/ICCV.2019.00677
   Hsu HK, 2020, IEEE WINT CONF APPL, P738, DOI 10.1109/WACV45572.2020.9093358
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Kim T, 2019, PROC CVPR IEEE, P12448, DOI 10.1109/CVPR.2019.01274
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee Y, 2019, P IEEE C COMPUTER VI, P0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   Maas A. L., 2013, INT C MACHINE LEARNI, V30, P3, DOI DOI 10.1109/ICCV.2017.304
   Massa F., 2018, MASKRCNN BENCHMARK F
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Pan Y, 2020, WACV, P1324
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Paszke A, 2019, ADV NEUR IN, V32
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P170, DOI 10.1145/3083187.3083216
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodriguez A. L., 2019, PROC BRIT MACH VIS C
   Saito K, 2019, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR.2019.00712
   Shen Z., 2019, ARXIV191102559
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song G., 2020, CVPR, P11563
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Hoang TH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2578, DOI 10.1145/3343031.3356073
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wei X.-S, 2020, CVPR, P11724
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Xie R., 2019, IEEE INT CONF COMP V, DOI DOI 10.1109/ICCVW.2019.00401
   Xu M., 2020, IEEE C COMP VIS PATT, P12355
   Yang Yanchao, 2020, CVPR, P4085
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YX, 2015, IEEE INT CONF ROBOT, P1310, DOI 10.1109/ICRA.2015.7139360
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zheng Y., 2020, IEEE C COMPUTER VISI, P13763, DOI DOI 10.1109/CVPR42600.2020.01378
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XG, 2019, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2019.00078
   Zhuang C, 2020, AAAI, P13122
NR 81
TC 24
Z9 24
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD JUL
PY 2021
VL 71
AR 102052
DI 10.1016/j.media.2021.102052
EA APR 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA SV1WT
UT WOS:000663616000012
PM 33895616
DA 2023-08-21
ER

PT J
AU Ashat, M
   Klair, JS
   Singh, D
   Murali, AR
   Krishnamoorthi, R
AF Ashat, Munish
   Klair, Jagpal Singh
   Singh, Dhruv
   Murali, Arvind Rangarajan
   Krishnamoorthi, Rajesh
TI Impact of real-time use of artificial intelligence in improving adenoma
   detection during colonoscopy: A systematic review and meta-analysis
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Review
ID COLORECTAL-CANCER; TASK-FORCE
AB Background and study aims With the advent of deep neural networks (DNN) learning, the field of artificial intelligence (AI) is rapidly evolving. Recent randomized controlled trials (RCT) have investigated the influence of integrating AI in colonoscopy and its impact on adenoma detection rates (ADRs) and polyp detection rates (PDRs). We performed a systematic review and meta-analysis to reliably assess if the impact is statistically significant enough to warrant the adoption of AI -assisted colonoscopy (AIAC) in clinical practice.
   Methods We conducted a comprehensive search of multiple electronic databases and conference proceedings to identify RCTs that compared outcomes between AIAC and conventional colonoscopy (CC). The primary outcome was ADR. The secondary outcomes were PDR and total withdrawal time (WT).
   Results Six RCTs (comparing AIAC vs CC) with 5058 individuals undergoing average-risk screening colonoscopy were included in the meta-analysis. ADR was significantly higher with AIAC compared to CC (33.7% versus 22.9%; odds ratio (OR) 1.76, 95% confidence interval (CI) 1.55-2.00; I-2 =28%). Similarly, PDR was significantly higher with AIAC (45.6% versus 30.6%; OR 1.90, 95%CI, 1.68-2.15, I-2 =0%). The overall WT was higher for MAC compared to CC (mean difference [MD] 0.46 (0.00-0.92) minutes, I-2 = 94%).
   Conclusions There is an increase in adenoma and polyp detection with the utilization of AIAC.
C1 [Ashat, Munish; Murali, Arvind Rangarajan] Univ Iowa Hosp & Clin, Dept Gastroenterol & Hepatol, Iowa City, IA 52242 USA.
   [Klair, Jagpal Singh; Krishnamoorthi, Rajesh] Virginia Mason Med Ctr, Digest Dis Inst, Seattle, WA 98101 USA.
   [Singh, Dhruv] Mayo Clin, Div Gastroenterol & Hepatol, Rochester, NY USA.
C3 University of Iowa; Virginia Mason Medical Center; Mayo Clinic
RP Krishnamoorthi, R (通讯作者)，Virginia Mason Med Ctr, Div Gastroenterol & Hepatol, 1100 Ninth Ave, Seattle, WA 98101 USA.
EM Rajesh.Krishnamoorthi@virginiamason.org
OI Ashat, Munish/0000-0002-3337-3140
CR AHN S, 2012, NEW ENGL J MED, V6, P64
   [Anonymous], HDB GRADING QUALITY
   ANSPA SJ, 2010, NEW ENGL J MED, V363, P1373
   ASLANIAN H, 2013, GASTROINTEST ENDOSC, V108, P166
   ATKINSON N, 2019, NEW ENGL J MED, V157, P462
   AZIZ M, 2020, NEW ENGL J MED, V33, P178
   Aziz M, 2019, GASTROINTEST ENDOSC, V90, P721, DOI 10.1016/j.gie.2019.06.041
   Barret M, 2014, NEW ENGL J MED, V370, P2540, DOI 10.1056/NEJMc1405329
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   BRENNER H, 2010, NEW ENGL J MED, V102, P89
   BRENNER H, 2007, ANN GASTROENTEROL, V56, P1585
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   CORLEY D, 2014, CLIN J GASTROENTEROL, V370, P1298
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   EASTERBROOK PJ, 1991, LANCET, V337, P867, DOI 10.1016/0140-6736(91)90201-Y
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   HIGGINS J, 2011, GASTROINTEST ENDOSC, V343, P5928
   Jemal A, 2011, CA-CANCER J CLIN, V61, P133, DOI 10.3322/caac.20105
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   KRIEGESKORTE N, 2019, GUT, V29, pR231
   Lanspa SJ, 2010, NEW ENGL J MED, V363, P1371, DOI 10.1056/NEJMc1006842
   Lawrence Zoe, 2020, Curr Treat Options Gastroenterol, DOI 10.1007/s11938-020-00280-4
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   MORI Y, 2015, ENDOSCOPY, V81, P621
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   NAKAGAWASENDA H, 2019, NEW ENGL J MED, V19, P431
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   REX D, 2015, NEW ENGL J MED, V81, P31
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   STANG A, 2010, GUT, V25, P603
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   ZAUBER A, 2012, LANCET, V366, P687
NR 36
TC 17
Z9 17
U1 0
U2 1
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD APR
PY 2021
VL 09
IS 04
BP E513
EP E521
DI 10.1055/a-1341-0457
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA QY0OO
UT WOS:000629741500003
PM 33816771
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Guo, XQ
   Yang, C
   Liu, YJ
   Yuan, YX
AF Guo, Xiaoqing
   Yang, Chen
   Liu, Yajie
   Yuan, Yixuan
TI Learn to Threshold: ThresholdNet With Confidence-Guided Manifold Mixup
   for Polyp Segmentation
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Image segmentation; Training; Cancer; Feature extraction; Manifolds;
   Deep learning; Task analysis; Polyp segmentation; CGMMix data
   augmentation; consistency regularization; ThresholdNet; TMSG module
AB The automatic segmentation of polyp in endoscopy images is crucial for early diagnosis and cure of colorectal cancer. Existing deep learning-based methods for polyp segmentation, however, are inadequate due to the limited annotated dataset and the class imbalance problems. Moreover, these methods obtained the final polyp segmentation results by simply thresholding the likelihood maps at an eclectic and equivalent value (often set to 0.5). In this paper, we propose a novel ThresholdNet with a confidence-guided manifold mixup (CGMMix) data augmentation method, mainly for addressing the aforementioned issues in polyp segmentation. The CGMMix conducts manifold mixup at the image and feature levels, and adaptively lures the decision boundary away from the under-represented polyp class with the confidence guidance to alleviate the limited training dataset and the class imbalance problems. Two consistency regularizations, mixup feature map consistency (MFMC) loss and mixup confidence map consistency (MCMC) loss, are devised to exploit the consistent constraints in the training of the augmented mixup data. We then propose a two-branch approach, termed ThresholdNet, to collaborate the segmentation and threshold learning in an alternative training strategy. The threshold map supervision generator (TMSG) is embedded to provide supervision for the threshold map, thereby inducing better optimization of the threshold branch. As a consequence, ThresholdNet is able to calibrate the segmentation result with the learned threshold map. We illustrate the effectiveness of the proposed method on two polyp segmentation datasets, and our methods achieved the state-of-the-art result with 87.307% and 87.879% dice score on the EndoScene dataset and the WCE polyp dataset. The source code is available at https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/Guo-Xiaoqing/ThresholdNet.
C1 [Guo, Xiaoqing; Yang, Chen; Yuan, Yixuan] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Liu, Yajie] Peking Univ, Dept Radiat Oncol, Shenzhen Hosp, Shenzhen 518036, Peoples R China.
C3 City University of Hong Kong; Peking University
RP Yuan, YX (通讯作者)，City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM xqguo.ee@my.cityu.edu.hk; cyang.ee@my.cityu.edu.hk; liuyajie@pkuszh.com;
   yxyuan.ee@cityu.edu.hk
OI GUO, Xiaoqing/0000-0002-9476-521X; Yuan, Yixuan/0000-0002-0853-6948;
   YANG, Chen/0000-0001-7841-5300
FU Hong Kong Research Grants Council (RGC) Early Career Scheme [21207420];
   Hong Kong RGC Collaborative Research Fund [C4063-18GF]; National Natural
   Science Foundation of China [62001410]
FX This work was supported by the Hong Kong Research Grants Council (RGC)
   Early Career Scheme under Grant 21207420, the Hong Kong RGC
   Collaborative Research Fund under Grant C4063-18GF, and the National
   Natural Science Foundation of China under Grant 62001410.
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bagheri M, 2019, IEEE ENG MED BIO, P6742, DOI 10.1109/EMBC.2019.8856793
   Berthelot D., 2019, ADV NEURAL INFORM PR
   Chaitanya K, 2019, LECT NOTES COMPUT SC, V11492, P29, DOI 10.1007/978-3-030-20351-1_3
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Guo XQ, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101733
   Guo XQ, 2019, LECT NOTES COMPUT SC, V11764, P293, DOI 10.1007/978-3-030-32239-7_33
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li ZJ, 2019, LECT NOTES COMPUT SC, V11766, P402, DOI 10.1007/978-3-030-32248-9_45
   Murugesan B, 2019, IEEE ENG MED BIO, P7223, DOI 10.1109/EMBC.2019.8857339
   Nguyen NQ, 2019, IEEE ACCESS, V7, P33795, DOI 10.1109/ACCESS.2019.2904094
   Nieminen M. T., 2019, P IEEE CVF INT C COM
   Poorneshwaran JM, 2019, IEEE ENG MED BIO, P7201, DOI 10.1109/EMBC.2019.8857958
   Qadir HA, 2019, IEEE ACCESS, V7, P169537, DOI 10.1109/ACCESS.2019.2954675
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI [DOI 10.3322/CAAC.21442, 10.3322/caac.21332]
   Smith RA, 2018, CA-CANCER J CLIN, V68, P297, DOI 10.3322/caac.21446
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Verma V., 2018, INT C MACH LEARN
   Wang LS, 2019, IEEE ACCESS, V7, P44676, DOI 10.1109/ACCESS.2019.2908386
   Wang Q, 2019, IEEE I CONF COMP VIS, P1466, DOI 10.1109/ICCV.2019.00155
   Wang Y, 2020, IEEE T MED IMAGING, V39, P866, DOI 10.1109/TMI.2019.2936500
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   Xu M., 2019, ARXIV191201805
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yuan Y., 2018, OCNET OBJECT CONTEXT
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Zhang H., 2018, P ICLR
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zoph B., 2019, ARXIV191202781
NR 39
TC 19
Z9 19
U1 1
U2 26
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD APR
PY 2021
VL 40
IS 4
BP 1134
EP 1146
DI 10.1109/TMI.2020.3046843
PG 13
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA RJ3XU
UT WOS:000637532800004
PM 33360986
DA 2023-08-21
ER

PT J
AU Hwang, SJ
   Park, SJ
   Kim, GM
   Baek, JH
AF Hwang, Seung-Jun
   Park, Sung-Jun
   Kim, Gyu-Min
   Baek, Joong-Hwan
TI Unsupervised Monocular Depth Estimation for Colonoscope System Using
   Feedback Network
SO SENSORS
LA English
DT Article
DE unsupervised deep learning; monocular depth estimation; colonoscopy
AB A colonoscopy is a medical examination used to check disease or abnormalities in the large intestine. If necessary, polyps or adenomas would be removed through the scope during a colonoscopy. Colorectal cancer can be prevented through this. However, the polyp detection rate differs depending on the condition and skill level of the endoscopist. Even some endoscopists have a 90% chance of missing an adenoma. Artificial intelligence and robot technologies for colonoscopy are being studied to compensate for these problems. In this study, we propose a self-supervised monocular depth estimation using spatiotemporal consistency in the colon environment. It is our contribution to propose a loss function for reconstruction errors between adjacent predicted depths and a depth feedback network that uses predicted depth information of the previous frame to predict the depth of the next frame. We performed quantitative and qualitative evaluation of our approach, and the proposed FBNet (depth FeedBack Network) outperformed state-of-the-art results for unsupervised depth estimation on the UCL datasets.
C1 [Hwang, Seung-Jun; Park, Sung-Jun; Kim, Gyu-Min; Baek, Joong-Hwan] Korea Aerosp Univ, Sch Elect & Informat Engn, Goyang 10540, South Korea.
C3 Korea Aerospace University
RP Baek, JH (通讯作者)，Korea Aerosp Univ, Sch Elect & Informat Engn, Goyang 10540, South Korea.
EM fogfog2@kau.kr; tjdwns1011@naver.com; gyumin46@naver.com;
   jhbaek@kau.ac.kr
OI Hwang, Seung-Jun/0000-0003-2576-2274
FU GRRC program of Gyeonggi province
FX This research was supported by the GRRC program of Gyeonggi province
   [GRRC Aviation 2017-B04, Development of Intelligent Interactive Media
   and Space Convergence Application System].
CR Bernth JE, 2017, IEEE ROBOT AUTOM LET, V2, P1718, DOI 10.1109/LRA.2017.2678540
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Chen R.J., 2019, ARXIV 190700283
   Ciuti G, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061648
   Deng J., 2020, ARXIV181204605
   Formosa GA, 2020, IEEE T ROBOT, V36, P545, DOI 10.1109/TRO.2019.2949466
   Freedman D, 2020, IEEE T MED IMAGING, V39, P3451, DOI 10.1109/TMI.2020.2994221
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Gordon A, 2019, IEEE I CONF COMP VIS, P8976, DOI 10.1109/ICCV.2019.00907
   Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611
   Guizilini V., 2020, ARXIV 190502693
   He K., 2015, ABS151203385 CORR
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kang M, 2021, MECHATRONICS, V73, DOI 10.1016/j.mechatronics.2020.102478
   Khan F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082272
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Luo X, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392377
   Ma RB, 2019, LECT NOTES COMPUT SC, V11768, P573, DOI 10.1007/978-3-030-32254-0_64
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Mahmood F, 2018, IEEE T MED IMAGING, V37, P2572, DOI 10.1109/TMI.2018.2842767
   Mirza M., 2014, CONDITIONAL GENERATI, DOI DOI 10.48550/ARXIV.1411.1784
   Mun JH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112459
   Nadeem S., 2016, ARXIV 160901329
   Palafox PR, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143224
   Patil V., 2020, ARXIV200102613
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Rex DK, 2017, BEST PRACT RES CL GA, V31, P425, DOI 10.1016/j.bpg.2017.05.010
   Shu C., 2020, ARXIV 200710603
   Song CX, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185389
   Vasiljevic I., 2020, ARXIV 200806630
   Visentini-Scarzanella M, 2017, INT J COMPUT ASS RAD, V12, P1089, DOI 10.1007/s11548-017-1609-2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Yoon JH, 2019, INT CONF 3D VISION, P126, DOI 10.1109/3DV.2019.00023
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 41
TC 9
Z9 9
U1 3
U2 9
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD APR
PY 2021
VL 21
IS 8
AR 2691
DI 10.3390/s21082691
PG 16
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA RT9KW
UT WOS:000644773600001
PM 33920357
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Tang, CP
   Shao, PP
   Hsieh, YH
   Leung, FW
AF Tang, Chia-Pei
   Shao, Paul P.
   Hsieh, Yu-Hsi
   Leung, Felix W.
TI A review of water exchange and artificial intelligence in improving
   adenoma detection
SO TZU CHI MEDICAL JOURNAL
LA English
DT Review
DE Adenoma detection rate; Adenoma miss rate; Artificial intelligence;
   Computer-aided colonoscopy; Water exchange
ID SCREENING COLONOSCOPY; QUALITY INDICATORS; COLORECTAL-CANCER; AIR
   INSUFFLATION; POLYP DETECTION; MULTICENTER; INCREASES; EXPERIENCE;
   ENDOSCOPY; DIAGNOSIS
AB Water exchange (WE) and artificial intelligence (AI) have made critical advances during the past decade. WE significantly increases adenoma detection and AI holds the potential to help endoscopists detect more polyps and adenomas. We performed an electronic literature search on PubMed using the following keywords: water-assisted and water exchange colonoscopy, adenoma and polyp detection, artificial intelligence, deep learning, neural networks, and computer-aided colonoscopy. We reviewed relevant articles published in English from 2010 to May 2020. Additional articles were searched manually from the reference lists of the publications reviewed. We discussed recent advances in both WE and AI, including their advantages and limitations. M may mitigate operator-dependent factors that limit the potential of WE. By increasing bowel cleanliness and improving visualization, WE may provide the platform to optimize the performance of Al for colonoscopies. The strengths of WE and AI may complement each other in spite of their weaknesses to maximize adenoma detection.
C1 [Tang, Chia-Pei; Hsieh, Yu-Hsi] Buddhist Tzu Chi Med Fdn, Dalin Tzu Chi Hosp, Dept Internal Med, Div Gastroenterol, 2 Minsheng Rd, Chiayi, Taiwan.
   [Tang, Chia-Pei; Hsieh, Yu-Hsi] Tzu Chi Univ, Sch Med, Hualien, Taiwan.
   [Shao, Paul P.; Leung, Felix W.] Vet Affairs Greater Los Angeles Healthcare Syst, Sepulveda Ambulatory Care Ctr, North Hills, CA USA.
   [Shao, Paul P.; Leung, Felix W.] Univ Calif Los Angeles, David Geffen Sch Med, Dept Med, Div Gastroenterol, Los Angeles, CA 90095 USA.
C3 Buddhist Tzu Chi General Hospital; Dalin Tzu Chi Hospital; Tzu Chi
   University; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); VA Greater Los Angeles Healthcare System;
   University of California System; University of California Los Angeles;
   University of California Los Angeles Medical Center; David Geffen School
   of Medicine at UCLA
RP Hsieh, YH (通讯作者)，Buddhist Tzu Chi Med Fdn, Dalin Tzu Chi Hosp, Dept Internal Med, Div Gastroenterol, 2 Minsheng Rd, Chiayi, Taiwan.
EM hsieh.yuhsi@msa.hinet.net
FU Dalin Tzu Chi Hospital, Buddhist Tzu Chi Medical Foundation; VA Clinical
   Merit; ASGE Clinical Research Funds
FX The study was supported by research fund from the Dalin Tzu Chi
   Hospital, Buddhist Tzu Chi Medical Foundation. Dr. Leung's research and
   publication effort is supported by VA Clinical Merit and ASGE Clinical
   Research Funds.
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Cadoni S, 2019, GASTROINTEST ENDOSC, V89, P159, DOI 10.1016/j.gie.2018.07.020
   Cadoni S, 2017, ENDOSCOPY, V49, P456, DOI 10.1055/s-0043-101229
   Caldwell John A, 2005, Travel Med Infect Dis, V3, P85, DOI 10.1016/j.tmaid.2004.07.008
   Cheng CL, 2019, BMC GASTROENTEROL, V19, DOI 10.1186/s12876-019-1065-2
   Chiu SYH, 2017, GUT, V66, P293, DOI 10.1136/gutjnl-2015-310256
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Eastridge BJ, 2003, AM J SURG, V186, P169, DOI 10.1016/S0002-9610(03)00183-1
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Fuccio L, 2018, GASTROINTEST ENDOSC, V88, P589, DOI 10.1016/j.gie.2018.06.028
   Gaba DM, 2002, NEW ENGL J MED, V347, P1249, DOI 10.1056/NEJMsa020846
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hsieh YH, 2020, J GASTROEN HEPATOL, V35, P256, DOI 10.1111/jgh.14839
   Hsieh YH, 2019, UNITED EUR GASTROENT, V7, P230, DOI 10.1177/2050640618817105
   Hsieh YH, 2017, GASTROINTEST ENDOSC, V86, P192, DOI 10.1016/j.gie.2016.12.005
   Jia H, 2017, AM J GASTROENTEROL, V112, P568, DOI 10.1038/ajg.2016.501
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee RH, 2011, GASTROINTEST ENDOSC, V74, P128, DOI 10.1016/j.gie.2011.03.003
   Leung FW, 2010, GASTROINTEST ENDOSC, V72, P693, DOI 10.1016/j.gie.2010.05.020
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Liu Y, 2018, SAUDI J GASTROENTERO, V24, P311, DOI 10.4103/sjg.SJG_118_18
   Luo H, 2013, GASTROINTEST ENDOSC, V77, P767, DOI 10.1016/j.gie.2012.12.007
   Ministry of Health and Welfare, 2016, CANC REGISTRY ANN RE
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Ogiwara T, 2017, NEUROSURG FOCUS, V42, DOI 10.3171/2017.3.FOCUS16498
   Peters SL, 2010, CLIN GASTROENTEROL H, V8, P439, DOI 10.1016/j.cgh.2010.01.013
   Philip P, 2006, ANN INTERN MED, V144, P785, DOI 10.7326/0003-4819-144-11-200606060-00004
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Sanaka MR, 2009, AM J GASTROENTEROL, V104, P1659, DOI 10.1038/ajg.2009.249
   Solis-Munoz P, 2014, J GASTROEN HEPATOL, V29, P1237, DOI 10.1111/jgh.12537
   Soon MS, 2005, AM J GASTROENTEROL, V100, P2749, DOI 10.1111/j.1572-0241.2005.00355.x
   Spadaccini M, 2020, CLIN GASTROENTEROL H, V18, P1454, DOI 10.1016/j.cgh.2019.10.044
   Thakkar S, 2020, GASTROENTEROLOGY, V158, P1219, DOI 10.1053/j.gastro.2019.12.035
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wu JQ, 2018, DIGEST LIVER DIS, V50, P661, DOI 10.1016/j.dld.2018.03.035
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
NR 49
TC 6
Z9 6
U1 0
U2 0
PU WOLTERS KLUWER MEDKNOW PUBLICATIONS
PI MUMBAI
PA WOLTERS KLUWER INDIA PVT LTD , A-202, 2ND FLR, QUBE, C T S  NO 1498A-2
   VILLAGE MAROL, ANDHERI EAST, MUMBAI, Maharashtra, INDIA
SN 1016-3190
EI 2223-8956
J9 TZU CHI MED J
JI Tzu Chi Med. J.
PD APR-JUN
PY 2021
VL 33
IS 2
BP 108
EP 114
DI 10.4103/tcmj.tcmj_88_20
PG 7
WC Medicine, General & Internal
WE Emerging Sources Citation Index (ESCI)
SC General & Internal Medicine
GA RI1WO
UT WOS:000636701900002
PM 33912406
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Baker, S
   Monlezun, DJ
   Wieghard, N
   Whitlow, C
   Margolin, D
AF Baker, Sarah
   Monlezun, Dominique J.
   Wieghard, Nicole
   Whitlow, Charles
   Margolin, David
TI Are the current colonoscopy recommendations for interval surveillance in
   patients with polyps enough? Machine learning-augmented propensity score
   cohort analysis of 1840 patients
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
LA English
DT Article
DE Colon and rectal surgery; Gastroenterology; Colonoscopy; Colon polyps;
   Adenomatous polyps; Colorectal cancer; Polyp surveillance
AB Background Colonoscopy remains the gold standard for screening and surveillance of colorectal neoplasms, and is associated with a lower risk of colorectal cancer (CRC)-related mortality. The current interval surveillance recommendations in patients with previous adenomas lack sufficient evidence. The prevalence of subsequent adenomas, and especially high-risk adenomas, during surveillance is not well known. Methods The primary outcome of this study was to determine the prevalence of polyps upon surveillance colonoscopy in patients who have a history of adenomas on initial average-risk-screening colonoscopy, but then have a normal initial surveillance (second) colonoscopy between 2003 and 2017. This is the first known retrospective cohort study of adenoma detection rate (ADR) with sub-group analysis of patients with serial surveillance colonoscopies by abnormal and high-risk surveillance findings separately by prior abnormal colonoscopies and correct surveillance strategies based on the recent March 2020 updated guidelines. After ADR calculation, machine learning-augmented propensity score adjusted multivariable regression with augmented inverse-probability weighting propensity (AIPW) score analysis was used to assess the relationship between guideline adherence, as well as abnormal and high-risk surveillance findings. Results A total of 1840 patients with pathologically confirmed adenomas or cancer on an initial average-risk-screening (first) colonoscopy met study criteria. 837 (45.5%) had confirmed adenomas on second colonoscopy, and 1003 (54.5%) had normal findings. Of 837 patients with polyps on both first and second colonoscopy, 423 (50.5%) had adenomas on third colonoscopy. Of the 1003 patients without polyps on second colonoscopy, 406 (40.5%) had confirmed adenomas on third colonoscopy. Guideline adherence was low at 9.18%, though was associated in propensity score adjusted multivariable regression with increased odds of an abnormal third (but not high-risk) colonoscopy, with comparable AIPW results. Conclusion This 14-year study demonstrates the ADR to be > 40% on the third colonoscopy for patients with adenomas on initial screening colonoscopy, who then have a normal second colonoscopy. Through advanced machine learning and propensity score analysis, we showed that correct adherence is associated with higher odds of abnormal, but not high-risk abnormal 3rd colonoscopy, with evidence that high-risk surveillance findings are reduced by providers shortening the time between surveillance colonoscopies in contrast to the guidelines for those for whom there is presumed greater clinical suspicion of eventual cancer. Larger prospective trials are needed to guide optimal surveillance for these patients.
C1 [Baker, Sarah; Wieghard, Nicole; Whitlow, Charles; Margolin, David] Ochsner Clin & Alton Ochsner Med Fdn, Dept Colorectal Surg, New Orleans, LA 70115 USA.
   [Monlezun, Dominique J.] Univ Texas MD Anderson Canc Ctr, Div Internal Med, Houston, TX 77030 USA.
   [Monlezun, Dominique J.] Global Syst Analyt & Struct, New Orleans, LA USA.
C3 Ochsner Health System; University of Texas System; UTMD Anderson Cancer
   Center
RP Baker, S (通讯作者)，Ochsner Clin & Alton Ochsner Med Fdn, Dept Colorectal Surg, New Orleans, LA 70115 USA.
EM sarahbakermd@gmail.com
OI Baker, Sarah/0000-0002-3124-3000
CR *ACSUSMSTFACR, 2008, CA-CANCER J CLIN, V58, P130
   [Anonymous], CA CANCER J CLIN
   Austin PC, 2015, STAT MED, V34, P3661, DOI 10.1002/sim.6607
   Brookhart MA, 2013, CIRC-CARDIOVASC QUAL, V6, P604, DOI 10.1161/CIRCOUTCOMES.113.000359
   Calonge N, 2008, ANN INTERN MED, V149, P627, DOI 10.7326/0003-4819-149-9-200811040-00243
   Chen JH, 2017, NEW ENGL J MED, V376, P2507, DOI 10.1056/NEJMp1702071
   Click B, 2018, JAMA-J AM MED ASSOC, V319, P2021, DOI 10.1001/jama.2018.5809
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dvorin EL, 2018, JAMA INTERN MED, V178, P852, DOI 10.1001/jamainternmed.2018.0103
   Ferlitsch M, 2011, JAMA-J AM MED ASSOC, V306, P1352, DOI 10.1001/jama.2011.1362
   Glynn AN, 2010, POLIT ANAL, V18, P36, DOI 10.1093/pan/mpp036
   Gupta S, 2020, AM J GASTROENTEROL, V115, P415, DOI 10.14309/ajg.0000000000000544
   Johnson KW, 2018, J AM COLL CARDIOL, V71, P2668, DOI 10.1016/j.jacc.2018.03.521
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Monlezun DJ, 2018, BIOMED RES INT-UK, V2018, DOI 10.1155/2018/5051289
   Obermeyer Z, 2016, NEW ENGL J MED, V375, P1216, DOI 10.1056/NEJMp1606181
   Price-Haywood EG, 2018, J AM MED INFORM ASSN, V25, P702, DOI 10.1093/jamia/ocx161
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Winawer S, 2003, GASTROENTEROLOGY, V124, P544, DOI 10.1053/gast.2003.50044
NR 19
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0930-2794
EI 1432-2218
J9 SURG ENDOSC
JI Surg. Endosc.
PD FEB
PY 2022
VL 36
IS 2
BP 1284
EP 1292
DI 10.1007/s00464-021-08403-3
EA MAR 2021
PG 9
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA YG4FF
UT WOS:000632307100002
PM 33763746
DA 2023-08-21
ER

PT J
AU Rodriguez-Diaz, E
   Jepeal, LI
   Baffy, G
   Lo, WK
   Mashimo, H
   A'amar, O
   Bigio, IJ
   Singh, SK
AF Rodriguez-Diaz, Eladio
   Jepeal, Lisa I.
   Baffy, Gyorgy
   Lo, Wai-Kit
   Mashimo, Hiroshi
   A'amar, Ousama
   Bigio, Irving J.
   Singh, Satish K.
TI Artificial Intelligence-Based Assessment of Colorectal Polyp Histology
   by Elastic-Scattering Spectroscopy
SO DIGESTIVE DISEASES AND SCIENCES
LA English
DT Article
DE Artificial intelligence; Colorectal neoplasm; Colonic polyps;
   Colonoscopy; Machine learning; Spectroscopy
ID OPTICAL BIOPSY; COMMUNITY PRACTICE; COLON POLYPS; WHITE-LIGHT;
   DIAGNOSIS; LESIONS; SYSTEM; ENDOSCOPY; IMPACT; CANCER
AB Background Colonoscopic screening and surveillance for colorectal cancer could be made safer and more efficient if endoscopists could predict histology without the need to biopsy and perform histopathology on every polyp. Elastic-scattering spectroscopy (ESS), using fiberoptic probes integrated into standard biopsy tools, can assess, both in vivo and in real time, the scattering and absorption properties of tissue related to its underlying pathology. Aims The objective of this study was to evaluate prospectively the potential of ESS to predict polyp pathology accurately. Methods We obtained ESS measurements from patients undergoing screening/surveillance colonoscopy using an ESS fiberoptic probe integrated into biopsy forceps. The integrated forceps were used for tissue acquisition, following current standards of care, and optical measurement. All measurements were correlated to the index pathology. A machine learning model was then applied to measurements from 367 polyps in 169 patients to prospectively evaluate its predictive performance. Results The model achieved sensitivity of 0.92, specificity of 0.87, negative predictive value (NPV) of 0.87, and high-confidence rate (HCR) of 0.84 for distinguishing 220 neoplastic polyps from 147 non-neoplastic polyps of all sizes. Among 138 neoplastic and 131 non-neoplastic polyps <= 5 mm, the model achieved sensitivity of 0.91, specificity of 0.88, NPV of 0.89, and HCR of 0.83. Conclusions Results show that ESS is a viable endoscopic platform for real-time polyp histology, particularly for polyps <= 5 mm. ESS is a simple, low-cost, clinically friendly, optical biopsy modality that, when interfaced with minimally obtrusive endoscopic tools, offers an attractive platform for in situ polyp assessment.
C1 [Rodriguez-Diaz, Eladio; Jepeal, Lisa I.; Singh, Satish K.] VA Boston Healthcare Syst, Res Serv, 150 South Huntington Ave, Boston, MA 02130 USA.
   [Rodriguez-Diaz, Eladio; A'amar, Ousama; Bigio, Irving J.; Singh, Satish K.] Boston Univ, Coll Engn, Dept Biomed Engn, 44 Cummington Mall, Boston, MA 02215 USA.
   [Baffy, Gyorgy; Lo, Wai-Kit; Mashimo, Hiroshi; Singh, Satish K.] VA Boston Healthcare Syst, Sect Gastroenterol, Dept Med, 150 South Huntington Ave, Boston, MA 02130 USA.
   [Baffy, Gyorgy; Lo, Wai-Kit; Mashimo, Hiroshi; Singh, Satish K.] Brigham & Womens Hosp, Dept Med, 25 Shattuck St, Boston, MA 02115 USA.
   [Baffy, Gyorgy; Lo, Wai-Kit; Mashimo, Hiroshi; Singh, Satish K.] Harvard Med Sch, 25 Shattuck St, Boston, MA 02115 USA.
   [Bigio, Irving J.; Singh, Satish K.] Boston Univ, Sch Med, Dept Med, 72 E Concord St, Boston, MA 02118 USA.
C3 US Department of Veterans Affairs; Veterans Health Administration (VHA);
   Harvard University; VA Boston Healthcare System; Boston University; US
   Department of Veterans Affairs; Veterans Health Administration (VHA);
   Harvard University; VA Boston Healthcare System; Harvard University;
   Brigham & Women's Hospital; Harvard University; Harvard Medical School;
   Boston University
RP Singh, SK (通讯作者)，VA Boston Healthcare Syst, Res Serv, 150 South Huntington Ave, Boston, MA 02130 USA.; Singh, SK (通讯作者)，Boston Univ, Coll Engn, Dept Biomed Engn, 44 Cummington Mall, Boston, MA 02215 USA.; Singh, SK (通讯作者)，VA Boston Healthcare Syst, Sect Gastroenterol, Dept Med, 150 South Huntington Ave, Boston, MA 02130 USA.; Singh, SK (通讯作者)，Brigham & Womens Hosp, Dept Med, 25 Shattuck St, Boston, MA 02115 USA.; Singh, SK (通讯作者)，Harvard Med Sch, 25 Shattuck St, Boston, MA 02115 USA.; Singh, SK (通讯作者)，Boston Univ, Sch Med, Dept Med, 72 E Concord St, Boston, MA 02118 USA.
EM eladior@bu.edu; lisa.jepeal@va.gov; gyorgy.baffy@va.gov;
   wai-kit.lo@va.gov; hiroshi.mashimo@va.gov; oaamar@bu.edu; bigio@bu.edu;
   satish.singh@va.gov
RI Baffy, Gyorgy/P-7986-2018
OI Baffy, Gyorgy/0000-0002-8334-0400; Singh, Satish/0000-0002-7664-3155
FU CSR&D Award from the US Department of Veterans Affairs [CX001146,
   BX004455]; BLR&D Merit Review Award from the US Department of Veterans
   Affairs [CX001146, BX004455]
FX This work was supported by CSR&D and BLR&D Merit Review Awards CX001146
   and BX004455 from the US Department of Veterans Affairs. This material
   is the result of work supported with resources, and the use of
   facilities, at the VA Boston Healthcare System. The content does not
   represent the views of the US Department of Veterans Affairs or the US
   Government. The authors acknowledge the contribution of Michelle
   Freshman who provided editorial assistance.
CR A'Amar OM, 2013, LASER MED SCI, V28, P1323, DOI 10.1007/s10103-012-1245-6
   Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dhar A, 2006, GASTROINTEST ENDOSC, V63, P257, DOI 10.1016/j.gie.2005.07.026
   Fan Claire, 2018, Curr Treat Options Gastroenterol, V16, P182, DOI 10.1007/s11938-018-0176-0
   Grillone Gregory A, 2017, Laryngoscope, V127 Suppl 4, pS1, DOI 10.1002/lary.26763
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lovat LB, 2006, GUT, V55, P1078, DOI 10.1136/gut.2005.081467
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mourant J R, 1996, J Biomed Opt, V1, P192, DOI 10.1117/12.231372
   Parikh ND, 2016, ENDOSCOPY, V48, P731, DOI 10.1055/s-0042-107592
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Rastogi A, 2014, GASTROINTEST ENDOSC, V79, P390, DOI 10.1016/j.gie.2013.07.032
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, AM J GASTROENTEROL, V104, P739, DOI 10.1038/ajg.2009.104
   Rodriguez-Diaz E, 2019, PHOTOCHEM PHOTOBIOL, V95, P1441, DOI 10.1111/php.13140
   Rodriguez-Diaz E, 2015, GASTROINTEST ENDOSC, V81, P539, DOI 10.1016/j.gie.2014.07.012
   Rodriguez-Diaz E, 2014, INFLAMM BOWEL DIS, V20, P1029, DOI 10.1097/MIB.0000000000000058
   Rodriguez-Diaz E, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3592488
   Rosen JE, 2014, IEEE T BIO-MED ENG, V61, P2336, DOI 10.1109/TBME.2013.2267452
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI [DOI 10.3322/CAAC.21442, 10.3322/caac.21332]
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Taunk P, 2019, INT J COLORECTAL DIS, V34, P2043, DOI 10.1007/s00384-019-03406-y
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
NR 35
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0163-2116
EI 1573-2568
J9 DIGEST DIS SCI
JI Dig. Dis. Sci.
PD FEB
PY 2022
VL 67
IS 2
SI SI
BP 613
EP 621
DI 10.1007/s10620-021-06901-x
EA MAR 2021
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA ZJ5SL
UT WOS:000632359300004
PM 33761089
DA 2023-08-21
ER

PT J
AU Misawa, M
   Kudo, SE
   Mori, Y
   Hotta, K
   Ohtsuka, K
   Matsuda, T
   Saito, S
   Kudo, T
   Baba, T
   Ishida, F
   Itoh, H
   Oda, M
   Mori, K
AF Misawa, Masashi
   Kudo, Shin-ei
   Mori, Yuichi
   Hotta, Kinichi
   Ohtsuka, Kazuo
   Matsuda, Takahisa
   Saito, Shoichi
   Kudo, Toyoki
   Baba, Toshiyuki
   Ishida, Fumio
   Itoh, Hayato
   Oda, Masahiro
   Mori, Kensaku
TI Development of a computer-aided detection system for colonoscopy and a
   publicly accessible large colonoscopy video database (with video)
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID VALIDATION; DIAGNOSIS; POLYPS
AB Background and Aims: Artificial intelligence (AI)-assisted polyp detection systems for colonoscopic use are currently attracting attention because they may reduce the possibility of missed adenomas. However, few systems have the necessary regulatory approval for use in clinical practice. We aimed to develop an AI-assisted polyp detection system and to validate its performance using a large colonoscopy video database designed to be publicly accessible.
   Methods: To develop the deep learning-based AI system, 56,668 independent colonoscopy images were obtained from 5 centers for use as training images. To validate the trained AI system, consecutive colonoscopy videos taken at a university hospital between October 2018 and January 2019 were searched to construct a database containing polyps with unbiased variance. All images were annotated by endoscopists according to the presence or absence of polyps and the polyps' locations with bounding boxes.
   Results: A total of 1405 videos acquired during the study period were identified for the validation database, 797 of which contained at least 1 polyp. Of these, 100 videos containing 100 independent polyps and 13 videos negative for polyps were randomly extracted, resulting in 152,560 frames (49,799 positive frames and 102,761 negative frames) for the database. The AI showed 90.5% sensitivity and 93.7% specificity for frame-based analysis. The per-polyp sensitivities for all, diminutive, protruded, and flat polyps were 98.0%, 98.3%, 98.5%, and 97.0%, respectively.
   Conclusions: Our trained AI system was validated with a new large publicly accessible colonoscopy database and could identify colorectal lesions with high sensitivity and specificity.
C1 [Misawa, Masashi; Kudo, Shin-ei; Mori, Yuichi; Kudo, Toyoki; Baba, Toshiyuki; Ishida, Fumio] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Mori, Yuichi] Univ Oslo, Inst Hlth & Soc, Clin Effectiveness Res Grp, Oslo, Norway.
   [Hotta, Kinichi] Shizuoka Canc Ctr, Div Endoscopy, Shizuoka, Japan.
   [Ohtsuka, Kazuo] Tokyo Med & Dent Univ, Dept Endoscopy, Tokyo, Japan.
   [Matsuda, Takahisa] Natl Canc Ctr, Canc Screening Ctr, Tokyo, Japan.
   [Matsuda, Takahisa] Natl Canc Ctr, Endoscopy Div, Tokyo, Japan.
   [Matsuda, Takahisa] Natl Canc Ctr, Ctr Publ Hlth Sci, Div Screening Technol, Tokyo, Japan.
   [Saito, Shoichi] Canc Inst Hosp, Dept Gastroenterol, Tokyo, Japan.
   [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
C3 Showa University; University of Oslo; Shizuoka Cancer Center; Tokyo
   Medical & Dental University (TMDU); National Cancer Center - Japan;
   National Cancer Center - Japan; National Cancer Center - Japan; Japanese
   Foundation for Cancer Research; Nagoya University
RP Misawa, M (通讯作者)，Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Tsuzuki Ku, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
RI Itoh, Hayato/AAM-4022-2021; Misawa, Masashi/H-9004-2019; Ohtsuka,
   Kazuo/AAA-5139-2021
OI Itoh, Hayato/0000-0002-1410-1078; Misawa, Masashi/0000-0002-8520-2036;
   Oda, Masahiro/0000-0001-7714-422X
CR [Anonymous], R LANG ENV STAT COMP
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chinzei K, 2018, ADV BIOMED ENG, V7, P118, DOI 10.14326/abe.7.118
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Fujifilm Corporation, FUJIFILM ACQUIRES CE
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Kingma D., 2015, ARXIV
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Medtronic, MEDTRONIC LAUNCHES 1
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Pentax Medical, HOYA GROUP PENTAX ME
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
NR 23
TC 68
Z9 70
U1 5
U2 25
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD APR
PY 2021
VL 93
IS 4
BP 960
EP +
DI 10.1016/j.gie.2020.07.060
EA MAR 2021
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA QY4GQ
UT WOS:000630000300029
PM 32745531
HC Y
HP N
DA 2023-08-21
ER

PT J
AU van der Zander, QEW
   Schreuder, RM
   Fonolla, R
   Scheeve, T
   van der Sommen, F
   Winkens, B
   Aepli, P
   Hayee, B
   Pischel, AB
   Stefanovic, M
   Subramaniam, S
   Bhandari, P
   de With, PHN
   Masclee, AAM
   Schoon, EJ
AF van der Zander, Quirine E. W.
   Schreuder, Ramon M.
   Fonolla, Roger
   Scheeve, Thom
   van der Sommen, Fons
   Winkens, Bjorn
   Aepli, Patrick
   Hayee, Bu'Hussain
   Pischel, Andreas B.
   Stefanovic, Milan
   Subramaniam, Sharmila
   Bhandari, Pradeep
   de With, Peter H. N.
   Masclee, Ad A. M.
   Schoon, Erik J.
TI Optical diagnosis of colorectal polyp images using a newly developed
   computer-aided diagnosis system (CADx) compared with intuitive optical
   diagnosis
SO ENDOSCOPY
LA English
DT Article
ID CLASSIFICATION; HISTOLOGY; ABILITY; SOCIETY
AB Background Optical diagnosis of colorectal polyps remains challenging. Image-enhancement techniques such as narrow-band imaging and blue-light imaging (BLI) can improve optical diagnosis. We developed and prospectively validated a computer-aided diagnosis system (CADx) using high-definition white-light (HDWL) and BLI images, and compared the system with the optical diagnosis of expert and novice endoscopists.
   Methods CADx characterized colorectal polyps by exploiting artificial neural networks. Six experts and 13 novices optically diagnosed 60 colorectal polyps based on intuition. After 4 weeks, the same set of images was permuted and optically diagnosed using the BLI Adenoma Serrated International Classification (BASIC).
   Results CADx had a diagnostic accuracy of 88.3% using HDWL images and 86.7% using BLI images. The overall diagnostic accuracy combining HDWL and BLI (multimodal imaging) was 95.0%, which was significantly higher than that of experts (81.7%, P = 0.03) and novices (66.7%, P < 0.001). Sensitivity was also higher for CADx (95.6% vs. 61.1% and 55.4%), whereas specificity was higher for experts compared with CADx and novices (95.6% vs. 93.3% and 93.2%). For endoscopists, diagnostic accuracy did not increase when using BASIC, either for experts (intuition 79.5% vs. BASIC 81.7%, P = 0.14) or for novices (intuition 66.7% vs. BASIC 66.5 %, P = 0.95).
   Conclusion CADx had a significantly higher diagnostic accuracy than experts and novices for the optical diagnosis of colorectal polyps. Multimodal imaging, incorporating both HDWL and BLI, improved the diagnostic accuracy of CADx. BASIC did not increase the diagnostic accuracy of endoscopists compared with intuitive optical diagnosis.
C1 [van der Zander, Quirine E. W.; Masclee, Ad A. M.] Maastricht Univ Med Ctr Maastricht, Div Gastroenterol & Hepatol, Maastricht, Netherlands.
   [van der Zander, Quirine E. W.; Schoon, Erik J.] Maastricht Univ, Sch Oncol & Dev Biol, GROW, Maastricht, Netherlands.
   [Schreuder, Ramon M.; Schoon, Erik J.] Catharina Hosp, Div Gastroenterol & Hepatol, Eindhoven, Netherlands.
   [Fonolla, Roger; Scheeve, Thom; van der Sommen, Fons; de With, Peter H. N.] Eindhoven Univ Technol, Dept Elect Engn, Eindhoven, Netherlands.
   [Winkens, Bjorn] Maastricht Univ, Care & Publ Hlth Res Inst, Dept Methodol & Stat, CAPHRI, Maastricht, Netherlands.
   [Aepli, Patrick] Luzerner Kantonsspital, Div Gastroenterol & Hepatol, Luzern, Switzerland.
   [Hayee, Bu'Hussain] Kings Coll Hosp London, Div Gastroenterol & Hepatol, London, England.
   [Pischel, Andreas B.] Univ Hosp Gothenburg, Div Gastroenterol & Hepatol, Gothenburg, Sweden.
   [Stefanovic, Milan] Diagnosticni Ctr Bled, Div Gastroenterol & Hepatol, Ljubljana, Slovenia.
   [Subramaniam, Sharmila; Bhandari, Pradeep] Queen Alexandra Hosp, Div Gastroenterol & Hepatol, Portsmouth, Hants, England.
C3 Maastricht University; Maastricht University Medical Centre (MUMC);
   Maastricht University; Catharina Hospital; Eindhoven University of
   Technology; Maastricht University; Lucerne Cantonal Hospital; King's
   College Hospital NHS Foundation Trust; King's College Hospital;
   Sahlgrenska University Hospital; Portsmouth Hospitals NHS Trust; Queen
   Alexandra Hospital
RP van der Zander, QEW (通讯作者)，Maastricht Univ, Div Gastroenterol & Hepatol, P Debyelaan 25, NL-6229 HX Maastricht, Netherlands.
EM q.vanderzander@maastrichtuniversity.nl
RI Winkens, Bjorn/ABK-8803-2022
OI Winkens, Bjorn/0000-0002-6747-6228; Scheeve, Thom/0000-0002-8288-0368;
   van der Sommen, Fons/0000-0002-3593-2356; van der Zander, Quirine
   E.W./0000-0002-8640-5521; Hayee, Bu'Hussain/0000-0003-1670-8815
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Altman DG., 1992, PRACTICAL STAT MED R
   Bisschops R, 2018, ENDOSCOPY, V50, P211, DOI 10.1055/s-0043-121570
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Djinbachian Roupen, 2019, Curr Treat Options Gastroenterol, V17, P99, DOI 10.1007/s11938-019-00220-x
   Erickson-Bhatt S J, 2015, BIOPHOTONICS ASSESSI, P175
   European Parliament Council of the European Union Regulation (EU), 2016, OFFICIAL J EUROPEAN, V119, P88
   Foss FA, 2011, DIAGN HISTOPATHOL, V17, P495, DOI DOI 10.1016/J.MPDHP.2011.08.002
   Hassan C, 2020, ENDOSCOPY, V52, P52, DOI 10.1055/a-0995-0084
   Ijspeert JE, 2015, GASTROINTEST ENDOSC, V81, pAB260, DOI 10.1016/j.gie.2015.03.1348
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Leggett B, 2010, GASTROENTEROLOGY, V138, P2088, DOI 10.1053/j.gastro.2009.12.066
   McCarthy W F, 2007, ASSESSMENT SAMPLE SI, P28
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Nakano A, 2017, ENDOSC INT OPEN, V5, pE224, DOI 10.1055/s-0043-102400
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rondonotti E, 2019, GASTROINTEST ENDOSC, V89, P554, DOI 10.1016/j.gie.2018.09.027
   Rosner B, 1990, FUNDAMENTALS BIOSTAT, Vthird
   Schlemper RJ, 2000, GUT, V47, P251, DOI 10.1136/gut.47.2.251
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   SONG EM, 2020, SCI REP UK, V10
   Subramaniam S, 2019, UNITED EUR GASTROENT, V7, P316, DOI 10.1177/2050640618822402
   Tan M., 2019, INT C MACH LEARN, P6105, DOI DOI 10.48550/ARXIV.1905.11946
   van de Wetering AJP, 2020, ENDOSC INT OPEN, V8, pE257, DOI 10.1055/a-1072-4853
   Van den Brink N, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-022724
   Vleugels JLA, 2018, GASTROENTEROLOGY, V154, P1682, DOI 10.1053/j.gastro.2018.01.063
   World Med Assoc, 2013, JAMA-J AM MED ASSOC, V310, P2191, DOI 10.1001/jama.2013.281053
   Yoshida N, 2014, DIGEST ENDOSC, V26, P250, DOI 10.1111/den.12127
NR 32
TC 10
Z9 10
U1 0
U2 5
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD DEC
PY 2021
VL 53
IS 12
BP 1219
EP 1226
DI 10.1055/a-1343-1597
EA MAR 2021
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA XC7NL
UT WOS:000627129900001
PM 33368056
OA Green Published, Bronze
DA 2023-08-21
ER

PT J
AU Afify, HM
   Mohammed, KK
   Hassanien, AE
AF Afify, Heba M.
   Mohammed, Kamel K.
   Hassanien, Aboul Ella
TI An improved framework for polyp image segmentation based on SegNet
   architecture
SO INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE convolutional neural network; Kvasir&#8208; SEG database; polyp image
   segmentation; SegNet; VGG&#8208; 16 network; VGG&#8208; 19 network
ID MISS RATE; COLONOSCOPY; RISK
AB A polyp is one of the major causes of gastroenterology, which leads to colorectal cancer. The detection of polyps by colonoscopy imaging is a significant challenge because of the diversity in polyp structure and lack of examination accuracy. To solve this problem, the automatic segmentation of polyps can be used to enhance examination accuracy and reduce gastrointestinal (GI) disease. In this paper, the framework of polyp image segmentation is developed by a deep learning approach, especially a convolutional neural network. This proposed framework used the Kvasir-SEG database, which contains 1000 GI polyp images and corresponding segmentation masks according to annotation by medical experts. This database is divided into 900 for training images and 100 for testing images. This framework is based on image preprocessing and two types of SegNet architecture to obtain the segmented polyp image. This paper has demonstrated state-of-the-art performance on both VGG-16, and VGG-19 networks for training and testing data to address colorectal cancer screening rates. The results confirmed that the VGG-19 model has outperformed the VGG-16 model via all evaluation parameters except sensitivity for the polyp segmentation on the Kvasir-SEG dataset. Additionally, it will support gastroenterologists during medical strategy to correctly choose the treatment with less time.
C1 [Afify, Heba M.] Higher Inst Engn El Shorouk City, Dept Syst & Biomed Engn, Cairo, Egypt.
   [Afify, Heba M.; Mohammed, Kamel K.; Hassanien, Aboul Ella] Sci Res Grp Egypt SRGE, Cairo, Egypt.
   [Mohammed, Kamel K.] Al Azhar Univ, Ctr Virus Res & Studies, Cairo, Egypt.
   [Hassanien, Aboul Ella] Cairo Univ, Fac Comp & Informat, Giza, Egypt.
C3 Egyptian Knowledge Bank (EKB); Al Azhar University; Egyptian Knowledge
   Bank (EKB); Cairo University
RP Afify, HM (通讯作者)，Higher Inst Engn El Shorouk City, Dept Syst & Biomed Engn, Cairo, Egypt.
EM hebaaffify@yahoo.com
RI Afify, Heba M./N-7458-2018; Tawfic, Kamel/AAS-5347-2020
OI Afify, Heba M./0000-0002-6279-0883; Tawfic, Kamel/0000-0003-3907-8588;
   Hassanien, Professor Aboul Ella/0000-0002-9989-6681
CR Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   De Groen PC., IEEE INT C IM PROC, V2
   Debesh JHA., 2019, ARXIV191107067
   Fang Y., 2020, IEEE T NEUR NET LEAR, V3015831, P1, DOI [10.1109/JSEN.2020.301583, DOI 10.1109/TNNLS.2019.2912082]
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   Moradi M, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA)
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pozdeev AA, 2019, IEEE NW RUSS YOUNG, P1216, DOI 10.1109/EIConRus.2019.8657018
   Prabakaran J., 2012, DIAGN THER ENDOSC, V2012, P1
   Rey JF, 2001, ENDOSCOPY, V33, P901
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rundle AG, 2008, GASTROENTEROLOGY, V134, P1311, DOI 10.1053/j.gastro.2008.02.032
   Salem M A M, 2018, COMPUTER VISION CONC, P129, DOI DOI 10.4018/978-1-5225-5204-8.CH006
   Sanchez-Gonzalez A, 2018, IEEE INT SYMP SIGNAL, P579, DOI 10.1109/ISSPIT.2018.8642748
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Ucar MK, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2836236
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   Witten IH, 2011, MOR KAUF D, P147, DOI 10.1016/B978-0-12-374856-0.00005-5
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
NR 36
TC 7
Z9 8
U1 2
U2 18
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-9457
EI 1098-1098
J9 INT J IMAG SYST TECH
JI Int. J. Imaging Syst. Technol.
PD SEP
PY 2021
VL 31
IS 3
BP 1741
EP 1751
DI 10.1002/ima.22568
EA MAR 2021
PG 11
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA TU9TB
UT WOS:000626805000001
DA 2023-08-21
ER

PT J
AU Choi, SJ
   Kim, ES
   Choi, K
AF Choi, Seong Ji
   Kim, Eun Sun
   Choi, Kihwan
TI Prediction of the histology of colorectal neoplasm in white light
   colonoscopic images using deep learning algorithms
SO SCIENTIFIC REPORTS
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; CLASSIFICATION; POLYPS; SYSTEM
AB The treatment plan of colorectal neoplasm differs based on histology. Although new endoscopic imaging systems have been developed, there are clear diagnostic thresholds and requirements in using them. To overcome these limitations, we trained convolutional neural networks (CNNs) with endoscopic images and developed a computer-aided diagnostic (CAD) system which predicts the pathologic histology of colorectal adenoma. We retrospectively collected colonoscopic images from two tertiary hospitals and labeled 3400 images into one of 4 classes according to the final histology: normal, low-grade dysplasia, high-grade dysplasia, and adenocarcinoma. We implemented a CAD system based on ensemble learning with three CNN models which transfer the knowledge learned from common digital photography images to the colonoscopic image domain. The deep learning models were trained to classify the colorectal adenoma into these 4 classes. We compared the outcomes of the CNN models to those of two endoscopist groups having different years of experience, and visualized the model predictions using Class Activation Mapping. In our multi-center study, our CNN-CAD system identified the histology of colorectal adenoma with as sensitivity 77.25%, specificity of 92.42%, positive predictive value of 77.16%, negative predictive value of 92.58% averaged over the 4 classes, and mean diagnostic time of 0.12 s per image. Our experiments demonstrate that the CNN-CAD showed a similar performance to that of endoscopic experts and outperformed that of trainees. The model visualization results also showed reasonable regions of interest to explain the classification decisions of CAD systems. We suggest that CNN-CAD system can predict the histology of colorectal adenoma.
C1 [Choi, Seong Ji; Kim, Eun Sun] Korea Univ, Coll Med, Dept Internal Med, Div Gastroenterol & Hepatol, 73 Goryeodae Ro, Seoul 02841, South Korea.
   [Choi, Kihwan] Korea Inst Sci & Technol KIST, Ctr Bion, 5,Hwarang Ro 14 Gil, Seoul 02792, South Korea.
C3 Korea University; Korea University Medicine (KU Medicine); Korea
   Institute of Science & Technology (KIST)
RP Kim, ES (通讯作者)，Korea Univ, Coll Med, Dept Internal Med, Div Gastroenterol & Hepatol, 73 Goryeodae Ro, Seoul 02841, South Korea.; Choi, K (通讯作者)，Korea Inst Sci & Technol KIST, Ctr Bion, 5,Hwarang Ro 14 Gil, Seoul 02792, South Korea.
EM silverkes@naver.com; kihwanc@kist.re.kr
RI Choi, Kihwan/GSJ-1404-2022
OI Choi, Kihwan/0000-0003-4724-0418; Kim, Eun Sun/0000-0003-1820-459X
FU Korea Institute of Science and Technology (KIST) Institutional Program
   [2E31122]; Korea Medical Device Development Fund - Korea government
   [202011A02]; Institute of Information and Communications Technology
   Planning and Evaluation (IITP) - Ministry of Science and ICT
   [2017-000432]; National Research Foundation of Korea (NRF) - Ministry of
   Education [2018R1D1A1B07048202]; National Research Foundation of
   Korea(NRF) - Korea government(MSIT) [NRF-2021M3E5D1A01015177];
   Technology Innovation Program [20006045]; Ministry of Trade, Industry
   and Energy (MOTIE); Technology development Program - Ministry of SMEs
   and Startups (MSS) [S2680996]; Korea Technology & Information Promotion
   Agency for SMEs (TIPA) [S2680996] Funding Source: Korea Institute of
   Science & Technology Information (KISTI), National Science & Technology
   Information Service (NTIS); National Research Foundation of Korea
   [2018R1D1A1B07048202] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX Portions of this work were presented in the 42nd Annual International
   Conference of the IEEE Engineering in Medicine and Biology Society
   (EMBC), Montreal, Canada, July -202039. This work was supported in part
   by Korea Institute of Science and Technology (KIST) Institutional
   Program (2E31122), by the Korea Medical Device Development Fund grant
   funded by the Korea government (202011A02), by Institute of Information
   and Communications Technology Planning and Evaluation (IITP) funded by
   the Ministry of Science and ICT (2017-000432), by Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Education (2018R1D1A1B07048202), by the National
   Research Foundation of Korea(NRF) grant funded by the Korea
   government(MSIT) (NRF-2021M3E5D1A01015177), by the Technology Innovation
   Program (20006045) funded by the Ministry of Trade, Industry and Energy
   (MOTIE), and by the Technology development Program (S2680996) funded by
   the Ministry of SMEs and Startups (MSS). We thank Dr. Young Woo Ha
   (Korea University College of Medicine) for his assistance in data
   collection.
CR Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Basford PJ., 2013, GASTROINTEST ENDOSC, V77, pAB1, DOI [10.1016/j.gie.2012.09.023, DOI 10.1016/J.GIE.2012.09.023]
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Buchner AM, 2010, GASTROENTEROLOGY, V138, P834, DOI 10.1053/j.gastro.2009.10.053
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Choi K, 2020, IEEE ENG MED BIO, P1156, DOI 10.1109/EMBC44109.2020.9176653
   Choi Y, 2012, J KOREAN MED SCI, V27, P36, DOI 10.3346/jkms.2012.27.1.36
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ignjatovic A, 2011, GASTROINTEST ENDOSC, V73, P128, DOI 10.1016/j.gie.2010.09.021
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Le Berre C, 2020, GASTROENTEROLOGY, V158, P76, DOI 10.1053/j.gastro.2019.08.058
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P603, DOI 10.1016/j.gie.2011.04.049
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Mori Y, 2013, ENDOSCOPY, V45, P98, DOI 10.1055/s-0032-1325932
   Paszke A., 2019, ADV NEURAL INFORM PR, V32, P8026, DOI DOI 10.48550/ARXIV.1912.01703
   Picot J, 2017, HEALTH TECHNOL ASSES, V21, P1, DOI 10.3310/hta21790
   Rex Douglas K, 2012, Gastroenterol Hepatol (N Y), V8, P128
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simon K, 2016, CLIN INTERV AGING, V11, DOI 10.2147/CIA.S109285
   Simonyan K., ARXIV
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Utsumi T, 2015, CLIN ENDOSC, V48, P491, DOI 10.5946/ce.2015.48.6.491
   Yoshida N, 2011, J GASTROENTEROL, V46, P65, DOI 10.1007/s00535-010-0339-9
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 39
TC 5
Z9 5
U1 1
U2 5
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAR 5
PY 2021
VL 11
IS 1
AR 5311
DI 10.1038/s41598-021-84299-2
PG 12
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA QU6SH
UT WOS:000627410600001
PM 33674628
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Barua, I
   Vinsard, DG
   Jodal, HC
   Loberg, M
   Kalager, M
   Holme, O
   Misawa, M
   Bretthauer, M
   Mori, Y
AF Barua, Ishita
   Vinsard, Daniela Guerrero
   Jodal, Henriette C.
   Loberg, Magnus
   Kalager, Mette
   Holme, Oyvind
   Misawa, Masashi
   Bretthauer, Michael
   Mori, Yuichi
TI Artificial intelligence for polyp detection during colonoscopy: a
   systematic review and meta-analysis
SO ENDOSCOPY
LA English
DT Review
ID RISK
AB Background Artificial intelligence (AI)-based polyp detection systems are used during colonoscopy with the aim of increasing lesion detection and improving colonoscopy quality. Patients and methods: We performed a systematic review and meta-analysis of prospective trials to determine the value of AI-based polyp detection systems for detection of polyps and colorectal cancer. We performed systematic searches in MEDLINE, EMBASE, and Cochrane CENTRAL. Independent reviewers screened studies and assessed eligibility, certainty of evidence, and risk of bias. We compared colonoscopy with and without AI by calculating relative and absolute risks and mean differences for detection of polyps, adenomas, and colorectal cancer. Results: Five randomized trials were eligible for analysis. Colonoscopy with AI increased adenoma detection rates (ADRs) and polyp detection rates (PDRs) compared to colonoscopy without AI (values given with 95%CI). ADR with AI was 29.6% (22.2%-37.0%) versus 19.3% (12.7%-25.9%) without AI; relative risk (RR] 1.52 (1.31-1.77), with high certainty. PDR was 45.4% (41.1%-49.8%) with AI versus 30.6% (26.5%-34.6%) without AI; RR 1.48 (1.37-1.60), with high certainty. There was no difference in detection of advanced adenomas (mean advanced adenomas per colonoscopy 0.03 for each group, high certainty). Mean adenomas detected per colonoscopy was higher for small adenomas (<= 5mm) for AI versus non-AI (mean difference 0.15 [0.12-0.18]), but not for larger adenomas (>5-<= 10mm, mean difference 0.03 [0.01-0.05];>10mm, mean difference 0.01 [0.00-0.02]; high certainty). Data on cancer are unavailable. Conclusions: AI-based polyp detection systems during colonoscopy increase detection of small nonadvanced adenomas and polyps, but not of advanced adenomas.
C1 [Barua, Ishita; Jodal, Henriette C.; Loberg, Magnus; Kalager, Mette; Holme, Oyvind; Bretthauer, Michael; Mori, Yuichi] Univ Oslo, Inst Hlth & Soc, Clin Effectiveness Res Grp, Oslo, Norway.
   [Barua, Ishita; Jodal, Henriette C.; Loberg, Magnus; Kalager, Mette; Holme, Oyvind; Bretthauer, Michael; Mori, Yuichi] Oslo Univ Hosp, Dept Transplantat Med, Oslo, Norway.
   [Vinsard, Daniela Guerrero] Univ Connecticut, Ctr Hlth, Dept Internal Med, Storrs, CT USA.
   [Vinsard, Daniela Guerrero] Mayo Clin, Dept Gastroenterol & Hepatol, Rochester, MN USA.
   [Misawa, Masashi; Mori, Yuichi] Showa Univ, Northern Yokohama Hosp, Ctr Digest Dis, Yokohama, Kanagawa, Japan.
C3 University of Oslo; University of Oslo; University of Connecticut; Mayo
   Clinic; Showa University
RP Barua, I (通讯作者)，Univ Oslo, Inst Hlth & Soc, Clin Effectiveness Res Grp, Oslo, Norway.
EM ishita.barua@medisin.uio.no
RI Mori, Yuichi/AAU-5406-2020; Misawa, Masashi/H-9004-2019
OI Misawa, Masashi/0000-0002-8520-2036; Mori, Yuichi/0000-0003-2262-0334;
   Barua, Ishita/0000-0003-4200-8521; Jodal, Henriette
   Cecilie/0000-0001-6957-9469
FU Norwegian Research Council [250256]; Norwegian Cancer Society [6741288,
   190345]
FX Funding was provided by the Norwegian Research Council (grant no.
   250256) and the Norwegian Cancer Society (grant no. 6741288 and 190345)
CR Akl EA, 2012, J CLIN EPIDEMIOL, V65, P262, DOI 10.1016/j.jclinepi.2011.04.015
   Berzin TM, 2020, LANCET, V395, P485, DOI 10.1016/S0140-6736(20)30294-4
   CAI B, 2015, LANCET GASTROENTEROL, V9, P2073
   Cochrane Central Register of Controlled Trials, IMP AUT POL DET SYST, DOI [10.1002/central/CN-01933143/full, DOI 10.1002/CENTRAL/CN-01933143/FULL]
   Cochrane Central Register of Controlled Trials, EFF COL REAL TIM DET, DOI [10.1002/central/CN-01908583/full, DOI 10.1002/CENTRAL/CN-01908583/FULL]
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   GONG D, 2020, PLOS MED, V5, P352
   GOTTLIEB K, 2015, GUT, V15, P6
   Guyatt GH, 2008, BRIT MED J, V336, P924, DOI 10.1136/bmj.39489.470347.AD
   Kalager M, 2018, GASTROENTEROLOGY, V155, P592, DOI 10.1053/j.gastro.2018.07.037
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lauby-Secretan B, 2018, NEW ENGL J MED, V378, P1734, DOI 10.1056/NEJMsr1714643
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1186/s13643-015-0087-2, 10.1136/bmj.b2535]
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Sterne JAC, 2011, BMJ-BRIT MED J, V343, DOI 10.1136/bmj.d4002
   SU J, 2020, INT J SURG, V91, P415
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   von Renteln D, 2016, GUT, V65, P1056, DOI 10.1136/gutjnl-2016-311555
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 22
TC 82
Z9 84
U1 7
U2 38
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD MAR
PY 2021
VL 53
IS 03
BP 277
EP 284
DI 10.1055/a-1201-7165
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA QM2FH
UT WOS:000621595500030
PM 32557490
OA Green Published
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Xu, JW
   Zhao, R
   Yu, YZ
   Zhang, QW
   Bian, XZ
   Wang, J
   Ge, ZZ
   Qian, DH
AF Xu, Jianwei
   Zhao, Ran
   Yu, Yizhou
   Zhang, Qingwei
   Bian, Xianzhang
   Wang, Jun
   Ge, Zhizheng
   Qian, Dahong
TI Real-time automatic polyp detection in colonoscopy using feature
   enhancement module and spatiotemporal similarity correlation unit
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Colonoscopy; Automatic polyp detection; Convolutional neural networks;
   False positive relearning; Image style transfer; Feature enhancement;
   Spatiotemporal information
ID VALIDATION
AB Automatic detection of polyps is challenging because different polyps vary greatly, while the changes between polyps and their analogues are small. The state-of-the-art methods are based on convolutional neural networks (CNNs). However, they may fail due to lack of training data, resulting in high rates of missed detection and false positives (FPs). In order to solve these problems, our method combines the two-dimensional (2-D) CNN-based real-time object detector network with spatiotemporal information. Firstly, we use a 2-D detector network to detect static images and frames, and based on the detector network, we propose two feature enhancement modules-the FP Relearning Module (FPRM) to make the detector network learning more about the features of FPs for higher precision, and the Image Style Transfer Module (ISTM) to enhance the features of polyps for sensitivity improvement. In video detection, we integrate spatiotemporal information, which uses Structural Similarity (SSIM) to measure the similarity between video frames. Finally, we propose the Inter-frame Similarity Correlation Unit (ISCU) to combine the results obtained by the detector network and frame similarity to make the final decision. We verify our method on both private databases and publicly available databases. Experimental results show that these modules and units provide a performance improvement compared with the baseline method. Comparison with the state-of-the-art methods shows that the proposed method outperforms the existing ones which can meet real-time constraints. It's demonstrated that our method provides a performance improvement in sensitivity, precision and specificity, and has great potential to be applied in clinical colonoscopy.
C1 [Xu, Jianwei; Bian, Xianzhang; Wang, Jun; Qian, Dahong] Shanghai Jiao Tong Univ, Sch Biomed Engn, Inst Med Robot, Deepwise Healthcare Joint Res Lab, Shanghai, Peoples R China.
   [Zhao, Ran; Zhang, Qingwei; Ge, Zhizheng] Shanghai Jiao Tong Univ, Renji Hosp, Sch Med,Key Lab Gastroenterol & Hepatol,Minist Hl, Shanghai Inst Digest Dis,Div Gastroenterol & Hepa, Shanghai, Peoples R China.
   [Yu, Yizhou] Deepwise Artificial Intelligence Lab, Beijing, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Qian, DH (通讯作者)，Shanghai Jiao Tong Univ, Sch Biomed Engn, Inst Med Robot, Deepwise Healthcare Joint Res Lab, Shanghai, Peoples R China.; Ge, ZZ (通讯作者)，Shanghai Jiao Tong Univ, Renji Hosp, Sch Med,Key Lab Gastroenterol & Hepatol,Minist Hl, Shanghai Inst Digest Dis,Div Gastroenterol & Hepa, Shanghai, Peoples R China.
EM jianwei_xu@sjtu.edu.cn; zhaoranzr1996@163.com; zhizhengge@aliyun.com;
   dahong.qian@sjtu.edu.cn
RI /F-3345-2010
OI /0000-0002-0470-5548; Jun, Wang/0000-0001-9115-3755
FU National Natural Science Foundation of China, China [81974276];
   Department of Science and Technology of Zhejiang Province-Key Research
   and Development Program, China [2017C03029]
FX This work was supported in part by the National Natural Science
   Foundation of China, China, Grant 81974276, the Department of Science
   and Technology of Zhejiang Province-Key Research and Development
   Program, China, Grant 2017C03029. The authors would like to thank to the
   endoscopists in Renji Hospital affiliated to Shanghai Jiaotong
   University School of Medicine for their helpful contribution in
   collecting the colonoscopy datasets and providing the annotations.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], 2007, IEEE INT C IMAGE PRO, DOI [10.1109/ICIP.2007.4379193, DOI 10.1109/ICIP.2007.4379193]
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Deng J., 2019, ARXIV180801244 CS
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Hwang M, 2020, COMPUT MED IMAG GRAP, V84, DOI 10.1016/j.compmedimag.2020.101763
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mahendran A, 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2016.265, 10.1167/16.12.326]
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Nichol K, 2016, PAINTER NUMBERS
   Peng X, 2019, IEEE ENG MED BIO, P1637, DOI 10.1109/EMBC.2019.8856484
   Qadir HA, 2019, IEEE ACCESS, V7, P169537, DOI 10.1109/ACCESS.2019.2954675
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P471, DOI 10.1016/S0002-9270(02)05928-2
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Soetikno R, 2006, GASTROENTEROLOGY, V130, P566, DOI 10.1053/j.gastro.2005.12.006
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Sub, 2020, ARXIV201006034CS
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tischendorf J., 2009, INT SOC OPT PHOT 200, p72602Q
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 47
TC 18
Z9 18
U1 3
U2 8
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD APR
PY 2021
VL 66
AR 102503
DI 10.1016/j.bspc.2021.102503
EA FEB 2021
PG 12
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA RH5DX
UT WOS:000636240200098
OA Green Submitted
DA 2023-08-21
ER

PT J
AU Jheng, YC
   Wang, YP
   Lin, HE
   Sung, KY
   Chu, YC
   Wang, HS
   Jiang, JK
   Hou, MC
   Lee, FY
   Lu, CL
AF Jheng, Ying-Chun
   Wang, Yen-Po
   Lin, Hung-En
   Sung, Kuang-Yi
   Chu, Yuan-Chia
   Wang, Huann-Sheng
   Jiang, Jeng-Kai
   Hou, Ming-Chih
   Lee, Fa-Yauh
   Lu, Ching-Liang
TI A novel machine learning-based algorithm to identify and classify
   lesions and anatomical landmarks in colonoscopy images
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
LA English
DT Article
DE Artificial intelligence; Colonoscopy; Colon diseases; Computer-aided
   diagnosis system; convolution neural network; Heat map
ID ARTIFICIAL-INTELLIGENCE; COLORECTAL POLYPS; TIME
AB Objectives Computer-aided diagnosis (CAD)-based artificial intelligence (AI) has been shown to be highly accurate for detecting and characterizing colon polyps. However, the application of AI to identify normal colon landmarks and differentiate multiple colon diseases has not yet been established. We aimed to develop a convolutional neural network (CNN)-based algorithm (GUTAID) to recognize different colon lesions and anatomical landmarks. Methods Colonoscopic images were obtained to train and validate the AI classifiers. An independent dataset was collected for verification. The architecture of GUTAID contains two major sub-models: the Normal, Polyp, Diverticulum, Cecum and CAncer (NPDCCA) and Narrow-Band Imaging for Adenomatous/Hyperplastic polyps (NBI-AH) models. The development of GUTAID was based on the 16-layer Visual Geometry Group (VGG16) architecture and implemented on Google Cloud Platform. Results In total, 7838 colonoscopy images were used for developing and validating the AI model. An additional 1273 images were independently applied to verify the GUTAID. The accuracy for GUTAID in detecting various colon lesions/landmarks is 93.3% for polyps, 93.9% for diverticula, 91.7% for cecum, 97.5% for cancer, and 83.5% for adenomatous/hyperplastic polyps. Conclusions A CNN-based algorithm (GUTAID) to identify colonic abnormalities and landmarks was successfully established with high accuracy. This GUTAID system can further characterize polyps for optical diagnosis. We demonstrated that AI classification methodology is feasible to identify multiple and different colon diseases.
C1 [Jheng, Ying-Chun; Wang, Yen-Po; Lin, Hung-En; Sung, Kuang-Yi; Wang, Huann-Sheng; Hou, Ming-Chih; Lu, Ching-Liang] Taipei Vet Gen Hosp, Endoscopy Ctr Diag & Treatment, Taipei, Taiwan.
   [Jheng, Ying-Chun; Wang, Yen-Po; Lin, Hung-En; Sung, Kuang-Yi; Hou, Ming-Chih; Lee, Fa-Yauh; Lu, Ching-Liang] Taipei Vet Gen Hosp, Dept Med, Div Gastroenterol, Taipei, Taiwan.
   [Wang, Huann-Sheng; Jiang, Jeng-Kai] Taipei Vet Gen Hosp, Dept Surg, Div Colon & Rectum Surg, Taipei, Taiwan.
   [Chu, Yuan-Chia] Taipei Vet Gen Hosp, Informat Management Off, Taipei, Taiwan.
   [Jheng, Ying-Chun] Taipei Vet Gen Hosp, Dept Med Res, Taipei, Taiwan.
   [Wang, Yen-Po; Lu, Ching-Liang] Natl Yang Ming Univ, Inst Brain Sci, Sch Med, Taipei, Taiwan.
   [Jheng, Ying-Chun; Wang, Yen-Po; Lin, Hung-En; Sung, Kuang-Yi; Chu, Yuan-Chia; Wang, Huann-Sheng; Jiang, Jeng-Kai; Hou, Ming-Chih; Lee, Fa-Yauh; Lu, Ching-Liang] Natl Yang Ming Univ, Fac Med, Sch Med, Taipei, Taiwan.
C3 Taipei Veterans General Hospital; Taipei Veterans General Hospital;
   Taipei Veterans General Hospital; Taipei Veterans General Hospital;
   Taipei Veterans General Hospital; National Yang Ming Chiao Tung
   University; National Yang Ming Chiao Tung University
RP Lu, CL (通讯作者)，Taipei Vet Gen Hosp, Endoscopy Ctr Diag & Treatment, Taipei, Taiwan.; Lu, CL (通讯作者)，Taipei Vet Gen Hosp, Dept Med, Div Gastroenterol, Taipei, Taiwan.; Lu, CL (通讯作者)，Natl Yang Ming Univ, Inst Brain Sci, Sch Med, Taipei, Taiwan.; Lu, CL (通讯作者)，Natl Yang Ming Univ, Fac Med, Sch Med, Taipei, Taiwan.
EM cllu@ym.edu.tw
OI Wang, Yen-Po/0000-0002-3769-0020
FU Taipei Veterans General Hospital [V108B-020, V109B-041, V108E-004-4,
   V109E-002-5]
FX This study was supported by Grants from the Taipei Veterans General
   Hospital (V108B-020, V109B-041, V108E-004-4, V109E-002-5).
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Berzin TM, 2020, LANCET, V395, P485, DOI 10.1016/S0140-6736(20)30294-4
   BORGLI H, 2019, SCI DATA
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chan GCY, 2017, IEEE I C SIGNAL IMAG, P493, DOI 10.1109/ICSIPA.2017.8120662
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cho M, 2018, INT J COLORECTAL DIS, V33, P549, DOI 10.1007/s00384-018-2980-3
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Freedman MT, 2008, ACAD RADIOL, V15, P249, DOI 10.1016/j.acra.2007.07.010
   Geus PD., 2018, MALICIOUS SOFTWARE C, P51
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hogarty DT, 2020, AM J CLIN DERMATOL, V21, P41, DOI 10.1007/s40257-019-00462-6
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Hwang DK, 2019, THERANOSTICS, V9, P232, DOI 10.7150/thno.28447
   Ioffe S., 2015, PROC INT C MACH LEAR, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Li J., 2010, DIAGN THER ENDOSC, DOI 10.1155/2010/419796
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Martineau M, 2018, LECT NOTES COMPUT SC, V11182, P426, DOI 10.1007/978-3-030-01449-0_36
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2019, ENDOSCOPY, V51, P219, DOI 10.1055/a-0754-5556
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, GASTROINTEST ENDOSC, V85, pAB510, DOI 10.1016/j.gie.2017.03.1178
   Obuch Joshua C, 2015, Curr Treat Options Gastroenterol, V13, P156, DOI 10.1007/s11938-015-0046-y
   OWAIS M, 2019, J CLIN MED
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   RAJPURKAR P, 2018, PLOS MED, V15
   Rangarajan AK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59108-x
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Takenaka K, 2020, GASTROENTEROLOGY, V158, P2150, DOI 10.1053/j.gastro.2020.02.012
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang SD, 2020, OPEN MED-WARSAW, V15, P190, DOI 10.1515/med-2020-0028
   Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457
   WOLFF WI, 1974, CANCER, V34, P912, DOI 10.1002/1097-0142(197409)34:3+<912::AID-CNCR2820340720>3.0.CO;2-P
   Wu, 2018, GASTROENTEROLOGY, V154, pS, DOI 10.1016/S0016-5085(18)32100-0
NR 44
TC 6
Z9 6
U1 1
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0930-2794
EI 1432-2218
J9 SURG ENDOSC
JI Surg. Endosc.
PD JAN
PY 2022
VL 36
IS 1
BP 640
EP 650
DI 10.1007/s00464-021-08331-2
EA FEB 2021
PG 11
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA YD3WN
UT WOS:000618592500001
PM 33591447
DA 2023-08-21
ER

PT J
AU Xu, YX
   Ding, W
   Wang, YB
   Tan, YL
   Xi, C
   Ye, NY
   Wu, DP
   Xu, XZ
AF Xu, Yixin
   Ding, Wei
   Wang, Yibo
   Tan, Yulin
   Xi, Cheng
   Ye, Nianyuan
   Wu, Dapeng
   Xu, Xuezhong
TI Comparison of diagnostic performance between convolutional neural
   networks and human endoscopists for diagnosis of colorectal polyp: A
   systematic review and meta-analysis
SO PLOS ONE
LA English
DT Review
AB Prospective randomized trials and observational studies have revealed that early detection, classification, and removal of neoplastic colorectal polyp (CP) significantly improve the prevention of colorectal cancer (CRC). The current effectiveness of the diagnostic performance of colonoscopy remains unsatisfactory with unstable accuracy. The convolutional neural networks (CNN) system based on artificial intelligence (AI) technology has demonstrated its potential to help endoscopists in increasing diagnostic accuracy. Nonetheless, several limitations of the CNN system and controversies exist on whether it provides a better diagnostic performance compared to human endoscopists. Therefore, this study sought to address this issue. Online databases (PubMed, Web of Science, Cochrane Library, and EMBASE) were used to search for studies conducted up to April 2020. Besides, the quality assessment of diagnostic accuracy scale-2 (QUADAS-2) was used to evaluate the quality of the enrolled studies. Moreover, publication bias was determined using the Deeks' funnel plot. In total, 13 studies were enrolled for this meta-analysis (ranged between 2016 and 2020). Consequently, the CNN system had a satisfactory diagnostic performance in the field of CP detection (sensitivity: 0.848 [95% CI: 0.692-0.932]; specificity: 0.965 [95% CI: 0.946-0.977]; and AUC: 0.98 [95% CI: 0.96-0.99]) and CP classification (sensitivity: 0.943 [95% CI: 0.927-0.955]; specificity: 0.894 [95% CI: 0.631-0.977]; and AUC: 0.95 [95% CI: 0.93-0.97]). In comparison with human endoscopists, the CNN system was comparable to the expert but significantly better than the non-expert in the field of CP classification (CNN vs. expert: RDOR: 1.03, P = 0.9654; non-expert vs. expert: RDOR: 0.29, P = 0.0559; non-expert vs. CNN: 0.18, P = 0.0342). Therefore, the CNN system exhibited a satisfactory diagnostic performance for CP and could be used as a potential clinical diagnostic tool during colonoscopy.
C1 [Xu, Yixin; Ding, Wei; Wang, Yibo; Tan, Yulin; Xi, Cheng; Ye, Nianyuan; Xu, Xuezhong] Xuzhou Med Univ, Dept Gen Surg, Changzhou Wujin Peoples Hosp, Jiangsu Univ,Wujin Clin Coll, Changzhou, Jiangsu, Peoples R China.
   [Wu, Dapeng] Jiangsu Prov Hosp Tradit Chinese Med, Dept Endoscopy, Nanjing, Jiangsu, Peoples R China.
C3 Jiangsu University; Xuzhou Medical University; Nanjing University of
   Chinese Medicine
RP Xu, XZ (通讯作者)，Xuzhou Med Univ, Dept Gen Surg, Changzhou Wujin Peoples Hosp, Jiangsu Univ,Wujin Clin Coll, Changzhou, Jiangsu, Peoples R China.
EM xxz197001@sina.com
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Allen JE, 2017, BEST PRACT RES CL GA, V31, P435, DOI 10.1016/j.bpg.2017.07.001
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Chandrasekhara V, 2015, GASTROINTEST ENDOSC, V81, P1087, DOI 10.1016/j.gie.2014.12.007
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Deeks JJ, 2001, BRIT MED J, V323, P157, DOI 10.1136/bmj.323.7305.157
   Guimaraes P, 2020, GUT, V69, P4, DOI 10.1136/gutjnl-2019-319347
   Guo Z, 2021, DIGEST ENDOSC, V33, P162, DOI 10.1111/den.13670
   Higgins JPT, 2003, BMJ-BRIT MED J, V327, P557, DOI 10.1136/bmj.327.7414.557
   IJspeert JEG, 2017, GUT, V66, P1225, DOI 10.1136/gutjnl-2015-310784
   IJspeert JEG, 2016, GUT, V65, P963, DOI 10.1136/gutjnl-2014-308411
   Jackson D, 2011, STAT MED, V30, P2481, DOI 10.1002/sim.4172
   Jackson D, 2010, STAT MED, V29, P1282, DOI 10.1002/sim.3602
   Jones CM, 2005, ANN THORAC SURG, V79, P16, DOI 10.1016/j.athoracsur.2004.09.040
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Kuntz KM, 2011, MED DECIS MAKING, V31, P530, DOI 10.1177/0272989X11408730
   Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837
   Li D, 2020, GASTROENTEROLOGY, V159, P502, DOI 10.1053/j.gastro.2020.04.004
   Montminy EM, 2020, MED CLIN N AM, V104, P1023, DOI 10.1016/j.mcna.2020.08.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   MOSES LE, 1993, STAT MED, V12, P1293, DOI 10.1002/sim.4780121403
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Pilonis ND, 2020, ANN INTERN MED, V173, P81, DOI 10.7326/M19-2477
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Saxe A, 2021, NAT REV NEUROSCI, V22, P55, DOI 10.1038/s41583-020-00395-8
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Sehgal V, 2018, GASTROENT RES PRACT, V2018, DOI 10.1155/2018/1872437
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Strum WB, 2016, NEW ENGL J MED, V375, P389, DOI 10.1056/NEJMc1604867
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   White IR, 2011, STATA J, V11, P255, DOI 10.1177/1536867X1101100206
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yamada M, 2015, GASTROINTEST ENDOSC, V82, P108, DOI 10.1016/j.gie.2014.12.037
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
NR 43
TC 16
Z9 16
U1 2
U2 10
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD FEB 16
PY 2021
VL 16
IS 2
AR e0246892
DI 10.1371/journal.pone.0246892
PG 15
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA QK8MA
UT WOS:000620632800006
PM 33592048
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Rodriguez-Diaz, E
   Baffy, G
   Lo, WK
   Mashimo, H
   Vidyarthi, G
   Mohapatra, SS
   Singh, SK
AF Rodriguez-Diaz, Eladio
   Baffy, Gyorgy
   Lo, Wai-Kit
   Mashimo, Hiroshi
   Vidyarthi, Gitanjali
   Mohapatra, Shyam S.
   Singh, Satish K.
TI Real-time artificial intelligence-based histologic classification of
   colorectal polyps with augmented visualization
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; COLON POLYPS; COMMUNITY PRACTICE; VASCULAR
   PATTERNS; WHITE-LIGHT; SYSTEM; COLONOSCOPY; ENDOSCOPY; SOCIETY;
   MAGNIFICATION
AB Background and Aims: Artificial intelligence (AI)-based computer-aided diagnostic (CADx) algorithms are a promising approach for real-time histology (RTH) of colonic polyps. Our aim is to present a novel in situ CADx approach that seeks to increase transparency and interpretability of results by generating an intuitive augmented visualization of the model's predicted histology over the polyp surface.
   Methods: Wedeveloped a deep learningmodel using semantic segmentation to delineate polyp boundaries and a deep learning model to classify subregions within the segmented polyp. These subregions were classified independently and were subsequently aggregated to generate a histology map of the polyp's surface. We used 740 high-magnification narrow-band images from 607 polyps in 286 patients and over 65,000 subregions to train and validate the model.
   Results: The model achieved a sensitivity of.96, specificity of.84, negative predictive value (NPV) of.91, and high-confidence rate (HCR) of.88, distinguishing 171 neoplastic polyps from 83 non-neoplastic polyps of all sizes. Among 93 neoplastic and 75 non-neoplastic polyps <= 5 mm, the model achieved a sensitivity of.95, specificity of.84, NPV of.91, and HCR of.86.
   Conclusions: The CADxmodel is capable of accurately distinguishing neoplastic from non-neoplastic polyps and provides a histology map of the spatial distribution of localized histologic predictions along the delineated polyp surface. This capability may improve interpretability and transparency of AI-based RTH and offer intuitive, accurate, and user-friendly guidance in real time for the clinical management and documentation of optical histology results.
C1 [Rodriguez-Diaz, Eladio; Singh, Satish K.] VA Boston Healthcare Syst, Res Serv, Boston, MA 02130 USA.
   [Rodriguez-Diaz, Eladio; Singh, Satish K.] Boston Univ, Coll Engn, Dept Biomed Engn, Boston, MA 02215 USA.
   [Baffy, Gyorgy; Lo, Wai-Kit; Mashimo, Hiroshi; Singh, Satish K.] VA Boston Healthcare Syst, Dept Med, Sect Gastroenterol, 150 South Huntington Ave,GI 111, Boston, MA 02130 USA.
   [Singh, Satish K.] Boston Univ, Sch Med, Dept Med, Boston, MA 02118 USA.
   [Baffy, Gyorgy; Lo, Wai-Kit; Mashimo, Hiroshi; Singh, Satish K.] Harvard Med Sch, Brigham & Womens Hosp, Dept Med, Boston, MA 02115 USA.
   [Vidyarthi, Gitanjali] James A Haley Vet Hosp, Sect Gastroenterol, Tampa, FL 33612 USA.
   [Mohapatra, Shyam S.] James A Haley Vet Hosp, Res Serv, Tampa, FL 33612 USA.
   [Vidyarthi, Gitanjali; Mohapatra, Shyam S.] Univ S Florida, Morsani Coll Med, Dept Med, Tampa, FL 33620 USA.
C3 US Department of Veterans Affairs; Veterans Health Administration (VHA);
   Harvard University; VA Boston Healthcare System; Boston University; US
   Department of Veterans Affairs; Veterans Health Administration (VHA);
   Harvard University; VA Boston Healthcare System; Boston University;
   Harvard University; Brigham & Women's Hospital; Harvard Medical School;
   US Department of Veterans Affairs; Veterans Health Administration (VHA);
   James A. Haley Veterans Hospital; US Department of Veterans Affairs;
   Veterans Health Administration (VHA); James A. Haley Veterans Hospital;
   State University System of Florida; University of South Florida
RP Singh, SK (通讯作者)，VA Boston Healthcare Syst, Dept Med, Sect Gastroenterol, 150 South Huntington Ave,GI 111, Boston, MA 02130 USA.
EM satish.singh@va.gov
RI Baffy, Gyorgy/P-7986-2018; 于, 于增臣/AAH-4657-2021
OI Baffy, Gyorgy/0000-0002-8334-0400; 
FU U.S. Department of Veterans Affairs as a collaboration as part of the VA
   Colorectal Cancer Cellgenomics Consortium ("VA4C") [IK6BX003778,
   CX001146, BX004455]; VA Boston Healthcare System
FX The following authors received research support for this study from the
   U.S. Department of Veterans Affairs as a collaboration as part of the VA
   Colorectal Cancer Cellgenomics Consortium ("VA4C"): S. S. Mohapatra
   (Research Career Scientist Award IK6BX003778) and S. K. Singh (CSR&D and
   BLR&D Merit Review Awards CX001146 and BX004455). This material is the
   result of work supported with resources and use of facilities at the VA
   Boston Healthcare System. The contents do not represent the views of the
   U.S. Department of Veterans Affairs or the U.S. Government. All other
   authors disclosed no financial relationships.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Berzin TM, 2020, GASTROINTEST ENDOSC, V92, P951, DOI 10.1016/j.gie.2020.06.035
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cho BJ, 2020, AM J GASTROENTEROL, V115, P70, DOI 10.14309/ajg.0000000000000476
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Fan Claire, 2018, Curr Treat Options Gastroenterol, V16, P182, DOI 10.1007/s11938-018-0176-0
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P494, DOI 10.1016/j.gie.2011.08.002
   Gupta S, 2020, GASTROENTEROLOGY, V158, P1131, DOI 10.1053/j.gastro.2019.10.026
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Ijspeert JE, 2015, GASTROINTEST ENDOSC, V81, pAB260, DOI 10.1016/j.gie.2015.03.1348
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Pu LZCT, 2020, GASTROINTEST ENDOSC, V92, P891, DOI 10.1016/j.gie.2020.02.042
   Rastogi A, 2014, GASTROINTEST ENDOSC, V79, P390, DOI 10.1016/j.gie.2013.07.032
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Rastogi A, 2009, GASTROINTEST ENDOSC, V69, P716, DOI 10.1016/j.gie.2008.09.058
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rex DK, 2009, AM J GASTROENTEROL, V104, P739, DOI 10.1038/ajg.2009.104
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Tamaki T, 2011, LECT NOTES COMPUT SC, V6493, P452
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Wada Y, 2009, GASTROINTEST ENDOSC, V70, P522, DOI 10.1016/j.gie.2009.01.040
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
NR 36
TC 31
Z9 33
U1 0
U2 9
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD MAR
PY 2021
VL 93
IS 3
BP 662
EP 670
DI 10.1016/j.gie.2020.09.018
EA FEB 2021
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA QL0PS
UT WOS:000620783500022
PM 32949567
DA 2023-08-21
ER

PT J
AU Kim, YJ
   Bae, JP
   Chung, JW
   Park, DK
   Kim, KG
   Kim, YJ
AF Kim, Young Jae
   Bae, Jang Pyo
   Chung, Jun-Won
   Park, Dong Kyun
   Kim, Kwang Gi
   Kim, Yoon Jae
TI New polyp image classification technique using transfer learning of
   network-in-network structure in endoscopic images
SO SCIENTIFIC REPORTS
LA English
DT Article
ID PREVALENCE
AB While colorectal cancer is known to occur in the gastrointestinal tract. It is the third most common form of cancer of 27 major types of cancer in South Korea and worldwide. Colorectal polyps are known to increase the potential of developing colorectal cancer. Detected polyps need to be resected to reduce the risk of developing cancer. This research improved the performance of polyp classification through the fine-tuning of Network-in-Network (NIN) after applying a pre-trained model of the ImageNet database. Random shuffling is performed 20 times on 1000 colonoscopy images. Each set of data are divided into 800 images of training data and 200 images of test data. An accuracy evaluation is performed on 200 images of test data in 20 experiments. Three compared methods were constructed from AlexNet by transferring the weights trained by three different state-of-the-art databases. A normal AlexNet based method without transfer learning was also compared. The accuracy of the proposed method was higher in statistical significance than the accuracy of four other state-of-the-art methods, and showed an 18.9% improvement over the normal AlexNet based method. The area under the curve was approximately 0.930 +/- 0.020, and the recall rate was 0.929 +/- 0.029. An automatic algorithm can assist endoscopists in identifying polyps that are adenomatous by considering a high recall rate and accuracy. This system can enable the timely resection of polyps at an early stage.
C1 [Kim, Young Jae; Bae, Jang Pyo; Kim, Kwang Gi] Gachon Univ, Coll Med, Gil Med Ctr, Dept Biomed Engn, 21 Namdong Daero 774 Beon Gil, Incheon 21565, South Korea.
   [Chung, Jun-Won; Park, Dong Kyun; Kim, Yoon Jae] Gachon Univ, Gil Med Ctr, Dept Internal Med, Div Gastroenterol, 21 Namdongdaero 774 Beon Gil, Incheon 21565, South Korea.
C3 Gachon University; Gachon University
RP Kim, KG (通讯作者)，Gachon Univ, Coll Med, Gil Med Ctr, Dept Biomed Engn, 21 Namdong Daero 774 Beon Gil, Incheon 21565, South Korea.; Kim, YJ (通讯作者)，Gachon Univ, Gil Med Ctr, Dept Internal Med, Div Gastroenterol, 21 Namdongdaero 774 Beon Gil, Incheon 21565, South Korea.
EM kimkg@gachon.ac.kr; yoonmed@gachon.ac.kr
RI Chung, Jun-Won/AAX-4365-2021; Kim, Yoon Jae/G-6633-2015; kim,
   kwanggi/D-6890-2012
OI Chung, Jun-Won/0000-0002-0869-7661; Kim, Yoon Jae/0000-0001-8477-6823;
   kim, kwanggi/0000-0001-9714-6038
FU Gachon University, Republic of Korea [2019-0369]; National Research
   Foundation of Korea(NRF) - Korea government(MEST) [NRF-2020R1A2C1011708]
FX This work was supported by a grant from Gachon University, Republic of
   Korea (Gachon 2019-0369), and by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MEST) (No.
   NRF-2020R1A2C1011708)
CR Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jaderberg M., 2015, P 28 INT C NEUR INF, P2017
   Jung KW, 2015, CANCER RES TREAT, V47, P127, DOI 10.4143/crt.2015.060
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumar S, 2017, GASTROINTEST ENDOSC, V85, P1273, DOI 10.1016/j.gie.2016.11.030
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin M., NETWORK IN NETWORK
   Lou GC, 2014, TURK J GASTROENTEROL, V25, P182, DOI 10.5152/tjg.2014.4664
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Park S.H., 2015, ISBI 2015 CHALLENGE
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sang-il Ahn, 2019, International Journal of Information and Electronics Engineering, V9, P50, DOI 10.18178/ijiee.2019.9.2.704
   Sonnenberg A, 2015, AM J GASTROENTEROL, V110, P1056, DOI 10.1038/ajg.2015.130
   STRYKER SJ, 1987, GASTROENTEROLOGY, V93, P1009, DOI 10.1016/0016-5085(87)90563-4
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Taniguchi H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25679-z
   Whitaker J, 2019, DEEP LEARNING NLP SP, P463
   Yang XK, 2019, IEEE SENSOR, DOI [10.1109/sensors43011.2019.8956809, 10.1145/3326285.3329067]
   Zhang JM, 2017, INT J COMPUT VISION, V124, P169, DOI 10.1007/s11263-017-1011-0
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang XM, 2018, MULTIMED TOOLS APPL, V77, P7469, DOI 10.1007/s11042-017-4657-2
   Zhou B., 2014, ADV NEURAL INFORM PR, P487
NR 26
TC 8
Z9 8
U1 0
U2 6
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD FEB 11
PY 2021
VL 11
IS 1
AR 3605
DI 10.1038/s41598-021-83199-9
PG 8
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA QT6UX
UT WOS:000626725700009
PM 33574394
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Ali, HA
   Shin, Y
   Solhusvik, J
   Bergsland, J
   Aabakken, L
   Balasingham, I
AF Ali, Hemin Ali
   Shin, Younghak
   Solhusvik, Johannes
   Bergsland, Jacob
   Aabakken, Lars
   Balasingham, Ilangko
TI Toward real-time polyp detection using fully CNNs for 2D Gaussian shapes
   prediction
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Polyp detection; Deep learning; Colonoscopy; Convolutional neural
   networks; Real-time detection
ID VALIDATION
AB To decrease colon polyp miss-rate during colonoscopy, a real-time detection system with high accuracy is needed. Recently, there have been many efforts to develop models for real-time polyp detection, but work is still required to develop real-time detection algorithms with reliable results. We use single-shot feed-forward fully convolutional neural networks (F-CNN) to develop an accurate real-time polyp detection system. F-CNNs are usually trained on binary masks for object segmentation. We propose the use of 2D Gaussian masks instead of binary masks to enable these models to detect different types of polyps more effectively and efficiently and reduce the number of false positives. The experimental results showed that the proposed 2D Gaussian masks are efficient for detection of flat and small polyps with unclear boundaries between background and polyp parts. The masks make a better training effect to discriminate polyps from the polyp-like false positives. The proposed method achieved state-of-the-art results on two polyp datasets. On the ETIS-LARIB dataset we achieved 86.54% recall, 86.12% precision, and 86.33% Flscore, and on the CVC-ColonDB we achieved 91% recall, 88.35% precision, and Fl-score 89.65%. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Ali, Hemin Ali; Bergsland, Jacob; Balasingham, Ilangko] Oslo Univ Hosp, Intervent Ctr, Oslo, Norway.
   [Ali, Hemin Ali; Solhusvik, Johannes] Univ Oslo, Dept Informat, Oslo, Norway.
   [Balasingham, Ilangko] Norwegian Univ Sci & Technol, Dept Elect Syst, Trondheim, Norway.
   [Aabakken, Lars] Univ Oslo, Dept Transplantat Med, Oslo, Norway.
   [Ali, Hemin Ali] OmniVis Technol Norway AS, Oslo, Norway.
   [Shin, Younghak] Mokpo Natl Univ, Dept Comp Engn, Mokpo, South Korea.
C3 University of Oslo; University of Oslo; Norwegian University of Science
   & Technology (NTNU); University of Oslo; Mokpo National University
RP Ali, HA (通讯作者)，Oslo Univ Hosp, Intervent Ctr, Oslo, Norway.; Ali, HA (通讯作者)，Univ Oslo, Dept Informat, Oslo, Norway.; Ali, HA (通讯作者)，OmniVis Technol Norway AS, Oslo, Norway.; Shin, Y (通讯作者)，Mokpo Natl Univ, Dept Comp Engn, Mokpo, South Korea.
EM hemina.qadir@gmail.com; shinyh0919@gmail.com
RI Balasingham, Ilangko/AGU-7268-2022; Bergsland, Jacob/H-3966-2016
CR An T, 2019, CHIN MED-UK, V14, DOI 10.1186/s13020-019-0225-1
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], 2015, ADV NEUR IN, DOI 10.1109/TPAMI.2016.2577031
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Deng J., 2018, P EUROPEAN C COMPUTE, P734
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Pogorelov K, 2018, COMP MED SY, P381, DOI 10.1109/CBMS.2018.00073
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Shvets AA, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P612, DOI 10.1109/ICMLA.2018.00098
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Vleugels JLA, 2017, BEST PRACT RES CL GA, V31, P359, DOI 10.1016/j.bpg.2017.05.005
   Wang D., 2019, ARXIV190902477
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhou X., 2019, ARXIV
NR 39
TC 18
Z9 18
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD FEB
PY 2021
VL 68
AR 101897
DI 10.1016/j.media.2020.101897
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA QA2QC
UT WOS:000613291900002
PM 33260111
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Keswani, RN
   Byrd, D
   Vicente, FG
   Heller, JA
   Klug, M
   Mazumder, NR
   Wood, J
   Yang, AD
   Etemadi, M
AF Keswani, Rajesh N.
   Byrd, Daniel
   Vicente, Florencia Garcia
   Heller, J. Alex
   Klug, Matthew
   Mazumder, Nikhilesh R.
   Wood, Jordan
   Yang, Anthony D.
   Etemadi, Mozziyar
TI Amalgamation of cloud-based colonoscopy videos with patient-level
   metadata to facilitate large-scale machine learning
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
AB Background and study aims Storage of full-length endoscopic procedures is becoming increasingly popular. To facilitate large-scale machine learning (ML) focused on clinical outcomes, these videos must be merged with the patient-level data in the electronic health record (EHR). Our aim was to present a method of accurately linking patient-level EHR data with cloud stored colonoscopy videos.
   Methods This study was conducted at a single academic medical center. Most procedure videos are automatically uploaded to the cloud server but are identified only by procedure time and procedure room. We developed and then tested an algorithm to match recorded videos with corresponding exams in the EHR based upon procedure time and room and subsequently extract frames of interest.
   Results Among 28,611 total colonoscopies performed over the study period, 21,170 colonoscopy videos in 20,420 unique patients (54.2% male, median age 58) were matched to EHR data. Of 100 randomly sampled videos, appropriate matching was manually confirmed in all. In total, these videos represented 489,721 minutes of colonoscopy performed by 50 endoscopists (median 214 colonoscopies per endoscopist). The most common procedure indications were polyp screening (47.3%), surveillance (28.9%) and inflammatory bowel disease (9.4%). From these videos, we extracted procedure highlights (identified by image capture; mean 8.5 per colonoscopy) and surrounding frames.
   Conclusions We report the successful merging of a large database of endoscopy videos stored with limited identifiers to rich patient-level data in a highly accurate manner. This technique facilitates the development of ML algorithms based upon relevant patient outcomes.
C1 [Keswani, Rajesh N.; Mazumder, Nikhilesh R.; Wood, Jordan] Northwestern Med, Digest Hlth Ctr, 676 N St Clair,Suite 1400, Chicago, IL 60611 USA.
   [Byrd, Daniel; Vicente, Florencia Garcia; Heller, J. Alex; Klug, Matthew; Etemadi, Mozziyar] Northwestern Med, Dept Anesthesiol, Chicago, IL 60611 USA.
   [Yang, Anthony D.] Northwestern Univ, Feinberg Sch Med, Dept Surg, Surg Outcomes & Qual Improvement Ctr, Chicago, IL 60611 USA.
   [Etemadi, Mozziyar] McCormick Sch Engn, Dept Biomed Engn, Chicago, IL USA.
C3 Northwestern University; Feinberg School of Medicine; Northwestern
   University; Feinberg School of Medicine; Northwestern University;
   Feinberg School of Medicine
RP Keswani, RN (通讯作者)，Northwestern Med, Digest Hlth Ctr, 676 N St Clair,Suite 1400, Chicago, IL 60611 USA.
EM raj-keswani@northwestern.edu
RI Mazumder, Nikhilesh/AAR-1748-2021
OI Mazumder, Nikhilesh/0000-0001-9749-5334
FU Gordon and Betty Moore Foundation; National Heart, Lung, and Blood
   Institute [K08HL145139]
FX Funding was provided by the Gordon and Betty Moore Foundation.; ADY is
   also supported by the National Heart, Lung, and Blood Institute
   (K08HL145139).
CR Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Duloy AM, 2019, GASTROINTEST ENDOSC, V89, P1212, DOI 10.1016/j.gie.2019.02.024
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Stidham RW, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3963
   Takenaka K, 2020, GASTROENTEROLOGY, V158, P2150, DOI 10.1053/j.gastro.2020.02.012
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
NR 11
TC 1
Z9 1
U1 0
U2 1
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD FEB
PY 2021
VL 09
IS 02
BP E233
EP E238
DI 10.1055/a-1326-1289
PG 6
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA QB6OX
UT WOS:000614260400006
PM 33553586
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Safarov, S
   Whangbo, TK
AF Safarov, Sirojbek
   Whangbo, Taeg Keun
TI A-DenseUNet: Adaptive Densely Connected UNet for Polyp Segmentation in
   Colonoscopy Images with Atrous Convolution
SO SENSORS
LA English
DT Article
DE semantic segmentation; convolutional neural networks; colonoscopy; polyp
   segmentation; deep learning; attention; dilated convolution
ID NEURAL-NETWORKS; CANCER
AB Colon carcinoma is one of the leading causes of cancer-related death in both men and women. Automatic colorectal polyp segmentation and detection in colonoscopy videos help endoscopists to identify colorectal disease more easily, making it a promising method to prevent colon cancer. In this study, we developed a fully automated pixel-wise polyp segmentation model named A-DenseUNet. The proposed architecture adapts different datasets, adjusting for the unknown depth of the network by sharing multiscale encoding information to the different levels of the decoder side. We also used multiple dilated convolutions with various atrous rates to observe a large field of view without increasing the computational cost and prevent loss of spatial information, which would cause dimensionality reduction. We utilized an attention mechanism to remove noise and inappropriate information, leading to the comprehensive re-establishment of contextual features. Our experiments demonstrated that the proposed architecture achieved significant segmentation results on public datasets. A-DenseUNet achieved a 90% Dice coefficient score on the Kvasir-SEG dataset and a 91% Dice coefficient score on the CVC-612 dataset, both of which were higher than the scores of other deep learning models such as UNet++, ResUNet, U-Net, PraNet, and ResUNet++ for segmenting polyps in colonoscopy images.
C1 [Safarov, Sirojbek] Gachon Univ, Dept IT Convergence Engn, Seongnam Si 461701, Gyeonggi Do, South Korea.
   [Whangbo, Taeg Keun] Gachon Univ, Dept Comp Sci, Seongnam Si 461701, Gyeonggi Do, South Korea.
C3 Gachon University; Gachon University
RP Whangbo, TK (通讯作者)，Gachon Univ, Dept Comp Sci, Seongnam Si 461701, Gyeonggi Do, South Korea.
EM sirojbeksafarov@gmail.com; tkwhangbo@gachon.ac.kr
OI Safarov, Sirojbek/0000-0001-5724-3271
FU GRRC program of Gyeonggi province [GRRC-Gachon2020]; National Research
   Foundation of Korea [4299990214053] Funding Source: Korea Institute of
   Science & Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This work was supported by the GRRC program of Gyeonggi province.
   [GRRC-Gachon2020(B04), Development of AI-based Healthcare Devices].
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   ATTANASIO A, 2021, IEEE ROBOT AUTOM LET, DOI DOI 10.1109/TMRB.2021.3054326
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Casella A, 2020, ANN BIOMED ENG, V48, P848, DOI 10.1007/s10439-019-02424-9
   Chen H, 2016, AAAI CONF ARTIF INTE, P1160
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen H, 2015, LECT NOTES COMPUT SC, V9349, P507, DOI 10.1007/978-3-319-24553-9_62
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chollet F., 2015, KERAS PROBABILISTIC
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Holschneider M., 1989, WAVELETS, P289, DOI DOI 10.1007/978-3-642-75988-8_28
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   JHA D, 2020, P INT C MULT MOD 202
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li H., 2018, ARXIV PREPRINT ARXIV
   Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960
   Li WQ, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00641-y
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P471, DOI 10.1016/S0002-9270(02)05928-2
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tavanapong, 2007, P 2007 IEEE INT C IM, V2
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yun K, 2020, IEEE ACCESS, V8, P32502, DOI 10.1109/ACCESS.2020.2973390
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhou ZL, 2021, IEEE T BIG DATA, V7, P559, DOI 10.1109/TBDATA.2019.2919570
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 52
TC 21
Z9 23
U1 3
U2 24
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD FEB
PY 2021
VL 21
IS 4
AR 1441
DI 10.3390/s21041441
PG 16
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA QQ7DQ
UT WOS:000624682200001
PM 33669539
OA gold, Green Submitted, Green Published
DA 2023-08-21
ER

PT J
AU Shaukat, A
   Colucci, D
   Erisson, L
   Phillips, S
   Ng, J
   Iglesias, JE
   Saltzman, JR
   Somers, S
   Brugge, W
AF Shaukat, Aasma
   Colucci, Daniel
   Erisson, Lavi
   Phillips, Sloane
   Ng, Jonathan
   Iglesias, Juan Eugenio
   Saltzman, John R.
   Somers, Samuel
   Brugge, William
TI Improvement in adenoma detection using a novel artificial
   intelligence-aided polyp detection device
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
AB Background and study aims Detecting colorectal neoplasia is the goal of high-quality screening and surveillance colonoscopy, as reflected by high adenoma detection rate (ADR) and adenomas per colonoscopy (APC). The aim of our study was to evaluate the performance of a novel artificial intelligence (AI)-aided polyp detection device, Skout, with the primary endpoints of ADR and APC in routine colonoscopy. Patients and methods We compared ADR and APC in a cohort of outpatients undergoing routine high-resolution colonoscopy with and without the use of a real-time, AI-aided polyp detection device. Patients undergoing colonoscopy with Skout were enrolled in a single-arm, unblinded, prospective trial and the results were compared with a historical cohort. All resected polyps were examined histologically. Results Eighty-three patients undergoing screening and surveillance colonoscopy at an outpatient endoscopy center were enrolled and outcomes compared with 283 historical control patients. Overall, ADR with and without Skout was 54.2% and 40.6% respectively (P=0.028) and 53.6% and 30.8%, respectively, in screening exams (P=0.024). Overall, APC rate with and without Skout was 1.46 and 1.01, respectively, (P=0.104) and 1.18 and 0.50, respectively, in screening exams (P=0.002). Overall, true histology rate (THR) with and without Skout was 73.8% and 78.4%, respectively, (P=0.463) and 75.0% and 71.0%, respectively, in screening exams (P=0.731).
   Conclusion We have demonstrated that our novel AI-aided polyp detection device increased the ADR in a cohort of patients undergoing screening and surveillance colonoscopy without a significant concomitant increase in hyperplastic polyp resection. AI-aided colonoscopy has the potential for improving the outcomes of patients undergoing colonoscopy.
C1 [Shaukat, Aasma] Univ Minnesota GI, Minneapolis, MN USA.
   [Colucci, Daniel; Erisson, Lavi; Phillips, Sloane; Ng, Jonathan; Iglesias, Juan Eugenio] Iterat Scopes, Cambridge, MA USA.
   [Iglesias, Juan Eugenio] UCL, European Res Council, London, England.
   [Iglesias, Juan Eugenio] Massachusetts Gen Hosp, Martinos Ctr Biol Imaging, Boston, MA 02114 USA.
   [Iglesias, Juan Eugenio] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Saltzman, John R.] Brigham & Womens Hosp Gastroenterol, Boston, MA USA.
   [Somers, Samuel] Concord Hosp Gastroenterol, Concord, NH USA.
   [Brugge, William] Mt Auburn Hosp Gastroenterol, Cambridge, MA USA.
C3 University of London; University College London; Harvard University;
   Massachusetts General Hospital; Massachusetts Institute of Technology
   (MIT)
RP Colucci, D (通讯作者)，Iterat Scopes Clin Business Dev, 1 Main,11th Floor, Cambridge, MA 02142 USA.
EM daniel.colucci@iterativescopes.com
FU Iterative Scopes, Inc.
FX This study was funded by Iterative Scopes, Inc. Support for this work
   was provided by Polina Golland, PhD, Joseph Anderson, MD, Lynn Butterly,
   MD, Michael Choi, MD, Daniel Chung, MD, David Lichtenstein, MD, Jennifer
   Nayor, MD, James Richter, MD, and David Rubin, MD.
CR Anderson JC, 2020, GASTROINTEST ENDOSC, V92, P387, DOI 10.1016/j.gie.2020.04.034
   Aniwan S, 2016, AM J GASTROENTEROL, V111, P723, DOI 10.1038/ajg.2015.440
   [Anonymous], NEW ENGL J MED
   Campbell I, 2007, STAT MED, V26, P3661, DOI 10.1002/sim.2832
   Fedewa SA, 2019, ENDOSC INT OPEN, V7, pE1344, DOI 10.1055/a-0895-5410
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lam AY, 2020, GASTROINTEST ENDOSC, V92, P355, DOI 10.1016/j.gie.2020.02.016
   Ma MX, 2017, GUT LIVER, V11, P747, DOI 10.5009/gnl16523
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Shaukat A, 2009, CLIN GASTROENTEROL H, V7, P1335, DOI 10.1016/j.cgh.2009.07.027
   Sweetser S, 2016, CLIN GASTROENTEROL H, V14, P1056, DOI 10.1016/j.cgh.2016.01.021
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
NR 18
TC 7
Z9 7
U1 0
U2 2
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD FEB
PY 2021
VL 09
IS 02
BP E263
EP E270
DI 10.1055/a-1321-1317
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA QB6OX
UT WOS:000614260400011
PM 33553591
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Wang, S
   Cong, Y
   Zhu, HC
   Chen, XY
   Qu, LQ
   Fan, HJ
   Zhang, Q
   Liu, MX
AF Wang, Shuai
   Cong, Yang
   Zhu, Hancan
   Chen, Xianyi
   Qu, Liangqiong
   Fan, Huijie
   Zhang, Qiang
   Liu, Mingxia
TI Multi-Scale Context-Guided Deep Network for Automated Lesion
   Segmentation With Endoscopy Images of Gastrointestinal Tract
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Multi-scale Context; fully convolutional network; lesion segmentation;
   endoscopy image; gastrointestinal tract
ID WIRELESS CAPSULE ENDOSCOPY; POLYP DETECTION; GASTRIC-CANCER; VALIDATION;
   CLASSIFICATION; GASTROSCOPY; TEXTURE
AB Accurate lesion segmentation based on endoscopy images is a fundamental task for the automated diagnosis of gastrointestinal tract (GI Tract) diseases. Previous studies usually use hand-crafted features for representing endoscopy images, while feature definition and lesion segmentation are treated as two standalone tasks. Due to the possible heterogeneity between features and segmentation models, these methods often result in suboptimal performance. Several fully convolutional networks have been recently developed to jointly perform feature learning and model training for GI Tract disease diagnosis. However, they generally ignore local spatial details of endoscopy images, as down-sampling operations (e.g., pooling and convolutional striding) may result in irreversible loss of image spatial information. To this end, we propose a multi-scale context-guided deep network (MCNet) for end-to-end lesion segmentation of endoscopy images in GI Tract, where both global and local contexts are captured as guidance for model training. Specifically, one global subnetwork is designed to extract the global structure and high-level semantic context of each input image. Then we further design two cascaded local subnetworks based on output feature maps of the global subnetwork, aiming to capture both local appearance information and relatively high-level semantic information in a multi-scale manner. Those feature maps learned by three subnetworks are further fused for the subsequent task of lesion segmentation. We have evaluated the proposed MCNet on 1,310 endoscopy images from the public EndoVis-Ab and CVC-ClinicDB datasets for abnormal segmentation and polyp segmentation, respectively. Experimental results demonstrate that MCNet achieves 74% and 85% mean intersection over union (mloU) on two datasets, respectively, outperforming several state-of-the-art approaches in automated lesion segmentation with endoscopy images of GI Tract.
C1 [Wang, Shuai; Cong, Yang; Qu, Liangqiong; Fan, Huijie] Chinese Acad Sci, State Key Lab Robot, Shenyang Inst Automat, Shenyang 110016, Peoples R China.
   [Zhu, Hancan] Shaoxing Univ, Sch Math Phys & Informat, Shaoxing 312000, Peoples R China.
   [Chen, Xianyi] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Zhang, Qiang] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China.
   [Liu, Mingxia] Taishan Univ, Dept Informat Sci & Technol, Tai An 271000, Shandong, Peoples R China.
C3 Chinese Academy of Sciences; Shenyang Institute of Automation, CAS;
   Shaoxing University; Nanjing University of Information Science &
   Technology; Dalian University of Technology; Taishan University
RP Liu, MX (通讯作者)，Taishan Univ, Dept Informat Sci & Technol, Tai An 271000, Shandong, Peoples R China.
EM shuaiwang.tai@gmail.com; congyang@sia.cn; hancanzhu@yeah.net;
   0204622@163.com; liangqiqu2-c@my.cityu.edu.hk; fanhuijie@sia.cn;
   992431358@qq.com; mxliu1226@gmail.com
RI zhang, qiang/HZJ-9551-2023; Liu, Mingxia/E-7824-2017; Zhang,
   Qiang/GXF-3105-2022; Zhang, Qiang/IWU-5000-2023
OI Liu, Mingxia/0000-0002-0598-5692; Wang, Shuai/0000-0003-3730-6401; Qu,
   Liangqiong/0000-0001-8235-7852; Zhu, Hancan/0000-0002-5236-686X; Zhang,
   Qiang/0000-0003-3776-9799
FU National Natural Science Foundation of China [61703301, 61602307];
   Natural Science Foundation of Zhejiang Province [LY19F020013]; Taishan
   Scholar Program of Shandong Province in China; Shandong Provincial
   Natural Science Foundation [ZR2019YQ27]; Scientific Research Foundation
   of Taishan University [Y-01-2018019]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61703301 and 61602307, in part by the
   Natural Science Foundation of Zhejiang Province under Grant LY19F020013,
   in part by the Taishan Scholar Program of Shandong Province in China, in
   part by the Shandong Provincial Natural Science Foundation under Grant
   ZR2019YQ27, and in part by the Scientific Research Foundation of Taishan
   University under Grant Y-01-2018019.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bao SQ, 2018, COMP M BIO BIO E-IV, V6, P113, DOI 10.1080/21681163.2016.1182072
   Barbalata C, 2016, IEEE J BIOMED HEALTH, V20, P322, DOI 10.1109/JBHI.2014.2374975
   Ben-Cohen A, 2016, LECT NOTES COMPUT SC, V10008, P77, DOI 10.1007/978-3-319-46976-8_9
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chen, 2018, ARXIV180910203
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Chu A, 2008, ARTIF INTELL MED, V42, P247, DOI 10.1016/j.artmed.2007.10.003
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hu QC, 2017, IEEE T INTELL TRANSP, V18, P3147, DOI 10.1109/TITS.2017.2679114
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Lian CF, 2018, MED IMAGE ANAL, V46, P106, DOI 10.1016/j.media.2018.02.009
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   Liu MX, 2019, IEEE T BIO-MED ENG, V66, P1195, DOI 10.1109/TBME.2018.2869989
   Liu YL, 2016, PATTERN RECOGN, V55, P58, DOI 10.1016/j.patcog.2016.01.030
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahapatra D, 2013, IEEE T MED IMAGING, V32, P2332, DOI 10.1109/TMI.2013.2282124
   Mahmood F, 2019, PROC SPIE, V10950, DOI 10.1117/12.2513117
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mylonaki M, 2003, GUT, V52, P1122, DOI 10.1136/gut.52.8.1122
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Ning ZY, 2019, IEEE J BIOMED HEALTH, V23, P1181, DOI 10.1109/JBHI.2018.2841992
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Riaz F, 2017, IEEE J BIOMED HEALTH, V21, P162, DOI 10.1109/JBHI.2015.2492464
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   Tollivoro TA, 2019, GASTROINTEST ENDOSC, V89, P168, DOI 10.1016/j.gie.2018.08.023
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Post RS, 2018, GASTROINTEST ENDOSC, V87, P397, DOI 10.1016/j.gie.2017.04.016
   Wang, 2020, IEEE T MED IMAG
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang S, 2020, IEEE T BIO-MED ENG, V67, P2710, DOI 10.1109/TBME.2020.2969608
   Wang S, 2019, MED IMAGE ANAL, V54, P168, DOI 10.1016/j.media.2019.03.003
   Wang S, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3051481
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yakubovskiy Pavel, 2019, SEGMENTATION MODELS
   Yao K, 2007, CLIN GASTROENTEROL H, V5, P869, DOI 10.1016/j.cgh.2007.02.034
   Yu F., 2016, P 4 INT C LEARN REP, DOI 10.48550/arXiv.1511.07122Focustolearnmore
   Yu LC, 2012, INT C PATT RECOG, P45
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhai SF, 2017, PROC CVPR IEEE, P4003, DOI 10.1109/CVPR.2017.426
   Zhang J, 2017, IEEE T IMAGE PROCESS, V26, P4753, DOI 10.1109/TIP.2017.2721106
   Zhu ZT, 2019, LECT NOTES COMPUT SC, V11769, P3, DOI 10.1007/978-3-030-32226-7_1
NR 70
TC 62
Z9 62
U1 16
U2 45
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD FEB
PY 2021
VL 25
IS 2
BP 514
EP 525
DI 10.1109/JBHI.2020.2997760
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA QE6IV
UT WOS:000616310200021
PM 32750912
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Zhang, YC
   Zhang, XB
   Wu, QB
   Gu, CY
   Wang, ZQ
AF Zhang, Yuanchuan
   Zhang, Xubing
   Wu, Qingbin
   Gu, Chaoyang
   Wang, Ziqiang
TI Artificial Intelligence-Aided Colonoscopy for Polyp Detection: A
   Systematic Review and Meta-Analysis of Randomized Clinical Trials
SO JOURNAL OF LAPAROENDOSCOPIC & ADVANCED SURGICAL TECHNIQUES
LA English
DT Review
DE artificial intelligence; colonoscopy; polyp detection; randomized
   clinical trial; meta-analysis
ID SESSILE SERRATED POLYPS; ASSISTED COLONOSCOPY; CANCER; QUALITY
AB Background: This study aimed to compare artificial intelligence (AI)-aided colonoscopy with conventional colonoscopy for polyp detection.
   Methods: A systematic literature search was performed in PubMed and Ovid for randomized clinical trials (RCTs) comparing AI-aided colonoscopy with conventional colonoscopy for polyp detection. The last search was performed on July 22, 2020. The primary outcome was polyp detection rate (PDR) and adenoma detection rate (ADR).
   Results: Seven RCTs published between 2019 and 2020 with a total of 5427 individuals were included. When compared with conventional colonoscopy, AI-aided colonoscopy significantly improved PDR (P < .001, odds ratio [OR] = 1.95, 95% confidence interval [CI]: 1.75 to 2.19, I-2 = 0%) and ADR (P < .001, OR = 1.72, 95% CI: 1.52 to 1.95, I-2 = 33%). Besides, polyps in the AI-aided group were significantly smaller in size than those in conventional group (P = .004, weighted mean difference = -0.48, 95% CI: -0.81 to -0.15, I-2 = 0%). In addition, AI-aided group detected significantly less proportion of advanced adenoma (P = .03, OR = 0.70, 95% CI: 0.50 to 0.97, I-2 = 46%), pedicle polyps (P < .001, OR = 0.64, 95% CI: 0.49 to 0.83, I-2 = 0%), and pedicle adenomas (P < .001, OR = 0.60, 95% CI: 0.44 to 0.80, I-2 = 0%).
   Conclusion: AI-aided colonoscopy could significantly increase the PDR and ADR, especially for those with small size. Besides, the shape and pathology recognition of the AI technique should be further improved in the future.
C1 [Zhang, Yuanchuan] Third Peoples Hosp Chengdu, Dept Gen Surg, Chengdu, Peoples R China.
   [Zhang, Xubing; Wu, Qingbin; Gu, Chaoyang; Wang, Ziqiang] Sichuan Univ, West China Hosp, Dept Gastrointestinal Surg, Guo Xue Xiang 37, Chengdu 610041, Peoples R China.
C3 Sichuan University
RP Wang, ZQ (通讯作者)，Sichuan Univ, West China Hosp, Dept Gastrointestinal Surg, Guo Xue Xiang 37, Chengdu 610041, Peoples R China.
EM wangziqiang@scu.edu.cn
RI zhang, yuanchuan/HHR-8901-2022
FU 1.3.5 project for disciplines of excellence-Clinical Research Incubation
   Project, West China Hospital, Sichuan University [2019HXFH031]
FX This study was supported by 1.3.5 project for disciplines of
   excellence-Clinical Research Incubation Project, West China Hospital,
   Sichuan University (No. 2019HXFH031)
CR Acs B, 2020, J INTERN MED, V288, P62, DOI 10.1111/joim.13030
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Bridoux V, 2012, J GASTROINTEST SURG, V16, P1758, DOI 10.1007/s11605-012-1952-0
   Chukmaitov A, 2019, INT J COLORECTAL DIS, V34, P1203, DOI 10.1007/s00384-019-03304-3
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Grande G, 2016, J CLIN GASTROENTEROL, V50, pS13, DOI 10.1097/MCG.0000000000000629
   Gupta N, 2019, JAMA-J AM MED ASSOC, V321, P2022, DOI 10.1001/jama.2019.4842
   Hoerter Nicholas, 2020, Curr Treat Options Gastroenterol, DOI 10.1007/s11938-020-00274-2
   Issa IA, 2017, WORLD J GASTROENTERO, V23, P5086, DOI 10.3748/wjg.v23.i28.5086
   Joseph DA, 2016, CANCER-AM CANCER SOC, V122, P2479, DOI 10.1002/cncr.30070
   Kataoka S, 2020, ENDOSC INT OPEN, V8, pE360, DOI 10.1055/a-1068-9228
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Meester RGS, 2020, GASTROENTEROLOGY, V159, P105, DOI 10.1053/j.gastro.2020.03.025
   Meester RGS, 2020, LANCET GASTROENTEROL, V5, P516, DOI 10.1016/S2468-1253(20)30074-1
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Sanchez-Montes C, 2020, GASTROENT HEPAT-BARC, V43, P222, DOI 10.1016/j.gastrohep.2019.11.004
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tang ZW, 2018, GASTROINTEST ENDOSC, V87, P723, DOI 10.1016/j.gie.2017.06.011
   Wan X, 2014, BMC MED RES METHODOL, V14, DOI 10.1186/1471-2288-14-135
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wolff J, 2020, J MED INTERNET RES, V22, DOI 10.2196/16866
   Zachariah R, 2020, TECH INNOVAT GASTROI, V22, P48, DOI 10.1016/j.tgie.2019.150631
NR 28
TC 10
Z9 10
U1 0
U2 4
PU MARY ANN LIEBERT, INC
PI NEW ROCHELLE
PA 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA
SN 1092-6429
EI 1557-9034
J9 J LAPAROENDOSC ADV S
JI J. Laparoendosc. Adv. Surg. Tech.
PD OCT
PY 2021
VL 31
IS 10
BP 1143
EP 1149
DI 10.1089/lap.2020.0777
EA FEB 2021
PG 7
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA YY2ZO
UT WOS:000614552300001
PM 33524298
DA 2023-08-21
ER

PT J
AU Nogueira-Rodriguez, A
   Dominguez-Carbajales, R
   Lopez-Fernandez, H
   Iglesias, A
   Cubiella, J
   Fdez-Riverola, F
   Reboiro-Jato, M
   Glez-Pena, D
AF Nogueira-Rodriguez, Alba
   Dominguez-Carbajales, Ruben
   Lopez-Fernandez, Hugo
   Iglesias, Agueda
   Cubiella, Joaquin
   Fdez-Riverola, Florentino
   Reboiro-Jato, Miguel
   Glez-Pena, Daniel
TI Deep Neural Networks approaches for detecting and classifying colorectal
   polyps
SO NEUROCOMPUTING
LA English
DT Article
DE Deep learning; Convolutional Neural Network (CNN); Polyp detection;
   Polyp localization; Polyp classification; Computer-aided diagnosis
ID ARTIFICIAL-INTELLIGENCE; COLONOSCOPY; DIAGNOSIS; PREVENTION; VALIDATION;
   ENDOSCOPY; CANCER
AB Deep Learning (DL) has attracted a lot of attention in the field of medical image analysis because of its higher performance in image classification when compared to previous state-of-the-art techniques. In addition, a recent meta-analysis found that the diagnostic performance of DL models is equivalent to that of health-care professionals. In this scenario, a lot of research using DL for polyp detection and classification have been published showing promising results in the last five years. Our work aims to review the most relevant studies from a technical point of view, focusing on the low-level details for the implementation of the DL models. To do so, this review analyzes the published research covering aspects like DL architectures, training strategies, data augmentation, transfer learning, or the features of the datasets used and their impact on the performance of the models. Additionally, comparative tables summarizing the main aspects analyzed in this review are publicly available at https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/sing-group/deeplearning-colonoscopy. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Nogueira-Rodriguez, Alba; Lopez-Fernandez, Hugo; Fdez-Riverola, Florentino; Reboiro-Jato, Miguel; Glez-Pena, Daniel] Univ Vigo, Dept Comp Sci, ESEI, Campus Lagoas, Orense 32004, Spain.
   [Nogueira-Rodriguez, Alba; Lopez-Fernandez, Hugo; Fdez-Riverola, Florentino; Reboiro-Jato, Miguel; Glez-Pena, Daniel] Campus Univ Lagoas Marcosende, Biomed Res Ctr CINBIO, Vigo 36310, Spain.
   [Nogueira-Rodriguez, Alba; Lopez-Fernandez, Hugo; Fdez-Riverola, Florentino; Reboiro-Jato, Miguel; Glez-Pena, Daniel] SERGAS UVIGO, SING Res Grp, Galicia Hlth Res Inst IIS Galicia, Orense, Spain.
   [Dominguez-Carbajales, Ruben; Iglesias, Agueda; Cubiella, Joaquin] Complexo Hosp Univ Ourense, Inst Invest Sanitaria Galicia, Dept Gastroenterol, Ctr Invest Biomed Red Enfermedades Hepat & Digest, Orense, Spain.
C3 Universidade de Vigo; Universidade de Vigo; CINBIO; CIBER - Centro de
   Investigacion Biomedica en Red; CIBEREHD; Complexo Hospitalario
   Universitario de Ourense, Verin e O Barco de Valdeorras
RP Glez-Pena, D (通讯作者)，Despacho 306,Edificio Politecn, Orense 32005, Spain.
EM dgpena@uvigo.es
RI Reboiro-Jato, Miguel/G-1102-2011; CUBIELLA, JOAQUIN/G-7692-2017;
   Rodríguez, Alba Nogueira/AAO-9957-2020; Glez-Peña, Daniel/D-5922-2014;
   Reboiro-Jato, Miguel/AAB-8453-2022; Fdez-Riverola,
   Florentino/G-1411-2011; Lopez-Fernandez, Hugo/H-7558-2017
OI Reboiro-Jato, Miguel/0000-0001-8749-2703; CUBIELLA,
   JOAQUIN/0000-0002-9994-4831; Rodríguez, Alba
   Nogueira/0000-0001-5991-7698; Glez-Peña, Daniel/0000-0002-6129-7245;
   Reboiro-Jato, Miguel/0000-0001-8749-2703; Fdez-Riverola,
   Florentino/0000-0002-3943-8013; Lopez-Fernandez,
   Hugo/0000-0002-6476-7206; , IIS Galicia Sur/0000-0003-3812-7413;
   Dominguez Carbajales, Ruben/0000-0003-3405-2389
FU CITI (Centro de Investigacion, Transferencia e Innovacion) from the
   University of Vigo; Conselleria de Educacion, Universidades e Formacion
   Profesional (Xunta de Galicia) [ED431C2018/55-GRC]; Ministerio de
   Economia, Industria y Competitividad, Gobierno de Espana
   [DPI2017-87494-R]; Xunta de Galicia [ED481A-2019/299, ED481B
   2016/068-0]; Instituto de Salud Carlos III [PI11/00094, PI17/00837]
FX SING group thanks CITI (Centro de Investigacion, Transferencia e
   Innovacion) from the University of Vigo for hosting its IT
   infrastructure. This work was partially supported by the Conselleria de
   Educacion, Universidades e Formacion Profesional (Xunta de Galicia)
   under the scope of the strategic funding of ED431C2018/55-GRC
   Competitive Reference Group and by the Ministerio de Economia, Industria
   y Competitividad, Gobierno de Espana under the scope of the PolyDeep
   project (DPI2017-87494-R). The authors also acknowledge the grants of
   Alba Nogueira-Rodriguez (predoctoral fellowship ED481A-2019/299) and
   Hugo Lopez-Fernandez (postdoctoral fellowship ED481B 2016/068-0), funded
   by the Xunta de Galicia. Joaquin Cubiella received grants from Instituto
   de Salud Carlos III (PI11/00094 and PI17/00837).
CR Ahmad OF, 2019, GASTROINTEST ENDOSC, V89, pAB647, DOI 10.1016/j.gie.2019.03.1135
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Azer SA, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55080473
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen JH, 2017, NEW ENGL J MED, V376, P2507, DOI 10.1056/NEJMp1702071
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cubiella J, 2018, GASTROENT HEPAT-BARC, V41, P585, DOI 10.1016/j.gastrohep.2018.07.012
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girshick R., 2015, PROC IEEE INT C COMP, P1440, DOI DOI 10.1109/ICCV.2015.169
   Girshick R., 2014, P IEEE C COMP VIS PA, P580, DOI DOI 10.1109/CVPR.2014.81
   He K., 2018, ARXIV170306870CS
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kandel P, 2019, GASTROINTEST ENDOSC, V89, pAB403, DOI 10.1016/j.gie.2019.03.613
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1995, P INT C ART NEUR NET, V60, P53
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Litjens G, 2017, ARXIV170205747CS
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Min J.K., 2019, GUT LIVER
   Misawa M, 2019, GASTROINTEST ENDOSC, V89, pAB646, DOI 10.1016/j.gie.2019.03.1134
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Nogueira-Rodriguez Alba, 2020, Distributed Computing and Artificial Intelligence, 16th International Conference, Special Sessions. Advances in Intelligent Systems and Computing (AISC 1004), P209, DOI 10.1007/978-3-030-23946-6_27
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Qadir H., 2019, IEEE J BIOMED HLTH I
   REDMON J, 2016, PROC CVPR IEEE, P779, DOI DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sabour S., 2017, P ADV NEUR INF PROC, P3859
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Singh S, 2014, AM J GASTROENTEROL, V109, P1375, DOI 10.1038/ajg.2014.171
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D., 2017, J HEALTHC ENG, P1
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhao S., 2019, GASTROENTEROLOGY, V156, pe11
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
   Zhu X, 2019, GASTROINTEST ENDOSC, V89, pAB625, DOI 10.1016/j.gie.2019.03.1087
NR 71
TC 44
Z9 44
U1 12
U2 57
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 29
PY 2021
VL 423
BP 721
EP 734
DI 10.1016/j.neucom.2020.02.123
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PG6XQ
UT WOS:000599876700009
OA hybrid
DA 2023-08-21
ER

PT J
AU Tas, M
   Yilmaz, B
AF Tas, Merve
   Yilmaz, Bulent
TI Super resolution convolutional neural network based pre-processing for
   automatic polyp detection in colonoscopy images
SO COMPUTERS & ELECTRICAL ENGINEERING
LA English
DT Article
DE Deep learning; Convolutional neural networks; Transfer learning; Super
   resolution; Colonoscopy; Colon polyp localization
ID VALIDATION; CNN
AB Colonoscopy is the most common methodology used to detect polyps on the colon surface. Increasing the image resolution has the potential to improve the automatic colonoscopy based diagnosis and polyp detection and localization. In this study, we proposed a pre-processing approach that uses convolutional neural network based super resolution method (SRCNN) to increase the resolution of the training colonoscopy images before the localization of polyps. We also investigated the use of CNN based models such as the Single Shot MultiBox Detector (SSD) and Faster Regional CNN (RCNN) for real-time polyp detection and localization. Our results showed that using SRCNN method before the training process provides better results in terms of accuracy in both models compared to the low-resolution cases. Furthermore, we reached an F2 score of 0.945 for the correct localization of colon polyps using Faster RCNN with ResNet-101 feature extractor.
C1 [Tas, Merve; Yilmaz, Bulent] Abdullah Gul Univ, Grad Sch Engn & Nat Sci, Dept Elect & Comp Engn, Kayseri, Turkey.
   [Yilmaz, Bulent] Abdullah Gul Univ, Sch Engn, Dept Elect Elect Engn, Kayseri, Turkey.
   [Tas, Merve; Yilmaz, Bulent] Abdullah Gul Univ, Sch Engn, Biomed Instrumentat & Signal Anal Lab BISA, Kayseri, Turkey.
   [Yilmaz, Bulent] Abdullah Gul Univ, Sch Life & Nat Sci, Dept Bioengn, Kayseri, Turkey.
C3 Abdullah Gul University; Abdullah Gul University; Abdullah Gul
   University; Abdullah Gul University
RP Tas, M (通讯作者)，Abdullah Gul Univ, Grad Sch Engn & Nat Sci, Dept Elect & Comp Engn, Kayseri, Turkey.
OI Yilmaz, Bulent/0000-0003-2954-1217
FU Turkish Higher Education Council [100/2000]
FX The first author, Merve Tas, was supported by the Turkish Higher
   Education Council's 100/2000 Scholarship Program.
CR [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2015, P 28 INT C NEUR INF
   [Anonymous], 2016, DESTECH TRANS COMP
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, INT SOC OPTICS PHOTO
   Chen Y, 2018, P INT C MED IM COMP
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong Chao, 2016, P EUR C COMP VIS
   Fernandez Oliva A., 2019, NONDETERMINISTIC OUT
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Jurek J, 2020, BIOCYBERN BIOMED ENG, V40, P111, DOI 10.1016/j.bbe.2019.10.003
   Ledig C., 2017, P IEEE C COMP VIS PA, P4681
   Lim B., 2017, P IEEE C COMP VIS PA
   Mahapatra D, 2019, COMPUT MED IMAG GRAP, V71, P30, DOI 10.1016/j.compmedimag.2018.10.005
   Mahendra KV., 2019, EC GASTROENTEROL DIG, V6, P663
   Mo X, 2018, P 24 INT C PATT REC
   Pham C-H, 2017, P IEEE 14 INT S BIOM
   Pogorelov K, 2017, P 8 ACM MULT SYST C
   Qadir HA, 2019, P 13 INT S MED INF C
   Qasem SN, 2019, CMC-COMPUT MATER CON, V59, P713, DOI 10.32604/cmc.2019.05617
   Redmon J., 2016, P IEEE C COMP VIS PA, P779, DOI DOI 10.1109/CVPR.2016.91
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang S., 2018, P IEEE C COMP VIS PA
   Zhao Q, 2019, P AAAI C ART INT
NR 28
TC 7
Z9 7
U1 2
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0045-7906
EI 1879-0755
J9 COMPUT ELECTR ENG
JI Comput. Electr. Eng.
PD MAR
PY 2021
VL 90
AR 106959
DI 10.1016/j.compeleceng.2020.106959
EA JAN 2021
PG 11
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RT2XY
UT WOS:000644328200004
DA 2023-08-21
ER

PT J
AU Weigt, J
   Repici, A
   Antonelli, G
   Afifi, A
   Kliegis, L
   Correale, L
   Hassan, C
   Neumann, H
AF Weigt, Jochen
   Repici, Alessandro
   Antonelli, Giulio
   Afifi, Ahmed
   Kliegis, Leon
   Correale, Loredana
   Hassan, Cesare
   Neumann, Helmut
TI Performance of a new integrated computer-assisted system (CADe/CADx) for
   detection and characterization of colorectal neoplasia
SO ENDOSCOPY
LA English
DT Article
ID COLONOSCOPY; SOCIETY
AB Background Use of artificial intelligence may increase detection of colorectal neoplasia at colonoscopy by improving lesion recognition (CADe) and reduce pathology costs by improving optical diagnosis (CADx). Methods A multicenter library of >= 200000 images from 1572 polyps was used to train a combined CADe/CADx system. System testing was performed on two independent image sets (CADe: 446 with polyps, 234 without; CADx: 267) from 234 polyps, which were also evaluated by six endoscopists (three experts, three non-experts). Results CADe showed sensitivity, specificity, and accuracy of 92.9%, 90.6%, and 91.7%, respectively. Experts showed significantly higher accuracy and specificity, and similar sensitivity, while non-experts+CADe showed comparable sensitivity but lower specificity and accuracy than CADe and experts. CADx showed sensitivity, specificity, and accuracy of 85.0%, 79.4%, and 83.6%, respectively. Experts showed comparable performance, whereas non-experts+CADx showed comparable accuracy but lower specificity than CADx and experts. Conclusions The high accuracy shown by CADe and CADx was similar to that of experts, supporting further evaluation in a clinical setting. When using CAD, non-experts achieved a similar performance to experts, with suboptimal specificity.
C1 [Weigt, Jochen; Afifi, Ahmed; Kliegis, Leon] Otto V Guericke Univ, Dept Gastroenterol Hepatol & Infect Dis, Magdeburg, Germany.
   [Repici, Alessandro; Correale, Loredana] IRCCS, Humanitas Clin & Res Ctr, Endoscopy Unit, Milan, Italy.
   [Repici, Alessandro] Humanitas Univ, Dept Biomed Sci, Milan, Italy.
   [Antonelli, Giulio; Hassan, Cesare] Nuovo Regina Margherita Hosp, Gastroenterol Unit, Rome, Italy.
   [Neumann, Helmut] Univ Hosp Mainz, Dept Interdisciplinary Endoscopy, Mainz, Germany.
   [Neumann, Helmut] GastroZentrum Lippe, Intervent Endoscopy, Bad Salzuflen, Germany.
C3 Otto von Guericke University; Humanitas University; Poliambulatorio
   Nuovo Regina Margherita; University Hospital Mainz
RP Neumann, H (通讯作者)，Univ Med Ctr Mainz, Med Dept 1, Interdisciplinary Endoscopy, FASGE,FJGES, Langenbeckstr 1, D-55131 Mainz, Germany.
EM helmut.neumann@unimedizin-mainz.de
RI Repici, Alessandro/HFH-8162-2022; hassan, cesare/H-2844-2012
OI Repici, Alessandro/0000-0002-1621-6450; hassan,
   cesare/0000-0001-7167-1459; Antonelli, Giulio/0000-0003-1797-3864;
   Weigt, Jochen/0000-0002-3334-2168
FU Fujifilm Corporation
FX Fujifilm Corporation, Equipment on loan
CR Anderson R, 2020, GASTROENTEROLOGY, V158, P1287, DOI 10.1053/j.gastro.2019.12.031
   Fuccio L, 2019, GASTROENTEROLOGY, V156, P1309, DOI 10.1053/j.gastro.2018.12.006
   Greuter MJE, 2017, ANN INTERN MED, V167, P544, DOI 10.7326/M16-2891
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Pilonis ND, 2020, ANN INTERN MED, V173, P81, DOI 10.7326/M19-2477
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Wieszczy P, 2020, GASTROENTEROLOGY, V158, P875, DOI 10.1053/j.gastro.2019.09.011
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 10
TC 31
Z9 31
U1 1
U2 1
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD FEB
PY 2022
VL 54
IS 02
BP 180
EP 184
DI 10.1055/a-1372-0419
EA JAN 2021
PG 5
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA YW4LO
UT WOS:000641700900001
PM 33494106
DA 2023-08-21
ER

PT J
AU Yao, Y
   Gou, SP
   Tian, R
   Zhang, XR
   He, SX
AF Yao, Yao
   Gou, Shuiping
   Tian, Ru
   Zhang, Xiangrong
   He, Shuixiang
TI Automated Classification and Segmentation in Colorectal Images Based on
   Self-Paced Transfer Network
SO BIOMED RESEARCH INTERNATIONAL
LA English
DT Article
AB Colorectal imaging improves on diagnosis of colorectal diseases by providing colorectal images. Manual diagnosis of colorectal disease is labor-intensive and time-consuming. In this paper, we present a method for automatic colorectal disease classification and segmentation. Because of label unbalanced and difficult colorectal data, the classification based on self-paced transfer VGG network (STVGG) is proposed. ImageNet pretraining network parameters are transferred to VGG network with training colorectal data to acquire good initial network performance. And self-paced learning is used to optimize the network so that the classification performance of label unbalanced and difficult samples is improved. In order to assist the colonoscopist to accurately determine whether the polyp needs surgical resection, feature of trained STVGG model is shared to Unet segmentation network as the encoder part and to avoid repeat learning of polyp segmentation model. The experimental results on 3061 colorectal images illustrated that the proposed method obtained higher classification accuracy (96%) and segmentation performance compared with a few other methods. The polyp can be segmented accurately from around tissues by the proposed method. The segmentation results underpin the potential of deep learning methods for assisting colonoscopist in identifying polyps and enabling timely resection of these polyps at an early stage.
C1 [Yao, Yao; Gou, Shuiping; Tian, Ru; Zhang, Xiangrong] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shanxi, Peoples R China.
   [Yao, Yao] Hangzhou Vocat & Tech Coll, Sch Informat Engn, Hangzhou 310018, Zhejiang, Peoples R China.
   [He, Shuixiang] Xi An Jiao Tong Univ, Dept Gastroenterol, Affiliated Hosp 1, Xian 710071, Shanxi, Peoples R China.
C3 Xidian University; Hangzhou Vocational & Technical College; Xi'an
   Jiaotong University
RP Gou, SP (通讯作者)，Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shanxi, Peoples R China.; He, SX (通讯作者)，Xi An Jiao Tong Univ, Dept Gastroenterol, Affiliated Hosp 1, Xian 710071, Shanxi, Peoples R China.
EM yaoyaocn@foxmail.com; shpgou@mail.xidian.edu.cn; 260998612@qq.com;
   584686067@qq.com; hesx123@126.com
OI HE, Shuixiang/0000-0002-4832-1896
FU Natural Science Foundation of Shaanxi Province [2019ZDLGY03-02-02,
   2017JM8026]; Research Plan of Improving Public Scientific Quality in
   Shaanxi Province [E219360001]; Fundamental Research Funds for the
   Central Universities [JC2001]; Focus on developing of Shaanxi Province
   [2020GY-049]
FX This study is supported by the Natural Science Foundation of Shaanxi
   Province under Grant Nos. 2019ZDLGY03-02-02 and 2017JM8026, Research
   Plan of Improving Public Scientific Quality in Shaanxi Province, No.
   E219360001, the Fundamental Research Funds for the Central Universities,
   No. JC2001, and Focus on developing of Shaanxi Province under Grant No.
   2020GY-049. This is a research project of visiting engineers in colleges
   and universities of Zhejiang Province in 2020.
CR Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Chang HY, 2019, J PATHOL TRANSL MED, V53, P1, DOI 10.4132/jptm.2018.12.16
   Ertosun Mehmet Gunhan, 2015, AMIA Annu Symp Proc, V2015, P1899
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Iizuka O, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58467-9
   Joseph DA, 2016, CANCER-AM CANCER SOC, V122, P2479, DOI 10.1002/cncr.30070
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Korbar B., 2017, J PATHOLOGY INFORN, V8
   Li Q, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P17, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2017.10
   Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286
   Meier A., 2018, ANN ONCOLOGY, V29
   Sena P, 2019, ONCOL LETT, V18, P6101, DOI 10.3892/ol.2019.10928
   Soreide K, 2009, EXPERT REV MOL DIAGN, V9, P125, DOI 10.1586/14737159.9.2.125
   Teramoto A, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/4067832
   Thakur N, 2020, CANCERS, V12, DOI 10.3390/cancers12071884
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van den Bent MJ, 2010, ACTA NEUROPATHOL, V120, P297, DOI 10.1007/s00401-010-0725-7
   Wang JY, 2011, IEEE T MED IMAGING, V30, P1996, DOI 10.1109/TMI.2011.2161673
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   Xu Y, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1685-x
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 26
TC 7
Z9 7
U1 2
U2 7
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2314-6133
EI 2314-6141
J9 BIOMED RES INT-UK
JI Biomed Res. Int.
PD JAN 21
PY 2021
VL 2021
AR 6683931
DI 10.1155/2021/6683931
PG 7
WC Biotechnology & Applied Microbiology; Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Research & Experimental Medicine
GA QE3HF
UT WOS:000616099600002
PM 33542924
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Ahmad, OF
   Mori, Y
   Misawa, M
   Kudo, SE
   Anderson, JT
   Bernal, J
   Berzin, TM
   Bisschops, R
   Byrne, MF
   Chen, PJ
   East, JE
   Eelbode, T
   Elson, DS
   Gurudu, SR
   Histace, A
   Karnes, WE
   Repici, A
   Singh, R
   Valdastri, P
   Wallace, MB
   Wang, P
   Stoyanov, D
   Lovat, LB
AF Ahmad, Omer F.
   Mori, Yuichi
   Misawa, Masashi
   Kudo, Shin-ei
   Anderson, John T.
   Bernal, Jorge
   Berzin, Tyler M.
   Bisschops, Raf
   Byrne, Michael F.
   Chen, Peng-Jen
   East, James E.
   Eelbode, Tom
   Elson, Daniel S.
   Gurudu, Suryakanth R.
   Histace, Aymeric
   Karnes, William E.
   Repici, Alessandro
   Singh, Rajvinder
   Valdastri, Pietro
   Wallace, Michael B.
   Wang, Pu
   Stoyanov, Danail
   Lovat, Laurence B.
TI Establishing key research questions for the implementation of artificial
   intelligence in colonoscopy: a modified Delphi method
SO ENDOSCOPY
LA English
DT Article
ID COMPUTER-AIDED DETECTION; GASTROINTESTINAL ENDOSCOPY; COLORECTAL
   NEOPLASIA; EUROPEAN-SOCIETY; RESEARCH AGENDA; POLYP DETECTION; OPTICAL
   BIOPSY; DIAGNOSIS; TRIAL
AB Background Artificial intelligence (AI) research in colonoscopy is progressing rapidly but widespread clinical implementation is not yet a reality. We aimed to identify the top implementation research priorities.
   Methods An established modified Delphi approach for research priority setting was used. Fifteen international experts, including endoscopists and translational computer scientists/engineers, from nine countries participated in an online survey over 9 months. Questions related to AI implementation in colonoscopy were generated as a long-list in the first round, and then scored in two subsequent rounds to identify the top 10 research questions. Results The top 10 ranked questions were categorized into five themes. Theme 1: clinical trial design/end points (4 questions), related to optimum trial designs for polyp detection and characterization, determining the optimal end points for evaluation of AI, and demonstrating impact on interval cancer rates. Theme 2: technological developments (3 questions), including improving detection of more challenging and advanced lesions, reduction of false-positive rates, and minimizing latency. Theme 3: clinical adoption/integration (1 question), concerning the effective combination of detection and characterization into one workflow. Theme 4: data access/annotation (1 question), concerning more efficient or automated data annotation methods to reduce the burden on human experts. Theme 5: regulatory approval (1 question), related to making regulatory approval processes more efficient.
   Conclusions This is the first reported international research priority setting exercise for AI in colonoscopy. The study findings should be used as a framework to guide future research with key stakeholders to accelerate the clinical implementation of AI in endoscopy.
C1 [Ahmad, Omer F.; Stoyanov, Danail; Lovat, Laurence B.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, London, England.
   [Mori, Yuichi; Misawa, Masashi; Kudo, Shin-ei] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Mori, Yuichi] Univ Oslo, Inst Hlth & Soc, Clin Effectiveness Res Grp, Oslo, Norway.
   [Anderson, John T.] Gloucestershire Hosp NHS Fdn Trust, Dept Gastroenterol, Gloucester, England.
   [Bernal, Jorge] Univ Autonoma Barcelona, Comp Sci Dept, Barcelona, Spain.
   [Bernal, Jorge] Comp Vis Ctr, Barcelona, Spain.
   [Berzin, Tyler M.] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Boston, MA USA.
   [Bisschops, Raf] Univ Hosp Leuven, Dept Gastroenterol & Hepatol, TARGID KU Leuven, Leuven, Belgium.
   [Byrne, Michael F.] Univ British Columbia, Vancouver Gen Hosp, Div Gastroenterol, Vancouver, BC, Canada.
   [Chen, Peng-Jen] Triserv Gen Hosp, Natl Def Med Ctr, Div Gastroenterol, Taipei, Taiwan.
   [East, James E.] John Radcliffe Hosp, Translat Gastroenterol Unit, Oxford, England.
   [East, James E.] Univ Oxford, Oxford NIHR Biomed Res Ctr, Oxford, England.
   [Eelbode, Tom] Katholieke Univ Leuven, Med Imaging Res Ctr, ESAT PSI, Leuven, Belgium.
   [Elson, Daniel S.] Imperial Coll London, Hamlyn Ctr Robot Surg, Inst Global Hlth Innovat, London, England.
   [Elson, Daniel S.] Imperial Coll London, Dept Surg & Canc, London, England.
   [Gurudu, Suryakanth R.] Mayo Clin, Div Gastroenterol & Hepatol, Scottsdale, AZ USA.
   [Histace, Aymeric] Univ Cergy Pointoise, Cergy Pointoise Cedex, CNRS, ENSEA,ETIS, Cergy Pontoise, France.
   [Karnes, William E.] Univ Calif Irvine, HH Chao Comprehens Digest Dis Ctr, Dept Med, Div Gastroenterol & Hepatol, Irvine, CA USA.
   [Repici, Alessandro] IRCCS, Dept Gastroenterol, Humanitas Clin & Res Ctr, Milan, Italy.
   [Repici, Alessandro] Humanitas Univ, Dept Biomed Sci, Milan, Italy.
   [Singh, Rajvinder] Lyell McEwan Hosp, Dept Gastroenterol & Hepatol, Adelaide, SA, Australia.
   [Valdastri, Pietro] Univ Leeds, Sch Elect & Elect Engn, Leeds, W Yorkshire, England.
   [Wallace, Michael B.] Mayo Clin, Div Gastroenterol & Hepatol, Jacksonville, FL USA.
   [Wang, Pu] Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Peoples R China.
   [Lovat, Laurence B.] Univ Coll London Hosp, Gastrointestinal Serv, London, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London; Showa University; University of Oslo; Gloucestershire Hospitals
   NHS Foundation Trust; Autonomous University of Barcelona; Centre de
   Visio per Computador (CVC); Harvard University; Beth Israel Deaconess
   Medical Center; Harvard Medical School; KU Leuven; University Hospital
   Leuven; University of British Columbia; National Defense Medical Center;
   Tri-Service General Hospital; University of Oxford; University of
   Oxford; KU Leuven; Imperial College London; Imperial College London;
   Mayo Clinic; Mayo Clinic Phoenix; Centre National de la Recherche
   Scientifique (CNRS); CY Cergy Paris Universite; University of California
   System; University of California Irvine; Humanitas University; Lyell
   McEwin Hospital; University of Leeds; Mayo Clinic; Sichuan Provincial
   People's Hospital; University College London Hospitals NHS Foundation
   Trust
RP Ahmad, OF (通讯作者)，Wellcome EPSRC Ctr Intervent & Surg Sci, Charles Bell House,43-45 Foley St, London W1W 7TS, England.
EM ofahmad123@gmail.com
RI Wallace, Michael/GZL-9731-2022; Bernal, Jorge/H-4647-2015; Mori,
   Yuichi/AAU-5406-2020; Misawa, Masashi/H-9004-2019; Lovat,
   Laurence/C-1986-2009; Repici, Alessandro/HFH-8162-2022
OI Wallace, Michael/0000-0002-6446-5785; Bernal, Jorge/0000-0001-8493-9514;
   Misawa, Masashi/0000-0002-8520-2036; Lovat,
   Laurence/0000-0003-4542-3915; Repici, Alessandro/0000-0002-1621-6450;
   Karnes, William/0000-0002-6225-9080; Mori, Yuichi/0000-0003-2262-0334;
   Chen, Peng Jen/0000-0001-5400-905X; Wang, Pu/0000-0002-1234-309X; Kudo,
   Toyoki/0000-0002-2953-9603; Anderson, John/0000-0002-6625-114X; Singh,
   Rajvinder/0000-0001-9116-6054; Bisschops, Raf/0000-0002-9994-8226
FU Wellcome Trust 203145Z/16/Z [203145Z/16/Z EP/P027938/1]; Engineering and
   Physical Sciences Research Council; EPSRC [EP/P027938/1, EP/R004080/1,
   EP/P012841/1] Funding Source: UKRI
FX Wellcome Trust 203145Z/16/Z; Engineering and Physical Sciences Research
   Council 203145Z/16/Z EP/P027938/1
CR Ahmad OF, 2020, TECH INNOVAT GASTROI, V22, P80, DOI 10.1016/j.tgie.2019.150636
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Barua I, 2021, ENDOSCOPY, V53, P277, DOI 10.1055/a-1201-7165
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Burt CG, 2009, DIS COLON RECTUM, V52, P898, DOI 10.1007/DCR.0b013e3181a0b358
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   East JE, 2018, LANCET GASTROENTEROL, V3, P10, DOI 10.1016/S2468-1253(17)30366-7
   Francis N, 2017, SURG ENDOSC, V31, P2042, DOI 10.1007/s00464-017-5531-z
   Guizard N, 2019, GASTROENTEROLOGY, V156, pS48
   Hart AL, 2017, J CROHNS COLITIS, V11, P204, DOI 10.1093/ecco-jcc/jjw144
   Hassan C, 2021, DIGEST ENDOSC, V33, P285, DOI 10.1111/den.13807
   Hassan C, 2018, GASTROINTEST ENDOSC, V88, P865, DOI 10.1016/j.gie.2018.08.022
   He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Langlotz CP, 2019, RADIOLOGY, V291, P781, DOI 10.1148/radiol.2019190613
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Liu XX, 2020, NAT MED, V26, P1364, DOI 10.1038/s41591-020-1034-x
   Lutnick B, 2019, NAT MACH INTELL, V1, P112, DOI 10.1038/s42256-019-0018-3
   Mori Y, 2020, GASTROINTEST ENDOSC, V92, P905, DOI 10.1016/j.gie.2020.03.3759
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Rees CJ, 2016, ENDOSCOPY, V48, P884, DOI 10.1055/s-0042-110398
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Xu S, 2014, SURG ENDOSC, V28, P2569, DOI 10.1007/s00464-014-3504-z
NR 33
TC 27
Z9 27
U1 0
U2 2
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD SEP
PY 2021
VL 53
IS 9
BP 893
EP 901
DI 10.1055/a-1306-7590
EA JAN 2021
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA YN3PU
UT WOS:000607390000001
PM 33167043
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Banik, D
   Roy, K
   Bhattacharjee, D
   Nasipuri, M
   Krejcar, O
AF Banik, Debapriya
   Roy, Kaushiki
   Bhattacharjee, Debotosh
   Nasipuri, Mita
   Krejcar, Ondrej
TI Polyp-Net: A Multimodel Fusion Network for Polyp Segmentation
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
LA English
DT Article
DE 2-D dual-tree complex wavelet transform (2-D DT-CWT); colonoscopy;
   convolutional neural network (CNN); fusion; level-set method (LSM);
   polyp; segmentation
ID IMAGES
AB Computer-aided diagnosis of disease primarily depends on proper vision-based measurement (VBM). The traditional approach followed for diagnosis of colorectal cancer includes a manual screening of colorectum via a colonoscope and resection of polyps for histopathological analysis to decide the grade of malignancy. This procedure is time-consuming and expensive, and removal of benign polyp for analysis signifies the inefficiency of the diagnosis system. These drawbacks inspired us to develop an automatic vision-based analysis method for preliminary in vivo malignancy analysis of the polyp region. In this work, we have proposed a fusion-based polyp segmentation network, namely, Polyp-Net. Recently, convolutional neural networks (CNNs) have shown immense success in the domain of medical image analysis as it can exploit in-depth significant features with high discrimination capabilities. Therefore, motivated by these insights, we have proposed an enriched version of CNN with a nascent pooling mechanism, namely dual-tree wavelet pooled CNN (DT-WpCNN). The resultant segmented mask contains some surplus high-intensity regions apart from the polyp region. These shortcomings are avoided using a new variation of the region-based level-set method, namely, the local gradient weighting-embedded level-set method (LGWe-LSM), which shows a significant reduction of false-positive rate. The pixel-level fusion of the two enhanced methods shows more potentiality in the segmentation of the polyp regions. Our proposed network is trained on CVC-colon DB and tested on CVC-clinic DB. It achieves a dice score of 0.839, volume-similarity of 0.863, precision of 0.836, recall of 0.811, F1-score of 0.823, F2-score of 0.815, and Hausdorff distance of 21.796 which outperforms the existing baseline CNN's and recent state-of-the-art methods.
C1 [Banik, Debapriya; Roy, Kaushiki; Bhattacharjee, Debotosh; Nasipuri, Mita] Jadavpur Univ, Comp Sci & Engn Dept, Kolkata 700032, India.
   [Bhattacharjee, Debotosh; Krejcar, Ondrej] Univ Hradec Kralove, Fac Informat & Management, Ctr Basic & Appl Sci, Hradec Kralove 50003, Czech Republic.
   [Krejcar, Ondrej] Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Kuala Lumpur 54100, Malaysia.
C3 Jadavpur University; University of Hradec Kralove; Universiti Teknologi
   Malaysia
RP Banik, D (通讯作者)，Jadavpur Univ, Comp Sci & Engn Dept, Kolkata 700032, India.
EM debu.cse88@gmail.com; kaushiki.cse@gmail.com; debotosh@ieee.org;
   mitanasipuri@gmail.com; ondrej.krejcar@uhk.cz
RI Bhattacharjee, Debotosh/L-8521-2015; Bhattacharjee,
   Debotosh/Q-4065-2019; Krejcar, Ondrej/A-8639-2008
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Krejcar, Ondrej/0000-0002-5992-2574;
   Banik, Debapriya/0000-0001-5031-1374
FU project (Development of a computer-assisted diagnosis system for
   segmenting and detecting abnormalities and disease diagnosis) -
   Department of Science and Technology (DST), Government of India; Grant
   Agency of Excellence, Faculty of Informatics and Management, University
   of Hradec Kralove, Czech Republic [2020/2205]; Universiti Teknologi
   Malaysia (UTM) [Vot-20H04]; Malaysia Research University Network (MRUN)
   [Vot 4L876]; Fundamental Research Grant Scheme (FRGS) under the Ministry
   of Education Malaysia [Vot5F073]; Council of Scientific and Industrial
   Research (CSIR) through the SRF-Direct Fellowship Program
   [09/096(0922)2K18 EMR-I]; Department of Science and Technology (DST),
   Government of India, through the DST INSPIRE Fellowship Program
   [IF170366]
FX This work was supported in part by the project (Development of a
   computer-assisted diagnosis system for segmenting and detecting
   abnormalities and disease diagnosis) funded by the Department of Science
   and Technology (DST), Government of India, in part by the project
   (2020/2205), Grant Agency of Excellence, Faculty of Informatics and
   Management, University of Hradec Kralove, Czech Republic, in part by the
   project at Universiti Teknologi Malaysia (UTM) under Research University
   Grant Vot-20H04, in part by Malaysia Research University Network (MRUN)
   Vot 4L876, and in part by the Fundamental Research Grant Scheme (FRGS)
   Vot5F073 supported under the Ministry of Education Malaysia. The work of
   Debapriya Banik was supported by the Council of Scientific and
   Industrial Research (CSIR) through the SRF-Direct Fellowship Program
   under Grant 09/096(0922)2K18 EMR-I. The work of Kaushiki Roy was
   supported by the Department of Science and Technology (DST), Government
   of India, through the DST INSPIRE Fellowship Program under Grant
   IF170366.
CR Asperti A., 2018, P INT JOINT C BIOM E, P199
   Banik Debapriya, 2020, Advanced Computing and Systems for Security. Volume Twelve. Advances in Intelligent Systems and Computing (AISC 1136), P109, DOI 10.1007/978-981-15-2930-6_9
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   De Vito L, 2017, IEEE T INSTRUM MEAS, V66, P2502, DOI 10.1109/TIM.2017.2733318
   Esedoglu S, 2002, EUR J APPL MATH, V13, P353, DOI 10.1017/S0956792501004904
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Ghafoorian M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05300-5
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Li SS, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/508543
   Lu Lu, 2018, Wuhan University Journal of Natural Sciences, V23, P178, DOI 10.1007/s11859-018-1308-z
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Nikmanesh S, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P690, DOI 10.1109/ISTEL.2018.8660980
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Philipsen RHHM, 2015, IEEE T MED IMAGING, V34, P1965, DOI 10.1109/TMI.2015.2418031
   Pogorelov K, 2018, COMP MED SY, P381, DOI 10.1109/CBMS.2018.00073
   Pramanik S, 2020, IEEE T INSTRUM MEAS, V69, P2722, DOI 10.1109/TIM.2019.2925879
   Pramanik S, 2019, IEEE T MED IMAGING, V38, P572, DOI 10.1109/TMI.2018.2867620
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanchez-Gonzalez A., 2017, SURG ROBOTICS
   Sasmal P, 2018, INT CONF CIRC SYST S, P201, DOI 10.1109/ICSIGSYS.2018.8372666
   Shirmohammadi S, 2016, IEEE INSTRU MEAS MAG, V19, P6
   Shirmohammadi S, 2014, IEEE INSTRU MEAS MAG, V17, P41, DOI 10.1109/MIM.2014.6825388
   Singh A, 2017, IEEE INT CONF COMP V, P1140, DOI 10.1109/ICCVW.2017.138
   Stanley Osher, 2004, APPL MECH REV, V57, pB15, DOI [10.1115/1.1760520, DOI 10.1115/1.1760520]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Xu SZ, 2011, J DIGIT IMAGING, V24, P754, DOI 10.1007/s10278-011-9365-2
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zagoruyko S., 2016, ARXIV160507146, P1
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 38
TC 26
Z9 26
U1 5
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9456
EI 1557-9662
J9 IEEE T INSTRUM MEAS
JI IEEE Trans. Instrum. Meas.
PY 2021
VL 70
AR 4000512
DI 10.1109/TIM.2020.3015607
PG 12
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA OU9KO
UT WOS:000591842200012
DA 2023-08-21
ER

PT J
AU Dogan, RS
   Yilmaz, B
AF Dogan, Refika Sultan
   Yilmaz, Bulent
TI Comparison of deep learning and conventional machine learning methods
   for classification of colon polyp types
SO EUROBIOTECH JOURNAL
LA English
DT Article
ID COMPUTER-AIDED CLASSIFICATION; DIAGNOSIS; ADENOMAS; SYSTEM
AB Determination of polyp types requires tissue biopsy during colonoscopy and then histopathological examination of the microscopic images which tremendously time-consuming and costly. The first aim of this study was to design a computer-aided diagnosis system to classify polyp types using colonoscopy images (optical biopsy) without the need for tissue biopsy. For this purpose, two different approaches were designed based on conventional machine learning (ML) and deep learning. Firstly, classification was performed using random forest approach by means of the features obtained from the histogram of gradients descriptor. Secondly, simple convolutional neural networks (CNN) based architecture was built to train with the colonoscopy images containing colon polyps. The performances of these approaches on two (adenoma & serrated vs. hyperplastic) or three (adenoma vs. hyperplastic vs. serrated) category classifications were investigated. Furthermore, the effect of imaging modality on the classification was also examined using white-light and narrow band imaging systems. The performance of these approaches was compared with the results obtained by 3 novice and 4 expert doctors. Two-category classification results showed that conventional ML approach achieved significantly better than the simple CNN based approach did in both narrow band and white-light imaging modalities. The accuracy reached almost 95% for white-light imaging. This performance surpassed the correct classification rate of all 7 doctors. Additionally, the second task (three-category) results indicated that the simple CNN architecture outperformed both conventional ML based approaches and the doctors. This study shows the feasibility of using conventional machine learning or deep learning based approaches in automatic classification of colon types on colonoscopy images.
C1 [Dogan, Refika Sultan; Yilmaz, Bulent] Abdullah Gul Univ, Fac Nat & Life Sci, Bioengn Dept, Kayseri, Turkey.
   [Yilmaz, Bulent] Abdullah Gul Univ, Fac Engn, Elect & Elect Engn Dept, Kayseri, Turkey.
   [Dogan, Refika Sultan; Yilmaz, Bulent] Abdullah Gul Univ, Fac Engn, Biomed Instrumentat & Signal Anal Lab, Kayseri, Turkey.
C3 Abdullah Gul University; Abdullah Gul University; Erciyes University;
   Abdullah Gul University; Erciyes University
RP Yilmaz, B (通讯作者)，Abdullah Gul Univ, Fac Nat & Life Sci, Bioengn Dept, Kayseri, Turkey.; Yilmaz, B (通讯作者)，Abdullah Gul Univ, Fac Engn, Elect & Elect Engn Dept, Kayseri, Turkey.; Yilmaz, B (通讯作者)，Abdullah Gul Univ, Fac Engn, Biomed Instrumentat & Signal Anal Lab, Kayseri, Turkey.
EM bulent.yilmaz@agu.edu.tr
CR Abu Ghosh MM, 2017, 2017 INTERNATIONAL CONFERENCE ON PROMISING ELECTRONIC TECHNOLOGIES (ICPET 2017), P77, DOI 10.1109/ICPET.2017.20
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Alhindi TJ, 2018, IEEE IJCNN
   [Anonymous], 2018, CA-CANCER J CLIN, DOI DOI 10.3322/caac.21551
   Aslan MF, 2020, MEASUREMENT, V158, DOI 10.1016/j.measurement.2020.107704
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bond JH, 2000, AM J GASTROENTEROL, V95, P3053
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai L, 2018, J FRANKLIN I, V355, P1991, DOI 10.1016/j.jfranklin.2017.09.003
   Cao X., 2011, P 18 IEEE INT C IM P, P2469
   Cooper GM, 2007, CELL MOL APPROACH, P743
   Cutler DR, 2007, ECOLOGY, V88, P2783, DOI 10.1890/07-0539.1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Fushiki T, 2011, STAT COMPUT, V21, P137, DOI 10.1007/s11222-009-9153-8
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Hafner M, 2010, IEEE T INF TECHNOL B, V14, P958, DOI 10.1109/TITB.2010.2044184
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Hasegawa S, 2011, ONCOL LETT, V2, P785, DOI 10.3892/ol.2011.341
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Jha D, 2020, ARXIV201107631
   Koyejo O. O., 2014, ADV NEURAL INFORM PR, V27
   KRISHNAN SM, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P610, DOI 10.1109/IEMBS.1994.411878
   Krishnan SM, 2002, INTESTINAL ABNORMALI, V20, P895, DOI [10.1109/iembs.1998.745583, DOI 10.1109/IEMBS.1998.745583]
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Mobadersany P, 2018, P NATL ACAD SCI USA, V115, pE2970, DOI 10.1073/pnas.1717139115
   Montgomery D.C, 2017, APPL STAT PROBABILIT
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Pace F, 2005, EUR J GASTROEN HEPAT, V17, P605, DOI 10.1097/00042737-200506000-00003
   Sharma A., 2016, INT J INNOV RES COMP, V3297, P11449, DOI [10.15680/IJIRCCE.2016., DOI 10.15680/IJIRCCE.2016]
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   SHINYA H, 1979, ANN SURG, V190, P679, DOI 10.1097/00000658-197912000-00001
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takayama T, 1998, NEW ENGL J MED, V339, P1277, DOI 10.1056/NEJM199810293391803
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Wang Y, 2019, PROC SPIE, V10950, DOI 10.1117/12.2512578
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 43
TC 1
Z9 1
U1 0
U2 3
PU SCIENDO
PI WARSAW
PA BOGUMILA ZUGA 32A, WARSAW, MAZOVIA, POLAND
EI 2564-615X
J9 EUROBIOTECH J
JI EuroBiotech J.
PD JAN
PY 2021
VL 5
IS 1
BP 34
EP 42
DI 10.2478/ebtj-2021-0006
PG 9
WC Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Science & Technology - Other Topics
GA QA0GJ
UT WOS:000613126700006
OA gold
DA 2023-08-21
ER

PT J
AU Ghatwary, N
   Zolgharni, M
   Janan, F
   Ye, XJ
AF Ghatwary, Noha
   Zolgharni, Massoud
   Janan, Faraz
   Ye, Xujiong
TI Learning Spatiotemporal Features for Esophageal Abnormality Detection
   From Endoscopic Videos
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Feature extraction; Videos; Spatiotemporal phenomena; Three-dimensional
   displays; Machine learning; Cancer; Esophagus; Esophageal abnormality
   detection; endoscopy; spatio-temporal features; deep learning
ID BARRETTS-ESOPHAGUS; DIAGNOSIS
AB Esophageal cancer is categorized as a type of disease with a high mortality rate. Early detection of esophageal abnormalities (i.e. precancerous and early cancerous) can improve the survival rate of the patients. Recent deep learning-based methods for selected types of esophageal abnormality detection from endoscopic images have been proposed. However, no methods have been introduced in the literature to cover the detection from endoscopic videos, detection from challenging frames and detection of more than one esophageal abnormality type. In this paper, we present an efficient method to automatically detect different types of esophageal abnormalities from endoscopic videos. We propose a novel 3D Sequential DenseConvLstm network that extracts spatiotemporal features from the input video. Our network incorporates 3D Convolutional Neural Network (3DCNN) and Convolutional Lstm (ConvLstm) to efficiently learn short and long term spatiotemporal features. The generated feature map is utilized by a region proposal network and ROI pooling layer to produce a bounding box that detects abnormality regions in each frame throughout the video. Finally, we investigate a post-processing method named Frame Search Conditional Random Field (FS-CRF) that improves the overall performance of the model by recovering the missing regions in neighborhood frames within the same clip. We extensively validate our model on an endoscopic video dataset that includes a variety of esophageal abnormalities. Our model achieved high performance using different evaluation metrics showing 93.7 recall, 92.7 precision, and 93.2 F-measure. Moreover, as no results have been reported in the literature for the esophageal abnormality detection from endoscopic videos, to validate the robustness of our model, we have tested the model on a publicly available colonoscopy video dataset, achieving the polyp detection performance in a recall of 81.18, precision of 96.45 and F-measure 88.16, compared to the state-of-the-art results of 78.84 recall, 90.51 precision and 84.27 F-measure using the same dataset. This demonstrates that the proposed method can be adapted to different gastrointestinal endoscopic video applications with a promising performance.
C1 [Ghatwary, Noha; Janan, Faraz; Ye, Xujiong] Univ Lincoln, Comp Sci Dept, Lincoln LN6 7TS, England.
   [Ghatwary, Noha] Arab Acad Sci & Technol, Comp Engn Dept, Alexandria, Egypt.
   [Zolgharni, Massoud] Univ West London, Comp Sci Dept, London W5 5RF, England.
C3 University of Lincoln; Egyptian Knowledge Bank (EKB); Arab Academy for
   Science, Technology & Maritime Transport
RP Ghatwary, N (通讯作者)，Univ Lincoln, Comp Sci Dept, Lincoln LN6 7TS, England.
EM nghatwary@lincoln.ac.uk; massoud.zolgharni@uwl.ac.uk;
   fjanan@lincoln.ac.uk; xye@lincoln.ac.uk
OI Zolgharni, Massoud/0000-0003-0904-2904; Janan,
   Faraz/0000-0001-7479-6708; ye, xujiong/0000-0003-0115-0724
CR Akilan T, 2020, IEEE T INTELL TRANSP, V21, P959, DOI 10.1109/TITS.2019.2900426
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], 2018, SUBCHALLENGE EARLY B
   Behrens A, 2011, DTSCH ARZTEBL INT, V108, P313, DOI 10.3238/arztebl.2011.0313
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Chollet F., 2015, KERAS PROBABILISTIC
   Colleoni E, 2019, IEEE ROBOT AUTOM LET, V4, P2714, DOI 10.1109/LRA.2019.2917163
   Domingues I, 2019, IEEE ACCESS, V7, P103080, DOI 10.1109/ACCESS.2019.2930891
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WJ, 2019, IEEE ACCESS, V7, P142053, DOI 10.1109/ACCESS.2019.2944676
   Eroglu A, 2004, DIS ESOPHAGUS, V17, P91, DOI 10.1111/j.1442-2050.2004.00382.x
   Fei-Fei, 2015, ARXIV150602078
   Flejou JF, 2005, GUT, V54, pI6, DOI 10.1136/gut.2004.041525
   GHATWARY N, 2019, P INT WORKSH MACH LE, P89
   Ghatwary N, 2019, IEEE ACCESS, V7, P84374, DOI 10.1109/ACCESS.2019.2925585
   Ghatwary N, 2017, COMM COM INF SC, V723, P897, DOI 10.1007/978-3-319-60964-5_78
   Ghatwary N, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014502
   Ghatwary N, 2019, INT J COMPUT ASS RAD, V14, P611, DOI 10.1007/s11548-019-01914-4
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.1109/CVPR.2018.00716
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang GL, 2017, IEEE ICC
   Huang J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6837, DOI 10.1109/ICASSP.2018.8461963
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   JR LAD, 2018, CLIN INFECT DIS, V96, P203, DOI DOI 10.1016/J.COMPBIOMED.2018.03.014
   Krahenbuhl P., 2011, ADV NEURAL INFORM PR, V24, P109, DOI DOI 10.5555/2986459.2986472
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   MATHAI TS, 2019, P INT C MED IM COMP, P173
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mendel R., 2017, BILDVERARBEITUNG MED, P80, DOI DOI 10.1007/978-3-662-54345-0_23
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Nwoye CI, 2019, INT J COMPUT ASS RAD, V14, P1059, DOI 10.1007/s11548-019-01958-6
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Scholvinck DW, 2017, ENDOSCOPY, V49, P113, DOI 10.1055/s-0042-118312
   Shi XJ, 2015, ADV NEUR IN, V28
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Szegedy C., 2017, AAAI, V4, P12
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   van Riel S, 2018, IEEE IMAGE PROC, P1383, DOI 10.1109/ICIP.2018.8451771
   Xu XAN, 2019, IEEE T MED IMAGING, V38, P1885, DOI 10.1109/TMI.2019.2894854
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhou ZL, 2019, IEEE ACCESS, V7, P100658, DOI 10.1109/ACCESS.2019.2930173
   Zhu GM, 2019, IEEE T MULTIMEDIA, V21, P1011, DOI 10.1109/TMM.2018.2869278
   Zhu HY, 2017, IEEE I CONF COMP VIS, P5814, DOI 10.1109/ICCV.2017.619
NR 50
TC 12
Z9 12
U1 2
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD JAN
PY 2021
VL 25
IS 1
BP 131
EP 142
DI 10.1109/JBHI.2020.2995193
PG 12
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA RP4NB
UT WOS:000641705100013
PM 32750901
OA Green Accepted
DA 2023-08-21
ER

PT J
AU Hassan, C
   Spadaccini, M
   Iannone, A
   Maselli, R
   Jovani, M
   Chandrasekar, VT
   Antonelli, G
   Yu, HG
   Areia, M
   Dinis-Ribeiro, M
   Bhandari, P
   Sharma, P
   Rex, DK
   Rosch, T
   Wallace, M
   Repici, A
AF Hassan, Cesare
   Spadaccini, Marco
   Iannone, Andrea
   Maselli, Roberta
   Jovani, Manol
   Chandrasekar, Viveksandeep Thoguluva
   Antonelli, Giulio
   Yu, Honggang
   Areia, Miguel
   Dinis-Ribeiro, Mario
   Bhandari, Pradeep
   Sharma, Prateek
   Rex, Douglas K.
   Roesch, Thomas
   Wallace, Michael
   Repici, Alessandro
TI Performance of artificial intelligence in colonoscopy for adenoma and
   polyp detection: a systematic review and meta-analysis
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
ID COMPUTER-AIDED DETECTION; RISK
AB Background and Aims: One-fourth of colorectal neoplasia are missed at screening colonoscopy, representing the main cause of interval colorectal cancer. Deep learning systems with real-time computer-aided polyp detection (CADe) showed high accuracy in artificial settings, and preliminary randomized controlled trials (RCTs) reported favorable outcomes in the clinical setting. The aim of this meta-analysis was to summarize available RCTs on the performance of CADe systems in colorectal neoplasia detection.
   Methods: We searched MEDLINE, EMBASE, and Cochrane Central databases until March 2020 for RCTs reporting diagnostic accuracy of CADe systems in the detection of colorectal neoplasia. The primary outcome was pooled adenoma detection rate (ADR), and secondary outcomes were adenoma per colonoscopy (APC) according to size, morphology, and location; advanced APC; polyp detection rate; polyps per colonoscopy; and sessile serrated lesions per colonoscopy. We calculated risk ratios (RRs), performed subgroup and sensitivity analyses, and assessed heterogeneity and publication bias.
   Results: Overall, 5 randomized controlled trials (4354 patients) were included in the final analysis. Pooled ADR was significantly higher in the CADe group than in the control group (791/2163 [ 36.6%] vs 558/2191 [ 25.2%]; RR, 1.44; 95% confidence interval [CI], 1.27-1.62; P<.01; I-2 = 42%). APC was also higher in the CADe group compared with control (1249/2163 [.58] vs 779/2191 [.36]; RR, 1.70; 95% CI, 1.53-1.89; P < .01; I-2 = 33%). APC was higher for <= 5-mm (RR, 1.69; 95% CI, 1.48-1.84), 6- to 9-mm (RR, 1.44; 95% CI, 1.19-1.75), and >= 10-mm adenomas (RR, 1.46; 95% CI, 1.04-2.06) and for proximal (RR, 1.59; 95% CI, 1.34-1.88), distal (RR, 1.68; 95% CI, 1.50-1.88), flat (RR, 1.78; 95% CI, 1.47-2.15), and polypoid morphology (RR, 1.54; 95% CI, 1.40-1.68). Regarding histology, CADe resulted in a higher sessile serrated lesion per colonoscopy (RR, 1.52; 95% CI, 1.14-2.02), whereas a nonsignificant trend for advanced ADR was found (RR, 1.35; 95% CI,.74-2.47; P = .33; I-2 = 69%). Level of evidence for RCTs was graded as moderate.
   Conclusions: According to available evidence, the incorporation of artificial intelligence as aid for detection of colorectal neoplasia results in a significant increase in the detection of colorectal neoplasia, and such effect is independent from main adenoma characteristics.
C1 [Hassan, Cesare; Antonelli, Giulio] Nuovo Regina Margherita Hosp, Digest Endoscopy Unit, Rome, Italy.
   [Spadaccini, Marco; Maselli, Roberta; Repici, Alessandro] Humanitas Clin & Res CenterIRCCS, Endoscopy Unit, Rozzano, Italy.
   [Spadaccini, Marco; Repici, Alessandro] Humanitas Univ, Dept Biomed Sci, Rozzano, Italy.
   [Iannone, Andrea] Univ Bari, Dept Emergency & Organ Transplantat, Sect Gastroenterol, Bari, Italy.
   [Jovani, Manol] Johns Hopkins Univ Hosp, Div Gastroenterol & Hepatol, Baltimore, MD 21287 USA.
   [Jovani, Manol] Harvard Med Sch, Massachusetts Gen Hosp, Div Gastroenterol, Boston, MA 02115 USA.
   [Chandrasekar, Viveksandeep Thoguluva; Sharma, Prateek] Kansas City VA Med Ctr, Gastroenterol & Hepatol, Kansas City, MO USA.
   [Yu, Honggang] Wuhan Univ, Dept Gastroenterol, Renmin Hosp, Wuhan, Peoples R China.
   [Areia, Miguel] Portuguese Oncol Inst Coimbra, Dept Gastroenterol, Coimbra, Portugal.
   [Dinis-Ribeiro, Mario] Univ Med, Fac Porto, MEDCIDS Dept Community Med Informat & Decis Hlth, Porto, Portugal.
   [Bhandari, Pradeep] Queen Alexandra Hosp, Dept Gastroenterol, Portsmouth, Hants, England.
   [Rex, Douglas K.] Indiana Univ Sch Med, Div Gastroenterol Hepatol, Indianapolis, IN 46202 USA.
   [Roesch, Thomas] Univ Hosp Hamburg Eppendorf, Dept Interdisciplinary Endoscopy, Hamburg, Germany.
   [Wallace, Michael] Mayo Clin, Dept Gastroenterol, Jacksonville, FL 32224 USA.
C3 Poliambulatorio Nuovo Regina Margherita; Humanitas University; IRCCS
   Humanitas Research Hospital; Universita degli Studi di Bari Aldo Moro;
   Johns Hopkins University; Johns Hopkins Medicine; Harvard University;
   Harvard Medical School; Massachusetts General Hospital; Wuhan
   University; Universidade de Coimbra; Portsmouth Hospitals NHS Trust;
   Queen Alexandra Hospital; Indiana University System; Indiana University
   Bloomington; University of Hamburg; University Medical Center
   Hamburg-Eppendorf; Mayo Clinic
RP Spadaccini, M (通讯作者)，Humanitas Res Hosp & Univ, Via Manzoni 56, I-20089 Milan, Italy.
EM marco.spadaccini@humanitas.it
RI Areia, Miguel/H-9590-2013; Maselli, Roberta/HJY-6995-2023; Repici,
   Alessandro/HFH-8162-2022; Sharma, Prateek/IZE-3910-2023; hassan,
   cesare/H-2844-2012; Wallace, Michael/GZL-9731-2022; Spadaccini,
   Marco/HOH-7613-2023; Dinis-Ribeiro, Mario/A-9248-2010
OI Areia, Miguel/0000-0001-9787-8175; Maselli, Roberta/0000-0001-7291-9110;
   Repici, Alessandro/0000-0002-1621-6450; hassan,
   cesare/0000-0001-7167-1459; Wallace, Michael/0000-0002-6446-5785;
   Spadaccini, Marco/0000-0003-3909-9012; Dinis-Ribeiro,
   Mario/0000-0003-0121-6850; Antonelli, Giulio/0000-0003-1797-3864;
   bhandari, pradeep/0000-0002-1241-2083
CR Anderson R, 2020, GASTROENTEROLOGY, V158, P1287, DOI 10.1053/j.gastro.2019.12.031
   Atkins D, 2004, BMC HEALTH SERV RES, V4, DOI 10.1186/1472-6963-4-38
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   DERSIMONIAN R, 1986, CONTROL CLIN TRIALS, V7, P177, DOI 10.1016/0197-2456(86)90046-2
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Greenspan M, 2013, AM J GASTROENTEROL, V108, P1286, DOI 10.1038/ajg.2013.149
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Higgins Julian P T, 2003, BMJ, V327, P557
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Luo DH, 2018, STAT METHODS MED RES, V27, P1785, DOI 10.1177/0962280216669183
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1186/s13643-015-0087-2, 10.1136/bmj.b2535]
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Parasa S, 2020, GASTROINTEST ENDOSC, V92, P938, DOI 10.1016/j.gie.2020.04.044
   Penz D, 2020, GASTROINTEST ENDOSC, V91, P135, DOI 10.1016/j.gie.2019.08.038
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Robertson DJ, 2014, GUT, V63, P949, DOI 10.1136/gutjnl-2012-303796
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Wan X, 2014, BMC MED RES METHODOL, V14, DOI 10.1186/1471-2288-14-135
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 24
TC 171
Z9 172
U1 5
U2 31
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JAN
PY 2021
VL 93
IS 1
BP 77
EP +
DI 10.1016/j.gie.2020.06.059
PG 15
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA PH6VV
UT WOS:000600548600008
PM 32598963
OA Green Submitted
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Holtmann, GJ
   Huelsen, A
   Shah, AY
   Hourigan, LF
   Morrison, M
AF Holtmann, Gerald J.
   Huelsen, Alexander
   Shah, Ayesha
   Hourigan, Luke F.
   Morrison, Mark
TI Is a Fundamental Design Change for Gastrointestinal Endoscopes Required?
SO JOURNAL OF CLINICAL GASTROENTEROLOGY
LA English
DT Review
DE gastrointestinal endoscopy; anesthesia; complications; innovation;
   infection; single-use; artificial intelligence
ID SUBMUCOSAL DISSECTION; MUCOSAL RESECTION; COMPLICATIONS; DISINFECTION;
   COLONOSCOPY; SOCIETY; LESIONS; TRACT
AB Since the first fiberoptic instruments, gastrointestinal endoscopy has shaped the field of gastroenterology and is now a key diagnostic and therapeutic tool. Compared with the initial fiberoptic endoscopes state-of-the-art optical chips (or charge-coupled device technology) allowed a quantum leap in image quality. Despite these advances, gastrointestinal endoscopy is far from being perfect. The diagnostic yield (eg, for adenoma detection rates) is highly operator dependent and there is still the need for sedation or even anesthesia to address discomfort during the procedure. Despite highly standardized cleaning and high-level disinfection the reuse of contemporary (and difficult to clean) endoscopes with multiple channels exposes patients to the risk of transmission of infections. Artificial intelligence and pattern recognition should eliminate interindividual variability including polyp detection rates, self-propelled, and (potentially remotely controlled) scopes with a soft shaft could reduce the discomfort during procedures and abolish the need for sedation and anesthesia altogether and single-use designs should eliminate the risk of patient-to-patient transmission of infections. While these innovations are feasible and could be implemented rapidly utilizing available technology, they require a paradigm shift affecting all levels of the value chain from the supplier of the instruments to the end-users. Some may negate the need for a paradigm shift, but it is evident that a major redesign of the endoscopic equipment is overdue to fully utilize novel technologies and most importantly ensure the best possible outcomes for patients.
C1 [Holtmann, Gerald J.; Huelsen, Alexander; Shah, Ayesha; Hourigan, Luke F.] Princess Alexandra Hosp, Brisbane, Qld, Australia.
   [Holtmann, Gerald J.; Huelsen, Alexander; Shah, Ayesha; Hourigan, Luke F.; Morrison, Mark] Univ Queensland, Diamantina Inst, Fac Med, Woolloongabba, Qld, Australia.
   [Holtmann, Gerald J.; Huelsen, Alexander; Shah, Ayesha; Hourigan, Luke F.] Univ Queensland, Diamantina Inst, Fac Hlth & Behav Sci, Woolloongabba, Qld, Australia.
C3 University of Queensland; University of Queensland
RP Holtmann, GJ (通讯作者)，Princess Alexandra Hosp, 199 Ipswich Rd, Woolloongabba, Qld 4102, Australia.
EM g.holtmann@uq.edu.au
RI Holtmann, G.J./I-5341-2014; Morrison, Mark/C-9707-2013
OI Holtmann, G.J./0000-0002-0206-2358; Morrison, Mark/0000-0001-9257-9133;
   Huelsen, Alexander/0000-0001-8069-3414
CR Alfa MJ, 2020, GASTROINTEST ENDOSC, V91, P236, DOI 10.1016/j.gie.2019.08.043
   Aljebreen AM, 2014, WORLD J GASTROENTERO, V20, P5113, DOI 10.3748/wjg.v20.i17.5113
   ARROWSMITH JB, 1991, GASTROINTEST ENDOSC, V37, P421, DOI 10.1016/S0016-5107(91)70773-6
   AXON ATR, 1981, LANCET, V1, P1093
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Cattoir L, 2017, INFECT CONT HOSP EP, V38, P1062, DOI 10.1017/ice.2017.115
   Chen WC, 2016, EXPERT REV GASTROENT, V10, P481, DOI 10.1586/17474124.2016.1122520
   De Ceglie A, 2016, CRIT REV ONCOL HEMAT, V104, P138, DOI 10.1016/j.critrevonc.2016.06.008
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   HIRSCHOWITZ B I, 1957, Med Bull (Ann Arbor), V23, P178
   Ho SH, 2018, J CLIN GASTROENTEROL, V52, P295, DOI 10.1097/MCG.0000000000000960
   Inoue H, 2010, ENDOSCOPY, V42, P265, DOI 10.1055/s-0029-1244080
   Kumbhari V, 2017, CURR OPIN GASTROEN, V33, P358, DOI 10.1097/MOG.0000000000000383
   Kume K, 2015, ENDOSCOPY, V47, P815, DOI 10.1055/s-0034-1391973
   Levy I, 2016, BEST PRACT RES CL GA, V30, P705, DOI 10.1016/j.bpg.2016.09.005
   McCafferty CE, 2018, ANN CLIN MICROB ANTI, V17, DOI 10.1186/s12941-018-0289-2
   Muguruma N, 2017, CLIN J GASTROENTEROL, V10, P1, DOI 10.1007/s12328-016-0710-3
   Muscarella LF, 2014, WORLD J GASTRO ENDOS, V6, P457, DOI 10.4253/wjge.v6.i10.457
   Neumann H, 2016, DIGEST ENDOSC, V28, P534, DOI 10.1111/den.12652
   Neves MS, 2016, GASTROINTEST ENDOSC, V83, P944, DOI 10.1016/j.gie.2015.09.016
   Ning B, 2017, ANN CARDIOTHORAC SUR, V6, P88, DOI 10.21037/acs.2017.03.15
   Nishizawa T, 2018, GUT LIVER, V12, P119, DOI 10.5009/gnl17095
   Ofstead CL, 2018, AM J INFECT CONTROL, V46, P689, DOI 10.1016/j.ajic.2018.03.002
   Penz D, 2020, GASTROINTEST ENDOSC, V91, P135, DOI 10.1016/j.gie.2019.08.038
   Petersen BT, 2017, GASTROINTEST ENDOSC, V85, P282, DOI 10.1016/j.gie.2016.10.002
   Rees CJ, 2019, NAT REV GASTRO HEPAT, V16, P584, DOI 10.1038/s41575-019-0178-y
   Repici A, 2020, GASTROINTEST ENDOSC, V92, P192, DOI 10.1016/j.gie.2020.03.019
   Valeriani F, 2018, AM J INFECT CONTROL, V46, P159, DOI 10.1016/j.ajic.2017.08.008
   Vargo John J 2nd, 2015, Gastrointest Endosc Clin N Am, V25, P147, DOI 10.1016/j.giec.2014.09.009
   Yeung BPM, 2016, WORLD J GASTROENTERO, V22, P1811, DOI 10.3748/wjg.v22.i5.1811
NR 30
TC 2
Z9 2
U1 0
U2 6
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0192-0790
EI 1539-2031
J9 J CLIN GASTROENTEROL
JI J. Clin. Gastroenterol.
PD JAN
PY 2021
VL 55
IS 1
BP 21
EP 24
DI 10.1097/MCG.0000000000001430
PG 4
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA PG4LV
UT WOS:000599709300004
PM 33021560
DA 2023-08-21
ER

PT J
AU Hong, LTT
   Thanh, NC
   Long, TQ
AF Hong, Le Thi Thu
   Thanh, Nguyen Chi
   Long, Tran Quoc
TI CRF-EfficientUNet: An Improved UNet Framework for Polyp Segmentation in
   Colonoscopy Images With Combined Asymmetric Loss Function and CRF-RNN
   Layer
SO IEEE ACCESS
LA English
DT Article
DE Image segmentation; Colonoscopy; Training; Feature extraction; Deep
   learning; Cancer; Image color analysis; Polyp segmentation; medical
   image analysis; deep learning; loss function
AB Colonoscopy is considered the gold-standard investigation for colorectal cancer screening. However, the polyps miss rate in clinical practice is relatively high due to different factors. This presents an opportunity to use AI models to automatically detect and segment polyps, supporting clinicians to reduce the number of polyps missed. Inspired by the success of UNets, a popular strategy for solving medical image segmentation tasks, this article proposes a novel framework for polyp segmentation called CRF-EfficientUNet, which enhances UNet using the EfficientNet encoder, a combined asymmetric loss function, and Conditional Random Field as a Recurrent Neural Network (CRF-RNN) layer on top. A novel loss function that combines pixel-wise cross-entropy loss and asymmetric similarity loss to solve the unbalanced imaging data problem is proposed. Training the proposed network with this loss function can achieve a considerably higher Dice score and better polyp segmentation prediction. In addition, we add the CRF-RNN layer to the proposed framework to improve the quality of semantic segmentation. Experimental results on popular benchmark datasets show that CRF-EfficientUNet achieves state-of-the-art accuracy compared to existing methods. The results of the experiments, which are performed on the CVC-ClinicDB dataset for training and testing, are 95.55% Dice and 92.23% IoU. While the experimental results on cross-dataset using Kvasir-SEG as the training set, CVC-ColonDB as the test set are 85.59% Dice and 76.19% IoU. These results indicate that the proposed method has high generalization capability and learning ability, and it can be a compelling choice for practical applications with considerable data variations. The source code is available at: https://hfbicf65f60ce88954b40s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/lethithuhong1302/CRF-EfficientUNet
C1 [Hong, Le Thi Thu; Thanh, Nguyen Chi] AMST, Inst Informat Technol, Hanoi 840000, Vietnam.
   [Long, Tran Quoc] Univ Engn & Technol, VNU, Fac Informat Technol, Hanoi 700000, Vietnam.
C3 Vietnam National University Hanoi
RP Thanh, NC (通讯作者)，AMST, Inst Informat Technol, Hanoi 840000, Vietnam.
EM thanhnc80@gmail.com
RI Nguyen, Chi Thanh/AAT-8488-2021
OI Nguyen, Chi Thanh/0000-0003-4335-7002
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   FY HMA, 2021, INT J IMAG SYST TECH, V31, P1741
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Hashemi SR, 2019, IEEE ACCESS, V7, P1721, DOI 10.1109/ACCESS.2018.2886371
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Krahenbuhl P., 2011, ADV NEURAL INFORM PR, V24, P109, DOI DOI 10.5555/2986459.2986472
   Lee H, 2022, PUBLIC MANAG REV, V24, P512, DOI 10.1080/14719037.2020.1846368
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liang, 2013, P INT MICCAI WORKSH, P53
   Mahmud T, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104119
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nguyen NQ, 2020, IEEE ACCESS, V8, P99495, DOI 10.1109/ACCESS.2020.2995630
   Nguyen NQ, 2019, IEEE ACCESS, V7, P33795, DOI 10.1109/ACCESS.2019.2904094
   Poudel S, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107445
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Rey JF, 2001, ENDOSCOPY, V33, P901
   Rittscher J., ARXIV190503209
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ross T., ARXIV200310299
   Safarov S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041441
   Sanchez-Peralta LF, 2020, INT J COMPUT ASS RAD, V15, P1975, DOI 10.1007/s11548-020-02262-4
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vazquez D., 2017, J HEALTHC ENG, P1
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yang C, 2021, IEEE J BIOMED HEALTH, V25, P3886, DOI 10.1109/JBHI.2021.3077271
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 41
TC 5
Z9 5
U1 4
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 156987
EP 157001
DI 10.1109/ACCESS.2021.3129480
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA XG0OU
UT WOS:000724461900001
OA gold
DA 2023-08-21
ER

PT J
AU Jha, D
   Ali, S
   Tomar, NK
   Johansen, HD
   Johansen, D
   Rittscher, J
   Riegler, MA
   Halvorsen, P
AF Jha, Debesh
   Ali, Sharib
   Tomar, Nikhil Kumar
   Johansen, Havard D.
   Johansen, Dag
   Rittscher, Jens
   Riegler, Michael A.
   Halvorsen, Pal
TI Real-Time Polyp Detection, Localization and Segmentation in Colonoscopy
   Using Deep Learning
SO IEEE ACCESS
LA English
DT Article
DE Colonoscopy; Image segmentation; Benchmark testing; Real-time systems;
   Cancer; Videos; Biomedical imaging; Medical image segmentation;
   ColonSegNet; colonoscopy; polyps; deep learning; detection;
   localisation; benchmarking; Kvasir-SEG
ID CONVOLUTIONAL NEURAL-NETWORKS; COLORECTAL POLYPS; VALIDATION; CANCER;
   RISK; CNN
AB Computer-aided detection, localisation, and segmentation methods can help improve colonoscopy procedures. Even though many methods have been built to tackle automatic detection and segmentation of polyps, benchmarking of state-of-the-art methods still remains an open problem. This is due to the increasing number of researched computer vision methods that can be applied to polyp datasets. Benchmarking of novel methods can provide a direction to the development of automated polyp detection and segmentation tasks. Furthermore, it ensures that the produced results in the community are reproducible and provide a fair comparison of developed methods. In this paper, we benchmark several recent state-of-the-art methods using Kvasir-SEG, an open-access dataset of colonoscopy images for polyp detection, localisation, and segmentation evaluating both method accuracy and speed. Whilst, most methods in literature have competitive performance over accuracy, we show that the proposed ColonSegNet achieved a better trade-off between an average precision of 0.8000 and mean IoU of 0.8100, and the fastest speed of 180 frames per second for the detection and localisation task. Likewise, the proposed ColonSegNet achieved a competitive dice coefficient of 0.8206 and the best average speed of 182.38 frames per second for the segmentation task. Our comprehensive comparison with various state-of-the-art methods reveals the importance of benchmarking the deep learning methods for automated real-time polyp identification and delineations that can potentially transform current clinical practices and minimise miss-detection rates.
C1 [Jha, Debesh; Tomar, Nikhil Kumar; Riegler, Michael A.; Halvorsen, Pal] SimulaMet, N-0167 Oslo, Norway.
   [Jha, Debesh; Ali, Sharib; Rittscher, Jens] Univ Oxford, Big Data Inst, Dept Engn Sci, Oxford OX3 7XF, England.
   [Johansen, Havard D.; Johansen, Dag] UiT Arctic Univ Norway, Dept Comp Sci, N-9037 Tromso, Norway.
   [Ali, Sharib; Rittscher, Jens] Oxford NIHR Biomed Res Ctr, Oxford OX4 2PGV, England.
   [Halvorsen, Pal] Oslo Metropolitan Univ, Dept Comp Sci, N-0167 Oslo, Norway.
C3 University of Oxford; UiT The Arctic University of Tromso; Oslo
   Metropolitan University (OsloMet)
RP Jha, D (通讯作者)，SimulaMet, N-0167 Oslo, Norway.; Jha, D; Ali, S (通讯作者)，Univ Oxford, Big Data Inst, Dept Engn Sci, Oxford OX3 7XF, England.; Ali, S (通讯作者)，Oxford NIHR Biomed Res Ctr, Oxford OX4 2PGV, England.
EM debesh@simula.no; sharib.ali@eng.ox.ac.uk
RI Riegler, Michael A/E-5443-2015; Ali, Sharib/U-3807-2019
OI Riegler, Michael A/0000-0002-3153-2064; Ali, Sharib/0000-0003-1313-3542;
   Johansen, Dag/0000-0001-7067-6477; Jha, Debesh/0000-0002-8078-6730;
   Dagenborg, Havard Johansen/0000-0002-1637-7262
FU Research Council of Norway [270053, 263248]; National Institute for
   Health Research (NIHR) Oxford BRC through the Wellcome Trust Core Award
   [203141/Z/16/Z]; National Institute for Health Research (NIHR) Oxford
   BRC; Wellcome Trust [203141/Z/16/Z]; NIHR Oxford Biomedical Research
   Centre
FX This work was supported in part by the Research Council of Norway under
   Contract 270053, and in part by the National Institute for Health
   Research (NIHR) Oxford BRC through the Wellcome Trust Core Award Grant
   203141/Z/16/Z. The work of Debesh Jha was supported by the Research
   Council of Norway project number 263248 (Privaton). The computations in
   this paper were performed on equipment provided by the Experimental
   Infrastructure for Exploration of Exascale Computing (eX3), which is
   financially supported by the Research Council of Norway under contract
   270053. Parts of computational resources were also used from the
   research supported by the National Institute for Health Research (NIHR)
   Oxford BRC with additional support from the Wellcome Trust Core Award
   Grant Number 203141/Z/16/Z. The work of Sharib Ali was supported by the
   NIHR Oxford Biomedical Research Centre. The views expressed are those of
   the author(s) and not necessarily those of the NHS, the NIHR or the
   Department of Health.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ali S, 2019, ARXIV PREPRINT ARXIV
   Ali S, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102002
   Ali S, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101900
   Ali S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59413-5
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Asplund J, 2018, ANN SURG ONCOL, V25, P2693, DOI 10.1245/s10434-018-6627-y
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baldeon-Calisto M, 2020, NEUROCOMPUTING, V392, P325, DOI 10.1016/j.neucom.2019.01.110
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED, DOI DOI 10.48550/ARXIV.2004.10934
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Castaneda D, 2018, GASTROINTEST ENDOSC, V88, P209, DOI 10.1016/j.gie.2018.03.022
   Chollet F, 2015, TECH REP
   Dai J., 2016, P ADV NEUR INF PROC, V29, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   de Lange T, 2018, WORLD J GASTROENTERO, V24, P5057, DOI 10.3748/wjg.v24.i45.5057
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   Holme O, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD009259.pub2
   Holzheimer R, 2001, SURG TREATMENT EVIDE
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jha Debesh, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P218, DOI 10.1007/978-3-030-67835-7_19
   Jha D, 2021, IEEE J BIOMED HEALTH, V25, P2029, DOI 10.1109/JBHI.2021.3049304
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kronborg O, 2007, DIGEST DIS, V25, P270, DOI 10.1159/000103899
   Lee J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61760-2
   Lee J, 2016, CLIN ENDOSC, V49, P355, DOI 10.5946/ce.2016.063
   Liang-Chieh Chen, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11211), P833, DOI 10.1007/978-3-030-01234-2_49
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Matyja M, 2019, ARCH MED SCI, V15, P424, DOI 10.5114/aoms.2018.74863
   Minaee S, 2020, ARXIV200105566
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P170, DOI 10.1145/3083187.3083216
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Riegler M., 2017, THESIS U OSLO OSLO
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy T., 2020, MED IMAGE ANAL, V70
   Saeedizadeh Narges, 2020, ArXiv
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Smedsrud PH, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00920-z
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI DOI 10.1109/CVPR42600.2020.01079
   Tan MX, 2019, PR MACH LEARN RES, V97
   TRANQUILLINI Caio Vinicius, 2018, Arq. Gastroenterol., V55, P358, DOI [10.1590/S0004-2803.201800000-79, 10.1590/s0004-2803.201800000-79]
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   WANG J, 2020, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2020.2983686.INTELL
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang R., 2020, ARXIV200500966
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Yamakawa M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44035-3
   Yanda Meng, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P352, DOI 10.1007/978-3-030-59719-1_35
   ZHANG Z, 2018, LECT NOTES COMPUT SC, V15, P749
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 73
TC 83
Z9 86
U1 6
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 40496
EP 40510
DI 10.1109/ACCESS.2021.3063716
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA RA1PN
UT WOS:000631190000001
PM 33747684
OA Green Published, Green Submitted, gold
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Lai, LL
   Blakely, A
   Invernizzi, M
   Lin, J
   Kidambi, T
   Melstrom, KA
   Yu, K
   Lu, T
AF Lai, Lily L.
   Blakely, Andrew
   Invernizzi, Marta
   Lin, James
   Kidambi, Trilokesh
   Melstrom, Kurt A.
   Yu, Kevin
   Lu, Thomas
TI Separation of color channels from conventional colonoscopy images
   improves deep neural network detection of polyps
SO JOURNAL OF BIOMEDICAL OPTICS
LA English
DT Article
DE artificial intelligence algorithms; deep learning; polyp discrimination;
   colorectal cancer; narrow-band imaging; color channel separation
ID COMPUTER-AIDED DIAGNOSIS; PREVENTION; CANCER
AB Significance: Colorectal cancer incidence has decreased largely due to detection and removal of polyps. Computer-aided diagnosis development may improve on polyp detection and discrimination.
   Aim: To advance detection and discrimination using currently available commercial colonoscopy systems, we developed a deep neural network (DNN) separating the color channels from images acquired under narrow-band imaging (NBI) and white-light endoscopy (WLE).
   Approach: Images of normal colon mucosa and polyps from colonoscopies were studied. Each color image was extracted based on the color channel: red/green/blue. A multilayer DNN was trained using one-channel, two-channel, and full-color images. The trained DNN was then tested for performance in detection of polyps.
   Results: The DNN performed better using full-colored NBI over WLE images in the detection of polyps. Furthermore, the DNN performed better using the two-channel red + green images when compared to full-color WLE images.
   Conclusions: The separation of color channels from full-color NBI and WLE images taken from commercially available colonoscopes may improve the ability of the DNN to detect and discriminate polyps. Further studies are needed to better determine the color channels and combination of channels to include and exclude in DNN development for clinical use. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.
C1 [Lai, Lily L.; Invernizzi, Marta; Melstrom, Kurt A.] City Hope Natl Med Ctr, Dept Surg, Duarte, CA 91010 USA.
   [Blakely, Andrew] NCI, Dept Surg, Natl Inst Hlth Campus, Bethesda, MD 20892 USA.
   [Lin, James; Kidambi, Trilokesh] City Hope Natl Med Ctr, Div Gastroenterol, Duarte, CA USA.
   [Yu, Kevin; Lu, Thomas] Jet Prop Lab, Pasadena, CA USA.
C3 City of Hope; National Institutes of Health (NIH) - USA; NIH National
   Cancer Institute (NCI); City of Hope; National Aeronautics & Space
   Administration (NASA); NASA Jet Propulsion Laboratory (JPL)
RP Lai, LL (通讯作者)，City Hope Natl Med Ctr, Dept Surg, Duarte, CA 91010 USA.
EM llai@coh.org
FU City of Hope National Medical Center; University of California at
   Riverside Research Initiative Fund
FX The research was supported in part by the City of Hope National Medical
   Center and the University of California at Riverside Research Initiative
   Fund.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Lu T, 2018, PROC SPIE, V10649, DOI 10.1117/12.2305134
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 16
TC 11
Z9 11
U1 0
U2 3
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1083-3668
EI 1560-2281
J9 J BIOMED OPT
JI J. Biomed. Opt.
PD JAN
PY 2021
VL 26
IS 1
AR 015001
DI 10.1117/1.JBO.26.1.015001
PG 9
WC Biochemical Research Methods; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Optics; Radiology, Nuclear Medicine &
   Medical Imaging
GA QF0UB
UT WOS:000616615000005
PM 33442965
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Lee, SA
   Cho, HC
   Cho, HC
AF Lee, Sin-Ae
   Cho, Hyun Chin
   Cho, Hyun-Chong
TI A Novel Approach for Increased Convolutional Neural Network Performance
   in Gastric-Cancer Classification Using Endoscopic Images
SO IEEE ACCESS
LA English
DT Article
DE Cancer; Lesions; Endoscopes; Image segmentation; Training; Image color
   analysis; Internet; Augmentation; computer-aided diagnosis (CADx); deep
   learning; gastric cancer; segmentation
ID AUGMENTATION; DIAGNOSIS
AB Gastric cancer is the third-most-common cause of cancer-related deaths in the world. Fortunately, it can be detected using endoscopy equipment. Computer-aided diagnosis (CADx) systems can help clinicians identify cancer from gastric diseases more accurately. In this paper, we present a CADx system that distinguishes and classifies gastric cancer from pre-cancerous conditions, such as gastric polyps, gastric ulcers, gastritis, and bleeding. The system uses a deep-learning model, Xception, which involves depth-wise separable convolutions, to classify cancer and non-cancers. The proposed method consists of two steps: Google's AutoAugment for augmentation and the simple linear iterative clustering (SLIC) superpixel and fast and robust fuzzy C-means (FRFCM) algorithm for image segmentation during preprocessing. These approaches produce a feasible method of distinguishing and classifying cancers from other gastric diseases. Based on biopsy-supported ground truth, the performance metrics of the area under the receiver operating characteristic curve (i.e. Az) are measured on the test sets. Based on the classification results, the Az of the proposed classification model is 0.96, which is 0.06 up from 0.90 which is the Az of the original data. Our methods are fully automated without the manual specification of region-of-interests for the test and with a random selection of images for model training. This methodology may play a crucial role in selecting effective treatment options without the need for a surgical biopsy.
C1 [Lee, Sin-Ae; Cho, Hyun-Chong] Kangwon Natl Univ, Interdisciplinary Grad Program BIT Med Convergenc, Chunchon 24341, South Korea.
   [Cho, Hyun Chin] Gyeongsang Natl Univ, Sch Med, Inst Hlth Sci, Dept Internal Med, Jinju 52727, South Korea.
   [Cho, Hyun Chin] Gyeongsang Natl Univ Hosp, Jinju 52727, South Korea.
   [Cho, Hyun-Chong] Kangwon Natl Univ, Dept Elect Engn, Chunchon 24341, South Korea.
C3 Kangwon National University; Gyeongsang National University; Gyeongsang
   National University; Gyeongsang National University Hospital; Kangwon
   National University
RP Cho, HC (通讯作者)，Kangwon Natl Univ, Interdisciplinary Grad Program BIT Med Convergenc, Chunchon 24341, South Korea.; Cho, HC (通讯作者)，Gyeongsang Natl Univ, Sch Med, Inst Hlth Sci, Dept Internal Med, Jinju 52727, South Korea.; Cho, HC (通讯作者)，Gyeongsang Natl Univ Hosp, Jinju 52727, South Korea.; Cho, HC (通讯作者)，Kangwon Natl Univ, Dept Elect Engn, Chunchon 24341, South Korea.
EM hccholuck@gmail.com; hyuncho@kangwon.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2017R1E1A1A03070297]; MSIT (Ministry of Science and ICT), Korea, under
   the ITRC (Information Technology Research Center) support program
   [IITP-2020-2018-0-01433]; National Research Foundation of Korea
   [2017R1E1A1A03070297] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2017R1E1A1A03070297). This research was supported by the MSIT (Ministry
   of Science and ICT), Korea, under the ITRC (Information Technology
   Research Center) support program (IITP-2020-2018-0-01433) supervised by
   the IITP (Institute for Information and communications Technology
   Promotion).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Asperti A, 2017, ARXIV171203689, P1
   Balakrishnan G, 2019, IEEE T MED IMAGING, V38, P1788, DOI 10.1109/TMI.2019.2897538
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   Choi Il Ju, 2018, Korean J Gastroenterol, V72, P245, DOI 10.4166/kjg.2018.72.5.245
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   DONGHYUN KIM, 2018, 전기학회논문지, V67, P928
   Ergashev Dilshod, 2019, [Journal of Korean Institute of Intelligent Systems, 한국지능시스템학회 논문지], V29, P204
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Honmyo U, 1997, ENDOSCOPY, V29, P366, DOI 10.1055/s-2007-1004217
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Khryashchev VV, 2019, ICGSP '19 - PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON GRAPHICS AND SIGNAL PROCESSING, P90, DOI 10.1145/3338472.3338492
   Kim DH, 2019, J ELECTR ENG TECHNOL, V14, P2549, DOI 10.1007/s42835-019-00259-x
   Ko KP, 2019, J KOREAN MED ASSOC, V62, P398, DOI 10.5124/jkma.2019.62.8.398
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee Sin-ae, 2020, 전기학회논문지, V69, P1033
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   MISUMI A, 1989, ENDOSCOPY, V21, P159
   Sahiner B, 2019, MED PHYS, V46, pe1, DOI 10.1002/mp.13264
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Zhao A, 2019, PROC CVPR IEEE, P8535, DOI 10.1109/CVPR.2019.00874
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 27
TC 7
Z9 7
U1 3
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 51847
EP 51854
DI 10.1109/ACCESS.2021.3069747
PG 8
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA RM7ZJ
UT WOS:000639876800001
OA gold
DA 2023-08-21
ER

PT J
AU Li, KD
   Fathan, MI
   Patel, K
   Zhang, TX
   Zhong, CC
   Bansal, A
   Rastogi, A
   Wang, JS
   Wang, GH
AF Li, Kaidong
   Fathan, Mohammad I.
   Patel, Krushi
   Zhang, Tianxiao
   Zhong, Cuncong
   Bansal, Ajay
   Rastogi, Amit
   Wang, Jean S.
   Wang, Guanghui
TI Colonoscopy polyp detection and classification: Dataset creation and
   comparative evaluations
SO PLOS ONE
LA English
DT Article
ID COLORECTAL-CANCER; CT COLONOGRAPHY; SEGMENTATION; NETWORKS; LESIONS
AB Colorectal cancer (CRC) is one of the most common types of cancer with a high mortality rate. Colonoscopy is the preferred procedure for CRC screening and has proven to be effective in reducing CRC mortality. Thus, a reliable computer-aided polyp detection and classification system can significantly increase the effectiveness of colonoscopy. In this paper, we create an endoscopic dataset collected from various sources and annotate the ground truth of polyp location and classification results with the help of experienced gastroenterologists. The dataset can serve as a benchmark platform to train and evaluate the machine learning models for polyp classification. We have also compared the performance of eight state-of-the-art deep learning-based object detection models. The results demonstrate that deep CNN models are promising in CRC screening. This work can serve as a baseline for future research in polyp detection and classification.
C1 [Li, Kaidong; Fathan, Mohammad I.; Patel, Krushi; Zhang, Tianxiao; Zhong, Cuncong] Univ Kansas, Dept Elect Engn & Comp Sci, Lawrence, KS 66045 USA.
   [Bansal, Ajay; Rastogi, Amit] Univ Kansas Med Ctr, Gastroenterol Hepatol & Motil, Kansas City, KS USA.
   [Wang, Jean S.] Washington Univ Sch Med, Dept Med, St Louis, MO USA.
   [Wang, Guanghui] Ryerson Univ, Dept Comp Sci, Toronto, ON, Canada.
C3 University of Kansas; University of Kansas; University of Kansas Medical
   Center; Washington University (WUSTL); Toronto Metropolitan University
RP Wang, GH (通讯作者)，Ryerson Univ, Dept Comp Sci, Toronto, ON, Canada.
EM wangcs@ryerson.ca
OI LI, KAIDONG/0000-0002-6589-4995; Zhang, Tianxiao/0000-0001-6171-3176
FU National Institute of Health (NIH) [1R03CA253212-01]
FX G.W. Grant no. 1R03CA253212-01 National Institute of Health (NIH)
   https://hfbicb89ad438b05a46e0s0qkw69uxxc656nn5fiac.eds.tju.edu.cn/.The funders had no role in study design, data
   collection and analysis, decision to publish, or preparation of the
   manuscript.
CR Adler DG, 2003, HOSP PHYS, P14
   American Cancer Society, 2015, CANC FACTS FIGURES 2
   [Anonymous], INT J COMPUT VISION, DOI DOI 10.1007/s11263-009-0275-4
   [Anonymous], 2018, IEEE CONF COMPUT
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED, DOI DOI 10.48550/ARXIV.2004.10934
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Cen F, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107737
   Chan MY, 2009, CLIN GASTROENTEROL H, V7, P1217, DOI 10.1016/j.cgh.2009.07.013
   Chang CC, 2009, INT J COLORECTAL DIS, V24, P1413, DOI 10.1007/s00384-009-0760-9
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Huo J, 2018, NEUROIMAGE, V175, P201, DOI 10.1016/j.neuroimage.2018.04.001
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li K, 2020, DEEP LEARNING COMPUT, V30, P41, DOI DOI 10.1201/9781351003827-2
   Lieberman DA, 2009, NEW ENGL J MED, V361, P1179, DOI 10.1056/NEJMcp0902176
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma WC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107149
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Mathew S, 2020, PROC CVPR IEEE, P4695, DOI [10.1109/cvpr42600.2020.00475, 10.1109/CVPR42600.2020.00475]
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Najafabadi M. M., 2015, J BIG DATA-GER, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Pappalardo Giovanna, 2020, 2020 IEEE 4th International Conference on Image Processing, Applications and Systems (IPAS), P58, DOI 10.1109/IPAS50080.2020.9334952
   Park S., 2015, POLYP DETECTION COLO
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/crv52889.2021.00032, 10.1109/CRV52889.2021.00032]
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Regula J, 2006, NEW ENGL J MED, V355, P1863, DOI 10.1056/NEJMoa054967
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rex DK, 1997, GASTROENTEROLOGY, V112, P17, DOI 10.1016/S0016-5085(97)70213-0
   Roth H.R., 2015, RECENT ADV COMPUTATI, P3, DOI [DOI 10.1007/978-3-319-14148-0_1, DOI 10.1007/978-3-319-14148-0]
   Roth HR, 2015, ARXIV PREPRINT ARXIV
   Sajid U, 2020, ARXIV PREPRINT ARXIV
   Simon K, 2016, CLIN INTERV AGING, V11, DOI 10.2147/CIA.S109285
   Smedsrud PH, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00920-z
   Stoop EM, 2012, LANCET ONCOL, V13, P55, DOI 10.1016/S1470-2045(11)70283-2
   Stracci F, 2014, FRONT PUBLIC HEALTH, V2, DOI 10.3389/fpubh.2014.00210
   Taha B, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P233, DOI 10.2316/P.2017.852-031
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Thanikachalam K, 2019, NUTRIENTS, V11, DOI 10.3390/nu11010164
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Van Gool L., 2021, ARXIV PREPRINT ARXIV
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wu Y, 2019, IEEE I CONF COMP VIS, P6301, DOI 10.1109/ICCV.2019.00639
   Xu WJ, 2020, NEURAL PROCESS LETT, V51, P993, DOI 10.1007/s11063-019-10124-7
   Xu WJ, 2019, IEEE T MULTIMEDIA, V21, P2387, DOI 10.1109/TMM.2019.2898777
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang SJ, 2020, I S MOD ANAL SIM COM, P1, DOI 10.1109/mascots50786.2020.9285955
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang Zewang, 2020, ARXIV PREPRINT ARXIV
   Zhang ZM, 2018, PROC CVPR IEEE, P3301, DOI 10.1109/CVPR.2018.00348
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
NR 78
TC 25
Z9 25
U1 1
U2 7
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PY 2021
VL 16
IS 8
AR e0255809
DI 10.1371/journal.pone.0255809
PG 26
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA UC4BY
UT WOS:000686474200001
PM 34403452
OA Green Published, Green Submitted, gold
DA 2023-08-21
ER

PT J
AU Mahmud, T
   Paul, B
   Fattah, SA
AF Mahmud, Tanvir
   Paul, Bishmoy
   Fattah, Shaikh Anowarul
TI PolypSegNet: A modified encoder-decoder architecture for automated polyp
   segmentation from colonoscopy images
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp segmentation; Colorectal cancer; Colonoscopy; Computer-aided
   diagnosis; Neural network
ID ADENOMA DETECTION; VALIDATION; DIAGNOSIS; NETWORK
AB Colorectal cancer has become one of the major causes of death throughout the world. Early detection of Polyp, an early symptom of colorectal cancer, can increase the survival rate to 90%. Segmentation of Polyp regions from colonoscopy images can facilitate the faster diagnosis. Due to varying sizes, shapes, and textures of polyps with subtle visible differences with the background, automated segmentation of polyps still poses a major challenge towards traditional diagnostic methods. Conventional Unet architecture and some of its variants have gained much popularity for its automated segmentation though having several architectural limitations that result in sub-optimal performance. In this paper, an encoder-decoder based modified deep neural network architecture is proposed, named as PolypSegNet, to overcome several limitations of traditional architectures for very precise automated segmentation of polyp regions from colonoscopy images. For achieving more generalized representation at each scale of both the encoder and decoder module, several sequential depth dilated inception (DDI) blocks are integrated into each unit layer for aggregating features from different receptive areas utilizing depthwise dilated convolutions. Different scales of contextual information from all encoder unit layers pass through the proposed deep fusion skip module (DFSM) to generate skip interconnection with each decoder layer rather than separately connecting different levels of encoder and decoder. For more efficient reconstruction in the decoder module, multi-scale decoded feature maps generated at various levels of the decoder are jointly optimized in the proposed deep reconstruction module (DRM) instead of only considering the decoded feature map from final decoder layer. Extensive experimentations on four publicly available databases provide very satisfactory performance with mean five-fold cross-validation dice scores of 91.52% in CVC-ClinicDB database, 92.8% in CVC-ColonDB database, 88.72% in Kvasir-SEG database, and 84.79% in ETIS-Larib database. The proposed network provides very accurate segmented polyp regions that will expedite the diagnosis of polyps even in challenging conditions.
C1 [Mahmud, Tanvir; Paul, Bishmoy; Fattah, Shaikh Anowarul] BUET, Dept EEE, ECE Bldg, Dhaka 1205, Bangladesh.
C3 Bangladesh University of Engineering & Technology (BUET)
RP Fattah, SA (通讯作者)，BUET, Dept EEE, ECE Bldg, Dhaka 1205, Bangladesh.
EM tanvirmahmud@eee.buet.ac.bd; paul.bish98@gmail.com;
   fattah@eee.buet.ac.bd
OI Mahmud, Tanvir/0000-0003-0529-2826
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   ALGHAMDI AM, 2020, IEEE T MED IMAGING, V39, DOI DOI 10.1007/S40314-020-01281-W
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Glez-Pena, 2020, NEUROCOMPUTING
   Guo YB, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P632, DOI 10.5220/0007698806320641
   Guo YB, 2020, J IMAGING, V6, DOI 10.3390/jimaging6070069
   Halvorsen, 2020, DOUBLEU NET DEEP CON
   Hashemi S.R., 2018, ABS1803 CORR, P11078
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Li, 2020, ARXIV2005, V2020
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lou GC, 2014, TURK J GASTROENTEROL, V25, P182, DOI 10.5152/tjg.2014.4664
   Mou L, 2020, IEEE T MED IMAGING, V39, P1392, DOI 10.1109/TMI.2019.2950051
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Qadir HA, 2019, IEEE ACCESS, V7, P169537, DOI 10.1109/ACCESS.2019.2954675
   Qadir HA, 2019, INT SYM MED INFORM, P181
   Rex DK, 2000, GASTROINTEST ENDOSC, V51, P33, DOI 10.1016/S0016-5107(00)70383-X
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rutter CM, 2012, CANCER CAUSE CONTROL, V23, P289, DOI 10.1007/s10552-011-9878-5
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van Wijk C, 2010, IEEE T MED IMAGING, V29, P688, DOI 10.1109/TMI.2009.2031323
   Wang LS, 2019, IEEE ACCESS, V7, P44676, DOI 10.1109/ACCESS.2019.2908386
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yao JH, 2004, IEEE T MED IMAGING, V23, P1344, DOI 10.1109/TMI.2004.826941
   Yao JH, 2007, MED PHYS, V34, P1655, DOI 10.1118/1.2717411
   Yu F., 2016, P 4 INT C LEARN REP, DOI 10.48550/arXiv.1511.07122Focustolearnmore
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Zhou ZL, 2021, IEEE T BIG DATA, V7, P559, DOI 10.1109/TBDATA.2019.2919570
NR 43
TC 32
Z9 34
U1 3
U2 23
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD JAN
PY 2021
VL 128
AR 104119
DI 10.1016/j.compbiomed.2020.104119
PG 13
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA PN6FH
UT WOS:000604572200002
PM 33254083
DA 2023-08-21
ER

PT J
AU Mori, Y
   Neumann, H
   Misawa, M
   Kudo, S
   Bretthauer, M
AF Mori, Yuichi
   Neumann, Helmut
   Misawa, Masashi
   Kudo, Shin-ei
   Bretthauer, Michael
TI Artificial intelligence in colonoscopy - Now on the market. What's next?
SO JOURNAL OF GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Article
DE Colorectal cancer; Colorectal polyps; Computer-aided diagnosis
ID COLORECTAL-CANCER; GUIDELINES; SOCIETY; SYSTEM
AB Adoption of artificial intelligence (AI) in clinical medicine is revolutionizing daily practice. In the field of colonoscopy, major endoscopy manufacturers have already launched their own AI products on the market with regulatory approval in Europe and Asia. This commercialization is strongly supported by positive evidence that has been recently established through rigorously designed prospective trials and randomized controlled trials. According to some of the trials, AI tools possibly increase the adenoma detection rate by roughly 50% and contribute to a 7-20% reduction of colonoscopy-related costs. Given that reliable evidence is emerging, together with active commercialization, this seems to be a good time for us to review and discuss the current status of AI in colonoscopy from a clinical perspective. In this review, we introduce the advantages and possible drawbacks of AI tools and explore their future potential including the possibility of obtaining reimbursement.
C1 [Mori, Yuichi; Bretthauer, Michael] Univ Oslo, Fac Med, Inst Hlth & Soc, Clin Effectiveness Res Grp, Bygg 20,Sognsvannsveien 21, N-0372 Oslo, Norway.
   [Mori, Yuichi; Misawa, Masashi; Kudo, Shin-ei] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Neumann, Helmut] Univ Med Ctr Mainz, Interdisciplinary Endoscopy Ctr, Mainz, Germany.
   [Bretthauer, Michael] Oslo Univ Hosp, Dept Transplantat Med, Oslo, Norway.
C3 University of Oslo; Showa University; Johannes Gutenberg University of
   Mainz; University of Oslo
RP Mori, Y (通讯作者)，Univ Oslo, Fac Med, Inst Hlth & Soc, Clin Effectiveness Res Grp, Bygg 20,Sognsvannsveien 21, N-0372 Oslo, Norway.; Mori, Y (通讯作者)，Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Tsuzuki Ku, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
EM yuichi.mori@medisin.uio.no
RI Mori, Yuichi/AAU-5406-2020; Misawa, Masashi/H-9004-2019
OI Misawa, Masashi/0000-0002-8520-2036; Kudo, Shin-ei/0000-0002-4268-1217;
   Mori, Yuichi/0000-0003-2262-0334
CR Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   East JE., 2020, GASTROINTEST ENDOSC
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C., 2019, GUT
   Hassan C., 2020, GASTROINTEST ENDOSC
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Liu W., 2020, SAUDI J GASTROENTERO
   Liu XX, 2020, NAT MED, V26, P1364, DOI 10.1038/s41591-020-1034-x
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Misawa M., 2020, GASTROINTEST ENDOSC
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Repici A, 2020, GASTROENTEROLOGY
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Topol EJ, 2020, NAT MED, V26, P1318, DOI 10.1038/s41591-020-1042-x
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Vinsard DG., 2020, ENDOSCOPY
   Wadhwa V., 2020, ENDOSC INT OPEN
   Wang P., 2020, LANCET GASTROENTEROL
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 26
TC 37
Z9 37
U1 0
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0815-9319
EI 1440-1746
J9 J GASTROEN HEPATOL
JI J. Gastroenterol. Hepatol.
PD JAN
PY 2021
VL 36
IS 1
SI SI
BP 7
EP 11
DI 10.1111/jgh.15339
PG 5
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA PS1KE
UT WOS:000607688400002
PM 33179322
DA 2023-08-21
ER

PT J
AU Phillips, F
   Beg, S
AF Phillips, Frank
   Beg, Sabina
TI Video capsule endoscopy: pushing the boundaries with software technology
SO TRANSLATIONAL GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Review
DE Video capsule endoscopy (VCE); deep learning (DL); artificial
   intelligence (AI); software enhancement
ID DEVICE-ASSISTED ENTEROSCOPY; DISORDERS EUROPEAN-SOCIETY; IMAGING COLOR
   ENHANCEMENT; GASTROINTESTINAL ENDOSCOPY; ARTIFICIAL-INTELLIGENCE;
   READING TIME; BLUE MODE; CELIAC-DISEASE; PERFORMANCE; MULTICENTER
AB Video capsule endoscopy (VCE) has transformed imaging of the small bowel as it is a non-invasive and well tolerated modality with excellent diagnostic capabilities. The way we read VCE has not changed much since its introduction nearly two decades ago. Reading is still very time intensive and prone to reader error. This review outlines the evidence regarding software enhancements which aim to address these challenges. These include the suspected blood indicator (SBI), automated fast viewing modes including QuickView, lesion characterization tools such Fuji Intelligent Color Enhancement, and three-dimensional (3D) representation tools. We also outline the exciting new evidence of artificial intelligence (AI) and deep learning (DL), which promises to revolutionize capsule reading. DL algorithms have been developed for identifying organs of origin, intestinal motility events, active bleeding, coeliac disease, polyp detection, hookworms and angioectasias, all with impressively high sensitivity and accuracy. More recently, an algorithm has been created to detect multiple abnormalities with a sensitivity of 99.9% and reading time of only 5.9 minutes. These algorithms will need to be validated robustly. However, it will not be long before we see this in clinical practice, aiding the clinician in rapid and accurate diagnosis.
C1 [Phillips, Frank; Beg, Sabina] Nottingham Univ Hosp NHS Trust, NIHR Nottingham Digest Dis Biomed Res Ctr, Dept Gastroenterol, Queens Med Ctr Campus, Nottingham, England.
C3 Nottingham University Hospital NHS Trust
RP Phillips, F (通讯作者)，Nottingham Univ Hosp NHS Trust, NIHR Nottingham Digest Dis Biomed Res Ctr, Dept Gastroenterol, Queens Med Ctr Campus, Nottingham, England.
EM frankmphillips@hotmail.com
CR Abdelaal UM, 2015, SAUDI J GASTROENTERO, V21, P418, DOI 10.4103/1319-3767.170954
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Beg S, 2018, FRONTLINE GASTROENTE, V9, P300, DOI 10.1136/flgastro-2017-100878
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Ding Z, 2019, GASTROENTEROL
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hosoe N, 2016, ENDOSC INT OPEN, V4, pE878, DOI 10.1055/s-0042-111389
   Hosoe N, 2012, CLIN RES HEPATOL GAS, V36, P66, DOI 10.1016/j.clinre.2011.09.009
   Hwang Y, 2018, CLIN ENDOSC, V51, P547, DOI 10.5946/ce.2018.173
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jang BI, 2010, SCAND J GASTROENTERO, V45, P370, DOI 10.3109/00365520903521574
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karargyris A, 2013, WORLD J GASTROENTERO, V19, P8028, DOI 10.3748/wjg.v19.i44.8028
   Koulaouzidis A, 2013, DIGEST LIVER DIS, V45, P909, DOI 10.1016/j.dld.2013.05.013
   Koulaouzidis A, 2013, WORLD J GASTROENTERO, V19, P3726, DOI 10.3748/wjg.v19.i24.3726
   Koulaouzidis A, 2012, J DIGEST DIS, V13, P621, DOI 10.1111/j.1751-2980.2012.00638.x
   Koulaouzidis A, 2012, EUR J GASTROEN HEPAT, V24, P1099, DOI 10.1097/MEG.0b013e32835563ab
   Koulaouzidis A, 2012, WORLD J GASTRO ENDOS, V4, P33, DOI 10.4253/wjge.v4.i2.33
   Kyriakos N, 2012, EUR J GASTROEN HEPAT, V24, P1276, DOI 10.1097/MEG.0b013e32835718d2
   Lai LH, 2006, EUR J GASTROEN HEPAT, V18, P283, DOI 10.1097/00042737-200603000-00009
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Nakamura M, 2015, DIGEST DIS SCI, V60, P1743, DOI 10.1007/s10620-014-3496-5
   Osawa H, 2014, DIGEST ENDOSC, V26, P105, DOI 10.1111/den.12205
   Pennazio M, 2015, ENDOSCOPY, V47, P352, DOI 10.1055/s-0034-1391855
   Petroniene R, 2005, AM J GASTROENTEROL, V100, P685, DOI 10.1111/j.1572-0241.2005.41069.x
   Rondonotti E, 2018, ENDOSCOPY, V50, P423, DOI 10.1055/a-0576-0566
   Saurin JC, 2012, DIGEST LIVER DIS, V44, P477, DOI 10.1016/j.dld.2011.12.021
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Subramanian V, 2012, DIGEST DIS SCI, V57, P1624, DOI 10.1007/s10620-012-2074-y
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Westerhof J, 2009, GASTROINTEST ENDOSC, V69, P497, DOI 10.1016/j.gie.2008.05.070
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yung DE, 2017, ENDOSCOPY, V49, P258, DOI 10.1055/s-0042-122015
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P43, DOI 10.1080/17474124.2017.1257384
   Zheng YP, 2012, AM J GASTROENTEROL, V107, P554, DOI 10.1038/ajg.2011.461
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 42
TC 3
Z9 3
U1 0
U2 7
PU AME PUBL CO
PI SHATIN
PA FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG
   00000, PEOPLES R CHINA
EI 2415-1289
J9 TRANSL GASTROENT HEP
JI Transl. Gastroenterol. Hepatol.
PD JAN
PY 2021
VL 6
AR 17
DI 10.21037/tgh.2020.02.01
PG 7
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA OX1WE
UT WOS:000593363000017
PM 33409411
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Ramakrishnan, VR
   Arbet, J
   Mace, JC
   Suresh, K
   Smith, SS
   Soler, ZM
   Smith, TL
AF Ramakrishnan, Vijay R.
   Arbet, Jaron
   Mace, Jess C.
   Suresh, Krithika
   Shintani Smith, Stephanie
   Soler, Zachary M.
   Smith, Timothy L.
TI Predicting olfactory loss in chronic rhinosinusitis using machine
   learning
SO CHEMICAL SENSES
LA English
DT Article
DE sinusitis; smell; olfaction; chronic disease; outcome assessment (health
   care); artificial intelligence; AI; ML; predictive analytics
ID QUALITY-OF-LIFE; CLASSIFICATION; DYSFUNCTION; VALIDATION; INFERENCE;
   OUTCOMES; THERAPY; ALLERGY; MODELS
AB Objective Compare machine learning (ML)-based predictive analytics methods to traditional logistic regression in classification of olfactory dysfunction in chronic rhinosinusitis (CRS-OD) and identify predictors within a large multi-institutional cohort of refractory CRS patients. Methods Adult CRS patients enrolled in a prospective, multi-institutional, observational cohort study were assessed for baseline CRS-OD using a smell identification test (SIT) or brief SIT (bSIT). Four different ML methods were compared to traditional logistic regression for classification of CRS normosmics versus CRS-OD. Results Data were collected for 611 study participants who met inclusion criteria between 2011 April and 2015 July. Thirty-four percent of enrolled patients demonstrated olfactory loss on psychophysical testing. Differences between CRS normosmics and those with smell loss included objective disease measures (CT and endoscopy scores), age, sex, prior surgeries, socioeconomic status, steroid use, polyp presence, asthma, and aspirin sensitivity. Most ML methods performed favorably in terms of predictive ability. Top predictors include factors previously reported in the literature, as well as several socioeconomic factors. Conclusion Olfactory dysfunction is a variable phenomenon in CRS patients. ML methods perform well compared to traditional logistic regression in classification of normosmia versus smell loss in CRS, and are able to include numerous risk factors into prediction models. Several actionable features were identified as risk factors for CRS-OD. These results suggest that ML methods may be useful for current understanding and future study of hyposmia secondary to sinonasal disease, the most common cause of persistent olfactory loss in the general population.
C1 [Ramakrishnan, Vijay R.] Univ Colorado, Dept Otolaryngol Head & Neck Surg, 12631 E 17th Ave,B205, Aurora, CO 80045 USA.
   [Arbet, Jaron; Suresh, Krithika] Univ Colorado, Colorado Sch Publ Hlth, Dept Biostat & Informat, Denver Anschutz Med Campus, Aurora, CO USA.
   [Mace, Jess C.; Smith, Timothy L.] Oregon Hlth & Sci Univ, Dept Otolaryngol Head & Neck Surg, Portland, OR USA.
   [Shintani Smith, Stephanie] Northwestern Univ, Dept Otolaryngol Head & Neck Surg, Chicago, IL 60611 USA.
   [Soler, Zachary M.] Med Univ South Carolina, Dept Otolaryngol Head & Neck Surg, Charleston, SC 29425 USA.
C3 University of Colorado System; University of Colorado Anschutz Medical
   Campus; Colorado School of Public Health; University of Colorado System;
   University of Colorado Anschutz Medical Campus; Oregon Health & Science
   University; Northwestern University; Medical University of South
   Carolina
RP Ramakrishnan, VR (通讯作者)，Univ Colorado, Dept Otolaryngol Head & Neck Surg, 12631 E 17th Ave,B205, Aurora, CO 80045 USA.
EM Vijay.Ramakrishnan@ucdenver.edu
OI Ramakrishnan, Vijay/0000-0003-2748-0705
FU Ludeman Family Center for Women's Health Research at the University of
   Colorado Anschutz Medical Campus; National Institute on Deafness and
   Other Communication Disorders (NIDCD) of the National Institutes of
   Health, Bethesda, MD [R01 DC005805, K23 DC014747, 1P01AI145818-01];
   National Institute of Allergy and Infectious Diseases (NIAID) of the
   National Institutes of Health, Bethesda, MD [R01 DC005805, K23 DC014747,
   1P01AI145818-01]
FX This study was supported in part by a grant from the Ludeman Family
   Center for Women's Health Research at the University of Colorado
   Anschutz Medical Campus (V.R.R.). V.R.R., J.C.M., Z.M.S., T.L.S., and
   S.S.S. are supported by grants for this investigation from the National
   Institute on Deafness and Other Communication Disorders (NIDCD) and the
   National Institute of Allergy and Infectious Diseases (NIAID) of the
   National Institutes of Health, Bethesda, MD [R01 DC005805 (T.L.S. and
   Z.M.S.), K23 DC014747 (V.R.R.), 1P01AI145818-01 (S.S.S.)]. Public
   clinical trial registration (www.clinicaltrials.gov) ID#NCT01332136.
   Contents are the authors' sole responsibility and do not necessarily
   represent official NIH views.
CR Agency for Healthcare Research and Quality, 2018, NATL HEALTHCARE QUAL
   Akdis CA, 2013, J ALLERGY CLIN IMMUN, V131, P1479, DOI 10.1016/j.jaci.2013.02.036
   [Anonymous], 1995, SMELL IDENTIFICATION
   [Anonymous], 1994, MACHINE LEARNING NEU
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Boulesteix AL, 2012, WIRES DATA MIN KNOWL, V2, P493, DOI 10.1002/widm.1072
   Bzdok D, 2018, NAT METHODS, V15, P232, DOI 10.1038/nmeth.4642
   Cristianini N., 2000, SUPPORT VECTOR MACHI, DOI DOI 10.1017/CBO9780511801389.013
   Cutillo CM, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0254-2
   DeConde AS, 2015, INT FORUM ALLERGY RH, V5, P233, DOI 10.1002/alr.21458
   DeConde AS, 2014, INT FORUM ALLERGY RH, V4, P725, DOI 10.1002/alr.21350
   Doty RL., 2001, BRIEF SMELL IDENTIFI
   El Rassi E, 2016, INT FORUM ALLERGY RH, V6, P287, DOI 10.1002/alr.21670
   Fernandez-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Fokkens WJ, 2012, RHINOLOGY, V50, P1, DOI 10.4193/Rhin20.600
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963
   Gitomer SA, 2016, OTOLARYNG HEAD NECK, V155, P173, DOI 10.1177/0194599816637856
   Hastie T., 2009, WRONG RIGHT WAY CROS, P245
   Hastie T., 2013, ELEMENTS STAT LEARNI
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Hopkins C, 2009, CLIN OTOLARYNGOL, V34, P447, DOI 10.1111/j.1749-4486.2009.01995.x
   Hopkins C, 2018, RHINOLOGY, V56, P22, DOI 10.4193/Rhin17.247
   Hothorn T, 2006, J COMPUT GRAPH STAT, V15, P651, DOI 10.1198/106186006X133933
   Hummel T, 2017, RHINOLOGY, V54, P7, DOI 10.4193/Rhino16.248
   Katotomichelakis M, 2014, EUR ARCH OTO-RHINO-L, V271, P733, DOI 10.1007/s00405-013-2626-6
   Kim JH, 2009, COMPUT STAT DATA AN, V53, P3735, DOI 10.1016/j.csda.2009.04.009
   Kohli P, 2017, LARYNGOSCOPE, V127, P309, DOI 10.1002/lary.26316
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Litvack JR, 2008, LARYNGOSCOPE, V118, P2225, DOI 10.1097/MLG.0b013e318184e216
   Lotsch J, 2019, CHEM SENSES, V44, P11, DOI 10.1093/chemse/bjy067
   Lund Valerie J., 1993, Rhinology (Utrecht), V31, P183
   LUND VJ, 1995, ANN OTO RHINOL LARYN, V104, P17, DOI 10.1177/000348949510410s02
   Molnar C., 2018, JOSS, V3, P786, DOI DOI 10.21105/JOSS.00786
   Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366
   Orlandi RR, 2016, INT FORUM ALLERGY RH, V6, pS22, DOI 10.1002/alr.21695
   Piccirillo JF, 2002, OTOLARYNG HEAD NECK, V126, P41, DOI 10.1067/mhn.2002.121022
   Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259
   Ramakrishnan VR, 2017, INT FORUM ALLERGY RH, V7, P343, DOI 10.1002/alr.21903
   Rombaux P, 2016, CURR ALLERGY ASTHM R, V16, DOI 10.1007/s11882-016-0617-6
   Rosenfeld RM, 2015, OTOLARYNG HEAD NECK, V152, pS1, DOI 10.1177/0194599815572097
   Schlosser RJ, 2020, INT FORUM ALLERGY RH, V10, P7, DOI 10.1002/alr.22445
   Senior BA, 2001, AM J RHINOL, V15, P15, DOI 10.2500/105065801781329428
   Settipane GA, 1996, ALLERGY ASTHMA PROC, V17, P269, DOI 10.2500/108854196778662237
   Simopoulos E, 2012, LARYNGOSCOPE, V122, P1450, DOI 10.1002/lary.23349
   Smith TL, 2013, INT FORUM ALLERGY RH, V3, P4, DOI 10.1002/alr.21065
   Soler ZM, 2016, CHEM SENSES, V41, P713, DOI 10.1093/chemse/bjw080
   Soler ZM, 2016, INT FORUM ALLERGY RH, V6, P407, DOI 10.1002/alr.21679
   Soler ZM, 2012, AM J RHINOL ALLERGY, V26, P110, DOI 10.2500/ajra.2012.26.3741
   Stekhoven DJ, 2012, BIOINFORMATICS, V28, P112, DOI 10.1093/bioinformatics/btr597
   Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25
   Strobl C, 2009, PSYCHOL METHODS, V14, P323, DOI 10.1037/a0016973
   Team RC, 2013, R LANG ENV STAT COMP, DOI DOI 10.1007/978-3-540-74686-7
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
NR 54
TC 3
Z9 3
U1 1
U2 1
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0379-864X
EI 1464-3553
J9 CHEM SENSES
JI Chem. Senses
PD JAN 1
PY 2021
VL 46
AR bjab042
DI 10.1093/chemse/bjab042
PG 9
WC Behavioral Sciences; Food Science & Technology; Neurosciences;
   Physiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Behavioral Sciences; Food Science & Technology; Neurosciences &
   Neurology; Physiology
GA ZR4XE
UT WOS:000767787000010
PM 34473227
OA Green Submitted, Bronze, Green Published
DA 2023-08-21
ER

PT J
AU Sasmal, P
   Bhuyan, MK
   Iwahori, Y
   Kasugai, K
AF Sasmal, Pradipta
   Bhuyan, M. K.
   Iwahori, Yuji
   Kasugai, Kunio
TI Colonoscopic Polyp Classification Using Local Shape and Texture Features
SO IEEE ACCESS
LA English
DT Article
DE Histograms; Shape; Feature extraction; Lighting; Fractals; Support
   vector machines; Image edge detection; Fractal weighted local binary
   pattern (FWLBP); fuzzy entropy; polyp; pyramid histogram of oriented
   gradient (PHOG); RUSBoosted tree; SVM
ID FEATURE-EXTRACTION; IMAGE; TRANSFORM
AB In this paper, a method is proposed for colonic polyp classification which can perform a virtual biopsy for assessing the stage of malignancy in polyps. Geometry, texture, and colour of a polyp give sufficient cue of its nature. The proposed framework characterizes geometry or shape of a polyp by pyramid histogram of oriented gradient (PHOG) features. To encapsulate the texture of the polyp surface, a fractal weighted local binary pattern (FWLBP) descriptor is employed, which is robust to affine transformation. It is also partially robust to illumination variations which is generally encountered during endoscopy. The optimal feature fusion is done using a feature ranking algorithm based on fuzzy entropy. Finally, to evaluate the classification performance of the proposed model, kernel-based support vector machines (SVM) and RUSBoosted tree are used. Experimental results carried on two databases clearly indicate that the proposed method can be used in the colonoscopic polyps classification. The proposed method can give polyp classification accuracies of 90.12% and 84.1%, and AUC of 0.91 and 0.92 for publicly available database and our own database, respectively.
C1 [Sasmal, Pradipta; Bhuyan, M. K.] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
   [Iwahori, Yuji] Chubu Univ, Dept Comp Sci, Kasugai, Aichi 4878501, Japan.
   [Kasugai, Kunio] Aichi Med Univ, Dept Gastroenterol, Nagakute, Aichi 4801195, Japan.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Chubu University; Aichi Medical University
RP Sasmal, P; Bhuyan, MK (通讯作者)，Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM s.pradipta@iitg.ac.in; mkb@iitg.ac.in
RI Iwahori, Yuji/AAH-4257-2020
OI Iwahori, Yuji/0000-0002-6421-8186
FU Japan Society for the Promotion of Science (JSPS) [20K11873]; Chubu
   University; Grants-in-Aid for Scientific Research [20K11873] Funding
   Source: KAKEN
FX The work of Yuji Iwahori was supported in part by the Japan Society for
   the Promotion of Science (JSPS) Grant-in-Aid Scienti~c Research (C)
   under Grant 20K11873, and in part by the Chubu University Grant.
CR Al-Kadi OS, 2008, IEEE T BIO-MED ENG, V55, P1822, DOI 10.1109/TBME.2008.919735
   Aman Javed M., 2010, Virtual Colonoscopy and Abdominal Imaging. Computational Challenges and Clinical Opportunities. Second International Workshop Held in Conjunction with MICCAI 2010. Revised Selected Papers, P15, DOI 10.1007/978-3-642-25719-3_3
   [Anonymous], 2016, INT WORKSH COMP ASS
   [Anonymous], 2001, LEARNING KERNELS
   [Anonymous], 1983, FRACTAL GEOMETRY NAT
   [Anonymous], P SPIE MED IMAGING 2
   Armi L., 2019, ABS190406554 CORR
   Armi L, 2019, MULTIMED TOOLS APPL, V78, P18995, DOI 10.1007/s11042-019-7207-2
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Bharati MH, 2004, CHEMOMETR INTELL LAB, V72, P57, DOI 10.1016/j.chemolab.2004.02.005
   Condessa F. J., 2011, DETECTION CLASSIFICA
   Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Engelhardt S., 2010, BILDVERARBEITUNG MED, V574, P350
   Falconer K, 2004, FRACTAL GEOMETRY MAT
   Fekri-Ershad S, 2019, MULTIMED TOOLS APPL, V78, P31121, DOI 10.1007/s11042-019-07937-y
   Fonolla R, 2019, I S BIOMED IMAGING, P74, DOI 10.1109/ISBI.2019.8759320
   Fu JJC, 2014, COMPUT MED IMAG GRAP, V38, P267, DOI 10.1016/j.compmedimag.2013.12.009
   Golhar M, 2021, IEEE ACCESS, V9, P631, DOI [10.1109/ACCESS.2020.3047544, 10.1109/access.2020.3047544]
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Khushaba RN, 2011, IEEE T BIO-MED ENG, V58, P121, DOI 10.1109/TBME.2010.2077291
   Lazebnik S., 2006, 2006 IEEE COMP SOC C, V2, P2169
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Messmann, 2006, ATLAS COLONOSCOPY TE
   Miranda E, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND TECHNOLOGY (ICIMTECH), P56, DOI 10.1109/ICIMTech.2016.7930302
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   Ramamoorthy S, 2015, ADV INTELL SYST, V324, P747, DOI 10.1007/978-81-322-2126-5_80
   Riaz F, 2011, LECT NOTES COMPUT SC, V6669, P709
   Roy S. K., 2018, ARXIV180103228
   SARKAR N, 1994, IEEE T SYST MAN CYB, V24, P115, DOI 10.1109/21.259692
   Sasmal P, 2020, PROCEEDINGS OF 2020 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON 2020), P247, DOI [10.1109/ASPCON49795.2020.9276732, 10.1109/aspcon49795.2020.9276732]
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Siegel RL., 2020, CA-CANCER J CLIN, V70, P145, DOI [DOI 10.3322/caac.21590, 10.3322/caac.21601]
   Song TC, 2021, IEEE T CIRC SYST VID, V31, P189, DOI 10.1109/TCSVT.2020.2972155
   Song TC, 2018, IEEE T CIRC SYST VID, V28, P1565, DOI 10.1109/TCSVT.2017.2671899
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
NR 41
TC 5
Z9 5
U1 2
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 92629
EP 92639
DI 10.1109/ACCESS.2021.3092263
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA TK1JF
UT WOS:000673923000001
OA gold
DA 2023-08-21
ER

PT J
AU Sasmal, P
   Paul, A
   Bhuyan, MK
   Iwahori, Y
   Kasugai, K
AF Sasmal, Pradipta
   Paul, Avinash
   Bhuyan, M. K.
   Iwahori, Yuji
   Kasugai, Kunio
TI Extraction of Key-Frames From Endoscopic Videos by Using Depth
   Information
SO IEEE ACCESS
LA English
DT Article
DE Estimation; Three-dimensional displays; Endoscopes; Sensors; Cameras;
   Image edge detection; Colonoscopy; Key-frames; colorectal cancer (CRC);
   monocular depth; polyps; 3D reconstruction
ID CLASSIFICATION; MANAGEMENT; POLYPS
AB Early detection of colorectal cancer (CRC) can reduce the risk of death. Polyps are the precursor to such cancer. Analyzing the polyps from the most significant frames out of thousands of endoscopy frames is vital for diagnosing and understanding disease. In this article, a deep learning-based monocular depth estimation (MDE) technique is proposed to select the most informative frames (key-frames) of an endoscopic video. In most cases, ground truth depth maps of polyps are not readily available, and that is why the transfer learning approach is adopted in our method. An endoscopic modality generally captures thousands of frames. In this scenario, it is quite essential to discard low-quality and clinically irrelevant frames of an endoscopic video while the most informative frames should be retained for clinical diagnosis. In this view, a key-frame selection strategy is proposed by utilizing the depth information of polyps. In our method, image moment, edge magnitude, and key points are considered for adaptively selecting the key-frames. One important application of our proposed method could be the 3D reconstruction of polyps with the help of extracted key-frames. It gives a surgeon a real-time 3D view of the polyp surface for resection which involves detaching the polyp from its mucosa layer. Also, polyps are localized with the help of extracted depth maps.
C1 [Sasmal, Pradipta; Paul, Avinash; Bhuyan, M. K.; Iwahori, Yuji] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
   [Iwahori, Yuji] Chubu Univ, Dept Comp Sci, Kasugai, Aichi 4878501, Japan.
   [Kasugai, Kunio] Aichi Med Univ, Dept Gastroenterol, Nagakute, Aichi 4801195, Japan.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Chubu University; Aichi Medical University
RP Sasmal, P; Bhuyan, MK (通讯作者)，Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM s.pradipta@iitg.ac.in; mkb@iitg.ac.in
RI Iwahori, Yuji/AAH-4257-2020
OI Iwahori, Yuji/0000-0002-6421-8186; Paul, Avinash/0000-0003-3564-8950
FU Japan Society for the Promotion of Science (JSPS) [20K11873]; Chubu
   University Grant; Grants-in-Aid for Scientific Research [20K11873]
   Funding Source: KAKEN
FX The work of Yuji Iwahori was supported in part by the Japan Society for
   the Promotion of Science (JSPS) Grant-in-Aid Scientific Research (C)
   under Grant 20K11873, and in part by the Chubu University Grant.
CR Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Baopu Li, 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P454, DOI 10.1109/ROBIO.2010.5723369
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Eigen D, 2014, ADV NEUR IN, V27
   Ejaz N, 2013, MICROSC RES TECHNIQ, V76, P559, DOI 10.1002/jemt.22205
   Engel S, 1997, NATURE, V388, P68, DOI 10.1038/40398
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Jha D, 2021, IEEE ACCESS, V9, P40496, DOI 10.1109/ACCESS.2021.3063716
   Law R, 2016, GASTROINTEST ENDOSC, V83, P1248, DOI 10.1016/j.gie.2015.11.014
   Lee HG, 2013, COMPUT BIOL MED, V43, P670, DOI 10.1016/j.compbiomed.2013.02.009
   Li BP, 2012, J MED SYST, V36, P2463, DOI 10.1007/s10916-011-9713-2
   Ma MY, 2019, IEEE ACCESS, V7, P11763, DOI 10.1109/ACCESS.2019.2891834
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mendi E, 2013, TELEMED E-HEALTH, V19, P36, DOI 10.1089/tmj.2011.0239
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Messmann, 2006, ATLAS COLONOSCOPY TE
   Ranftl, 2019, ARXIV190701341
   Sasmal P, 2021, IEEE ACCESS, V9, P92629, DOI 10.1109/ACCESS.2021.3092263
   Saxena A, 2007, IEEE I CONF COMP VIS, P1
   Seitz L, 2005, GASTROINTEST ENDOSC, V61, pAB264
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI [10.3322/caac.21220, 10.3322/caac.21208, 10.3322/caac.21395]
   Tjoa MP, 2002, IEEE CCEC 2002: CANADIAN CONFERENCE ON ELECTRCIAL AND COMPUTER ENGINEERING, VOLS 1-3, CONFERENCE PROCEEDINGS, P1177, DOI 10.1109/CCECE.2002.1013115
   Wang S, 2016, ARTIF INTELL MED, V66, P1, DOI 10.1016/j.artmed.2015.08.006
   Xian K, 2018, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2018.00040
   Xu D, 2019, IEEE T PATTERN ANAL, V41, P1426, DOI 10.1109/TPAMI.2018.2839602
   Yamakawa M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44035-3
NR 34
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 153004
EP 153011
DI 10.1109/ACCESS.2021.3126835
PG 8
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA XA2VK
UT WOS:000720511100001
OA Green Submitted, gold
DA 2023-08-21
ER

PT J
AU Sierra-Sosa, D
   Patino-Barrientos, S
   Garcia-Zapirain, B
   Castillo-Olea, C
   Elmaghraby, A
AF Sierra-Sosa, Daniel
   Patino-Barrientos, Sebastian
   Garcia-Zapirain, Begonya
   Castillo-Olea, Cristian
   Elmaghraby, Adel
TI Exploiting Deep Learning Techniques for Colon Polyp Segmentation
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Colon polyps; deep learning; image segmentation
AB As colon cancer is among the top causes of death, there is a growing interest in developing improved techniques for the early detection of colon polyps. Given the close relation between colon polyps and colon cancer, their detection helps avoid cancer cases. The increment in the availability of colorectal screening tests and the number of colonoscopies have increased the burden on the medical personnel. In this article, the application of deep learning techniques for the detection and segmentation of colon polyps in colonoscopies is presented. Four techniques were implemented and evaluated: Mask-RCNN, PANet, Cascade R-CNN and Hybrid Task Cascade (HTC). These were trained and tested using CVC-Colon database, ETIS-LARIB Polyp, and a proprietary dataset. Three experiments were conducted to assess the techniques performance: 1) Training and testing using each database independently, 2) Mergingd the databases and testing on each database independently using a merged test set, and 3) Training on each dataset and testing on the merged test set. In our experiments, PANet architecture has the best performance in Polyp detection, and HTC was the most accurate to segment them. This approach allows us to employ Deep Learning techniques to assist healthcare professionals in the medical diagnosis for colon cancer. It is anticipated that this approach can be part of a framework for a semi-automated polyp detection in colonoscopies.
C1 [Sierra-Sosa, Daniel; Elmaghraby, Adel] Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA.
   [Patino-Barrientos, Sebastian] Univ EAFIT, Ctr Comp Cient Apolo, Medellin, Colombia.
   [Garcia-Zapirain, Begonya; Castillo-Olea, Cristian] Univ Deusto, eVida Res Grp, Bilbao, Spain.
C3 University of Louisville; Universidad EAFIT; University of Deusto
RP Sierra-Sosa, D (通讯作者)，Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA.
EM desier01@louisville.edu
RI Zapirain, Begoña Garcia/L-5619-2014; Elmaghraby, Adel S/B-3353-2014
OI Zapirain, Begoña Garcia/0000-0002-9356-1186; Elmaghraby, Adel
   S/0000-0001-5274-8596
FU Basque Government "Aids for health research projects"; Basque Government
   Department of Education (eVIDA Certified Group) [IT905-16]
FX This research was supported by the Basque Government "Aids for health
   research projects" and the publication fees supported by the Basque
   Government Department of Education (eVIDA Certified Group IT905-16).
CR Arévalo F, 2012, Rev. gastroenterol. Perú, V32, P123
   Barnard R. J., 2004, EVIDENCE BASED COMPL, V1
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   CDC, 2013, US CANC STAT 2013
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Day D W, 1978, Major Probl Pathol, V10, P58
   Ferlay J, 2018, EUR J CANCER, V103, P356, DOI 10.1016/j.ejca.2018.07.005
   GREZ I MANUEL, 2008, Rev Chil Cir, V60, P249, DOI 10.4067/S0718-40262008000300015
   Gu MJ, 2018, BMC CANCER, V18, DOI 10.1186/s12885-017-3968-z
   Gualdrini Ubaldo Alfredo, 2005, Acta Gastroenterologica Latinoamericana, V35, P104
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Jemal A, 2009, CA-CANCER J CLIN, V59, P225, DOI 10.3322/caac.20006
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Observatorio AECC, 2020, CANC COL CIFR
   Observatorio del Cancer de la AECC, 2018, INC MORT CANC COL ES
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Rico Adriana, 2016, J Cancer Res Ther (Manch), V5, P7, DOI 10.14312/2052-4994.2017-2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Sociedad Espanola de Oncologia Medica, 2018, CIFR CANC ESP 2018
   Tamakoshi A, 2017, J EPIDEMIOL, V27, pS36, DOI 10.1016/j.je.2016.12.004
   World Health Organization, 2014, CANC COUNTR PROF
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
NR 28
TC 2
Z9 2
U1 5
U2 19
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2021
VL 67
IS 2
BP 1629
EP 1644
DI 10.32604/cmc.2021.013618
PG 16
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA QF1NT
UT WOS:000616667200018
OA gold
DA 2023-08-21
ER

PT J
AU Thomaz, VD
   Sierra-Franco, CA
   Raposo, AB
AF Thomaz, Victor de Almeida
   Sierra-Franco, Cesar A.
   Raposo, Alberto B.
TI Training data enhancements for improving colonic polyp detection using
   deep convolutional neural networks
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Article
DE Colonoscopy; Polyp detection; Augmentation; Training data; Generative
   adversarial networks
ID VALIDATION
AB Background: Over the last years, the most relevant results in the context of polyp detection were achieved through deep learning techniques. However, the most common obstacles in this field are the small datasets with a reduced number of samples and the lack of data variability. This paper describes a method to reduce this limitation and improve polyp detection results using publicly available colonoscopic datasets.
   Methods: To address this issue, we increased the number and variety of images from the original dataset. Our method consists on adding polyps to the dataset images. The developed algorithm performs a rigorous selection of the best region within the image to receive the polyp. This procedure preserves the realistic features of the images while creating more diverse samples for training purposes. Our method allows copying existing polyps to new non-polypoid target regions. We also develop a strategy to generate new and more varied polyps through generative adversarial neural networks. Hence, the developed approach enriches the training data, creating automatically new samples with their appropriate labels.
   Results: We applied the proposed data enhancement over a colonic polyp dataset. Thus, we can assess the effectiveness of our approach through a Faster R-CNN detection model. Performance results show improvements over the polyp detections while reducing the false-negative rate. The experimental results also show better recall metrics in comparison with both the original training set and other studies in the literature.
   Conclusion: We demonstrate that our proposed method has the potential to increase the data variability and number of samples in a reduced polyp dataset, improving the polyp detection rate and recall values. These results open new possibilities for advancing the study and implementation of new methods to improve computer-assisted medical image analysis.
C1 [Thomaz, Victor de Almeida] Pontifical Catholic Univ Rio de Janeiro, Rua Marques de Sao Vicente 225, Gavea Rio De Janeiro, Brazil.
   [Sierra-Franco, Cesar A.; Raposo, Alberto B.] Tecgraf Inst Tech Sci Software Dev, Rua Marques de Sao Vicente 225, Gavea Rio De Janeiro, Brazil.
C3 Pontificia Universidade Catolica do Rio de Janeiro
RP Thomaz, VD (通讯作者)，Pontifical Catholic Univ Rio de Janeiro, Rua Marques de Sao Vicente 225, Gavea Rio De Janeiro, Brazil.
EM vthomaz@inf.puc-rio.br; casfranco@tecgraf.puc-rio.br;
   abraposo@tecgraf.puc-rio.br
RI Raposo, Alberto B/G-3204-2012
OI Raposo, Alberto/0000-0001-7279-1823
CR Amber A, 2015, 3RD INTERNATIONAL CONFERENCE ON APPLIED COMPUTING AND INFORMATION TECHNOLOGY (ACIT 2015) 2ND INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND INTELLIGENCE (CSI 2015), P299, DOI 10.1109/ACIT-CSI.2015.60
   American Cancer Society, 2017, KEY STAT COL CANC
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Bernal J, 2018, P 32 CARS C, V13, pS166
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Biswas M, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON ELECTRONICS, MATERIALS ENGINEERING & NANO-TECHNOLOGY (IEMENTECH)
   Costa P., 2017, ARXIV170108974
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Guibas J. T., 2017, ABS17090 CORR
   Han C, 2018, I S BIOMED IMAGING, P734, DOI 10.1109/ISBI.2018.8363678
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hwang S, 2007, IEEE INT C IM PROC 2, V2, pII
   Kang J, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1469
   Kingma DP, 2015, P INT C LEARN ICLR
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   Lin T-Y, EUR C COMP VIS
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   Mirza M., 2014, ARXIV14111784, DOI DOI 10.48550/ARXIV.1411.1784
   Pogorelov K, 2018, COMP MED SY, P381, DOI 10.1109/CBMS.2018.00073
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Riegler M, 2016, P 7 INT C MULT SYST, P29
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shaikhina T, 2017, ARTIF INTELL MED, V75, P51, DOI 10.1016/j.artmed.2016.12.003
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Soille P, 2003, MORPHOLOGICAL IMAGE
   Taha B, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P233, DOI 10.2316/P.2017.852-031
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Thomaz VD, 2019, COMP MED SY, P192, DOI 10.1109/CBMS.2019.00047
   Urban G, 2018, GASTROENTEROLOGY
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
NR 40
TC 8
Z9 8
U1 3
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD JAN
PY 2021
VL 111
AR 101988
DI 10.1016/j.artmed.2020.101988
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA PZ5YD
UT WOS:000612815000006
PM 33461694
DA 2023-08-21
ER

PT J
AU Tran, ST
   Cheng, CH
   Nguyen, TT
   Le, MH
   Liu, DG
AF Tran, Song-Toan
   Cheng, Ching-Hwa
   Nguyen, Thanh-Tuan
   Le, Minh-Hai
   Liu, Don-Gey
TI TMD-Unet: Triple-Unet with Multi-Scale Input Features and Dense Skip
   Connection for Medical Image Segmentation
SO HEALTHCARE
LA English
DT Article
DE medical image segmentation; nuclei segmentation; liver segmentation;
   polyp segmentation; skin lesion segmentation; spleen segmentation; left
   atrium segmentation; electron microscopy segmentation; Unet architecture
ID ARCHITECTURE; NETWORKS
AB Deep learning is one of the most effective approaches to medical image processing applications. Network models are being studied more and more for medical image segmentation challenges. The encoder-decoder structure is achieving great success, in particular the Unet architecture, which is used as a baseline architecture for the medical image segmentation networks. Traditional Unet and Unet-based networks still have a limitation that is not able to fully exploit the output features of the convolutional units in the node. In this study, we proposed a new network model named TMD-Unet, which had three main enhancements in comparison with Unet: (1) modifying the interconnection of the network node, (2) using dilated convolution instead of the standard convolution, and (3) integrating the multi-scale input features on the input side of the model and applying a dense skip connection instead of a regular skip connection. Our experiments were performed on seven datasets, including many different medical image modalities such as colonoscopy, electron microscopy (EM), dermoscopy, computed tomography (CT), and magnetic resonance imaging (MRI). The segmentation applications implemented in the paper include EM, nuclei, polyp, skin lesion, left atrium, spleen, and liver segmentation. The dice score of our proposed models achieved 96.43% for liver segmentation, 95.51% for spleen segmentation, 92.65% for polyp segmentation, 94.11% for EM segmentation, 92.49% for nuclei segmentation, 91.81% for left atrium segmentation, and 87.27% for skin lesion segmentation. The experimental results showed that the proposed model was superior to the popular models for all seven applications, which demonstrates the high generality of the proposed model.
C1 [Tran, Song-Toan; Nguyen, Thanh-Tuan; Le, Minh-Hai; Liu, Don-Gey] Feng Chia Univ, Program Elect & Commun Engn, Taichung 40724, Taiwan.
   [Tran, Song-Toan; Le, Minh-Hai] Tra Vinh Univ, Dept Elect & Elect, Tra Vinh 87000, Vietnam.
   [Cheng, Ching-Hwa; Liu, Don-Gey] Feng Chia Univ, Dept Elect Engn, Taichung 40724, Taiwan.
C3 Feng Chia University; Tra Vinh University; Feng Chia University
RP Tran, ST (通讯作者)，Feng Chia Univ, Program Elect & Commun Engn, Taichung 40724, Taiwan.; Tran, ST (通讯作者)，Tra Vinh Univ, Dept Elect & Elect, Tra Vinh 87000, Vietnam.
EM tstoan1512@tvu.edu.vn; chengch@fcu.edu.tw; nttuan@kgc.edu.vn;
   lmhai@tvu.edu.vn; dgliu@fcu.edu.tw
RI Liu, Tang-Chieh/AHD-3857-2022; Tran, Song-Toan/AAA-8196-2021
OI Liu, Tang-Chieh/0000-0002-0961-7539; Tran, Song-Toan/0000-0002-8329-0036
CR Adegun A, 2019, LECT NOTES COMPUT SC, V11663, P232, DOI 10.1007/978-3-030-27272-2_20
   Akbari M, 2018, IEEE ENG MED BIO, P69, DOI 10.1109/EMBC.2018.8512197
   Albishri AA, 2019, IEEE INT C BIOINFORM, P1416, DOI 10.1109/BIBM47256.2019.8983266
   Ali R, 2019, PROC NAECON IEEE NAT, P311, DOI 10.1109/NAECON46414.2019.9058245
   Alom, 2018, ARXIV PREPRINT ARXIV
   Alom M.Z., 2018, ARXIV181103447
   Alom MZ, 2018, PROC NAECON IEEE NAT, P228, DOI 10.1109/NAECON.2018.8556686
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Aresta G, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48004-8
   Azad Reza, 2019, P IEEE CVF INT C COM, P0
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bilic P, 2019, ARXIV190104056
   Cai L, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.02.44
   Caicedo JC, 2019, NAT METHODS, V16, P1247, DOI 10.1038/s41592-019-0612-7
   Cardona A, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000502
   Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen YL, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.01110
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   He K., 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hofener H, 2018, COMPUT MED IMAG GRAP, V70, P43, DOI 10.1016/j.compmedimag.2018.08.010
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/icassp40776.2020.9053405, 10.1109/ICASSP40776.2020.9053405]
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Isensee F., 2018, NAT METHODS
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jiang HY, 2019, IEEE ACCESS, V7, P24898, DOI 10.1109/ACCESS.2019.2899608
   Keetha NV., 2020, ARXIV200309293
   Lei T., 2020, ARXIV PREPRINT ARXIV
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Liu W, 2020, ALGORITHMS, V13, DOI 10.3390/a13030060
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Ozturk S, 2020, J DIGIT IMAGING, V33, P958, DOI 10.1007/s10278-020-00343-z
   Panayides AS, 2020, IEEE J BIOMED HEALTH, V24, P1837, DOI 10.1109/JBHI.2020.2991043
   Poorneshwaran JM, 2019, IEEE ENG MED BIO, P7201, DOI 10.1109/EMBC.2019.8857958
   R D Seeja, 2019, Asian Pac J Cancer Prev, V20, P1555
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Seo H, 2020, IEEE T MED IMAGING, V39, P1316, DOI 10.1109/TMI.2019.2948320
   Simpson AL, 2019, ARXIV190209063
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang LS, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00285
   Weng Y, 2019, IEEE ACCESS, V7, P44247, DOI 10.1109/ACCESS.2019.2908991
   Xi XF, 2020, IEEE ACCESS, V8, P68944, DOI 10.1109/ACCESS.2020.2985671
   Yu F., 2016, P 4 INT C LEARN REP, DOI 10.48550/arXiv.1511.07122Focustolearnmore
   Zhang J., 2018, P IEEE C COMP VIS PA
   Zhang JP, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4271
   Zhang JX, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050721
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhou T., 2019, ARRAY, V3, DOI 10.1016/j.array.2019.100004
   Zhou ZL, 2021, IEEE T BIG DATA, V7, P559, DOI 10.1109/TBDATA.2019.2919570
   Zhuang J., 2019, ARXIV181007810
NR 56
TC 34
Z9 34
U1 42
U2 153
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-9032
J9 HEALTHCARE-BASEL
JI Healthcare
PD JAN
PY 2021
VL 9
IS 1
AR 54
DI 10.3390/healthcare9010054
PG 19
WC Health Care Sciences & Services; Health Policy & Services
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services
GA PV8TD
UT WOS:000610252900001
PM 33419018
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Xia, J
   Xia, T
   Pan, J
   Gao, F
   Wang, S
   Qian, YY
   Wang, H
   Zhao, J
   Jiang, X
   Zou, WB
   Wang, YC
   Zhou, W
   Li, ZS
   Liao, Z
AF Xia, Ji
   Xia, Tian
   Pan, Jun
   Gao, Fei
   Wang, Shuang
   Qian, Yang-Yang
   Wang, Heng
   Zhao, Jie
   Jiang, Xi
   Zou, Wen-Bin
   Wang, Yuan-Chen
   Zhou, Wei
   Li, Zhao-Shen
   Liao, Zhuan
TI Use of artificial intelligence for detection of gastric lesions by
   magnetically controlled capsule endoscopy
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID CONVOLUTIONAL NEURAL-NETWORKS; DEEP; GASTROSCOPY; CANCER
AB Background and Aims: Magnetically controlled capsule endoscopy (MCE) has become an efficient diagnostic modality for gastric diseases. We developed a novel automatic gastric lesion detection system to assist in diagnosis and reduce inter-physician variations. This study aimed to evaluate the diagnostic capability of the computeraided detection system for MCE images.
   Methods: We developed a novel automatic gastric lesion detection system based on a convolutional neural network (CNN) and faster region-based convolutional neural network (RCNN). A total of 1,023,955 MCE images from 797 patients were used to train and test the system. These images were divided into 7 categories (erosion, polyp, ulcer, submucosal tumor, xanthoma, normal mucosa, and invalid images). The primary endpoint was the sensitivity of the system.
   Results: The systemdetected gastric focal lesions with 96.2% sensitivity (95% confidence interval [CI], 95.7%-96.5%), 76.2% specificity (95% CI, 75.97%-76.3%), 16.0% positive predictive value (95% CI, 15.7%-16.3%), 99.7% negative predictive value (95% CI, 99.74%-99.79%), and 77.1% accuracy (95% CI, 76.9%-77.3%) (sensitivity was 99.3% for erosions; 96.5% for polyps; 89.3% for ulcers; 87.2% for submucosal tumors; 90.6% for xanthomas; 67.8% for normal; and 96.1% for invalid images). Analysis of the receiver operating characteristic curve showed that the area under the curve for all positive images was 0.84. Image processing time was 44 milliseconds per image for the system and 0.38 +/- 0.29 seconds per image for clinicians (P <.001). The kappa value of 2 times repeated reads was 1.
   Conclusions: The CNN faster-RCNN-based diagnostic program system showed good performance in diagnosing gastric focal lesions in MCE images.
C1 [Xia, Ji; Xia, Tian; Pan, Jun; Qian, Yang-Yang; Jiang, Xi; Zou, Wen-Bin; Wang, Yuan-Chen; Zhou, Wei; Li, Zhao-Shen; Liao, Zhuan] Second Mil Med Univ, Changhai Hosp, Natl Clin Res Ctr Digest Dis, Dept Gastroenterol, 168 Changhai Rd, Shanghai 200433, Peoples R China.
   [Gao, Fei; Wang, Shuang; Wang, Heng; Zhao, Jie] Beijing Medicinovo Technol Co Ltd, Beijing, Peoples R China.
C3 Naval Medical University
RP Liao, Z (通讯作者)，Second Mil Med Univ, Changhai Hosp, Natl Clin Res Ctr Digest Dis, Dept Gastroenterol, 168 Changhai Rd, Shanghai 200433, Peoples R China.
EM zhuanliao@hotmail.com
RI Zou, Wen-Bin/ACK-2432-2022
FU National Natural Science Foundation of China [81422010]; "Ten Thousand
   Plan"-National High Level Talents Special Support Plan; Shuguang Program
   of Shanghai Education Development Foundation [15SG33]; Shanghai
   Municipal Education Commission [15SG33]; Chang Jiang Scholars Program of
   Ministry of Education [Q2015190]; Shanghai "Rising Stars of Medical
   Talent" Youth Development Program [[2019]72]; Shanghai Sailing Program,
   China [18YF1422800, 19YF1446700]
FX This study is supported by grants from the National Natural Science
   Foundation of China (to Z.L., no. 81422010); the "Ten Thousand
   Plan"-National High Level Talents Special Support Plan (to Z.L.); the
   Shuguang Program of Shanghai Education Development Foundation and
   Shanghai Municipal Education Commission (to Z.L., no. 15SG33); the Chang
   Jiang Scholars Program of Ministry of Education (to Z.L., no. Q2015190);
   Shanghai "Rising Stars of Medical Talent" Youth Development Program (to
   T.X., no.[2019]72) and Shanghai Sailing Program (to J.P., no.
   18YF1422800; to Y.-Y.Q., no. 19YF1446700), China. The study funders had
   no role in the design and conduct of the study; collection, management,
   analysis, and interpretation of the data; preparation, review, or
   approval of the manuscript; and decision to submit the manuscript for
   publication. The opinions, results, and conclusions reported in this
   article are those of the authors and are independent from the funding
   sources.
CR Alizadeh M, 2017, J BIOMED RES, V31, P419, DOI 10.7555/JBR.31.20160008
   Barbosa DC, 2012, BIOMED ENG ONLINE, V11, DOI 10.1186/1475-925X-11-3
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Guimaraes P, 2020, GUT, V69, P4, DOI 10.1136/gutjnl-2019-319347
   Hewett David G, 2010, Gastrointest Endosc Clin N Am, V20, P673, DOI 10.1016/j.giec.2010.07.011
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Jiang Xi, 2019, VideoGIE, V4, P239, DOI 10.1016/j.vgie.2019.03.003
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liao ZA, 2016, CLIN GASTROENTEROL H, V14, P1266, DOI 10.1016/j.cgh.2016.05.013
   Liao Zhuan, 2012, J Interv Gastroenterol, V2, P155, DOI 10.4161/jig.23751
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Y, 2017, A170302442V2 ARXIV
   Luo HY, 2019, LANCET ONCOL, V20, P1645, DOI 10.1016/S1470-2045(19)30637-0
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Qiao PP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166488
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Tai FWD, 2019, LANCET GASTROENTEROL, V4, P749, DOI 10.1016/S2468-1253(19)30262-6
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Yoon HJ, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091310
   Zhao AJ, 2018, GASTROINTEST ENDOSC, V88, P466, DOI 10.1016/j.gie.2018.05.003
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
   Zou WB, 2015, ENDOSCOPY, V47, P526, DOI 10.1055/s-0034-1391123
NR 28
TC 27
Z9 32
U1 1
U2 25
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JAN
PY 2021
VL 93
IS 1
BP 133
EP +
DI 10.1016/j.gie.2020.05.027
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA PH6VV
UT WOS:000600548600018
PM 32470426
DA 2023-08-21
ER

PT J
AU Yang, XY
   Wei, QX
   Zhang, CH
   Zhou, KB
   Kong, L
   Jiang, WW
AF Yang, Xiaoyong
   Wei, Qianxing
   Zhang, Changhe
   Zhou, Kaibo
   Kong, Li
   Jiang, Weiwei
TI Colon Polyp Detection and Segmentation Based on Improved MRCNN
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
LA English
DT Article
DE Colorectal cancer; colonic polyps; deep learning (DL); endoscopic
   informatics; therapeutic endoscopy
ID COLORECTAL-CANCER; COLONOSCOPY; POPULATION; PRECISION; SCREEN
AB Colon polyps have a greater chance of developing into colon cancer, and colonoscopy is one of the most commonly used methods to detect colon polyps. However, the effectiveness of colonoscopy depends largely on the technical level of the physicians, and there are fewer experienced physicians. Besides, traditional artificial intelligence methods cannot obtain a unified model with good results for all patients. To solve these problems, a colon polyp detection and segmentation method based on mask regions convolutional neural network (MRCNN) with precise region of interest (PrROI) pooling is proposed in this article. The proposed method is constructed in two parts: 1) an image filter is used to filter the initial image, filtering out the low-quality image data and 2) the screened images are divided into multiple groups according to patients and sent to the improved MRCNN for training to obtain the corresponding private model of each patient. Data sets from an open challenge and a Chinese hospital are used to verify the effectiveness of the proposed method, which is able to detect polyps with an average-precision (AP) of 0.76 and segment polyps with an intersection over union (IOU) of 86.87%. The proposed method has a potential to assist endoscopists in detecting and segmenting polyps during colonoscopy.
C1 [Yang, Xiaoyong; Wei, Qianxing; Zhang, Changhe; Zhou, Kaibo; Kong, Li] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.
   [Jiang, Weiwei] Huazhong Univ Sci & Technol, Union Hosp, Tongji Med Coll, Dept Gastroenterol, Wuhan 430022, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Jiang, WW (通讯作者)，Huazhong Univ Sci & Technol, Union Hosp, Tongji Med Coll, Dept Gastroenterol, Wuhan 430022, Peoples R China.
EM xiaoyongyang@hust.cdu.cn; qxwei@hust.edu.cn; changhezhang@hust.edu.cn;
   zhoukb@hust.edu.cn; hustkongli@263.net; jiangwwuh@163.com
OI Zhang, Changhe/0000-0001-7046-9240
CR [Anonymous], 2015, DEEP LEARNING NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2017, P IEEE INT C COMPUTE
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bhandari G. P, 2018, 5 IEEE UPCON
   Bray F, 2015, CANC DIS CONTROL PRI
   Bretthauer M, 2016, JAMA INTERN MED, V176, P894, DOI 10.1001/jamainternmed.2016.0960
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   [常娥 CHANG E], 2006, [情报科学, Information Science], V24, P627
   Gessl I, 2019, GASTROINTEST ENDOSC, V89, P496, DOI 10.1016/j.gie.2018.08.013
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Liao Y., 2019, IEEE ICME
   Lieberman DA, 2000, NEW ENGL J MED, V343, P162, DOI 10.1056/NEJM200007203430301
   Liu J, 2018, J MANUF PROCESS, V35, P570, DOI 10.1016/j.jmapro.2018.08.038
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Martinez F., 2019, 2019 22 S IM SIGN PR, P1
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   OBRIEN MJ, 1990, GASTROENTEROLOGY, V98, P371, DOI 10.1016/0016-5085(90)90827-N
   Peery AF, 2018, GASTROENTEROLOGY, V154, P1352, DOI 10.1053/j.gastro.2018.01.003
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Robertson SE, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P603
   Sano Y, 2016, DIGEST ENDOSC, V28, P243, DOI 10.1111/den.12579
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Song M., 2018, INSTANCE SEGMENTATIO
   Su H, 2019, INT GEOSCI REMOTE SE, P1454, DOI 10.1109/IGARSS.2019.8898573
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Tjaden JM, 2018, SURG ENDOSC, V32, P3108, DOI 10.1007/s00464-018-6025-3
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yan C., 2019, Patent, Patent No. [CN 110 659 664 A, 110659664]
   Yilmaz E, 2008, KNOWL INF SYST, V16, P173, DOI 10.1007/s10115-007-0101-7
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuxuan L., 2019, IEEE CVF
   Zhang GP, 2016, LECT NOTES COMPUT SC, V10029, P344, DOI 10.1007/978-3-319-49055-7_31
   Zhao L., 2020, INT J PATTERN RECOGN, V34, P20
   Zhao TB, 2018, PROC SPIE, V10780, DOI 10.1117/12.2325570
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 42
TC 12
Z9 12
U1 1
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9456
EI 1557-9662
J9 IEEE T INSTRUM MEAS
JI IEEE Trans. Instrum. Meas.
PY 2021
VL 70
AR 4501710
DI 10.1109/TIM.2020.3038011
PG 10
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA UK2KK
UT WOS:000691803600032
DA 2023-08-21
ER

PT J
AU Sinonquel, P
   Eelbode, T
   Bossuyt, P
   Maes, F
   Bisschops, R
AF Sinonquel, Pieter
   Eelbode, Tom
   Bossuyt, Peter
   Maes, Frederik
   Bisschops, Raf
TI Artificial intelligence and its impact on quality improvement in upper
   and lower gastrointestinal endoscopy
SO DIGESTIVE ENDOSCOPY
LA English
DT Review
DE artificial intelligence; endoscopy; lower gastrointestinal tract;
   quality; upper gastrointestinal tract
ID HELICOBACTER-PYLORI INFECTION; COMPUTER-AIDED DIAGNOSIS; CONVOLUTIONAL
   NEURAL-NETWORK; DEEP LEARNING ALGORITHM; SQUAMOUS-CELL CARCINOMA;
   BARRETTS-ESOPHAGUS; GASTRIC-CANCER; ASSISTED COLONOSCOPY; AUTOMATIC
   DETECTION; SYSTEM
AB Artificial intelligence (AI) and its application in medicine has grown large interest. Within gastrointestinal (GI) endoscopy, the field of colonoscopy and polyp detection is the most investigated, however, upper GI follows the lead. Since endoscopy is performed by humans, it is inherently an imperfect procedure. Computer-aided diagnosis may improve its quality by helping prevent missing lesions and supporting optical diagnosis for those detected. An entire evolution in AI systems has been established in the last decades, resulting in optimization of the diagnostic performance with lower variability and matching or even outperformance of expert endoscopists. This shows a great potential for future quality improvement of endoscopy, given the outstanding diagnostic features of AI. With this narrative review, we highlight the potential benefit of AI to improve overall quality in daily endoscopy and describe the most recent developments for characterization and diagnosis as well as the recent conditions for regulatory approval.
C1 [Sinonquel, Pieter; Bossuyt, Peter; Bisschops, Raf] Univ Hosp Leuven, Dept Gastroenterol & Hepatol, Herestr 49, B-3000 Leuven, Belgium.
   [Eelbode, Tom; Maes, Frederik] Univ Hosp Leuven, Med Imaging Res Ctr MIRC, Leuven, Belgium.
   [Sinonquel, Pieter; Bisschops, Raf] Katholieke Univ Leuven, Dept Translat Res Gastrointestinal Dis TARGID, Leuven, Belgium.
   [Eelbode, Tom; Maes, Frederik] Katholieke Univ Leuven, Elect Engn ESAT PSI, Leuven, Belgium.
   [Bossuyt, Peter] Imelda Hosp, Dept Gastroenterol & Hepatol, Bonheiden, Belgium.
C3 KU Leuven; University Hospital Leuven; KU Leuven; University Hospital
   Leuven; KU Leuven; KU Leuven; Imeldaziekenhuis
RP Sinonquel, P (通讯作者)，Univ Hosp Leuven, Dept Gastroenterol & Hepatol, Herestr 49, B-3000 Leuven, Belgium.
EM pieter.sinonquel@uzleuven.be
RI Bossuyt, Peter/AAP-3119-2020; Maes, Frederik/I-7572-2013
OI Bossuyt, Peter/0000-0003-4027-7365; Maes, Frederik/0000-0003-0027-1479;
   Sinonquel, Pieter/0000-0001-7750-5064; Bisschops,
   Raf/0000-0002-9994-8226
FU Research Foundation Flanders; Pentax; KU Leuven [C24/18/047]; Flemish
   Government (AI Research Program)
FX RB AND TE are supported by a grant of Research Foundation Flanders. PS
   is supported by an unrestricted research grant from Pentax. FM is
   supported by KU Leuven internal grant C24/18/047 and by the Flemish
   Government (AI Research Program).
CR Abrams JA, 2009, CLIN GASTROENTEROL H, V7, P736, DOI 10.1016/j.cgh.2008.12.027
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Atkinson NSS, 2019, GASTROENTEROLOGY, V157, P462, DOI 10.1053/j.gastro.2019.04.014
   Baker JA, 2003, AM J ROENTGENOL, V181, P1083, DOI 10.2214/ajr.181.4.1811083
   Bisschops R, 2017, ENDOSCOPY, V49, P342, DOI 10.1055/s-0042-121005
   Bossuyt P, 2020, GUT, V69, P1778, DOI 10.1136/gutjnl-2019-320056
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Charisis VS, 2016, WORLD J GASTROENTERO, V22, P8641, DOI 10.3748/wjg.v22.i39.8641
   Chen D, 2020, GASTROINTEST ENDOSC, V91, P332, DOI 10.1016/j.gie.2019.09.016
   Cronin KA, 2018, CANCER, V124, P2801
   de Groof AJ, 2020, GASTROINTEST ENDOSC, V91, P1242, DOI 10.1016/j.gie.2019.12.048
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   de Groof J, 2019, UNITED EUR GASTROENT, V7, P538, DOI 10.1177/2050640619837443
   de Souza LA, 2018, COMPUT BIOL MED, V96, P203, DOI 10.1016/j.compbiomed.2018.03.014
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Dong Y, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000017510
   Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Falk GW, 1999, GASTROINTEST ENDOSC, V49, P170, DOI 10.1016/S0016-5107(99)70482-7
   Gulati S, 2020, DIGEST ENDOSC, V32, P512, DOI 10.1111/den.13481
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   Hashimoto R, 2020, GASTROINTEST ENDOSC, V91, P1264, DOI 10.1016/j.gie.2019.12.049
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Hassan C, 2017, GUT, V66, P1949, DOI 10.1136/gutjnl-2016-311906
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Horiuchi Y, 2020, DIGEST DIS SCI, V65, P1355, DOI 10.1007/s10620-019-05862-6
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Ishihara R, 2010, DIS ESOPHAGUS, V23, P480, DOI 10.1111/j.1442-2050.2009.01039.x
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jain S, 2018, J GASTROEN HEPATOL, V33, P615, DOI 10.1111/jgh.13921
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   KHAN MA, 2019, J MED SYST, V43
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kono M, 2021, DIGEST ENDOSC, V33, P569, DOI 10.1111/den.13800
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Lee YC, 2009, GASTROINTEST ENDOSC, V69, P408, DOI 10.1016/j.gie.2008.05.033
   Leenhardt R, 2020, ENDOSC INT OPEN, V8, pE415, DOI 10.1055/a-1035-9088
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Maeda Y, 2020, DIGEST ENDOSC, V32, P1082, DOI 10.1111/den.13655
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Miyaki R, 2013, J GASTROEN HEPATOL, V28, P841, DOI 10.1111/jgh.12149
   Mohammadian Taher, 2019, Monoclonal Antibodies in Immunodiagnosis and Immunotherapy, V38, P1, DOI 10.1089/mab.2018.0032
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mustain B., 2017, INT J BIOMED IMAGING, P1, DOI [10.1155/2017/9545920, DOI 10.1155/2017/9545920]
   Muto M, 2010, J CLIN ONCOL, V28, P1566, DOI 10.1200/JCO.2009.25.4680
   Nagami Y, 2014, AM J GASTROENTEROL, V109, P845, DOI 10.1038/ajg.2014.94
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Namikawa K, 2020, ENDOSCOPY, V52, P1077, DOI 10.1055/a-1194-8771
   Neumann H, 2019, DIGEST ENDOSC, V31, P389, DOI 10.1111/den.13391
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Omata F, 2014, SCAND J GASTROENTERO, V49, P222, DOI 10.3109/00365521.2013.863964
   Otani K, 2020, ENDOSCOPY, V52, P786, DOI 10.1055/a-1167-8157
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Reid BJ, 2000, AM J GASTROENTEROL, V95, P3089, DOI 10.1111/j.1572-0241.2000.03182.x
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rey JF, 2001, ENDOSCOPY, V33, P901
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Scholvinck DW, 2017, ENDOSCOPY, V49, P113, DOI 10.1055/s-0042-118312
   Sharma P, 2012, GASTROINTEST ENDOSC, V76, P252, DOI 10.1016/j.gie.2012.05.007
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI [10.3322/caac.21220, 10.3322/caac.21208, 10.3322/caac.21395]
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Smyth EC, 2018, NAT REV DIS PRIMERS, V3, P1
   Suykens J, 2020, GASTROINTEST ENDOSC, V91, pAB241
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takenaka K, 2020, GASTROENTEROLOGY, V158, P2150, DOI 10.1053/j.gastro.2020.02.012
   Tamashiro A, 2020, DIGEST ENDOSC, V32, P1057, DOI 10.1111/den.13653
   Tokai Y, 2020, ESOPHAGUS-TOKYO, V17, P250, DOI 10.1007/s10388-020-00716-x
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Wada Y, 2018, ENDOSC INT OPEN, V6, pE425, DOI 10.1055/s-0044-101142
   Waljee AK, 2018, INFLAMM BOWEL DIS, V24, P1185, DOI 10.1093/ibd/izy031
   Waljee AK, 2017, J CROHNS COLITIS, V11, P801, DOI 10.1093/ecco-jcc/jjx014
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   XIA J, 2020, GASTROINTEST ENDOSC
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zheng WF, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000109
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 100
TC 14
Z9 16
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JAN
PY 2021
VL 33
IS 2
SI SI
BP 242
EP 253
DI 10.1111/den.13888
EA DEC 2020
PG 12
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA PT0YA
UT WOS:000600029100001
PM 33145847
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Lei, S
   Wang, ZL
   Tu, MT
   Liu, PX
   Lei, L
   Xiao, X
   Zhou, GY
   Liu, XG
   Li, LP
   Wang, P
AF Lei, Shan
   Wang, Zhilan
   Tu, Mengtian
   Liu, Peixi
   Lei, Lei
   Xiao, Xun
   Zhou, GuanYu
   Liu, Xiaogang
   Li, Liangping
   Wang, Pu
TI Adenoma detection rate is not influenced by the time of day in
   computer-aided detection colonoscopy
SO MEDICINE
LA English
DT Article
DE adenoma detection rate; afternoon; colonoscopy; computer-aided
   detection; morning
ID COLORECTAL-CANCER; ARTIFICIAL-INTELLIGENCE; QUALITY INDICATORS;
   ENDOSCOPIST FATIGUE; RISK; FUTURE; POLYPS; IMPACT
AB Because of endoscopist fatigue, the time of colonoscopy have been shown to influence adenoma detection rate (ADR). Computer-aided detection (CADe) provides simultaneous visual alerts on polyps during colonoscopy and thus to increase adenoma detection rate. This is attributable to the strengthening of endoscopists diagnostic level and alleviation of fatigue. The aim of the study was to investigate whether CADe colonoscopy could eliminate the influence of the afternoon fatigue on ADR. We retrospectively analyzed the recorded data of patients who were performed CADe colonoscopy from September 2017 to February 2019 in Endoscopy Center of Sichuan Provincial People's Hospital. Patients demographic as well as baseline data recorded during colonoscopy were used for the analysis. Morning colonoscopy was defined as colonoscopic procedures starting between 8:00 am and 12:00 noon. Afternoon colonoscopy was defined as procedures starting at 2:00 pm and thereafter. The primary outcome was ADR. Univariate analysis and multivariate regression analysis were also performed. A total of 484 CADe colonoscopies were performed by 4 endoscopists in the study. The overall polyp detection rate was 52% and overall ADR was 35.5%. The mean number of adenomas detected per colonoscopy (0.62 vs 0.61, P > .05) and ADR (0.36 vs 0.35, P > .05) were similar in the am and pm group. Multivariable analysis shows that the ADR of CADe colonoscopy was influenced by the age (P < .001), gender (P = .004) and withdrawal time (P < .001), no correlation was found regarding bowel preparation (P = .993) and endoscopist experience (P = .804). CADe colonoscopy could eliminate the influence of the afternoon fatigue on ADR. The ADR during CADe colonoscopy is significantly affected by age, gender and withdrawal time.
C1 [Lei, Shan; Wang, Zhilan; Liu, Peixi; Lei, Lei; Xiao, Xun; Zhou, GuanYu; Liu, Xiaogang; Li, Liangping; Wang, Pu] Univ Elect Sci & Technol China, Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Peoples R China.
   [Tu, Mengtian] Univ Elect Sci & Technol China, Sichuan Prov Peoples Hosp, Dept Internal Med, Chengdu, Peoples R China.
C3 Sichuan Provincial People's Hospital; University of Electronic Science &
   Technology of China; Sichuan Provincial People's Hospital; University of
   Electronic Science & Technology of China
RP Wang, P (通讯作者)，Univ Elect Sci & Technol China, Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Peoples R China.
EM wangpuhuaxi@qq.com
OI Wang, Pu/0000-0002-1234-309X
CR Adler A, 2013, GUT, V62, P236, DOI 10.1136/gutjnl-2011-300167
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Almario CV, 2017, GASTROINTEST ENDOSC, V85, P611, DOI 10.1016/j.gie.2016.11.024
   [Anonymous], 2018, DIGEST LIVER DIS, DOI DOI 10.1016/j.dld.2018.03.035
   [Anonymous], 2017, ENDOSCOPY, DOI DOI 10.1055/s-0043-109430
   [Anonymous], 2016, ENDOSCOPY, DOI DOI 10.1055/s-0035-1569674
   Berzin TM, 2020, LANCET, V395, P485, DOI 10.1016/S0140-6736(20)30294-4
   Burke Carol, 2017, Gastroenterol Hepatol (N Y), V13, P1
   Chan MY, 2009, CLIN GASTROENTEROL H, V7, P1217, DOI 10.1016/j.cgh.2009.07.013
   Chen WQ, 2018, CHINESE J CANCER RES, V30, P1, DOI 10.21147/j.issn.1000-9604.2018.01.01
   Citarda F, 2001, GUT, V48, P812, DOI 10.1136/gut.48.6.812
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Freedman JS, 2011, GASTROINTEST ENDOSC, V73, P1197, DOI 10.1016/j.gie.2011.01.019
   Gregory DL., 2020, GASTROINTEST ENDOSC, V5107, P143
   Jonathan, 2011, AM J GASTROENTEROL, V106, P1466
   Jover R, 2016, ENDOSCOPY, V48, P241, DOI 10.1055/s-0042-100185
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kang HW, 2010, AM J GASTROENTEROL, V105, P178, DOI 10.1038/ajg.2009.541
   Kim JS, 2015, DIGEST DIS SCI, V60, P3092, DOI 10.1007/s10620-015-3737-2
   Lee CK, 2015, J CLIN GASTROENTEROL, V49, pe51, DOI 10.1097/MCG.0000000000000175
   Liu SZ, 2015, CHINESE J CANCER RES, V27, P22, DOI 10.3978/j.issn.1000-9604.2015.02.01
   Liu X., 2019, MED BALTIMORE, V98, pE15103
   Lurix E, 2012, GASTROINTEST ENDOSC, V75, P827, DOI 10.1016/j.gie.2011.12.008
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Munson GW, 2011, GASTROINTEST ENDOSC, V73, P467, DOI 10.1016/j.gie.2010.07.025
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Sanaka MR, 2009, AM J GASTROENTEROL, V104, P1659, DOI 10.1038/ajg.2009.249
   Teng TY, 2016, SURG ENDOSC, V30, P1796, DOI 10.1007/s00464-015-4448-7
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yuichi Mori., 2019, CLIN GASTROENTEROL H, V3565, P30997
NR 37
TC 3
Z9 3
U1 0
U2 3
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0025-7974
EI 1536-5964
J9 MEDICINE
JI Medicine (Baltimore)
PD DEC 18
PY 2020
VL 99
IS 51
AR e23685
DI 10.1097/MD.0000000000023685
PG 5
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA PZ6HB
UT WOS:000612839600058
PM 33371110
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Laiz, P
   Vitria, J
   Wenzek, H
   Malagelada, C
   Azpiroz, F
   Segui, S
AF Laiz, Pablo
   Vitria, Jordi
   Wenzek, Hagen
   Malagelada, Carolina
   Azpiroz, Fernando
   Segui, Santi
TI WCE polyp detection with triplet based embeddings
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Article
DE Deep metric learning; Triplet loss; Deep learning; Capsule endoscopy;
   Polyp detection
ID WIRELESS CAPSULE ENDOSCOPY; ARTIFICIAL-INTELLIGENCE; DISORDERS
AB Wireless capsule endoscopy is a medical procedure used to visualize the entire gastrointestinal tract and to diagnose intestinal conditions, such as polyps or bleeding. Current analyses are performed by manually inspecting nearly each one of the frames of the video, a tedious and error-prone task. Automatic image analysis methods can be used to reduce the time needed for physicians to evaluate a capsule endoscopy video. However these methods are still in a research phase.
   In this paper we focus on computer-aided polyp detection in capsule endoscopy images. This is a challenging problem because of the diversity of polyp appearance, the imbalanced dataset structure and the scarcity of data. We have developed a new polyp computer-aided decision system that combines a deep convolutional neural network and metric learning. The key point of the method is the use of the Triplet Loss function with the aim of improving feature extraction from the images when having small dataset. The Triplet Loss function allows to train robust detectors by forcing images from the same category to be represented by similar embedding vectors while ensuring that images from different categories are represented by dissimilar vectors. Empirical results show a meaningful increase of AUC values compared to state-of-the-art methods.
   A good performance is not the only requirement when considering the adoption of this technology to clinical practice. Trust and explainability of decisions are as important as performance. With this purpose, we also provide a method to generate visual explanations of the outcome of our polyp detector. These explanations can be used to build a physician's trust in the system and also to convey information about the inner working of the method to the designer for debugging purposes.
C1 [Laiz, Pablo; Vitria, Jordi; Segui, Santi] Univ Barcelona, Dept Math & Comp Sci, Barcelona, Spain.
   [Wenzek, Hagen] CorporateHlth Int ApS, Odense, Denmark.
   [Malagelada, Carolina; Azpiroz, Fernando] Univ Hosp Vall dHebron, Digest Syst Res Unit, Barcelona, Spain.
C3 University of Barcelona; Hospital Universitari Vall d'Hebron
RP Laiz, P (通讯作者)，Univ Barcelona, Dept Math & Comp Sci, Barcelona, Spain.
EM laizpablo@ub.edu
RI Azpiroz, Maite Fuentes/Y-6916-2018; Malagelada, Carolina/F-3743-2016;
   Segui, Santi/E-4860-2010
OI Azpiroz, Maite Fuentes/0000-0003-1304-1285; Malagelada,
   Carolina/0000-0001-7097-1492; Segui, Santi/0000-0002-8603-138X; Azpiroz,
   Fernando/0000-0002-7327-960X
FU CorporateHealth International ApS; MINECO [RTI2018-095232-B-C21, SGR
   1742]; Innovate UK project [104633]; Innovate UK [104633] Funding
   Source: UKRI
FX The authors would like to thank the team from CorporateHealth
   International ApS for their feedback and economic support and NVIDIA for
   their GPU donations. This work has been also supported by MINECO Grant
   RTI2018-095232-B-C21 and SGR 1742 as well as the Innovate UK project
   104633.
CR Akay A, 2019, IEEE J BIOMED HEALTH, V23, P906, DOI 10.1109/JBHI.2019.2894713
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Belle A, 2013, SCI WORLD J, DOI 10.1155/2013/769639
   Byrne MF, 2019, GASTROINTEST ENDOSC, V89, P195, DOI 10.1016/j.gie.2018.08.017
   Chen HH, 2013, INT CONF BIOMED, P116, DOI 10.1109/BMEI.2013.6746918
   Chu XQ, 2010, LECT NOTES COMPUT SC, V6362, P522
   Ciaccio EJ, 2013, WORLD J GASTRO ENDOS, V5, P313, DOI 10.4253/wjge.v5.i7.313
   Ciaccio EJ, 2010, COMPUT METH PROG BIO, V100, P39, DOI 10.1016/j.cmpb.2010.02.005
   Cobrin GM, 2006, CANCER-AM CANCER SOC, V107, P22, DOI 10.1002/cncr.21975
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Drozdzal M, 2013, COMPUT MED IMAG GRAP, V37, P72, DOI 10.1016/j.compmedimag.2012.09.002
   El Ansari M, 2017, 2017 INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND MOBILE COMMUNICATIONS (WINCOM), P407
   El Khatib A, 2015, IEEE ENG MED BIO, P2669, DOI 10.1109/EMBC.2015.7318941
   Fleuret F., 2018, ARXIV180300942
   Goran L, 2018, WORLD J GASTRO ENDOS, V10, P184, DOI 10.4253/wjge.v10.i9.184
   Guo XQ, 2019, LECT NOTES COMPUT SC, V11764, P293, DOI 10.1007/978-3-030-32239-7_33
   Hennans A., 2017, ARXIV170307737
   Hwang Y, 2018, CLIN ENDOSC, V51, P547, DOI 10.5946/ce.2018.173
   Iakovidis D. K., 2013, IEEE INT C BIOINFORM, P1
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kobaek-Larsen M, 2018, COLORECTAL DIS, V20, P479, DOI 10.1111/codi.13965
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Li J, 2018, J DIGEST DIS, V19, P386, DOI 10.1111/1751-2980.12614
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Malagelada C, 2012, NEUROGASTROENT MOTIL, V24, P223, DOI 10.1111/j.1365-2982.2011.01823.x
   Malagelada C, 2015, AM J PHYSIOL-GASTR L, V309, pG413, DOI 10.1152/ajpgi.00193.2015
   McGoran JJ, 2019, WORLD J GASTROENTERO, V25, P4051, DOI 10.3748/wjg.v25.i30.4051
   Mikolajczyk J, 2018, P I C NEW T SIG PROC, P118
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Rahim T, 2020, COMPUT MED IMAG GRAP, V85, DOI 10.1016/j.compmedimag.2020.101767
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Segui S, 2014, IEEE J BIOMED HEALTH, V18, P1831, DOI 10.1109/JBHI.2014.2304179
   Siegel R.L., 2021, CA-CANCER J CLIN, V71, P33, DOI 10.3322/caac.21654
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Taghanaki SA, 2019, COMPUT MED IMAG GRAP, V75, P24, DOI 10.1016/j.compmedimag.2019.04.005
   Takada K, 2020, DIGEST ENDOSC, V32, P529, DOI 10.1111/den.13659
   Usman MA, 2016, COMPUT MED IMAG GRAP, V54, P16, DOI 10.1016/j.compmedimag.2016.09.005
   Vasilakakis M, 2019, EXPERT REV GASTROENT, V13, P129, DOI 10.1080/17474124.2019.1553616
   Yang YJ, 2020, CLIN ENDOSC, V53, P387, DOI 10.5946/ce.2020.133
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan Y., 2018, RIIS DENSENET ROTATI, P620
   Yuan YX, 2020, IEEE T AUTOM SCI ENG, V17, P574, DOI 10.1109/TASE.2019.2936645
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Yuan ZJ, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254671
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang XL, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0205050
   Zhao Q, 2015, COMPUT MED IMAG GRAP, V41, P108, DOI 10.1016/j.compmedimag.2014.05.011
   Zhao Q, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P948, DOI 10.1109/WCICA.2011.5970656
   ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
   Zwinger LL, 2019, J CLIN GASTROENTEROL, V53, pE101, DOI 10.1097/MCG.0000000000000994
NR 62
TC 12
Z9 12
U1 0
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD DEC
PY 2020
VL 86
AR 101794
DI 10.1016/j.compmedimag.2020.101794
PG 12
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA PB3JV
UT WOS:000596222000008
PM 33130417
OA Green Accepted, Green Submitted
DA 2023-08-21
ER

PT J
AU Liu, PX
   Wang, P
   Brown, JGR
   Berzin, TM
   Zhou, GY
   Liu, WH
   Xiao, X
   Chen, ZY
   Zhang, ZH
   Zhou, C
   Lei, L
   Xiong, F
   Li, LP
   Liu, XG
AF Liu, Peixi
   Wang, Pu
   Glissen Brown, Jeremy R.
   Berzin, Tyler M.
   Zhou, Guanyu
   Liu, Weihui
   Xiao, Xun
   Chen, Ziyang
   Zhang, Zhihong
   Zhou, Chao
   Lei, Lei
   Xiong, Fei
   Li, Liangping
   Liu, Xiaogang
TI The single-monitor trial: an embedded CADe system increased adenoma
   detection during colonoscopy: a prospective randomized study
SO THERAPEUTIC ADVANCES IN GASTROENTEROLOGY
LA English
DT Article
DE artificial intelligence; colonoscopy; computer-aided diagnosis; polyp
ID COMPUTER-AIDED DETECTION; INATTENTIONAL BLINDNESS; MULTICENTER;
   ENDOSCOPY; PARTICIPATION; POLYPS; IMPACT; RISK
AB Background: Computer-aided detection (CADe) of colon polyps has been demonstrated to improve colon polyp and adenoma detection during colonoscopy by indicating the location of a given polyp on a parallel monitor. The aim of this study was to investigate whether embedding the CADe system into the primary colonoscopy monitor may serve to increase polyp and adenoma detection, without increasing physician fatigue level.
   Methods: Consecutive patients presenting for colonoscopies were prospectively randomized to undergo routine colonoscopy with or without the assistance of a real-time polyp detection CADe system. Fatigue level was evaluated from score 0 to 10 by the performing endoscopists after each colonoscopy procedure. The main outcome was adenoma detection rate (ADR).
   Results: Out of 790 patients analyzed, 397 were randomized to routine colonoscopy (control group), and 393 to a colonoscopy with computer-aided diagnosis (CADe group). The ADRs were 20.91% and 29.01%, respectively (OR = 1.546, 95% CI 1.116-2.141, p = 0.009). The average number of adenomas per colonoscopy (APC) was 0.29 and 0.48, respectively (Change Folds = 1.64, 95% CI 1.299-2.063, p < 0.001). The improvement in polyp detection was mainly due to increased detection of non-advanced diminutive adenomas, serrated adenoma and hyperplastic polyps. The fatigue score for each procedure was 3.28 versus 3.40 for routine and CADe group, p = 0.357.
   Conclusions: A real-time CADe system employed on the primary endoscopy monitor may lead to improvements in ADR and polyp detection rate without increasing fatigue level during colonoscopy. The integration of a low-latency and high-performance CADe systems may serve as an effective quality assurance tool during colonoscopy. number, ChiCTR1800018058.
C1 [Wang, Pu] Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, 32 West Second Sect First Ring Rd, Chengdu, Sichuan, Peoples R China.
   [Liu, Peixi; Zhou, Guanyu; Liu, Weihui; Xiao, Xun; Chen, Ziyang; Zhang, Zhihong; Zhou, Chao; Lei, Lei; Xiong, Fei; Li, Liangping; Liu, Xiaogang] Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Chengdu, Sichuan, Peoples R China.
   [Glissen Brown, Jeremy R.; Berzin, Tyler M.] Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Boston, MA 02215 USA.
   [Glissen Brown, Jeremy R.; Berzin, Tyler M.] Harvard Med Sch, Boston, MA 02115 USA.
C3 Sichuan Provincial People's Hospital; Sichuan Provincial People's
   Hospital; Harvard University; Beth Israel Deaconess Medical Center;
   Harvard University; Harvard Medical School
RP Wang, P (通讯作者)，Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, 32 West Second Sect First Ring Rd, Chengdu, Sichuan, Peoples R China.
EM wangpuhuaxi@qq.com
OI Liu, Wei-hui/0000-0003-2871-8316; Glissen Brown,
   Jeremy/0000-0002-7204-7241; Wang, Pu/0000-0002-1234-309X
CR Adler A, 2012, CLIN GASTROENTEROL H, V10, P155, DOI 10.1016/j.cgh.2011.10.026
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Almansa C, 2011, AM J GASTROENTEROL, V106, P1070, DOI 10.1038/ajg.2011.26
   [Anonymous], [No title captured]
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Bai Y, 2018, ENDOSCOPY, V50, P128, DOI 10.1055/s-0043-119213
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Cai B, 2015, ONCOL LETT, V9, P2073, DOI 10.3892/ol.2015.3005
   Chen HD, 2019, GUT, V68, P1450, DOI 10.1136/gutjnl-2018-317124
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Fang JY, 2014, GASTROINTEST TUMORS, V1, P53, DOI 10.1159/000362585
   Glissen Brown Jeremy R, 2020, VideoGIE, V5, P135, DOI 10.1016/j.vgie.2020.01.002
   Gralnek IM, 2014, LANCET ONCOL, V15, P353, DOI 10.1016/S1470-2045(14)70020-8
   Head J, 2015, EXP BRAIN RES, V233, P1481, DOI 10.1007/s00221-015-4222-z
   Jia H, 2017, AM J GASTROENTEROL, V112, P568, DOI 10.1038/ajg.2016.501
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lami M, 2018, ENDOSCOPY, V50, P701, DOI 10.1055/s-0044-101026
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Memmert D, 2010, J GEN PSYCHOL, V137, P129, DOI 10.1080/00221301003645061
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Robertson DJ, 2015, GUT, V64, P982, DOI 10.1136/gutjnl-2014-308076
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Wang P, 2020, GASTROENTEROLOGY, V159, P1252, DOI 10.1053/j.gastro.2020.06.023
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Xu Y, 2018, SCAND J GASTROENTERO, V53, P365, DOI 10.1080/00365521.2018.1433230
   Yoo WG, 2014, J PHYS THER SCI, V26, P1807, DOI 10.1589/jpts.26.1807
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
NR 31
TC 29
Z9 30
U1 1
U2 4
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1756-283X
EI 1756-2848
J9 THER ADV GASTROENTER
JI Ther. Adv. Gastroenterol.
PD DEC
PY 2020
VL 13
AR 1756284820979165
DI 10.1177/1756284820979165
PG 13
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA PG9AU
UT WOS:000600020100001
PM 33403003
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Sanchez-Peralta, LF
   Pagador, JB
   Picon, A
   Calderon, AJ
   Polo, F
   Andraka, N
   Bilbao, R
   Glover, B
   Saratxaga, CL
   Sanchez-Margallo, FM
AF Sanchez-Peralta, Luisa F.
   Blas Pagador, J.
   Picon, Artzai
   Jose Calderon, Angel
   Polo, Francisco
   Andraka, Nagore
   Bilbao, Roberto
   Glover, Ben
   Saratxaga, Cristina L.
   Sanchez-Margallo, Francisco M.
TI PICCOLO White-Light and Narrow-Band Imaging Colonoscopic Dataset: A
   Performance Comparative of Models and Datasets
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE deep learning; colorectal cancer; public dataset; clinical metadata;
   colonoscopy; binary masks; polyps; detection; localisation; segmentation
ID CLASSIFICATION; LESIONS
AB Featured Application
   This dataset can be used for supervised training of models for colorectal polyp detection, localisation, segmentation and classification.
   Colorectal cancer is one of the world leading death causes. Fortunately, an early diagnosis allows for effective treatment, increasing the survival rate. Deep learning techniques have shown their utility for increasing the adenoma detection rate at colonoscopy, but a dataset is usually required so the model can automatically learn features that characterize the polyps. In this work, we present the PICCOLO dataset, that comprises 3433 manually annotated images (2131 white-light images 1302 narrow-band images), originated from 76 lesions from 40 patients, which are distributed into training (2203), validation (897) and test (333) sets assuring patient independence between sets. Furthermore, clinical metadata are also provided for each lesion. Four different models, obtained by combining two backbones and two encoder-decoder architectures, are trained with the PICCOLO dataset and other two publicly available datasets for comparison. Results are provided for the test set of each dataset. Models trained with the PICCOLO dataset have a better generalization capacity, as they perform more uniformly along test sets of all datasets, rather than obtaining the best results for its own test set. This dataset is available at the website of the Basque Biobank, so it is expected that it will contribute to the further development of deep learning methods for polyp detection, localisation and classification, which would eventually result in a better and earlier diagnosis of colorectal cancer, hence improving patient outcomes.
C1 [Sanchez-Peralta, Luisa F.; Blas Pagador, J.; Sanchez-Margallo, Francisco M.] Jesus Uson Minimally Invas Surg Ctr, N-521,Km 41-7, E-10071 Caceres, Spain.
   [Picon, Artzai; Saratxaga, Cristina L.] Basque Res & Technol Alliance BRTA, TECNALIA, Parque Tecnol Bizkaia,C Geldo Edificio 700, E-48160 Derio Bizkaia, Spain.
   [Jose Calderon, Angel; Polo, Francisco] Hosp Univ Basurto, Gastroenterol Dept, Ave Montevideo 18, E-48013 Bilbao, Spain.
   [Andraka, Nagore; Bilbao, Roberto] Basque Fdn Hlth Innovat & Res BIOEF, Basque Biobank, Ronda Azkue 1, E-48902 Baracaldo, Spain.
   [Glover, Ben] Imperial Coll London, Exhibit Rd, London SW7 2BU, England.
C3 Basurto Hospital; Imperial College London
RP Sanchez-Peralta, LF (通讯作者)，Jesus Uson Minimally Invas Surg Ctr, N-521,Km 41-7, E-10071 Caceres, Spain.
EM msanchez@ccmijesususon.com; jbpagador@ccmijesususon.com;
   artzai.picon@tecnalia.com; angeljose.calderongarcia@osakidetza.eus;
   francisco.poloortiz@osakidetza.eus; nagoreandraka@gmail.com;
   bilbao@bioef.eus; bglover@ic.ac.uk; Cristina.Lopez@tecnalia.com;
   lfsanchez@ccmijesususon.com
RI Sánchez Margallo, Francisco Miguel Miguel/I-5605-2019; Pagador, J.
   Blas/J-9858-2016; Sánchez-Peralta, Luisa F/G-9772-2012; Sánchez-Peralta,
   Luisa F./M-2976-2018; Pagador, Blas/D-5914-2011
OI Sánchez Margallo, Francisco Miguel Miguel/0000-0003-2138-988X; Pagador,
   J. Blas/0000-0002-4382-5075; Sánchez-Peralta, Luisa
   F./0000-0002-7630-353X; Pagador, Blas/0000-0002-4382-5075; Bilbao,
   Roberto/0000-0002-1199-0420; L. Saratxaga, Cristina/0000-0003-1429-7936;
   Picon, Artzai/0000-0002-3316-6571
FU PICCOLO project; European Union's Horizon2020 research and innovation
   programme [732111]; Consejeria de Economia, Ciencia y Agenda Digital of
   Junta de Extremadura - (European Regional Development Fund-ERDF)
   [GR18199]
FX This work was partially supported by PICCOLO project. This project has
   received funding from the European Union's Horizon2020 research and
   innovation programme under grant agreement No 732111. The sole
   responsibility of this publication lies with the author. The European
   Union is not responsible for any use that may be made of the information
   contained therein. Furthermore, this publication has also been partially
   supported by GR18199 from Consejeria de Economia, Ciencia y Agenda
   Digital of Junta de Extremadura (co-funded by European Regional
   Development Fund-ERDF. "A way to make Europe"/"Investing in your
   future". This work has been performed by the ICTS "NANBIOSIS" at the
   Jesus Uson Minimally Invasive Surgery Centre.
CR Abadi Martin, 2016, arXiv
   Abaza A, 2012, INT C PATT RECOG, P3103
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], CA CANCER J CLIN, DOI [10.3322/CAAC.21254, DOI 10.3322/caac.21254]
   [Anonymous], CA CANC J CLIN, DOI DOI 10.3322/caac.21332
   [Anonymous], 2014, WORLD CANC REPORT 20
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Aziz M, 2020, J GASTROEN HEPATOL, V35, P1676, DOI 10.1111/jgh.15070
   Bernal J, 2019, INT J COMPUT ASS RAD, V14, P191, DOI 10.1007/s11548-018-1864-x
   Borgli H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00622-y
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chan H.-P., 2020, DEEP LEARNING MED IM
   Chaurasia A., 2017, IEEE VCIP, P1, DOI DOI 10.1109/VCIP.2017.8305148
   Chlebus G, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217228
   Hattori S, 2014, WORLD J GASTRO ENDOS, V6, P600, DOI 10.4253/wjge.v6.i12.600
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   International Agency for Research on Cancer, 2018, COL CANC FACTSH
   Ishaq S, 2017, DIGEST LIVER DIS, V49, P721, DOI 10.1016/j.dld.2017.03.030
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Joskowicz L, 2019, EUR RADIOL, V29, P1391, DOI 10.1007/s00330-018-5695-5
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kim J, 2018, PRECIS FUTURE MED, V2, P37, DOI 10.23838/pfm.2018.00030
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lund Martin, 2019, JBI Database System Rev Implement Rep, V17, P2265, DOI 10.11124/JBISRIR-2017-003927
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   Nagendran M, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m689
   Nogueira-Rodriguez A, 2021, NEUROCOMPUTING, V423, P721, DOI 10.1016/j.neucom.2020.02.123
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sanchez-Peralta LF, 2018, BRIT J SURG, V105, P5
   Sanchez-Peralta LF, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101923
   Sanchez-Peralta LF, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8081316
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Tajbakhsh N, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101693
   Thambawita Vajira, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3386295
   Tripathi B, 2015, LIGHT HARVESTING NANOMATERIALS, P3
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   Wiegering A, 2016, INT J COLORECTAL DIS, V31, P1039, DOI 10.1007/s00384-015-2501-6
NR 44
TC 21
Z9 21
U1 1
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD DEC
PY 2020
VL 10
IS 23
AR 8501
DI 10.3390/app10238501
PG 13
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA PC6BW
UT WOS:000597085000001
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Shi, TY
   Jiang, HY
   Zheng, B
AF Shi, Tianyu
   Jiang, Huiyan
   Zheng, Bin
TI A Stacked Generalization U-shape network based on zoom strategy and its
   application in biomedical image segmentation
SO COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
LA English
DT Article
DE Biomedical image segmentation; Convolutional neural network; Deep
   supervision; Stacked generalization; Zoom loss function
AB Background and objective: The deep neural network model can learn complex non-linear relationships in the data and has superior flexibility and adaptability. A downside of this flexibility is that they are sensitive to initial conditions, both in terms of the initial random weights and in terms of the statistical noise in the training dataset. And the disadvantage caused by adaptability is that deep convolutional networks usually have poor robustness or generalization when the models are trained using the extremely limited amount of labeled data, especially in the biomedical imaging informatics field.
   Methods: In this paper, we propose to develop and test a stacked generalization U-shape network (SG-UNet) based on the zoom strategy applying to biomedical image segmentation. SG-UNet is essentially a stacked generalization architecture consisting of multiple sub-modules, which takes multi-resolution images as input and uses hybrid features to segment regions of interest and detect diseases under the multi-supervision. The proposed new SG-UNet applies the zoom of multi-supervision to do optimization search in global feature space without pre-training. Besides, the zoom loss function can gradually enhance the focus training on a sparse set of hard samples.
   Results: We evaluated the proposed algorithm in comparison with several popular U-shape ensemble network architectures across multi-modal biomedical image segmentation tasks to segment malignant rectal cancers, polyps and glands from the three imaging modalities of computed tomography (CT), digital colonoscopy and histopathology images. Applying the proposed algorithm improves 3.116%, 2.676%, 2.356% on Dice coefficients, and 3.044%, 2.420%, 1.928% on F2-score for the three imaging modality datasets, respectively. The comparison results using different amounts of rectal cancer CT data show that the proposed algorithm has a slower tendency of diminishing marginal efficiency. And glands segmentation study results also support the feasibility of yielding comparable performance with other state-of-the-art methods.
   Conclusions: The proposed algorithm can be trained more efficiently by using the small image datasets without using additional techniques such as fine-tuning, and achieves higher accuracy with less computational complexity than other stacked ensemble networks for biomedical image segmentation. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Shi, Tianyu; Jiang, Huiyan] Northeastern Univ, Software Coll, Shenyang 110819, Peoples R China.
   [Jiang, Huiyan] Northeastern Univ, Key Lab Intelligent Comp Biomed Image, Minist Educ, Shenyang 110819, Peoples R China.
   [Zheng, Bin] Univ Oklahoma, Sch Elect & Comp Engn, Norman, OK 73019 USA.
C3 Northeastern University - China; Northeastern University - China;
   University of Oklahoma System; University of Oklahoma - Norman
RP Jiang, HY (通讯作者)，Northeastern Univ, Software Coll, Shenyang 110819, Peoples R China.; Jiang, HY (通讯作者)，Northeastern Univ, Key Lab Intelligent Comp Biomed Image, Minist Educ, Shenyang 110819, Peoples R China.
EM hyjiang@mail.neu.edu.cn; Bin.Zheng-1@ou.edu
RI Zheng, Bin/HGU-5316-2022
OI Zheng, Bin/0000-0002-7682-6648
FU National Natural Science Foundation of China [61872075]; China
   Scholarship Council [201906080058]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61872075) and the China Scholarship Council (Contract
   201906080058).
CR Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Albeahdili HM, 2015, INT J ADV COMPUT SC, V6, P79
   Andreini P, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105268
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Graham S, 2019, MED IMAGE ANAL, V52, P199, DOI 10.1016/j.media.2018.12.001
   Guo J., 2018, STACKED DENSE U NETS
   Hacker K, 2019, INT C CYBER WARFARE, P110
   Jiang HY, 2019, IEEE ACCESS, V7, P24898, DOI 10.1109/ACCESS.2019.2899608
   Kr_ahenb_uhl P., 2015, ARXIV PREPRINT ARXIV
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li HM, 2020, IEEE ACCESS, V8, P8004, DOI 10.1109/ACCESS.2019.2963254
   Li SQ, 2018, COMPUT METH PROG BIO, V165, P205, DOI 10.1016/j.cmpb.2018.09.001
   Li ZJ, 2019, LECT NOTES COMPUT SC, V11766, P402, DOI 10.1007/978-3-030-32248-9_45
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lopez MM., 2017, DEEP LEARNING APPL N
   Manivannan S, 2018, IEEE T MED IMAGING, V37, P210, DOI 10.1109/TMI.2017.2750210
   MONDAL AK, 2018, ARXIV181012241
   Neher H, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P313, DOI 10.1109/CRV.2018.00051
   Pinckaers H., 2019, ARXIV191010470
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897
   Sirinukunwattana K, 2017, MED IMAGE ANAL, V35, P489, DOI 10.1016/j.media.2016.08.008
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Taghanaki S. A., 2019, ARXIV191007655
   Tang ZQ, 2020, IEEE T PATTERN ANAL, V42, P2038, DOI 10.1109/TPAMI.2019.2907634
   Wei L, 2020, NEUROCOMPUTING, V383, P1, DOI 10.1016/j.neucom.2019.11.093
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yan Xu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P496, DOI 10.1007/978-3-319-46723-8_57
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yuyin Zhou, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P222, DOI 10.1007/978-3-319-66179-7_26
   Zhang J., 2018, ARXIV181200352
   Zhang YX, 2019, IEEE IJCNN
   Zheng H, 2019, AAAI CONF ARTIF INTE, P5909
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhuang J, 2018, ARXIV181007810
NR 39
TC 16
Z9 16
U1 3
U2 15
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0169-2607
EI 1872-7565
J9 COMPUT METH PROG BIO
JI Comput. Meth. Programs Biomed.
PD DEC
PY 2020
VL 197
AR 105678
DI 10.1016/j.cmpb.2020.105678
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Engineering, Biomedical; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA OZ3IQ
UT WOS:000594824200001
PM 32791449
DA 2023-08-21
ER

PT J
AU Wimmer, G
   Hafner, M
   Uhl, A
AF Wimmer, Georg
   Haefner, Michael
   Uhl, Andreas
TI Improving CNN training on endoscopic image data by extracting
   additionally training data from endoscopic videos
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Article
DE Computer assisted diagnosis; Endoscopy; Colonic polyps; Convolutional
   neural networks; Augmentation
ID CLASSIFICATION
AB In this work we present a technique to deal with one of the biggest problems for the application of convolutional neural networks (CNNs) in the area of computer assisted endoscopic image diagnosis, the insufficient amount of training data. Based on patches from endoscopic images of colonic polyps with given label information, our proposed technique acquires additional (labeled) training data by tracking the area shown in the patches through the corresponding endoscopic videos and by extracting additional image patches from frames of these areas. So similar to the widely used augmentation strategies, additional training data is produced by adding images with different orientations, scales and points of view than the original images. However, contrary to augmentation techniques, we do not artificially produce image data but use real image data from videos under different image recording conditions (different viewpoints and image qualities). By means of our proposed method and by filtering out all extracted images with insufficient image quality, we are able to increase the amount of labeled image data by factor 39. We will show that our proposed method clearly and continuously improves the performance of CNNs.
C1 [Wimmer, Georg; Uhl, Andreas] Univ Salzburg, Dept Comp Sci, Jakob Haringerstr 2, A-5020 Salzburg, Austria.
   [Haefner, Michael] St Elizabeth Hosp, Dept Gastroenterol & Hepatol, Landstrasser Hauptstr 4a, A-1030 Vienna, Austria.
C3 Salzburg University
RP Wimmer, G (通讯作者)，Univ Salzburg, Dept Comp Sci, Jakob Haringerstr 2, A-5020 Salzburg, Austria.
EM gwimmer@cs.sbg.ac
FU Austrian Science Fund, FWF KLI project [429]
FX This work is supported by the Austrian Science Fund, FWF KLI project429.
CR Asperti A., 2018, P 11 INT JOINT C BIO, V0006730901990205
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Brandao P., 2018, J MED ROBOT, V3
   BriechleHanebeck K. U., 2001, P SPIE INT SOC OPTIC, V4387, DOI [10.1117/12421129, DOI 10.1117/12421129]
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Du W., 2019, IEEE ACCESS, DOI [10.1109/ACCESS.2010.2914676, DOI 10.1109/ACCESS.2010.2914676]
   Hafner M., 2018, P OAGM WORKSH 2018 O
   He K., 2015, ABS151203385 CORR
   Islam AR, 2018, PROCEEDINGS OF 2018 3RD INTERNATIONAL CONFERENCE ON BIOMEDICAL IMAGING, SIGNAL PROCESSING (ICBSP 2018), P49, DOI 10.1145/3288200.3288207
   Kato S, 2006, WORLD J GASTROENTERO, V12, P1416, DOI 10.3748/wjg.v12.i9.1416
   Kodashima S, 2010, WORLD J GASTROENTERO, V16, P1043, DOI 10.3748/wjg.v16.i9.1043
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Mori Y, 2017, ENDOSCOPY, V49
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Paszke A., 2019, ADV NEURAL INFORM PR, V32, P8026, DOI DOI 10.48550/ARXIV.1912.01703
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tamaki T., 2016, ABS160806709 CORR
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Wimmer G., 2017, 2017 IEEE 19 INT WOR, P1, DOI [10.1109/MISP.2017.8122221, DOI 10.1109/MMSP.2017.8122221]
   Wimmer G, 2019, WORLD J GASTROENTERO, V25, P1197, DOI 10.3748/wjg.v25.i10.1197
   Wimmer G, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.034504
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 30
TC 1
Z9 1
U1 0
U2 6
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD DEC
PY 2020
VL 86
AR 101798
DI 10.1016/j.compmedimag.2020.101798
PG 12
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA PB3JV
UT WOS:000596222000007
PM 33075676
OA hybrid
DA 2023-08-21
ER

PT J
AU Ito, H
   Uragami, N
   Miyazaki, T
   Yang, W
   Issha, K
   Matsuo, K
   Kimura, S
   Arai, Y
   Tokunaga, H
   Okada, S
   Kawamura, M
   Yokoyama, N
   Kushima, M
   Inoue, H
   Fukagai, T
   Kamijo, Y
AF Ito, Hiroaki
   Uragami, Naoyuki
   Miyazaki, Tomokazu
   Yang, William
   Issha, Kenji
   Matsuo, Kai
   Kimura, Satoshi
   Arai, Yuji
   Tokunaga, Hiromasa
   Okada, Saiko
   Kawamura, Machiko
   Yokoyama, Noboru
   Kushima, Miki
   Inoue, Haruhiro
   Fukagai, Takashi
   Kamijo, Yumi
TI Highly accurate colorectal cancer prediction model based on Raman
   spectroscopy using patient serum
SO WORLD JOURNAL OF GASTROINTESTINAL ONCOLOGY
LA English
DT Article
DE Colorectal cancer; Raman spectroscopy; Machine learning; Blood; Serum;
   Diagnosis
ID NONINVASIVE DETECTION; CARCINOMA SEQUENCE; OPTICAL DIAGNOSIS;
   PROSTATE-CANCER; BLOOD-SERUM; LABEL-FREE; DISCRIMINATION; SPECTRA;
   TISSUE; CEA
AB BACKGROUND
   Colorectal cancer (CRC) is an important disease worldwide, accounting for the second highest number of cancer-related deaths and the third highest number of new cancer cases. The blood test is a simple and minimally invasive diagnostic test. However, there is currently no blood test that can accurately diagnose CRC.
   AIM
   To develop a comprehensive, spontaneous, minimally invasive, label-free, bloodbased CRC screening technique based on Raman spectroscopy.
   METHODS
   We used Raman spectra recorded using 184 serum samples obtained from patients undergoing colonoscopies. Patients with malignant tumor histories as well as those with cancers in organs other than the large intestine were excluded. Consequently, the specific diseases of 184 patients were CRC (12), rectal neuroendocrine tumor (2), colorectal adenoma (68), colorectal hyperplastic polyp (18), and others (84). We used the 1064-nm wavelength laser for excitation. The power of the laser was set to 200 mW.
   RESULTS
   Use of the recorded Raman spectra as training data allowed the construction of a boosted tree CRC prediction model based on machine learning. Therefore, the generalized R-2 values for CRC, adenomas, hyperplastic polyps, and neuroendocrine tumors were 0.9982, 0.9630, 0.9962, and 0.9986, respectively.
   CONCLUSION
   For machine learning using Raman spectral data, a highly accurate CRC prediction model with a high R-2 value was constructed. We are currently planning studies to demonstrate the accuracy of this model with a large amount of additional data.
C1 [Ito, Hiroaki; Uragami, Naoyuki; Matsuo, Kai; Yokoyama, Noboru; Inoue, Haruhiro] Showa Univ, Ctr Digest Dis, Koto Toyosu Hosp, Tokyo 1358577, Japan.
   [Miyazaki, Tomokazu] JSR Corp, Div Res, Tokyo 1050021, Japan.
   [Yang, William] BaySpec Inc, San Jose, CA 95131 USA.
   [Issha, Kenji] Fuji Tech Res Inc, Yokohama, Kanagawa 2206215, Japan.
   [Kimura, Satoshi] Showa Univ, Northern Yokohama Hosp, Dept Lab Med, Yokohama, Kanagawa 2248503, Japan.
   [Kimura, Satoshi] Showa Univ, Northern Yokohama Hosp, Cent Clin Lab, Yokohama, Kanagawa 2248503, Japan.
   [Arai, Yuji; Okada, Saiko] Showa Univ, Dept Clin Lab, Koto Toyosu Hosp, Tokyo 1358577, Japan.
   [Tokunaga, Hiromasa] Showa Univ Hosp, Dept Clin Lab, Tokyo 1428555, Japan.
   [Tokunaga, Hiromasa] BML Inc, Tokyo 1510051, Japan.
   [Kawamura, Machiko] Saitama Canc Ctr, Dept Hematol, Inamachi, Saitama 3620806, Japan.
   [Kushima, Miki] Showa Univ, Koto Toyosu Hosp, Dept Pathol, Tokyo 1358577, Japan.
   [Fukagai, Takashi] Showa Univ, Koto Toyosu Hosp, Dept Urol, Tokyo 1358577, Japan.
   [Kamijo, Yumi] Showa Univ, Koto Toyosu Hosp, Tokyo 1358577, Japan.
C3 Showa University; JSR Corporation; Showa University; Showa University;
   Showa University; Showa University; BML, Inc.; Showa University; Showa
   University; Showa University
RP Ito, H (通讯作者)，Showa Univ, Koto Toyosu Hosp, Ctr Digest Dis, Dept Surg,Koto Ku, 5-1-38 Toyosu, Tokyo 1358577, Japan.
EM h.ito@med.showa-u.ac.jp
OI Kawamura, Machiko/0000-0002-6138-1690
FU Japanese Society for the Promotion of Science (JSPS) [JP17K09022]
FX Supported by the Japanese Society for the Promotion of Science (JSPS),
   based on the JSPS KAKENHI Grants-in-Aid for Scientific Research (C), No.
   JP17K09022.
CR Bhatti I, 2015, INT J SURG, V16, P123, DOI 10.1016/j.ijsu.2015.03.002
   Chan JW, 2006, BIOPHYS J, V90, P648, DOI 10.1529/biophysj.105.066761
   Chen N, 2017, INT J NANOMED, V12, P5399, DOI 10.2147/IJN.S137756
   Chen YP, 2012, MED PHYS, V39, P5664, DOI 10.1118/1.4747269
   Chen YP, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.6.067003
   Cheng WT, 2005, MICROSC RES TECHNIQ, V68, P75, DOI 10.1002/jemt.20229
   Ciccolallo L, 2005, GUT, V54, P268, DOI 10.1136/gut.2004.044214
   De Gelder J, 2007, J RAMAN SPECTROSC, V38, P1133, DOI 10.1002/jrs.1734
   Desmond BJ, 2020, CANCERS, V12, DOI 10.3390/cancers12010052
   Edwards HGM, 2003, SPECTROCHIM ACTA A, V59, P2301, DOI 10.1016/S1386-1425(03)00073-8
   Farquharson S, 2008, MOLECULES, V13, P2608, DOI 10.3390/molecules13102608
   Feng SY, 2015, BIOMED OPT EXPRESS, V6, P3494, DOI 10.1364/BOE.6.003494
   Filella X, 1991, J Nucl Biol Med, V35, P158
   Gao YF, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21048-y
   Gardiner DJ., 1989, PRACTICAL RAMAN SPEC, P1, DOI [10.1007/978-3-642-74040-4_1, DOI 10.1007/978-3-642-74040-4]
   Hamfjord J, 2019, ANN ONCOL, V30, P1088, DOI 10.1093/annonc/mdz139
   Hastie T., 2009, ELEMENTS STAT LEARNI, V2, P1, DOI DOI 10.1007/978-0-387-84858-7_7
   HILL MJ, 1978, LANCET, V1, P245, DOI 10.1016/S0140-6736(78)90487-7
   Hong Y, 2020, J BIOPHOTONICS, V13, DOI 10.1002/jbio.201960176
   Huang ZW, 2005, PHOTOCHEM PHOTOBIOL, V81, P1219, DOI 10.1562/2005-02-24-RA-449
   Huang ZW, 2003, INT J CANCER, V107, P1047, DOI 10.1002/ijc.11500
   Ito H, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211986
   Ito H, 2015, SCI REP-UK, V5, DOI 10.1038/srep10455
   Ito H, 2014, NANOMED-NANOTECHNOL, V10, P599, DOI 10.1016/j.nano.2013.09.006
   Kanellos I, 2006, COLORECTAL DIS, V8, P436, DOI 10.1111/j.1463-1318.2006.00991.x
   Koljenovic S, 2005, ANAL CHEM, V77, P7958, DOI 10.1021/ac0512599
   Krafft C, 2005, SPECTROCHIM ACTA A, V61, P1529, DOI 10.1016/j.saa.2004.11.017
   Lakshmi RJ, 2002, RADIAT RES, V157, P175, DOI 10.1667/0033-7587(2002)157[0175:TRSFTS]2.0.CO;2
   Lau DP, 2005, LASER SURG MED, V37, P192, DOI 10.1002/lsm.20226
   Li SX, 2015, SCI REP-UK, V5, DOI 10.1038/srep09582
   Li XZ, 2015, APPL SPECTROSC, V69, P1334, DOI 10.1366/14-07829
   Lin D, 2011, OPT EXPRESS, V19, P13565, DOI 10.1364/OE.19.013565
   Malini R, 2006, BIOPOLYMERS, V81, P179, DOI 10.1002/bip.20398
   Mohammadi M, 2012, J CLIN PATHOL, V65, P924, DOI 10.1136/jclinpath-2012-200803
   Morita S, 2004, DIS COLON RECTUM, V47, P227, DOI 10.1007/s10350-003-0041-6
   Murakami T, 2015, MODERN PATHOL, V28, P146, DOI 10.1038/modpathol.2014.41
   Negin BP, 2010, CURR TREAT OPTION ON, V11, P1, DOI 10.1007/s11864-010-0115-3
   NICOLINI A, 1995, CANCER DETECT PREV, V19, P183
   Nijssen A, 2002, J INVEST DERMATOL, V119, P64, DOI 10.1046/j.1523-1747.2002.01807.x
   Notingher I, 2004, J R SOC INTERFACE, V1, P79, DOI 10.1098/rsif.2004.0008
   O Faolain E, 2005, VIB SPECTROSC, V38, P121, DOI 10.1016/j.vibspec.2005.02.013
   Patil CA, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3520132
   Prasetyanti PR, 2013, MOL CANCER, V12, DOI 10.1186/1476-4598-12-126
   Ruiz-Chica AJ, 2004, J RAMAN SPECTROSC, V35, P93, DOI 10.1002/jrs.1107
   Sajan D, 2004, SPECTROCHIM ACTA A, V60, P173, DOI 10.1016/S1386-1425(03)00193-8
   Shao XG, 2017, NANOMED-NANOTECHNOL, V13, P1051, DOI 10.1016/j.nano.2016.12.001
   Shetty G, 2006, BRIT J CANCER, V94, P1460, DOI 10.1038/sj.bjc.6603102
   Shinkins B, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171810
   Short MA, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2209549
   Stone N, 2004, FARADAY DISCUSS, V126, P141, DOI 10.1039/b304992b
   Tan YY, 2017, LIPIDS HEALTH DIS, V16, DOI 10.1186/s12944-017-0465-y
   Vargas-Obieta E, 2016, LASER MED SCI, V31, P1317, DOI 10.1007/s10103-016-1976-x
   Wang GF, 2011, ANAL CHEM, V83, P2554, DOI 10.1021/ac102829b
   Wang J, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.8.087003
   Xiao R, 2016, NANOMED-NANOTECHNOL, V12, P2475, DOI 10.1016/j.nano.2016.07.014
   Xue LL, 2018, INT J NANOMED, V13, P4977, DOI 10.2147/IJN.S167996
   Yang CG, 2017, BMC CANCER, V17, DOI 10.1186/s12885-017-3704-8
   Zhang K, 2018, BIOMED OPT EXPRESS, V9, P4345, DOI 10.1364/BOE.9.004345
NR 58
TC 8
Z9 9
U1 0
U2 17
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1948-5204
J9 WORLD J GASTRO ONCOL
JI World J. Gastrointest. Oncol.
PD NOV 15
PY 2020
VL 12
IS 11
BP 1311
EP 1324
DI 10.4251/wjgo.v12.i11.1311
PG 14
WC Oncology; Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology; Gastroenterology & Hepatology
GA PR9SH
UT WOS:000607570000007
PM 33250963
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Wittenberg, T
   Raithel, M
AF Wittenberg, Thomas
   Raithel, Martin
TI Artificial Intelligence-Based Polyp Detection in Colonoscopy: Where Have
   We Been, Where Do We Stand, and Where Are We Headed?
SO VISCERAL MEDICINE
LA English
DT Review
DE Artificial intelligence; AI; Colonoscopy; Adenoma and polyp detection;
   History
ID PIT-PATTERN-CLASSIFICATION; TEXTURE; ABNORMALITY; VALIDATION; DIAGNOSIS
AB Background: In the past, image-based computer-assisted diagnosis and detection systems have been driven mainly from the field of radiology, and more specifically mammography. Nevertheless, with the availability of large image data collections (known as the "Big Data" phenomenon) in correlation with developments from the domain of artificial intelligence (AI) and particularly so-called deep convolutional neural networks, computer-assisted detection of adenomas and polyps in real-time during screening colonoscopy has become feasible. Summary: With respect to these developments, the scope of this contribution is to provide a brief overview about the evolution of AI-based detection of adenomas and polyps during colonoscopy of the past 35 years, starting with the age of "handcrafted geometrical features" together with simple classification schemes, over the development and use of "texture-based features" and machine learning approaches, and ending with current developments in the field of deep learning using convolutional neural networks. In parallel, the need and necessity of large-scale clinical data will be discussed in order to develop such methods, up to commercially available AI products for automated detection of polyps (adenoma and benign neoplastic lesions). Finally, a short view into the future is made regarding further possibilities of AI methods within colonoscopy. Key Messages: Researchofimage-based lesion detection in colonoscopy data has a 35-year-old history. Milestones such as the Paris nomenclature, texture features, big data, and deep learning were essential for the development and availability of commercial AI-based systems for polyp detection.
C1 [Wittenberg, Thomas] Fraunhofer Inst Integrated Circuits IIS, Erlangen, Germany.
   [Raithel, Martin] Malteser Waldkrankenhaus St Marien, Erlangen, Germany.
C3 Fraunhofer Gesellschaft
RP Wittenberg, T (通讯作者)，Fraunhofer Inst Integrated Circuits IIS, Dept Biomed Engn, Wolfsmantel 33, DE-91054 Erlangen, Germany.
EM thomas.wittenberg@iis.fraunhofer.de
RI Wittenberg, Thomas/AAD-6340-2019; Wittenberg, Thomas/HOF-7801-2023
OI Wittenberg, Thomas/0000-0003-0840-8695; 
CR Abdelhafiz D, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2823-4
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ali S., 2020, ENDOSCOPY DIS DETECT
   Ameling S., 2009, 11th International Congress of the IUPESM. World Congress on Medical Physics and Biomedical Engineering. Image Processing, Biosignal Processing, Modelling and Simulation, Biomechanics, P995, DOI 10.1007/978-3-642-03882-2_265
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chahal D, 2020, GASTROINTEST ENDOSC, V92, P813, DOI 10.1016/j.gie.2020.04.074
   Chettaoui H., 2006, PROC IEEE 3 CAN C CO, P65
   Debesh J, ARXIV191107069V1
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Esgiar AN, 1999, IEE CONF PUBL, P335, DOI 10.1049/cp:19990338
   Hafner M, 2007, PROCEEDINGS OF THE 5TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P516
   Hafner M, 2007, COMP MED SY, P159, DOI 10.1109/CBMS.2007.85
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hafner M., 2007, 2007 IEEE Workshop on Machine Learning for Signal Processing, P99, DOI 10.1109/MLSP.2007.4414289
   Hassan C, 2020, GASTROINTESTINAL END
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Hiremath PS, 2004, LECT NOTES COMPUTER, V3316
   Horsch A, 2003, PROCS WORKSH BILDN S, P263
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Karkanis S, 2000, MINIM INVASIV THER, V9, P225, DOI 10.1080/13645700009169652
   Karkanis S, 1999, P WORKSH MACH LEARN, P59
   KARKANIS SA, 2000, EUROMICRO CONF PROC, pA42, DOI DOI 10.1109/EURMIC.2000.874524
   Karkanis SA, 2000, 4 WORLD MULT SYST CY, VVI, P96
   Klare P, 2017, BIOMED ENG-BIOMED TE, V62, P15, DOI DOI 10.1515/BMT-2017-5003
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Magoulas GD, 2004, APPL SOFT COMPUT, V4, P369, DOI 10.1016/j.asoc.2004.01.005
   Manivannan S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P184, DOI 10.1109/ICCVW.2013.31
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mo X, 1809, ARXIV180901263, DOI 10.1109/ACCESS.2018.2856402
   Mohammed A, 2018, ARXIV180601907V1CSCV
   Munzenmayer C, 2009, INT J CARS, V2, pS368
   Nowack S, 2015, P CURAC 2015 WORKSH, P201
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Phee SJ, 1998, IEEE ENG MED BIOL, V17, P81, DOI 10.1109/51.677173
   Plagianakos VP, 2001, NNESMED 2001 4 INT C, P59
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Rex DK, 2018, GASTROINTEST ENDOSC, V88, P335, DOI 10.1016/j.gie.2018.02.043
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shevchenko N, 2008, TAG 7 JAHR COMP ROB, P205
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Stehle S, 2009, P SOC PHOTO-OPT INS, DOI 10.1117/12.808103
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Tjoa MP, 2003, P ANN INT IEEE EMBS, V25, P710, DOI 10.1109/IEMBS.2003.1279862
   Tjoa MP, 2001, P ANN INT IEEE EMBS, V23, P2665, DOI 10.1109/IEMBS.2001.1017331
   Tjoa MP, 2002, IEEE CCEC 2002: CANADIAN CONFERENCE ON ELECTRCIAL AND COMPUTER ENGINEERING, VOLS 1-3, CONFERENCE PROCEEDINGS, P1177, DOI 10.1109/CCECE.2002.1013115
   Urban G, 2019, GASNOT SIGNTRONOT SI, V155, P1069
   Vorhies W, 2017, DATA SCI CENTRA 0509
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Weigt J, 2020, Z GASTROENTEROL, V58, pe181, DOI [10.1055/s-0040-1716218, DOI 10.1055/S-0040-1716218]
   Wittenberg Thomas, 2019, Current Directions in Biomedical Engineering, V5, P231, DOI 10.1515/cdbme-2019-0059
   Wittenberg T, 1999, SPIE MED IM 2016 COM
   Wittenberg T, 2004, PROCS EFMI SPEC TON, P129
   Yala A, 2019, RADIOLOGY, V292, P60, DOI 10.1148/radiol.2019182716
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
NR 66
TC 4
Z9 4
U1 1
U2 5
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 2297-4725
EI 2297-475X
J9 VISC MED
JI Visc. Med.
PD DEC
PY 2020
VL 36
IS 6
BP 428
EP 438
DI 10.1159/000512438
EA NOV 2020
PG 11
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA PE1UU
UT WOS:000590579300001
PM 33447598
OA Green Published, Bronze
DA 2023-08-21
ER

PT J
AU Wang, XY
   Meng, YF
   Lou, HF
   Wang, KJ
   Wang, CS
   Zhang, L
AF Wang, Xiaoyan
   Meng, Yifan
   Lou, Hongfei
   Wang, Kuiji
   Wang, Chengshuo
   Zhang, Luo
TI Blood eosinophil count combined with asthma history could predict
   chronic rhinosinusitis with nasal polyp recurrence
SO ACTA OTO-LARYNGOLOGICA
LA English
DT Article
DE Asthma; blood eosinophils percentage; chronic rhinosinusitis with nasal
   polyps; endoscopic sinus surgery; machine learning algorithm;
   prediction; recurrence
AB Background
   The use of non-invasive clinical markers for predicting CRS recurrence is still not well investigated.
   Objective
   The aim of this study was to investigate the comprehensive effects of non-invasive clinical markers on the recurrence of CRS with nasal polyps (CRSwNP).
   Materials and methods
   A total of 346 consecutive CRSwNP patients undergoing endoscopic functional sinus surgery were recruited. The demographic characteristics and clinical parameters were recorded. Machine learning algorithm were used for evaluating the predictive value of asthma history and blood eosinophils percentage.
   Results
   Finally, 313/346 patients completed the study. The average follow-up time was 24 months after the first surgery. For the CRSwNP with asthma patients, the blood eosinophils percentage cut-off value was 3.7%. However, for the CRSwNP without asthma patients, the blood eosinophils percentage cut-off value was high, at 6.9%.
   Conclusion
   Combined asthma history and blood eosinophils percentage can predict CRSwNP recurrence, while asthma history can reduce the threshold of blood eosinophils percentage to predict CRSwNP recurrence.
   Significance
   For the CRS patients, combined asthma history and blood eosinophils percentage can predict recurrence, while asthma history can reduce the threshold of blood eosinophils percentage to predict recurrence.
C1 [Wang, Xiaoyan; Meng, Yifan; Lou, Hongfei; Wang, Kuiji; Wang, Chengshuo; Zhang, Luo] Capital Med Univ, Beijing TongRen Hosp, Dept Otolaryngol Head & Neck Surg, Beijing, Peoples R China.
   [Meng, Yifan; Lou, Hongfei; Wang, Kuiji; Wang, Chengshuo; Zhang, Luo] Chinese Acad Med Sci, Res Unit Diag & Treatment Chron Nasal Dis, Beijing, Peoples R China.
   [Zhang, Luo] Beijing Inst Otolaryngol, Beijing Key Lab Nasal Dis, Beijing, Peoples R China.
   [Zhang, Luo] Capital Med Univ, Beijing TongRen Hosp, Dept Allergy, Beijing, Peoples R China.
C3 Capital Medical University; Chinese Academy of Medical Sciences - Peking
   Union Medical College; Capital Medical University
RP Wang, CS (通讯作者)，Capital Med Univ, Beijing TongRen Hosp, Dept Otolaryngol Head & Neck Surg, Beijing, Peoples R China.; Zhang, L (通讯作者)，Beijing Inst Otolaryngol, 17 HouGouHuTong, Beijing 100005, Peoples R China.
EM wangcs830@126.com; dr.luozhang@139.com
OI Zhang, Luo/0000-0002-0910-9884
FU National Natural Science Foundation of China [81900916]; Beijing Nova
   Program [Z201100006820043]; Beijing Municipal Administration of
   Hospitals' Youth Programme [QML20190208]; Priming Scientific Research
   Foundation for the Senior Researcher in Beijing TongRen Hospital,
   Capital Medical University [2017-YJJ-GGL-005]; National Key R&D Program
   of China [2018YFC0116800]; program for Changjiang Scholars and
   Innovative Research Team [IRT13082]; CAMS Innovation Fund for Medical
   Sciences [2019-I2M-5-022]; Beijing municipal administration of
   hospitals' mission plan [SML20150203]; Beijing Municipal Administration
   of hospitals' Dengfeng plan [DFL20190202]; Beijing Municipal
   Administration of hospitals clinical medicine development of special
   funding support [XMLX201816]
FX This work was supported by grants from the National Natural Science
   Foundation of China (81900916), Beijing Nova Program (Z201100006820043),
   Beijing Municipal Administration of Hospitals' Youth Programme
   (QML20190208), the Priming Scientific Research Foundation for the Senior
   Researcher in Beijing TongRen Hospital, Capital Medical University
   (2017-YJJ-GGL-005), National Key R&D Program of China (2018YFC0116800),
   the program for Changjiang Scholars and Innovative Research Team
   (IRT13082), Beijing municipal administration of hospitals' mission plan
   (SML20150203), Beijing Municipal Administration of hospitals' Dengfeng
   plan (DFL20190202), Beijing Municipal Administration of hospitals
   clinical medicine development of special funding support (XMLX201816),
   CAMS Innovation Fund for Medical Sciences (2019-I2M-5-022).
CR Bateman, 2020, GLOB STRAT ASTHM MAN, P1
   Boulet LP, 2015, CURR OPIN PULM MED, V21, P1, DOI 10.1097/MCP.0000000000000125
   Brescia G, 2019, ACTA OTO-LARYNGOL, V139, P48, DOI 10.1080/00016489.2018.1538567
   Brescia G, 2017, INT FORUM ALLERGY RH, V7, P261, DOI 10.1002/alr.21885
   Bukstein D, 2011, ALLERGY ASTHMA PROC, V32, P185, DOI 10.2500/aap.2011.32.3449
   Davis J., 2006, P 23 INT C MACH LEAR, P233, DOI [10.1145/1143844.1143874, DOI 10.1145/1143844.1143874]
   DeConde AS, 2017, LARYNGOSCOPE, V127, P550, DOI 10.1002/lary.26391
   Dweik RA, 2010, AM J RESP CRIT CARE, V181, P1033, DOI 10.1164/rccm.200905-0695OC
   Fokkens WJ, 2012, RHINOLOGY, V50, P1, DOI 10.4193/Rhin20.600
   Guo M, 2018, AM J RHINOL ALLERGY, V32, P440, DOI 10.1177/1945892418793523
   Honma A, 2016, J LARYNGOL OTOL, V130, P1147, DOI 10.1017/S0022215116009324
   Lou HF, 2016, RHINOLOGY, V54, P150, DOI [10.4193/Rhino15.271, 10.4193/Rhin15.271]
   Lou HF, 2015, AM J RHINOL ALLERGY, V29, P350, DOI 10.2500/ajra.2015.29.4231
   Meng YF, 2019, INT FORUM ALLERGY RH, V9, P1236, DOI 10.1002/alr.22355
   Meng YF, 2016, INT FORUM ALLERGY RH, V6, P812, DOI 10.1002/alr.21749
   Noda N, 2012, AM J RHINOL ALLERGY, V26, P255, DOI 10.2500/ajra.2012.26.3772
   Wang KJ, 2014, INT ARCH ALLERGY IMM, V163, P51, DOI 10.1159/000356317
   Wang XD, 2016, J ALLERGY CLIN IMMUN, V138, P1344, DOI 10.1016/j.jaci.2016.05.041
   Zhang N, 2008, J ALLERGY CLIN IMMUN, V122, P961, DOI 10.1016/j.jaci.2008.07.008
NR 19
TC 49
Z9 53
U1 1
U2 14
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0001-6489
EI 1651-2251
J9 ACTA OTO-LARYNGOL
JI Acta Oto-Laryngol.
PD MAR 1
PY 2021
VL 141
IS 3
BP 279
EP 285
DI 10.1080/00016489.2020.1844288
EA NOV 2020
PG 7
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology
GA QQ1VR
UT WOS:000597860500001
PM 33302768
DA 2023-08-21
ER

PT J
AU Zammit, SC
   Sidhu, R
AF Chetcuti Zammit, Stefania
   Sidhu, Reena
TI Capsule endoscopy - Recent developments and future directions
SO EXPERT REVIEW OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Review
DE Small-bowel capsule endoscopy; Crohn&#8217; s capsule endoscopy;
   artificial intelligence; magnetically controlled upper gastrointestinal
   capsule; colon capsule endoscopy
ID MAGNETICALLY GUIDED CAPSULE; DEVICE-ASSISTED ENTEROSCOPY; DISORDERS
   EUROPEAN-SOCIETY; CROHNS-DISEASE; DIAGNOSTIC YIELD; COLONOSCOPY; 1ST;
   GASTROSCOPY; EXPERIENCE; ACCURACY
AB Introduction
   Capsule endoscopy (CE) is an established modality in the diagnostic algorithm of small bowel (SB) pathology. Its use has expanded for investigation of upper and lower gastrointestinal diseases with similar prototypes.
   Areas covered
   This review covers the role and recent advances of CE, as a non-invasive investigative tool.
   Expert opinion
   The use of upper gastrointestinal CE is useful in patients who require surveillance for varices particularly in the current era of the COVID-19 pandemic. It has also shown high accuracy in the detection of upper gastrointestinal hemorrhage in patients presenting with a suspicion of hemorrhage. Findings on CE help to guide further management by device-assisted enteroscopy. The data on colon CE suggest comparable diagnostic accuracy to colonoscopy for polyp detection; however, more evidence is required in the high-risk group. Crohn's CE has become an integral part of the management of patients with Crohn's disease offering a comparative assessment tool post escalation of therapy. Artificial intelligence within CE has demonstrated similar if not better diagnostic yield compared to the human with a significantly shorter reading time. Artificial intelligence is likely to be in-built within CE reading platforms over the next few years minimizing reporting time and human error.
C1 [Chetcuti Zammit, Stefania; Sidhu, Reena] Royal Hallamshire Hosp, Acad Dept Gastroenterol, Sheffield, S Yorkshire, England.
C3 N8 Research Partnership; White Rose University Consortium; University of
   Sheffield
RP Zammit, SC (通讯作者)，Sheffield Teaching Hosp, Royal Hallamshire Hosp, Acad Dept Gastroenterol, Sheffield S10 2JF, S Yorkshire, England.
EM stf_che@yahoo.com
RI Chetcuti Zammit, Stefania/GPK-5290-2022
OI Chetcuti Zammit, Stefania/0000-0002-1361-2204
CR Aasen T, 2019, CANCERS, V11, DOI 10.3390/cancers11030320
   Aggarwal V, 2017, GASTROINTEST ENDOSC, V86, P1070, DOI 10.1016/j.gie.2017.09.011
   Al-Bawardy B, 2015, INFLAMM BOWEL DIS, V21, P2158, DOI 10.1097/MIB.0000000000000482
   Albert JG, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000001941
   [Anonymous], 2017, RHEUMATOLOGY, V56, pe22
   [Anonymous], 2020, CLIN GUIDE TRIAGING
   Assadsangabi A, 2015, J GASTROEN HEPATOL, V30, P984, DOI 10.1111/jgh.12891
   Atlas DS, 2011, GASTROINTEST ENDOSC, V74, P1315, DOI 10.1016/j.gie.2011.05.049
   Baichi MM, 2006, GASTROINTEST ENDOSC, V64, P283, DOI 10.1016/j.gie.2006.02.036
   Bar-Gil Shitrit A, 2017, SCAND J GASTROENTERO, V52
   Barret M, 2012, AM J GASTROENTEROL, V107, P1546, DOI 10.1038/ajg.2012.199
   Belsey J, 2012, CURR MED RES OPIN, V28, P1883, DOI 10.1185/03007995.2012.747953
   Ben-Horin S, 2019, LANCET GASTROENTEROL, V4, P519, DOI 10.1016/S2468-1253(19)30088-3
   Bhardwaj A, 2009, AM J GASTROENTEROL, V104, P1533, DOI 10.1038/ajg.2009.86
   Branchi F, 2020, DIGEST ENDOSC, V32, P778, DOI 10.1111/den.13575
   Bruining DH, 2020, BMJ OPEN GASTROENTER, V7, DOI 10.1136/bmjgast-2019-000365
   Cave D, 2005, ENDOSCOPY, V37, P1065, DOI 10.1055/s-2005-870264
   Chak A, 2014, GASTROINTEST ENDOSC, V80, P774, DOI 10.1016/j.gie.2014.04.034
   Chandran S, 2013, GASTROINTEST ENDOSC, V77, P891, DOI 10.1016/j.gie.2013.01.003
   Chetcuti Zammit S, 2020, CLIN RES HEPATOL GAS, V44, P753
   Chetcuti Zammit S, 2019, J GASTROINTESTIN LIV, V28
   Chetcuti Zammit S, 2020, TECH COLOPROCTOL, V24
   Chetcuti Zammit S, 2020, DIG ENDOSC, V32, P823
   Ching HL, 2019, GASTROINTEST ENDOSC, V90, P430, DOI 10.1016/j.gie.2019.04.248
   Ching HL, 2019, ENDOSCOPY, V51, P409, DOI 10.1055/a-0750-5682
   Ching HL, 2018, WORLD J GASTROENTERO, V24, P2893, DOI 10.3748/wjg.v24.i26.2893
   Colli A, 2014, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008760.pub2
   Culliford A, 2005, GASTROINTEST ENDOSC, V62, P55, DOI 10.1016/S0016-5107(05)01566-X
   Daum S, 2007, ENDOSCOPY, V39, P455, DOI 10.1055/s-2007-966239
   De Palma Giovanni D, 2012, J Med Case Rep, V6, P121, DOI 10.1186/1752-1947-6-121
   Denzer UW, 2015, J CLIN GASTROENTEROL, V49, P101, DOI 10.1097/MCG.0000000000000110
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Valenzuela JE, 2016, REV ESP ENFERM DIG, V108, P394, DOI 10.17235/reed.2016.4318/2016
   Valenzuela JE, 2015, REV ESP ENFERM DIG, V107, P211
   Eliakim R, 2018, ENDOSC INT OPEN, V6, pE1235, DOI 10.1055/a-0677-170
   Ell C, 2002, ENDOSCOPY, V34, P685, DOI 10.1055/s-2002-33446
   Endo H, 2017, J GASTROENTEROL, V52, P194, DOI 10.1007/s00535-016-1212-2
   Friedrich K, 2013, J GASTROEN HEPATOL, V28, P1496, DOI 10.1111/jgh.12280
   Galloro G, 2020, DIG LIVER DIS, V52
   Gastineau S, 2012, DIGEST LIVER DIS, V44, P839, DOI 10.1016/j.dld.2012.05.018
   Gay G, 2006, ENDOSCOPY, V38, P49, DOI 10.1055/s-2005-921176
   Gilbert D, 2008, J GASTROEN HEPATOL, V23, P1806, DOI 10.1111/j.1440-1746.2008.05643.x
   Gomes C, 2018, WORLD J GASTRO ENDOS, V10, P74, DOI 10.4253/wjge.v10.i4.74
   Gonzalez-Suarez B, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01717-4
   Gupta S, 2020, GASTROINTEST ENDOSC, V92, P735, DOI 10.1016/j.gie.2020.04.050
   Hale MF, 2016, EUR J GASTROEN HEPAT, V28, P1145, DOI 10.1097/MEG.0000000000000696
   Hansel SL, 2020, GASTROENTEROL REP, V8, P31, DOI 10.1093/gastrol/goz054
   Hartmann D, 2005, GASTROINTEST ENDOSC, V61, P826, DOI 10.1016/S0016-5107(05)00372-X
   Hashimoto R, 2020, GASTROINTEST ENDOSC, V91, P1264, DOI 10.1016/j.gie.2019.12.049
   Hassan C, 2021, DIGEST ENDOSC, V33, P285, DOI 10.1111/den.13807
   Hawkes E, 2019, GUT, V68, pA165, DOI 10.1136/gutjnl-2019-BSGAbstracts.316
   Holleran G, 2014, ENDOSCOPY, V46, P473, DOI 10.1055/s-0034-1365402
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Judge C, 2019, ENDOSC INT OPEN, V7, pE1379, DOI 10.1055/a-0990-9225
   KJOLHEDE T, 2020, ENDOSCOPY 0828, VOnli
   Kopylov U, 2016, EUR J GASTROEN HEPAT, V28, P1137, DOI 10.1097/MEG.0000000000000692
   Kopylov U, 2015, AM J GASTROENTEROL, V110, P1316, DOI 10.1038/ajg.2015.221
   Krijbolder MS, 2018, NETH J MED, V76, P27
   Le Berre C, 2019, WORLD J GASTROENTERO, V25, P4534, DOI 10.3748/wjg.v25.i31.4534
   Leighton JA, 2017, GASTROINTEST ENDOSC, V85, P196, DOI 10.1016/j.gie.2016.09.009
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Li X, 2009, ENDOSCOPY, V41, P762, DOI 10.1055/s-0029-1215009
   Liao ZA, 2010, GASTROINTEST ENDOSC, V71, P280, DOI 10.1016/j.gie.2009.09.031
   Lin OS, 2007, GASTROINTEST ENDOSC, V65, P725, DOI 10.1016/j.gie.2006.11.033
   Lobo A, 2020, INT J QUAL HEALTH C, V32, P332, DOI 10.1093/intqhc/mzaa039
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P821, DOI 10.1016/j.gie.2020.06.034
   Maaser C, 2019, J CROHNS COLITIS, V13, P144, DOI 10.1093/ecco-jcc/jjy113
   MacLeod C, 2020, COLORECTAL DIS, V22, P621, DOI 10.1111/codi.15134
   Maiden L, 2009, DIGEST DIS SCI, V54, P1280, DOI 10.1007/s10620-008-0486-5
   Maiden L, 2005, GASTROENTEROLOGY, V128
   Makipour K, 2014, DIGEST ENDOSC, V26, P646, DOI 10.1111/den.12243
   Marya NB, GASTROINTEST ENDOSC, V89, P33
   McCarty TR, 2017, J CLIN GASTROENTEROL, V51, P174, DOI 10.1097/MCG.0000000000000589
   Meltzer AC, 2014, AM J EMERG MED, V32, P823, DOI 10.1016/j.ajem.2013.11.012
   MIROCAM MC, 2000, CAPSULE SYN MED LTD
   Mitsui K, 2016, J CLIN GASTROENTEROL, V50, P141, DOI 10.1097/MCG.0000000000000335
   Monteiro S, 2018, INFLAMM BOWEL DIS, V24, P2033, DOI 10.1093/ibd/izy098
   Mowat C, 2019, BMJ OPEN GASTROENTER, V6, DOI 10.1136/bmjgast-2019-000293
   Nemeth A, 2017, UNITED EUR GASTROENT, V5, P677, DOI 10.1177/2050640616675219
   Ojidu H, 2018, EUR J GASTROEN HEPAT, V30, P520, DOI 10.1097/MEG.0000000000001090
   Pan, 2020, GASTROINTEST ENDOSC, V91
   Papamichael K, 2015, ANN GASTROENTEROL, V28, P464
   Pasha SF, 2020, INFLAMM BOWEL DIS, V26, P33, DOI 10.1093/ibd/izz083
   Pennazio M, 2015, ENDOSCOPY, V47, P352, DOI 10.1055/s-0034-1391855
   Perez-Cuadrado-Robles E, 2018, DIG ENDOSC, V30
   Physicians RCo, JOINT ADV GROUP GI E
   Pioche M, 2014, ENDOSCOPY, V46, P479, DOI 10.1055/s-0033-1358832
   Pioche M, 2011, GASTROINTEST ENDOSC, V73, P1181, DOI 10.1016/j.gie.2011.02.011
   Placone N, 2020, CLIN ENDOSC, V53, P713, DOI 10.5946/ce.2019.213
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   Postgate A, 2008, ENDOSCOPY, V40, P496, DOI 10.1055/s-2007-995590
   Postgate A, 2009, GASTROINTEST ENDOSC, V70
   Qian YY, 2018, DIGEST LIVER DIS, V50, P1041, DOI 10.1016/j.dld.2018.04.013
   Rey JF, 2012, GASTROINTEST ENDOSC, V75, P373, DOI 10.1016/j.gie.2011.09.030
   Rezapour M, 2017, GASTROINTEST ENDOSC, V85, P1157, DOI 10.1016/j.gie.2016.12.024
   Rommele C, 2017, GASTROENT RES PRACT, V2017, DOI 10.1155/2017/4969814
   Rondonotti E, 2018, ENDOSCOPY, V50, P423, DOI 10.1055/a-0576-0566
   Rondonotti E, 2014, CLIN GASTROENTEROL H, V12, P1303, DOI 10.1016/j.cgh.2013.12.027
   S Ct B, 2018, GUT, V6
   Shah K, 2020, AM J EMERG MED, V38, DOI 10.1016/j.ajem.2020.04.075
   Shirasawa T, 2015, HEPATO-GASTROENTEROL, V62, P240, DOI 10.5754/hge14860
   Sidhu R, 2020, ENDOSCOPY, V52
   Sidhu R, 2007, GASTROENTEROL NURS, V30, P45, DOI 10.1097/00001610-200701000-00005
   Singh A, 2013, GASTROINTEST ENDOSC, V77, P761, DOI 10.1016/j.gie.2012.11.041
   Singh R, 2019, INT J INTELL UNMANNE, V7, P2, DOI 10.1108/IJIUS-05-2018-0013
   Soffer S, 2020, GASTROINTEST ENDOSC, V92, P831, DOI 10.1016/j.gie.2020.04.039
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Spada C, 2016, CLIN GASTROENTEROL H, V14, P1533, DOI 10.1016/j.cgh.2016.04.038
   Spada C, 2015, GUT, V64, P272, DOI 10.1136/gutjnl-2013-306550
   Sung JJY, 2016, GASTROINTEST ENDOSC, V84, P907, DOI 10.1016/j.gie.2016.04.043
   Tai FWD, 2021, UNITED EUR GASTROENT, V9, P248, DOI 10.1177/2050640620948664
   Teshima CW, 2011, J GASTROEN HEPATOL, V26, P796, DOI 10.1111/j.1440-1746.2010.06530.x
   Thygesen MK, 2019, ACTA ONCOL, V58, pS71, DOI 10.1080/0284186X.2019.1581372
   Tomba C, 2016, J CLIN GASTROENTEROL, V50, P313, DOI 10.1097/MCG.0000000000000424
   Tontini GE, 2020, BMC GASTROENTEROL, V20, DOI 10.1186/s12876-020-01231-0
   Tontini GE, 2017, GASTROINTEST ENDOSC, V85, P401, DOI 10.1016/j.gie.2016.07.063
   Tontini GE, 2014, ENDOSCOPY, V46, DOI 10.1055/s-0034-1377358
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Toth E, 2017, ANN TRANSL MED, V5, DOI 10.21037/atm.2017.03.91
   Tun GSZ, 2016, EUR J GASTROEN HEPAT, V28, P820, DOI 10.1097/MEG.0000000000000629
   Uchida G, 2021, DIGEST ENDOSC, V33, P66, DOI 10.1111/den.13669
   Urquhart P, 2014, FAM CANCER, V13, P249, DOI 10.1007/s10689-014-9700-0
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vicnesh J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1285-6
   Vlachogiannakos J, 2011, DIG DIS SCI, V56
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang YC, 2019, DIGEST DIS SCI, V64, P1297, DOI 10.1007/s10620-018-5415-7
   Wu S, 2020, J GASTROEN HEPATOL, V35, P634, DOI 10.1111/jgh.14899
   Xavier S, 2019, DIGEST LIVER DIS, V51, P1388, DOI 10.1016/j.dld.2019.04.014
   Xavier S, 2018, REV ESP ENFERM DIG, V110, P155, DOI 10.17235/reed.2017.5071/2017
   Yamada A, 2012, HEPATO-GASTROENTEROL, V59, P676, DOI 10.5754/hge12180
   Yousuf H, 2018, DIGEST DIS, V36, P202, DOI 10.1159/000485375
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P979, DOI 10.1080/17474124.2017.1359540
   Yung DE, 2017, ENDOSCOPY, V49, P258, DOI 10.1055/s-0042-122015
   Zhang TH, 2018, CRYST RES TECHNOL, V53, DOI 10.1002/crat.201800147
   Zhang Wenchao, 2014, BMC Bioinformatics, V15 Suppl 11, pS5, DOI 10.1186/1471-2105-15-S11-S5
   Zhao AJ, 2018, GASTROINTEST ENDOSC, V88, P466, DOI 10.1016/j.gie.2018.05.003
   Zhu SG, 2018, DIGEST LIVER DIS, V50, P42, DOI 10.1016/j.dld.2017.09.129
   Zou WB, 2015, ENDOSCOPY, V47, P526, DOI 10.1055/s-0034-1391123
NR 139
TC 21
Z9 21
U1 2
U2 19
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1747-4124
EI 1747-4132
J9 EXPERT REV GASTROENT
JI Expert Rev. Gastroenterol. Hepatol.
PD FEB 1
PY 2021
VL 15
IS 2
BP 127
EP 137
DI 10.1080/17474124.2021.1840351
EA NOV 2020
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA QE4WF
UT WOS:000584058700001
PM 33111600
OA Bronze
DA 2023-08-21
ER

PT J
AU Uemura, T
   Nappi, JJ
   Ryu, Y
   Watari, C
   Kamiya, T
   Yoshida, H
AF Uemura, Tomoki
   Nappi, Janne J.
   Ryu, Yasuji
   Watari, Chinatsu
   Kamiya, Tohru
   Yoshida, Hiroyuki
TI A generative flow-based model for volumetric data augmentation in 3D
   deep learning for computed tomographic colonography
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article
DE Generative models; Data augmentation; Deep learning; Computer-aided
   detection; Virtual colonoscopy; Artificial intelligence
ID CT COLONOGRAPHY; COLONOSCOPY; NEOPLASIA; ACCURACY; POLYPS
AB Purpose Deep learning can be used for improving the performance of computer-aided detection (CADe) in various medical imaging tasks. However, in computed tomographic (CT) colonography, the performance is limited by the relatively small size and the variety of the available training datasets. Our purpose in this study was to develop and evaluate a flow-based generative model for performing 3D data augmentation of colorectal polyps for effective training of deep learning in CADe for CT colonography. Methods We developed a 3D-convolutional neural network (3D CNN) based on a flow-based generative model (3D Glow) for generating synthetic volumes of interest (VOIs) that has characteristics similar to those of the VOIs of its training dataset. The 3D Glow was trained to generate synthetic VOIs of polyps by use of our clinical CT colonography case collection. The evaluation was performed by use of a human observer study with three observers and by use of a CADe-based polyp classification study with a 3D DenseNet. Results The area-under-the-curve values of the receiver operating characteristic analysis of the three observers were not statistically significantly different in distinguishing between real polyps and synthetic polyps. When trained with data augmentation by 3D Glow, the 3D DenseNet yielded a statistically significantly higher polyp classification performance than when it was trained with alternative augmentation methods. Conclusion The 3D Glow-generated synthetic polyps are visually indistinguishable from real colorectal polyps. Their application to data augmentation can substantially improve the performance of 3D CNNs in CADe for CT colonography. Thus, 3D Glow is a promising method for improving the performance of deep learning in CADe for CT colonography.
C1 [Uemura, Tomoki; Nappi, Janne J.; Watari, Chinatsu; Yoshida, Hiroyuki] Massachusetts Gen Hosp, Dept Radiol, 3D Imaging Res, 25 New Chardon St,Suite 400C, Boston, MA 02114 USA.
   [Uemura, Tomoki; Nappi, Janne J.; Watari, Chinatsu; Yoshida, Hiroyuki] Harvard Med Sch, 25 New Chardon St,Suite 400C, Boston, MA 02114 USA.
   [Uemura, Tomoki; Kamiya, Tohru] Kyushu Inst Technol, Dept Mech & Control Engn, 1-1 Sensui Cho, Kitakyushu, Fukuoka 8048550, Japan.
   [Ryu, Yasuji] Tonami Gen Hosp, Dept Radiol, 1-61 Shintomi Cho, Tonami, Toyama 9391395, Japan.
C3 Harvard University; Massachusetts General Hospital; Harvard University;
   Harvard Medical School; Kyushu Institute of Technology
RP Yoshida, H (通讯作者)，Massachusetts Gen Hosp, Dept Radiol, 3D Imaging Res, 25 New Chardon St,Suite 400C, Boston, MA 02114 USA.; Yoshida, H (通讯作者)，Harvard Med Sch, 25 New Chardon St,Suite 400C, Boston, MA 02114 USA.
EM yoshida.hiro@mgh.harvard.edu
RI Nappi, Janne/B-9424-2008
OI Nappi, Janne/0000-0002-0108-0992
FU National Institutes of Health (NIH) [R01CA212382, R01EB023942]
FX This study was supported partly by the National Institutes of Health
   (NIH) under Award Nos. R01CA212382 and R01EB023942. The content is
   solely the responsibility of the authors and does not necessarily
   represent the official views of the NIH. J.J.N. and H.Y. are
   co-inventors of electronic cleansing and computer-aided detection
   software patents.
CR Chen YZ, 2018, IEEE ENG MED BIO, P678, DOI 10.1109/EMBC.2018.8512305
   Dinh L., 2017, INT C LEARNING REPRE
   Dinh L, 2014, TECHNICAL REPORT
   Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996
   Kingma D, 2018, 32 C NEUR INF PROC S, P10235
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Nappi J, 2008, MED IMAGE ANAL, V12, P413, DOI 10.1016/j.media.2008.01.001
   Nappi JJ, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217260
   Nagata K, 2009, ACAD RADIOL, V16, P780, DOI 10.1016/j.acra.2008.12.027
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   Nappi J, 2017, SPIE MED IMAGING COM, V10575, P1057518
   Nappi J, 2017, INT J CARS, V12S1, P144
   Nappi J, 2007, ACAD RADIOL, V14, P287, DOI 10.1016/j.acra.2006.11.007
   Nappi JJ, 2020, PROC SPIE, V11314, DOI 10.1117/12.2549793
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   R Core Team, 2014, R LANG ENV STAT COMP
   Regge D, 2013, EUR J RADIOL, V82, P1171, DOI 10.1016/j.ejrad.2012.04.022
   Regge D, 2009, JAMA-J AM MED ASSOC, V301, P2453, DOI 10.1001/jama.2009.832
   Robin X, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-77
   Rockey DC, 2005, LANCET, V365, P305
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Shin HC, 2018, LECT NOTES COMPUT SC, V11037, P1, DOI 10.1007/978-3-030-00536-8_1
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Siu AL, 2016, ANN INTERN MED, V164, P279, DOI 10.7326/M15-2886
   Tachibana R, 2018, RADIOGRAPHICS, V38, P2034, DOI 10.1148/rg.2018170173
   Uemura T, 2018, INT J CARS, V13S1, P94
   Uemura T., 2019, P SPIE
   Uemura T, 2020, PROC SPIE, V11314, DOI 10.1117/12.2549103
   Winawer SJ, 1997, GASTROENTEROLOGY, V112, P594, DOI 10.1053/gast.1997.v112.agast970594
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
NR 32
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD JAN
PY 2021
VL 16
IS 1
BP 81
EP 89
DI 10.1007/s11548-020-02275-z
EA NOV 2020
PG 9
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA PV6NE
UT WOS:000585754500001
PM 33150471
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Nguyen, DT
   Lee, MB
   Pham, TD
   Batchuluun, G
   Arsalan, M
   Park, KR
AF Dat Tien Nguyen
   Lee, Min Beom
   Tuyen Danh Pham
   Batchuluun, Ganbayar
   Arsalan, Muhammad
   Park, Kang Ryoung
TI Enhanced Image-Based Endoscopic Pathological Site Classification Using
   an Ensemble of Deep Learning Models
SO SENSORS
LA English
DT Article
DE pathological site classification; in vivo endoscopy; computer-aided
   diagnosis; artificial intelligence; ensemble learning
ID NETWORK-BASED METHOD; SEGMENTATION; CNN
AB In vivo diseases such as colorectal cancer and gastric cancer are increasingly occurring in humans. These are two of the most common types of cancer that cause death worldwide. Therefore, the early detection and treatment of these types of cancer are crucial for saving lives. With the advances in technology and image processing techniques, computer-aided diagnosis (CAD) systems have been developed and applied in several medical systems to assist doctors in diagnosing diseases using imaging technology. In this study, we propose a CAD method to preclassify the in vivo endoscopic images into negative (images without evidence of a disease) and positive (images that possibly include pathological sites such as a polyp or suspected regions including complex vascular information) cases. The goal of our study is to assist doctors to focus on the positive frames of endoscopic sequence rather than the negative frames. Consequently, we can help in enhancing the performance and mitigating the efforts of doctors in the diagnosis procedure. Although previous studies were conducted to solve this problem, they were mostly based on a single classification model, thus limiting the classification performance. Thus, we propose the use of multiple classification models based on ensemble learning techniques to enhance the performance of pathological site classification. Through experiments with an open database, we confirmed that the ensemble of multiple deep learning-based models with different network architectures is more efficient for enhancing the performance of pathological site classification using a CAD system as compared to the state-of-the-art methods.
C1 [Dat Tien Nguyen; Lee, Min Beom; Tuyen Danh Pham; Batchuluun, Ganbayar; Arsalan, Muhammad; Park, Kang Ryoung] Dongguk Univ, Div Elect & Elect Engn, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.
C3 Dongguk University
RP Batchuluun, G (通讯作者)，Dongguk Univ, Div Elect & Elect Engn, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.
EM nguyentiendat@dongguk.edu; mblee@dongguk.edu; phamdanhtuyen@dongguk.edu;
   ganabata87@dongguk.edu; arsal@dongguk.edu; parkgr@dongguk.edu
OI Arsalan, Muhammad/0000-0003-1868-5207
FU National Research Foundation of Korea (NRF) - Ministry of Science and
   ICT (MSIT) through the Basic Science Research Program
   [NRF-2020R1A2C1006179]; NRF - MSIT through the Basic Science Research
   Program [NRF-2019R1A2C1083813, NRF-2019R1F1A1041123]; National Research
   Foundation of Korea [2019R1F1A1041123, 2019R1A2C1083813] Funding Source:
   Korea Institute of Science & Technology Information (KISTI), National
   Science & Technology Information Service (NTIS)
FX This work was supported in part by the National Research Foundation of
   Korea (NRF) funded by the Ministry of Science and ICT (MSIT) through the
   Basic Science Research Program under Grant NRF-2020R1A2C1006179, in part
   by the NRF funded by the MSIT through the Basic Science Research Program
   under Grant NRF-2019R1F1A1041123, and in part by the NRF funded by the
   MSIT through the Basic Science Research Program under Grant
   NRF-2019R1A2C1083813.
CR [Anonymous], 2014, GASTROINTESTINAL INT, DOI DOI 10.1016/J.GII.2014.02.005
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Carvajal DN, 2010, PEDIATR REV, V31, P511, DOI 10.1542/pir.31-12-511
   Chi JN, 2017, J DIGIT IMAGING, V30, P477, DOI 10.1007/s10278-017-9997-y
   Chu PM, 2019, IEEE ACCESS, V7, P1021, DOI 10.1109/ACCESS.2018.2886213
   Nguyen DT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071810
   Nguyen DT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071822
   Nguyen DT, 2019, J CLIN MED, V8, DOI 10.3390/jcm8111976
   Fonolla R, 2019, I S BIOMED IMAGING, P74, DOI 10.1109/ISBI.2019.8759320
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G., 2016, ABS160806993 CORR
   Huang WK, 2019, IEEE ACCESS, V7, P67905, DOI 10.1109/ACCESS.2019.2918224
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Kowsari K, 2018, 2ND INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND DATA MINING (ICISDM 2018), P19, DOI 10.1145/3206098.3206111
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li YX, 2018, I S BIOMED IMAGING, P182, DOI 10.1109/ISBI.2018.8363550
   Ma JL, 2017, ULTRASONICS, V73, P221, DOI 10.1016/j.ultras.2016.09.011
   Milletari F, 2017, COMPUT VIS IMAGE UND, V164, P92, DOI 10.1016/j.cviu.2017.04.002
   Mirbeik-Sabzevari A, 2019, IEEE T MED IMAGING, V38, P2188, DOI 10.1109/TMI.2019.2902600
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ribeiro J, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTERS IN EDUCATION (SIIE)
   Selvaraju R.R., 2016, ARXIV
   Simonyan K., 2015, 3 INT C LEARN REPRES, P1
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wickstrom K, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101619
   World Health Organization, CANC REP
   Xian M, 2018, PATTERN RECOGN, V79, P340, DOI 10.1016/j.patcog.2018.02.012
   Xie YT, 2020, IEEE T MED IMAGING, V39, P2482, DOI 10.1109/TMI.2020.2972964
   Xu Y, 2019, ULTRASONICS, V91, P1, DOI 10.1016/j.ultras.2018.07.006
   Ye ML, 2016, MED IMAGE ANAL, V30, P144, DOI 10.1016/j.media.2015.10.003
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 37
TC 17
Z9 18
U1 1
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD NOV
PY 2020
VL 20
IS 21
AR 5982
DI 10.3390/s20215982
PG 24
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA OR2UW
UT WOS:000589331400001
PM 33105736
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Freedman, D
   Blau, Y
   Katzir, L
   Aides, A
   Shimshoni, I
   Veikherman, D
   Golany, T
   Gordon, A
   Corrado, G
   Matias, Y
   Rivlin, E
AF Freedman, Daniel
   Blau, Yochai
   Katzir, Liran
   Aides, Amit
   Shimshoni, Ilan
   Veikherman, Danny
   Golany, Tomer
   Gordon, Ariel
   Corrado, Greg
   Matias, Yossi
   Rivlin, Ehud
TI Detecting Deficient Coverage in Colonoscopies
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Colonoscopy; coverage; depth estimation; unsupervised deep learning
ID VISUAL ODOMETRY; SURFACE; SLAM
AB Colonoscopy is tool of choice for preventing Colorectal Cancer, by detecting and removing polyps before they become cancerous. However, colonoscopy is hampered by the fact that endoscopists routinely miss 22-28% of polyps. While some of these missed polyps appear in the endoscopist's field of view, others are missed simply because of substandard coverage of the procedure, i.e. not all of the colon is seen. This paper attempts to rectify the problem of substandard coverage in colonoscopy through the introduction of the C2D2 (Colonoscopy Coverage Deficiency via Depth) algorithm which detects deficient coverage, and can thereby alert the endoscopist to revisit a given area. More specifically, C2D2 consists of two separate algorithms: the first performs depth estimation of the colon given an ordinary RGB video stream; while the second computes coverage given these depth estimates. Rather than compute coverage for the entire colon, our algorithm computes coverage locally, on a segment-by-segment basis; C2D2 can then indicate in real-time whether a particular area of the colon has suffered from deficient coverage, and if so the endoscopist can return to that area. Our coverage algorithm is the first such algorithm to be evaluated in a large-scale way; while our depth estimation technique is the first calibration-free unsupervised method applied to colonoscopies. The C2D2 algorithm achieves state of the art results in the detection of deficient coverage. On synthetic sequences with ground truth, it is 2.4 times more accurate than human experts; while on real sequences, C2D2 achieves a 93.0% agreement with experts.
C1 [Freedman, Daniel; Blau, Yochai; Katzir, Liran; Aides, Amit; Shimshoni, Ilan; Veikherman, Danny; Golany, Tomer; Matias, Yossi; Rivlin, Ehud] Google Res, IL-31905 Haifa, Israel.
   [Gordon, Ariel; Corrado, Greg] Google Res, Mountain View, CA 94043 USA.
C3 Google Incorporated; Google Incorporated
RP Freedman, D (通讯作者)，Google Res, IL-31905 Haifa, Israel.
EM danielfreedman@google.com; yochaib@google.com; lirank@google.com;
   amitaides@google.com; ishimshoni@google.com; veikherm@google.com;
   tomergolany@google.com; gariel@google.com; gcorrado@google.com;
   yossi@google.com; ehud@google.com
OI Freedman, Daniel/0000-0001-7354-0129; Katzir, Liran/0000-0002-3635-8755
CR Aghanouri M, 2019, IET IMAGE PROCESS, V13, P2321, DOI 10.1049/iet-ipr.2018.6366
   Almalioglu Y, 2019, IEEE INT CONF ROBOT, P5474, DOI 10.1109/ICRA.2019.8793512
   [Anonymous], 2016, ADV NEURAL INFORM PR
   Armin MA, 2016, INT J COMPUT ASS RAD, V11, P1599, DOI 10.1007/s11548-016-1462-8
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen D, 2020, GASTROINTEST ENDOSC, V91, P332, DOI 10.1016/j.gie.2019.09.016
   Chen Richard J, 2019, KDD WORKSH APPL DAT
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gordon A, 2019, IEEE I CONF COMP VIS, P8976, DOI 10.1109/ICCV.2019.00907
   Hong DH, 2014, COMPUT MED IMAG GRAP, V38, P22, DOI 10.1016/j.compmedimag.2013.10.005
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Lee YM, 2017, CLIN ENDOSC, V50, P254, DOI 10.5946/ce.2016.115
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li RH, 2018, IEEE INT CONF ROBOT, P7286, DOI 10.1109/ICRA.2018.8461251
   Liu MS, 2018, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2018.00596
   Ma RB, 2019, LECT NOTES COMPUT SC, V11768, P573, DOI 10.1007/978-3-030-32254-0_64
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Mahmood F, 2018, IEEE T MED IMAGING, V37, P2572, DOI 10.1109/TMI.2018.2842767
   Mahmoud N, 2019, IEEE T MED IMAGING, V38, P79, DOI 10.1109/TMI.2018.2856109
   Maier-Hein L, 2014, IEEE T MED IMAGING, V33, P1913, DOI 10.1109/TMI.2014.2325607
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Pinheiro G, 2018, IEEE INT C BIOINFORM, P724, DOI 10.1109/BIBM.2018.8621450
   Qingyu Zhao, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P439, DOI 10.1007/978-3-319-46720-7_51
   Rau A, 2019, INT J COMPUT ASS RAD, V14, P1167, DOI 10.1007/s11548-019-01962-w
   Rex DK, 2007, GASTROINTEST ENDOSC, V65, P145, DOI 10.1016/j.gie.2006.09.028
   Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Turan M, 2018, IEEE INT C INT ROBOT, P1801, DOI 10.1109/IROS.2018.8593623
   Turan M, 2018, NEUROCOMPUTING, V275, P1861, DOI 10.1016/j.neucom.2017.10.014
   Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19122746
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang R, 2017, IEEE I CONF COMP VIS, P3923, DOI 10.1109/ICCV.2017.421
   Wang S, 2017, INT CONF ACOUST SPEE, P436, DOI 10.1109/ICASSP.2017.7952193
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Widya AR, 2019, IEEE J TRANSL ENG HE, V7, DOI 10.1109/JTEHM.2019.2946802
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Yang N, 2018, LECT NOTES COMPUT SC, V11212, P835, DOI 10.1007/978-3-030-01237-3_50
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043
   Zhou HZ, 2018, LECT NOTES COMPUT SC, V11220, P851, DOI 10.1007/978-3-030-01270-0_50
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 47
TC 30
Z9 30
U1 1
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD NOV
PY 2020
VL 39
IS 11
BP 3451
EP 3462
DI 10.1109/TMI.2020.2994221
PG 12
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA OM9RL
UT WOS:000586352000018
PM 32746092
OA Green Submitted, hybrid
DA 2023-08-21
ER

PT J
AU Sinagra, E
   Badalamenti, M
   Maida, M
   Spadaccini, M
   Maselli, R
   Rossi, F
   Conoscenti, G
   Raimondo, D
   Pallio, S
   Repici, A
   Anderloni, A
AF Sinagra, Emanuele
   Badalamenti, Matteo
   Maida, Marcello
   Spadaccini, Marco
   Maselli, Roberta
   Rossi, Francesca
   Conoscenti, Giuseppe
   Raimondo, Dario
   Pallio, Socrate
   Repici, Alessandro
   Anderloni, Andrea
TI Use of artificial intelligence in improving adenoma detection rate
   during colonoscopy: Might both endoscopists and pathologists be further
   helped
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Colonoscopy; Artificial intelligence; Adenoma detection rate; Pathology;
   Endoscopy; Computer-aided detection and diagnosis
ID COMPUTER-AIDED DIAGNOSIS; COLORECTAL POLYP HISTOLOGY; GASTROINTESTINAL
   ENDOSCOPY; OPTICAL DIAGNOSIS; SYSTEM; CANCER; QUALITY; LESIONS; RISK;
   FUTURE
AB Colonoscopy remains the standard strategy for screening for colorectal cancer around the world due to its efficacy in both detecting adenomatous or pre-cancerous lesions and the capacity to remove them intra-procedurally. Computer-aided detection and diagnosis (CAD), thanks to the brand new developed innovations of artificial intelligence, and especially deep-learning techniques, leads to a promising solution to human biases in performance by guarantying decision support during colonoscopy. The application of CAD on real-time colonoscopy helps increasing the adenoma detection rate, and therefore contributes to reduce the incidence of interval cancers improving the effectiveness of colonoscopy screening on critical outcome such as colorectal cancer related mortality. Furthermore, a significant reduction in costs is also expected. In addition, the assistance of the machine will lead to a reduction of the examination time and therefore an optimization of the endoscopic schedule. The aim of this opinion review is to analyze the clinical applications of CAD and artificial intelligence in colonoscopy, as it is reported in literature, addressing evidence, limitations, and future prospects.
C1 [Sinagra, Emanuele; Rossi, Francesca; Conoscenti, Giuseppe; Raimondo, Dario] Fdn Ist San Raffaele Giglio, Gastroenterol & Endoscopy Unit, I-90015 Cefalu, Italy.
   [Badalamenti, Matteo; Spadaccini, Marco; Maselli, Roberta; Repici, Alessandro; Anderloni, Andrea] Humanitas Clin & Res Ctr IRCCS, Div Gastroenterol, Digest Endoscopy Unit, I-20089 Rozzano, Italy.
   [Maida, Marcello] S Elia Raimondi Hosp, Gastroenterol & Endoscopy Unit, I-93100 Caltanissetta, Italy.
   [Pallio, Socrate] AOUP Policlin G Martino, Endoscopy Unit, I-98125 Messina, Italy.
RP Sinagra, E (通讯作者)，Fdn Ist San Raffaele Giglio, Gastroenterol & Endoscopy Unit, I-90015 Cefalu, Italy.
EM emanuelesinagra83@googlemail.com
RI Spadaccini, Marco/HOH-7613-2023; Repici, Alessandro/HFH-8162-2022;
   Maselli, Roberta/HJY-6995-2023; Maida, Marcello/I-4118-2019
OI Spadaccini, Marco/0000-0003-3909-9012; Repici,
   Alessandro/0000-0002-1621-6450; Maselli, Roberta/0000-0001-7291-9110;
   Maida, Marcello/0000-0002-4992-9289; Badalamenti,
   Matteo/0000-0002-9543-9862; Anderloni, Andrea/0000-0002-1021-0031
CR Ahmad OF, 2019, FRONTLINE GASTROENTE, V10, P198, DOI 10.1136/flgastro-2018-101047
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   [Anonymous], NEW ENGL J MED
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Coe SG, 2013, AM J GASTROENTEROL, V108, P219, DOI 10.1038/ajg.2012.417
   Crockett SD, 2018, ENDOSCOPY, V50, P984, DOI 10.1055/a-0597-1740
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   El Hajjar A, 2020, CHINESE MED J-PEKING, V133, P326, DOI 10.1097/CM9.0000000000000623
   Fitzmaurice C, 2015, JAMA ONCOL, V1, P505, DOI 10.1001/jamaoncol.2015.0735
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Lee BI, 2019, CLIN ENDOSC, V52, P100, DOI 10.5946/ce.2019.012
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Maida M, 2019, EXPERT REV ANTICANC, V19, P223, DOI 10.1080/14737140.2019.1565999
   Maida M, 2017, EXPERT REV ANTICANC, V17, P1131, DOI 10.1080/14737140.2017.1392243
   MANDEL JS, 1993, NEW ENGL J MED, V328, P1365, DOI 10.1056/NEJM199305133281901
   McGill SK, 2015, GUT, V64, P184, DOI 10.1136/gutjnl-2013-305743
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Puig I, 2018, GUT LIVER, V12, P385, DOI 10.5009/gnl17137
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Repici A, 2019, GASTROENTEROLOGY, V156, P2198, DOI 10.1053/j.gastro.2019.02.001
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Thakkar S, 2020, GASTROENTEROLOGY, V158, P1219, DOI 10.1053/j.gastro.2019.12.035
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wieszczy P, 2017, BEST PRACT RES CL GA, V31, P441, DOI 10.1016/j.bpg.2017.07.002
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 39
TC 16
Z9 16
U1 0
U2 4
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD OCT 21
PY 2020
VL 26
IS 39
DI 10.3748/wjg.v26.i39.5911
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA PN2QU
UT WOS:000604330200001
PM 33132644
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Attardo, S
   Chandrasekar, VT
   Spadaccini, M
   Maselli, R
   Patel, HK
   Desai, M
   Capogreco, A
   Badalamenti, M
   Galtieri, PA
   Pellegatta, G
   Fugazza, A
   Carrara, S
   Anderloni, A
   Occhipinti, P
   Hassan, C
   Sharma, P
   Repici, A
AF Attardo, Simona
   Chandrasekar, Viveksandeep Thoguluva
   Spadaccini, Marco
   Maselli, Roberta
   Patel, Harsh K.
   Desai, Madhav
   Capogreco, Antonio
   Badalamenti, Matteo
   Galtieri, Piera Alessia
   Pellegatta, Gaia
   Fugazza, Alessandro
   Carrara, Silvia
   Anderloni, Andrea
   Occhipinti, Pietro
   Hassan, Cesare
   Sharma, Prateek
   Repici, Alessandro
TI Artificial intelligence technologies for the detection of colorectal
   lesions: The future is now
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Endoscopy; Colonoscopy; Screening; Surveillance; Technology; Quality;
   Artificial intelligence
ID COMPUTER-AIDED DETECTION; POLYP DETECTION; DETECTION SYSTEM;
   GASTROINTESTINAL ENDOSCOPY; NEOPLASTIC POLYPS; ADENOMA DETECTION;
   RISK-FACTORS; MISS RATE; COLONOSCOPY; EFFICACY
AB Several studies have shown a significant adenoma miss rate up to 35% during screening colonoscopy, especially in patients with diminutive adenomas. The use of artificial intelligence (AI) in colonoscopy has been gaining popularity by helping endoscopists in polyp detection, with the aim to increase their adenoma detection rate (ADR) and polyp detection rate (PDR) in order to reduce the incidence of interval cancers. The efficacy of deep convolutional neural network (DCNN)-based AI system for polyp detection has been trained and tested inex vivosettings such as colonoscopy still images or videos. Recent trials have evaluated the real-time efficacy of DCNN-based systems showing promising results in term of improved ADR and PDR. In this review we reported data from the preliminaryex vivoexperiences and summarized the results of the initial randomized controlled trials.
C1 [Attardo, Simona; Occhipinti, Pietro] AOU Maggiore Carita, Dept Endoscopy & Digest Dis, I-28100 Novara, Italy.
   [Chandrasekar, Viveksandeep Thoguluva; Desai, Madhav; Sharma, Prateek] Kansas City VA Med Ctr, Dept Gastroenterol & Hepatol, Kansas City, MO 64128 USA.
   [Spadaccini, Marco; Maselli, Roberta; Capogreco, Antonio; Badalamenti, Matteo; Galtieri, Piera Alessia; Pellegatta, Gaia; Fugazza, Alessandro; Carrara, Silvia; Anderloni, Andrea; Repici, Alessandro] Humanitas Res Hosp, Dept Endoscopy, Via Manzoni 56, I-20089 Rozzano, Italy.
   [Spadaccini, Marco; Capogreco, Antonio; Repici, Alessandro] Humanitas Univ, Dept Biomed Sci, I-20089 Rozzano, Italy.
   [Patel, Harsh K.] Ochsner Clin Fdn, Dept Internal Med, New Orleans, LA 70124 USA.
   [Hassan, Cesare] Nuovo Regina Margherita Hosp, Endoscopy Unit, I-00153 Rome, Italy.
C3 Azienda Ospedaliera Maggiore della Carita di Novara; University of
   Eastern Piedmont Amedeo Avogadro; IRCCS Humanitas Research Hospital;
   Humanitas University; IRCCS Humanitas Research Hospital; Ochsner Health
   System; Poliambulatorio Nuovo Regina Margherita
RP Spadaccini, M (通讯作者)，Humanitas Res Hosp, Dept Endoscopy, Via Manzoni 56, I-20089 Rozzano, Italy.
EM marco.spadaccini@humanitas.it
RI hassan, cesare/H-2844-2012; Maselli, Roberta/HJY-6995-2023; Repici,
   Alessandro/HFH-8162-2022; Patel, Harsh/AAK-8810-2021; Anderloni,
   Andrea/ABE-9139-2020; Fugazza, Alessandro/ABG-9381-2021; Sharma,
   Prateek/IZE-3910-2023; Carrara, Silvia/AAC-5298-2022; Spadaccini,
   Marco/HOH-7613-2023
OI hassan, cesare/0000-0001-7167-1459; Maselli,
   Roberta/0000-0001-7291-9110; Repici, Alessandro/0000-0002-1621-6450;
   Anderloni, Andrea/0000-0002-1021-0031; Fugazza,
   Alessandro/0000-0003-0485-4903; Spadaccini, Marco/0000-0003-3909-9012;
   Carrara, Silvia/0000-0003-4206-9463; Galtieri,
   Piera/0000-0002-3253-6972; Pellegatta, Gaia/0000-0003-0235-4905;
   Badalamenti, Matteo/0000-0002-9543-9862
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Brenner H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g2467
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Ebigbo A, 2019, ENDOSC INT OPEN, V7, pE1616, DOI 10.1055/a-1010-5705
   Eelbode T, 2019, GASTROINTEST ENDOSC, V89, pAB632, DOI 10.1016/j.gie.2019.03.1103
   Ertem FU, 2018, GASTROINTEST ENDOSC, V88, P705, DOI 10.1016/j.gie.2018.05.012
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Hassan C, 2021, DIGEST ENDOSC, V33, P285, DOI 10.1111/den.13807
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Hewitson P, 2007, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001216.pub2
   Hoerter N, 2020, CURR TREAT OPTIONS G
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Jerebko A, 2006, LECT NOTES COMPUT SC, V4191, P169
   k Geetha, 2016, Asian Pac J Cancer Prev, V17, P4869
   Kaminski MF, 2017, UNITED EUR GASTROENT, V5, P309, DOI 10.1177/2050640617700014
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lui TKL, 2019, GASTROINTEST ENDOSC, V89, pAB135
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Martinez Barellas M R, 1989, Rev Enferm, V12, P80
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   Misawa M, 2019, GASTROINTEST ENDOSC, V89, pAB646, DOI 10.1016/j.gie.2019.03.1134
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Ozawa T, 2020, THER ADV GASTROENTER, V13, DOI 10.1177/1756284820910659
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Park SY, 2016, MED IMAGING 2016 COM
   Pogorelov K, 2018, COMP MED SY, P381, DOI 10.1109/CBMS.2018.00073
   Repici A, 2020, GASTROENTEROLOGY, V159, P512, DOI 10.1053/j.gastro.2020.04.062
   Shichijo S, 2019, GASTROINTEST ENDOSC, V89, pAB653, DOI 10.1016/j.gie.2019.03.1147
   Shinozaki S, 2020, DIGEST ENDOSC, V32, P874, DOI 10.1111/den.13613
   Shirin H, 2019, GASTROINTEST ENDOSC, V89, P545, DOI 10.1016/j.gie.2018.09.028
   Singh S, 2014, AM J GASTROENTEROL, V109, P1375, DOI 10.1038/ajg.2014.171
   Spadaccini M, 2020, CLIN GASTROENTEROL H, V18, P1454, DOI 10.1016/j.cgh.2019.10.044
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Williet N, 2018, ENDOSCOPY, V50, P846, DOI 10.1055/a-0577-3500
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhu X, 2018, GASTROINTEST ENDOSC, V87, pAB251
NR 55
TC 13
Z9 13
U1 0
U2 5
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD OCT 7
PY 2020
VL 26
IS 37
BP 5606
EP 5616
DI 10.3748/wjg.v26.i37.5606
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA OH7DQ
UT WOS:000582755000005
PM 33088155
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Goyal, H
   Mann, R
   Gandhi, Z
   Perisetti, A
   Ali, A
   Ali, KA
   Sharma, N
   Saligram, S
   Tharian, B
   Inamdar, S
AF Goyal, Hemant
   Mann, Rupinder
   Gandhi, Zainab
   Perisetti, Abhilash
   Ali, Aman
   Ali, Khizar Aman
   Sharma, Neil
   Saligram, Shreyas
   Tharian, Benjamin
   Inamdar, Sumant
TI Scope of Artificial Intelligence in Screening and Diagnosis of
   Colorectal Cancer
SO JOURNAL OF CLINICAL MEDICINE
LA English
DT Review
DE artificial intelligence; colorectal cancer; colon cancer; polyp;
   screening; colonoscopy; computer-aided diagnosis
ID COMPUTER-AIDED DIAGNOSIS; CONFOCAL LASER ENDOMICROSCOPY; POLYP
   HISTOLOGY; COLONOSCOPY; CLASSIFICATION; SYSTEM; LESIONS; IMAGES; RISK;
   ENDOCYTOSCOPY
AB Globally, colorectal cancer is the third most diagnosed malignancy. It causes significant mortality and morbidity, which can be reduced by early diagnosis with an effective screening test. Integrating artificial intelligence (AI) and computer-aided detection (CAD) with screening methods has shown promising colorectal cancer screening results. AI could provide a "second look" for endoscopists to decrease the rate of missed polyps during a colonoscopy. It can also improve detection and characterization of polyps by integration with colonoscopy and various advanced endoscopic modalities such as magnifying narrow-band imaging, endocytoscopy, confocal endomicroscopy, laser-induced fluorescence spectroscopy, and magnifying chromoendoscopy. This descriptive review discusses various AI and CAD applications in colorectal cancer screening, polyp detection, and characterization.
C1 [Goyal, Hemant] Wright Ctr Grad Med Educ, Dept Internal Med, Scranton, PA 18505 USA.
   [Mann, Rupinder] St Agnes Med Ctr, Fresno, CA 93720 USA.
   [Gandhi, Zainab] Geisinger Community Med Ctr, Dept Med, Scranton, PA 18510 USA.
   [Perisetti, Abhilash] Univ Arkansas Med Sci, Dept Gastroenterol & Hepatol, Little Rock, AR 72205 USA.
   [Ali, Aman] Wilkes Barre Gen Hosp, Commonwealth Med Coll, Div Gastroenterol, Wilkes Barre, PA 18764 USA.
   [Ali, Aman; Ali, Khizar Aman] Digest Care Associates, Kingston, PA 18704 USA.
   [Sharma, Neil] Parkview Canc Inst, Div Intervent Oncol & Surg Endoscopy IOSE, Ft Wayne, IN 46845 USA.
   [Sharma, Neil] Indiana Univ Sch Med, Div Intervent Oncol & Surg Endoscopy, Ft Wayne, IN 46805 USA.
   [Saligram, Shreyas] Univ Texas Hlth San Antonio, Dept Med, San Antonio, TX 78229 USA.
   [Tharian, Benjamin] Univ Arkansas Med Sci, Gen & Adv Endoscopy, Little Rock, AR 72205 USA.
   [Inamdar, Sumant] Univ Arkansas Med Sci, Adv Endoscopy Fellowship, Little Rock, AR 72205 USA.
C3 University of Arkansas System; University of Arkansas Medical Sciences;
   Geisinger Commonwealth School of Medicine; Purdue University System;
   Indiana University Purdue University Fort Wayne; University of Texas
   System; University of Texas Health Science Center at San Antonio;
   University of Arkansas System; University of Arkansas Medical Sciences;
   University of Arkansas System; University of Arkansas Medical Sciences
RP Goyal, H (通讯作者)，Wright Ctr Grad Med Educ, Dept Internal Med, Scranton, PA 18505 USA.
EM doc.hemant@yahoo.com; rupindrmann@yahoo.com; drzainabgandhi@gmail.com;
   abhilash.perisetti@gmail.com; amanali786@hotmail.com;
   aminali92403@gmail.com; neil.sharma@parkview.com; drsaligram@yahoo.com;
   Btharian@uams.edu; Sinamdar@uams.edu
RI Perisetti, Abhilash/ISU-8946-2023; Perisetti, Abhilash/L-2619-2019;
   Goyal, Hemant/E-3153-2012
OI Goyal, Hemant/0000-0002-9433-9042; Perisetti,
   Abhilash/0000-0003-4074-6395; Gandhi, Zainab/0000-0002-7214-4981
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Brenner H, 2011, ANN INTERN MED, V154, P22, DOI 10.7326/0003-4819-154-1-201101040-00004
   Buchner Anna M, 2017, Gastroenterol Hepatol (N Y), V13, P336
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   De Palma GD, 2009, WORLD J GASTROENTERO, V15, P5770, DOI 10.3748/wjg.15.5770
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Golub R, 1998, J AM COLL SURGEONS, V187, P584, DOI 10.1016/S1072-7515(98)00241-5
   Goyal H, 2017, WORLD J GASTROENTERO, V23, P4879, DOI 10.3748/wjg.v23.i27.4879
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hafner M, 2010, IEEE T INF TECHNOL B, V14, P958, DOI 10.1109/TITB.2010.2044184
   Hafner M, 2009, LECT NOTES COMPUT SC, V5761, P247, DOI 10.1007/978-3-642-04268-3_31
   Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011
   Hirata M, 2007, GASTROINTEST ENDOSC, V66, P945, DOI 10.1016/j.gie.2007.05.053
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Hornbrook MC, 2017, DIGEST DIS SCI, V62, P2719, DOI 10.1007/s10620-017-4722-8
   Hosoe N, 2021, DIGEST ENDOSC, V33, P529, DOI 10.1111/den.13769
   Issa IA, 2017, WORLD J GASTROENTERO, V23, P5086, DOI 10.3748/wjg.v23.i28.5086
   Kahi CJ, 2009, CLIN GASTROENTEROL H, V7, P770, DOI 10.1016/j.cgh.2008.12.030
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kinar Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171759
   Kinar Y, 2016, J AM MED INFORM ASSN, V23, P879, DOI 10.1093/jamia/ocv195
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Kudo S, 2014, J GASTROEN HEPATOL, V29, P83, DOI 10.1111/jgh.12374
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lin JS, 2016, JAMA-J AM MED ASSOC, V315, P2576, DOI 10.1001/jama.2016.3332
   Matsuda T, 2008, AM J GASTROENTEROL, V103, P1926, DOI 10.1111/j.1572-0241.2008.01931.x
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Morris EJA, 2015, GUT, V64, P1248, DOI 10.1136/gutjnl-2014-308362
   Park S.Y, 2016, P MED IM 2016 COMP A
   Perisetti Abhilash, 2018, World J Gastrointest Pharmacol Ther, V9, P31, DOI 10.4292/wjgpt.v9.i4.31
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Ruffle JK, 2019, AM J GASTROENTEROL, V114, P422, DOI 10.1038/s41395-018-0268-4
   Russell Stuart, 2009, ARTIFICIAL INTELLIGE
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shalev-Shwartz S., 2014, UNDERSTANDING MACHIN
   Singh H, 2006, JAMA-J AM MED ASSOC, V295, P2366, DOI 10.1001/jama.295.20.2366
   Smith RA, 2019, CA-CANCER J CLIN, V69, P184, DOI 10.3322/caac.21557
   Song BW, 2014, INT J COMPUT ASS RAD, V9, P1021, DOI 10.1007/s11548-014-0991-2
   Spell DW, 2004, CANCER DETECT PREV, V28, P37, DOI 10.1016/j.cdp.2003.10.002
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Taylor SA, 2008, EUR RADIOL, V18, P1666, DOI 10.1007/s00330-008-0936-7
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yang YJ, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051593
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
NR 71
TC 26
Z9 27
U1 3
U2 20
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0383
J9 J CLIN MED
JI J. Clin. Med.
PD OCT
PY 2020
VL 9
IS 10
AR 3313
DI 10.3390/jcm9103313
PG 22
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA OL1NU
UT WOS:000585109300001
PM 33076511
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Li, TB
   Brown, JRG
   Tsourides, K
   Mahmud, N
   Cohen, JM
   Berzin, TM
AF Li, Taibo
   Glissen Brown, Jeremy R.
   Tsourides, Kelovoulos
   Mahmud, Nadim
   Cohen, Jonah M.
   Berzin, Tyler M.
TI Training a computer-aided polyp detection system to detect sessile
   serrated adenomas using public domain colonoscopy videos
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID COLORECTAL-CANCER INCIDENCE; MISS RATE; SCREENING COLONOSCOPY;
   MORTALITY; RISK
AB Background Colorectal cancer (CRC) is a major public health burden worldwide, and colonoscopy is the most commonly used CRC screening tool. Still, there is variability in adenoma detection rate (ADR) among endoscopists. Recent studies have reported improved ADR using deep learning models trained on videos curated largely from private in-house datasets. Few have focused on the detection of sessile serrated adenomas (SSAs), which are the most challenging target clinically.
   Methods We identified 23 colonoscopy videos available in the public domain and for which pathology data were provided, totaling 390 minutes of footage. Expert endoscopists annotated segments of video with adenomatous polyps, from which we captured 509 polyp-positive and 6,875 polyp-free frames. Via data augmentation, we generated 15,270 adenomatous polyp-positive images, of which 2,310 were SSAs, and 20,625 polyp-negative images. We used the CNN AlexNet and fine-tuned its parameters using 90% of the images, before testing its performance on the remaining 10% of images unseen by the model.
   Results We trained the model on 32,305 images and tested performance on 3,590 images with the same proportion of SSA, non-SSA polyp-positive, and polyp-negative images. The overall accuracy of the model was 0.86, with a sensitivity of 0.73 and a specificity of 0.96.Positive predictive value was 0.93 and negative predictive value was 0.96.The area under the curve was 0.94.SSAs were detected in 93% of SSA-positive images.
   Conclusions Using a relatively small set of publicly-available colonoscopy data, we obtained sizable training and validation sets of endoscopic images using data augmentation, and achieved an excellent performance in adenomatous polyp detection.
C1 [Li, Taibo] Johns Hopkins Sch Med, MD PhD Program, Baltimore, MD USA.
   [Li, Taibo] MIT Dept Elect Engn & Comp Sci, Cambridge, MA USA.
   [Glissen Brown, Jeremy R.; Cohen, Jonah M.; Berzin, Tyler M.] Beth Israel Deaconess, Med Ctr, Ctr Adv Endoscopy, Div Gastroenterol, Boston, MA USA.
   [Glissen Brown, Jeremy R.; Cohen, Jonah M.; Berzin, Tyler M.] Harvard Med Sch, Boston, MA 02130 USA.
   [Tsourides, Kelovoulos] MIT Dept Brain & Cognit Sci, Cambridge, MA USA.
   [Mahmud, Nadim] Hosp Univ Penn, Boston, MA USA.
C3 Johns Hopkins University; Johns Hopkins Medicine; Harvard University;
   Beth Israel Deaconess Medical Center; Harvard University; Harvard
   Medical School
RP Brown, JRG (通讯作者)，Beth Israel Deaconess Med Ctr, Gastroenterol, 330 Brookline Ave, Boston, MA 02130 USA.
EM jglissen@bidmc.harvard.edu
RI Li, Taibo/ABG-5912-2020
OI Li, Taibo/0000-0002-6624-9293
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Benedict M, 2015, WORLD J GASTROENTERO, V21, P12735, DOI 10.3748/wjg.v21.i45.12735
   Bettington M, 2014, AM J SURG PATHOL, V38, P158, DOI 10.1097/PAS.0000000000000103
   Bouwens MWE, 2014, ENDOSCOPY, V46, P225, DOI 10.1055/s-0034-1364936
   Brody H, 2015, NATURE, V526, pS1, DOI [10.1038/526S1a, 10.1038/521S1a]
   Center MM, 2009, CANCER EPIDEM BIOMAR, V18, P1688, DOI 10.1158/1055-9965.EPI-09-0090
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838
   Jacob BJ, 2012, GASTROINTEST ENDOSC, V76, P355, DOI 10.1016/j.gie.2012.03.247
   Jia Y., 2014, ARXIV14085093CSCV
   Kahi CJ, 2009, CLIN GASTROENTEROL H, V7, P770, DOI 10.1016/j.cgh.2008.12.030
   Kim NH, 2017, INTEST RES, V15, P411, DOI 10.5217/ir.2017.15.3.411
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Ma MX, 2017, GUT LIVER, V11, P747, DOI 10.5009/gnl16523
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Obuch Joshua C, 2015, Curr Treat Options Gastroenterol, V13, P156, DOI 10.1007/s11938-015-0046-y
   Pan J, 2016, AM J GASTROENTEROL, V111, P355, DOI 10.1038/ajg.2015.418
   Perez L, 2017, ARXIV171204621CSCV
   Rajaratnam R, 2017, GASTROINTEST ENDOSC, V85, pAB417, DOI 10.1016/j.gie.2017.03.967
   Rex DK, 2012, AM J GASTROENTEROL, V107, P1315, DOI 10.1038/ajg.2012.161
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Wang CL, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000012297
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
NR 27
TC 4
Z9 4
U1 0
U2 0
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD OCT
PY 2020
VL 08
IS 10
BP E1448
EP E1454
DI 10.1055/a-1229-3927
PG 7
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA OI1FT
UT WOS:000583033800036
PM 33043112
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Mori, Y
   Kudo, S
   East, JE
   Rastogi, A
   Bretouer, M
   Misawa, M
   Sekiguchi, M
   Matsuda, T
   Saito, Y
   Ikematsu, H
   Hotta, K
   Ohtsuka, K
   Kudo, T
   Mori, K
AF Mori, Yuichi
   Kudo, Shin-ei
   East, James E.
   Rastogi, Amit
   Bretouer, Michael
   Misawa, Masashi
   Sekiguchi, Masau
   Matsuda, Takahisa
   Saito, Yutaka
   Ikematsu, Hiroaki
   Hotta, Kinichi
   Ohtsuka, Kazuo
   Kudo, Toyoki
   Mori, Kensaku
TI Cost savings in colonoscopy with artificial intelligence-aided polyp
   diagnosis: an add-on analysis of a clinical trial (with video)
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID COLORECTAL LESIONS; OPTICAL BIOPSY; SYSTEM; CANCER; CLASSIFICATION;
   HISTOLOGY
AB Background and Aims: Artificial intelligence (AI) is being implemented in colonoscopy practice, but no study has investigated whether AI is cost saving. We aimed to quantify the cost reduction using AI as an aid in the optical diagnosis of colorectal polyps.
   Methods: This study is an add-on analysis of a clinical trial that investigated the performance of AI for differentiating colorectal polyps (ie, neoplastic versus non-neoplastic). We included all patients with diminutive (<= 5 mm) rectosigmoid polyps in the analyses. The average colonoscopy cost was compared for 2 scenarios: (1) a diagnoseand-leave strategy supported by the AI prediction (ie, diminutive rectosigmoid polyps were not removed when predicted as non-neoplastic), and (2) a resect-all-polyps strategy. Gross annual costs for colonoscopies were also calculated based on the number and reimbursement of colonoscopies conducted under public health insurances in 4 countries.
   Results: Overall, 207 patients with 250 diminutive rectosigmoid polyps (104 neoplastic, 144 non-neoplastic, and 2 indeterminate) were included. AI correctly differentiated neoplastic polyps with 93.3% sensitivity, 95.2% specificity, and 95.2% negative predictive value. Thus, 105 polyps were removed and 145 were left under the diagnose-and-leave strategy, which was estimated to reduce the average colonoscopy cost and the gross annual reimbursement for colonoscopies by 18.9% and US$149.2 million in Japan, 6.9% and US$12.3 million in England, 7.6% and US$1.1 million in Norway, and 10.9% and US$85.2 million in the United States, respectively, compared with the resect-all-polyps strategy.
   Conclusions: The use of AI to enable the diagnose-and-leave strategy results in substantial cost reductions for colonoscopy.
C1 [Mori, Yuichi; Bretouer, Michael; Misawa, Masashi; Kudo, Toyoki] Univ Oslo, Inst Hlth & Soc, Dept Hlth Management & Hlth Econ, Oslo, Norway.
   [Kudo, Shin-ei] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [East, James E.] John Radcliffe Hosp, Translat Gastroenterol Unit, Oxford, England.
   [East, James E.] Univ Oxford, Oxford NIHR Biomed Res Ctr, Oxford, England.
   [Rastogi, Amit] Univ Kansas, Med Ctr, Div Gastroenterol, Kansas City, KS 66103 USA.
   [Bretouer, Michael] Oslo Univ Hosp, Dept Transplantat Med, Oslo, Norway.
   [Sekiguchi, Masau; Matsuda, Takahisa] Natl Canc Ctr, Canc Screening Ctr, Tokyo, Japan.
   [Sekiguchi, Masau; Matsuda, Takahisa] Natl Canc Ctr, Div Screening Technol, Ctr Publ Hlth Sci, Tokyo, Japan.
   [Sekiguchi, Masau; Matsuda, Takahisa; Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Tokyo, Japan.
   [Ikematsu, Hiroaki] Natl Canc Ctr Hosp East, Dept Gastroenterol & Endoscopy, Kashiwa, Chiba, Japan.
   [Hotta, Kinichi] Shizuoka Canc Ctr, Div Endoscopy, Shizuoka, Japan.
   [Ohtsuka, Kazuo] Tokyo Med & Dent Univ, Dept Endoscopy, Tokyo, Japan.
   [Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
C3 University of Oslo; Showa University; University of Oxford; University
   of Oxford; University of Kansas; University of Kansas Medical Center;
   University of Oslo; National Cancer Center - Japan; National Cancer
   Center - Japan; National Cancer Center - Japan; National Cancer Center -
   Japan; Shizuoka Cancer Center; Tokyo Medical & Dental University (TMDU);
   Nagoya University
RP Mori, Y (通讯作者)，Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Tsuzuki Ku, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
EM ibusiginjp@gmail.com
RI Ohtsuka, Kazuo/AAA-5139-2021; Mori, Yuichi/AAU-5406-2020; Misawa,
   Masashi/H-9004-2019
OI Misawa, Masashi/0000-0002-8520-2036
FU Japan Society for the Promotion of Science [19K08403, 17H05305];
   National Institute for Health Research (NIHR) Oxford Biomedical Research
   Centre; Grants-in-Aid for Scientific Research [17H05305, 19K08403]
   Funding Source: KAKEN
FX This study was supported by Grants-in-Aid for Scientific Research (no.
   19K08403 and 17H05305) from the Japan Society for the Promotion of
   Science. The funding source did not play a role in the design, conduct,
   or reporting of the study. We express our gratitude to Olympus Corp and
   Cybernet Corp for their instrumental support for the present study. We
   also thank Karl Embleton, PhD, from Edanz Group
   (www.edanzediting.com/ac) for editing a draft of this manuscript, which
   was paid for by the Japan Society for the Promotion of Science (no.
   19K08403). James E. East was funded by the National Institute for Health
   Research (NIHR) Oxford Biomedical Research Centre. The views expressed
   are those of the author(s) and not necessarily those of the National
   Health Service, the NIHR or the Department of Health.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Atkinson NS, 2015, GASTROINTEST ENDOSC, V82, P118, DOI 10.1016/j.gie.2015.01.059
   Bretthauer M, 2016, JAMA INTERN MED, V176, P894, DOI 10.1001/jamainternmed.2016.0960
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Kaminski MF, 2015, ENDOSCOPY, V47, P1144, DOI 10.1055/s-0034-1392769
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Ministry of Health Labour and Welfare in Japan, 2014, NDB OP DAT
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rutter MD, 2020, GUT, V69, P201, DOI 10.1136/gutjnl-2019-319858
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Shenbagaraj L, 2019, FRONTLINE GASTROENTE, V10, P7, DOI 10.1136/flgastro-2018-100970
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   U.S. Department of Health & Human Services, 2015, MED FEE FOR SERV BEN
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
NR 30
TC 69
Z9 70
U1 0
U2 13
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD OCT
PY 2020
VL 92
IS 4
BP 905
EP +
DI 10.1016/j.gie.2020.03.3759
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA NV5JN
UT WOS:000574357800014
PM 32240683
OA Green Submitted
DA 2023-08-21
ER

PT J
AU Parasa, S
   Wallace, M
   Bagci, U
   Antonino, M
   Berzin, T
   Byrne, M
   Celik, H
   Farahani, K
   Golding, M
   Gross, S
   Jamali, V
   Mendonca, P
   Mori, Y
   Ninh, A
   Repici, A
   Rex, D
   Skrinak, K
   Thakkar, SJ
   van Hooft, JE
   Vargo, J
   Yu, HG
   Xu, ZY
   Sharma, P
AF Parasa, Sravanthi
   Wallace, Michael
   Bagci, Ulas
   Antonino, Mark
   Berzin, Tyler
   Byrne, Michael
   Celik, Haydar
   Farahani, Keyvan
   Golding, Martin
   Gross, Seth
   Jamali, Vafa
   Mendonca, Paulo
   Mori, Yuichi
   Ninh, Andrew
   Repici, Alessandro
   Rex, Douglas
   Skrinak, Kris
   Thakkar, Shyam J.
   van Hooft, Jeanin E.
   Vargo, John
   Yu, Honggang
   Xu, Ziyue
   Sharma, Prateek
TI Proceedings from the First Global Artificial Intelligence in
   Gastroenterology and Endoscopy Summit
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID DEEP-LEARNING ALGORITHM; NEURAL-NETWORK; CLASSIFICATION; VALIDATION;
   LESIONS; POLYPS; CANCER
AB Background and Aims: Artificial intelligence (AI), specifically deep learning, offers the potential to enhance the field of GI endoscopy in areas ranging from lesion detection and classification to quality metrics and documentation. Progress in this field will be measured by whether AI implementation can lead to improved patient outcomes and more efficient clinical workflow for GI endoscopists. The aims of this article are to report the findings of a multidisciplinary group of experts focusing on issues in AI research and applications related to gastroenterology and endoscopy, to review the current status of the field, and to produce recommendations for investigators developing and studying new AI technologies for gastroenterology.
   Methods: A multidisciplinary meeting was held on September 28, 2019, bringing together academic, industry, and regulatory experts in diverse fields including gastroenterology, computer and imaging sciences, machine learning, computer vision, U.S. Food and Drug Administration, and the National Institutes of Health. Recent and ongoing studies in gastroenterology and current technology in AI were presented and discussed, key gaps in knowledge were identified, and recommendations were made for research that would have the highest impact in making advances and implementation in the field of AI to gastroenterology.
   Results: There was a consensus that AI will transform the field of gastroenterology, particularly endoscopy and image interpretation. Powered by advanced machine learning algorithms, the use of computer vision in endoscopy has the potential to result in better prediction and treatment outcomes for patients with gastroenterology disorders and cancer. Large libraries of endoscopic images, "EndoNet," will be important to facilitate development and application of AI systems. The regulatory environment for implementation of AI systems is evolving, but common outcomes such as colon polyp detection have been highlighted as potential clinical trial endpoints. Other threshold outcomes will be important, as well as clarity on iterative improvement of clinical systems.
   Conclusions: Gastroenterology is a prime candidate for early adoption of AI. AI is rapidly moving from an experimental phase to a clinical implementation phase in gastroenterology. It is anticipated that the implementation of AI in gastroenterology over the next decade will have a significant and positive impact on patient care and clinical workflows. Ongoing collaboration among gastroenterologists, industry experts, and regulatory agencies will be important to ensure that progress is rapid and clinically meaningful. However, several constraints and areas will benefit from further exploration, including potential clinical applications, implementation, structure and governance, role of gastroenterologists, and potential impact of AI in gastroenterology.
C1 [Parasa, Sravanthi] Swedish Med Ctr, Dept Gastroenterol, Seattle, WA 98122 USA.
   [Wallace, Michael] Mayo Clin, Dept Med, Jacksonville, FL 32224 USA.
   [Wallace, Michael] Digest Dis Res Program, Jacksonville, FL USA.
   [Wallace, Michael] Florida Gastroenterol Soc, Jacksonville, FL USA.
   [Bagci, Ulas] Univ Cent Florida, Ctr Res Comp Vis, Artificial Intelligence Med AIM, Orlando, FL 32816 USA.
   [Antonino, Mark] US FDA, Div Renal Gastrointestinal Obes & Transplant Devi, Off Gastrorenal ObGyn Gen Hosp & Urol Devices,Ctr, Gastroenterol & Endoscopy Devices Team,Off Prod E, Silver Spring, MD USA.
   [Berzin, Tyler] Beth Israel Deaconess Med Ctr, Dept Med, Boston, MA 02215 USA.
   [Byrne, Michael] Univ British Columbia, Div Gastroenterol, Vancouver Gen Hosp, Vancouver, BC, Canada.
   [Celik, Haydar] NIH, Clin Ctr, Bethesda, MD 20892 USA.
   [Celik, Haydar] George Washington Univ, Washington, DC USA.
   [Farahani, Keyvan] NCI, Image Guided Intervent & Imaging Informat, NIH, Rockville, MD USA.
   [Golding, Martin] US FDA, Div Renal Gastrointestinal Obes & Transplant Devi, Off Gastrorenal ObGyn Gen Hosp & Urol Devices, Gastroenterol & Endoscopy Devices Team,Off Prod E, Silver Spring, MD USA.
   [Gross, Seth] NYU Langone Hlth, Div Gastroenterol Clin Care & Qual, Dept Med, New York, NY USA.
   [Jamali, Vafa] Medtronic Inc, Resp Gastrointestinal & Informat, Boulder, CO USA.
   [Mendonca, Paulo] Facebook Inc, Spatial AI, Redmond, WA USA.
   [Mori, Yuichi] Showa Univ, Northern Yokohama Hosp, Ctr Digest Dis, Yokohama, Kanagawa, Japan.
   [Ninh, Andrew] Docbot, Irvine, CA USA.
   [Repici, Alessandro] Res Hosp, Digest Endoscopy Unit, Humanitas, Milan, Italy.
   [Rex, Douglas] Indiana Univ Sch Med, Dept Med, Indianapolis, IN 46202 USA.
   [Rex, Douglas] Indiana Univ Sch Med, Dept Endoscopy, Indianapolis, IN 46202 USA.
   [Rex, Douglas] Indiana Univ Sch Med, Dept Gastroenterol, Indianapolis, IN 46202 USA.
   [Skrinak, Kris] Amazon Web Serv, New York, NY USA.
   [Thakkar, Shyam J.] Temple Univ, Dept Endoscopy, Allegheny Hlth Network, Dept Med, Philadelphia, PA 19122 USA.
   [Thakkar, Shyam J.] Carnegie Mellon Univ, Dept Biomed Engn, Pittsburgh, PA 15213 USA.
   [van Hooft, Jeanin E.] Gastrointestinal Oncol Ctr Amsterdam, Amsterdam, Netherlands.
   [Vargo, John] Cleveland Clin, Dept Med Gastroenterol Hepatol & Nutr, Cleveland, OH 44106 USA.
   [Yu, Honggang] Wuhan Univ, Renmin Hosp, Div Gastroenterol, Wuhan, Peoples R China.
   [Xu, Ziyue] NVIDIA, Med Image Anal, Bethesda, MD USA.
   [Sharma, Prateek] Univ Kansas, Sch Med, Div Gastroenterol & Hepatol, Kansas City, KS USA.
C3 Swedish Medical Center; Mayo Clinic; State University System of Florida;
   University of Central Florida; US Food & Drug Administration (FDA);
   Harvard University; Beth Israel Deaconess Medical Center; University of
   British Columbia; National Institutes of Health (NIH) - USA; NIH
   Clinical Center (CC); George Washington University; National Institutes
   of Health (NIH) - USA; NIH National Cancer Institute (NCI); US Food &
   Drug Administration (FDA); NYU Langone Medical Center; Medtronic;
   Facebook Inc; Showa University; Indiana University System; Indiana
   University Bloomington; Indiana University System; Indiana University
   Bloomington; Indiana University System; Indiana University Bloomington;
   Amazon.com; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Temple University; Carnegie Mellon University; Cleveland Clinic
   Foundation; Wuhan University; Nvidia Corporation; University of Kansas;
   University of Kansas Medical Center
RP Parasa, S (通讯作者)，Swedish Med Ctr, Dept Gastroenterol, Seattle, WA 98122 USA.
RI Sharma, Prateek/IZE-3910-2023; Repici, Alessandro/HFH-8162-2022; van
   hooft, Jeanin/AAT-3600-2020; Mori, Yuichi/AAU-5406-2020; van hooft,
   Jeanin/AAD-3595-2019; Wallace, Michael/GZL-9731-2022
OI Repici, Alessandro/0000-0002-1621-6450; van hooft,
   Jeanin/0000-0002-4424-0079; Wallace, Michael/0000-0002-6446-5785
FU NCI NIH HHS [R01 CA246704] Funding Source: Medline
CR Altman RB, 2017, CLIN PHARMACOL THER, V101, P585, DOI 10.1002/cpt.650
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Bentley F, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2503823
   Chung Chia-Fang, 2019, Proc ACM Interact Mob Wearable Ubiquitous Technol, V3, DOI 10.1145/3314394
   Epstein Daniel, 2014, P 2014 C DES INT SYS, P667, DOI DOI 10.1145/2598510.2598558
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hassan AR, 2015, COMPUT METH PROG BIO, V122, P341, DOI 10.1016/j.cmpb.2015.09.005
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   McKinsey Global Institute, ARTIFICIAL INTELLIGE
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Pan G., 2009, Journal of Medical Engineering & Technology, V33, P575, DOI 10.1080/03091900903111974
   Poplin R, 2018, NAT BIOMED ENG, V2, P158, DOI 10.1038/s41551-018-0195-0
   Shung D, 2019, DIGEST DIS SCI, V64, P2078, DOI 10.1007/s10620-019-05645-z
   Stamm JA, 2016, AM J MED, V129, P20, DOI 10.1016/j.amjmed.2015.08.026
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Thakkar S, 2020, GASTROENTEROLOGY, V158, P1219, DOI 10.1053/j.gastro.2019.12.035
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Waljee AK, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.3721
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
   Zia J, 2016, CLIN TRANSL GASTROEN, V7, DOI 10.1038/ctg.2016.9
NR 29
TC 18
Z9 18
U1 2
U2 15
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD OCT
PY 2020
VL 92
IS 4
BP 938
EP +
DI 10.1016/j.gie.2020.04.044
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA NV5JN
UT WOS:000574357800019
PM 32343978
DA 2023-08-21
ER

PT J
AU Pu, LZCT
   Maicas, G
   Tian, Y
   Yamamura, T
   Nakamura, M
   Suzuki, H
   Singh, G
   Rana, K
   Hirooka, Y
   Burt, AD
   Fujishiro, M
   Carneiro, G
   Singh, R
AF Pu, Leonardo Zorron Cheng Tao
   Maicas, Gabriel
   Tian, Yu
   Yamamura, Takeshi
   Nakamura, Masanao
   Suzuki, Hiroto
   Singh, Gurfarmaan
   Rana, Khizar
   Hirooka, Yoshiki
   Burt, Alastair D.
   Fujishiro, Mitsuhiro
   Carneiro, Gustavo
   Singh, Rajvinder
TI Computer-aided diagnosis for characterization of colorectal lesions:
   comprehensive software that includes differentiation of serrated lesions
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID MODIFIED SANOS; CLASSIFICATION; POLYPS; HISTOLOGY; ACCURACY; SYSTEM;
   TUMORS
AB Background and Aims: Endoscopy guidelines recommend adhering to policies such as resect and discard only if the optical biopsy is accurate. However, accuracy in predicting histology can vary greatly. Computer-aided diagnosis (CAD) for characterization of colorectal lesions may help with this issue. In this study, CAD software developed at the University of Adelaide (Australia) that includes serrated polyp differentiation was validated with Japanese images on narrow-band imaging (NBI) and blue-laser imaging (BLI).
   Methods: CAD software developed using machine learning and densely connected convolutional neural net-works was modeled with NBI colorectal lesion images (Olympus 190 series - Australia) and validated for NBI (Olympus 290 series) and BLI (Fujifilm 700 series) with Japanese datasets. All images were correlated with histology according to the modified Sano classification. The CAD software was trained with Australian NBI images and tested with separate sets of images from Australia (NBI) and Japan (NBI and BLI).
   Results: An Australian dataset of 1235 polyp images was used as training, testing, and internal validation sets. A Japanese dataset of 20 polyp images on NBI and 49 polyp images on BLI was used as external validation sets. The CAD software had a mean area under the curve (AUC) of 94.3% for the internal set and 84.5% and 90.3% for the external sets (NBI and BLI, respectively).
   Conclusions: The CAD achieved AUCs comparable with experts and similar results with NBI and BLI. Accurate CAD prediction was achievable, even when the predicted endoscopy imaging technology was not part of the training set.
C1 [Pu, Leonardo Zorron Cheng Tao; Singh, Gurfarmaan; Rana, Khizar; Burt, Alastair D.; Singh, Rajvinder] Univ Adelaide, Fac Hlth & Med Sci, Adelaide, SA, Australia.
   [Pu, Leonardo Zorron Cheng Tao; Nakamura, Masanao; Fujishiro, Mitsuhiro] Nagoya Univ, Grad Sch Med, Dept Gastroenterol & Hepatol, Nagoya, Aichi, Japan.
   [Maicas, Gabriel; Tian, Yu; Carneiro, Gustavo] Univ Adelaide, Australian Inst Machine Learning, Adelaide, SA, Australia.
   [Tian, Yu] South Australian Hlth & Med Res Inst, Adelaide, SA, Australia.
   [Yamamura, Takeshi; Suzuki, Hiroto] Nagoya Univ Hosp, Dept Endoscopy, Nagoya, Aichi, Japan.
   [Hirooka, Yoshiki] Fujita Hlth Univ, Dept Liver Biliary Tract & Pancreas Dis, Toyoake, Aichi, Japan.
   [Singh, Rajvinder] Lyell McEwin Hosp, Dept Gastroenterol & Hepatol, Adelaide, SA, Australia.
C3 University of Adelaide; Nagoya University; University of Adelaide; South
   Australian Health & Medical Research Institute (SAHMRI); Nagoya
   University; Fujita Health University; Lyell McEwin Hospital
RP Pu, LZCT (通讯作者)，Univ Adelaide, Adelaide, SA 5000, Australia.; Pu, LZCT (通讯作者)，Nagoya Univ, North Terrace, Adelaide, SA 5000, Australia.
EM leonardo.zorronchengtaopu@adelaide.edu.au
RI Burt, Alastair D/D-3634-2013; Hirooka, Yoshiki/I-7351-2014
OI Burt, Alastair D/0000-0002-3011-7774; Hirooka,
   Yoshiki/0000-0001-9639-7425; Fujishiro, Mitsuhiro/0000-0002-4074-1140;
   Rana, Khizar/0000-0002-5986-6621; Singh, Rajvinder/0000-0001-9116-6054;
   Carneiro, Gustavo/0000-0002-5571-6220
FU Australian Research Council [DP180103232]
FX We acknowledge Brock Campbell for his contribution to the initial CNN
   model. This study was partially supported by the Australian Research
   Council (grant DP180103232).
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Huang G., P IEEE C COMP VIS PA
   IJspeert JEG, 2016, GUT, V65, P963, DOI 10.1136/gutjnl-2014-308411
   Jass JR, 2007, HISTOPATHOLOGY, V50, P113, DOI 10.1111/j.1365-2559.2006.02549.x
   Kahi CJ, 2011, CLIN GASTROENTEROL H, V9, P42, DOI 10.1016/j.cgh.2010.09.013
   Kingma D.P., INT C LEARN REPR
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Pu LZCT, 2019, J GASTROEN HEPATOL, V34, P226
   Pu LZCT, 2018, WORLD J GASTRO ENDOS, V10, P210, DOI 10.4253/wjge.v10.i9.210
   Pyenson B, 2015, ABDOM IMAGING, V40, P2966, DOI 10.1007/s00261-015-0538-1
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Samowitz WS, 2005, GASTROENTEROLOGY, V129, P837, DOI 10.1053/j.gastro.2005.06.020
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Sharma P, 2014, ANZ J SURG, V84, P365, DOI 10.1111/ans.12366
   Singh R, 2013, DIGEST ENDOSC, V25, P16, DOI 10.1111/den.12075
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
NR 28
TC 25
Z9 25
U1 0
U2 5
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD OCT
PY 2020
VL 92
IS 4
BP 891
EP 899
DI 10.1016/j.gie.2020.02.042
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA NV5JN
UT WOS:000574357800012
PM 32145289
DA 2023-08-21
ER

PT J
AU Rahim, T
   Usman, MA
   Shin, SY
AF Rahim, Tariq
   Usman, Muhammad Arslan
   Shin, Soo Young
TI A survey on contemporary computer-aided tumor, polyp, and ulcer
   detection methods in wireless capsule endoscopy imaging
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Review
DE Computer-aided; Gastrointestinal tract; Polyp; Ulcer; Tumor; Wireless
   capsule endoscopy
ID BLEEDING DETECTION; TEXTURAL FEATURES; DEEP CNN; CLASSIFICATION;
   LACUNARITY; IMAGES; SEGMENTATION; RECOGNITION
AB Wireless capsule endoscopy (WCE) is a process in which a patient swallows a camera-embedded pill-shaped device that passes through the gastrointestinal (GI) tract, captures and transmits images to an external receiver. WCE devices are considered as a replacement of conventional endoscopy methods which are usually painful and distressful for the patients. WCE devices produce over 60,000 images typically during their course of operation inside the GI tract. These images need to be examined by expert physicians who attempt to identify frames that contain inflammation/disease. It can be hectic for a physician to go through such a large number of frames, hence computer-aided detection methods are considered an efficient alternative.
   Various anomalies can take place in the GI tract of a human being but the most important and common ones and the aim of this survey are ulcers, polyps, and tumors. In this paper, we have presented a survey of contemporary computer-aided detection methods that take WCE images as input and classify those images in a diseased/abnormal or disease-free/normal image. We have considered methods that detect tumors, polyps and ulcers, as these three diseases lie in the same category. Furthermore, general abnormalities and bleeding inside the GI tract may be the symptoms of these diseases; so an attempt is also made to enlighten the research work done for abnormalities and bleeding detection inside WCE images. Several studies have been included with in-depth detail of their methodologies, findings, and conclusions. Also, we have attempted to classify these methods based on their technical aspects. A formal discussion and comparison of recent review articles are also provided to have a benchmark for the presented survey mentioning their limitations. This paper also includes a proposed classification approach where a cascade approach of neural networks is presented for the classification of tumor, polyp, and ulcer jointly along with data set specifications and results. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Rahim, Tariq; Usman, Muhammad Arslan; Shin, Soo Young] Kumoh Natl Inst Technol, Gumi 39177, Gyeongbuk, South Korea.
C3 Kumoh National University Technology
RP Shin, SY (通讯作者)，Kumoh Natl Inst Technol, Gumi 39177, Gyeongbuk, South Korea.
EM tariqrahim@kumoh.ac.kr; arslanusman@msn.com; wdragon@kumoh.ac.kr
RI Shin, Soo Young/ABG-4608-2021; Rahim, Tariq/AAO-7762-2021
OI Shin, Soo Young/0000-0002-2526-2395; 
FU Priority Research Centers Program through the National Research
   Foundation of Korea (NRF) - "Ministry of Education, Science and
   Technology" [2018R1A6A1A03024003]
FX This work was supported by Priority Research Centers Program through the
   National Research Foundation of Korea (NRF)funded by the "Ministry of
   Education, Science and Technology" (2018R1A6A1A03024003).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Alizadeh M., 2018, ABS180202232 CORR
   Alizadeh M, 2017, J BIOMED RES, V31, P419, DOI 10.7555/JBR.31.20160008
   ALLAIN C, 1991, PHYS REV A, V44, P3552, DOI 10.1103/PhysRevA.44.3552
   ANDREADIS I, 1990, PATTERN RECOGN LETT, V11, P51, DOI 10.1016/0167-8655(90)90055-7
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Ashokkumar B., 2014, INT J ENG RES APPL, V4, P50
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Barbosa DJC, 2009, IEEE ENG MED BIO, P6683, DOI 10.1109/IEMBS.2009.5334013
   Barbosa DJC, 2008, IEEE ENG MED BIO, P3012, DOI 10.1109/IEMBS.2008.4649837
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Bourbakis N, 2005, BIBE 2005: 5TH IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, P232
   Candes EJ, 2000, CURVELETS SURPRISING
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Charfi S, 2019, IET IMAGE PROCESS, V13, P1023, DOI 10.1049/iet-ipr.2018.6232
   Charisis V, 2010, IEEE ENG MED BIO, P3674, DOI 10.1109/IEMBS.2010.5627648
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Collins B, 2003, NAT REV DRUG DISCOV, V2, P11, DOI 10.1038/nrd966
   Csurka G, 2004, PROC WORKSHOP STAT L, V1, P1
   Dalal N., 2005, 2005 IEEE COMP SOC C, V1, P886, DOI DOI 10.1109/CVPR.2005.177
   Demanet L, 2007, PROC SPIE, V6701, DOI 10.1117/12.733257
   Dinevari VF, 2016, APPL BIONICS BIOMECH, V2016, DOI 10.1155/2016/3678913
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Dong P, 2000, INT J REMOTE SENS, V21, P3369, DOI 10.1080/014311600750019985
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Eliakim R, 2017, ANN TRANSL MED, V5, DOI 10.21037/atm.2017.04.17
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fan W., 1999, ADACOST MISCLASSIFIC
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Ghosh T., 2015, TENCON IEEE REGION, P1, DOI [10.1109/TENCON.2015.7373186, DOI 10.1109/TENCON.2015.7373186]
   Ghosh T, 2018, J MED BIOL ENG, V38, P482, DOI 10.1007/s40846-017-0318-1
   Ghosh T, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2017.2756034
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hajabdollahi M., 2018, ABS180207788 CORR
   Haji Maghsoudi Omid, 2013, 2013 20th Iranian Conference on Biomedical Engineering (ICBME). Proceedings, P286, DOI 10.1109/ICBME.2013.6782236
   Han B, 2018, ADV NEUR IN, V31
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hoens T. R., 2013, IMBALANCED DATASETS
   Hwang S., 2007, 2007 IEEE INT C IM P, V2, P11465
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Hwang Y, 2018, CLIN ENDOSC, V51, P547, DOI 10.5946/ce.2018.173
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Inoue T., 2001, FUZZY SUPPORT VECTOR
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Jani KK, 2019, CURR MED IMAGING, V15, P622, DOI 10.2174/1573405614666181102152434
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P266, DOI 10.1109/RCAR.2016.7784037
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kubat M, 1997, P 14 INT C MACH LEAR, V97, P179
   Larose DT., 2014, DISCOVERING KNOWLEDG
   Lazebnik S., 2006, P IEEE INT C COMP VI, V2, P2169, DOI DOI 10.1109/CVPR.2006.68
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Li BP, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P498, DOI 10.1109/IROS.2009.5354726
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Lin O., 2005, P 4 INT C CAPS END M
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Liu G, 2016, COMPUT BIOL MED, V70, P131, DOI 10.1016/j.compbiomed.2016.01.021
   Liu JG, 2009, OPTIM ENG, V10, P289, DOI 10.1007/s11081-008-9066-y
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma A. J. H., 2011, 2011 IEEE International Conference on Computer Vision (ICCV 2011), P2041, DOI 10.1109/ICCV.2011.6126477
   Ma L, 2015, IEEE T GEOSCI REMOTE, V53, P2832, DOI 10.1109/TGRS.2014.2365676
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Mohapatra S, 2012, BIOMED ENG LETT, V2, P100, DOI 10.1007/s13534-012-0056-9
   Nam H., 2016, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2016.465, DOI 10.1109/CVPR.2016.465]
   Nasrabadi N.M., 2007, ELECT IMAGING, V16
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Noya F, 2017, IEEE ENG MED BIO, P3158, DOI 10.1109/EMBC.2017.8037527
   Obukhova N, 2019, PROC CONF OPEN INNOV, P285, DOI 10.23919/FRUCT.2019.8711921
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Pogorelov K, 2019, J APPL CLIN MED PHYS, V20, P141, DOI 10.1002/acm2.12662
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Qu HN, 2010, PATTERN RECOGN, V43, P3448, DOI 10.1016/j.patcog.2010.05.002
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Sharma MK, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI [10.1109/i2ct45611.2019.9033954, 10.1080/19386362.2019.1691322]
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Sindhu CP, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Sindhu S, 2017, IN C IND ENG ENG MAN, P100, DOI 10.1109/IEEM.2017.8289859
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Teague M.R., 1980, IMAGE ANAL VIA GEN T
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Usman MA, 2017, COMPUT BIOL MED, V91, P112, DOI 10.1016/j.compbiomed.2017.10.007
   Usman MA, 2016, COMPUT MED IMAG GRAP, V54, P16, DOI 10.1016/j.compmedimag.2016.09.005
   Vieira PM, 2020, MED PHYS, V47, P52, DOI 10.1002/mp.13709
   Vieira PM, 2015, IEEE ENG MED BIO, P3025, DOI 10.1109/EMBC.2015.7319029
   Viola P., 2001, WORKSH STAT COMP THE
   Wireless Capsule Endoscopy, 2020, WIRELESS CAPSULE END
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P339, DOI 10.1142/S1793536909000187
   Xiaoying Liu, 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P737, DOI 10.1109/BHI.2012.6211688
   Xing XH, 2019, I S BIOMED IMAGING, P104, DOI 10.1109/ISBI.2019.8759401
   Yanagawa Y., 2017, IPSJ T COMPUT VIS AP, V9, P3
   Yu LC, 2012, INT C PATT RECOG, P45
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
NR 130
TC 30
Z9 30
U1 3
U2 21
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD OCT
PY 2020
VL 85
AR 101767
DI 10.1016/j.compmedimag.2020.101767
PG 25
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA OH6LX
UT WOS:000582704200001
PM 32966967
OA Green Submitted
DA 2023-08-21
ER

PT J
AU Soffer, S
   Klang, E
   Shimon, O
   Nachmias, N
   Eliakim, R
   Ben-Horin, S
   Kopylov, U
   Barash, Y
AF Soffer, Shelly
   Klang, Eyal
   Shimon, Orit
   Nachmias, Noy
   Eliakim, Rami
   Ben-Horin, Shomron
   Kopylov, Uri
   Barash, Yiftach
TI Deep learning for wireless capsule endoscopy: a systematic review and
   meta-analysis
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
ID COMPUTER-AIDED DIAGNOSIS; SMALL-BOWEL; COLONOSCOPY; RECOGNITION;
   MULTICENTER; CHALLENGES; POLYPS; IMAGES; TOOL
AB Background and Aims: Deep learning is an innovative algorithm based on neural networks. Wireless capsule endoscopy (WCE) is considered the criterion standard for detecting small-bowel diseases. Manual examination of WCE is time-consuming and can benefit from automatic detection using artificial intelligence (AI). We aimed to perform a systematic review of the current literature pertaining to deep learning implementation in WCE.
   Methods: We conducted a search in PubMed for all original publications on the subject of deep learning applications in WCE published between January 1, 2016 and December 15, 2019. Evaluation of the risk of bias was performed using tailored Quality Assessment of Diagnostic Accuracy Studies-2. Pooled sensitivity and specificity were calculated. Summary receiver operating characteristic curves were plotted.
   Results: Of the 45 studies retrieved, 19 studies were included. All studies were retrospective. Deep learning applications for WCE included detection of ulcers, polyps, celiac disease, bleeding, and hookworm. Detection accuracy was above 90% for most studies and diseases. Pooled sensitivity and specificity for ulcer detection were .95 (95% confidence interval [CI], .89-.98) and .94 (95% CI, .90-.96), respectively. Pooled sensitivity and specificity for bleeding or bleeding source were .98 (95% CI, .96-.99) and .99 (95% CI, .97-.99), respectively.
   Conclusions: Deep learning has achieved excellent performance for the detection of a range of diseases in WCE. Notwithstanding, current research is based on retrospective studies with a high risk of bias. Thus, future prospective, multicenter studies are necessary for this technology to be implemented in the clinical use of WCE.
C1 [Soffer, Shelly; Klang, Eyal; Barash, Yiftach] Sheba Med Ctr, Dept Diagnost Imaging, Tel Hashomer, Israel.
   [Soffer, Shelly; Klang, Eyal; Barash, Yiftach] Sheba Med Ctr, DeepVis Lab, Tel Hashomer, Israel.
   [Eliakim, Rami; Ben-Horin, Shomron; Kopylov, Uri] Sheba Med Ctr, Dept Gastroenterol, Tel Hashomer, Israel.
   [Soffer, Shelly; Klang, Eyal; Shimon, Orit; Nachmias, Noy; Eliakim, Rami; Ben-Horin, Shomron; Kopylov, Uri; Barash, Yiftach] Tel Aviv Univ, Sackler Sch Med, Tel Aviv, Israel.
   [Shimon, Orit] Beilinson Med Ctr, Rabin Med Ctr, Dept Anesthesia, Petah Tiqwa, Israel.
   [Nachmias, Noy] Tel Aviv Sourasky Med Ctr, Dept Internal Med D, Tel Aviv, Israel.
C3 Chaim Sheba Medical Center; Chaim Sheba Medical Center; Chaim Sheba
   Medical Center; Tel Aviv University; Sackler Faculty of Medicine; Rabin
   Medical Center; Tel Aviv University; Sackler Faculty of Medicine; Tel
   Aviv Sourasky Medical Center
RP Soffer, S (通讯作者)，Sheba Med Ctr, IL-5265601 Tel Hashomer, Israel.
EM soffer.shelly@gmail.com
OI Kopylov, Uri/0000-0002-7156-0588
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Aidoc, 2019, CLIN PROV RAD AI
   Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Aoki T, 2020, DIGEST ENDOSC, V32, P585, DOI 10.1111/den.13517
   Aoki T, 2020, J GASTROEN HEPATOL, V35, P1196, DOI 10.1111/jgh.14941
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Barash Y, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2019.12.101
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Chen Y, 2016, CLIN THER, V38, P688, DOI 10.1016/j.clinthera.2015.12.001
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Doebler P., 2015, R PACKAG, V1, P15
   Eliakim R, 2006, ENDOSCOPY, V38, P963, DOI 10.1055/s-2006-944832
   Eliakim R, 2003, EUR J GASTROEN HEPAT, V15, P363, DOI 10.1097/00042737-200304000-00005
   Eliakim R, 2008, CURR OPIN GASTROEN, V24, P159, DOI 10.1097/MOG.0b013e3282f3d946
   Eliakim R, 2013, CURR OPIN GASTROEN, V29, P133, DOI 10.1097/MOG.0b013e32835bdc03
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fleuren LM, 2020, INTENS CARE MED, V46, P383, DOI 10.1007/s00134-019-05872-y
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Han S, 2018, GASTROENTEROL RES, V11, P106, DOI 10.14740/gr949w
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Hricak H, 2018, RADIOLOGY, V286, P764, DOI 10.1148/radiol.2017171503
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iandola F, 2014, ARXIV14041869V1
   Ioannidis JPA, 2007, BMJ-BRIT MED J, V335, P914, DOI 10.1136/bmj.39343.408449.80
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Klang E, 2018, J THORAC DIS, V10, P1325, DOI 10.21037/jtd.2018.02.76
   Konda VJA, 2017, ENDOSCOPY, V49, P734, DOI 10.1055/s-0043-113439
   Kopylov U, 2015, INFLAMM BOWEL DIS, V21, P2726, DOI 10.1097/MIB.0000000000000497
   Kopylov U, 2015, CURR OPIN GASTROEN, V31, P111, DOI 10.1097/MOG.0000000000000159
   Kopylov U, 2013, CLIN EXP GASTROENTER, V6, P129, DOI 10.2147/CEG.S48005
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Koulaouzidis A, 2015, EXPERT REV GASTROENT, V9, P217, DOI 10.1586/17474124.2014.952281
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwong MT, 2019, BIO-DES MANUF, V2, P31, DOI 10.1007/s42242-018-0030-1
   Le Berre C, 2019, GASTROENTEROLOGY, V158
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee NM, 2010, EXPERT REV GASTROENT, V4, P503, DOI [10.1586/egh.10.44, 10.1586/EGH.10.44]
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Meyer P, 2018, COMPUT BIOL MED, V98, P126, DOI 10.1016/j.compbiomed.2018.05.018
   Microsoft, PROJ INNEREYE MED IM
   Mishkin DS, 2006, GASTROINTEST ENDOSC, V63, P539, DOI 10.1016/j.gie.2006.01.014
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1186/s13643-015-0087-2, 10.1136/bmj.b2535]
   Nowak T, 2017, ANN TRANSL MED, V5, DOI 10.21037/atm.2017.10.20
   Nyaga V., 2017, METAPROP STATA MODUL
   Pennazio M, 2015, ENDOSCOPY, V47, P352, DOI 10.1055/s-0034-1391855
   Powles J, 2017, HEALTH TECHNOL-GER, V7, P351, DOI 10.1007/s12553-017-0179-1
   Reitsma JB, 2005, J CLIN EPIDEMIOL, V58, P982, DOI 10.1016/j.jclinepi.2005.02.022
   Rondonotti E, 2012, DIGEST LIVER DIS, V44, P1006, DOI 10.1016/j.dld.2012.06.014
   Saurin JC, 2018, ENDOSC INT OPEN, V6, pE616, DOI 10.1055/a-0587-4788
   Saurin JC, 2012, DIGEST LIVER DIS, V44, P477, DOI 10.1016/j.dld.2011.12.021
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Soffer S, 2019, RADIOLOGY, V290, P590, DOI 10.1148/radiol.2018180547
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Van Gossum A, 2009, NEW ENGL J MED, V361, P264, DOI 10.1056/NEJMoa0806347
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Wang S, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab5086
   Wang S, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/7546215
   Watson DS, 2019, BMJ-BRIT MED J, V364, DOI 10.1136/bmj.l886
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Zebra Medical Vision, 2019, TRANSF PAT CAR POW A
   Zheng YP, 2012, AM J GASTROENTEROL, V107, P554, DOI 10.1038/ajg.2011.461
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 77
TC 94
Z9 97
U1 2
U2 28
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD OCT
PY 2020
VL 92
IS 4
BP 831
EP +
DI 10.1016/j.gie.2020.04.039
PG 17
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA NV5JN
UT WOS:000574357800005
PM 32334015
DA 2023-08-21
ER

PT J
AU Wadhwa, V
   Alagappan, M
   Gonzalez, A
   Gupta, K
   Brown, JRG
   Cohen, J
   Sawhney, M
   Pleskow, D
   Berzin, TM
AF Wadhwa, Vaibhav
   Alagappan, Muthuraman
   Gonzalez, Adalberto
   Gupta, Kapil
   Brown, Jeremy R. Glissen
   Cohen, Jonah
   Sawhney, Mandeep
   Pleskow, Douglas
   Berzin, Tyler M.
TI Physician sentiment toward artificial intelligence (AI) in colonoscopic
   practice: a survey of US gastroenterologists
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID CLASSIFICATION
AB Background and study aims Early studies have shown that artificial intelligence (AI) has the potential to augment the performance of gastroenterologists during endoscopy. Our aim was to determine how gastroenterologists view the potential role of AI in gastrointestinal endoscopy.
   Methods In this cross-sectional study, an online survey was sent to US gastroenterologists. The survey included questions about physician level of training, experience, and practice characteristics and physician perception of AI. Descriptive statistics were used to summarize sentiment about AI. Univariate and multivariate analyses were used to assess whether background information about physicians correlated to their sentiment.
   Results Surveys were emailed to 330 gastroenterologists nationwide. Between December 2018 and January 2019, 124 physicians (38%) completed the survey. Eighty-six percent of physicians reported interest in AI-assisted colonoscopy; 84.7% agreed that computer-assisted polyp detection (CADe) would improve their endoscopic performance. Of the respondents, 57.2% felt comfortable using computer-aided diagnosis (CADx) to support a "diagnose and leave" strategy for hyperplastic polyps. Multivariate analysis showed that post-fellowship experience of fewer than 15 years was the most important factor in determining whether physicians were likely to believe that CADe would lead to more removed polyps (odds ratio=5.09; P =.01). The most common concerns about implementation of AI were cost (75.2%), operator dependence (62.8%), and increased procedural time (60.3%).
   Conclusions Gastroenterologists have strong interest in the application of AI to colonoscopy, particularly with regard to CADe for polyp detection. The primary concerns were its cost, potential to increase procedural time, and potential to develop operator dependence. Future developments in AI should prioritize mitigation of these concerns.
C1 [Wadhwa, Vaibhav; Alagappan, Muthuraman; Brown, Jeremy R. Glissen; Cohen, Jonah; Sawhney, Mandeep; Pleskow, Douglas; Berzin, Tyler M.] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Boston, MA 02115 USA.
   [Gonzalez, Adalberto] Cleveland Clin Florida, Dept Gastroenterol & Hepatol, Weston, FL USA.
   [Gupta, Kapil] Univ Miami, JFK Med Ctr, Palm Beach Reg GME Consortium, Atlantis, FL USA.
C3 Harvard University; Beth Israel Deaconess Medical Center; Harvard
   Medical School; Cleveland Clinic Foundation
RP Berzin, TM (通讯作者)，Beth Israel Deaconess Med Ctr, Gastrointestinal Endoscopy, 110 Francis St, Boston, MA 02215 USA.; Berzin, TM (通讯作者)，Harvard Med Sch, Adv Therapeut Endoscopy Fellowship, 110 Francis St, Boston, MA 02215 USA.; Berzin, TM (通讯作者)，Harvard Med Sch, Med, 110 Francis St, Boston, MA 02215 USA.
EM tberzin@bidmc.harvard.edu
RI Pleskow, Douglas K/F-3319-2016
OI Pleskow, Douglas K/0000-0003-0092-9496
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cohen J, 2019, GASTROINTEST ENDOSC, V90, P35, DOI 10.1016/j.gie.2019.03.020
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Hassan C, 2019, GASTROINTEST ENDOSC, V89, P583, DOI 10.1016/j.gie.2018.10.019
   Kochhar G, 2018, CLIN GASTROENTEROL H, V16, P1556, DOI 10.1016/j.cgh.2018.02.045
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Rex DK, 2002, AM J GASTROENTEROL, V97, P1296, DOI 10.1016/S0002-9270(02)04168-0
   Ruffle JK, 2019, AM J GASTROENTEROL, V114, P422, DOI 10.1038/s41395-018-0268-4
   Sarwar S, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0106-0
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Togashi K, 2019, DIGEST ENDOSC, V31, P270, DOI 10.1111/den.13354
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Doorn SC, 2017, GUT, V66, P438, DOI 10.1136/gutjnl-2015-310097
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Willems P., 2019, J CAN ASS GASTROENTE, V2, P467
NR 19
TC 17
Z9 17
U1 0
U2 2
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD OCT
PY 2020
VL 08
IS 10
BP E1379
EP E1384
DI 10.1055/a-1223-1926
PG 6
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA OI1FT
UT WOS:000583033800022
PM 33015341
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Walradt, T
   Brown, JRG
   Alagappan, M
   Lerner, HP
   Berzin, TM
AF Walradt, Trent
   Brown, Jeremy R. Glissen
   Alagappan, Muthu
   Lerner, Herbert P.
   Berzin, Tyler M.
TI Regulatory considerations for artificial intelligence tecnnologies in GI
   endoscopy
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
ID HISTOLOGY; SYSTEM
AB Artificial intelligence (AI) technologies in clinical medicine have become the subject of intensive investigative efforts and popular attention. In domains ranging from pathology to radiology, AI has demonstrated the potential to improve clinical performance and efficiency. In gastroenterology, AI has been applied on multiple fronts, with particular progress seen in the areas of computer-aided polyp detection (CADe) and computer-aided polyp diagnosis (CADx), to assist gastroenterologists during colonoscopy. As clinical evidence accrues for CADe and CADx, our attention must also turn toward the unique challenges that this new wave of technologies represent for the U.S. Food and Drug Administration and other regulatory agencies, who are tasked with protecting public health by ensuring the safety of medical devices. In this review, we describe the current regulatory pathways for AI tools in gastroenterology and the expected evolution of these pathways.
C1 [Walradt, Trent; Brown, Jeremy R. Glissen; Alagappan, Muthu; Berzin, Tyler M.] Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Div Gastroenterol, 330 Brookline Ave, Boston, MA 02130 USA.
   [Walradt, Trent; Brown, Jeremy R. Glissen; Alagappan, Muthu; Berzin, Tyler M.] Harvard Med Sch, 330 Brookline Ave, Boston, MA 02130 USA.
   [Lerner, Herbert P.] US FDA, Rockville, MD 20857 USA.
C3 Harvard University; Beth Israel Deaconess Medical Center; Harvard
   University; Harvard Medical School; US Food & Drug Administration (FDA)
RP Walradt, T (通讯作者)，Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Div Gastroenterol, 330 Brookline Ave, Boston, MA 02130 USA.; Walradt, T (通讯作者)，Harvard Med Sch, 330 Brookline Ave, Boston, MA 02130 USA.
OI , Trent/0000-0003-1081-0923; Glissen Brown, Jeremy/0000-0002-7204-7241
CR [Anonymous], DIG HLTH SOFTW PREC
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Canadian Institutes of Health Research Government of Canada, INTR ART INT MACH LE
   ChinaMed Device LLC, NMPA CFDA FIN GUID A
   Cybernet Systems Co Ltd, ENDOBRAIND ART INT S
   Department of Health, 2020, POL US ART INT AI HE
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   FDA, FDA PERM MARK ART IN
   fda, DIG HLTH INN ACT PLA
   FDA, DEV SOFTW PREC PROGR
   Harvey H., GET CLIN AI TECH APP
   IMDRF SaMD Working Group, SOFTW MED DEV SAMD K
   IMDRF SaMD Working Group, SOFTW MED DEV SAMD C
   IMDRF SaMD Working Group, SOFTW MED DEV POSS F
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Lieberman D, 2020, GASTROENTEROLOGY, V158, P862, DOI 10.1053/j.gastro.2019.07.052
   Liu XX, 2019, LANCET, V394, P1225, DOI 10.1016/S0140-6736(19)31819-7
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   National Electrical Manufacturers Association, HIST DICOM STAND
   Pharmaceuticals and Medical Devices Agency, GUID EV ART INT ASS
   Repici A, 2013, GASTROINTEST ENDOSC, V78, P106, DOI 10.1016/j.gie.2013.01.035
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   The US Food and Drug Administration, PROP REG FRAM MOD AR
   Therapeutic Goods Administration, CONS REG SOFTW INCL
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   U.S. Food and Drug Administration, EV AUT CLASS 3 DES D
   U.S. Food and Drug Administration, DEC SUBM 510 K CHANG
   U.S. Food and Drug Administration, STUD MARK YOUR DEV
   U.S. Food and Drug Administration, LEARN MED DEV HAS BE
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   VOELKER R, 2018, JAMA-J AM MED ASSOC, V320, P23, DOI DOI 10.1001/JAMA.2018.8565
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
NR 36
TC 11
Z9 11
U1 1
U2 2
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD OCT
PY 2020
VL 92
IS 4
BP 801
EP 806
DI 10.1016/j.gie.2020.05.040
PG 6
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA NV5JN
UT WOS:000574357800001
PM 32504697
OA Bronze
DA 2023-08-21
ER

PT J
AU Wang, P
   Liu, PX
   Brown, JRG
   Berzin, TM
   Zhou, GY
   Lei, S
   Liu, XG
   Li, LP
   Xiao, X
AF Wang, Pu
   Liu, Peixi
   Brown, Jeremy R. Glissen
   Berzin, Tyler M.
   Zhou, Guanyu
   Lei, Shan
   Liu, Xiaogang
   Li, Liangping
   Xiao, Xun
TI Lower Adenoma Miss Rate of Computer-Aided Detection-Assisted Colonoscopy
   vs Routine White-Light Colonoscopy in a Prospective Tandem Study
SO GASTROENTEROLOGY
LA English
DT Article
DE AMR; Artificial Intelligence; Early Detection; Neoplasm
ID ARTIFICIAL-INTELLIGENCE; INATTENTIONAL BLINDNESS; COLORECTAL-CANCER;
   WIDE-ANGLE; MULTICENTER; ENDOSCOPY; POLYPS; QUALITY; IMPACT;
   PARTICIPATION
AB BACKGROUND AND AIMS: Up to 30% of adenomas might be missed during screening colonoscopy-these could be polyps that appear on-screen but are not recognized by endoscopists or polyps that are in locations that do not appear on the screen at all. Computer-aided detection (CADe) systems, based on deep learning, might reduce rates of missed adenomas by displaying visual alerts that identify precancerous polyps on the endoscopy monitor in real time. We compared adenoma miss rates of CADe colonoscopy vs routine white-light colonoscopy.
   METHODS: We performed a prospective study of patients, 1875 years old, referred for diagnostic, screening, or surveillance colonoscopies at a single endoscopy center of Sichuan Provincial People's Hospital from June 3, 2019 through September 24, 2019. Same day, tandem colonoscopies were performed for each participant by the same endoscopist. Patients were randomly assigned to groups that received either CADe colonoscopy (n=184) or routine colonoscopy (n=185) first, followed immediately by the other procedure. Endoscopists were blinded to the group each patient was assigned to until immediately before the start of each colonoscopy. Polyps that were missed by the CADe system but detected by endoscopists were classified as missed polyps. False polyps were those continuously traced by the CADe system but then determined not to be polyps by the endoscopists. The primary endpoint was adenoma miss rate, which was defined as the number of adenomas detected in the second-pass colonoscopy divided by the total number of adenomas detected in both passes.
   RESULTS: The adenoma miss rate was significantly lower with CADe colonoscopy (13.89%; 95% CI, 8.24%-19.54%) than with routine colonoscopy (40.00%; 95% CI, 31.23%-48.77%, P<.0001). The polyp miss rate was significantly lower with CADe colonoscopy (12.98%; 95% CI, 9.08%-16.88%) than with routine colonoscopy (45.90%; 95% CI, 39.65%-52.15%) (P<.0001). Adenoma miss rates in ascending, transverse, and descending colon were significantly lower with CADe colonoscopy than with routine colonoscopy (ascending colon 6.67% vs 39.13%; P=.0095; transverse colon 16.33% vs 45.16%; P=.0065; and descending colon 12.50% vs 40.91%, P=.0364).
   CONCLUSIONS: CADe colonoscopy reduced the overall miss rate of adenomas by endoscopists using white-light endoscopy. Routine use of CADe might reduce the incidence of interval colon cancers.
C1 [Wang, Pu; Liu, Peixi; Zhou, Guanyu; Lei, Shan; Liu, Xiaogang; Li, Liangping; Xiao, Xun] Sichuan Acad Med Sci, Dept Gastroenterol, 32 West Second Sect,First Ring Rd, Chengdu 610042, Sichuan, Peoples R China.
   [Wang, Pu; Liu, Peixi; Zhou, Guanyu; Lei, Shan; Liu, Xiaogang; Li, Liangping; Xiao, Xun] Sichuan Prov Peoples Hosp, 32 West Second Sect,First Ring Rd, Chengdu 610042, Sichuan, Peoples R China.
   [Brown, Jeremy R. Glissen; Berzin, Tyler M.] Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Boston, MA 02215 USA.
   [Brown, Jeremy R. Glissen; Berzin, Tyler M.] Harvard Med Sch, Ctr Adv Endoscopy, Boston, MA 02115 USA.
C3 Sichuan Provincial People's Hospital; Sichuan Provincial People's
   Hospital; Harvard University; Beth Israel Deaconess Medical Center;
   Harvard University; Harvard Medical School
RP Xiao, X (通讯作者)，Sichuan Acad Med Sci, Dept Gastroenterol, 32 West Second Sect,First Ring Rd, Chengdu 610042, Sichuan, Peoples R China.; Xiao, X (通讯作者)，Sichuan Prov Peoples Hosp, 32 West Second Sect,First Ring Rd, Chengdu 610042, Sichuan, Peoples R China.
EM xiaoxun001@outlook.com
OI Glissen Brown, Jeremy/0000-0002-7204-7241; Wang, Pu/0000-0002-1234-309X
CR Adler A, 2012, CLIN GASTROENTEROL H, V10, P155, DOI 10.1016/j.cgh.2011.10.026
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Almansa C, 2011, AM J GASTROENTEROL, V106, P1070, DOI 10.1038/ajg.2011.26
   Aniwan S, 2016, AM J GASTROENTEROL, V111, P723, DOI 10.1038/ajg.2015.440
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Bai Y, 2018, ENDOSCOPY, V50, P128, DOI 10.1055/s-0043-119213
   Berzin TM, 2020, LANCET, V395, P485, DOI 10.1016/S0140-6736(20)30294-4
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Cai B, 2015, ONCOL LETT, V9, P2073, DOI 10.3892/ol.2015.3005
   Chin M, 2016, WORLD J GASTROENTERO, V22, P9642, DOI 10.3748/wjg.v22.i43.9642
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dominitz JA, 2016, AM J GASTROENTEROL, V111, P730, DOI 10.1038/ajg.2016.103
   Gralnek IM, 2014, LANCET ONCOL, V15, P353, DOI 10.1016/S1470-2045(14)70020-8
   Halpern Z, 2015, ENDOSCOPY, V47, P238, DOI 10.1055/s-0034-1391437
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Head J, 2015, EXP BRAIN RES, V233, P1481, DOI 10.1007/s00221-015-4222-z
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Jia H, 2017, AM J GASTROENTEROL, V112, P568, DOI 10.1038/ajg.2016.501
   Nguyen KT, 2019, J VISION, V19, DOI 10.1167/19.14.14
   Kudo T, 2018, GASTROINTEST ENDOSC, V88, P854, DOI 10.1016/j.gie.2018.06.011
   Lami M, 2018, ENDOSCOPY, V50, P701, DOI 10.1055/s-0044-101026
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Leufkens AM, 2011, GASTROINTEST ENDOSC, V73, P480, DOI 10.1016/j.gie.2010.09.004
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Memmert D, 2010, J GEN PSYCHOL, V137, P129, DOI 10.1080/00221301003645061
   Rex DK, 2003, AM J GASTROENTEROL, V98, P2000, DOI 10.1016/S0002-9270(03)00625-7
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rutter MD, 2020, GUT, V69, P201, DOI 10.1136/gutjnl-2019-319858
   Shinozaki S, 2020, DIGEST ENDOSC, V32, P874, DOI 10.1111/den.13613
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Tziatzios G, 2019, DIGEST LIVER DIS, V51, P1079, DOI 10.1016/j.dld.2019.05.012
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Xu Y, 2018, SCAND J GASTROENTERO, V53, P365, DOI 10.1080/00365521.2018.1433230
   Yoo WG, 2014, J PHYS THER SCI, V26, P1807, DOI 10.1589/jpts.26.1807
   Zhou GY, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231880
NR 42
TC 87
Z9 92
U1 2
U2 14
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD OCT
PY 2020
VL 159
IS 4
BP 1252
EP +
DI 10.1053/j.gastro.2020.06.023
PG 15
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA OC9ZA
UT WOS:000579513500033
PM 32562721
OA Bronze
DA 2023-08-21
ER

PT J
AU Luo, YC
   Zhang, Y
   Liu, M
   Lai, YH
   Liu, PP
   Wang, Z
   Xing, TY
   Huang, Y
   Li, Y
   Li, AM
   Wang, YD
   Luo, XB
   Liu, SD
   Han, ZL
AF Luo, Yuchen
   Zhang, Yi
   Liu, Ming
   Lai, Yihong
   Liu, Panpan
   Wang, Zhen
   Xing, Tongyin
   Huang, Ying
   Li, Yue
   Li, Aiming
   Wang, Yadong
   Luo, Xiaobei
   Liu, Side
   Han, Zelong
TI Artificial Intelligence-Assisted Colonoscopy for Detection of Colon
   Polyps: a Prospective, Randomized Cohort Study
SO JOURNAL OF GASTROINTESTINAL SURGERY
LA English
DT Article
DE Colonoscopy; Artificial intelligence; Computer-aided diagnose
ID COMPUTER-AIDED DETECTION; MISS RATE; INCREASES; RISK
AB Background and aims Improving the rate of polyp detection is an important measure to prevent colorectal cancer (CRC). Real-time automatic polyp detection systems, through deep learning methods, can learn and perform specific endoscopic tasks previously performed by endoscopists. The purpose of this study was to explore whether a high-performance, real-time automatic polyp detection system could improve the polyp detection rate (PDR) in the actual clinical environment.
   Methods The selected patients underwent same-day, back-to-back colonoscopies in a random order, with either traditional colonoscopy or artificial intelligence (AI)-assisted colonoscopy performed first by different experienced endoscopists (> 3000 colonoscopies). The primary outcome was the PDR. It was registered with. (NCT047126265).
   Results In this study, we randomized 150 patients. The AI system significantly increased the PDR (34.0% vs 38.7%,p< 0.001). In addition, AI-assisted colonoscopy increased the detection of polyps smaller than 6 mm (69 vs 91,p< 0.001), but no difference was found with regard to larger lesions.
   Conclusions A real-time automatic polyp detection system can increase the PDR, primarily for diminutive polyps. However, a larger sample size is still needed in the follow-up study to further verify this conclusion.
C1 [Luo, Yuchen; Zhang, Yi; Liu, Ming; Lai, Yihong; Liu, Panpan; Wang, Zhen; Xing, Tongyin; Huang, Ying; Li, Yue; Li, Aiming; Wang, Yadong; Luo, Xiaobei; Liu, Side; Han, Zelong] Southern Med Univ, Nanfang Hosp, Dept Gastroenterol, Guangzhou 510515, Peoples R China.
C3 Southern Medical University - China
RP Luo, XB; Liu, SD; Han, ZL (通讯作者)，Southern Med Univ, Nanfang Hosp, Dept Gastroenterol, Guangzhou 510515, Peoples R China.
EM luoxiaobei63@126.com; liuside2011@163.com; hzl198886@163.com
RI wangwangwang, yuanyaunyuan/HHN-6432-2022; liu, pan/HIR-9103-2022
FU Guangdong Gastrointestinal Disease Research Center [2017B020209003]
FX This project is supported by the "Guangdong Gastrointestinal Disease
   Research Center" (No.2017B020209003).
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Bressler B, 2007, GASTROENTEROLOGY, V132, P96, DOI 10.1053/j.gastro.2006.10.027
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   International Agency for Research on Cancer, 2018, GLOB 2018 CANC FACH
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lieberman DA, 2000, NEW ENGL J MED, V343, P162, DOI 10.1056/NEJM200007203430301
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2019, GUT
   Zheng B, 2012, SURG ENDOSC, V26, P1352, DOI 10.1007/s00464-011-2038-x
NR 16
TC 32
Z9 32
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1091-255X
EI 1873-4626
J9 J GASTROINTEST SURG
JI J. Gastrointest. Surg.
PD AUG
PY 2021
VL 25
IS 8
BP 2011
EP 2018
DI 10.1007/s11605-020-04802-4
EA SEP 2020
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA TS1SM
UT WOS:000572314000001
PM 32968933
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Lui, TKL
   Leung, WK
AF Lui, Thomas K. L.
   Leung, Wai K.
TI Is artificial intelligence the final answer to missed polyps in
   colonoscopy?
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Artificial intelligence; Adenoma; Colonoscopy; Colorectal cancer; Polyps
ID WHITE-LIGHT COLONOSCOPY; ADENOMA DETECTION RATE; COLORECTAL CANCERS;
   SCREENING COLONOSCOPY; WITHDRAWAL TIMES; INCREASES; PARTICIPATION;
   RETROFLEXION; MULTICENTER; DEFINITION
AB Lesions missed by colonoscopy are one of the main reasons for post-colonoscopy colorectal cancer, which is usually associated with a worse prognosis. Because the adenoma miss rate could be as high as 26%, it has been noted that endoscopists with higher adenoma detection rates are usually associated with lower adenoma miss rates. Artificial intelligence (AI), particularly the deep learning model, is a promising innovation in colonoscopy. Recent studies have shown that AI is not only accurate in colorectal polyp detection but can also reduce the miss rate. Nevertheless, the application of AI in real-time detection has been hindered by heterogeneity of the AI models and study design as well as a lack of long-term outcomes. Herein, we discussed the principle of various AI models and systematically reviewed the current data on the use of AI on colorectal polyp detection and miss rates. The limitations and future prospects of AI on colorectal polyp detection are also discussed.
C1 [Lui, Thomas K. L.; Leung, Wai K.] Univ Hong Kong, Dept Med, Queen Mary Hosp, 102 Pokfulam Rd, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Leung, WK (通讯作者)，Univ Hong Kong, Dept Med, Queen Mary Hosp, 102 Pokfulam Rd, Hong Kong, Peoples R China.
EM waikleung@hku.hk
OI Lui, Ka Luen, Thomas/0000-0002-2986-3681
CR [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2012, MACHINE LEARNING PRO
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Atkinson NSS, 2019, GASTROENTEROLOGY, V157, P462, DOI 10.1053/j.gastro.2019.04.014
   Barclay RI, 2005, GASTROINTEST ENDOSC, V61, pAB107, DOI 10.1016/S0016-5107(05)00682-6
   Barclay RL, 2008, CLIN GASTROENTEROL H, V6, P1091, DOI 10.1016/j.cgh.2008.04.018
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cadoni S, 2017, ENDOSCOPY, V49, P456, DOI 10.1055/s-0043-101229
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cheung KS, 2019, J GASTROEN HEPATOL, V34, P1545, DOI 10.1111/jgh.14674
   Clark BT, 2014, AM J GASTROENTEROL, V109, P1714, DOI 10.1038/ajg.2014.232
   Cohen J, 2017, J CLIN GASTROENTEROL, V51, P818, DOI 10.1097/MCG.0000000000000695
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Fitzmaurice C, 2017, JAMA ONCOL, V3, P524, DOI 10.1001/jamaoncol.2016.5688
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gupta N, 2016, GASTROENTEROLOGY, V151, P1054, DOI 10.1053/j.gastro.2016.10.008
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kudo T, 2018, GASTROINTEST ENDOSC, V88, P854, DOI 10.1016/j.gie.2018.06.011
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee HS, 2017, ENDOSCOPY, V49, P334, DOI 10.1055/s-0042-119401
   Leung WK, 2020, GASTROINTEST ENDOSC, V91, P104, DOI 10.1016/j.gie.2019.06.031
   Leung WK, 2014, AM J GASTROENTEROL, V109, P855, DOI 10.1038/ajg.2014.83
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Lui TK, 2020, GASTROINTEST ENDOSC, VS0016-5107, P34459
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Rameshshanker R, 2020, GASTROINTEST ENDOSC, V91, P894, DOI 10.1016/j.gie.2019.11.046
   Repici A, 2020, GASTROENTEROLOGY
   Robertson DJ, 2014, GUT, V63, P949, DOI 10.1136/gutjnl-2012-303796
   Russell JA, 2010, SPORTS REHABILITATION AND INJURY PREVENTION, P3
   Sanduleanu S, 2015, GUT, V64, P1257, DOI 10.1136/gutjnl-2014-307992
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Takiyama H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25842-6
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, GASTROENTEROLOGY
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang WH, 2018, INT J COLORECTAL DIS, V33, P561, DOI 10.1007/s00384-018-3003-0
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 45
TC 11
Z9 12
U1 0
U2 9
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD SEP 21
PY 2020
VL 26
IS 35
BP 5248
EP 5255
DI 10.3748/wjg.v26.i35.5248
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA NV6LA
UT WOS:000574429300002
PM 32994685
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Wang, KW
   Dong, M
AF Wang, Ke-Wei
   Dong, Ming
TI Potential applications of artificial intelligence in colorectal polyps
   and cancer: Recent advances and prospects
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Review
DE Artificial intelligence; Deep learning; Computer-assisted diagnosis;
   Colorectal polyps; Colorectal cancer
ID COMPUTER-AIDED DIAGNOSIS; ADENOMA DETECTION RATE; MISS RATE; SYSTEM;
   LESIONS; CLASSIFICATION; COLONOSCOPY; ACCURACY; ENDOCYTOSCOPY;
   RECOGNITION
AB Since the advent of artificial intelligence (AI) technology, it has been constantly studied and has achieved rapid development. The AI assistant system is expected to improve the quality of automatic polyp detection and classification. It could also help prevent endoscopists from missing polyps and make an accurate optical diagnosis. These functions provided by AI could result in a higher adenoma detection rate and decrease the cost of polypectomy for hyperplastic polyps. In addition, AI has good performance in the staging, diagnosis, and segmentation of colorectal cancer. This article provides an overview of recent research focusing on the application of AI in colorectal polyps and cancer and highlights the advances achieved.
C1 [Wang, Ke-Wei; Dong, Ming] China Med Univ, Affiliated Hosp 1, Dept Gastrointestinal Surg, 155 Nanjing North St, Shenyang 110001, Liaoning, Peoples R China.
C3 China Medical University
RP Wang, KW (通讯作者)，China Med Univ, Affiliated Hosp 1, Dept Gastrointestinal Surg, 155 Nanjing North St, Shenyang 110001, Liaoning, Peoples R China.
EM kwwang@cmu.edu.cn
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Atkinson NSS, 2019, GASTROENTEROLOGY, V157, P462, DOI 10.1053/j.gastro.2019.04.014
   Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Brenner H, 2014, LANCET, V383, P1490, DOI 10.1016/S0140-6736(13)61649-9
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Coe SG, 2013, GASTROINTEST ENDOSC, V77, P631, DOI 10.1016/j.gie.2012.12.001
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Grey ADNJ, 2016, REJUV RES, V19, P105, DOI 10.1089/rej.2016.1827
   De Palma GD, 2016, COLORECTAL DIS, V18, pO66, DOI 10.1111/codi.13222
   Ding L, 2019, CHINESE MED J-PEKING, V132, P379, DOI 10.1097/CM9.0000000000000095
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Gupta N, 2017, CLIN GASTROENTEROL H, V15, P820, DOI 10.1016/j.cgh.2017.01.033
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Ichimasa K, 2018, ENDOSCOPY, V50, P230, DOI 10.1055/s-0043-122385
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Jin EH, 2020, GASTROENTEROLOGY, V158, P2169, DOI [10.1053/j.gastro.2020.02.03, 10.1053/j.gastro.2020.02.036]
   Kainz P, 2017, PEERJ, V5, DOI 10.7717/peerj.3874
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li Y, 2019, AM J CANCER RES, V9, P2482
   Li ZX, 2018, OPHTHALMOLOGY, V125, P1199, DOI 10.1016/j.ophtha.2018.01.023
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Lu Y, 2018, CANCER RES, V78, P5135, DOI 10.1158/0008-5472.CAN-18-0494
   Lui TKL, 2020, GASTROINTEST ENDOSC, V92, P11, DOI 10.1016/j.gie.2020.02.033
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Neumann H, 2015, DIGEST ENDOSC, V27, P232, DOI 10.1111/den.12395
   Raczkowski L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50587-1
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sena P, 2019, ONCOL LETT, V18, P6101, DOI 10.3892/ol.2019.10928
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Theofilatos K, 2015, ARTIF INTELL MED, V63, P181, DOI 10.1016/j.artmed.2014.12.012
   Trebeschi S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05728-9
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang JZ, 2018, MED PHYS, V45, P2560, DOI 10.1002/mp.12918
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yamakawa M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44035-3
   Yoon H, 2019, J DIGIT IMAGING, V32, P131, DOI 10.1007/s10278-018-0112-9
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang S, 2019, COMPUT MED IMAG GRAP, V77, DOI 10.1016/j.compmedimag.2019.101645
NR 67
TC 19
Z9 20
U1 5
U2 17
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD SEP 14
PY 2020
VL 26
IS 34
BP 5090
EP 5100
DI 10.3748/wjg.v26.i34.5090
PG 11
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA NW2OK
UT WOS:000574849000003
PM 32982111
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Hwang, M
   Wang, D
   Kong, XX
   Wang, ZH
   Li, J
   Jiang, WC
   Hwang, KS
   Ding, KF
AF Hwang, Maxwell
   Wang, Da
   Kong, Xiang-Xing
   Wang, Zhanhuai
   Li, Jun
   Jiang, Wei-Cheng
   Hwang, Kao-Shing
   Ding, Kefeng
TI An automated detection system for colonoscopy images using a dual
   encoder-decoder model
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Article
DE Colorectal cancer; Computer-aided detection; Deep learning; Polyp
   detection; Convolutional neural network
ID POLYPS
AB Conventional computer-aided detection systems (CADs) for colonoscopic images utilize shape, texture, or temporal information to detect polyps, so they have limited sensitivity and specificity. This study proposes a method to extract possible polyp features automatically using convolutional neural networks (CNNs). The objective of this work aims at building up a light-weight dual encoder-decoder model structure for polyp detection in colonoscopy Images. This proposed model, though with a relatively shallow structure, is expected to have the capability of a similar performance to the methods with much deeper structures. The proposed CAD model consists of two sequential encoder-decoder networks that consist of several CNN layers and full connection layers. The front end of the model is a hetero-associator (also known as hetero-encoder) that uses backpropagation learning to generate a set of reliably corrupted labeled images with a certain degree of similarity to a ground truth image, which eliminates the need for a large amount of training data that is usually required for medical images tasks. This dual CNN architecture generates a set of noisy images that are similar to the labeled data to train its counterpart, the auto-associator (also known as auto-encoder), in order to increase the successor's discriminative power in classification. The auto-encoder is also equipped with CNNs to simultaneously capture the features of the labeled images that contain noise. The proposed method uses features that are learned from open medical datasets and the dataset of Zhejiang University (ZJU), which contains around one thousand images. The performance of the proposed architecture is compared with a state-of-the-art detection model in terms of the metrics of the Jaccard index, the DICE similarity score, and two other geometric measures. The improvements in the performance of the proposed model are attributed to the effective reduction in false positives in the auto-encoder and the generation of noisy candidate images by the hetero-encoder. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Hwang, Maxwell; Wang, Da; Kong, Xiang-Xing; Wang, Zhanhuai; Li, Jun; Ding, Kefeng] Zhejiang Univ, Dept Colorectal Surg, Affiliated Hosp 2, Sch Med, Hangzhou, Peoples R China.
   [Hwang, Maxwell; Wang, Da; Kong, Xiang-Xing; Wang, Zhanhuai; Li, Jun; Ding, Kefeng] China Natl Minist Educ, Key Lab Mol Biol Med Sci, Key Lab Canc Prevent & Intervent, Canc Inst, Hangzhou, Zhejiang, Peoples R China.
   [Hwang, Maxwell; Wang, Da; Kong, Xiang-Xing; Wang, Zhanhuai; Li, Jun; Ding, Kefeng] Zhejiang Univ, Sch Med, Affiliated Hosp 2, Hangzhou, Peoples R China.
   [Jiang, Wei-Cheng] Tunghai Univ, Dept Elect Engn, Taichung, Taiwan.
   [Hwang, Kao-Shing] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
C3 Zhejiang University; Zhejiang University; Tunghai University; National
   Sun Yat Sen University
RP Ding, KF (通讯作者)，China Natl Minist Educ, Key Lab Mol Biol Med Sci, Key Lab Canc Prevent & Intervent, Canc Inst, Hangzhou, Zhejiang, Peoples R China.
EM dingkefeng@zju.edu.cn
OI Hwang, Kao-Shing/0000-0001-9234-4836
FU Key Technology Research and Development Program of Zhejiang Province
   [2017C03017]; National Natural Science Foundation of China [81672916,
   LQ17H160008]; National Key R&D Program of China [2017YFC0908200]
FX This work was supported in part by the Key Technology Research and
   Development Program of Zhejiang Province (2017C03017), the National
   Natural Science Foundation of China (81672916) and (LQ17H160008), and
   the National Key R&D Program of China (2017YFC0908200).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   El Khatib A., 2015, P IEEE ANN INT C MED
   Fernandes K., 2018, IEEE ACCESS, DOI DOI 10.1109/ACCESS.2018
   Fischer P., 2003, P MED IM COMP ASS IN
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu M, 2019, IEEE ACCESS, V7, P75058, DOI [10.1109/ACCESS.2019.2921027, 10.1109/access.2019.2921027]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ranzato M.A., 2007, 2007 IEEE C COM VIS, P1, DOI [10.1109/CVPR.2007.383157, DOI 10.1109/CVPR.2007.383157, 10.1109/cvpr.2007.383157]
   Roth H.R., 2015, P IEEE INT S BIOM IM
   Sharifi M., 2019, J BIOMOL STRUCT DYN, P1, DOI DOI 10.1080/07391102.2019.1643787
   Shin Y., 2017, P 39 ANN INT C IEEE
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Sundaram PS, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1153-9
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D., 2017, J HEALTHC ENG, P1
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 23
TC 6
Z9 6
U1 0
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD SEP
PY 2020
VL 84
AR 101763
DI 10.1016/j.compmedimag.2020.101763
PG 9
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA NR0ET
UT WOS:000571238200012
PM 32805673
DA 2023-08-21
ER

PT J
AU Gao, JB
   Guo, YH
   Sun, YX
   Qu, GQ
AF Gao, Junbo
   Guo, Yuanhao
   Sun, Yingxue
   Qu, Guoqiang
TI Application of Deep Learning for Early Screening of Colorectal
   Precancerous Lesions under White Light Endoscopy
SO COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE
LA English
DT Article
ID CLASSIFICATION; CANCER
AB Background and Objective. Colorectal cancer (CRC) is a common gastrointestinal tumour with high morbidity and mortality. Endoscopic examination is an effective method for early detection of digestive system tumours. However, due to various reasons, missed diagnoses and misdiagnoses are common occurrences. Our goal is to use deep learning methods to establish colorectal lesion detection, positioning, and classification models based on white light endoscopic images and to design a computer-aided diagnosis (CAD) system to help physicians reduce the rate of missed diagnosis and improve the accuracy of the detection rate.Methods. We collected and sorted out the white light endoscopic images of some patients undergoing colonoscopy. The convolutional neural network model is used to detect whether the image contains lesions: CRC, colorectal adenoma (CRA), and colorectal polyps. The accuracy, sensitivity, and specificity rates are used as indicators to evaluate the model. Then, the instance segmentation model is used to locate and classify the lesions on the images containing lesions, and mAP (mean average precision), AP(50), and AP(75)are used to evaluate the performance of an instance segmentation model.Results. In the process of detecting whether the image contains lesions, we compared ResNet50 with the other four models, that is, AlexNet, VGG19, ResNet18, and GoogLeNet. The result is that ResNet50 performs better than several other models. It scored an accuracy of 93.0%, a sensitivity of 94.3%, and a specificity of 90.6%. In the process of localization and classification of the lesion in images containing lesions by Mask R-CNN, its mAP, AP(50), and AP(75)were 0.676, 0.903, and 0.833, respectively.Conclusion. We developed and compared five models for the detection of lesions in white light endoscopic images. ResNet50 showed the optimal performance, and Mask R-CNN model could be used to locate and classify lesions in images containing lesions.
C1 [Gao, Junbo; Guo, Yuanhao; Sun, Yingxue] Shanghai Maritime Univ, Informat Engn Coll, Shanghai 201306, Peoples R China.
   [Qu, Guoqiang] Shanghai Sixth People Hosp, Eastern Hosp, Dept Gastroenterol, Shanghai 201306, Peoples R China.
C3 Shanghai Maritime University
RP Gao, JB (通讯作者)，Shanghai Maritime Univ, Informat Engn Coll, Shanghai 201306, Peoples R China.
EM jbgao@shmtu.edu.cn; 915695803@qq.com; 770652728@qq.com; qgqahtl@163.com
FU Shanghai University of Medicine and Health Sciences Seed Foundation
   [SFP-18-22-14-006]
FX This research was supported by the Shanghai University of Medicine and
   Health Sciences Seed Foundation (SFP-18-22-14-006) in China.
CR Ali N, 2019, TRANSLATIONAL BIOPHO, V1, DOI [10.1002/tbio.201900003, DOI 10.1002/TBIO.201900003]
   Chen YP, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203897
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Lange T, 2018, WORLD J GASTROENTERO, V24, P5057, DOI 10.3748/wjg.v24.i45.5057
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Fu YH, 2018, MINER ENG, V115, P68, DOI 10.1016/j.mineng.2017.10.005
   Hariharan B, 2017, IEEE T PATTERN ANAL, V39, P627, DOI 10.1109/TPAMI.2016.2578328
   Jia J., 2014, US Patent, Patent No. 201414471
   Jiang W, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301374
   Jie X., 2014, CHINESE J COLORECTAL, V3
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Liu YiJia, 2019, International Journal of Geosciences, V10, P884, DOI 10.4236/ijg.2019.1010050
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Murino A, 2016, CURR OPIN GASTROEN, V32, P38, DOI 10.1097/MOG.0000000000000230
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Soltani G, 2019, BMC ENDOCR DISORD, V19, DOI 10.1186/s12902-019-0444-6
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Togashi K, 2019, DIGEST ENDOSC, V31, P270, DOI 10.1111/den.13354
   Wen W., 2016, P ADV NEUR INF PROC
   Wu XL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151287
   Xia D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124169
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 28
TC 7
Z9 7
U1 2
U2 9
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1748-670X
EI 1748-6718
J9 COMPUT MATH METHOD M
JI Comput. Math. Method Med.
PD AUG 25
PY 2020
VL 2020
AR 8374317
DI 10.1155/2020/8374317
PG 8
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA NQ3MP
UT WOS:000570768800004
PM 32952602
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Fonolla, R
   van der Zander, QEW
   Schreuder, RM
   Masclee, AAM
   Schoon, EJ
   van der Sommen, F
   de With, PHN
AF Fonolla, Roger
   E. W. van der Zander, Quirine
   Schreuder, Ramon M.
   Masclee, Ad A. M.
   Schoon, Erik J.
   van der Sommen, Fons
   de With, Peter H. N.
TI A CNN CADx System for Multimodal Classification of Colorectal Polyps
   Combining WL, BLI, and LCI Modalities
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE blue light imaging; linked color imaging; colorectal polyp
   classification; artificial intelligence; deep learning; CADx; CNN
ID CHROMOENDOSCOPY; ENDOSCOPY; DIAGNOSIS
AB Colorectal polyps are critical indicators of colorectal cancer (CRC). Blue Laser Imaging and Linked Color Imaging are two modalities that allow improved visualization of the colon. In conjunction with the Blue Laser Imaging (BLI) Adenoma Serrated International Classification (BASIC) classification, endoscopists are capable of distinguishing benign and pre-malignant polyps. Despite these advancements, this classification still prevails a high misclassification rate for pre-malignant colorectal polyps. This work proposes a computer aided diagnosis (CADx) system that exploits the additional information contained in two novel imaging modalities, enabling more informative decision-making during colonoscopy. We train and benchmark six commonly used CNN architectures and compare the results with 19 endoscopists that employed the standard clinical classification model (BASIC). The proposed CADx system for classifying colorectal polyps achieves an area under the curve (AUC) of 0.97. Furthermore, we incorporate visual explanatory information together with a probability score, jointly computed from White Light, Blue Laser Imaging, and Linked Color Imaging. Our CADx system for automatic polyp malignancy classification facilitates future advances towards patient safety and may reduce time-consuming and costly histology assessment.
C1 [Fonolla, Roger; van der Sommen, Fons; de With, Peter H. N.] Eindhoven Univ Technol, Dept Elect Engn Video Coding & Architectures VCA, NL-5600 MB Eindhoven, Netherlands.
   [E. W. van der Zander, Quirine; Masclee, Ad A. M.] Maastricht Univ, Med Ctr, Div Gastroenterol & Hepatol, NL-6229 HX Maastricht, Netherlands.
   [E. W. van der Zander, Quirine] Maastricht Univ, Sch Oncol & Dev Biol GROW, NL-6229 ER Maastricht, Netherlands.
   [Schreuder, Ramon M.; Schoon, Erik J.] Catharina Hosp, Dept Gastroenterol & Hepatol, NL-5623 EJ Eindhoven, Netherlands.
   [Masclee, Ad A. M.] Maastricht Univ, Sch Nutr & Translat Res Metab NUTRIM, NL-6229 ER Maastricht, Netherlands.
C3 Eindhoven University of Technology; Maastricht University; Maastricht
   University; Catharina Hospital; Maastricht University
RP Fonolla, R (通讯作者)，Eindhoven Univ Technol, Dept Elect Engn Video Coding & Architectures VCA, NL-5600 MB Eindhoven, Netherlands.
EM r.fonolla.navarro@tue.nl; q.vanderzander@maastrichtuniversity.nl;
   ramonmichel.schreuder@catharinaziekenhuis.nl; a.masclee@mumc.nl;
   erik.schoon@catharinaziekenhuis.nl; fvdsommen@tue.nl;
   P.H.N.de.With@tue.nl
OI van der Sommen, Fons/0000-0002-3593-2356; van der Zander, Quirine
   E.W./0000-0002-8640-5521; Fonolla, Roger/0000-0002-1024-9091
FU European Union [721766]; Marie Curie Actions (MSCA) [721766] Funding
   Source: Marie Curie Actions (MSCA)
FX This project has received funding from the European Union's Horizon 2020
   research and innovation program under the Marie Sklodowska-Curie grant
   agreement No. 721766.
CR Bisschops R, 2018, ENDOSCOPY, V50, P211, DOI 10.1055/s-0043-121570
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   East JE, 2007, GUT, V56, P1168
   Ferlay J, 2019, INT J CANCER, V144, P1941, DOI 10.1002/ijc.31937
   Fonolla R, 2019, I S BIOMED IMAGING, P74, DOI 10.1109/ISBI.2019.8759320
   Gross S., 2009, SPIE MED IMAGING, V7260
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Har-Noy O, 2017, DIGEST DIS SCI, V62, P2982, DOI 10.1007/s10620-017-4772-y
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jass JR, 2007, HISTOPATHOLOGY, V50, P113, DOI 10.1111/j.1365-2559.2006.02549.x
   Kandel P, 2019, CLIN ENDOSC, V52, P239, DOI 10.5946/ce.2018.136
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Murata M, 2017, NINTH INTERNATIONAL CONFERENCES ON PERVASIVE PATTERNS AND APPLICATIONS (PATTERNS 2017), P109
   Neumann H, 2018, UNITED EUR GASTROENT, V6, P1099, DOI 10.1177/2050640618769731
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Ribeiro E, 2017, I S BIOMED IMAGING, P1044, DOI 10.1109/ISBI.2017.7950695
   Scheeve T., 2019, MED IMAGING 2019 COM
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Subramaniam S, 2019, UNITED EUR GASTROENT, V7, P316, DOI 10.1177/2050640618822402
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Tsuji S, 2018, ENDOSC INT OPEN, V6, pE1382, DOI 10.1055/a-0650-4362
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Visovan II, 2017, BOSNIAN J BASIC MED, V17, P152, DOI 10.17305/bjbms.2017.1686
   Vleugels JLA, 2018, GASTROENTEROLOGY, V154, P1682, DOI 10.1053/j.gastro.2018.01.063
   Wang DC, 2019, PROC INT C TOOLS ART, P636, DOI 10.1109/ICTAI.2019.00094
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Yoshida N, 2019, GUT LIVER, V13, P140, DOI 10.5009/gnl18276
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 37
TC 12
Z9 12
U1 2
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD AUG
PY 2020
VL 10
IS 15
AR 5040
DI 10.3390/app10155040
PG 13
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA NL0QB
UT WOS:000567129600001
OA Green Submitted, gold
DA 2023-08-21
ER

PT J
AU Haj-Manouchehri, A
   Mohammadi, HM
AF Haj-Manouchehri, Azadeh
   Mohammadi, Hossein Mahvash
TI Polyp detection using CNNs in colonoscopy video
SO IET COMPUTER VISION
LA English
DT Article
ID VALIDATION
AB Polyps are a group of cells growing on the inner surface of the colon. Over time, some polyps can lead to colon cancer, which is often fatal if found in its later stages. Colon cancer can be prevented if the polyps are identified and removed in their early stages. Colonoscopy is a very effective screening method to remove polyps and it largely prevents colon cancer. However, some polyps may not be detected during a colonoscopy due to human error. Over the past two decades, many studies have been conducted on computer-aided detection to reduce the miss rate of polyps. This study consists of two distinct parts, the detection of frames containing polyps and polyp segmentation. In the first section, a new convolutional neural network based on the VGG network is proposed. The proposed network has an accuracy of 86% on a newly collected dataset. In the polyp segmentation section, a fully convolutional network and an effective post-processing algorithm are presented. An evaluation of the proposed polyp segmentation system on the ETIS-LARIB database achieves an overall 82.00% F2 score, which outperforms the methods that participated in the sub-challenge of MICCAI.
C1 [Haj-Manouchehri, Azadeh; Mohammadi, Hossein Mahvash] Univ Isfahan, Comp Engn Dept, Hezarjirib St, Esfahan, Iran.
C3 University of Isfahan
RP Mohammadi, HM (通讯作者)，Univ Isfahan, Comp Engn Dept, Hezarjirib St, Esfahan, Iran.
EM h.mahvash@eng.ui.ac.ir
RI Mahvash Mohammadi, Hossein/AAC-7200-2022
OI Mahvash Mohammadi, Hossein/0000-0003-0509-6219
CR Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Angermann Q, 2016, PROCEDIA COMPUT SCI, V90, P182, DOI 10.1016/j.procs.2016.07.017
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hwang S., 2007, 2007 IEEE INT C IM P, V2, pI
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kingma D., 2015, ARXIV
   Liu Q., 2017, THESIS
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Mustain B., 2017, INT J BIOMED IMAGING, P1, DOI [10.1155/2017/9545920, DOI 10.1155/2017/9545920]
   Park S., 2015, POLYP DETECTION COLO
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Taha Bilal, 2017, Proceedings of the IASTED International Conference on Biomedical Engineering (BioMed 2017), P233, DOI 10.2316/P.2017.852-031
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Uhl A, 2014, IEEE IMAGE PROC, P2299, DOI 10.1109/ICIP.2014.7025466
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan ZJ, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254671
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 31
TC 16
Z9 16
U1 1
U2 6
PU INST ENGINEERING TECHNOLOGY-IET
PI HERTFORD
PA MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND
SN 1751-9632
EI 1751-9640
J9 IET COMPUT VIS
JI IET Comput. Vis.
PD AUG
PY 2020
VL 14
IS 5
BP 241
EP 247
DI 10.1049/iet-cvi.2019.0300
PG 7
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PE2XJ
UT WOS:000598231500008
OA Bronze
DA 2023-08-21
ER

PT J
AU Sanchez-Peralta, LF
   Bote-Curiel, L
   Picon, A
   Sanchez-Margallo, FM
   Pagador, JB
AF Sanchez-Peralta, Luisa F.
   Bote-Curiel, Luis
   Picon, Artzai
   Sanchez-Margallo, Francisco M.
   Blas Pagador, J.
TI Deep learning to find colorectal polyps in colonoscopy: A systematic
   literature review
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Review
DE Colorectal cancer; Deep learning; Detection; Localization; Segmentation
ID CONVOLUTIONAL NEURAL-NETWORKS; COMPUTER-AIDED DETECTION; CLASSIFICATION;
   VALIDATION; DIAGNOSIS; LESIONS
AB Colorectal cancer has a great incidence rate worldwide, but its early detection significantly increases the survival rate. Colonoscopy is the gold standard procedure for diagnosis and removal of colorectal lesions with potential to evolve into cancer and computer-aided detection systems can help gastroenterologists to increase the adenoma detection rate, one of the main indicators for colonoscopy quality and predictor for colorectal cancer prevention. The recent success of deep learning approaches in computer vision has also reached this field and has boosted the number of proposed methods for polyp detection, localization and segmentation. Through a systematic search, 35 works have been retrieved. The current systematic review provides an analysis of these methods, stating advantages and disadvantages for the different categories used; comments seven publicly available datasets of colonoscopy images; analyses the metrics used for reporting and identifies future challenges and recommendations. Convolutional neural networks are the most used architecture together with an important presence of data augmentation strategies, mainly based on image transformations and the use of patches. End-to-end methods are preferred over hybrid methods, with a rising tendency. As for detection and localization tasks, the most used metric for reporting is the recall, while Intersection over Union is highly used in segmentation. One of the major concerns is the difficulty for a fair comparison and reproducibility of methods. Even despite the organization of challenges, there is still a need for a common validation framework based on a large, annotated and publicly available database, which also includes the most convenient metrics to report results. Finally, it is also important to highlight that efforts should be focused in the future on proving the clinical value of the deep learning based methods, by increasing the adenoma detection rate.
C1 [Sanchez-Peralta, Luisa F.; Bote-Curiel, Luis; Sanchez-Margallo, Francisco M.; Blas Pagador, J.] Jesus Uson Minimally Invas Surg Ctr, Ctra N-521,Km 41-8, Caceres 10071, Spain.
   [Picon, Artzai] Tecnalia Parque Cientif & Tecnol Bizkaia, C Astondo Bidea,Edificio 700, Derio 48160, Spain.
RP Sanchez-Peralta, LF (通讯作者)，Jesus Uson Minimally Invas Surg Ctr, Ctra N-521,Km 41-8, Caceres 10071, Spain.
EM lfsanchez@ccmijesususon.com; lbote@ccmijesuson.com;
   artzai.picon@tecnalia.com; msanche@ccmijesususon.com;
   jbpagador@ccmijesususon.com
RI Sánchez-Peralta, Luisa F./M-2976-2018; Bote-Curiel, Luis/Z-3437-2019;
   Sánchez Margallo, Francisco Miguel Miguel/I-5605-2019; Pagador, J.
   Blas/J-9858-2016; Sánchez-Peralta, Luisa F/G-9772-2012
OI Sánchez-Peralta, Luisa F./0000-0002-7630-353X; Bote-Curiel,
   Luis/0000-0001-8845-2834; Sánchez Margallo, Francisco Miguel
   Miguel/0000-0003-2138-988X; Pagador, J. Blas/0000-0002-4382-5075; Picon,
   Artzai/0000-0002-3316-6571
FU PICCOLO project; European Union [732111]
FX This work was partially supported by PICCOLO project. This project has
   received funding from the European Union's Horizon2020 Research and
   Innovation Programme under grant agreement No. 732111. The sole
   responsibility of this publication lies with the author. The European
   Union is not responsible for any use that may be made of the information
   contained therein. The authors would also like to thank Dr. Federico
   Soria for his support on this manuscript and Dr. Jose Carlos Marin, from
   Hospital 12 de Octubre, and Dr. Angel Calderon and Dr. Francisco Polo,
   from Hospital de Basurto, for the images in Fig. 4.
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Akbari M, 2018, IEEE ENG MED BIO, P65, DOI 10.1109/EMBC.2018.8512226
   Aksenov SV, 2018, SOVREM TEHNOL MED, V10, P7, DOI 10.17691/stm2018.10.2.01
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   [Anonymous], IMAGENET DAT
   [Anonymous], 2014, WORLD CANC REPORT 20
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Axyonov S., 2016, DISTRIBUTED COMPUTER, P27
   Badrinarayanan V, 2015, ARXIV151100561, DOI DOI 10.1109/TPAMI.2016.2644615
   Bardhi O, 2017, IEEE INT SYMP SIGNAL, P445, DOI 10.1109/ISSPIT.2017.8388684
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, INTECHOPEN, DOI [10.5772/61012, DOI 10.5772/61012]
   Bernal J, 2019, INT J COMPUT ASS RAD, V14, P191, DOI 10.1007/s11548-018-1864-x
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Berros Fombella JP, 2017, MANUAL SEOM PREVENCI
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Biswas M, 2019, FRONT BIOSCI-LANDMRK, V24, P392, DOI 10.2741/4725
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Castaneda D, 2018, GASTROINTEST ENDOSC, V88, P209, DOI 10.1016/j.gie.2018.03.022
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   COCO Consortium, MSCOCO DAT
   Cubuk E. D., 2018, ARXIV180509501
   Danelakis A, 2018, COMPUT MED IMAG GRAP, V70, P83, DOI 10.1016/j.compmedimag.2018.10.002
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Eaton-Rosen Z, 2018, 1 C MED IM DEEP LEAR
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ferlay J, 2018, EUR J CANCER, V103, P356, DOI 10.1016/j.ejca.2018.07.005
   FREEDMAN DA, 1981, ANN STAT, V9, P1218, DOI 10.1214/aos/1176345638
   Fu JJC, 2014, COMPUT MED IMAG GRAP, V38, P267, DOI 10.1016/j.compmedimag.2013.12.009
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   He B, 2019, ARTIF INTELL MED, V93, P43, DOI 10.1016/j.artmed.2018.05.001
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Heberle H, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0611-3
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   International Agency for Research on Cancer, 2018, TECH REP
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Jegou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Joskowicz L, 2019, EUR RADIOL, V29, P1391, DOI 10.1007/s00330-018-5695-5
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kim J, 2018, PRECIS FUTURE MED, V2, P37, DOI 10.23838/pfm.2018.00030
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lemley J, 2017, IEEE ACCESS, V5, P5858, DOI 10.1109/ACCESS.2017.2696121
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Marron JS, 2007, J AM STAT ASSOC, V102, P1267, DOI 10.1198/016214507000001120
   Mcdermott MBA, 2019, 7 INT C LEARN REPR I
   Medela A, 2019, CONSTELLATION LOSS I, P10675
   Medela A, 2019, I S BIOMED IMAGING, P1860, DOI 10.1109/ISBI.2019.8759182
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Mohammed A, 2018, 29 BRIT MACH VIS C B
   Moriya T, 2018, PROC SPIE, V10578, DOI 10.1117/12.2293414
   Muller MF, 2016, VIRCHOWS ARCH, V469, P125, DOI 10.1007/s00428-016-1956-3
   Murthy VN, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254333
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Park S., 2015, POLYP DETECTION COLO
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Picon A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216756
   Pineau J., 2019, MACHINE LEARNING REP
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P112, DOI 10.1145/3083187.3083189
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Pogorelov K, 2018, COMP MED SY, P381, DOI 10.1109/CBMS.2018.00073
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P170, DOI 10.1145/3083187.3083216
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pouyanfar S, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3150226
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Ranganathan Priya, 2017, Perspect Clin Res, V8, P187, DOI 10.4103/picr.PICR_123_17
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rex DK, 2017, BEST PRACT RES CL GA, V31, P425, DOI 10.1016/j.bpg.2017.05.010
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Robinson R, 2019, J CARDIOVASC MAGN R, V21, DOI 10.1186/s12968-019-0523-x
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sanchez-Peralta LF, 2019, BRIT J SURG, V106, P16
   Sanchez-Peralta LF, 2018, BRIT J SURG, V105, P5
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Son J., 2017, ARXIV170609318
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Taha B, 2017, IEEE IMAGE PROC, P2060, DOI 10.1109/ICIP.2017.8296644
   Tajbakhsh N, 2017, ADV COMPUT VIS PATT, P181, DOI 10.1007/978-3-319-42999-1_11
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Tran T, 2017, 31 C NEUR INF PROC S
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Varayil JE, 2011, GASTROENTEROLOGY, V140, pS718
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang WH, 2018, INT J COLORECTAL DIS, V33, P561, DOI 10.1007/s00384-018-3003-0
   Wei JW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40041-7
   Wei XH, 2018, P ACM MEAS ANAL COMP, V2, DOI [10.1007/s11104-018-03902-0, 10.1145/3179415]
   Wichakam I, 2018, LECT NOTES COMPUT SC, V10704, P393, DOI 10.1007/978-3-319-73603-7_32
   Wicke Kai, 2018, 2018 AIAA Aerospace Sciences Meeting, P1
   Wiegering A, 2016, INT J COLORECTAL DIS, V31, P1039, DOI 10.1007/s00384-015-2501-6
   Wieszczy P, 2017, BEST PRACT RES CL GA, V31, P441, DOI 10.1016/j.bpg.2017.07.002
   Williams CB, 2009, INSERTION TECHNIQUE, DOI 10.1002/9781444316902.ch40
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yu S, 2019, COMPUT MED IMAG GRAP, V74, P61, DOI 10.1016/j.compmedimag.2019.02.005
   YUAN Z, 2017, PROG BIOMED OPT IMAG, V133, P1, DOI DOI 10.1117/12.2254671
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
NR 131
TC 47
Z9 48
U1 6
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD AUG
PY 2020
VL 108
AR 101923
DI 10.1016/j.artmed.2020.101923
PG 23
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Medical Informatics
GA NW4AN
UT WOS:000574951400011
PM 32972656
OA hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Patel, K
   Li, KD
   Tao, K
   Wang, Q
   Bansal, A
   Rastogi, A
   Wang, GH
AF Patel, Krushi
   Li, Kaidong
   Tao, Ke
   Wang, Quan
   Bansal, Ajay
   Rastogi, Amit
   Wang, Guanghui
TI A comparative study on polyp classification using convolutional neural
   networks
SO PLOS ONE
LA English
DT Article
AB Colorectal cancer is the third most common cancer diagnosed in both men and women in the United States. Most colorectal cancers start as a growth on the inner lining of the colon or rectum, called 'polyp'. Not all polyps are cancerous, but some can develop into cancer. Early detection and recognition of the type of polyps is critical to prevent cancer and change outcomes. However, visual classification of polyps is challenging due to varying illumination conditions of endoscopy, variant texture, appearance, and overlapping morphology between polyps. More importantly, evaluation of polyp patterns by gastroenterologists is subjective leading to a poor agreement among observers. Deep convolutional neural networks have proven very successful in object classification across various object categories. In this work, we compare the performance of the state-of-the-art general object classification models for polyp classification. We trained a total of six CNN models end-to-end using a dataset of 157 video sequences composed of two types of polyps: hyperplastic and adenomatous. Our results demonstrate that the state-of-the-art CNN models can successfully classify polyps with an accuracy comparable or better than reported among gastroenterologists. The results of this study can guide future research in polyp classification.
C1 [Patel, Krushi; Li, Kaidong; Wang, Guanghui] Univ Kansas, Sch Engn, Lawrence, KS 66045 USA.
   [Tao, Ke; Wang, Quan] First Hosp Jilin Univ, Changchun, Peoples R China.
   [Bansal, Ajay; Rastogi, Amit] Univ Kansas, Med Ctr, Kansas City, KS 66103 USA.
C3 University of Kansas; Jilin University; University of Kansas; University
   of Kansas Medical Center
RP Wang, GH (通讯作者)，Univ Kansas, Sch Engn, Lawrence, KS 66045 USA.
EM ghwang@ku.edu
FU General Research Fund (GRF) of the University of Kansas [2228901]
FX This research was partly supported by the General Research Fund (GRF) of
   the University of Kansas under grant number 2228901. There was no
   additional external funding received for this study.
CR [Anonymous], 2015, PROC CVPR IEEE
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Cen F, 2019, IEEE T CYBERNETICS
   Cen F, 2019, IEEE ACCESS, V7, P26595, DOI 10.1109/ACCESS.2019.2901376
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   He L, 2018, INT C PATT RECOG, P2504, DOI 10.1109/ICPR.2018.8546170
   He L, 2018, IEEE T IMAGE PROCESS, V27, P4676, DOI 10.1109/TIP.2018.2832296
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   KIM DH, 2010, CT COLONOGRAPHY PRIN, P3
   Korbar B, 2017, J PATHOLOGY INFORN, P8, DOI [10.4103/jpi.jpi_34_1728828201, DOI 10.4103/JPI.JPI_34_1728828201]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li K., 2019, ABS191201844
   Li K, 2019, COLONOSCOPY POLYP DE
   LIANG FF, 2020, PATTERN RECOGN, V104, DOI DOI 10.1016/J.PATCOG.2019.107149
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma WC, 2018, INT C PATT RECOG, P2510, DOI 10.1109/ICPR.2018.8545693
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sajid U, 2020, IEEE T CIRC SYST VID, V30, P3499, DOI 10.1109/TCSVT.2020.2978717
   SHINYA H, 1979, ANN SURG, V190, P679, DOI 10.1097/00000658-197912000-00001
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Society AC, KEY STAT COL CANC
   Srivastava Rupesh Kumar, 2015, PROC 32TH INT C MACH
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tokgoz Y, 2018, ERCIYES MED J, V40, P65, DOI 10.5152/etd.2018.0010
   Uhl A, 2014, IEEE IMAGE PROC, P2299, DOI 10.1109/ICIP.2014.7025466
   Wimmer G, 2016, INT WORKSH COMP ASS, P59
   Wimmer G, 2016, INT C PATT RECOG, P2150, DOI 10.1109/ICPR.2016.7899954
   Wu Y, 2019, IEEE I CONF COMP VIS, P6301, DOI 10.1109/ICCV.2019.00639
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu WJ, 2019, IEEE T MULTIMEDIA, V21, P2387, DOI 10.1109/TMM.2019.2898777
   Xu WJ, 2019, PATTERN RECOGN, V93, P570, DOI 10.1016/j.patcog.2019.05.017
NR 39
TC 24
Z9 24
U1 0
U2 5
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JUL 30
PY 2020
VL 15
IS 7
AR e0236452
DI 10.1371/journal.pone.0236452
PG 16
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA MW2PD
UT WOS:000556884700006
PM 32730279
OA gold, Green Submitted, Green Published
DA 2023-08-21
ER

PT J
AU Wang, W
   Tian, JG
   Zhang, CW
   Luo, YH
   Wang, X
   Li, J
AF Wang, Wei
   Tian, Jinge
   Zhang, Chengwen
   Luo, Yanhong
   Wang, Xin
   Li, Ji
TI An improved deep learning approach and its applications on colonic polyp
   images detection
SO BMC MEDICAL IMAGING
LA English
DT Article
DE Colonic polyps; Deep learning; Convolutional neural networks; Global
   average pooling
ID COMPUTER-AIDED DIAGNOSIS; VALIDATION; VISION; TUMOR
AB Background Colonic polyps are more likely to be cancerous, especially those with large diameter, large number and atypical hyperplasia. If colonic polyps cannot be treated in early stage, they are likely to develop into colon cancer. Colonoscopy is easily limited by the operator's experience, and factors such as inexperience and visual fatigue will directly affect the accuracy of diagnosis. Cooperating with Hunan children's hospital, we proposed and improved a deep learning approach with global average pooling (GAP) in colonoscopy for assisted diagnosis. Our approach for assisted diagnosis in colonoscopy can prompt endoscopists to pay attention to polyps that may be ignored in real time, improve the detection rate, reduce missed diagnosis, and improve the efficiency of medical diagnosis. Methods We selected colonoscopy images from the gastrointestinal endoscopy room of Hunan children's hospital to form the colonic polyp datasets. And we applied the image classification method based on Deep Learning to the classification of Colonic Polyps. The classic networks we used are VGGNets and ResNets. By using global average pooling, we proposed the improved approaches: VGGNets-GAP and ResNets-GAP. Results The accuracies of all models in datasets exceed 98%. The TPR and TNR are above 96 and 98% respectively. In addition, VGGNets-GAP networks not only have high classification accuracies, but also have much fewer parameters than those of VGGNets. Conclusions The experimental results show that the proposed approach has good effect on the automatic detection of colonic polyps. The innovations of our method are in two aspects: (1) the detection accuracy of colonic polyps has been improved. (2) our approach reduces the memory consumption and makes the model lightweight. Compared with the original VGG networks, the parameters of our VGG19-GAP networks are greatly reduced.
C1 [Wang, Wei; Tian, Jinge; Zhang, Chengwen; Wang, Xin; Li, Ji] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Peoples R China.
   [Luo, Yanhong] Hunan Childrens Hosp, Changsha 410000, Peoples R China.
C3 Changsha University of Science & Technology
RP Wang, W; Wang, X (通讯作者)，Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Peoples R China.; Luo, YH (通讯作者)，Hunan Childrens Hosp, Changsha 410000, Peoples R China.
EM wangwei@csust.edu.cn; mfxgz123@163.com; wangxin@csust.edu.cn
RI Yu, Kun/IAP-9807-2023; liu, jiajia/IUN-0901-2023; liu,
   jiajia/ISS-0316-2023
OI wang, wei/0000-0002-2298-3429
FU National Defense Pre-Research Foundation of China [7301506]; National
   Natural Science Foundation of China [61070040]; Scientific Research Fund
   of Hunan Provincial Education Department [17C0043]; Natural Science
   Foundation of Hunan Province [2019JJ80105]; Clinical Medical technology
   Innovation and Guidance Project of Hunan Province [2018SK5040]
FX This research was supported by National Defense Pre-Research Foundation
   of China under Grant 7301506, National Natural Science Foundation of
   China under Grant 61070040, Scientific Research Fund of Hunan Provincial
   Education Department under Grant 17C0043, Natural Science Foundation of
   Hunan Province under Grant 2019JJ80105, and Clinical Medical technology
   Innovation and Guidance Project of Hunan Province under Grant
   2018SK5040. The funding bodies played no role in the design of the study
   and collection, analysis, and interpretation of data and in writing the
   manuscript.
CR Badgeley MA, 2019, BIOINFORMATICS, V35, P1610, DOI 10.1093/bioinformatics/bty855
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gross S, 2009, MED IMAGING 2009 COM
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Hongbin Zhu, 2010, Virtual Colonoscopy and Abdominal Imaging. Computational Challenges and Clinical Opportunities. Second International Workshop Held in Conjunction with MICCAI 2010. Revised Selected Papers, P9, DOI 10.1007/978-3-642-25719-3_2
   Hwang S, 2007, IM PROC 2007 ICIP 20
   Jerebko A, 2006, LECT NOTES COMPUT SC, V4191, P169
   Johnson CD, 2000, RADIOLOGY, V216, P331, DOI 10.1148/radiology.216.2.r00au47331
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kang J, 2003, EL COMP ENG 2003 IEE
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Lo SB, 2018, AM J ROENTGENO, V210, P1
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mughal B, 2017, CURR MED IMAGING, V13, P121, DOI 10.2174/1573405612666160901121802
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Sargent D, 2016, PROC SPIE, V9784, DOI 10.1117/12.2217123
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang HF, 2015, PHYS MED BIOL, V60, P7207, DOI 10.1088/0031-9155/60/18/7207
   Wang W, 2022, MINIM INVASIV THER, V31, P238, DOI 10.1080/13645706.2020.1781190
   Wang W, 2019, INT J COMPUT INT SYS, V12, P1592, DOI 10.2991/ijcis.d.191209.001
   Wang W, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8258275
   Wang W, 2019, OPT ENG, V58, DOI 10.1117/1.OE.58.4.040901
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 33
TC 29
Z9 29
U1 2
U2 5
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 1471-2342
J9 BMC MED IMAGING
JI BMC Med. Imag.
PD JUL 22
PY 2020
VL 20
IS 1
AR 83
DI 10.1186/s12880-020-00482-3
PG 14
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA MT6RZ
UT WOS:000555101300001
PM 32698839
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Becq, A
   Chandnani, M
   Bharadwaj, S
   Baran, B
   Ernest-Suarez, K
   Gabr, M
   Glissen-Brown, J
   Sawhney, M
   Pleskow, DK
   Berzin, TM
AF Becq, Aymeric
   Chandnani, Madhuri
   Bharadwaj, Shishira
   Baran, Bulent
   Ernest-Suarez, Kenneth
   Gabr, Moamen
   Glissen-Brown, Jeremy
   Sawhney, Mandeep
   Pleskow, Douglas K.
   Berzin, Tyler M.
TI Effectiveness of a Deep-learning Polyp Detection System in Prospectively
   Collected Colonoscopy Videos With Variable Bowel Preparation Quality
SO JOURNAL OF CLINICAL GASTROENTEROLOGY
LA English
DT Article
DE colon polyp detection; artificial intelligence; deep learning; variable
   bowel preparation
ID ADENOMA DETECTION RATE; TRAINEE PARTICIPATION; MISS RATE; MULTICENTER;
   INDICATORS; INCREASES; RATES; RISK
AB Background: Colonoscopy is the gold standard for polyp detection, but polyps may be missed. Artificial intelligence (AI) technologies may assist in polyp detection. To date, most studies for polyp detection have validated algorithms in ideal endoscopic conditions. Aim: To evaluate the performance of a deep-learning algorithm for polyp detection in a real-world setting of routine colonoscopy with variable bowel preparation quality. Methods: We performed a prospective, single-center study of 50 consecutive patients referred for colonoscopy. Procedural videos were analyzed by a validated deep-learning AI polyp detection software that labeled suspected polyps. Videos were then re-read by 5 experienced endoscopists to categorize all possible polyps identified by the endoscopist and/or AI, and to measure Boston Bowel Preparation Scale. Results: In total, 55 polyps were detected and removed by the endoscopist. The AI system identified 401 possible polyps. A total of 100 (24.9%) were categorized as "definite polyps;" 53/100 were identified and removed by the endoscopist. A total of 63 (15.6%) were categorized as "possible polyps" and were not removed by the endoscopist. In total, 238/401 were categorized as false positives. Two polyps identified by the endoscopist were missed by AI (false negatives). The sensitivity of AI for polyp detection was 98.8%, the positive predictive value was 40.6%. The polyp detection rate for the endoscopist was 62% versus 82% for the AI system. Mean segmental Boston Bowel Preparation Scale were similar (2.64, 2.59,P=0.47) for true and false positives, respectively. Conclusions: A deep-learning algorithm can function effectively to detect polyps in a prospectively collected series of colonoscopies, even in the setting of variable preparation quality.
C1 [Becq, Aymeric; Chandnani, Madhuri; Bharadwaj, Shishira; Gabr, Moamen; Glissen-Brown, Jeremy; Sawhney, Mandeep; Pleskow, Douglas K.; Berzin, Tyler M.] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Div Gastroenterol, Boston, MA 02115 USA.
   [Baran, Bulent] Koc Univ Hosp, Dept Gastroenterol, Istanbul, Turkey.
   [Ernest-Suarez, Kenneth] Univ Costa Rica, Hosp Mexico, Dept Gastroenterol, San Jose, Costa Rica.
C3 Harvard University; Beth Israel Deaconess Medical Center; Harvard
   Medical School; Koc University; Universidad Costa Rica
RP Berzin, TM (通讯作者)，Harvard Med Sch, Beth Israel Deaconess Med Ctr, 330 Brookline Ave,Rabb Rose 101, Boston, MA 02215 USA.
EM tberzin@bidmc.harvard.edu
RI Chandnani, Madhuri/AAY-9854-2020; Pleskow, Douglas K/F-3319-2016
OI Pleskow, Douglas K/0000-0003-0092-9496; Ernest-Suarez,
   Kenneth/0000-0001-8360-8190; Glissen Brown, Jeremy/0000-0002-7204-7241
CR American Cancer Society, 2019, CANC FACTS FIGURES 2
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Brenner H, 2014, LANCET, V383, P1490, DOI 10.1016/S0140-6736(13)61649-9
   Chalifoux SL, 2014, J CLIN GASTROENTEROL, V48, P524, DOI 10.1097/MCG.0000000000000022
   Cohen J, 2017, J CLIN GASTROENTEROL, V51, P818, DOI 10.1097/MCG.0000000000000695
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Desai M, 2019, GASTROINTEST ENDOSC, V89, P453, DOI 10.1016/j.gie.2018.09.006
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Millan MS, 2008, DIS COLON RECTUM, V51, P1217, DOI 10.1007/s10350-008-9315-3
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Ngu WS, 2018, THER ADV GASTROENTER, V11, P1, DOI 10.1177/1756283X17746311
   Qayed E, 2017, WORLD J GASTRO ENDOS, V9, P204, DOI 10.4253/wjge.v9.i5.204
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2015, AM J GASTROENTEROL, V110, P72, DOI 10.1038/ajg.2014.385
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
NR 21
TC 17
Z9 18
U1 1
U2 10
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0192-0790
EI 1539-2031
J9 J CLIN GASTROENTEROL
JI J. Clin. Gastroenterol.
PD JUL
PY 2020
VL 54
IS 6
BP 554
EP 557
DI 10.1097/MCG.0000000000001272
PG 4
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA MC0DV
UT WOS:000542968600012
PM 31789758
DA 2023-08-21
ER

PT J
AU Dimas, G
   Bianchi, F
   Iakovidis, DK
   Karargyris, A
   Ciuti, G
   Koulaouzidis, A
AF Dimas, George
   Bianchi, Federico
   Iakovidis, Dimitris K.
   Karargyris, Alexandros
   Ciuti, Gastone
   Koulaouzidis, Anastasios
TI Endoscopic single-image size measurements
SO MEASUREMENT SCIENCE AND TECHNOLOGY
LA English
DT Article
DE medical image analysis; endoscopy; size measurement
ID POLYP SIZE; CAPSULE; CANCER; LOCALIZATION; DIAGNOSIS
AB In the practice of clinical gastrointestinal endoscopy, precise estimation of the size of a lesion/finding, such as a polyp, is quintessential in diagnosis, e.g. risk estimation for malignancy. However, various studies confirmed that endoscopic assessment of lesion size has inherent limitations and significant measurement errors. Image-based methods proposed for in-vivo-size measurements, rely on reference objects such as the endoscopic biopsy forceps. The aforementioned problem becomes more challenging in the field of capsule endoscopy, as capsules lack navigation and/or biopsy capabilities. To cope with this problem, we propose a methodology that requires only an endoscopic image-without any need for a reference object-in order to estimate the size of an object of interest in it. The first step in this methodology requires the user to define a linear segment within the image. Then, it takes into consideration the intrinsic parameters of the camera, to project known 3D points on the 2D image plane. With known 3D to 2D point correspondences, in order to perform a measurement, a rough approximation of the distance between the object of interest and the camera is needed. For this purpose, a convolutional neural network is utilized which generates depth maps from monocular images. The proposed methodology is validated by experimentation performed in a 3D printed model of the human colon. The results show that it is feasible to measure the size of various objects in endoscopic images with a mean absolute error of 1.10 mm +/- 0.89 mm.
C1 [Dimas, George; Iakovidis, Dimitris K.] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
   [Bianchi, Federico; Ciuti, Gastone] Scuola Super Sant Anna, BioRobot Inst, Pisa, Italy.
   [Bianchi, Federico; Ciuti, Gastone] Scuola Super Sant Anna, Dept Excellence Robot & AI, Pisa, Italy.
   [Karargyris, Alexandros] IBM Res, San Jose, CA USA.
   [Koulaouzidis, Anastasios] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh, Midlothian, Scotland.
C3 Scuola Superiore Sant'Anna; Scuola Superiore Sant'Anna; International
   Business Machines (IBM); Royal Infirmary of Edinburgh; University of
   Edinburgh
RP Iakovidis, DK (通讯作者)，Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
EM diakovidis@uth.gr
RI Ciuti, Gastone/T-6377-2018; Koulaouzidis, Anastasios/G-9060-2014
OI Ciuti, Gastone/0000-0002-0855-7976; Koulaouzidis,
   Anastasios/0000-0002-2248-489X; Iakovidis, Dimitris/0000-0002-5027-5323
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Alhashim I., 2018, ARXIV E PRINTS
   Andalo FA, 2015, COMPUT VIS IMAGE UND, V138, P51, DOI 10.1016/j.cviu.2015.03.017
   [Anonymous], 2003, GASTROINTEST ENDOS S, V58, pS3
   Arebi N, 2007, SCAND J GASTROENTERO, V42, P859, DOI 10.1080/00365520601137280
   Armaroli P, 2015, CANCER EPIDEMIOL, V39, pS139, DOI 10.1016/j.canep.2015.10.021
   Bianchi F, 2019, EXPERT REV MED DEVIC, V16, P381, DOI 10.1080/17434440.2019.1608182
   Bianchi F, 2017, ANN TRANSL MED, V5, DOI 10.21037/atm.2017.09.15
   Bouguet J.Y., 2015, CAMERA CALIBRATION T
   Brandao P, 2016, P 2016 JOINT WORKSH
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Diamantis DE, 2019, BIOMED SIGNAL PROCES, V49, P192, DOI 10.1016/j.bspc.2018.12.005
   Dimas G, 2017, COMPUT BIOL MED, V89, P429, DOI 10.1016/j.compbiomed.2017.08.029
   Dimas G, 2017, MEAS SCI TECHNOL, V28, DOI 10.1088/1361-6501/aa7ebf
   Ghanouni A, 2013, EXPERT REV MED DEVIC, V10, P489, DOI 10.1586/17434440.2013.811867
   Goldstein O, 2018, GUT, V67, P1755, DOI 10.1136/gutjnl-2017-314829
   Hassan C, 2012, ALIMENT PHARM THER, V36, P929, DOI 10.1111/apt.12071
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2019, IEEE J BIOMED HEALTH, V23, P2211, DOI 10.1109/JBHI.2018.2853987
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   IARC, 2018, GLOBOCAN 2018 GLOB C
   Kaz AM, 2016, GASTROINTEST ENDOSC, V83, P812, DOI 10.1016/j.gie.2015.08.082
   Kume K, 2014, GASTROENT RES PRACT, V2014, DOI 10.1155/2014/714294
   Kun Peng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1658, DOI 10.1109/ICPR.2010.410
   Morales TG, 1996, GASTROINTEST ENDOSC, V43, P25
   Oka K, 2014, WORLD J GASTROENTERO, V20, P4050, DOI 10.3748/wjg.v20.i14.4050
   Park H, 2017, SURG ENDOSC, V31, P4824, DOI 10.1007/s00464-017-5560-7
   Prior F, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.124
   Quirini M, 2008, GASTROINTEST ENDOSC, V67, P1153, DOI 10.1016/j.gie.2007.11.052
   Schoen RE, 1997, GASTROINTEST ENDOSC, V46, P492, DOI 10.1016/S0016-5107(97)70002-6
   Schreuders EH, 2015, GUT, V64, P1637, DOI 10.1136/gutjnl-2014-309086
   Senore C, 2015, GUT, V64, P1158, DOI 10.1136/gutjnl-2014-308081
   Sliker L, 2015, EXPERT REV MED DEVIC, V12, P737, DOI 10.1586/17434440.2015.1080120
   Sliker LJ, 2014, EXPERT REV MED DEVIC, V11, P649, DOI 10.1586/17434440.2014.941809
   Swain P, 2003, GUT, V52, P48
   VAKIL N, 1994, GASTROINTEST ENDOSC, V40, P178, DOI 10.1016/S0016-5107(94)70163-6
   Vasilakakis MD, 2020, GASTROENTEROL REV, V15, P179, DOI 10.5114/pg.2019.87528
   Visentini-Scarzanella M, 2018, ENDOSC INT OPEN, V6, pE602, DOI 10.1055/a-0577-2798
   Woods SP, 2013, IEEE T BIO-MED ENG, V60, P945, DOI 10.1109/TBME.2012.2228647
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
   Zhou M, 2014, 2014 7 INT C BIOM EN
NR 43
TC 8
Z9 8
U1 2
U2 31
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0957-0233
EI 1361-6501
J9 MEAS SCI TECHNOL
JI Meas. Sci. Technol.
PD JUL
PY 2020
VL 31
IS 7
AR 074010
DI 10.1088/1361-6501/ab803c
PG 10
WC Engineering, Multidisciplinary; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA LM8MB
UT WOS:000532502100001
DA 2023-08-21
ER

PT J
AU Guo, YB
   Bernal, J
   Matuszewski, BJ
AF Guo, Yunbo
   Bernal, Jorge
   Matuszewski, Bogdan J.
TI Polyp Segmentation with Fully Convolutional Deep Neural
   Networks-Extended Evaluation Study
SO JOURNAL OF IMAGING
LA English
DT Article
DE fully convolutional dilation neural networks; polyp segmentation; data
   augmentation; cross-validation; ablation tests
AB Analysis of colonoscopy images plays a significant role in early detection of colorectal cancer. Automated tissue segmentation can be useful for two of the most relevant clinical target applications-lesion detection and classification, thereby providing important means to make both processes more accurate and robust. To automate video colonoscopy analysis, computer vision and machine learning methods have been utilized and shown to enhance polyp detectability and segmentation objectivity. This paper describes a polyp segmentation algorithm, developed based on fully convolutional network models, that was originally developed for the Endoscopic Vision Gastrointestinal Image Analysis (GIANA) polyp segmentation challenges. The key contribution of the paper is an extended evaluation of the proposed architecture, by comparing it against established image segmentation benchmarks utilizing several metrics with cross-validation on the GIANA training dataset. Different experiments are described, including examination of various network configurations, values of design parameters, data augmentation approaches, and polyp characteristics. The reported results demonstrate the significance of the data augmentation, and careful selection of the method's design parameters. The proposed method delivers state-of-the-art results with near real-time performance. The described solution was instrumental in securing the top spot for the polyp segmentation sub-challenge at the 2017 GIANA challenge and second place for the standard image resolution segmentation task at the 2018 GIANA challenge.
C1 [Guo, Yunbo; Matuszewski, Bogdan J.] Univ Cent Lancashire, Sch Engn, Comp Vis & Machine Learning CVML Grp, Preston PR1 2HE, Lancs, England.
   [Bernal, Jorge] Univ Autonoma Barcelona, Comp Vis Ctr, Image Sequence Evaluat Lab, Bellaterra 08193, Spain.
   [Bernal, Jorge] Univ Autonoma Barcelona, Comp Sci Dept, Bellaterra 08193, Spain.
C3 University of Central Lancashire; Autonomous University of Barcelona;
   Centre de Visio per Computador (CVC); Autonomous University of Barcelona
RP Guo, YB (通讯作者)，Univ Cent Lancashire, Sch Engn, Comp Vis & Machine Learning CVML Grp, Preston PR1 2HE, Lancs, England.
EM ybguo1@uclan.ac.uk; jorge.bernal@uab.cat; bmatuszewski1@uclan.ac.uk
RI Bernal, Jorge/H-4647-2015
OI Bernal, Jorge/0000-0001-8493-9514; Guo, Yunbo/0000-0001-6804-4884
NR 0
TC 19
Z9 20
U1 1
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2313-433X
J9 J IMAGING
JI J. Imaging
PD JUL
PY 2020
VL 6
IS 7
AR 69
DI 10.3390/jimaging6070069
PG 21
WC Imaging Science & Photographic Technology
WE Emerging Sources Citation Index (ESCI)
SC Imaging Science & Photographic Technology
GA MS3AZ
UT WOS:000554154800001
PM 34460662
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Jia, X
   Mai, XC
   Cui, Y
   Yuan, YX
   Xing, XH
   Seo, H
   Xing, L
   Meng, MQH
AF Jia, Xiao
   Mai, Xiaochun
   Cui, Yi
   Yuan, Yixuan
   Xing, Xiaohan
   Seo, Hyunseok
   Xing, Lei
   Meng, Max Q. -H.
TI Automatic Polyp Recognition in Colonoscopy Images Using Deep Learning
   and Two-Stage Pyramidal Feature Prediction
SO IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING
LA English
DT Article
DE Colonoscopy; Computer architecture; Proposals; Semantics; Image
   recognition; Task analysis; Image segmentation; Deep residual network
   (ResNet); feature pyramids; PLPNet; polyp recognition; two-stage
   framework
ID VALIDATION; COLON
AB Polyp recognition in colonoscopy images is crucial for early colorectal cancer detection and treatment. However, the current manual review requires undivided concentration of the gastroenterologist and is prone to diagnostic errors. In this article, we present an effective, two-stage approach called PLPNet, where the abbreviation "PLP" stands for the word "polyp," for automated pixel-accurate polyp recognition in colonoscopy images using very deep convolutional neural networks (CNNs). Compared to hand-engineered approaches and previous neural network architectures, our PLPNet model improves recognition accuracy by adding a polyp proposal stage that predicts the location box with polyp presence. Several schemes are proposed to ensure the model's performance. First of all, we construct a polyp proposal stage as an extension of the faster R-CNN, which performs as a region-level polyp detector to recognize the lesion area as a whole and constitutes stage I of PLPNet. Second, stage II of PLPNet is built in a fully convolutional fashion for pixelwise segmentation. We define a feature sharing strategy to transfer the learned semantics of polyp proposals to the segmentation task of stage II, which is proven to be highly capable of guiding the learning process and improve recognition accuracy. Additionally, we design skip schemes to enrich the feature scales and thus allow the model to generate detailed segmentation predictions. For accurate recognition, the advanced residual nets and feature pyramids are adopted to seek deeper and richer semantics at all network levels. Finally, we construct a two-stage framework for training and run our model convolutionally via a single-stream network at inference time to efficiently output the polyp mask. Experimental results on public data sets of GIANA Challenge demonstrate the accuracy gains of our approach, which surpasses previous state-of-the-art methods on the polyp segmentation task (74.7 Jaccard Index) and establishes new top results in the polyp localization challenge (81.7 recall). Note to Practitioners-Given the current manual review of colonoscopy is laborious and time-consuming, computational methods that can assist automatic polyp recognition will enhance the outcome both in terms of efficiency and diagnostic accuracy of colonoscopy. This article suggests a new approach using a very deep convolutional neural network (CNN) architecture for polyp recognition, which gains accuracy from deeper and richer representations. The method, called PLPNet, can effectively detect polyps in colonoscopy images and generate high-quality segmentation masks in a pixel-to-pixel manner. We evaluate the proposed framework on publicly available data sets, and we show by experiments that our method surpasses the state-of-the-art polyp recognition results. The finding of this article corroborates that CNNs with very deep architecture and richer semantics are highly efficient in medical image learning and inference. We believe that the proposed method will facilitate potential computer-aided applications in clinical practice, in that it can enhance medical decision-making in cancer detection and imaging.
C1 [Jia, Xiao; Mai, Xiaochun; Xing, Xiaohan; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Cui, Yi] ViewRay Inc, Mountain View, CA 94043 USA.
   [Yuan, Yixuan] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Seo, Hyunseok; Xing, Lei] Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94305 USA.
   [Meng, Max Q. -H.] Chinese Univ Hong Kong Shenzhen, Shenzhen Res Inst, Shenzhen 518172, Peoples R China.
C3 Chinese University of Hong Kong; City University of Hong Kong; Stanford
   University; Chinese University of Hong Kong, Shenzhen
RP Meng, MQH (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM xjia@cuhk.edu.hk; xcmai@ee.cuhk.edu.hk; cuiyi.trea@gmail.com;
   yxyuan.ee@cityu.edu.hk; xhxing@ee.cuhk.edu.hk; hsseo@stanford.edu;
   lei@stanford.edu; max.meng@ieee.org
RI meng, meng/GWZ-7461-2022; Xiaochun, MAI/GXZ-8033-2022
OI Xing, Xiaohan/0000-0002-9992-3387; seo, hyunseok/0000-0003-0224-8942;
   Meng, Max Q.-H./0000-0002-5255-5898; Xing, Lei/0000-0003-2536-5359;
   Yuan, Yixuan/0000-0002-0853-6948
FU Hong Kong Research Grants Council (RGC) Collaborative Research Fund
   (CRF) [C4063-18GF]; Shenzhen Science and Technology Innovation Project
   [JCYJ20170413161503220]
FX The work of Max Q.-H. Meng was supported in part by the Hong Kong
   Research Grants Council (RGC) Collaborative Research Fund (CRF) Project
   under Grant C4063-18GF and in part by the Shenzhen Science and
   Technology Innovation Project under Grant JCYJ20170413161503220.
CR American Cancer Society, 2019, CANC FACTS FIGURES 2
   American Cancer Society, 2017, COL CANC FACTS FIG 2
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bovik AC., 2010, HDB IMAGE VIDEO PROC
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang G., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243
   Jia X, 2020, P IEEE, V108, P178, DOI 10.1109/JPROC.2019.2950506
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jin YM, 2018, IEEE T MED IMAGING, V37, P1114, DOI 10.1109/TMI.2017.2787657
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Lei HJ, 2018, PATTERN RECOGN, V79, P290, DOI 10.1016/j.patcog.2018.02.006
   Liang-Chieh Chen, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11211), P833, DOI 10.1007/978-3-030-01234-2_49
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmood F, 2019, PROC SPIE, V10950, DOI 10.1117/12.2513117
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sargent D, 2016, PROC SPIE, V9784, DOI 10.1117/12.2217123
   Sarikaya D, 2017, IEEE T MED IMAGING, V36, P1542, DOI 10.1109/TMI.2017.2665671
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Tao Y, 2017, CHIN CONTR CONF, P4288, DOI 10.23919/ChiCC.2017.8028032
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D., 2017, J HEALTHC ENG, P1
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Xiao WT, 2018, IEEE INT C ELECTR TA
   Yan Xu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P496, DOI 10.1007/978-3-319-46723-8_57
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319
NR 45
TC 43
Z9 43
U1 5
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-5955
EI 1558-3783
J9 IEEE T AUTOM SCI ENG
JI IEEE Trans. Autom. Sci. Eng.
PD JUL
PY 2020
VL 17
IS 3
BP 1570
EP 1584
DI 10.1109/TASE.2020.2964827
PG 15
WC Automation & Control Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems
GA MF5JU
UT WOS:000545379200037
DA 2023-08-21
ER

PT J
AU Lui, TKL
   Guo, CG
   Leung, WK
AF Lui, Thomas K. L.
   Guo, Chuan-Guo
   Leung, Wai K.
TI Accuracy of artificial intelligence on histology prediction and
   detection of colorectal polyps: a systematic review and meta-analysis
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
ID COMPUTER-AIDED DIAGNOSIS; REAL-TIME; VIDEO VALIDATION; DISCARD STRATEGY;
   NEURAL-NETWORK; CLASSIFICATION; COLONOSCOPY; ENDOSCOPY; ALGORITHM;
   SOCIETY
AB Background and Aims: We performed a meta-analysis of all published studies to determine the diagnostic accuracy of artificial intelligence (AI) on histology prediction and detection of colorectal polyps.
   Method: We searched Embase, PubMed, Medline, Web of Science, and Cochrane library databases to identify studies using AI for colorectal polyp histology prediction and detection. The quality of included studies was measured by the Quality Assessment of Diagnostic Accuracy Studies tool. We used a bivariate meta-analysis following a random-effects model to summarize the data and plotted hierarchical summary receiver operating characteristic curves. The area under the hierarchical summary receiver operating characteristic curve (AUC) served as an indicator of the diagnostic accuracy and during head-to-head comparisons.
   Results: A total of 7680 images of colorectal polyps from 18 studies were included in the analysis of histology prediction. The accuracy of the AI (AUC) was .96 (95% confidence interval [CI], .95-.98), with a corresponding pooled sensitivity of 92.3% (95% CI, 88.8%-94.9%) and specificity of 89.8% (95% CI, 85.3%-93.0%). The AUC of AI using narrow-band imaging (NBI) was significantly higher than the AUC using non-NBI (.98 vs .84, P < .01). The performance of AI was superior to nonexpert endoscopists (.97 vs .90, P < .01). For characterization of diminutive polyps using a deep learning model with nonmagnifying NBI, the pooled negative predictive value was 95.1% (95% CI, 87.7%-98.1%). For polyp detection, the pooled AUC was .90 (95% CI, .67-1.00) with a sensitivity of 95.0% (95% CI, 91.0%-97.0%) and a specificity of 88.0% (95% CI, 58.0%-99.0%).
   Conclusions: AI was accurate in histology prediction and detection of colorectal polyps, including diminutive polyps. The performance of AI was better under NBI and was superior to nonexpert endoscopists. Despite the difference in AI models and study designs, AI performances are rather consistent, which could serve as a reference for future AI studies.
C1 [Lui, Thomas K. L.; Guo, Chuan-Guo; Leung, Wai K.] Univ Hong Kong, Queen Mary Hosp, Dept Med, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Leung, WK (通讯作者)，Queen Mary Hosp, Dept Med, 4-F Profess Block,102 Pokfulam Rd, Hong Kong, Peoples R China.
EM waikleung@hku.hk
RI Guo, Chuan-Guo/GWU-8356-2022; Leung, Wai Keung/B-8140-2011
OI Guo, Chuan-Guo/0000-0002-0657-473X; Leung, Wai
   Keung/0000-0002-5993-1059; Lui, Ka Luen, Thomas/0000-0002-2986-3681
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Deville Walter L, 2002, BMC Med Res Methodol, V2, P9, DOI 10.1186/1471-2288-2-9
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Gupta N, 2017, CLIN GASTROENTEROL H, V15, P820, DOI 10.1016/j.cgh.2017.01.033
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hirata I, 2012, DIGESTION, V85, P74, DOI 10.1159/000334642
   Horiuchi H, 2019, SCAND J GASTROENTERO, V54, P800, DOI 10.1080/00365521.2019.1627407
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Liberati A, 2009, ANN INTERN MED, V151, pW65, DOI [10.7326/0003-4819-151-4-200908180-00136, 10.1371/journal.pmed.1000097, 10.1136/bmj.b4037, 10.1136/bmj.b2700]
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Lui TKL, 2019, GASTROINTEST ENDOSC, V89, pAB135
   Lui TKL, 2019, HONG KONG MED J, V25, P31
   Matsui H, 2019, GASTROINTEST ENDOSC, V89, pAB75, DOI 10.1016/j.gie.2019.04.050
   McGill SK, 2013, GUT, V62, P1704, DOI 10.1136/gutjnl-2012-303965
   Min M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39416-7
   Misawa M, 2019, GASTROINTEST ENDOSC, V89, pAB646, DOI 10.1016/j.gie.2019.03.1134
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   OTA K, 2019, CLIN J GASTROENTEROL, V13, DOI DOI 10.3389/FNHUM.2019.00297
   Paggi S, 2012, ENDOSCOPY, V44, P899, DOI 10.1055/s-0032-1309891
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rombaoa C, 2019, GASTROINTEST ENDOSC, V89, pAB619, DOI 10.1016/j.gie.2019.03.1076
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   So NYH, 2019, HONG KONG MED J, V25, P38
   Stroup DF, 2000, JAMA-J AM MED ASSOC, V283, P2008, DOI 10.1001/jama.283.15.2008
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takeuchi Y, 2014, DIGEST ENDOSC, V26, P90, DOI 10.1111/den.12248
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009
   Zachariah R, 2019, GASTROINTEST ENDOSC, V89, pAB655, DOI 10.1016/j.gie.2019.03.1151
   Zhou J, 2020, GASTROINTEST ENDOSC, V91, P428, DOI 10.1016/j.gie.2019.11.026
   Zhu X, 2018, GASTROINTEST ENDOSC, V87, pAB251
NR 46
TC 54
Z9 55
U1 3
U2 13
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JUL
PY 2020
VL 92
IS 1
BP 11
EP +
DI 10.1016/j.gie.2020.02.033
PG 18
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA MD9UU
UT WOS:000544312100003
PM 32119938
DA 2023-08-21
ER

PT J
AU Saito, H
   Aoki, T
   Aoyama, K
   Kato, Y
   Tsuboi, A
   Yamada, A
   Fujishiro, M
   Oka, S
   Ishihara, S
   Matsuda, T
   Nakahori, M
   Tanaka, S
   Koike, K
   Tada, T
AF Saito, Hiroaki
   Aoki, Tomonori
   Aoyama, Kazuharu
   Kato, Yusuke
   Tsuboi, Akiyoshi
   Yamada, Atsuo
   Fujishiro, Mitsuhiro
   Oka, Shiro
   Ishihara, Soichiro
   Matsuda, Tomoki
   Nakahori, Masato
   Tanaka, Shinji
   Koike, Kazuhiko
   Tada, Tomohiro
TI Automatic detection and classification of protruding lesions in wireless
   capsule endoscopy images based on a deep convolutional neural network
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
AB Background and Aims: Protruding lesions of the small bowel vary in wireless capsule endoscopy (WCE) images, and their automatic detection may be difficult. We aimed to develop and test a deep learning-based system to automatically detect protruding lesions of various types in WCE images.
   Methods: We trained a deep convolutional neural network (CNN), using 30,584 WCE images of protruding le-sions from 292 patients. We evaluated CNN performance by calculating the area under the receiver operating characteristic curve (AUC), sensitivity, and specificity, using an independent set of 17,507 test images from 93 pa-tients, including 7507 images of protruding lesions from 73 patients.
   Results: The developed CNN analyzed 17,507 images in 530.462 seconds. The AUC for detection of protruding lesions was 0.911 (95% confidence interval [Cl] , 0.9069-0.9155). The sensitivity and specificity of the CNN were 90.7% (95% CI, 90.0%-91.4%) and 79.8% (95% CI, 79.0%-80.6%), respectively, at the optimal cut-off value of 0.317 for probability score. In a subgroup analysis of the category of protruding lesions, the sensitivities were 86.5%, 92.0%, 95.8%, 77.0%, and 94.4% for the detection of polyps, nodules, epithelial tumors, submucosal tumors, and venous structures, respectively. In individual patient analyses (n = 73), the detection rate of protruding lesions was 98.6%.
   Conclusion: We developed and tested a new computer-aided system based on a CNN to automatically detect various protruding lesions in WCE images. Patient-level analyses with larger cohorts and efforts to achieve better diagnostic performance are necessary in further studies.
C1 [Saito, Hiroaki; Matsuda, Tomoki; Nakahori, Masato] Sendai Kousei Hosp, Dept Gastroenterol, Sendai, Miyagi, Japan.
   [Aoki, Tomonori; Yamada, Atsuo; Koike, Kazuhiko] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Aoyama, Kazuharu; Kato, Yusuke; Tada, Tomohiro] AI Med Serv Inc, Tokyo, Japan.
   [Tsuboi, Akiyoshi; Oka, Shiro; Tanaka, Shinji] Hiroshima Univ Hosp, Dept Endoscopy, Hiroshima, Japan.
   [Fujishiro, Mitsuhiro] Nagoya Univ, Dept Gastroenterol & Hepatol, Grad Sch Med, Nagoya, Aichi, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
C3 Sendai Kousei Hospital; University of Tokyo; Hiroshima University;
   Nagoya University; University of Tokyo
RP Saito, H (通讯作者)，Sendai Kousei Hosp, Dept Gastroenterol, Aoba Ku, 4-15 Hirose Cho, Sendai, Miyagi 9800873, Japan.
EM h.saito0515@gmail.com
RI SAITO, HIROAKI/HLH-2447-2023; Tanaka, Shinji/G-5266-2019; Oka,
   Shiro/AAZ-8368-2021; Ishihara, Soichiro/AFK-1375-2022
OI SAITO, HIROAKI/0000-0002-0824-454X; Fujishiro,
   Mitsuhiro/0000-0002-4074-1140
CR Al-shebani Q, 2019, ARTIF INTELL MED, V94, P18, DOI 10.1016/j.artmed.2018.12.008
   Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Costamagna G, 2002, GASTROENTEROLOGY, V123, P999, DOI 10.1053/gast.2002.35988
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Ghosh T, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2017.2756034
   Hwang Y, 2018, CLIN ENDOSC, V51, P547, DOI 10.5946/ce.2018.173
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Korman LY, 2005, ENDOSCOPY, V37, P951, DOI 10.1055/s-2005-870329
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Liu W, 2016, ARXIV151202325V5CSCV
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Omori T, 2018, ENDOSC INT OPEN, V6, pE669, DOI 10.1055/a-0599-5852
   Shah P, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0148-3
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Vieira PM, 2020, MED PHYS, V47, P52, DOI 10.1002/mp.13709
   Yangqing J, CAFFE CONVOLUTIONAL
   YOUDEN WJ, 1950, BIOMETRICS, V6, P172, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
NR 21
TC 83
Z9 84
U1 1
U2 14
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JUL
PY 2020
VL 92
IS 1
BP 144
EP +
DI 10.1016/j.gie.2020.01.054
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA MD9UU
UT WOS:000544312100021
PM 32084410
DA 2023-08-21
ER

PT J
AU Kacmaz, RN
   Yilmaz, B
   Aydin, Z
AF Kacmaz, Rukiye Nur
   Yilmaz, Bulent
   Aydin, Zafer
TI Effect of interpolation on specular reflections in texture-based
   automatic colonic polyp detection
SO INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE classification; colon polyp; image processing; machine learning;
   specular reflection
AB Reflections of LED light cause unwanted noise effects called specular reflection (SR) on colonoscopic images. The aim of this study was to seek answers to the following two questions. (a) How are the texture features used in automatic detection of polyps affected by the interpolation on specular reflections? (b) If they are affected does it really affect the classification performance? In order to answer these questions, we used 610 colonoscopy images, and divided each image into tiles whose sizes were 32-by-32 pixels. From these tiles, we selected the ones without any specular reflection. We added different shape and size specular reflections cropped from real images onto the reflection-free tiles. We then used the nearest neighbors, bilinear and bicubic interpolation techniques on the tiles on which SRs were added. On these tiles we extracted 116 texture features using 3 second-order approaches, and 4 first-order statistics. First, we used paired samplettest. Second, we performed automatic classification of polyps and background using random forest and k nearest neighbors (k-NN) approaches using the texture features for different combinations of specular reflections added on the tiles from the polyp or background. The results showed that depending on the size of specular reflection, interpolation can cause a significant difference between the texture features that were coming from reflection-free tiles and the same tiles on which interpolation was performed. In addition, we note that bicubic interpolation may be preferred to eliminate specular reflection when texture features are used for background and polyp discrimination.
C1 [Kacmaz, Rukiye Nur; Yilmaz, Bulent; Aydin, Zafer] Abdullah Gul Univ, Grad Sch Engn & Sci, Elect & Comp Engn Dept, Kayseri, Turkey.
   [Kacmaz, Rukiye Nur; Yilmaz, Bulent] Abdullah Gul Univ, Biomed Image & Signal Anal Lab, Kayseri, Turkey.
   [Yilmaz, Bulent] Abdullah Gul Univ, Sch Engn, Elect & Elect Engn Dept, Kayseri, Turkey.
   [Aydin, Zafer] Abdullah Gul Univ, Sch Engn, Comp Engn Dept, Kayseri, Turkey.
C3 Abdullah Gul University; Abdullah Gul University; Abdullah Gul
   University; Abdullah Gul University
RP Kacmaz, RN (通讯作者)，Abdullah Gul Univ, Grad Sch Engn & Sci, Elect & Comp Engn Dept, Kayseri, Turkey.
EM rukiyenurkacmaz@gmail.com
OI Yilmaz, Bulent/0000-0003-2954-1217; , rukiye/0000-0002-3237-9997
FU Turkish Higher Education Council's 100/2000 Program
FX The first author RNK is supported by the Turkish Higher Education
   Council's 100/2000 Program as a graduate student with a monthly stipend.
CR Alexandre LA, 2007, KPKDD P 11 EUR C PRI
   AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   [Anonymous], 2014, IMAGE PROCESSING ANA
   [Anonymous], 2007, P ICIP
   Aydi W., 2011, INT J ELECT ENERGETI, V5, P697
   Benco M, 2007, RADIOENGINEERING, V16, P64
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Ergen B., 2011, MUHENDISLIK BILIMLER, V23, P87
   Ghosh A, 2010, EURASIP J IMAGE VIDE, V2010, P1
   Ghosh T, 2015, TENCON IEEE REGION
   Guo JJ, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P125, DOI 10.1109/BigMM.2016.78
   Karapetyan G, 2013, 2013 COMPUTER SCIENCE AND INFORMATION TECHNOLOGIES (CSIT)
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Olivier R, 2012, INT J ADV COMPUT SC, V3, P25
   Ong JL, 2011, IEEE T IMAGE PROCESS, V20, P1000, DOI 10.1109/TIP.2010.2076295
   Ong JL, 2011, PATTERN RECOGN LETT, V32, P337, DOI 10.1016/j.patrec.2010.09.012
   Ong JL, 2008, I S BIOMED IMAGING, P636
   Park M, 2008, P 2008 INT C MULT UB
   Stehle TH, 2006, P 10 INT STUD C EL E, P6
   Tajbakhsh N, 2014, I S BIOMED IMAGING, P97, DOI 10.1109/ISBI.2014.6867818
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Tchoulack S., 2008, 2008 JOINT 6 INT IEE
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
NR 26
TC 4
Z9 4
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-9457
EI 1098-1098
J9 INT J IMAG SYST TECH
JI Int. J. Imaging Syst. Technol.
PD MAR
PY 2021
VL 31
IS 1
BP 327
EP 335
DI 10.1002/ima.22457
EA JUN 2020
PG 9
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA QC6JM
UT WOS:000543363000001
DA 2023-08-21
ER

PT J
AU Namikawa, K
   Hirasawa, T
   Yoshio, T
   Fujisaki, J
   Ozawa, T
   Ishihara, S
   Aoki, T
   Yamada, A
   Koike, K
   Suzuki, H
   Tada, T
AF Namikawa, Ken
   Hirasawa, Toshiaki
   Yoshio, Toshiyuki
   Fujisaki, Junko
   Ozawa, Tsuyoshi
   Ishihara, Soichiro
   Aoki, Tomonori
   Yamada, Atsuo
   Koike, Kazuhiko
   Suzuki, Hideo
   Tada, Tomohiro
TI Utilizing artificial intelligence in endoscopy: a clinician's guide
SO EXPERT REVIEW OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Review
DE Artificial intelligence; gastric cancer; helicobacter pylori; esophageal
   squamous cell carcinoma; colon polyp; narrow band imaging; magnified
   endoscopy; esophagogastroduodenoscopy; colonoscopy; capsule endoscopy
ID HELICOBACTER-PYLORI INFECTION; CONVOLUTIONAL NEURAL-NETWORK;
   COMPUTER-AIDED DIAGNOSIS; SQUAMOUS-CELL CARCINOMA; DEEP-LEARNING
   ALGORITHM; CAPSULE ENDOSCOPY; ENDOCYTOSCOPIC OBSERVATION; SUBMUCOSAL
   DISSECTION; GASTRIC-CANCER; CLASSIFICATION
AB Introduction Artificial intelligence (AI) that surpasses human ability in image recognition is expected to be applied in the field of gastrointestinal endoscopes. Accordingly, its research and development (R &D) is being actively conducted. With the development of endoscopic diagnosis, there is a shortage of specialists who can perform high-precision endoscopy. We will examine whether AI with excellent image recognition ability can overcome this problem. Areas covered Since 2016, papers on artificial intelligence using convolutional neural network (CNN in other word Deep Learning) have been published. CNN is generally capable of more accurate detection and classification than conventional machine learning. This is a review of papers using CNN in the gastrointestinal endoscopy area, along with the reasons why AI is required in clinical practice. We divided this review into four parts: stomach, esophagus, large intestine, and capsule endoscope (small intestine). Expert opinion Potential applications for the AI include colorectal polyp detection and differentiation, gastric and esophageal cancer detection, and lesion detection in capsule endoscopy. The accuracy of endoscopic diagnosis will increase if the AI and endoscopist perform the endoscopy together.
C1 [Namikawa, Ken; Hirasawa, Toshiaki; Yoshio, Toshiyuki; Fujisaki, Junko] Japanese Fdn Canc Res, Canc Inst Hosp, Dept Gastroenterol, Tokyo, Japan.
   [Ozawa, Tsuyoshi] Teikyo Univ, Dept Surg, Sch Med, Tokyo, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Aoki, Tomonori; Yamada, Atsuo; Koike, Kazuhiko] Univ Tokyo, Grad Sch Med, Dept Gastroenterol, Tokyo, Japan.
   [Suzuki, Hideo] Univ Tsukuba, Dept Gastroenterol, Grad Sch Inst Clin Med, Tsukuba, Ibaraki, Japan.
   [Tada, Tomohiro] AI Med Serv Inc, Tokyo, Japan.
   [Tada, Tomohiro] Inst Gastroenterol & Proctol, Saitama, Japan.
C3 Japanese Foundation for Cancer Research; Teikyo University; University
   of Tokyo; University of Tokyo; University of Tsukuba
RP Tada, T (通讯作者)，Inst Gastroenterol & Proctol, Saitama, Japan.
EM tadatomo@saitama.nifty.jp
RI Yoshio, Toshiyuki/ABC-4723-2021; Ishihara, Soichiro/AFK-1375-2022
OI Yoshio, Toshiyuki/0000-0002-6546-0329; Hirasawa,
   Toshiaki/0000-0002-6450-1934
CR Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   Aoki T, 2020, DIGEST ENDOSC, V32, P585, DOI 10.1111/den.13517
   Aoki T, 2020, J GASTROEN HEPATOL, V35, P1196, DOI 10.1111/jgh.14941
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Becq A, 2020, J CLIN GASTROENTEROL, V54, P554, DOI 10.1097/MCG.0000000000001272
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai SL, 2019, GASTROINTEST ENDOSC, V90, P745, DOI 10.1016/j.gie.2019.06.044
   Chen D, 2020, GASTROINTEST ENDOSC, V91, P332, DOI 10.1016/j.gie.2019.09.016
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   de Groof AJ, 2020, GASTROINTEST ENDOSC, V91, P1242, DOI 10.1016/j.gie.2019.12.048
   de Groof AJ, 2020, GASTROENTEROLOGY, V158, P915, DOI 10.1053/j.gastro.2019.11.030
   Ding Z, 2019, GASTROENTEROLOGY, V157, P1044, DOI 10.1053/j.gastro.2019.06.025
   Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   Enzinger PC, 2003, NEW ENGL J MED, V349, P2241, DOI 10.1056/NEJMra035010
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Everson M, 2019, UNITED EUR GASTROENT, V7, P297, DOI 10.1177/2050640618821800
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Ferlay J, 2019, INT J CANCER, V144, P1941, DOI 10.1002/ijc.31937
   Guimaraes P, 2020, GUT, V69, P4, DOI 10.1136/gutjnl-2019-319347
   Gulshan Varun, 2016, JAMA-J AM MED ASSOC, V316, P22
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   Hashimoto R, 2020, GASTROINTEST ENDOSC, V91, P1264, DOI 10.1016/j.gie.2019.12.049
   Hassan C, 2017, GUT, V66, P1949, DOI 10.1136/gutjnl-2016-311906
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He X, 2018, GASTROENTEROLOGY, V155
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Horiuchi Y, 2020, DIGEST DIS SCI, V65, P1355, DOI 10.1007/s10620-019-05862-6
   Hosokawa O, 2007, HEPATO-GASTROENTEROL, V54, P442
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Inoue H, 1997, DIGEST ENDOSC, V9/1, P16, DOI DOI 10.1111/j.1443-1661.1997.tb00453.x
   Inoue H, 1996, DIGEST ENDOSC, V8, P134, DOI DOI 10.1111/j.1443-1661.1996.tb00429.x
   Ishihara R, 2010, DIS ESOPHAGUS, V23, P480, DOI 10.1111/j.1442-2050.2009.01039.x
   Ishioka M, 2019, DIGEST ENDOSC, V31, pe34, DOI 10.1111/den.13306
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Iwatate M, 2018, DIGEST ENDOSC, V30, P642, DOI 10.1111/den.13065
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Klang E, 2020, GASTROINTEST ENDOSC, V91, P606, DOI 10.1016/j.gie.2019.11.012
   Klare P, 2019, GASTROINTEST ENDOSC, V89
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kumagai Y, 2015, DIS ESOPHAGUS, V28, P269, DOI 10.1111/dote.12183
   Kumagai Y, 2004, ENDOSCOPY, V36, P590, DOI 10.1055/s-2004-814533
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Kumagai Y, 2017, ENDOSCOPY, V49, P176, DOI 10.1055/s-0042-119267
   Kuraoka K, 2009, HEPATO-GASTROENTEROL, V56, P63
   Lee YC, 2009, GASTROINTEST ENDOSC, V69, P408, DOI 10.1016/j.gie.2008.05.033
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Luo HY, 2019, LANCET ONCOL, V20, P1645, DOI 10.1016/S1470-2045(19)30637-0
   Matsuguma H, 2007, J CLIN ONCOL, V25
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Nagami Y, 2014, AM J GASTROENTEROL, V109, P845, DOI 10.1038/ajg.2014.94
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Nayor J, 2017, GASTROINTEST ENDOSC, V85, P1263, DOI 10.1016/j.gie.2016.10.041
   Ngu WS, 2019, GUT, V68, P280, DOI 10.1136/gutjnl-2017-314889
   Nonaka S, 2008, ENDOSCOPY, V40, P347, DOI 10.1055/s-2007-995433
   Ohmori M, 2020, GASTROINTEST ENDOSC, V91, P301, DOI 10.1016/j.gie.2019.09.034
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Repici A, 2019, GASTROENTEROLOGY, V156, P2198, DOI 10.1053/j.gastro.2019.02.001
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Saito H, 2020, GASTROINTEST ENDOSC, V92, P144, DOI 10.1016/j.gie.2020.01.054
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shimizu Y, 2008, J GASTROEN HEPATOL, V23, P546, DOI 10.1111/j.1440-1746.2007.04990.x
   Shimizu Y, 2006, GASTROINTEST ENDOSC, V64, P255, DOI 10.1016/j.gie.2006.01.049
   Shiotani A, 2012, J CLIN GASTROENTEROL, V46, pE92, DOI 10.1097/MCG.0b013e31824fff94
   Song EM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56697-0
   Takiyama H., 2018, SCI REP, V8, P1
   Tamashiro A, 2020, DIGEST ENDOSC, V32, P1057, DOI 10.1111/den.13653
   Tokai Y, 2020, ESOPHAGUS-TOKYO, V17, P250, DOI 10.1007/s10388-020-00716-x
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Tsuchida T, 2010, J CLIN ONCOL, V28, DOI 10.1200/jco.2010.28.15_suppl.tps204
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Wu LL, 2019, ENDOSCOPY, V51, P522, DOI 10.1055/a-0855-3532
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Yalamarthi S, 2004, ENDOSCOPY, V36, P874, DOI 10.1055/s-2004-825853
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yao K, 2017, GASTRIC CANCER, V20, pS28, DOI 10.1007/s10120-016-0680-7
   Yoshio T, 2017, DIGEST ENDOSC, V29, P152, DOI 10.1111/den.12712
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zachariah R, 2020, AM J GASTROENTEROL, V115, P138, DOI 10.14309/ajg.0000000000000429
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 99
TC 10
Z9 10
U1 3
U2 35
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1747-4124
EI 1747-4132
J9 EXPERT REV GASTROENT
JI Expert Rev. Gastroenterol. Hepatol.
PD AUG 2
PY 2020
VL 14
IS 8
BP 689
EP 706
DI 10.1080/17474124.2020.1779058
EA JUN 2020
PG 18
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA MX8RI
UT WOS:000545843300001
PM 32500760
OA hybrid
DA 2023-08-21
ER

PT J
AU Billah, M
   Waheed, S
AF Billah, Mustain
   Waheed, Sajjad
TI Minimum redundancy maximum relevance (mRMR) based feature selection from
   endoscopic images for automatic gastrointestinal polyp detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Minimum redundancy maximum relevance (mRMR); Video endoscopy; Ensemble
   classifier; Feature selection; Convolutional Neural Network (CNN); Color
   Wavelet (CW); Feature extraction
AB In this paper, a computer based system has been proposed as a support to gastrointestinal polyp detection. It can detect and classify gastrointestinal polyps from endoscopic video. Color wavelet (CW) features and convolutional neural network (CNN) features of endoscopic video frames are extracted. Mutual information based feature selection technique-Minimum redundancy maximum relevance (mRMR) is used to scale down feature vector. Instead of using a single classifier, Bootstrap Aggregrating (Bagging)- an ensemble classifier is used. Proposed system has been assessed against different public databases and our own datasets. Evaluation shows that, the system outperforms the existing methods.
C1 [Billah, Mustain; Waheed, Sajjad] Mawlana Bhashani Sci & Technol Univ MBSTU, Dept Informat & Commun Technol ICT, Tangail, Bangladesh.
C3 Mawlana Bhashani Science & Technology University
RP Billah, M (通讯作者)，Mawlana Bhashani Sci & Technol Univ MBSTU, Dept Informat & Commun Technol ICT, Tangail, Bangladesh.
EM mustainbillahx@gmail.com; swaheed.iu@gmail.com
CR Abouelenien M., 2013, AM J SCI ENG, V2, P24
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Anguelov D, 2016, SSD SINGLE SHOT MULT
   [Anonymous], 2017, J APPL ENVIRON BIOL
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Berrendero JR, 2016, J STAT COMPUT SIM, V86, P891, DOI 10.1080/00949655.2015.1042378
   Billah M, 2018, BIOMED ENG LETT, V8, P69, DOI 10.1007/s13534-017-0048-x
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Girshick TDR, 2014, RICH FEATURE HIERARC
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kodogiannis VS, 2007, INT J INFORM TECHNOL, V13, P46
   Kopelman Y, 2019, J GASTROENTEROL COMP, V3, P101
   Li BU, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P2326, DOI 10.1109/ROBIO.2009.5420455
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Nagito ATJHS, 2019, INT SOC OPTICS PHOTO, V11049, p110492O
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Radovic M, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1423-9
   Redmon J., 2017, 2017 IEEE C COMPUTER, P7263
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Sun MJ, 2019, J MED IMAG HEALTH IN, V9, P126, DOI 10.1166/jmihi.2019.2550
   Unler A, 2011, INFORM SCIENCES, V181, P4625, DOI 10.1016/j.ins.2010.05.037
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 30
TC 21
Z9 21
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23633
EP 23643
DI 10.1007/s11042-020-09151-7
EA JUN 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539889900002
DA 2023-08-21
ER

PT J
AU Gulati, S
   Emmanuel, A
   Patel, M
   Williams, S
   Haji, A
   Hayee, B
   Neumann, H
AF Gulati, Shraddha
   Emmanuel, Andrew
   Patel, Mehul
   Williams, Sophie
   Haji, Amyn
   Hayee, Bu'Hussain
   Neumann, Helmut
TI Artificial intelligence in luminal endoscopy
SO THERAPEUTIC ADVANCES IN GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
DE AI; endoscopy; imaging
ID HELICOBACTER-PYLORI INFECTION; CONVOLUTIONAL NEURAL-NETWORK;
   COMPUTER-AIDED DIAGNOSIS; COLORECTAL POLYP HISTOLOGY; SQUAMOUS-CELL
   CARCINOMA; CAPSULE ENDOSCOPY; GASTRIC-CANCER; QUANTITATIVE-ANALYSIS;
   DETECTION SYSTEM; TIME
AB Artificial intelligence is a strong focus of interest for global health development. Diagnostic endoscopy is an attractive substrate for artificial intelligence with a real potential to improve patient care through standardisation of endoscopic diagnosis and to serve as an adjunct to enhanced imaging diagnosis. The possibility to amass large data to refine algorithms makes adoption of artificial intelligence into global practice a potential reality. Initial studies in luminal endoscopy involve machine learning and are retrospective. Improvement in diagnostic performance is appreciable through the adoption of deep learning. Research foci in the upper gastrointestinal tract include the diagnosis of neoplasia, including Barrett's, squamous cell and gastric where prospective and real-time artificial intelligence studies have been completed demonstrating a benefit of artificial intelligence-augmented endoscopy. Deep learning applied to small bowel capsule endoscopy also appears to enhance pathology detection and reduce capsule reading time. Prospective evaluation including the first randomised trial has been performed in the colon, demonstrating improved polyp and adenoma detection rates; however, these appear to be relevant to small polyps. There are potential additional roles of artificial intelligence relevant to improving the quality of endoscopic examinations, training and triaging of referrals. Further large-scale, multicentre and cross-platform validation studies are required for the robust incorporation of artificial intelligence-augmented diagnostic luminal endoscopy into our routine clinical practice.
C1 [Neumann, Helmut] Univ Hosp Mainz, Dept Interdisciplinary Endoscopy, D-55131 Mainz, Germany.
   [Gulati, Shraddha; Emmanuel, Andrew; Patel, Mehul; Williams, Sophie; Haji, Amyn; Hayee, Bu'Hussain; Neumann, Helmut] Kings Coll Hosp NHS Fdn Trust, Kings Inst Therapeut Endoscopy, London, England.
C3 University Hospital Mainz; King's College Hospital NHS Foundation Trust
RP Neumann, H (通讯作者)，Univ Hosp Mainz, Dept Interdisciplinary Endoscopy, D-55131 Mainz, Germany.
EM Helmut.Neumann@unimedizin-mainz.de
RI Patel, Mehul/IVV-0981-2023
OI Hayee, Bu'Hussain/0000-0003-1670-8815
CR Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Arnott I, 2019, INTELLIGENT AUTOMATE
   Bisschops R, 2019, ENDOSCOPY, V51, P1155, DOI 10.1055/a-1031-7657
   Buttice C, 2019, AI IS ENHANCING WEAR
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Ebigbo A, 2020, GUT, V69, P615, DOI 10.1136/gutjnl-2019-319460
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Gong DX, 2020, LANCET GASTROENTEROL, V5, P352, DOI 10.1016/S2468-1253(19)30413-3
   Gopi VP, 2012, COMM COM INF SC, V292, P220
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Gulati S, 2020, DIGEST ENDOSC, V32, P512, DOI 10.1111/den.13481
   Guo LJ, 2020, GASTROINTEST ENDOSC, V91, P41, DOI 10.1016/j.gie.2019.08.018
   Hafner M, 2009, LECT NOTES COMPUT SC, V5761, P247, DOI 10.1007/978-3-642-04268-3_31
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Horiuchi Y, 2020, DIGEST DIS SCI, V65, P1355, DOI 10.1007/s10620-019-05862-6
   Huang CR, 2004, ENDOSCOPY, V36, P601, DOI 10.1055/s-2004-814519
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Ishioka M, 2019, DIGEST ENDOSC, V31, pe34, DOI 10.1111/den.13306
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kandel P, 2019, GASTROINTEST ENDOSC, V89, pAB403, DOI 10.1016/j.gie.2019.03.613
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li L, 2020, GASTRIC CANCER, V23, P126, DOI 10.1007/s10120-019-00992-2
   Liu HY, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P102, DOI 10.1109/PACRIM.2011.6032875
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Luo HY, 2019, LANCET ONCOL, V20, P1645, DOI 10.1016/S1470-2045(19)30637-0
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   McAlindon ME, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.09.18
   Misawa M, 2019, GASTROINTEST ENDOSC, V89, pAB646, DOI 10.1016/j.gie.2019.03.1134
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Miyaki R, 2013, J GASTROEN HEPATOL, V28, P841, DOI 10.1111/jgh.12149
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2018, DIGEST ENDOSC, V30, P52, DOI 10.1111/den.13005
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Noya F, 2017, IEEE ENG MED BIO, P3158, DOI 10.1109/EMBC.2017.8037527
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Priestman S, 2016, J ISLAM ARCHAEOL, V3, P1, DOI 10.1558/jia.26266
   Qi X, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2337314
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rombaoa C, 2019, GASTROINTEST ENDOSC, V89, pAB619, DOI 10.1016/j.gie.2019.03.1076
   Saurin JC, 2012, DIGEST LIVER DIS, V44, P477, DOI 10.1016/j.dld.2011.12.021
   Sehgal M, 2018, CASE REP DENT, V2018, DOI 10.1155/2018/9867402
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin D, 2016, GASTROINTEST ENDOSC, V83, P107, DOI 10.1016/j.gie.2015.06.045
   Shiroma S, 2019, GASTROINTEST ENDOSC, V89, pAB189, DOI 10.1016/j.gie.2019.03.142
   Sommen FVD, 2016, GASTROENTEROLOGY, V48, P617
   Spechler SJ, 2011, GASTROENTEROLOGY, V140, P1084, DOI 10.1053/j.gastro.2011.01.030
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Tafreshi MK, 2014, LECT NOTES COMPUT SC, V8673, P89, DOI 10.1007/978-3-319-10404-1_12
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Takenaka K, 2020, GASTROENTEROLOGY, V158, P2150, DOI 10.1053/j.gastro.2020.02.012
   Tang DH, 2019, GASTROINTEST ENDOSC, V89, pAB654, DOI 10.1016/j.gie.2019.03.1148
   Thosani N, 2016, GASTROINTEST ENDOSC, V83, P684, DOI 10.1016/j.gie.2016.01.007
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Tokai Y, 2019, GASTROINTEST ENDOSC, V89, pAB169, DOI 10.1016/j.gie.2019.03.100
   Tsuboi A, 2020, DIGEST ENDOSC, V32, P382, DOI 10.1111/den.13507
   Turan M, 2017, INT J INTELL ROBOT, V1, P399, DOI 10.1007/s41315-017-0036-4
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P595, DOI 10.1109/ICDSP.2015.7251943
   Wu LL, 2019, GUT, V68, P2161, DOI 10.1136/gutjnl-2018-317366
   Yamada M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50567-5
   Yasuda T, 2020, DIGEST ENDOSC, V32, P373, DOI 10.1111/den.13509
   Ye ML, 2017, INT J COMPUT ASS RAD, V12, P1281, DOI 10.1007/s11548-017-1620-7
   Yoon HJ, 2019, J CLIN MED, V8, DOI 10.3390/jcm8091310
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P43, DOI 10.1080/17474124.2017.1257384
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 91
TC 7
Z9 7
U1 0
U2 7
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 2631-7745
J9 THER ADV GASTROINTES
JI Ther. Adv. Gastrointest. Endosc.
PD JUN
PY 2020
VL 13
AR 2631774520935220
DI 10.1177/2631774520935220
PG 15
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA MF9GN
UT WOS:000545646100001
PM 32637935
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Jin, EH
   Lee, D
   Bae, JH
   Kang, HY
   Kwak, MS
   Seo, JY
   Yang, JI
   Yang, SY
   Lim, SH
   Yim, JY
   Lim, JH
   Chung, GE
   Chung, SJ
   Choi, JM
   Han, YM
   Kang, SJ
   Lee, J
   Kim, HC
   Kim, JS
AF Jin, Eun Hyo
   Lee, Dongheon
   Bae, Jung Ho
   Kang, Hae Yeon
   Kwak, Min-Sun
   Seo, Ji Yeon
   Yang, Jong In
   Yang, Sun Young
   Lim, Seon Hee
   Yim, Jeong Yoon
   Lim, Joo Hyun
   Chung, Goh Eun
   Chung, Su Jin
   Choi, Ji Min
   Han, Yoo Min
   Kang, Seung Joo
   Lee, Jooyoung
   Kim, Hee Chan
   Kim, Joo Sung
TI Improved Accuracy in Optical Diagnosis of Colorectal Polyps Using
   Convolutional Neural Networks with Visual Explanations
SO GASTROENTEROLOGY
LA English
DT Article
DE Deep Learning; Colorectal Cancer; Cancer Screening; Diagnostic
ID COMPUTER-AIDED DIAGNOSIS; RISK-FACTORS; GRIT; SYSTEM; VALIDATION;
   CANCER; CLASSIFICATION; MAGNIFICATION; PREDICTOR; ADENOMAS
AB BACKGROUND & AIMS: Narrow-band imaging (NBI) can be used to determine whether colorectal polyps are adenomatous or hyperplastic. We investigated whether an artificial intelligence (AI) system can increase the accuracy of characterizations of polyps by endoscopists of different skill levels. METHODS: We developed convolutional neural networks (CNNs) for evaluation of diminutive colorectal polyps, based on efficient neural architecture searches via parameter sharing with augmentation using NBIs of diminutive (<= 5 mm) polyps, collected from October 2015 through October 2017 at the Seoul National University Hospital, Healthcare System Gangnam Center (training set). We trained the CNN using images from 1100 adenomatous polyps and 1050 hyperplastic polyps from 1379 patients. We then tested the system using 300 images of 180 adenomatous polyps and 120 hyperplastic polyps, obtained from January 2018 to May 2019. We compared the accuracy of 22 endoscopists of different skill levels (7 novices, 4 experts, and 11 NBI-trained experts) vs the CNN in evaluation of images (adenomatous vs hyperplastic) from 180 adenomatous and 120 hyperplastic polyps. The endoscopists then evaluated the polyp images with knowledge of the CNN-processed results. We conducted mixed-effect logistic and linear regression analyses to determine the effects of AI assistance on the accuracy of analysis of diminutive colorectal polyps by endoscopists (primary outcome). RESULTS: The CNN distinguished adenomatous vs hyperplastic diminutive polyps with 86.7% accuracy, based on histologic analysis as the reference standard. Endoscopists distinguished adenomatous vs hyperplastic diminutive polyps with 82.5% overall accuracy (novices, 73.8% accuracy; experts, 83.8% accuracy; and NBI-trained experts, 87.6% accuracy). With knowledge of the CNN-processed results, the overall accuracy of the endoscopists increased to 88.5% (P<.05). With knowledge of the CNN-processed results, the accuracy of novice endoscopists increased to 85.6% (P<.05). The CNN-processed results significantly reduced endoscopist time of diagnosis (from 3.92 to 3.37 seconds per polyp, P=.042). CONCLUSIONS: We developed a CNN that significantly increases the accuracy of evaluation of diminutive colorectal polyps (as adenomatous vs hyperplastic) and reduces the time of diagnosis by endoscopists. This AI assistance system significantly increased the accuracy of analysis by novice endoscopists, who achieved near-expert levels of accuracy without extra training. The CNN assistance system can reduce the skill-level dependence of endoscopists and costs.
C1 [Jin, Eun Hyo; Bae, Jung Ho; Kang, Hae Yeon; Kwak, Min-Sun; Seo, Ji Yeon; Yang, Jong In; Yang, Sun Young; Lim, Seon Hee; Yim, Jeong Yoon; Lim, Joo Hyun; Chung, Goh Eun; Chung, Su Jin; Choi, Ji Min; Han, Yoo Min; Kang, Seung Joo; Kim, Joo Sung] Seoul Natl Univ Hosp Healthcare Syst, Healthcare Res Inst, Gangnam Ctr, Dept Internal Med, Seoul, South Korea.
   [Lee, Dongheon; Kim, Hee Chan] Seoul Natl Univ, Grad Sch, Interdisciplinary Program Bioengn, Seoul, South Korea.
   [Lee, Jooyoung; Kim, Joo Sung] Seoul Natl Univ, Liver Res Inst, Dept Internal Med, Coll Med, Seoul, South Korea.
   [Kim, Hee Chan] Seoul Natl Univ, Dept Biomed Engn, Coll Med, Seoul, South Korea.
   [Kim, Hee Chan] Seoul Natl Univ, Med Res Ctr, Inst Med & Biol Engn, Seoul, South Korea.
C3 Seoul National University (SNU); Seoul National University Hospital;
   Seoul National University (SNU); Seoul National University (SNU); Seoul
   National University (SNU); Seoul National University (SNU)
RP Kim, JS (通讯作者)，Seoul Natl Univ, Dept Internal Med, Coll Med, 101 Daehak Ro, Seoul 03080, South Korea.; Kim, JS (通讯作者)，Seoul Natl Univ, Liver Res Inst, Coll Med, 101 Daehak Ro, Seoul 03080, South Korea.; Kim, HC (通讯作者)，Seoul Natl Univ Hosp, Dept Biomed Engn, 101 Daehak Ro, Seoul 03080, South Korea.
EM hckim@snu.ac.kr; jooskim@snu.ac.kr
RI lee, dongheon/AAV-4862-2021; Han, Yoo Min/AAC-5661-2022; Yang,
   Jong-In/C-4300-2013
OI lee, dongheon/0000-0002-3121-7099; Yang, Sun Young/0000-0003-4766-3752;
   Jin, Eun Hyo/0000-0002-2126-3315; Bae, Jung Ho/0000-0001-7669-1213;
   Kang, Hae Yeon/0000-0003-3965-7539; Kwak, Min-Sun/0000-0003-0353-6460
FU Ministry of Science and ICT (MSIT), South Korea, under the Information
   Technology Research Center (ITRC) support program
   [IITP-2019-2018-0-01833]
FX EHJ was supported by the Ministry of Science and ICT (MSIT), South
   Korea, under the Information Technology Research Center (ITRC) support
   program (IITP-2019-2018-0-01833) supervised by the Institute for
   Information & Communications Technology Promotion (IITP).
CR Adebayo J., 2018, ARXIV181003292
   Aurelio YS, 2019, NEURAL PROCESS LETT, V50, P1937, DOI 10.1007/s11063-018-09977-1
   Bae JH, 2019, CLIN GASTROENTEROL H, V17, P2479, DOI 10.1016/j.cgh.2019.02.019
   Begoli E, 2019, NAT MACH INTELL, V1, P20, DOI 10.1038/s42256-018-0004-1
   Billah M, 2018, BIOMED ENG LETT, V8, P69, DOI 10.1007/s13534-017-0048-x
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Castelvecchi D, 2016, NATURE, V537, P20, DOI [10.1038/nature.2016.20491, 10.1038/538020a]
   Castro Eduardo, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P230, DOI 10.1109/BHI.2018.8333411
   Chaput U, 2011, DIGEST LIVER DIS, V43, P609, DOI 10.1016/j.dld.2011.02.002
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cronin KA, 2018, CANCER-AM CANCER SOC, V124, P2785, DOI [10.1002/cncr.32802, 10.1002/cncr.31551]
   Dam A, 2019, AEM EDUC TRAIN, V3, P14, DOI 10.1002/aet2.10311
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duckworth AL, 2007, J PERS SOC PSYCHOL, V92, P1087, DOI 10.1037/0022-3514.92.6.1087
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Halliday L, 2017, POSTGRAD MED J, V93, P389, DOI 10.1136/postgradmedj-2015-133919
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Ignjatovic A, 2011, GASTROINTEST ENDOSC, V73, P128, DOI 10.1016/j.gie.2010.09.021
   Kendall A., 2017, PROC ADV NEURAL INF, V30, P5574
   Kingma D., 2015, ARXIV
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Lee Ung, 2019, [Anxiety and Mood, 대한불안의학회지], V15, P53, DOI 10.24986/anxmod.2019.15.1.007
   Leslie A, 2002, BRIT J SURG, V89, P845, DOI 10.1046/j.1365-2168.2002.02120.x
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mansour RF, 2018, BIOMED ENG LETT, V8, P41
   Miller-Matero LR, 2018, EDUC HEALTH, V31, P109, DOI 10.4103/efh.EfH_152_16
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Pham H, 2018, PR MACH LEARN RES, V80
   Ponugoti P, 2019, ENDOSCOPY, V51, P221, DOI 10.1055/a-0831-2348
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Poplin R, 2018, NAT BIOMED ENG, V2, P158, DOI 10.1038/s41551-018-0195-0
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Salles A, 2017, AM J SURG, V213, P288, DOI 10.1016/j.amjsurg.2016.10.012
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shahidi N, 2020, GASTROENTEROLOGY, V158, P783, DOI 10.1053/j.gastro.2019.10.024
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Sung JJY, 2005, LANCET ONCOL, V6, P871, DOI 10.1016/S1470-2045(05)70422-8
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vleugels JLA, 2018, GASTROENTEROLOGY, V154, P1682, DOI 10.1053/j.gastro.2018.01.063
   Wagner J, 2019, PROC CVPR IEEE, P9089, DOI 10.1109/CVPR.2019.00931
   WanG J, 2017, CONVOLUTIONAL NEURAL, V11, P1
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 52
TC 53
Z9 56
U1 6
U2 20
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD JUN
PY 2020
VL 158
IS 8
BP 2169
EP +
DI 10.1053/j.gastro.2020.02.03
PG 19
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA LW6GG
UT WOS:000539242100034
PM 32119927
DA 2023-08-21
ER

PT J
AU Mostafiz, R
   Rahman, MM
   Uddin, MS
AF Mostafiz, Rafid
   Rahman, Mohammad Motiur
   Uddin, Mohammad Shorif
TI Gastrointestinal polyp classification through empirical mode
   decomposition and neural features
SO SN APPLIED SCIENCES
LA English
DT Article
DE Video endoscopy; Gastrointestinal polyp detection and classification;
   Convolutional neural network; Empirical mode decomposition
ID COMPUTER-AIDED CLASSIFICATION
AB This study describes an automated detection of polyp type as it is very important to determine the existence of dysplasia-a stage leading to the development of gastrointestinal cancer. The polyp-type classification is performed by a multiclass support vector machine from feature-fusion of bi- dimensional empirical mode decomposition (BEMD) and convolutional neural network (CNN). An extensive experiment is performed using standard datasets by extracted features from the individual technique as well as a fusion of features from BEMD and CNN. The fusion technique confirms satisfactory performance compared to other techniques with an accuracy of 98.94%. Moreover, it shows potentiality in precisely classifying some challenging polyps even though these are somehow confusing for human experts.
C1 [Mostafiz, Rafid; Rahman, Mohammad Motiur] Mawlana Bhashani Sci & Technol Univ, Dept Comp Sci & Engn, Tangail, Bangladesh.
   [Mostafiz, Rafid] Dhaka Int Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
   [Uddin, Mohammad Shorif] Jahangirnagar Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
C3 Mawlana Bhashani Science & Technology University; Dhaka International
   University (DIU); Jahangirnagar University
RP Mostafiz, R (通讯作者)，Mawlana Bhashani Sci & Technol Univ, Dept Comp Sci & Engn, Tangail, Bangladesh.; Mostafiz, R (通讯作者)，Dhaka Int Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
EM rafid.dka@gmail.com; mm73rahman@gmail.com; shorifuddin@gmail.com
RI Uddin, Mohammad Shorif/L-6994-2019; Rahman, Mohammad
   Motiur/AAR-2994-2020
OI Uddin, Mohammad Shorif/0000-0002-7184-2809; Rahman, Mohammad
   Motiur/0000-0003-4417-8276; Mostafiz, Rafid/0000-0002-5905-6530
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Damerval C, 2005, IEEE SIGNAL PROC LET, V12, P701, DOI 10.1109/LSP.2005.855548
   El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   Graf AB, 2002, 099 MAXPLANCK I BIOL
   Hafner M, 2010, IEEE T INF TECHNOL B, V14, P958, DOI 10.1109/TITB.2010.2044184
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kodogiannis VS, 2007, INT J INFORM TECHNOL, V13, P46
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Li ST, 2003, PATTERN RECOGN, V36, P2883, DOI 10.1016/S0031-3203(03)00219-X
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Linderhed A, 2002, P SOC PHOTO-OPT INS, V4738, P1, DOI 10.1117/12.458772
   Liu Z, 2007, INT J REMOTE SENS, V28, P4081, DOI 10.1080/01431160601075483
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Mostafiz R, 2020, INT J IMAG SYST TECH, V30, P224, DOI 10.1002/ima.22350
   Mourikis P, 2014, BMC DEV BIOL, V14, DOI 10.1186/1471-213X-14-2
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Ribeiro E., 2016, COMPUT MATH METHOD M, V2016, P16, DOI DOI 10.1155/2016/6584725.ARTICLE
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sargent D, 2016, PROC SPIE, V9784, DOI 10.1117/12.2217123
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tang XL, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113285
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 32
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2523-3963
EI 2523-3971
J9 SN APPL SCI
JI SN Appl. Sci.
PD JUN
PY 2020
VL 2
IS 6
AR 1143
DI 10.1007/s42452-020-2944-4
PG 10
WC Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Science & Technology - Other Topics
GA LU9ST
UT WOS:000538087000147
OA Bronze
DA 2023-08-21
ER

PT J
AU Tan, JX
   Gao, YF
   Liang, ZR
   Cao, WG
   Pomeroy, MJ
   Huo, YM
   Li, LH
   Barish, MA
   Abbasi, AF
   Pickhardt, PJ
AF Tan, Jiaxing
   Gao, Yongfeng
   Liang, Zhengrong
   Cao, Weiguo
   Pomeroy, Marc J.
   Huo, Yumei
   Li, Lihong
   Barish, Matthew A.
   Abbasi, Almas F.
   Pickhardt, Perry J.
TI 3D-GLCM CNN: A 3-Dimensional Gray-Level Co-Occurrence Matrix-Based CNN
   Model for Polyp Classification via CT Colonography
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Polyp differentiation; image features; deep learning; GLCM; CT
   colonoscopy
ID CONVOLUTIONAL NEURAL-NETWORKS; COMPUTER-AIDED DIAGNOSIS;
   AMERICAN-CANCER-SOCIETY; NODULE DETECTION; FEATURES; SURVEILLANCE;
   COLONOSCOPY; REDUCTION; LESIONS; SYSTEM
AB Accurately classifying colorectal polyps, or differentiating malignant from benign ones, has a significant clinical impact on early detection and identifying optimal treatment of colorectal cancer. Convolution neural network (CNN) has shown great potential in recognizing different objects (e.g. human faces) from multiple slice (or color) images, a task similar to the polyp differentiation, given a large learning database. This study explores the potential of CNN learning from multiple slice (or feature) images to differentiate malignant from benign polyps from a relatively small database with pathological ground truth, including 32 malignant and 31 benign polyps represented by volumetric computed tomographic (CT) images. The feature image in this investigation is the gray-level co-occurrence matrix (GLCM). For each volumetric polyp, there are 13 GLCMs, computed from each of the 13 directions through the polyp volume. For comparison purpose, the CNN learning is also applied to the multi-slice CT images of the volumetric polyps. The comparison study is further extended to include Random Forest (RF) classification of the Haralick texture features (derived from the GLCMs). From the relatively small database, this study achieved scores of 0.91/0.93 (two-fold/leave-one-out evaluations) AUC (area under curve of the receiver operating characteristics) by using the CNN on the GLCMs, while the RF reached 0.84/0.86 AUC on the Haralick features and the CNN rendered 0.79/0.80 AUC on the multiple-slice CT images. The presented CNN learning from the GLCMs can relieve the challenge associated with relatively small database, improve the classification performance over the CNN on the raw CT images and the RF on the Haralick features, and have the potential to perform the clinical task of differentiating malignant from benign polyps with pathological ground truth.
C1 [Tan, Jiaxing; Huo, Yumei; Li, Lihong] CUNY Coll Staten Isl, Dept Comp Sci, Staten Isl, NY 10314 USA.
   [Tan, Jiaxing; Gao, Yongfeng; Cao, Weiguo; Barish, Matthew A.; Abbasi, Almas F.] SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
   [Liang, Zhengrong; Pomeroy, Marc J.] SUNY Stony Brook, Dept Radiol & Biomed Engn, Stony Brook, NY 11794 USA.
   [Liang, Zhengrong; Pomeroy, Marc J.] SUNY Stony Brook, Dept Biomed Engn, Stony Brook, NY 11794 USA.
   [Pickhardt, Perry J.] Univ Wisconsin, Sch Med, Dept Radiol, Madison, WI 53792 USA.
C3 City University of New York (CUNY) System; College of Staten Island
   (CUNY); State University of New York (SUNY) System; State University of
   New York (SUNY) Stony Brook; State University of New York (SUNY) System;
   State University of New York (SUNY) Stony Brook; State University of New
   York (SUNY) System; State University of New York (SUNY) Stony Brook;
   University of Wisconsin System; University of Wisconsin Madison
RP Liang, ZR (通讯作者)，SUNY Stony Brook, Dept Radiol & Biomed Engn, Stony Brook, NY 11794 USA.
EM jerome.liang@sunysb.edu
OI Tan, Jiaxing/0000-0001-9908-3691; HUO, YUMEI/0000-0003-3550-8843; Gao,
   Yongfeng/0000-0001-6169-3478
FU NIH/National Cancer Institute (NCI) [CA206171, CA220004]
FX This work was supported in part by the NIH/National Cancer Institute
   (NCI) under Grant CA206171 and Grant CA220004.
CR *AM CANC SOC, 2016, KEY STAT LUNG CANC
   Anirudh R., 2016, P SOC PHOTO-OPT INS, V9785
   [Anonymous], COMPUTER AIDED DETEC
   Baka N, 2017, IEEE T MED IMAGING, V36, P2138, DOI 10.1109/TMI.2017.2738612
   Byers T, 1997, CA-CANCER J CLIN, V47, P154, DOI 10.3322/canjclin.47.3.154
   Carneiro G, 2013, IEEE T PATTERN ANAL, V35, P2592, DOI 10.1109/TPAMI.2013.96
   Demir C., 2005, 0509 RENSS POL I
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Fiori M, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414600143
   Gatenby RA, 2013, RADIOLOGY, V269, P8, DOI 10.1148/radiol.13122697
   Han FF, 2015, J DIGIT IMAGING, V28, P99, DOI 10.1007/s10278-014-9718-8
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Hofmanninger J, 2015, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2015.7298643
   Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266
   Hu YF, 2016, IEEE T MED IMAGING, V35, P1522, DOI 10.1109/TMI.2016.2518958
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang XJ, 2017, I S BIOMED IMAGING, P379, DOI 10.1109/ISBI.2017.7950542
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang HY, 2018, IEEE J BIOMED HEALTH, V22, P1227, DOI 10.1109/JBHI.2017.2725903
   Kim DH, 2007, NEW ENGL J MED, V357, P1403, DOI 10.1056/NEJMoa070543
   Kingma D., 2015, ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Levin B, 2008, GASTROENTEROLOGY, V134, P1570, DOI 10.1053/j.gastro.2008.02.002
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lundberg SM, 2017, ADV NEUR IN, V30
   Manivannan S, 2018, IEEE T MED IMAGING, V37, P210, DOI 10.1109/TMI.2017.2750210
   Ming Ma, 2014, 2014 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), P1, DOI 10.1109/NSSMIC.2014.7430920
   Pickhardt PJ, 2004, RADIOGRAPHICS, V24, P1535, DOI 10.1148/rg.246045063
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Pomeroy M. J., 2018, P SOC PHOTO-OPT INS
   Pooler BD, 2019, ACAD RADIOL, V26, P30, DOI 10.1016/j.acra.2018.03.002
   Prasanna P, 2016, SCI REP-UK, V6, DOI 10.1038/srep37241
   Rathore S, 2013, IEEE ACM T COMPUT BI, V10, P545, DOI 10.1109/TCBB.2013.84
   Schlegl T, 2014, LECT NOTES COMPUT SC, V8848, P82, DOI 10.1007/978-3-319-13972-2_8
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Slabaugh G, 2010, ALGORITHMS, V3, P21, DOI 10.3390/a3010021
   Song BW, 2014, INT J COMPUT ASS RAD, V9, P1021, DOI 10.1007/s11548-014-0991-2
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan J., 2018, P INT WORKSH PATCH B
   Tan JX, 2019, J X-RAY SCI TECHNOL, V27, P17, DOI 10.3233/XST-180426
   Tao Y, 2017, CHIN CONTR CONF, P4288, DOI 10.23919/ChiCC.2017.8028032
   U.S. Preventive Services Task Force, FIN REC STAT COL CAN
   Wang Hai-Li, 2018, Zhongguo Shi Yan Xue Ye Xue Za Zhi, V26, P171, DOI 10.7534/j.issn.1009-2137.2018.01.029
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Willis BH, 2017, STAT MED, V36, P3283, DOI 10.1002/sim.7372
   Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510
   Yan Y., 2018, P AS C MACH LEARN
   Yin Q. M., 2019, NAT PROD RES, P1, DOI DOI 10.1080/14786419.2019.1611813
   Yoshida H, 2001, IEEE T MED IMAGING, V20, P1261, DOI 10.1109/42.974921
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang S, 2019, COMPUT MED IMAG GRAP, V77, DOI 10.1016/j.compmedimag.2019.101645
NR 54
TC 40
Z9 42
U1 4
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD JUN
PY 2020
VL 39
IS 6
BP 2013
EP 2024
DI 10.1109/TMI.2019.2963177
PG 12
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA ME8SH
UT WOS:000544923000020
PM 31899419
OA Green Accepted
DA 2023-08-21
ER

PT J
AU Guo, Z
   Nemoto, D
   Zhu, X
   Li, Q
   Aizawa, M
   Utano, K
   Isohata, N
   Endo, S
   Lefor, AK
   Togashi, K
AF Guo, Zhe
   Nemoto, Daiki
   Zhu, Xin
   Li, Qin
   Aizawa, Masato
   Utano, Kenichi
   Isohata, Noriyuki
   Endo, Shungo
   Kawarai Lefor, Alan
   Togashi, Kazutomo
TI Polyp detection algorithm can detect small polyps: Ex vivo reading test
   compared with endoscopists
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE adenoma detection rate; colon polyp; colonoscopy; computer-aided
   detection
ID MISS RATE; COLONOSCOPY; PARTICIPATION; INCREASES
AB Background and Study Aims Small polyps are occasionally missed during colonoscopy. This study was conducted to validate the diagnostic performance of a polyp-detection algorithm to alert endoscopists to unrecognized lesions.
   Methods A computer-aided detection (CADe) algorithm was developed based on convolutional neural networks using training data from 1991 still colonoscopy images from 283 subjects with adenomatous polyps. The CADe algorithm was evaluated on a validation dataset including 50 short videos with 1-2 polyps (3.5 +/- 1.5 mm, range 2-8 mm) and 50 videos without polyps. Two expert colonoscopists and two physicians in training separately read the same videos, blinded to the presence of polyps. The CADe algorithm was also evaluated using eight full videos with polyps and seven full videos without a polyp.
   Results The per-video sensitivity of CADe for polyp detection was 88% and the per-frame false-positive rate was 2.8%, with a confidence level of >= 30%. The per-video sensitivity of both experts was 88%, and the sensitivities of the two physicians in training were 84% and 76%. For each reader, the frames with missed polyps appearing on short videos were significantly less than the frames with detected polyps, but no trends were observed regarding polyp size, morphology or color. For full video readings, per-polyp sensitivity was 100% with a per-frame false-positive rate of 1.7%, and per-frame specificity of 98.3%.
   Conclusions The sensitivity of CADe to detect small polyps was almost equivalent to experts and superior to physicians in training. A clinical trial using CADe is warranted.
C1 [Guo, Zhe; Zhu, Xin; Li, Qin] Univ Aizu, Biomed Informat Engn Lab, Aizu Wakamatsu, Fukushima, Japan.
   [Nemoto, Daiki; Aizawa, Masato; Utano, Kenichi; Isohata, Noriyuki; Endo, Shungo; Togashi, Kazutomo] Fukushima Med Univ, Dept Coloproctol, Aizu Med Ctr, 21-2 Maeda, Aizu Wakamatsu, Fukushima 9693492, Japan.
   [Kawarai Lefor, Alan] Jichi Med Univ, Dept Surg, Shimotsuke, Tochigi, Japan.
C3 University of Aizu; Jichi Medical University
RP Togashi, K (通讯作者)，Fukushima Med Univ, Dept Coloproctol, Aizu Med Ctr, 21-2 Maeda, Aizu Wakamatsu, Fukushima 9693492, Japan.
EM togashik@fmu.ac.jp
RI Guo, Zhe/AAD-4026-2021; Lefor, Alan/E-9979-2012
OI Guo, Zhe/0000-0001-6657-4793; Lefor, Alan/0000-0001-6673-5630; zhu,
   xin/0000-0002-4376-0806; Li, Qin/0000-0001-9073-5753; Nemoto,
   Daiki/0000-0002-6812-2966
FU MEXT/JSPS KAKENHI [JP 18K08010]; University of Aizu [2019-P-2]
FX WE WOULD LIKE to thank Dr. Marise Miyake and Dr. Yuki Sato (Junior
   resident, Aizu Medical Center Fukushima Medical University, Japan) for
   participation in the reading test. This work was partially funded by
   MEXT/JSPS KAKENHI Grant Number JP 18K08010 and the Competitive Research
   Fund of the University of Aizu Grant Number 2019-P-2.
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Castaneda D, 2018, GASTROINTEST ENDOSC, V88, P209, DOI 10.1016/j.gie.2018.03.022
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Guo Z, 2020, I S BIOMED IMAGING, P1655, DOI 10.1109/ISBI45749.2020.9098500
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Marcondes FO, 2018, DIGEST DIS SCI, V63, P856, DOI 10.1007/s10620-018-4947-1
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Pasha SF, 2012, AM J GASTROENTEROL, V107, P363, DOI 10.1038/ajg.2011.436
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Rex DK, 2018, GASTROINTEST ENDOSC, V88, P335, DOI 10.1016/j.gie.2018.02.043
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI [10.3322/caac.21220, 10.3322/caac.21208, 10.3322/caac.21395]
   Sonnenberg A, 2008, GASTROINTEST ENDOSC, V67, P489, DOI 10.1016/j.gie.2007.08.041
   Stoffel EM, 2008, CANCER PREV RES, V1, P507, DOI 10.1158/1940-6207.CAPR-08-0096
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhu X, 2018, GASTROINTEST ENDOSC, V87, pAB251
NR 26
TC 12
Z9 12
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JAN
PY 2021
VL 33
IS 1
BP 162
EP 169
DI 10.1111/den.13670
EA MAY 2020
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA PN1TC
UT WOS:000535853800001
PM 32173917
DA 2023-08-21
ER

PT J
AU Lee, JY
   Jeong, J
   Song, EM
   Ha, C
   Lee, HJ
   Koo, JE
   Yang, DH
   Kim, N
   Byeon, JS
AF Lee, Ji Young
   Jeong, Jinhoon
   Song, Eun Mi
   Ha, Chunae
   Lee, Hyo Jeong
   Koo, Ja Eun
   Yang, Dong-Hoon
   Kim, Namkug
   Byeon, Jeong-Sik
TI Real-time detection of colon polyps during colonoscopy using deep
   learning: systematic validation with four independent datasets
SO SCIENTIFIC REPORTS
LA English
DT Article
ID COLORECTAL-CANCER; SCREENING COLONOSCOPY; ADENOMA DETECTION; INCREASES;
   RISK
AB We developed and validated a deep-learning algorithm for polyp detection. We used a YOLOv2 to develop the algorithm for automatic polyp detection on 8,075 images (503 polyps). We validated the algorithm using three datasets: A: 1,338 images with 1,349 polyps; B: an open, public CVC-clinic database with 612 polyp images; and C: 7 colonoscopy videos with 26 polyps. To reduce the number of false positives in the video analysis, median filtering was applied. We tested the algorithm performance using 15 unaltered colonoscopy videos (dataset D). For datasets A and B, the per-image polyp detection sensitivity was 96.7% and 90.2%, respectively. For video study (dataset C), the per-image polyp detection sensitivity was 87.7%. False positive rates were 12.5% without a median filter and 6.3% with a median filter with a window size of 13. For dataset D, the sensitivity and false positive rate were 89.3% and 8.3%, respectively. The algorithm detected all 38 polyps that the endoscopists detected and 7 additional polyps. The operation speed was 67.16 frames per second. The automatic polyp detection algorithm exhibited good performance, as evidenced by the high detection sensitivity and rapid processing. Our algorithm may help endoscopists improve polyp detection.
C1 [Lee, Ji Young; Lee, Hyo Jeong; Koo, Ja Eun] Asan Med Ctr, Hlth Screening & Promot Ctr, Seoul, South Korea.
   [Jeong, Jinhoon] Univ Ulsan, Asan Med Ctr, Asan Med Inst Convergence Sci & Technol, Dept Biomed Engn,Coll Med, Seoul, South Korea.
   [Song, Eun Mi; Ha, Chunae; Yang, Dong-Hoon; Byeon, Jeong-Sik] Univ Ulsan, Asan Med Ctr, Dept Gastroenterol, Coll Med, Seoul, South Korea.
   [Kim, Namkug] Univ Ulsan, Asan Med Ctr, Dept Convergence Med, Coll Med, Seoul, South Korea.
C3 University of Ulsan; Asan Medical Center; University of Ulsan; Asan
   Medical Center; University of Ulsan; Asan Medical Center; University of
   Ulsan; Asan Medical Center
RP Byeon, JS (通讯作者)，Univ Ulsan, Asan Med Ctr, Dept Gastroenterol, Coll Med, Seoul, South Korea.; Kim, N (通讯作者)，Univ Ulsan, Asan Med Ctr, Dept Convergence Med, Coll Med, Seoul, South Korea.
EM namkugkim@gmail.com; jsbyeon@amc.seoul.kr
RI Kim, Namkug/E-3843-2012; Yang, Dong-Hoon/B-3437-2015
OI Kim, Namkug/0000-0002-3438-2217; Yang, Dong-Hoon/0000-0001-7756-2704
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [NRF-2017R1A2B4005846]
FX This work was supported by a National Research Foundation of Korea (NRF)
   grant funded by the Korean government (MSIT) (NRF-2017R1A2B4005846). The
   funders had no role in the design of the study; in the collection,
   analyses, or interpretation of data; in the writing of the manuscript;
   or in the decision to publish the results.
CR Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Baxter NN, 2012, J CLIN ONCOL, V30, P2664, DOI 10.1200/JCO.2011.40.4772
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bond A, 2015, WORLD J GASTRO ENDOS, V7, P969, DOI 10.4253/wjge.v7.i10.969
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Doubeni CA, 2013, ANN INTERN MED, V158, P312, DOI 10.7326/0003-4819-158-5-201303050-00003
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gonzalez RC., 2017, DIGITAL IMAGE PROCES
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Kahi CJ, 2011, CLIN GASTROENTEROL H, V9, P42, DOI 10.1016/j.cgh.2010.09.013
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   Lami M, 2018, ENDOSCOPY, V50, P701, DOI 10.1055/s-0044-101026
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mizuno K, 2014, DIGEST ENDOSC, V26, P84, DOI 10.1111/den.12263
   Redmon J, 2013, DARKNET OPEN SOURCE, V2019, P2013
   Redmon J., 2017, P IEEE C COMP VIS PA, P1
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vleugels JLA, 2017, GASTROINTEST ENDOSC, V85, P1169, DOI 10.1016/j.gie.2016.12.014
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
NR 27
TC 44
Z9 44
U1 1
U2 12
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAY 20
PY 2020
VL 10
IS 1
AR 8379
DI 10.1038/s41598-020-65387-1
PG 9
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA LY3YG
UT WOS:000540464700001
PM 32433506
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Poon, CCY
   Jiang, YQ
   Zhang, RK
   Lo, WWY
   Cheung, MSH
   Yu, RX
   Zheng, YL
   Wong, JCT
   Liu, Q
   Wong, SH
   Mak, TWC
   Lau, JYW
AF Poon, Carmen C. Y.
   Jiang, Yuqi
   Zhang, Ruikai
   Lo, Winnie W. Y.
   Cheung, Maggie S. H.
   Yu, Ruoxi
   Zheng, Yali
   Wong, John C. T.
   Liu, Qing
   Wong, Sunny H.
   Mak, Tony W. C.
   Lau, James Y. W.
TI AI-doscopist: a real-time deep-learning-based algorithm for localising
   polyps in colonoscopy videos with edge computing devices
SO NPJ DIGITAL MEDICINE
LA English
DT Article
ID VALIDATION; CLASSIFICATION; DIAGNOSIS
AB We have designed a deep-learning model, an "Artificial Intelligent Endoscopist (a.k.a. AI-doscopist)", to localise colonic neoplasia during colonoscopy. This study aims to evaluate the agreement between endoscopists and AI-doscopist for colorectal neoplasm localisation. AI-doscopist was pre-trained by 1.2 million non-medical images and fine-tuned by 291,090 colonoscopy and non-medical images. The colonoscopy images were obtained from six databases, where the colonoscopy images were classified into 13 categories and the polyps' locations were marked image-by-image by the smallest bounding boxes. Seven categories of non-medical images, which were believed to share some common features with colorectal polyps, were downloaded from an online search engine. Written informed consent were obtained from 144 patients who underwent colonoscopy and their full colonoscopy videos were prospectively recorded for evaluation. A total of 128 suspicious lesions were resected or biopsied for histological confirmation. When evaluated image-by-image on the 144 full colonoscopies, the specificity of AI-doscopist was 93.3%. AI-doscopist were able to localise 124 out of 128 polyps (polyp-based sensitivity = 96.9%). Furthermore, after reviewing the suspected regions highlighted by AI-doscopist in a 102-patient cohort, an endoscopist has high confidence in recognizing four missed polyps in three patients who were not diagnosed with any lesion during their original colonoscopies. In summary, AI-doscopist can localise 96.9% of the polyps resected by the endoscopists. If AI-doscopist were to be used in real-time, it can potentially assist endoscopists in detecting one more patient with polyp in every 20-33 colonoscopies.
C1 [Poon, Carmen C. Y.; Jiang, Yuqi; Zhang, Ruikai; Lo, Winnie W. Y.; Yu, Ruoxi; Zheng, Yali] Chinese Univ Hong Kong, Dept Surg, Div Biomed Engn Res, Hong Kong, Peoples R China.
   [Cheung, Maggie S. H.; Lau, James Y. W.] Chinese Univ Hong Kong, Dept Surg, Prince Wales Hosp, Div Vasc & Gen Surg, Hong Kong, Peoples R China.
   [Zheng, Yali] Shenzhen Technol Univ, Coll Hlth Sci & Environm Engn, Shenzhen, Peoples R China.
   [Wong, John C. T.; Wong, Sunny H.] Chinese Univ Hong Kong, Inst Digest Dis, Dept Med & Therapeut, Div Gastroenterol & Hepatol, Hong Kong, Peoples R China.
   [Liu, Qing] Xian Jiaotong Liverpool Univ, Dept Elect & Elect Engn, Suzhou, Peoples R China.
   [Mak, Tony W. C.] Chinese Univ Hong Kong, Dept Surg, Div Colorectal Surg, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong; Chinese University of Hong Kong; Prince
   of Wales Hospital; Shenzhen Technology University; Chinese University of
   Hong Kong; Xi'an Jiaotong-Liverpool University; Chinese University of
   Hong Kong
RP Poon, CCY (通讯作者)，Chinese Univ Hong Kong, Dept Surg, Div Biomed Engn Res, Hong Kong, Peoples R China.; Lau, JYW (通讯作者)，Chinese Univ Hong Kong, Dept Surg, Prince Wales Hosp, Div Vasc & Gen Surg, Hong Kong, Peoples R China.
EM cpoon@surgery.cuhk.edu.hk; laujyw@surgery.cuhk.edu.hk
RI Zhang, Ruikai/W-9848-2019; Poon, Carmen C. Y./B-4616-2011; Wong, Sunny
   H/N-3754-2015
OI Zhang, Ruikai/0000-0001-8929-628X; Poon, Carmen C.
   Y./0000-0001-7717-4752; Wong, Sunny H/0000-0002-3354-9310
FU Hong Kong General Research Fund; Hong Kong Innovation and Technology
   Fund
FX The work was supported in part by Hong Kong General Research Fund and
   Hong Kong Innovation and Technology Fund. We are grateful for Surgical
   Team Three of the surgical department of the Chinese University of Hong
   Kong for their help in collecting the endoscopy videos at the Prince of
   Wales Hospital.
CR Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zheng YL, 2018, IEEE ENG MED BIO, P4142, DOI 10.1109/EMBC.2018.8513337
   Zimmermann-Fraedrich K, 2019, GASTROENTEROLOGY, V157, P660, DOI 10.1053/j.gastro.2019.05.011
NR 23
TC 17
Z9 18
U1 4
U2 7
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2398-6352
J9 NPJ DIGIT MED
JI npj Digit. Med.
PD MAY 18
PY 2020
VL 3
IS 1
AR 73
DI 10.1038/s41746-020-0281-z
PG 8
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA LO5PM
UT WOS:000533679600001
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Pannu, HS
   Ahuja, S
   Dang, N
   Soni, S
   Malhi, AK
AF Pannu, Husanbir Singh
   Ahuja, Sahil
   Dang, Nitin
   Soni, Sahil
   Malhi, Avleen Kaur
TI Deep learning based image classification for intestinal hemorrhage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Ensemble; Image processing; Capsule
   endoscopy
ID BLEEDING DETECTION; CAPSULE; RECOGNITION
AB Convolutional neural networks (CNN) have become a popular choice for image segmentation and classification. Internal body images are obscure in nature with involvement of noise, luminance variation, rotation and blur. Thus optimal choice of features for machine learning model to classify bleeding is still an open problem. CNN is efficient for attribute selection and ensemble learning makes a generalized robust system. Capsule endoscopy is a new technology which enables a gastroenterologist to visualize the entire digestive tract including small bowel to diagnose bleeding, ulcer and polyp. This paper presents a supervised learning ensemble to detect the bleeding in the images of Wireless Capsule Endoscopy. It accurately finds out the best possible combination of attributes required to classify bleeding symptoms in endoscopy images. A careful setting for CNN layer options and optimizer for back propagation after reducing the color palette using minimum variance quantization has shown promising results. Results of testing on public and real dataset has been analyzed. Proposed ensemble is able to achieve 0.95 on the public endoscopy dataset and 0.93 accuracy on the real video dataset. A detailed data analysis has also been incorporated in the study including RGB pixel intensities, distributions of binary classes and various class ratios for training.
C1 [Pannu, Husanbir Singh; Ahuja, Sahil; Dang, Nitin; Soni, Sahil; Malhi, Avleen Kaur] Thapar Inst Engn & Technol, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Malhi, AK (通讯作者)，Thapar Inst Engn & Technol, Patiala, Punjab, India.
EM hspannu@thapar.edu; avleen@thapar.edu
OI Ahuja, Sahil/0000-0002-2710-1640
FU Aalto University
FX Open access funding provided by Aalto University.
CR Abouelenien M., 2013, AM J SCI ENG, V2, P24
   Anjomshoae S, 2019, LECT NOTES ARTIF INT, V11763, P95, DOI 10.1007/978-3-030-30391-4_6
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Carpi F, 2013, EXPERT REV MED DEVIC, V10, P433, DOI 10.1586/17434440.2013.811832
   Coelho P, 2018, LECT NOTES COMPUT SC, V10882, P553, DOI 10.1007/978-3-319-93000-8_63
   Du WJ, 2019, IEEE ACCESS, V7, P142053, DOI 10.1109/ACCESS.2019.2944676
   Figueiredo IN, 2013, COMP M BIO BIO E-IV, V1, P198, DOI 10.1080/21681163.2013.796164
   Fuentes alvarez JR, DEEP LEARNING HIERAR
   Ghosh T, 2018, IEEE IMAGE PROC, P3034, DOI 10.1109/ICIP.2018.8451300
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hajabdollahi M, 2019, IEEE ENG MED BIO, P7227, DOI 10.1109/EMBC.2019.8857751
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kaur H, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3343440
   Kim H, 2017, ADV METEOROL, V2017, DOI 10.1155/2017/1917372
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   LeCun Y., 1995, HDB BRAIN THEORY NEU, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Li SZ, 2019, IEEE INT C BIOINFORM, P818, DOI 10.1109/BIBM47256.2019.8983292
   Li XL, 2017, IEEE ENG MED BIO, P1994, DOI 10.1109/EMBC.2017.8037242
   Liangpunsakul S, 2003, AM J GASTROENTEROL, V98, P2676, DOI 10.1016/j.amjgastroenterol.2003.07.006
   Liu JG, 2009, OPTIM ENG, V10, P289, DOI 10.1007/s11081-008-9066-y
   Liu SF, 2019, ENGINEERING-PRC, V5, P261, DOI 10.1016/j.eng.2018.11.020
   Liu W, 2017, IEEE ACCESS, V5, P24417, DOI 10.1109/ACCESS.2017.2766203
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Lucchese L, 1999, MULTIMEDIA COMMUNICA, P110
   Malhi A., 2019, P INT WORKSHOP EXPLA, P1
   Najarian K., 2018, ARXIV PREPRINT ARXIV
   Pan GB, 2011, J MED SYST, V35, P1477, DOI 10.1007/s10916-009-9424-0
   Radenovi F, 2018, IEEE T PATTERN ANAL
   Raginsky M, 2011, IEEE T SIGNAL PROCES, V59, P4139, DOI 10.1109/TSP.2011.2157913
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sainju S, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0025-1
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Usman MA, 2016, COMPUT MED IMAG GRAP, V54, P16, DOI 10.1016/j.compmedimag.2016.09.005
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Xing XH, 2018, IEEE ENG MED BIO, P3594, DOI 10.1109/EMBC.2018.8513012
   Xiong XP, 2015, 2015 IEEE MTT-S INTERNATIONAL MICROWAVE WORKSHOP SERIES ON ADVANCED MATERIALS AND PROCESSES FOR RF AND THZ APPLICATIONS (IMWS-AMP), P1, DOI 10.1109/IMWS-AMP.2015.7324898
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zheng HY, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P1, DOI 10.1109/Trustcom.2015.350
   Zhou Z.-H., 2015, ENCY BIOMETRICS, P411, DOI DOI 10.1007/978-1-4899-7488-4_293
NR 48
TC 21
Z9 21
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21941
EP 21966
DI 10.1007/s11042-020-08905-7
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000532899600001
OA hybrid
DA 2023-08-21
ER

PT J
AU Carneiro, G
   Pu, LZCT
   Singh, R
   Burt, A
AF Carneiro, Gustavo
   Pu, Leonardo Zorron Cheng Tao
   Singh, Rajvinder
   Burt, Alastair
TI Deep learning uncertainty and confidence calibration for the five-class
   polyp classification from colonoscopy
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Polyp classification; Deep learning; Model calibration; Classification
   uncertainty; Bayesian learning; Bayesian inference
ID SOCIETY TASK-FORCE; COLORECTAL-CANCER; VALIDATION; DIAGNOSIS; SYSTEM
AB There are two challenges associated with the interpretability of deep learning models in medical image analysis applications that need to be addressed: confidence calibration and classification uncertainty. Confidence calibration associates the classification probability with the likelihood that it is actually correct - hence, a sample that is classified with confidence X% has a chance of X% of being correctly classified. Classification uncertainty estimates the noise present in the classification process, where such noise estimate can be used to assess the reliability of a particular classification result. Both confidence calibration and classification uncertainty are considered to be helpful in the interpretation of a classification result produced by a deep learning model, but it is unclear how much they affect classification accuracy and calibration, and how they interact. In this paper, we study the roles of confidence calibration (via post-process temperature scaling) and classification uncertainty (computed either from classification entropy or the predicted variance produced by Bayesian methods) in deep learning models. Results suggest that calibration and uncertainty improve classification interpretation and accuracy. This motivates us to propose a new Bayesian deep learning method that relies both on calibration and uncertainty to improve classification accuracy and model interpretability. Experiments are conducted on a recently proposed five-class polyp classification problem, using a data set containing 940 high-quality images of colorectal polyps, and results indicate that our proposed method holds the state-of-the-art results in terms of confidence calibration and classification accuracy. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Carneiro, Gustavo] Univ Adelaide, Sch Comp Sci, Australian Inst Machine Learning, Adelaide, SA 5005, Australia.
   [Pu, Leonardo Zorron Cheng Tao; Singh, Rajvinder; Burt, Alastair] Univ Adelaide, Fac Hlth & Med Sci, Adelaide, SA 5005, Australia.
C3 University of Adelaide; University of Adelaide
RP Carneiro, G (通讯作者)，Univ Adelaide, Sch Comp Sci, Australian Inst Machine Learning, Adelaide, SA 5005, Australia.
EM gustavo.carneiro@adelaide.edu.au
RI Burt, Alastair D/D-3634-2013
OI Burt, Alastair D/0000-0002-3011-7774; Singh,
   Rajvinder/0000-0001-9116-6054; Carneiro, Gustavo/0000-0002-5571-6220
FU Australian Research Council [DP180103232]; Alexander von
   Humboldt-Stiftung;  [2018/7063 - NALHN/THRF];  [0006005804]
FX G.C. acknowledges the support by the Australian Research Council through
   grant DP180103232 and the Alexander von Humboldt-Stiftung for the
   renewed research stay sponsorship. All authors acknowledge the grant
   2018/7063 - NALHN/THRF - Project Grant - 0006005804 and the TitanXp
   donated by NVidia.
CR Abadi M., 2015, P 12 USENIX C OPERAT, DOI [DOI 10.5555/3026877.3026899, DOI 10.1038/NN.3331]
   Bar Y, 2015, I S BIOMED IMAGING, P294, DOI 10.1109/ISBI.2015.7163871
   Bishop C.M., 2006, PATTERN RECOGN, P738, DOI DOI 10.1117/1.2819119
   Bullock J., 2018, ARXIV181200548
   Chollet F., 2015, KERAS PROBABILISTIC
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eaton-Rosen Z, 2018, LECT NOTES COMPUT SC, V11070, P691, DOI 10.1007/978-3-030-00928-1_78
   Gal Y., 2016, P 33 INT C MACH LEAR, DOI DOI 10.5555/3045390.3045502
   Gal Y, 2017, ADV NEUR IN, V30
   Gamerman D., 2006, MARKOV CHAIN MONTE C, DOI DOI 10.1201/9781482296426
   Goodman B, 2017, AI MAG, V38, P50, DOI 10.1609/aimag.v38i3.2741
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Huang G., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243
   Iwatate M, 2018, DIGEST ENDOSC, V30, P642, DOI 10.1111/den.13065
   Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310
   Jiang XQ, 2012, J AM MED INFORM ASSN, V19, P263, DOI 10.1136/amiajnl-2011-000291
   Kendall A., 2017, PROC ADV NEURAL INF, V30, P5574
   King DB, 2015, ACS SYM SER, V1214, P1
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Levin B, 2008, GASTROENTEROLOGY, V134, P1570, DOI 10.1053/j.gastro.2008.02.002
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lipton ZC, 2018, COMMUN ACM, V61, P36, DOI 10.1145/3233231
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Nair T, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101557
   Nair V., 2010, P 27 INT C MACHINE L, P807, DOI DOI 10.5555/3104322.3104425
   Pu LZCT, 2018, GASTROINTEST ENDOSC, V87, pAB245
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Ribeiro E, 2017, I S BIOMED IMAGING, P1044, DOI 10.1109/ISBI.2017.7950695
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Settles B., 2012, SYNTHESIS LECT ARTIF
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Singh R, 2013, DIGEST ENDOSC, V25, P16, DOI 10.1111/den.12075
   Tian Y, 2019, PROCEEDINGS OF THE 2019 SUMMER SIMULATION CONFERENCE (SUMMERSIM '19)
   Wang JB, 2017, INT C ELECTR MACH SY
NR 36
TC 27
Z9 27
U1 3
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD MAY
PY 2020
VL 62
AR 101653
DI 10.1016/j.media.2020.101653
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA LP5JE
UT WOS:000534353000005
PM 32172037
DA 2023-08-21
ER

PT J
AU Yang, YJ
   Cho, BJ
   Lee, MJ
   Kim, JH
   Lim, H
   Bang, CS
   Jeong, HM
   Hong, JT
   Baik, GH
AF Yang, Young Joo
   Cho, Bum-Joo
   Lee, Myung-Je
   Kim, Ju Han
   Lim, Hyun
   Bang, Chang Seok
   Jeong, Hae Min
   Hong, Ji Taek
   Baik, Gwang Ho
TI Automated Classification of Colorectal Neoplasms in White-Light
   Colonoscopy Images via Deep Learning
SO JOURNAL OF CLINICAL MEDICINE
LA English
DT Article
DE colonoscopy; colorectal neoplasm; artificial intelligence; deep
   learning; convolutional neural network
ID COMPUTER-AIDED DIAGNOSIS; OPTICAL DIAGNOSIS; POLYPS; CANCER; VALIDATION;
   ENDOSCOPY; SOCIETY; ACCURACY; SYSTEM
AB Background: Classification of colorectal neoplasms during colonoscopic examination is important to avoid unnecessary endoscopic biopsy or resection. This study aimed to develop and validate deep learning models that automatically classify colorectal lesions histologically on white-light colonoscopy images. Methods: White-light colonoscopy images of colorectal lesions exhibiting pathological results were collected and classified into seven categories: stages T1-4 colorectal cancer (CRC), high-grade dysplasia (HGD), tubular adenoma (TA), and non-neoplasms. The images were then re-classified into four categories including advanced CRC, early CRC/HGD, TA, and non-neoplasms. Two convolutional neural network models were trained, and the performances were evaluated in an internal test dataset and an external validation dataset. Results: In total, 3828 images were collected from 1339 patients. The mean accuracies of ResNet-152 model for the seven-category and four-category classification were 60.2% and 67.3% in the internal test dataset, and 74.7% and 79.2% in the external validation dataset, respectively, including 240 images. In the external validation, ResNet-152 outperformed two endoscopists for four-category classification, and showed a higher mean area under the curve (AUC) for detecting TA+ lesions (0.818) compared to the worst-performing endoscopist. The mean AUC for detecting HGD+ lesions reached 0.876 by Inception-ResNet-v2. Conclusions: A deep learning model presented promising performance in classifying colorectal lesions on white-light colonoscopy images; this model could help endoscopists build optimal treatment strategies.
C1 [Yang, Young Joo; Lim, Hyun; Bang, Chang Seok; Jeong, Hae Min; Hong, Ji Taek; Baik, Gwang Ho] Hallym Univ, Coll Med, Dept Internal Med, Chunchon 24252, South Korea.
   [Yang, Young Joo; Bang, Chang Seok; Jeong, Hae Min; Hong, Ji Taek; Baik, Gwang Ho] Hallym Univ, Inst Liver & Digest Dis, Chunchon 24253, South Korea.
   [Cho, Bum-Joo; Lee, Myung-Je] Hallym Univ, Med Ctr, Med Artificial Intelligence Ctr, Anyang 14068, South Korea.
   [Cho, Bum-Joo; Kim, Ju Han] Seoul Natl Univ, Coll Med, Seoul Natl Univ Biomed Informat SNUBI, Div Biomed Informat, Seoul 03080, South Korea.
   [Cho, Bum-Joo] Hallym Univ, Sacred Heart Hosp, Dept Ophthalmol, Anyang 14068, South Korea.
C3 Hallym University; Hallym University; Hallym University; Seoul National
   University (SNU); Hallym University
RP Cho, BJ (通讯作者)，Hallym Univ, Med Ctr, Med Artificial Intelligence Ctr, Anyang 14068, South Korea.; Cho, BJ (通讯作者)，Seoul Natl Univ, Coll Med, Seoul Natl Univ Biomed Informat SNUBI, Div Biomed Informat, Seoul 03080, South Korea.; Cho, BJ (通讯作者)，Hallym Univ, Sacred Heart Hosp, Dept Ophthalmol, Anyang 14068, South Korea.
EM yjyang@hallym.or.kr; bjcho8@gmail.com; mach.ai.leemj@gmail.com;
   juhan@snu.ac.kr; hlim77@hallym.or.kr; cloudslove@hallym.or.kr;
   cromnjeong@gmail.com; hahahjt2@naver.com; baikgh2@hanmail.net
RI Bang, Chang SEOK/I-9689-2019
OI Lim, Hyun/0000-0001-6581-6420; YANG, YOUNGJOO/0000-0001-6325-1104; Lee,
   Myungje/0000-0002-2877-0619
FU Bio & Medical Technology Development Program of the National Research
   Foundation (NRF); Korean government, Ministry of Science and ICT (MSIT)
   [NRF-2017M3A9E8033207]; Hallym University Research Fund 2018
   [HURF-2018-22]
FX This research was supported by the Bio & Medical Technology Development
   Program of the National Research Foundation (NRF), and funded by the
   Korean government, Ministry of Science and ICT (MSIT) (grant number
   NRF-2017M3A9E8033207) and Hallym University Research Fund 2018
   (HURF-2018-22).
CR Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chao WL, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030099
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Cho BJ, 2019, ENDOSCOPY, V51, P1121, DOI 10.1055/a-0981-6133
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   He KM, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Huang G, 2017, PROC INT C LEARN REP
   Jung KW, 2015, CANCER RES TREAT, V47, P127, DOI 10.4143/crt.2015.060
   Keswani RN, 2016, GASTROINTEST ENDOSC, V84, P296, DOI 10.1016/j.gie.2016.01.048
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Lee BI, 2012, CLIN ENDOSC, V45, P25, DOI 10.5946/ce.2012.45.1.25
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Park HW, 2009, GUT LIVER, V3, P35, DOI 10.5009/gnl.2009.3.1.35
   Peery AF, 2018, GASTROENTEROLOGY, V154, P1352, DOI 10.1053/j.gastro.2018.01.003
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wanders LK, 2013, LANCET ONCOL, V14, P1337, DOI 10.1016/S1470-2045(13)70509-6
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Yang YJ, 2019, WORLD J GASTROENTERO, V25, P1666, DOI 10.3748/wjg.v25.i14.1666
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 36
TC 22
Z9 22
U1 2
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0383
J9 J CLIN MED
JI J. Clin. Med.
PD MAY
PY 2020
VL 9
IS 5
AR 1593
DI 10.3390/jcm9051593
PG 12
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA LY0OO
UT WOS:000540223800350
PM 32456309
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Dunham, ME
   Kong, KHA
   McWhorter, AJ
   Adkins, LK
AF Dunham, Michael E.
   Kong, Keonho A.
   McWhorter, Andrew J.
   Adkins, Lacey K.
TI Optical Biopsy: Automated Classification of Airway Endoscopic Findings
   Using a Convolutional Neural Network
SO LARYNGOSCOPE
LA English
DT Article
DE Artificial intelligence; neural network; machine learning; vocal fold
   lesions; endoscopy; optical biopsy
ID DIAGNOSIS
AB Objectives/Hypothesis Create an autonomous computational system to classify endoscopy findings.
   Study Design Computational analysis of vocal fold images at an academic, tertiary-care laryngology practice.
   Methods A series of normal and abnormal vocal fold images were obtained from the image database of an academic tertiary care laryngology practice. The benign images included normals, nodules, papilloma, polyps, and webs. A separate set of carcinoma and leukoplakia images comprised a single malignant-premalignant class. All images were classified with their existing labels. Images were randomly withheld from each class for testing. The remaining images were used to train and validate a neural network for classifying vocal fold lesions. Two classifiers were developed. A multiclass system classified the five categories of benign lesions. A separate analysis was performed using a binary classifier trained to distinguish malignant-premalignant from benign lesions.
   Results Precision ranged from 71.7% (polyps) to 89.7% (papilloma), and recall ranged from 70.0% (papilloma) to 88.0% (nodules) for the benign classifier. Overall accuracy for the benign classifier was 80.8%. The binary classifier correctly identified 92.0% of the malignant-premalignant lesions with an overall accuracy of 93.0%.
   Conclusions Autonomous classification of endoscopic images with artificial intelligence technology is possible. Better network implementations and larger datasets will continue to improve classifier accuracy. A clinically useful optical cancer screening system may require a multimodality approach that incorporates nonvisual spectra.
   Level of Evidence NA Laryngoscope, 2020
C1 [Dunham, Michael E.; Kong, Keonho A.; McWhorter, Andrew J.; Adkins, Lacey K.] Louisiana State Univ, Hlth Sci Ctr, Dept Otolaryngol Head & Neck Surg, Sch Med, New Orleans, LA USA.
C3 Louisiana State University System; Louisiana State University Health
   Sciences Center New Orleans
RP Dunham, ME (通讯作者)，533 Bolivar St, New Orleans, LA 70112 USA.
EM mdunha@lsuhsc.edu
OI Adkins, Lacey/0000-0002-4104-6270
CR Ameling S., 2009, 11th International Congress of the IUPESM. World Congress on Medical Physics and Biomedical Engineering. Image Processing, Biosignal Processing, Modelling and Simulation, Biomechanics, P995, DOI 10.1007/978-3-642-03882-2_265
   Bur AM, 2019, OTOLARYNG HEAD NECK, V160, P603, DOI 10.1177/0194599819827507
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Crowson MG, 2020, LARYNGOSCOPE, V130, P45, DOI 10.1002/lary.27850
   DUVAL F, 2017, NEURAL NETWORKS ARTI
   Eluyode O.S., 2013, EURO J APPL ENG SCI, V2, P36
   Haddad WM, 2007, IEEE T NEURAL NETWOR, V18, P1049, DOI 10.1109/TNN.2007.899164
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   KALE SD, 2016, INT J INNOV RES COMP, V4, P17169
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lau DP, 2005, LASER SURG MED, V37, P192, DOI 10.1002/lsm.20226
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Makki FM, 2013, J LARYNGOL OTOL, V127, P890, DOI 10.1017/S0022215113001825
   Margeta J, 2017, COMP M BIO BIO E-IV, V5, P339, DOI 10.1080/21681163.2015.1061448
   McCarthy J, 2006, AI MAG, V27, P12
   Nie D, 2018, IEEE T BIO-MED ENG, V65, P2720, DOI 10.1109/TBME.2018.2814538
   Norris B, 2011, LARYNGOSCOPE, V121, P2317, DOI 10.1002/lary.22192
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Renieblas GP, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.3.035501
   Rubegni P, 2002, J INVEST DERMATOL, V119, P471, DOI 10.1046/j.1523-1747.2002.01835.x
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Shaikhina T, 2017, ARTIF INTELL MED, V75, P51, DOI 10.1016/j.artmed.2016.12.003
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szeliski R, 2011, TEXTS COMPUT SCI, P1
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tjoa MP, 2002, IEEE CCEC 2002: CANADIAN CONFERENCE ON ELECTRCIAL AND COMPUTER ENGINEERING, VOLS 1-3, CONFERENCE PROCEEDINGS, P1177, DOI 10.1109/CCECE.2002.1013115
   Wang TD, 2004, CLIN GASTROENTEROL H, V2, P744, DOI 10.1016/S1542-3565(04)00345-3
   WU YZ, 1993, RADIOLOGY, V187, P81, DOI 10.1148/radiology.187.1.8451441
   Zhou ZW, 2017, PROC CVPR IEEE, P4761, DOI 10.1109/CVPR.2017.506
NR 30
TC 11
Z9 13
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-852X
EI 1531-4995
J9 LARYNGOSCOPE
JI Laryngoscope
PD FEB
PY 2022
VL 132
SU 4
SI SI
BP S1
EP S8
DI 10.1002/lary.28708
EA APR 2020
PG 8
WC Medicine, Research & Experimental; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine; Otorhinolaryngology
GA YF0GR
UT WOS:000529035300001
PM 32343434
DA 2023-08-21
ER

PT J
AU Aziz, M
   Fatima, R
   Dong, C
   Lee-Smith, W
   Nawras, A
AF Aziz, Muhammad
   Fatima, Rawish
   Dong, Charles
   Lee-Smith, Wade
   Nawras, Ali
TI The impact of deep convolutional neural network-based artificial
   intelligence on colonoscopy outcomes: A systematic review with
   meta-analysis
SO JOURNAL OF GASTROENTEROLOGY AND HEPATOLOGY
LA English
DT Review
DE artificial intelligence; colonoscopy; deep convolutional neural network;
   high-definition
ID COLORECTAL-CANCER; DETECTION RATES; RISK; QUALITY
AB Background and Aim The utility of artificial intelligence (AI) in colonoscopy has gained popularity in current times. Recent trials have evaluated the efficacy of deep convolutional neural network (DCNN)-based AI system in colonoscopy for improving adenoma detection rate (ADR) and polyp detection rate (PDR). We performed a systematic review and meta-analysis of the available studies to assess the impact of DCNN-based AI-assisted colonoscopy in improving the ADR and PDR.
   Methods We queried the following database for this study: PubMed, Embase, Cochrane Library, Web of Sciences, and Computers and Applied Sciences. We only included randomized controlled trials that compared AI colonoscopy to standard colonoscopy (SC). Our outcomes included ADR and PDR. Risk ratios (RR) with 95% confidence interval (CI) were calculated using random effects model and DerSimonian-Laird approach for each outcome.
   Results A total of three studies with 2815 patients (1415 in SC group and 1400 in AI group) were included. AI colonoscopy resulted in significantly improved ADR (32.9% vs 20.8%, RR: 1.58, 95% CI 1.39-1.80, P = < 0.001) and PDR (43.0% vs 27.8%, RR: 1.55, 95% CI 1.39-1.72, P = < 0.001) compared with SC.
   Conclusion Given the results and limitations, the utility of AI colonoscopy holds promise and should be evaluated in more randomized controlled trials across different population, especially in patients solely undergoing colonoscopy for screening purpose as improved ADR will ultimately help in reducing incident colorectal cancer.
C1 [Aziz, Muhammad; Fatima, Rawish; Dong, Charles] Univ Toledo, Dept Internal Med, Med Ctr, 3000 Arlington Ave, Toledo, OH 43614 USA.
   [Lee-Smith, Wade] Univ Toledo, Univ Toledo Lib, Med Ctr, 2801 W Bancroft St, Toledo, OH 43606 USA.
   [Nawras, Ali] Univ Toledo, Dept Gastroenterol, Med Ctr, 2801 W Bancroft St, Toledo, OH 43606 USA.
C3 University System of Ohio; University of Toledo; University System of
   Ohio; University of Toledo; University System of Ohio; University of
   Toledo
RP Aziz, M (通讯作者)，Univ Toledo, Dept Internal Med, Med Ctr, 3000 Arlington Ave, Toledo, OH 43614 USA.
EM marajani@hotmail.com
RI Lee-Smith, Wade M/D-3361-2009
OI Lee-Smith, Wade M/0000-0003-1744-8525
CR Ai XY, 2018, EUR J GASTROEN HEPAT, V30, P181, DOI 10.1097/MEG.0000000000001009
   Anderson JC, 2013, CLIN GASTROENTEROL H, V11, P1308, DOI 10.1016/j.cgh.2013.04.042
   Atkins L, 2016, GASTROINTEST ENDOSC, V83, P617, DOI 10.1016/j.gie.2015.08.075
   AZIZ M, 2019, CLIN GASTROENTEROL H
   Aziz M, 2020, ANN GASTROENTEROL, V33, P178, DOI 10.20524/aog.2020.0459
   Aziz M, 2020, MINERVA GASTROENT D, V66, P164, DOI 10.23736/S1121-421X.20.02652-5
   Aziz M, 2020, DIGEST DIS SCI, V65, P1586, DOI 10.1007/s10620-019-05997-6
   Aziz M, 2019, GASTROINTEST ENDOSC, V90, P721, DOI 10.1016/j.gie.2019.06.041
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Desai M, 2019, GASTROINTEST ENDOSC, V89, P453, DOI 10.1016/j.gie.2018.09.006
   Facciorusso A, 2019, CLIN GASTROENTEROL H, V17, P2439, DOI 10.1016/j.cgh.2018.11.058
   Froehlich F, 2005, GASTROINTEST ENDOSC, V61, P378, DOI 10.1016/S0016-5107(04)02776-2
   Fuccio L, 2018, GASTROINTEST ENDOSC, V88, P589, DOI 10.1016/j.gie.2018.06.028
   Hassan C, 2017, UNITED EUR GASTROENT, V5, P149, DOI 10.1177/2050640616667171
   Higgins Julian P T, 2011, BMJ, V343, pd5928, DOI 10.1136/bmj.d5928
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Leggett B, 2010, GASTROENTEROLOGY, V138, P2088, DOI 10.1053/j.gastro.2009.12.066
   Liu WN, 2020, SAUDI J GASTROENTERO, V26, P13, DOI 10.4103/sjg.SJG_377_19
   Puhan MA, 2014, BMJ-BRIT MED J, V349, DOI 10.1136/bmj.g5630
   REX D, 2014, US DIG DIS SCI, V60, P639
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   SEO JY, DIG DIS SCI
   Shuster JJ, 2011, RES SYNTH METHODS, V2, P126, DOI DOI 10.1002/JRSM.38
   Su JR, 2020, GASTROINTEST ENDOSC, V91, P415, DOI 10.1016/j.gie.2019.08.026
   Sulz MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154149
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
NR 29
TC 37
Z9 38
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0815-9319
EI 1440-1746
J9 J GASTROEN HEPATOL
JI J. Gastroenterol. Hepatol.
PD OCT
PY 2020
VL 35
IS 10
BP 1676
EP 1683
DI 10.1111/jgh.15070
EA APR 2020
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA NY8GL
UT WOS:000528562900001
PM 32267558
DA 2023-08-21
ER

PT J
AU Wei, JW
   Suriawinata, AA
   Vaickus, LJ
   Ren, B
   Liu, XY
   Lisovsky, M
   Tomita, N
   Abdollahi, B
   Kim, AS
   Snover, DC
   Baron, JA
   Barry, EL
   Hassanpour, S
AF Wei, Jason W.
   Suriawinata, Arief A.
   Vaickus, Louis J.
   Ren, Bing
   Liu, Xiaoying
   Lisovsky, Mikhail
   Tomita, Naofumi
   Abdollahi, Behnaz
   Kim, Adam S.
   Snover, Dale C.
   Baron, John A.
   Barry, Elizabeth L.
   Hassanpour, Saeed
TI Evaluation of a Deep Neural Network for Automated Classification of
   Colorectal Polyps on Histopathologic Slides
SO JAMA NETWORK OPEN
LA English
DT Article
ID COLONOSCOPIC POLYPECTOMY; HISTOLOGICAL DIAGNOSIS; CANCER INCIDENCE;
   PREVENTION; TRENDS; STAGE
AB Question Are deep neural networks trained on data from a single institution for classification of colorectal polyps on digitized histopathologic slides generalizable across multiple external institutions? Findings In this prognostic study of a deep neural network to classify the 4 most common polyp types on digitized histopathologic slides from a single institution (internal test set) and 24 US institutions (external test set), the mean accuracy was 93.5% on the internal test set and 87.0% on the external test set. Meaning Deep neural networks may provide a generalizable approach for the classification of colorectal polyps on digitized histopathologic slides.
   This prognostic study evaluates the performance and generalizability of a deep neural network trained on data from a single institution for classification of colorectal polyps on histopathologic slide images.
   Importance Histologic classification of colorectal polyps plays a critical role in screening for colorectal cancer and care of affected patients. An accurate and automated algorithm for the classification of colorectal polyps on digitized histopathologic slides could benefit practitioners and patients. Objective To evaluate the performance and generalizability of a deep neural network for colorectal polyp classification on histopathologic slide images using a multi-institutional data set. Design, Setting, and Participants This prognostic study used histopathologic slides collected from January 1, 2016, to June 31, 2016, from Dartmouth-Hitchcock Medical Center, Lebanon, New Hampshire, with 326 slides used for training, 157 slides for an internal data set, and 25 for a validation set. For the external data set, 238 slides for 179 distinct patients were obtained from 24 institutions across 13 US states. Data analysis was performed from April 9 to November 23, 2019. Main Outcomes and Measures Accuracy, sensitivity, and specificity of the model to classify 4 major colorectal polyp types: tubular adenoma, tubulovillous or villous adenoma, hyperplastic polyp, and sessile serrated adenoma. Performance was compared with that of local pathologists' at the point of care identified from corresponding pathology laboratories. Results For the internal evaluation on the 157 slides with ground truth labels from 5 pathologists, the deep neural network had a mean accuracy of 93.5% (95% CI, 89.6%-97.4%) compared with local pathologists' accuracy of 91.4% (95% CI, 87.0%-95.8%). On the external test set of 238 slides with ground truth labels from 5 pathologists, the deep neural network achieved an accuracy of 87.0% (95% CI, 82.7%-91.3%), which was comparable with local pathologists' accuracy of 86.6% (95% CI, 82.3%-90.9%). Conclusions and Relevance The findings suggest that this model may assist pathologists by improving the diagnostic efficiency, reproducibility, and accuracy of colorectal cancer screenings.
C1 [Wei, Jason W.; Tomita, Naofumi; Abdollahi, Behnaz; Hassanpour, Saeed] Dartmouth Coll, Dept Biomed Data Sci, One Med Ctr Dr,HB 7261, Lebanon, NH 03756 USA.
   [Wei, Jason W.; Hassanpour, Saeed] Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.
   [Suriawinata, Arief A.; Vaickus, Louis J.; Ren, Bing; Liu, Xiaoying; Lisovsky, Mikhail] Dartmouth Hitchcock Med Ctr, Dept Pathol & Lab Med, Lebanon, NH 03766 USA.
   [Kim, Adam S.] Minnesota Gastroenterol PA, Minneapolis, MN USA.
   [Snover, Dale C.] Fairview Southdale Hosp, Dept Pathol, Edina, MN USA.
   [Baron, John A.] Univ N Carolina, Dept Med, Chapel Hill, NC 27515 USA.
   [Barry, Elizabeth L.; Hassanpour, Saeed] Dartmouth Coll, Dept Epidemiol, Hanover, NH 03755 USA.
C3 Dartmouth College; Dartmouth College; Dartmouth College; University of
   North Carolina; University of North Carolina Chapel Hill; Dartmouth
   College
RP Hassanpour, S (通讯作者)，Dartmouth Coll, Dept Biomed Data Sci, One Med Ctr Dr,HB 7261, Lebanon, NH 03756 USA.
EM Saeed.Hassanpour@dartmouth.edu
RI Suriawinata, Arief/ABA-7718-2020; Suriawinata, Arief/ITV-4699-2023
FU NIH [R01CA098286, R01LM012837, P20GM104416]; Geisel School of Medicine
   at Dartmouth; Norris Cotton Cancer Center
FX This work was supported by grants R01CA098286 (Dr Baron), R01LM012837
   (Dr Hassanpour), and P20GM104416 (Dr Hassanpour) from the NIH, the
   Geisel School of Medicine at Dartmouth, and the Norris Cotton Cancer
   Center.
CR Baron JA, 2015, NEW ENGL J MED, V373, P1519, DOI 10.1056/NEJMoa1500409
   Bosman FT., 2010, WHO CLASSIFICATION T
   Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1136/bmj.h5527, 10.1373/clinchem.2015.246280, 10.1148/radiol.2015151516]
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3
   Citarda F, 2001, GUT, V48, P812, DOI 10.1136/gut.48.6.812
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Cress RD, 2006, CANCER, V107, P1142, DOI 10.1002/cncr.22011
   Diamant A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39206-1
   Edwards BK, 2010, CANCER-AM CANCER SOC, V116, P544, DOI 10.1002/cncr.24760
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   He K., 2015, P C COMP VIS PATT RE
   He K, 2015, MBIO, V6, DOI 10.1128/mBio.00546-15
   Irvin J, 2019, P ASS ADV ART INT C
   Jean S, 2014, P ASS COMP LING INT
   Jemal A, 2009, CA-CANCER J CLIN, V59, P225, DOI 10.3322/caac.20006
   Kawamura R, RECTLABEL
   Kim DW, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-019-43372-7, 10.1038/s41598-018-36760-y]
   Korbar Bruno, 2017, J Pathol Inform, V8, P30, DOI 10.4103/jpi.jpi_34_17
   Korbar B, 2017, IEEE COMPUT SOC CONF, P821, DOI 10.1109/CVPRW.2017.114
   Kronborg O, 1996, LANCET, V348, P1467, DOI 10.1016/S0140-6736(96)03430-7
   Li XC, 2019, LANCET ONCOL, V20, P193, DOI 10.1016/S1470-2045(18)30762-9
   Mikolov T., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P196, DOI 10.1109/ASRU.2011.6163930
   Osmond A, 2014, J CLIN PATHOL, V67, P781, DOI 10.1136/jclinpath-2014-202177
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Siegel RL, 2012, CANCER EPIDEM BIOMAR, V21, P411, DOI 10.1158/1055-9965.EPI-11-1020
   Terry MB, 2002, CANCER EPIDEM BIOMAR, V11, P660
   van Putten PG, 2011, HISTOPATHOLOGY, V58, P974, DOI 10.1111/j.1365-2559.2011.03822.x
   Wei JW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40041-7
   Wilson ML, 2018, LANCET, V391, P1927, DOI [10.1016/S0140-6736(18)30458-6, 10.1016/S0140-6736]
   World Med Assoc, 2013, JAMA-J AM MED ASSOC, V310, P2191, DOI 10.1001/jama.2013.281053
   Yoon H, 2002, GASTROEN CLIN BIOL, V26, P220
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 35
TC 36
Z9 37
U1 1
U2 7
PU AMER MEDICAL ASSOC
PI CHICAGO
PA 330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA
SN 2574-3805
J9 JAMA NETW OPEN
JI JAMA Netw. Open
PD APR 23
PY 2020
VL 3
IS 4
AR e203398
DI 10.1001/jamanetworkopen.2020.3398
PG 11
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA LJ2DP
UT WOS:000529980900001
PM 32324237
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Zhou, GY
   Xiao, X
   Tu, MT
   Liu, PX
   Yang, D
   Liu, XG
   Zhang, RY
   Li, LP
   Lei, S
   Wang, H
   Song, Y
   Wang, P
AF Zhou, Guanyu
   Xiao, Xun
   Tu, Mengtian
   Liu, Peixi
   Yang, Dan
   Liu, Xiaogang
   Zhang, Renyi
   Li, Liangping
   Lei, Shan
   Wang, Han
   Song, Yan
   Wang, Pu
TI Computer aided detection for laterally spreading tumors and sessile
   serrated adenomas during colonoscopy
SO PLOS ONE
LA English
DT Article
ID ENDOSCOPIC MUCOSAL RESECTION; COLORECTAL-CANCER; INATTENTIONAL
   BLINDNESS; PROSPECTIVE MULTICENTER; POLYPS; RISK; VALIDATION; DIAGNOSIS;
   SYSTEM; RATES
AB Background
   Evidence has shown that deep learning computer aided detection (CADe) system achieved high overall detection accuracy for polyp detection during colonoscopy.
   Aim
   The detection performance of CADe system on non-polypoid laterally spreading tumors (LSTs) and sessile serrated adenomas/polyps (SSA/Ps), with higher risk for malignancy transformation and miss rate, has not been exclusively investigated.
   Methods
   A previously validated deep learning CADe system for polyp detection was tested exclusively on LSTs and SSA/Ps. 1451 LST images from 184 patients were collected between July 2015 and January 2019, 82 SSA/Ps videos from 26 patients were collected between September 2018 and January 2019. The per-frame sensitivity and per-lesion sensitivity were calculated.
   Results
   (1) For LSTs image dataset, the system achieved an overall per-image sensitivity and per-lesion sensitivity of 94.07% (1365/1451) and 98.99% (197/199) respectively. The perframe sensitivity for LST-G(H), LST-G(M), LST-NG(F), LST-NG(PD) was 93.97% (343/365), 98.72% (692/701), 85.71% (324/378) and 85.71% (6/7) respectively. The per-lesion sensitivity of each subgroup was 100.00% (71/71), 100.00% (64/64), 98.31% (58/59) and 80.00% (4/5). (2) For SSA/Ps video dataset, the system achieved an overall per-frame sensitivity and per-lesion sensitivity of 84.10% (15883/18885) and 100.00% (42/42), respectively.
   Conclusions
   This study demonstrated that a local-feature-prioritized automatic CADe system could detect LSTs and SSA/Ps with high sensitivity. The per-frame sensitivity for non-granular LSTs and small SSA/Ps should be further improved.
C1 [Zhou, Guanyu; Xiao, Xun; Tu, Mengtian; Liu, Peixi; Liu, Xiaogang; Zhang, Renyi; Li, Liangping; Lei, Shan; Wang, Han; Song, Yan; Wang, Pu] Sichuan Acad Med Sci, Dept Gastroenterol, Chengdu, Sichuan, Peoples R China.
   [Zhou, Guanyu; Xiao, Xun; Tu, Mengtian; Liu, Peixi; Liu, Xiaogang; Zhang, Renyi; Li, Liangping; Lei, Shan; Wang, Han; Song, Yan; Wang, Pu] Sichuan Prov Peoples Hosp, Chengdu, Sichuan, Peoples R China.
   [Yang, Dan] Southwest Med Univ, Affiliated Hosp, Dept Gastroenterol, Luzhou, Sichuan, Peoples R China.
C3 Sichuan Provincial People's Hospital; Sichuan Provincial People's
   Hospital; Southwest Medical University
RP Wang, P (通讯作者)，Sichuan Acad Med Sci, Dept Gastroenterol, Chengdu, Sichuan, Peoples R China.; Wang, P (通讯作者)，Sichuan Prov Peoples Hosp, Chengdu, Sichuan, Peoples R China.
EM wangpuhuaxi@qq.com
RI Zhang, Renyi/K-6900-2015; Tu, Mengtian/AAU-6816-2020
OI Zhang, Renyi/0000-0002-3647-1416; Wang, Pu/0000-0002-1234-309X; Yang,
   Dan/0000-0002-7347-7729
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   [Anonymous], [No title captured]
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Bandos AI, 2009, BIOMETRICS, V65, P247, DOI 10.1111/j.1541-0420.2008.01049.x
   Burgess NG, 2016, GUT, V65, P437, DOI 10.1136/gutjnl-2014-308603
   Burke Carol, 2017, Gastroenterol Hepatol (N Y), V13, P1
   Cenaj O, 2018, MODERN PATHOL, V31, P633, DOI 10.1038/modpathol.2017.169
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Erichsen R, 2016, GASTROENTEROLOGY, V150, P895, DOI 10.1053/j.gastro.2015.11.046
   Fan Claire, 2018, Curr Treat Options Gastroenterol, V16, P182, DOI 10.1007/s11938-018-0176-0
   Fang JY, 2014, GASTROINTEST TUMORS, V1, P53, DOI 10.1159/000362585
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Hetzel JT, 2010, AM J GASTROENTEROL, V105, P2656, DOI 10.1038/ajg.2010.315
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hurlstone DP, 2004, GUT, V53, P1334, DOI 10.1136/gut.2003.036913
   Kahi CJ, 2019, CLIN ENDOSC, V52, P235, DOI 10.5946/ce.2018.112
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   KUDO S, 1993, ENDOSCOPY, V25, P455, DOI 10.1055/s-2007-1010367
   Lami M, 2018, ENDOSCOPY, V50, P701, DOI 10.1055/s-0044-101026
   Limketkai BN, 2013, GASTROINTEST ENDOSC, V77, P360, DOI 10.1016/j.gie.2012.11.013
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Memmert D, 2010, J GEN PSYCHOL, V137, P129, DOI 10.1080/00221301003645061
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rogart JN, 2008, AM J GASTROENTEROL, V103, P2841, DOI 10.1111/j.1572-0241.2008.02085.x
   Rotondano G, 2011, ENDOSCOPY, V43, P856, DOI 10.1055/s-0030-1256639
   Sano Y, 2016, DIGEST ENDOSC, V85, P822
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Szylberg L, 2015, GASTROENT RES PRACT, V2015, DOI 10.1155/2015/573814
   Tziatzios G, 2019, DIGEST LIVER DIS, V51, P1079, DOI 10.1016/j.dld.2019.05.012
   Uraoka T, 2006, GUT, V55, P1592, DOI 10.1136/gut.2005.087452
   Uraoka T, 2015, J GASTROENTEROL, V50, P555, DOI 10.1007/s00535-014-0999-y
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wolfe JM, 2006, VIS COGN, V14, P749, DOI 10.1080/13506280500195292
   Zhao XH, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094552
NR 37
TC 17
Z9 18
U1 0
U2 9
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD APR 21
PY 2020
VL 15
IS 4
AR e0231880
DI 10.1371/journal.pone.0231880
PG 11
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA LR9OP
UT WOS:000536024800062
PM 32315365
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Hoogenboom, SA
   Bagci, U
   Wallace, MB
AF Hoogenboom, Sanne A.
   Bagci, Ulas
   Wallace, Michael B.
TI Artificial intelligence in gastroenterology. The current state of play
   and the potential. How will it affect our practice and when?
SO TECHNIQUES AND INNOVATIONS IN GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
DE Artificial intelligence; Computer-aided detection; Computer-aided
   diagnosis; Deep learning; Endoscopy; Gastroenterology
ID HELICOBACTER-PYLORI INFECTION; CONVOLUTIONAL NEURAL-NETWORKS; COLORECTAL
   POLYP HISTOLOGY; COMPUTER-AIDED DIAGNOSIS; GASTRIC-CANCER; CAPSULE
   ENDOSCOPY; DIFFERENTIAL-DIAGNOSIS; QUANTITATIVE-ANALYSIS; COLON POLYPS;
   MISS RATE
AB Background: Artificial intelligence (AI) is exponentially gaining interest and utilization in medical fields. Deep learning, a particular branch of AI under machine learning, started a revolution in AI by learning to recognize complex features itself, without dependence on a priori human-generated rules of classification. In recent years, several applications of AI are emerging in gastrointestinal endoscopy. Computer-aided detection and diagnosis might be the solution for the operator dependency in endoscopy. In this review, we aim to provide an introduction for gastroenterologists to the complex terminology that is linked to AI, the current state of play in AI-assisted endoscopy, and its future directions. Methods: We performed a literature search on MED-LINE and PUBMED through May 2019 for relevant articles using keywords as AI, deep learning, computer-aided detection and diagnosis, and gastrointestinal endoscopy. Results: AI-applications in endoscopy described in the literature included colorectal polyp detection and classification, assessment of cancer inva-siveness, video capsule endoscopy, detection of esophageal and gastric cancer, and Helicobacter pylori gastritis. Conclusion: AI-assisted endoscopy is a strongly evolving field and recent innovations and research on this sub-ject are promising. Initial important steps along the AI-road have been taken by initiating the first prospective studies on AI-assisted endoscopy to minimize the risk of selection bias and overfitting of the AI-models. Future research will investigate if AI-assisted endoscopy will refine our current endoscopic abilities. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Hoogenboom, Sanne A.; Wallace, Michael B.] Mayo Clin, Div Gastroenterol & Hepatol, Jacksonville, FL 32224 USA.
   [Bagci, Ulas; Wallace, Michael B.] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA.
C3 Mayo Clinic; State University System of Florida; University of Central
   Florida
RP Wallace, MB (通讯作者)，Mayo Clin, Div Gastroenterol & Hepatol, Jacksonville, FL 32224 USA.; Wallace, MB (通讯作者)，Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA.
EM wallace.michael@mayo.edu
RI Wallace, Michael/GZL-9731-2022; Bagci, Ulas/A-4225-2012
OI Wallace, Michael/0000-0002-6446-5785; Bagci, Ulas/0000-0001-7379-6829
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Akasu T, 2000, WORLD J SURG, V24, P1061, DOI 10.1007/s002680010151
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Apel D, 2006, GASTROINTEST ENDOSC, V63, P824, DOI 10.1016/j.gie.2005.09.013
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Burt JR, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20170545
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Groof J, 2019, UNITED EUR GASTROENT, V7, P538, DOI 10.1177/2050640619837443
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399
   Fu KI, 2004, ENDOSCOPY, V36, P1089, DOI 10.1055/s-2004-826039
   Goodwin CS, 1997, CLIN INFECT DIS, V25, P1017, DOI 10.1086/516077
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Imperiale TF, 2008, NEW ENGL J MED, V359, P1218, DOI 10.1056/NEJMoa0803597
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Karkanis GDM SA, 1999, ADV COURS ART INT AC, pChania59
   Katai H, 2018, GASTRIC CANCER, V21, P144, DOI 10.1007/s10120-017-0716-7
   Kobayashi K., 2003, DIGEST ENDOSC, V15, P298, DOI [DOI 10.1046/J.1443-1661.2003.T01-3-00262.X, 10.1046/j.1443-1661.2003.t01-3-00262.x]
   Kodashima S, 2007, DIGEST LIVER DIS, V39, P762, DOI 10.1016/j.dld.2007.03.004
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee JH, 2019, SURG ENDOSC, V33, P3790, DOI 10.1007/s00464-019-06677-2
   Lee JH, 2019, SURG ENDOSC
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Malagelada C, 2015, AM J PHYSIOL-GASTR L, V309, pG413, DOI 10.1152/ajpgi.00193.2015
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Miyaki R, 2015, J CLIN GASTROENTEROL, V49, P108, DOI 10.1097/MCG.0000000000000104
   Miyaki R, 2013, J GASTROEN HEPATOL, V28, P841, DOI 10.1111/jgh.12149
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2018, DIGEST ENDOSC, V30, P52, DOI 10.1111/den.13005
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Mukae M, 2015, GASTROINTEST ENDOSC, V81, P682, DOI 10.1016/j.gie.2014.10.027
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Norvig P, 2009, ARTIF INTELL, V3rd
   NVIDIA, 2016, WHATS DIFF ART INT M
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Philbrick KA, 2018, AM J ROENTGENOL, V211, P1184, DOI 10.2214/AJR.18.20331
   Qi X, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2337314
   Quang T, 2016, GASTROINTEST ENDOSC, V84, P834, DOI 10.1016/j.gie.2016.03.1472
   Renner J, 2018, SCAND J GASTROENTERO, V53, P1100, DOI 10.1080/00365521.2018.1501092
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Saurin JC, 2012, DIGEST LIVER DIS, V44, P477, DOI 10.1016/j.dld.2011.12.021
   Scholvinck DW, 2017, ENDOSCOPY, V49, P113, DOI 10.1055/s-0042-118312
   Shichijo S, 2019, SCAND J GASTROENTERO, V54, P158, DOI 10.1080/00365521.2019.1577486
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin D, 2015, CLIN GASTROENTEROL H, V13, P272, DOI 10.1016/j.cgh.2014.07.030
   Snover DC, 2011, HUM PATHOL, V42, P1, DOI 10.1016/j.humpath.2010.06.002
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Su MY, 2006, AM J GASTROENTEROL, V101, P2711, DOI 10.1111/j.1572-0241.2006.00932.x
   Swager AF, 2017, GASTROINTEST ENDOSC, V86, P839, DOI 10.1016/j.gie.2017.03.011
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Voutilainen ME, 2005, EUR J GASTROEN HEPAT, V17, P1345, DOI 10.1097/00042737-200512000-00013
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yung DE, 2017, EXPERT REV GASTROENT, V11, P43, DOI 10.1080/17474124.2017.1257384
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 86
TC 14
Z9 14
U1 0
U2 0
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 2666-5107
EI 2590-0307
J9 TECH INNOVAT GASTROI
JI Tech. Innovation Gastrointes. Endoscopy
PD APR
PY 2020
VL 22
IS 2
SI SI
BP 42
EP 47
DI 10.1016/j.tgie.2019.150634
PG 6
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA VK9TP
UT WOS:000771335700002
DA 2023-08-21
ER

PT J
AU Mori, Y
   Kudo, S
   Misawa, M
   Takeda, K
   Kudo, T
   Itoh, H
   Oda, M
   Mori, K
AF Mori, Yuichi
   Kudo, Shin-ei
   Misawa, Masashi
   Takeda, Kenichi
   Kudo, Toyoki
   Itoh, Hayato
   Oda, Masahiro
   Mori, Kensaku
TI How Far Will Clinical Application of AI Applications Advance for
   Colorectal Cancer Diagnosis?
SO JOURNAL OF THE ANUS RECTUM AND COLON
LA English
DT Review
DE machine learning; colonoscopy; computer-aided diagnosis; colorectal
   cancer
ID LESIONS; SYSTEM; PREVENTION; ACCURACY
AB Integrating artificial intelligence (AI) applications into colonoscopy practice is being accelerated as deep learning technologies emerge. In this field, most of the preceding research has focused on polyp detection and characterization, which can mitigate inherent human errors accompanying colonoscopy procedures. On the other hand, more challenging research areas are currently capturing attention: the automated prediction of invasive cancers. Colorectal cancers (CRCs) harbor potential lymph node metastasis when they invade deeply into submucosal layers, which should be resected surgically rather than endoscopically. However, pretreatment discrimination of deeply invasive submucosal CRCs is considered difficult, according to previous prospective studies (e.g., <70% sensitivity), leading to an increased number of unnecessary surgeries for large adenomas or slightly invasive submucosal CRCs. AI is now expected to overcome this challenging hurdle because it is considered to provide better performance in predicting invasive cancer than non-expert endoscopists. In this review, we introduce five relevant publications in this area. Unfortunately, progress in this research area is in a very preliminary phase, compared to that of automated polyp detection and characterization, because of the lack of number of invasive CRCs used for machine learning. However, this issue will be overcome with more target images and cases. The research field of AI for invasive CRCs is just starting but could be a game changer of patient care in the near future, given rapidly growing technologies, and research will gradually increase.
C1 [Mori, Yuichi; Kudo, Shin-ei; Misawa, Masashi; Takeda, Kenichi; Kudo, Toyoki] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
C3 Showa University; Nagoya University
RP Mori, Y (通讯作者)，Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
EM ibusiginjp@gmail.com
RI Misawa, Masashi/H-9004-2019; Mori, Yuichi/AAU-5406-2020; Itoh,
   Hayato/AAM-4022-2021
OI Misawa, Masashi/0000-0002-8520-2036; Itoh, Hayato/0000-0002-1410-1078
CR Backes Y, 2017, AM J GASTROENTEROL, V112, P54, DOI 10.1038/ajg.2016.403
   Backes Y, 2019, GUT, V68, P271, DOI 10.1136/gutjnl-2017-314723
   Hassan C., 2019, GUT
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Kudo SE, 2019, CLIN GASTROENTEROL H
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Miyachi H, 2016, J GASTROEN HEPATOL, V31, P1126, DOI 10.1111/jgh.13257
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Sano Y, 2009, GASTROINTEST ENDOSC, V69, P278, DOI 10.1016/j.gie.2008.04.066
   Shimura T, 2014, CLIN GASTROENTEROL H, V12, P662, DOI 10.1016/j.cgh.2013.06.022
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 19
TC 2
Z9 2
U1 0
U2 1
PU JAPAN SOC COLOPROCTOLOGY
PI TOKYO
PA C/O KYORINSHA CO, LTD, 3-46-10 NISHIGAHARA, KITA-KU, TOKYO, 1140024,
   JAPAN
SN 2432-3853
J9 J ANUS RECTUM COLON
JI J. Anus Rectum Colon
PD APR
PY 2020
VL 4
IS 2
BP 47
EP 50
DI 10.23922/jarc.2019-045
PG 4
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA LI3EO
UT WOS:000529366800001
PM 32346642
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Rex, DK
AF Rex, Douglas K.
TI Can we do resect and discard with artificial intelligence-assisted colon
   polyp "optical biopsy?"
SO TECHNIQUES AND INNOVATIONS IN GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
DE Colonoscopy; Artificial intelligence; Colorectal polyp; Adenoma;
   Hyperplastic polyp
ID VALUABLE ENDOSCOPIC INNOVATIONS; COMPUTER-AIDED DIAGNOSIS; SMALL
   COLORECTAL POLYPS; ADENOMA DETECTION RATE; REAL-TIME; SYSTEM;
   CLASSIFICATION; COLONOSCOPY; SURVEILLANCE; LESIONS
AB Resect and discard refers to a paradigm for the management of colorectal adenomas 1-5 mm in size. In this paradigm, histology of colorectal polyps is predicted endoscopically based on surface features. Lesions that are <5 mm in size and predicted to be adenomas are resected endoscopically and discarded rather than submitted to pathology. Adenomas in this size range have an extremely low risk of cancer, and the cost savings of the resect and discard paradigm would be substantial. Artificial intelligence programs can improve the overall prediction for histology based on endoscopic imaging, and reduce operator dependence in endoscopic predictions. Although meta-analyses have concluded that the accuracy of endoscopic prediction is sufficiently high to institute the resect and discard paradigm in clinical practice, actual implementation has faced several obstacles. These include lack of financial incentives for endoscopists, perceived increased medical-legal risk compared with the current management paradigm of submitting all polyps to pathology, and local rules for tissue handling. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Rex, Douglas K.] Indiana Univ Sch Med, Div Gastroenterol Hepatol, 550 N Univ Blvd,Suite 4100, Indianapolis, IN 46202 USA.
C3 Indiana University System; Indiana University Bloomington
RP Rex, DK (通讯作者)，Indiana Univ Sch Med, Div Gastroenterol Hepatol, 550 N Univ Blvd,Suite 4100, Indianapolis, IN 46202 USA.
EM drex@iu.edu
CR Barge W, 2018, GASTROINTEST ENDOSC, V88, P536, DOI 10.1016/j.gie.2018.05.015
   Bisschops R, 2018, ENDOSCOPY, V50, P211, DOI 10.1055/s-0043-121570
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   IJspeert JEG, 2016, GUT, V65, P963, DOI 10.1136/gutjnl-2014-308411
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   McGill SK, 2013, GUT, V62, P1704, DOI 10.1136/gutjnl-2012-303965
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Murphy CC, 2016, CLIN GASTROENTEROL H, V14, P436, DOI 10.1016/j.cgh.2015.10.008
   Ponugoti P, 2019, ENDOSCOPY, V51, P221, DOI 10.1055/a-0831-2348
   Ponugoti P, 2017, GASTROINTEST ENDOSC, V85, P622, DOI 10.1016/j.gie.2016.10.022
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2015, ENDOSCOPY, V47, P245, DOI 10.1055/s-0034-1391330
   Rex DK, 2011, ANN INTERN MED, V154, P622, DOI 10.7326/0003-4819-154-9-201105030-00007
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V137, P1229, DOI 10.1053/j.gastro.2009.06.042
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Schoen RE, 2010, GASTROENTEROLOGY, V138, P73, DOI 10.1053/j.gastro.2009.09.062
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Thosani N, 2016, GASTROINTEST ENDOSC, V83, P684, DOI 10.1016/j.gie.2016.01.007
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Vemulapalli KC, 2014, GASTROINTEST ENDOSC, V80, P299, DOI 10.1016/j.gie.2014.02.1029
   Vleugels JLA, 2018, GASTROENTEROLOGY, V154, P1682, DOI 10.1053/j.gastro.2018.01.063
NR 38
TC 6
Z9 6
U1 0
U2 0
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 2666-5107
EI 2590-0307
J9 TECH INNOVAT GASTROI
JI Tech. Innovation Gastrointes. Endoscopy
PD APR
PY 2020
VL 22
IS 2
SI SI
BP 52
EP 55
DI 10.1016/j.tgie.2019.150638
PG 4
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA VK9TP
UT WOS:000771335700004
OA Green Submitted, Bronze
DA 2023-08-21
ER

PT J
AU Shahidi, N
   Bourke, MJ
AF Shahidi, Neal
   Bourke, Michael J.
TI Can artificial intelligence accurately diagnose endoscopically curable
   gastrointestinal cancers?
SO TECHNIQUES AND INNOVATIONS IN GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
DE Adenoma; Endoscopy; Colonoscopy; Polyp
ID SQUAMOUS-CELL CARCINOMA; LYMPH-NODE METASTASIS; SUBMUCOSAL DISSECTION;
   MUCOSAL RESECTION; SUPERFICIAL ADENOCARCINOMA; COLORECTAL NEOPLASIA;
   CLINICAL-OUTCOMES; ESOPHAGEAL CANCER; RISK-FACTORS; PREDICTION
AB Endoscopic tissue resection is a rapidly evolving field. En bloc resection techniques, specifically endoscopic submucosal dissection, allow for organ-sparing curative endoscopic resection for early gastrointestinal cancers. However, using current techniques to quantify depth of invasion, it remains difficult for endoscopists to reliably select optimal endoscopic submucosal dissection candidates. In this review, we highlight that artificial intelligence platforms can now quantify the depth of invasion of esophageal, gastric, and colorectal neoplasia. While real-time performance evaluation is needed, this represents a significant advancement in endoscopic tissue resection and carries the potential to provide real-time guidance for selecting the appropriate tissue resection technique. 0 2019 Elsevier Inc. All rights reserved.
C1 [Shahidi, Neal; Bourke, Michael J.] Westmead Hosp, Dept Gastroenterol & Hepatol, Suite 106a 151-155 Hawkesbury Rd, Sydney, NSW 2145, Australia.
   [Shahidi, Neal; Bourke, Michael J.] Univ Sydney, Westmead Clin Sch, Sydney, NSW, Australia.
   [Shahidi, Neal] Univ British Columbia, Dept Med, Vancouver, BC, Canada.
C3 University of Sydney; University of Sydney; University of British
   Columbia
RP Bourke, MJ (通讯作者)，Westmead Hosp, Dept Gastroenterol & Hepatol, Suite 106a 151-155 Hawkesbury Rd, Sydney, NSW 2145, Australia.; Bourke, MJ (通讯作者)，Univ Sydney, Westmead Clin Sch, Sydney, NSW, Australia.
EM michael@citywestgastro.com.au
FU University of British Columbia Clinician Investigator Program
FX Neal Shahidi is supported by the University of British Columbia
   Clinician Investigator Program.
CR Ahlenstiel G, 2014, GASTROINTEST ENDOSC, V80, P668, DOI 10.1016/j.gie.2014.04.015
   Bahin FF, 2018, GUT, V67, P1965, DOI 10.1136/gutjnl-2017-313823
   Bhatt A, 2015, AM J GASTROENTEROL, V110, P784, DOI 10.1038/ajg.2014.425
   Boerwinkel DF, 2014, GASTROENTEROLOGY, V146, P622, DOI 10.1053/j.gastro.2014.01.007
   Bollschweiler E, 2006, ENDOSCOPY, V38, P149, DOI 10.1055/s-2006-924993
   Bourke MJ, 2018, GASTROENTEROLOGY, V154, P1887, DOI 10.1053/j.gastro.2018.01.068
   Burgess NG, 2017, GASTROENTEROLOGY, V153, P732, DOI 10.1053/j.gastro.2017.05.047
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Choi J, 2010, ENDOSCOPY, V42, P705, DOI 10.1055/s-0030-1255617
   Fuccio L, 2017, GASTROINTEST ENDOSC, V86, P74, DOI 10.1016/j.gie.2017.02.024
   Gotoda Takuji, 2000, Gastric Cancer, V3, P219, DOI 10.1007/PL00011720
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Hirasawa K, 2010, GASTROINTEST ENDOSC, V72, P960, DOI 10.1016/j.gie.2010.07.030
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Jayanna M, 2016, CLIN GASTROENTEROL H, V14, P271, DOI 10.1016/j.cgh.2015.08.037
   Klein A, 2017, GASTROENTEROLOGY, V152, P466, DOI 10.1053/j.gastro.2016.12.029
   Kubota K, 2012, SURG ENDOSC, V26, P1485, DOI 10.1007/s00464-011-2036-z
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Larghi A, 2005, GASTROINTEST ENDOSC, V62, P16, DOI 10.1016/S0016-5107(05)00319-6
   Lee IS, 2013, ANN SURG ONCOL, V20, P4231, DOI 10.1245/s10434-013-3196-y
   Li Z, 2019, J AM COLL SURGEONS, V228, P627, DOI 10.1016/j.jamcollsurg.2018.12.014
   Libanio D, 2016, GASTROINTEST ENDOSC, V84, P572, DOI 10.1016/j.gie.2016.06.033
   Ma MX, 2017, GASTROINTEST ENDOSC, V85, pAB212, DOI 10.1016/j.gie.2017.03.473
   Manner H, 2008, AM J GASTROENTEROL, V103, P2589, DOI 10.1111/j.1572-0241.2008.02083.x
   Martin AN, 2016, J GASTROINTEST SURG, V20, P1554, DOI 10.1007/s11605-016-3195-y
   May A, 2004, GUT, V53, P634, DOI 10.1136/gut.2003.029421
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Moriya H, 2011, WORLD J SURG, V35, P2031, DOI 10.1007/s00268-011-1143-2
   Moss A, 2015, GUT, V64, P57, DOI 10.1136/gutjnl-2013-305516
   Mou S, 2013, SURG ENDOSC, V27, P2692, DOI 10.1007/s00464-013-2835-5
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Ono H, 2016, DIGEST ENDOSC, V28, P3, DOI 10.1111/den.12518
   Oyama T, 2017, ESOPHAGUS-TOKYO, V14, P105, DOI 10.1007/s10388-016-0527-7
   Park CH, 2015, DIGEST LIVER DIS, V47, P37, DOI 10.1016/j.dld.2014.10.011
   Pimentel-Nunes P, 2015, ENDOSCOPY, V47, P829, DOI 10.1055/s-0034-1392882
   Raymond DP, 2016, ANN THORAC SURG, V102, P207, DOI 10.1016/j.athoracsur.2016.04.055
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P253, DOI 10.1016/j.gie.2017.03.1546
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Sato H, 2015, ENDOSCOPY, V47, P122, DOI 10.1055/s-0034-1390858
   Savides T, 2000, Gastrointest Endosc, V51, P635
   Sgourakis G, 2013, WORLD J GASTROENTERO, V19, P1424, DOI 10.3748/wjg.v19.i9.1424
   Swan MP, 2009, GASTROINTEST ENDOSC, V70, P1128, DOI 10.1016/j.gie.2009.05.039
   Tajima Y, 2000, CANCER, V89, P248, DOI 10.1002/1097-0142(20000715)89:2<248::AID-CNCR7>3.0.CO;2-Q
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Tanaka S, 2015, DIGEST ENDOSC, V27, P417, DOI 10.1111/den.12456
   Terheggen G, 2017, GUT, V66, P783, DOI 10.1136/gutjnl-2015-310126
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Yoshinaga S, 2008, GASTROINTEST ENDOSC, V67, P202, DOI 10.1016/j.gie.2007.09.054
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 51
TC 2
Z9 2
U1 0
U2 1
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 2666-5107
EI 2590-0307
J9 TECH INNOVAT GASTROI
JI Tech. Innovation Gastrointes. Endoscopy
PD APR
PY 2020
VL 22
IS 2
SI SI
BP 61
EP 65
DI 10.1016/j.tgie.2019.150639
PG 5
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA VK9TP
UT WOS:000771335700006
DA 2023-08-21
ER

PT J
AU Wang, P
   Liu, XG
   Berzin, TM
   Brown, JRG
   Liu, PX
   Zhou, C
   Lei, L
   Li, LP
   Guo, ZZ
   Lei, S
   Xiong, F
   Wang, H
   Song, Y
   Pan, Y
   Zhou, GY
AF Wang, Pu
   Liu, Xiaogang
   Berzin, Tyler M.
   Brown, Jeremy R. Glissen
   Liu, Peixi
   Zhou, Chao
   Lei, Lei
   Li, Liangping
   Guo, Zhenzhen
   Lei, Shan
   Xiong, Fei
   Wang, Han
   Song, Yan
   Pan, Yan
   Zhou, Guanyu
TI Effect of a deep-learning computer-aided detection system on adenoma
   detection during colonoscopy (CADe-DB trial): a double-blind randomised
   study
SO LANCET GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Article
ID COLORECTAL-CANCER; SCREENING COLONOSCOPY; POLYP DETECTION; WIDE-ANGLE;
   TASK-FORCE; RISK; PREVENTION; QUALITY; IMPACT; PARTICIPATION
AB Background Colonoscopy with computer-aided detection (CADe) has been shown in non-blinded trials to improve detection of colon polyps and adenomas by providing visual alarms during the procedure. We aimed to assess the effectiveness of a CADe system that avoids potential operational bias.
   Methods We did a double-blind randomised trial at the endoscopy centre in Caotang branch hospital of Sichuan Provincial People's Hospital in China. We enrolled consecutive patients (aged 18-75 years) presenting for diagnostic and screening colonoscopy. We excluded patients with a history of inflammatory bowel disease, colorectal cancer, or colorectal surgery or who had a contraindication for biopsy; we also excluded patients who had previously had an unsuccessful colonoscopy and who had a high suspicion for polyposis syndromes, inflammatory bowel disease, and colorectal cancer. We allocated patients (1:1) to colonoscopy with either the CADe system or a sham system. Randomisation was by computer-generated random number allocation. Patients and the endoscopist were unaware of the random assignment. To achieve masking, the output of the system was shown on a second monitor that was only visible to an observer who was responsible for reporting the alerts. The primary outcome was the adenoma detection rate (ADR), which is the proportion of individuals having a complete colonoscopy, from caecum to rectum, who had one or more adenomas detected. The primary analysis was per protocol. We also analysed characteristics of polyps and adenomas missed initially by endoscopists but detected by the CADe system. This trial is complete and is registered with https://hfbic2d2f5c8bb0f04f43h0qkw69uxxc656nn5fiac.eds.tju.edu.cn , ChiCTR1800017675.
   Findings Between Sept 3, 2018, and Jan 11, 2019, 1046 patients were enrolled to the study, of whom 36 were excluded before randomisation, 508 were allocated colonoscopy with polyp detection using the CADe system, and 502 were allocated colonoscopy with the sham system. After further excluding patients who met exclusion criteria, 484 patients in the CADe group and 478 in the sham group were induded in analyses. The ADR was significantly greater in the CADe group than in the sham group, with 165 (34%) of 484 patients allocated to the CADe system having one or more adenomas detected versus 132 (28%) of 478 allocated to the sham system (odds ratio 1.36, 95% CI 1. 03-1. 79; p=0.030). No complications were reported among all colonoscopy procedures. Polyps initially missed by the endoscopist but identified by the CADe system were generally small in size, isochromatic, flat in shape, had an unclear boundary, were partly behind colon folds, and were on the edge of the visual field.
   Interpretation Polyps initially missed by the endoscopist had characteristics that are sometimes difficult for skilled endoscopists to recognise. Such polyps could be detected using a high-performance CADe system during colonoscopy. The effect of CADe during colonoscopy on the incidence of interval colorectal cancer should be investigated. Copyright (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Wang, Pu; Liu, Xiaogang; Liu, Peixi; Zhou, Chao; Lei, Lei; Li, Liangping; Guo, Zhenzhen; Lei, Shan; Xiong, Fei; Wang, Han; Song, Yan; Pan, Yan; Zhou, Guanyu] Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Peoples R China.
   [Berzin, Tyler M.; Brown, Jeremy R. Glissen] Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Boston, MA 02215 USA.
   [Berzin, Tyler M.; Brown, Jeremy R. Glissen] Harvard Med Sch, Boston, MA 02215 USA.
C3 Sichuan Provincial People's Hospital; Harvard University; Beth Israel
   Deaconess Medical Center; Harvard University; Harvard Medical School
RP Zhou, GY (通讯作者)，Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Peoples R China.
EM zhou.guanyu@outlook.com
OI Glissen Brown, Jeremy/0000-0002-7204-7241; Wang, Pu/0000-0002-1234-309X;
   Wang, Han/0000-0002-7475-1830
CR Adler A, 2012, CLIN GASTROENTEROL H, V10, P155, DOI 10.1016/j.cgh.2011.10.026
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   [Anonymous], [No title captured]
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Cohen J, 2017, J CLIN GASTROENTEROL, V51, P818, DOI 10.1097/MCG.0000000000000695
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Doubeni CA, 2013, ANN INTERN MED, V158, P312, DOI 10.7326/0003-4819-158-5-201303050-00003
   Fang JY, 2014, GASTROINTEST TUMORS, V1, P53, DOI 10.1159/000362585
   Horton N, 2016, AM J GASTROENTEROL, V111, P1330, DOI 10.1038/ajg.2016.273
   Jeong YH, 2016, J KOREAN MED SCI, V31, P1426, DOI 10.3346/jkms.2016.31.9.1426
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Lami M, 2018, ENDOSCOPY, V50, P701, DOI 10.1055/s-0044-101026
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Martinez ME, 2009, GASTROENTEROLOGY, V136, P832, DOI 10.1053/j.gastro.2008.12.007
   Pabby A, 2005, GASTROINTEST ENDOSC, V61, P385, DOI 10.1016/S0016-5107(04)02765-8
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Rees CJ, 2019, NAT REV GASTRO HEPAT, V16, P584, DOI 10.1038/s41575-019-0178-y
   Rex DK, 2003, AM J GASTROENTEROL, V98, P2000, DOI 10.1016/S0002-9270(03)00625-7
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2010, AM J GASTROENTEROL, V105, P2312, DOI 10.1038/ajg.2010.245
   Robertson DJ, 2015, GUT, V64, P982, DOI 10.1136/gutjnl-2014-308076
   Schoefl R, 2015, DIGEST DIS, V33, P38, DOI 10.1159/000366034
   Siu AL, 2016, ANN INTERN MED, V164, P279, DOI 10.7326/M15-2886
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Tziatzios G, 2019, DIGEST LIVER DIS, V51, P1079, DOI 10.1016/j.dld.2019.05.012
   Vleugels JLA, 2017, GASTROINTEST ENDOSC, V85, P1169, DOI 10.1016/j.gie.2016.12.014
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 36
TC 187
Z9 195
U1 5
U2 34
PU ELSEVIER INC
PI SAN DIEGO
PA 525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA
EI 2468-1253
J9 LANCET GASTROENTEROL
JI Lancet Gastroenterol. Hepatol.
PD APR
PY 2020
VL 5
IS 4
BP 343
EP 351
DI 10.1016/S2468-1253(19)30411-x
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA KU8GP
UT WOS:000519950400018
PM 31981517
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Yuan, YX
   Qin, WJ
   Ibragimov, B
   Zhang, GL
   Han, B
   Meng, MQH
   Xing, L
AF Yuan, Yixuan
   Qin, Wenjian
   Ibragimov, Bulat
   Zhang, Guanglei
   Han, Bin
   Meng, Max Q-H
   Xing, Lei
TI Densely Connected Neural Network With Unbalanced Discriminant and
   Category Sensitive Constraints for Polyp Recognition
SO IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING
LA English
DT Article
DE Deep learning; Image recognition; Task analysis; Data models; Biomedical
   imaging; Shape; Feature extraction; Category sensitive (CS) loss;
   densely connected convolutional network (DenseNet); polyp image
   classification; unbalanced discriminant (UD) loss
ID WIRELESS CAPSULE ENDOSCOPY; CLASSIFICATION; IMAGES
AB Automatic polyp recognition in endoscopic images is challenging because of the low contrast between polyps and the surrounding area, the fuzzy and irregular polyp borders, and varying imaging light conditions. In this article, we propose a novel densely connected convolutional network with "unbalanced discriminant (UD)" loss and "category sensitive (CS)" loss (DenseNet-UDCS) for the task. We first utilize densely connected convolutional network (DenseNet) as the basic framework to conduct end-to-end polyp recognition task. Then, the proposed dual constraints, UD loss and CS loss, are simultaneously incorporated into the DenseNet model to calculate discriminative and suitable image features. The UD loss in our network effectively captures classification errors from both majority and minority categories to deal with the strong data imbalance of polyp images and normal ones. The CS loss imposes the ratio of intraclass and interclass variations in the deep feature learning process to enable features with large interclass variation and small intraclass compactness. With the joint supervision of UD loss and CS loss, a robust DenseNet-UDCS model is trained to recognize polyps from endoscopic images. The experimental results achieved polyp recognition accuracy of 93.19%, showing that the proposed DenseNet-UDCS can accurately characterize the endoscopic images and recognize polyps from the images. In addition, our DenseNet-UDCS model is superior in detection accuracy in comparison with state-of-the-art polyp recognition methods. Note to Practitioners-Wireless capsule endoscopy (WCE) is a crucial diagnostic tool for polyp detection and therapeutic monitoring, thanks to its noninvasive, user-friendly, and nonpainful properties. A challenge in harnessing the enormous potential of the WCE to benefit the gastrointestinal (GI) patients is that it requires clinicians to analyze a huge number of images (about 50 000 images for each patient). We propose a novel automatic polyp recognition scheme, namely, DenseNet-UDCS model, by addressing practical image unbalanced problem and small interclass variances and large intraclass differences in the data set. The comprehensive experimental results demonstrate superior reliability and robustness of the proposed model compared to the other polyp recognition approaches. Our DenseNet-UDCS model can be further applied in the clinical practice to provide valuable diagnosis information for GI disease recognition and precision medicine.
C1 [Yuan, Yixuan; Meng, Max Q-H] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Qin, Wenjian] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing 518055, Peoples R China.
   [Ibragimov, Bulat] Univ Copenhagen, Dept Machine Learning & Med Imaging, DK-2100 Copenhagen, Denmark.
   [Ibragimov, Bulat] Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen, Denmark.
   [Zhang, Guanglei] Beihang Univ, Sch Biol Sci & Med Engn, Beijing Adv Innovat Ctr Biomed Engn, Beijing 100191, Peoples R China.
   [Han, Bin; Xing, Lei] Stanford Univ, Dept Radiat Oncol, Stanford, CA 94305 USA.
C3 City University of Hong Kong; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS; University of Copenhagen;
   University of Copenhagen; Beihang University; Stanford University
RP Yuan, YX (通讯作者)，City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM yxyuan.ee@cityu.edu.hk; qinwenjian09@mails.ucas.edu.cn; bulat@di.ku.dk;
   guangleizhang@buaa.edu.cn; hanbin@stanford.edu; max@ee.cuhk.edu.hk;
   lei@stanford.edu
RI Zhang, Guanglei/GPX-8904-2022; meng, meng/GWZ-7461-2022
OI Zhang, Guanglei/0000-0002-2617-9673; Ibragimov,
   Bulat/0000-0001-7739-7788; Meng, Max Q.-H./0000-0002-5255-5898; Yuan,
   Yixuan/0000-0002-0853-6948; Xing, Lei/0000-0003-2536-5359
FU Sichuan Provincial Science and Technology Department Applied Basic
   Research Project [2019JY0632]; CityU Start-Up Fund [7200580]
FX This work was supported in part by Sichuan Provincial Science and
   Technology Department Applied Basic Research Project 2019JY0632 and in
   part by CityU Start-Up Fund 7200580.
CR Abadi M., 2016, CORR ABS160304467
   [Anonymous], 2007, 2 C ESP INF ZARZG
   [Anonymous], KEY STAT COL CANC
   [Anonymous], 2015, DEEP LEARNING NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Hartmann D, 2005, GASTROINTEST ENDOSC, V61, P826, DOI 10.1016/S0016-5107(05)00372-X
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jeatrakul P, 2010, LECT NOTES COMPUT SC, V6444, P152, DOI 10.1007/978-3-642-17534-3_19
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Khan Salman H, 2018, IEEE Trans Neural Netw Learn Syst, V29, P3573, DOI 10.1109/TNNLS.2017.2732482
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li C, 2014, NEUROCOMPUTING, V123, P398, DOI 10.1016/j.neucom.2013.08.002
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Silva J, 2013, IEEE ENG MED BIO, P5711, DOI 10.1109/EMBC.2013.6610847
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simard PY, 2003, PROC INT CONF DOC, P958
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Song Y, 2013, I S BIOMED IMAGING, P198
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JB, 2017, ELECTRON LETT, V53, P918, DOI 10.1049/el.2017.0523
   Wang SJ, 2016, IEEE IJCNN, P4368, DOI 10.1109/IJCNN.2016.7727770
   XU L, 2018, P SOC PHOTO-OPT INS
   Ypsilantis PP, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137036
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YX, 2018, IEEE T CYBERNETICS, V48, P2074, DOI 10.1109/TCYB.2017.2726818
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 48
TC 21
Z9 21
U1 4
U2 36
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-5955
EI 1558-3783
J9 IEEE T AUTOM SCI ENG
JI IEEE Trans. Autom. Sci. Eng.
PD APR
PY 2020
VL 17
IS 2
BP 574
EP 583
DI 10.1109/TASE.2019.2936645
PG 10
WC Automation & Control Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems
GA LH3FP
UT WOS:000528673100003
DA 2023-08-21
ER

PT J
AU Zachariah, R
   Ninh, A
   Karnes, W
AF Zachariah, Robin
   Ninh, Andrew
   Karnes, William
TI Artificial intelligence for colon polyp detection: Why should we embrace
   this?
SO TECHNIQUES AND INNOVATIONS IN GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
DE Machine learning; Convolutional neural networks; Colorectal cancer
   prevention; Adenoma detection rate
ID ADENOMA DETECTION; COLORECTAL-CANCER; COLONOSCOPY; VALIDATION;
   PREVENTION
AB Optimal success of colonoscopy for prevention of colorectal cancer is currently measured by adenoma detection rate (ADR), which reflects a colonoscopists ability to identify colorectal and remove precancerous polyps. Among colonoscopists in the same health care system and shared patient population, ADR varies from 7% to 53%. For every 1% increase in ADR, risk of interval colorectal cancer is reduced by 3%-6%. Beyond attaining excellent exposure of entire mucosal surface during colonoscopy, ADR can be improved with a second observer. Computer-aided detection ("facial recognition" for polyps) has potential to improve ADR as a second observer. Several groups are working to bring this technology into the endoscopy unit. Success will require real-time implementation of an affordable system with very high accuracy and proven benefit to improve ADR and reduce miss rate of precancerous lesions. In just the past year, computer-aided detection systems that run live during colonoscopy have been shown to improve ADR using affordable off-the-shelf computers. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Zachariah, Robin; Karnes, William] Univ Calif Irvine, Med Ctr, Dept Gastroenterol, Orange, CA 92668 USA.
   [Ninh, Andrew; Karnes, William] Docbot, Irvine, CA USA.
C3 University of California System; University of California Irvine
RP Zachariah, R (通讯作者)，Univ Calif Irvine, Med Ctr, Dept Gastroenterol, Orange, CA 92668 USA.
EM rzachar1@uci.edu
OI Karnes, William/0000-0002-6225-9080
CR Abadir AP, 2018, AM J GASTROENTEROL, V113, pS348
   Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Almansa C, 2011, AM J GASTROENTEROL, V106, P1070, DOI 10.1038/ajg.2011.26
   Anderson JC, 2015, CLIN TRANSL GASTROEN, V6, DOI 10.1038/ctg.2015.5
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chin M, 2016, WORLD J GASTROENTERO, V22, P9642, DOI 10.3748/wjg.v22.i43.9642
   Clark BT, 2016, GASTROINTEST ENDOSC, V84, P126, DOI 10.1016/j.gie.2015.12.030
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Eckardt AJ, 2013, ANN GASTROENTEROL, V26, P272
   El-Halabi MM, 2019, GASTROINTEST ENDOSC, V89, P137, DOI 10.1016/j.gie.2018.08.021
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Karnes WE, 2018, GASTROINTEST ENDOSC, V87
   Kuntz KM, 2011, MED DECIS MAKING, V31, P530, DOI 10.1177/0272989X11408730
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li TB, 2016, GASTROINTEST ENDOSC, V83, pAB482, DOI 10.1016/j.gie.2016.03.671
   Madhoun MF, 2012, GASTROINTEST ENDOSC, V75, P127, DOI 10.1016/j.gie.2011.07.048
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Peters SL, 2010, CLIN GASTROENTEROL H, V8, P439, DOI 10.1016/j.cgh.2010.01.013
   Requa J, 2018, AM J GASTROENTEROL, V113, pS158
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Samarasena J., 2018, GASTROINTEST ENDOSC, V87, DOI [10.1016/j.gie.2018.04.461, DOI 10.1016/J.GIE.2018.04.461.]
   SHINYA H, 1979, ANN SURG, V190, P679, DOI 10.1097/00000658-197912000-00001
   Surveillance Epidemiology and End Results (SEER), 2016, PROGRAM
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang P, 2017, AM J GASTROENTEROL, V112, pS106, DOI 10.1038/ajg.2014.297
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Xu L, 2016, GASTROENT RES PRACT, V2016, DOI 10.1155/2016/7631981
   Yoshida N, 2018, DIGEST DIS SCI, V63, P3457, DOI 10.1007/s10620-018-5275-1
   Zachariah R, 2018, AM COLL GASTR ANN SC
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 35
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 2666-5107
EI 2590-0307
J9 TECH INNOVAT GASTROI
JI Tech. Innovation Gastrointes. Endoscopy
PD APR
PY 2020
VL 22
IS 2
SI SI
BP 48
EP 51
DI 10.1016/j.tgie.2019.150631
PG 4
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA VK9TP
UT WOS:000771335700003
DA 2023-08-21
ER

PT J
AU Charfi, S
   El Ansari, M
AF Charfi, Said
   El Ansari, Mohamed
TI A locally based feature descriptor for abnormalities detection
SO SOFT COMPUTING
LA English
DT Article
DE Ulcer; Inflammatory; Polyp; Feature extraction; Contrast
ID WIRELESS CAPSULE ENDOSCOPY; ULCER DETECTION; TEXTURE; CLASSIFICATION;
   BOWEL
AB Wireless capsule endoscopy (WCE) is a novel imaging technique that can view the entire small bowel in human body. Therefore, it has been gradually adopted compared with traditional endoscopies for gastrointestinal diseases. However, the task of reviewing the vast amount of images produced by a WCE test is exhaustive for the physicians. This paper presents a new feature extraction scheme for pathological inflammation and ulcer regions discrimination in WCE images. In addition, the novel approach is adopted for polyp recognition in colonoscopy videos. A novel idea based on extracting certain local features from the image is proposed. Then, the occurrence histogram of these features is used as descriptor of the image. The new feature descriptor scheme is grayscale rotation invariant and computationally simple as the operator can be realized with a few operations in a small neighborhood. The proposed operator does not discard the contrast information. Besides, we propose to test the quality of the model using logarithmic loss metric and show how calibration can be useful in reducing the aforementioned measure. Extensive classification experiments have been applied on different datasets, which prove that the occurrence histogram of the extracted features is powerful. The proposed method achieved 99.1%, 99.7% and 99.2% in terms of the precision in the first, second and third datasets, respectively, and surpassed some known local descriptors on a texture dataset.
C1 [Charfi, Said; El Ansari, Mohamed] Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Charfi, S (通讯作者)，Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
EM charfisaid@gmail.com; melansari@gmail.com
RI El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066
FU National Center for Scientific and technical Research (CNRST) in Rabat
FX We gratefully acknowledge and express our thanks to the National Center
   for Scientific and technical Research (CNRST) in Rabat for its research
   grant.
CR Adler DG, 2003, HOSP PHYS, P14
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], 2016, SOFT COMPUT, DOI 10.1007/s00500-016-2247-2
   [Anonymous], 2014, P IEEE C COMP VIS PA
   Barbosa DJC, 2009, IEEE ENG MED BIO, P6683, DOI 10.1109/IEMBS.2009.5334013
   Charfi S., 2017, MULTIMED TOOLS APPL, P1
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   Charisis VS, 2012, COMPUT METH PROG BIO, V107, P61, DOI 10.1016/j.cmpb.2011.10.004
   Charleer Sven, 2018, IEEE Transactions on Learning Technologies, V11, P389, DOI 10.1109/TLT.2017.2720670
   Cimpoi M, 2018, DESCRIBABLE TEXTURES
   El Ansari M, 2017, 2017 INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND MOBILE COMMUNICATIONS (WINCOM), P407
   Endoscopy C, 2018, CAPSULE ENDOSCOPY PR
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Ghosh T., 2016, INT J SCI ENG RES, V7, P737
   Girgis HZ, 2010, I S BIOMED IMAGING, P1373, DOI 10.1109/ISBI.2010.5490253
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Haji Maghsoudi Omid, 2013, 2013 20th Iranian Conference on Biomedical Engineering (ICBME). Proceedings, P286, DOI 10.1109/ICBME.2013.6782236
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kodogiannis VS, 2007, NEUROCOMPUTING, V70, P704, DOI 10.1016/j.neucom.2006.10.024
   Kodogiannis VS, 2007, ENG APPL ARTIF INTEL, V20, P539, DOI 10.1016/j.engappai.2006.09.006
   Kopylov Uri, 2016, Gastrointest Endosc Clin N Am, V26, P611, DOI 10.1016/j.giec.2016.06.007
   Koshy NE, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1725, DOI 10.1109/ECS.2015.7124881
   Kundu AK, 2017, IEEE REG 10 HUMANIT, P734, DOI 10.1109/R10-HTC.2017.8289062
   Kundu AK, 2017, TENCON IEEE REGION, P1300, DOI 10.1109/TENCON.2017.8228058
   Li BP, 2015, MED PHYS, V42, P645, DOI 10.1118/1.4905164
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2011, ARTIF INTELL MED, V52, P11, DOI 10.1016/j.artmed.2011.01.003
   Li BP, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P498, DOI 10.1109/IROS.2009.5354726
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Maini R, 2010, ARXIV10034053
   Mitselos IV, 2015, WORLD J GASTRO ENDOS, V7, P643, DOI 10.4253/wjge.v7.i6.643
   Ogiela MR, 2016, SOFT COMPUT, V20, P4193, DOI 10.1007/s00500-016-2186-y
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Platt JC, 2000, ADV NEUR IN, P61
   Ponte A, 2018, GASTROENT HEPAT-BARC, V41, P245, DOI 10.1016/j.gastrohep.2017.11.001
   Riegler M, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P282, DOI 10.1145/2910017.2910629
   Rokkas T, 2010, GASTROINTEST ENDOSC, V71, P792, DOI 10.1016/j.gie.2009.10.050
   Saurin JC, 2016, CLIN ENDOSC, V49, P26, DOI 10.5946/ce.2016.49.1.26
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sevo I, 2016, COMPUT BIOL MED, V72, P138, DOI 10.1016/j.compbiomed.2016.03.017
   Shin Y, 2018, COMPUT MED IMAG GRAP, V69, P33, DOI 10.1016/j.compmedimag.2018.08.001
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Suman S, 2016, ADV SCI LETT, V22, P2764, DOI 10.1166/asl.2016.7099
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Walsh CG, 2017, J BIOMED INFORM, V76, P9, DOI 10.1016/j.jbi.2017.10.008
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yeh J-Y, 2014, J SOFTWARE ENG APPL, V7, P422, DOI DOI 10.4236/JSEA.2014.75039
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
NR 53
TC 10
Z9 10
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD MAR
PY 2020
VL 24
IS 6
BP 4469
EP 4481
DI 10.1007/s00500-019-04208-8
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KM9TN
UT WOS:000514483700038
DA 2023-08-21
ER

PT J
AU Khan, MA
   Khan, MA
   Ahmed, F
   Mittal, M
   Goyal, LM
   Hemanth, DJ
   Satapathy, SC
AF Khan, Mehshan Ahmed
   Khan, Muhammad Attique
   Ahmed, Fawad
   Mittal, Mamta
   Goyal, Lalit Mohan
   Hemanth, D. Jude
   Satapathy, Suresh Chandra
TI Gastrointestinal diseases segmentation and classification based on
   duo-deep architectures
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Stomach diseases; Mask RCNN; CNN features; Feature selection
ID CAPSULE ENDOSCOPY IMAGES; REDUCTION
AB Nowadays, almost one million gastrointestinal patients are successfully treated by Wireless Capsule Endoscopy (WCE). It is the latest technology in the area of medical imaging for the diagnosis of gastrointestinal diseases such as ulcer, polyp, bleeding, etc. Manual diagnosis process is time-consuming and hard for doctors; therefore, researchers have proposed computerized techniques for detection and classification of these diseases. In this article, a deep learning-based method is presented for ulcer detection and gastrointestinal diseases (ulcer, polyp, bleeding) classification. Modified mask Recurrent Convolutional Neural Network (RCNN) based ulcer segmentation is proposed. The ulcer annotated images are utilized to train the Mask RCNN model to obtain output in the form of bounding box ulcer detected area and mask segmented region. In the classification phase, the ResNet101 pre-trained CNN model is fine-tuned through transfer learning to derive deep features. The acquired deep features are optimized through grasshopper optimization along with minimum distance fitness function. The best-selected features are finally supplied to a Multi-class Support Vector Machine (MSVM) of cubic kernel function for final classification. Experiments have been performed in two-steps; first, the ulcer segmentation results are computed through recall, precision, and Mean Overlap Coefficient (MOC). The ResNet50+FPN as backbone and training all the layers of Mask-RCNN gives best results in terms of MOC = 0.8807 and average precision = 1.0. Second, the best classification accuracy of 99.13% is achieved on the cubic SVM for K = 10. It is clearly perceived that the proposed method outperforms when compared and analyzed with the existing methods. (c) 2019 Elsevier B.V. All rights reserved.
C1 [Khan, Mehshan Ahmed; Ahmed, Fawad] HITEC Univ, Dept EE, Museum Rd, Taxila, Pakistan.
   [Khan, Muhammad Attique] HITEC Univ, Dept CS, Museum Rd, Taxila, Pakistan.
   [Mittal, Mamta] GB Pant Govt Engn Coll, Dept Comp Sci & Engn, New Delhi 110020, India.
   [Goyal, Lalit Mohan] JC Bose Univ Sci & Technol, YMCA, Dept CE, Faridabad, India.
   [Hemanth, D. Jude] Karunya Univ, Dept ECE, Coimbatore, Tamil Nadu, India.
   [Satapathy, Suresh Chandra] Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
C3 NITEC University; NITEC University; J.C. Bose University of Science &
   Technology, YMCA; Karunya Institute of Technology & Sciences; Kalinga
   Institute of Industrial Technology (KIIT)
RP Mittal, M (通讯作者)，GB Pant Govt Engn Coll, Dept Comp Sci & Engn, New Delhi 110020, India.
EM attique.khan440@gmail.com; mittalmamta79@gmail.com
RI Khan, Dr. Muhammad Attique/AAX-2644-2021; Mittal, Mamta/AAC-2229-2020;
   Sataphaty, Suresh Chandra/AAW-9662-2020; GOYAL, LALIT
   MOHAN/AAH-4030-2020; khan, sajid/HGE-2406-2022; Ahmed Khan,
   Mehshan/HGT-8212-2022; khan, mehshan/HGT-8257-2022
OI Khan, Dr. Muhammad Attique/0000-0002-6347-4890; Mittal,
   Mamta/0000-0003-0490-4413; GOYAL, LALIT MOHAN/0000-0003-4618-0281; Ahmed
   Khan, Mehshan/0000-0002-7380-8532; 
CR Al-shebani Q, 2019, ARTIF INTELL MED, V94, P18, DOI 10.1016/j.artmed.2018.12.008
   Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   [Anonymous], NAT PROD RES 0520
   [Anonymous], 2019, VGG IMAGE ANNOTATOR
   [Anonymous], MICROSC RES TECH
   [Anonymous], 2019, PATTERN RECOGN
   [Anonymous], 2019, MED TEACH, DOI DOI 10.1080/0142159X.2019.1626979
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Bchir O, 2019, SIGNAL IMAGE VIDEO P, V13, P121, DOI 10.1007/s11760-018-1336-3
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hemanth DJ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1111-6
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jaderberg M, 2015, ADV NEUR IN, V28
   KHAN MA, 2019, PATTERN RECOGNIT LET
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P741, DOI 10.1002/jemt.23220
   Lan LB, 2019, IEEE ACCESS, V7, P30017, DOI 10.1109/ACCESS.2019.2901568
   Lee HG, 2013, COMPUT BIOL MED, V43, P670, DOI 10.1016/j.compbiomed.2013.02.009
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Mittal M, 2019, APPL SOFT COMPUT, V78, P346, DOI 10.1016/j.asoc.2019.02.036
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sethi JK, 2019, J STAT MANAG SYST, V22, P697, DOI 10.1080/09720510.2019.1609726
   Sharif M, 2021, J EXP THEOR ARTIF IN, V33, P577, DOI 10.1080/0952813X.2019.1572657
   Sharma RK, 2019, PATHOG GLOB HEALTH, V113, P263, DOI [10.1080/20477724.2019.1685802, 10.1007/978-981-10-8234-4_1]
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Waleed A., 2017, MASK R CNN OBJECT DE
   Wang Q, 2019, OPT LASER TECHNOL, V110, P152, DOI 10.1016/j.optlastec.2018.08.051
NR 35
TC 87
Z9 87
U1 4
U2 52
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD MAR
PY 2020
VL 131
BP 193
EP 204
DI 10.1016/j.patrec.2019.12.024
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX6EF
UT WOS:000521971700028
DA 2023-08-21
ER

PT J
AU Mostafiz, R
   Hasan, M
   Hossain, I
   Rahman, MM
AF Mostafiz, Rafid
   Hasan, Mosaddik
   Hossain, Imran
   Rahman, Mohammad M.
TI An intelligent system for gastrointestinal polyp detection in endoscopic
   video using fusion of bidimensional empirical mode decomposition and
   convolutional neural network features
SO INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY
LA English
DT Article
DE CEMD features; convolutional neural network (CNN); empirical mode
   decomposition; support vector machine (SVM); video endoscopy
ID COMPUTER-AIDED CLASSIFICATION
AB This paper presents an intelligent system for gastrointestinal polyp detection in endoscopic video. Video endoscopy is a popular diagnostic modality in assessing the gastrointestinal polyps. But the accuracy of diagnosis mostly depends on doctors' experience that is crucial to detect polyps in many cases. Computer-aided polyp detection is promising to reduce the miss detection rate of polyp and thus improve the accuracy of diagnosis results. The proposed method illustrates an automatic system based on a new color feature extraction scheme as a support for gastrointestinal polyp detection. The scheme is the combination of color empirical mode decomposition features and convolutional neural network features extracted from video frames. The features are fed into a linear support vector machine to train the classifier. Experiments on standard public databases show that the proposed scheme outperforms the previous conventional methods, gaining accuracy of 99.53%, sensitivity of 99.91%, and specificity of 99.15%.
C1 [Mostafiz, Rafid; Hasan, Mosaddik; Rahman, Mohammad M.] Mawlana Bhashani Sci & Technol Univ, Dept Comp Sci & Engn, Tangail, Bangladesh.
   [Mostafiz, Rafid] Dhaka Int Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
   [Hossain, Imran] Comilla Univ, Dept Informat & Commun Technol, Comilla, Bangladesh.
C3 Mawlana Bhashani Science & Technology University; Dhaka International
   University (DIU); Comilla University
RP Rahman, MM (通讯作者)，Mawlana Bhashani Sci & Technol Univ, Dept Comp Sci & Engn, Tangail, Bangladesh.
EM mm73rahman@gmail.com
RI Rahman, Mohammad Motiur/AAR-2994-2020
OI Rahman, Mohammad Motiur/0000-0003-4417-8276; Mostafiz,
   Rafid/0000-0002-5905-6530
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], P 12 IEEE INT S BIOM
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Damerval C, 2005, IEEE SIGNAL PROC LET, V12, P701, DOI 10.1109/LSP.2005.855548
   El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   Hafner M, 2010, IEEE T INF TECHNOL B, V14, P958, DOI 10.1109/TITB.2010.2044184
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kodogiannis VS, 2007, INT J INFORM TECHNOL, V13, P46
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Li ST, 2003, PATTERN RECOGN, V36, P2883, DOI 10.1016/S0031-3203(03)00219-X
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Linderhed A, 2002, P SOC PHOTO-OPT INS, V4738, P1, DOI 10.1117/12.458772
   Liu Z, 2007, INT J REMOTE SENS, V28, P4081, DOI 10.1080/01431160601075483
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ribeiro J, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTERS IN EDUCATION (SIIE)
   Sargent D, 2016, PROC SPIE, V9784, DOI 10.1117/12.2217123
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Wimmer G, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.034504
   Xie MG, 2016, INT CONF WIRE COMMUN
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 33
TC 10
Z9 10
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0899-9457
EI 1098-1098
J9 INT J IMAG SYST TECH
JI Int. J. Imaging Syst. Technol.
PD MAR
PY 2020
VL 30
IS 1
BP 224
EP 233
DI 10.1002/ima.22350
PG 10
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA KH4EN
UT WOS:000510597000018
DA 2023-08-21
ER

PT J
AU Ozawa, T
   Ishihara, S
   Fujishiro, M
   Kumagai, Y
   Shichijo, S
   Tada, T
AF Ozawa, Tsuyoshi
   Ishihara, Soichiro
   Fujishiro, Mitsuhiro
   Kumagai, Youichi
   Shichijo, Satoki
   Tada, Tomohiro
TI Automated endoscopic detection and classification of colorectal polyps
   using convolutional neural networks
SO THERAPEUTIC ADVANCES IN GASTROENTEROLOGY
LA English
DT Article
DE artificial intelligence; classification; colon; colorectal;
   convolutional neural network; detection; diagnosis; polyp
ID COMPUTER-AIDED DETECTION; ADENOMA DETECTION; DIAGNOSIS; COLONOSCOPY;
   HISTOLOGY; SYSTEM; CANCER
AB Background:
   Recently the American Society for Gastrointestinal Endoscopy addressed the 'resect and discard' strategy, determining that accurate in vivo differentiation of colorectal polyps (CP) is necessary. Previous studies have suggested a promising application of artificial intelligence (AI), using deep learning in object recognition. Therefore, we aimed to construct an AI system that can accurately detect and classify CP using stored still images during colonoscopy.
   Methods:
   We used a deep convolutional neural network (CNN) architecture called Single Shot MultiBox Detector. We trained the CNN using 16,418 images from 4752 CPs and 4013 images of normal colorectums, and subsequently validated the performance of the trained CNN in 7077 colonoscopy images, including 1172 CP images from 309 various types of CP. Diagnostic speed and yields for the detection and classification of CP were evaluated as a measure of performance of the trained CNN.
   Results:
   The processing time of the CNN was 20 ms per frame. The trained CNN detected 1246 CP with a sensitivity of 92% and a positive predictive value (PPV) of 86%. The sensitivity and PPV were 90% and 83%, respectively, for the white light images, and 97% and 98% for the narrow band images. Among the correctly detected polyps, 83% of the CP were accurately classified through images. Furthermore, 97% of adenomas were precisely identified under the white light imaging.
   Conclusions:
   Our CNN showed promise in being able to detect and classify CP through endoscopic images, highlighting its high potential for future application as an AI-based CP diagnosis support system for colonoscopy.
C1 [Ozawa, Tsuyoshi] Teikyo Univ, Dept Surg, Sch Med, Itabashi Ku, 2-11-1 Kaga, Tokyo 1738606, Japan.
   [Ozawa, Tsuyoshi; Ishihara, Soichiro; Tada, Tomohiro] Tada Tomohiro Inst Gastroenterol & Proctol, Saitama, Japan.
   [Ishihara, Soichiro; Tada, Tomohiro] Univ Tokyo, Grad Sch Med, Dept Surg Oncol, Tokyo, Japan.
   [Fujishiro, Mitsuhiro] Nagoya Univ, Grad Sch Med, Dept Gastroenterol, Nagoya, Aichi, Japan.
   [Kumagai, Youichi] Saitama Med Univ, Saitama Med Ctr, Dept Digest Tract & Gen Surg, Saitama, Japan.
   [Shichijo, Satoki] Osaka Int Canc Inst, Dept Gastrointestinal Oncol, Osaka, Japan.
   [Tada, Tomohiro] AI Med Serv Inc, Tokyo, Japan.
C3 Teikyo University; University of Tokyo; Nagoya University; Saitama
   Medical University
RP Ozawa, T (通讯作者)，Teikyo Univ, Dept Surg, Sch Med, Itabashi Ku, 2-11-1 Kaga, Tokyo 1738606, Japan.
EM tsuozawa244@gmail.com
RI Ishihara, Soichiro/AFK-1375-2022; 藤城, 光弘/AAN-3131-2020
OI Ozawa, Tsuyoshi/0000-0002-0701-7978; Fujishiro,
   Mitsuhiro/0000-0002-4074-1140
FU Japan Society for the promotion of Science [19K16810]; Grants-in-Aid for
   Scientific Research [19K16810] Funding Source: KAKEN
FX The authors disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: This research
   is financially supported by the Japanese Grans-inAid for Scientific
   Research (grant number 19K16810) from Japan Society for the promotion of
   Science.
CR Almadi MA, 2015, CAN J GASTROENTEROL, V29, P304, DOI 10.1155/2015/789038
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   CIOMPI F, 2017, SCI REP UK, V7
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   IJspeert JEG, 2017, GUT, V66, P1225, DOI 10.1136/gutjnl-2015-310784
   Ijspeert JE, 2015, GASTROINTEST ENDOSC, V81, pAB260, DOI 10.1016/j.gie.2015.03.1348
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Manceau G, 2016, UPDATES SURG, V68, P3, DOI 10.1007/s13304-016-0345-4
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Postgate A, 2008, ENDOSCOPY, V40, P496, DOI 10.1055/s-2007-995590
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI [DOI 10.3322/CAAC.21442, 10.3322/caac.21332]
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Strum WB, 2016, NEW ENGL J MED, V374, P1065, DOI [10.1056/NEJMra1513581, 10.1056/NEJMc1604867]
   Su MY, 2006, AM J GASTROENTEROL, V101, P2711, DOI 10.1111/j.1572-0241.2006.00932.x
   Takeuchi Y, 2010, GASTROINTEST ENDOSC, V72, P1006, DOI 10.1016/j.gie.2010.06.055
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2020, LANCET GASTROENTEROL, V5, P343, DOI [10.1016/S2468-1253(19)30411-X, 10.1016/S2468-1253(19)30411-x]
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Xu Y, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1685-x
   Yoshida N, 2014, DIGEST ENDOSC, V26, P250, DOI 10.1111/den.12127
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 36
TC 64
Z9 65
U1 4
U2 16
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1756-283X
EI 1756-2848
J9 THER ADV GASTROENTER
JI Ther. Adv. Gastroenterol.
PD MAR
PY 2020
VL 13
AR 1756284820910659
DI 10.1177/1756284820910659
PG 13
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA LB0EE
UT WOS:000524310600001
PM 32231710
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Garcia-Rodriguez, A
   Bernal, J
   Sanchez, FJ
   Cordova, H
   Duran, RG
   de Miguel, CR
   Fernandez-Esparrach, G
AF Garcia-Rodriguez, Ana
   Bernal, Jorge
   Sanchez, F. Javier
   Cordova, Henry
   Garces Duran, Rodrigo
   Rodriguez de Miguel, Cristina
   Fernandez-Esparrach, Gloria
TI Polyp fingerprint: automatic recognition of colorectal polyps' unique
   features
SO SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
LA English
DT Article
DE Content-based image retrieval; Artificial intelligence; Colorectal
   polyps
AB Background Content-based image retrieval (CBIR) is an application of machine learning used to retrieve images by similarity on the basis of features. Our objective was to develop a CBIR system that could identify images containing the same polyp ('polyp fingerprint'). Methods A machine learning technique called Bag of Words was used to describe each endoscopic image containing a polyp in a unique way. The system was tested with 243 white light images belonging to 99 different polyps (for each polyp there were at least two images representing it in two different temporal moments). Images were acquired in routine colonoscopies at Hospital Clinic using high-definition Olympus endoscopes. The method provided for each image the closest match within the dataset. Results The system matched another image of the same polyp in 221/243 cases (91%). No differences were observed in the number of correct matches according to Paris classification (protruded: 90.7% vs. non-protruded: 91.3%) and size (< 10 mm: 91.6% vs. > 10 mm: 90%). Conclusions A CBIR system can match accurately two images containing the same polyp, which could be a helpful aid for polyp image recognition.
C1 [Garcia-Rodriguez, Ana; Cordova, Henry; Garces Duran, Rodrigo; Rodriguez de Miguel, Cristina; Fernandez-Esparrach, Gloria] Univ Barcelona, CIBEREHD, IDIBAPS, Endoscopy Unit,Gastroenterol Dept,Hosp Clin, Barcelona, Spain.
   [Bernal, Jorge; Sanchez, F. Javier] Univ Autonoma Barcelona, Dept Comp Sci, Barcelona, Spain.
   [Bernal, Jorge; Sanchez, F. Javier] Comp Vis Ctr, Barcelona, Spain.
C3 CIBER - Centro de Investigacion Biomedica en Red; CIBEREHD; University
   of Barcelona; Hospital Clinic de Barcelona; IDIBAPS; Autonomous
   University of Barcelona; Centre de Visio per Computador (CVC)
RP Fernandez-Esparrach, G (通讯作者)，Univ Barcelona, CIBEREHD, IDIBAPS, Endoscopy Unit,Gastroenterol Dept,Hosp Clin, Barcelona, Spain.
EM mgfernan@clinic.cat
RI Rodríguez de Miguel, Cristina/CAF-1291-2022; Bernal, Jorge/H-4647-2015;
   Córdova, Henry/HJG-5764-2022; Cordova Guevara, Henry Nelson/D-7844-2019
OI Bernal, Jorge/0000-0001-8493-9514; Garces Duran,
   Rodrigo/0000-0002-4080-8704; Garcia-Rodriguez, Ana/0000-0001-7637-922X;
   Rodriguez de Miguel, Cristina/0000-0002-5576-0854;
   Fernandez-Esparrach/0000-0002-3378-3940; Cordova Guevara, Henry
   Nelson/0000-0002-6636-6764
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Qin P., 2019, INT J PERFORMABILITY, V15, P326
   Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455
   Von Renteln D, 2017, EXPERT REV GASTROENT, V11, P835, DOI 10.1080/17474124.2017.1309279
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
NR 5
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0930-2794
EI 1432-2218
J9 SURG ENDOSC
JI Surg. Endosc.
PD APR
PY 2020
VL 34
IS 4
BP 1887
EP 1889
DI 10.1007/s00464-019-07240-9
EA FEB 2020
PG 3
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA KW9LX
UT WOS:000516059600002
PM 32048018
DA 2023-08-21
ER

PT J
AU Park, YS
   Lee, JW
AF Park, Ye-Seul
   Lee, Jung-Won
TI Class-Labeling Method for Designing a Deep Neural Network of Capsule
   Endoscopic Images Using a Lesion-Focused Knowledge Model
SO JOURNAL OF INFORMATION PROCESSING SYSTEMS
LA English
DT Article
DE Capsule Endoscopy; Class-labeling Method; Deep Learning; Knowledge Base
   (KB); Ontology
ID CROHNS-DISEASE; CELIAC-DISEASE; TERMINOLOGY
AB Capsule endoscopy is one of the increasingly demanded diagnostic methods among patients in recent years because of its ability to observe small intestine difficulties. It is often conducted for 12 to 14 hours, but significant frames constitute only 10% of whole frames. Thus, it has been designed to automatically acquire significant frames through deep learning. For example, studies to track the position of the capsule (stomach, small intestine, etc.) or to extract lesion-related information (polyps, etc.) have been conducted. However, although grouping or labeling the training images according to similar features can improve the performance of a learning model, various attributes (such as degree of wrinkles, presence of valves, etc.) are not considered in conventional approaches. Therefore, we propose a class-labeling method that can be used to design a learning model by constructing a knowledge model focused on main lesions defined in standard terminologies for capsule endoscopy (minimal standard terminology, capsule endoscopy structured terminology). This method enables the designing of a systematic learning model by labeling detailed classes through differentiation of similar characteristics.
C1 [Park, Ye-Seul; Lee, Jung-Won] Ajou Univ, Dept Elect & Comp Engn, Suwon, South Korea.
C3 Ajou University
RP Lee, JW (通讯作者)，Ajou Univ, Dept Elect & Comp Engn, Suwon, South Korea.
EM yeseuly777@gmail.com; jungwony@ajou.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2019R1H1A2101112]; National Research Foundation of Korea
   [2019R1H1A2101112] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2019R1H1A2101112).
CR Aabakken L, 2009, ENDOSCOPY, V41, P727, DOI 10.1055/s-0029-1214949
   Bejakovic S, 2009, IEEE INT CONF ROBOT, P3755
   Chen HH, 2017, NEUROCOMPUTING, V229, P77, DOI 10.1016/j.neucom.2016.06.077
   Chen J, 2016, INT C PATT RECOG, P1303, DOI 10.1109/ICPR.2016.7899817
   Ciaccio EJ, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-44
   Fischer M, 2017, AAPS PHARMSCITECH, V18, P404, DOI 10.1208/s12249-016-0521-3
   Gal E, 2008, DIGEST DIS SCI, V53, P1933, DOI 10.1007/s10620-007-0084-y
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Korman LY, 2005, ENDOSCOPY, V37, P951, DOI 10.1055/s-2005-870329
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Li XL, 2017, IEEE ENG MED BIO, P1994, DOI 10.1109/EMBC.2017.8037242
   Lujan-Sanchis M, 2017, WORLD J GASTROENTERO, V23, P703, DOI 10.3748/wjg.v23.i4.703
   Moneghini D, 2016, DIGEST LIVER DIS, V48, pE216, DOI 10.1016/S1590-8658(16)30359-0
   Nakawala H, 2019, INT J COMPUT ASS RAD, V14, P685, DOI 10.1007/s11548-018-1882-8
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Prasad A, 2011, J PSEUDO-DIFFER OPER, V2, P355, DOI 10.1007/s11868-011-0034-5
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Shitrit ABG, 2017, SCAND J GASTROENTERO, V52, P328, DOI 10.1080/00365521.2016.1253769
   Taha Bilal, 2017, Proceedings of the IASTED International Conference on Biomedical Engineering (BioMed 2017), P233, DOI 10.2316/P.2017.852-031
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Yan K., 2019, P IEEE C COMP VIS PA, P8523
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zheng T, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0880-2
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
NR 26
TC 2
Z9 2
U1 0
U2 4
PU KOREA INFORMATION PROCESSING SOC
PI SEOUL
PA 1002HO YONGSUNGBIZTEL 314-1 2GA HANKANGRO YONGSAN-GU, SEOUL, 140-750,
   SOUTH KOREA
SN 1976-913X
EI 2092-805X
J9 J INF PROCESS SYST
JI J. Inf. Process. Syst.
PD FEB
PY 2020
VL 16
IS 1
BP 171
EP 183
DI 10.3745/JIPS.02.0127
PG 13
WC Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA MA1BR
UT WOS:000541650500014
DA 2023-08-21
ER

PT J
AU Rath, T
   Morgenstern, N
   Vitali, F
   Atreya, R
   Neurath, MF
AF Rath, Timo
   Morgenstern, Nadine
   Vitali, Francesco
   Atreya, Raja
   Neurath, Markus F.
TI Advanced Endoscopic Imaging in Colonic Neoplasia
SO VISCERAL MEDICINE
LA English
DT Review
DE Endoscopy; Colorectal cancer; Colorectal polyps; Endocytoscopy;
   Endomicroscopy
ID CONFOCAL LASER ENDOMICROSCOPY; HIGH-DEFINITION COLONOSCOPY; WHITE-LIGHT
   COLONOSCOPY; SMALL COLORECTAL POLYPS; I-SCAN; OPTICAL-DIAGNOSIS;
   INTRAEPITHELIAL NEOPLASIA; SURVEILLANCE COLONOSCOPY; COMMUNITY PRACTICE;
   INDIGO CARMINE
AB Background: Endoscopic imaging is a rapidly evolving field with a constant influx of new concepts and technologies. Since the introduction of video endoscopy and subsequently high-definition imaging as the first revolutions in gastrointestinal endoscopy, several technologies of virtual chromoendoscopy have been developed and brought to the market in the past decade, which have shaped and revolutionized for a second time our approach to endoscopic imaging. In parallel to these developments, microscopic imaging technologies, such as endomicroscopy and endocytoscopy, allow us to examine single cells within the mucosa in real time, thereby enabling histological diagnoses during ongoing endoscopy. Summary: In this review, we provide an overview on the technical background of different technologies of advanced endoscopic imaging, and then review and discuss their role and applications for the diagnosis and management of colorectal neoplasms as well as limitations and challenges that exist despite all technological improvements. Key Messages: Technologies of advanced endoscopic imaging have profound impact not only on our imaging capabilities, they are also about to fundamentally change our approach to managing lesions in the gastrointestinal tract: not every lesion found during colonoscopy has to be excised or sent for histopathologic evaluation. However, before this becomes widespread reality, major obstacles such as patient acceptance, adoption by less trained endoscopists, and also legal aspects need to carefully addressed. The development of computer-aided diagnosis and artificial intelligence algorithms hold the potential to overcome the obstacles associated with the concept of optical biopsy and will most likely fundamentally facilitate, shape, and change decision making in the management of colorectal lesions.
C1 [Rath, Timo; Morgenstern, Nadine; Vitali, Francesco; Atreya, Raja; Neurath, Markus F.] Friedrich Alexander Univ Erlangen Nuremberg, Univ Hosp Erlangen, Ludwig Demling Endoscopy Ctr Excellence, Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Rath, T (通讯作者)，Univ Hosp Erlangen, Ludwig Demling Endoscopy Ctr Excellence, Ulmenweg 18, DE-91054 Erlangen, Germany.
EM Timo.Rath@uk-erlangen.de
OI Rath, Timo/0000-0002-7728-9338
CR Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Basford PJ, 2014, GASTROINTEST ENDOSC, V79, P111, DOI 10.1016/j.gie.2013.06.013
   Bhat YM, 2014, GASTROINTEST ENDOSC, V80, P919, DOI 10.1016/j.gie.2014.06.019
   Bowman Erik A, 2015, Diagn Ther Endosc, V2015, P167406, DOI 10.1155/2015/167406
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P556, DOI 10.1016/j.gie.2011.01.002
   Buchner AM, 2010, GASTROENTEROLOGY, V138, P834, DOI 10.1053/j.gastro.2009.10.053
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Butterly L, 2014, AM J GASTROENTEROL, V109, P417, DOI 10.1038/ajg.2013.442
   Committee AT, 2015, GASTROINTESTINAL END, V81, P502
   De Palma GD, 2010, DIGEST LIVER DIS, V42, P791, DOI 10.1016/j.dld.2010.03.009
   de Wijkerslooth TR, 2013, GASTROINTEST ENDOSC, V77, P617, DOI 10.1016/j.gie.2012.10.018
   Dinesen L, 2012, GASTROINTEST ENDOSC, V75, P604, DOI 10.1016/j.gie.2011.10.017
   Eberl T, 2007, ENDOSCOPY, V39, P497, DOI 10.1055/s-2007-966446
   Fujimoto D, 2018, ENDOSC INT OPEN, V6, pE322, DOI 10.1055/s-0043-124469
   Goetz M, 2014, NAT REV GASTRO HEPAT, V11, P11, DOI 10.1038/nrgastro.2013.134
   Gomez V, 2010, ENDOSCOPY, V42, P286, DOI 10.1055/s-0029-1243951
   Gono K, 2015, CLIN ENDOSC, V48, P476, DOI 10.5946/ce.2015.48.6.476
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hoffman A, 2010, ENDOSCOPY, V42, P827, DOI 10.1055/s-0030-1255713
   Hoffman A, 2010, DIGEST LIVER DIS, V42, P45, DOI 10.1016/j.dld.2009.04.005
   Hoffman A, 2014, DIGEST LIVER DIS, V46, P991, DOI 10.1016/j.dld.2014.07.169
   Horimatsu T, 2015, INT J COLORECTAL DIS, V30, P947, DOI 10.1007/s00384-015-2230-x
   Hurlstone DP, 2005, ENDOSCOPY, V37, P1186, DOI 10.1055/s-2005-921032
   IJspeert JEG, 2017, GUT, V66, P1225, DOI 10.1136/gutjnl-2015-310784
   Inoue H, 2005, NAT CLIN PRACT GASTR, V2, P31, DOI 10.1038/ncpgasthep0072
   Inoue Haruhiro, 2010, Nihon Rinsho, V68, P1247
   Jin XF, 2012, J GASTROEN HEPATOL, V27, P882, DOI 10.1111/j.1440-1746.2011.06987.x
   Kahi CJ, 2011, CLIN GASTROENTEROL H, V9, P42, DOI 10.1016/j.cgh.2010.09.013
   Kahi CJ, 2010, AM J GASTROENTEROL, V105, P1301, DOI 10.1038/ajg.2010.51
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Kiesslich R, 2004, GASTROENTEROLOGY, V127, P706, DOI 10.1053/j.gastro.2004.06.050
   Kiesslich R, 2003, GASTROENTEROLOGY, V124, P880, DOI 10.1053/gast.2003.50146
   Kim B, 2017, SURG ENDOSC, V31, P594, DOI 10.1007/s00464-016-5003-x
   Klenske E, 2018, DIGEST LIVER DIS, V50, P878, DOI 10.1016/j.dld.2018.06.009
   Klenske E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197520
   Kudo SE, 2011, ENDOSCOPY, V43, P869, DOI 10.1055/s-0030-1256663
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Kudo S, 2020, CLIN GASTROENTEROL H, V18, P1874, DOI 10.1016/j.cgh.2019.09.009
   Kudo SE, 2015, GASTROINTEST ENDOSC, V82, P912, DOI 10.1016/j.gie.2015.04.039
   Kudo T, 2015, DIGEST ENDOSC, V27, P754, DOI 10.1111/den.12469
   Kuiper T, 2012, AM J GASTROENTEROL, V107, P543, DOI 10.1038/ajg.2012.14
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Kutsukawa M, 2014, GASTROINTEST ENDOSC, V79, P648, DOI 10.1016/j.gie.2013.08.029
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Leung WK, 2014, AM J GASTROENTEROL, V109, P855, DOI 10.1038/ajg.2014.83
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Longcroft-Wheaton G, 2012, ENDOSCOPY, V44, P905, DOI 10.1055/s-0032-1310004
   Longcroft-Wheaton GR, 2011, EUR J GASTROEN HEPAT, V23, P903, DOI 10.1097/MEG.0b013e328349e276
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nagorni A, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008361.pub2
   OBRIEN MJ, 1990, GASTROENTEROLOGY, V98, P371, DOI 10.1016/0016-5085(90)90827-N
   Ogawa Y, 2017, ENDOSC INT OPEN, V5, pE769, DOI 10.1055/s-0043-113562
   Ogiso K, 2016, J GASTROENTEROL, V51, P883, DOI 10.1007/s00535-016-1167-3
   dos Santos CEO, 2019, GASTROINTEST ENDOSC, V90, P826, DOI 10.1016/j.gie.2019.06.045
   Omata F, 2014, SCAND J GASTROENTERO, V49, P222, DOI 10.3109/00365521.2013.863964
   Paggi S, 2018, ENDOSCOPY, V50, P396, DOI 10.1055/a-0580-7405
   Pasha SF, 2012, AM J GASTROENTEROL, V107, P363, DOI 10.1038/ajg.2011.436
   Rastogi A, 2014, GASTROINTEST ENDOSC, V79, P390, DOI 10.1016/j.gie.2013.07.032
   Rath T, 2018, DIGEST ENDOSC, V30, P730, DOI 10.1111/den.13251
   Rath T, 2015, WORLD J GASTROENTERO, V21, P11260, DOI 10.3748/wjg.v21.i40.11260
   Rath T, 2015, BMC GASTROENTEROL, V15, DOI 10.1186/s12876-015-0374-3
   Rex DK, 2007, GASTROENTEROLOGY, V133, P42, DOI 10.1053/j.gastro.2007.04.029
   Rex DK, 2015, GASTROINTEST ENDOSC, V82, P376, DOI 10.1016/j.gie.2015.04.029
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Sakata S, 2017, GASTROINTEST ENDOSC, V86, P372, DOI 10.1016/j.gie.2016.11.031
   Sanduleanu S, 2010, CLIN GASTROENTEROL H, V8, P371, DOI 10.1016/j.cgh.2009.08.006
   Sasajima K, 2006, GASTROINTEST ENDOSC, V63, P1010, DOI 10.1016/j.gie.2006.01.021
   Shahid MW, 2012, ENDOSCOPY, V44, P343, DOI 10.1055/s-0031-1291589
   Subramanian V, 2011, ENDOSCOPY, V43, P499, DOI 10.1055/s-0030-1256207
   Subramanian V, 2013, INFLAMM BOWEL DIS, V19, P350, DOI 10.1002/ibd.23002
   Suzuki T, 2017, GASTROINTEST ENDOSC, V86, P692, DOI 10.1016/j.gie.2017.01.044
   Testoni PA, 2012, WORLD J GASTROENTERO, V18, P5231, DOI 10.3748/wjg.v18.i37.5231
   Vleugels JLA, 2017, J CLIN GASTROENTEROL, V51, P426, DOI 10.1097/MCG.0000000000000727
   Vu HT, 2015, DIGEST DIS SCI, V60, P502, DOI 10.1007/s10620-014-3376-z
NR 79
TC 2
Z9 2
U1 0
U2 6
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 2297-4725
EI 2297-475X
J9 VISC MED
JI Visc. Med.
PD FEB
PY 2020
VL 36
IS 1
BP 48
EP 59
DI 10.1159/000505411
PG 12
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA KN6FZ
UT WOS:000514933000009
PM 32110657
OA Green Published, Bronze
DA 2023-08-21
ER

PT J
AU Su, JR
   Li, Z
   Shao, XJ
   Ji, CR
   Ji, R
   Zhou, RC
   Li, GC
   Liu, GQ
   He, YS
   Zuo, XL
   Li, YQ
AF Su, Jing-Ran
   Li, Zhen
   Shao, Xue-Jun
   Ji, Chao-Ran
   Ji, Rui
   Zhou, Ru-Chen
   Li, Guang-Chao
   Liu, Guan-Qun
   He, Yi-Shan
   Zuo, Xiu-Li
   Li, Yan-Qing
TI Impact of a real-time automatic quality control system on colorectal
   polyp and adenoma detection: a prospective randomized controlled study
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Article
ID MISS RATE; COLONOSCOPY; CANCER; PERFORMANCE; RISK; INDICATORS; RATES
AB Background and Aims: Quality control can decrease variations in the performance of colonoscopists and improve the effectiveness of colonoscopy to prevent colorectal cancers. Unfortunately, routine quality control is difficult to carry out because a practical method is lacking. The aim of this study was to develop an automatic quality control system (AQCS) and assess whether it could improve polyp and adenoma detection in clinical practice.
   Methods: First, we developed AQCS based on deep convolutional neural network models for timing of the withdrawal phase, supervising withdrawal stability, evaluating bowel preparation, and detecting colorectal polyps. Next, consecutive patients were prospectively randomized to undergo routine colonoscopies with or without the assistance of AQCS. The primary outcome of the study was the adenoma detection rate (ADR) in the AQCS and control groups.
   Results: A total of 659 patients were enrolled and randomized. A total of 308 and 315 patients were analyzed in the AQCS and control groups, respectively. AQCS significantly increased the ADR (0.289 vs 0.165, P < .001) and the mean number of adenomas per procedure (0.367 vs 0.178, P < .001) compared with the control group. A significant increase was also observed in the polyp detection rate (0.383 vs 0.254, P = .001) and the mean number of polyps detected per procedure (0.575 vs 0.305, P < .001). In addition, the withdrawal time (7.03 minutes vs 5.68 minutes, P < .001) and adequate bowel preparation rate (87.34% vs 80.63%, P = .023) were superior for the AQCS group.
   Conclusions: AQCS could effectively improve the performance of colonoscopists during the withdrawal phase and significantly increase polyp and adenoma detection.
C1 [Su, Jing-Ran; Li, Zhen; Ji, Chao-Ran; Ji, Rui; Zhou, Ru-Chen; Li, Guang-Chao; Liu, Guan-Qun; He, Yi-Shan; Zuo, Xiu-Li; Li, Yan-Qing] Shandong Univ, Qilu Hosp, Dept Gastroenterol, 107 Wenhuaxi Rd, Jinan 250012, Peoples R China.
   [Shao, Xue-Jun] Qingdao Medicon Digital Engn Co Ltd, Qingdao, Shandong, Peoples R China.
C3 Shandong University
RP Li, YQ (通讯作者)，Shandong Univ, Qilu Hosp, Dept Gastroenterol, 107 Wenhuaxi Rd, Jinan 250012, Peoples R China.
EM liyanqing@sdu.edu.cn
RI Li, Zhen/AFK-5293-2022; Li, Zhen/HHM-3328-2022; Li, Yan/K-7292-2012; Li,
   Zhen/AAH-2515-2022
OI Li, Zhen/0000-0002-9783-169X; 
FU Key Research and Development Program of Shandong Province [2018CXGC1209]
FX This study was supported by the Key Research and Development Program of
   Shandong Province (no. 2018CXGC1209).
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Al Kobaisi A, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P359, DOI 10.1109/ICMLA.2018.00060
   Algorry AM, 2017, PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), P516, DOI 10.1109/CSCI.2017.87
   Antioquia A.M.C., 2018, IEEE VISUAL COMMUNIC, P1, DOI 10.1109/VCIP.2018.8698672
   Atkins L, 2016, GASTROINTEST ENDOSC, V83, P617, DOI 10.1016/j.gie.2015.08.075
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chang P, 2018, AM J NEURORADIOL, V39, P1201, DOI 10.3174/ajnr.A5667
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Debnath BK, 2018, IRAN J FUZZY SYST, V15, P1
   Ertam F, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P755, DOI 10.1109/UBMK.2017.8093521
   Jover R, 2012, ENDOSCOPY, V44, P444, DOI 10.1055/s-0032-1306690
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kang XY, 2018, AM J GASTROENTEROL, V113, P601, DOI 10.1038/ajg.2018.25
   Ketwaroo GA, 2015, CURR OPIN GASTROEN, V31, P56, DOI 10.1097/MOG.0000000000000140
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Lee TJW, 2013, ENDOSCOPY, V45, P20, DOI 10.1055/s-0032-1325803
   Lieberman D, 2007, GASTROINTEST ENDOSC, V65, P757, DOI 10.1016/j.gie.2006.12.055
   Lieberman D, 2006, NEW ENGL J MED, V355, P2588, DOI 10.1056/NEJMe068254
   Mehrotra A, 2012, GASTROINTEST ENDOSC, V75, P1233, DOI 10.1016/j.gie.2012.01.045
   Rees CJ, 2016, GUT, V65, P1923, DOI 10.1136/gutjnl-2016-312044
   Rees CJ, 2016, GUT, V65, P2045, DOI 10.1136/gutjnl-2016-312043
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Rex DK, 2000, GASTROINTEST ENDOSC, V51, P33, DOI 10.1016/S0016-5107(00)70383-X
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Siegel RL, 2012, CANCER EPIDEM BIOMAR, V21, P411, DOI 10.1158/1055-9965.EPI-11-1020
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Tang W, 2018, 3 IEEE INT C COMP CO, P1362
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang J, 2017, IEEE T MED IMAGING, V36, P1172, DOI 10.1109/TMI.2017.2655486
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang X, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P439, DOI 10.1109/ICIVC.2018.8492860
NR 38
TC 146
Z9 154
U1 3
U2 28
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD FEB
PY 2020
VL 91
IS 2
BP 415
EP +
DI 10.1016/j.gie.2019.08.026
PG 14
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA KE5AE
UT WOS:000508567300031
PM 31454493
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Wickstrom, K
   Kampffmeyer, M
   Jenssen, R
AF Wickstrom, Kristoffer
   Kampffmeyer, Michael
   Jenssen, Robert
TI Uncertainty and interpretability in convolutional neural networks for
   semantic segmentation of colorectal polyps
SO MEDICAL IMAGE ANALYSIS
LA English
DT Article
DE Polyp segmentation; Decision support systems; Fully convolutional
   networks; Monte carlo dropout; Guided backpropagation; Monte carlo
   guided backpropagation
ID COLONOSCOPY; VALIDATION; DROPOUT
AB Colorectal polyps are known to be potential precursors to colorectal cancer, which is one of the leading causes of cancer-related deaths on a global scale. Early detection and prevention of colorectal cancer is primarily enabled through manual screenings, where the intestines of a patient is visually examined. Such a procedure can be challenging and exhausting for the person performing the screening. This has resulted in numerous studies on designing automatic systems aimed at supporting physicians during the examination. Recently, such automatic systems have seen a significant improvement as a result of an increasing amount of publicly available colorectal imagery and advances in deep learning research for object image recognition. Specifically, decision support systems based on Convolutional Neural Networks (CNNs) have demonstrated state-of-the-art performance on both detection and segmentation of colorectal polyps. However, CNN-based models need to not only be precise in order to be helpful in a medical context. In addition, interpretability and uncertainty in predictions must be well understood. In this paper, we develop and evaluate recent advances in uncertainty estimation and model interpretability in the context of semantic segmentation of polyps from colonoscopy images. Furthermore, we propose a novel method for estimating the uncertainty associated with important features in the input and demonstrate how interpretability and uncertainty can be modeled in DSSs for semantic segmentation of colorectal polyps. Results indicate that deep models are utilizing the shape and edge information of polyps to make their prediction. Moreover, inaccurate predictions show a higher degree of uncertainty compared to precise predictions. (C) 2019 The Authors. Published by Elsevier B.V.
C1 [Wickstrom, Kristoffer; Kampffmeyer, Michael; Jenssen, Robert] UiT Arctic Univ Norway, Dept Phys & Technol, NO-9037 Tromso, Norway.
C3 UiT The Arctic University of Tromso
RP Wickstrom, K (通讯作者)，UiT Arctic Univ Norway, Dept Phys & Technol, NO-9037 Tromso, Norway.
EM kristoffer.k.wickstrom@uit.no
RI Wickstrøm, Kristoffer/AAR-5964-2020
OI Wickstrøm, Kristoffer/0000-0003-1395-7154; Kampffmeyer,
   Michael/0000-0002-7699-0405
CR Alemu Y, 2009, PROCEEDINGS OF THE ASME SUMMER BIOENGINEERING CONFERENCE 2008, PTS A AND B, P1097
   Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   [Anonymous], ARXIV161001644
   [Anonymous], CA CANCER J CLIN, DOI [10.3322/CAAC.21254, DOI 10.3322/caac.21254]
   [Anonymous], 2007, IEEE INT C IMAGE PRO, DOI [10.1109/ICIP.2007.4379193, DOI 10.1109/ICIP.2007.4379193]
   [Anonymous], 2015, P ICLR WORKSH TRACK
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Condessa F, 2012, LECT NOTES COMPUT SC, V7325, P188, DOI 10.1007/978-3-642-31298-4_23
   Dubost F, 2019, MED IMAGE ANAL, V51, P89, DOI 10.1016/j.media.2018.10.008
   Gal Y, 2016, PR MACH LEARN RES, V48
   Guo S, 2019, INT J MED INFORM, V126, P105, DOI 10.1016/j.ijmedinf.2019.03.015
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Ioffe S., 2015, INT C MACHINE LEARNI
   Kendall A., 2015, ARXIV 151102680
   King DB, 2015, ACS SYM SER, V1214, P1
   Larsen I.K., 2016, CANC NORWAY 2015 CAN
   Liu Q., 2017, THESIS
   Nida N, 2019, INT J MED INFORM, V124, P37, DOI 10.1016/j.ijmedinf.2019.01.005
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sharma N, 2010, J MED PHYS, V35, P3, DOI 10.4103/0971-6203.58777
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shwartz-Ziv R., 2017, ARXIV170300810
   Simonyan K, 2015, INT C LEARN REPR, P1
   Simonyan K, 2014, WORKSH INT C LEARN R
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vaswani A, 2017, ADV NEUR IN, V30
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Werbos P., 1974, REGRESSION NEW TOOLS
   Wicke Kai, 2018, 2018 AIAA Aerospace Sciences Meeting, P1
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yu S., 2018, ARXIV180400057
   Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 45
TC 58
Z9 58
U1 8
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1361-8415
EI 1361-8423
J9 MED IMAGE ANAL
JI Med. Image Anal.
PD FEB
PY 2020
VL 60
AR 101619
DI 10.1016/j.media.2019.101619
PG 19
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Biomedical; Radiology,
   Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Radiology, Nuclear Medicine & Medical
   Imaging
GA LG2DC
UT WOS:000527917100026
PM 31810005
OA Green Submitted, hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Majid, A
   Khan, MA
   Yasmin, M
   Rehman, A
   Yousafzai, A
   Tariq, U
AF Majid, Abdul
   Khan, Muhammad Attique
   Yasmin, Mussarat
   Rehman, Amjad
   Yousafzai, Abdullah
   Tariq, Usman
TI Classification of stomach infections: A paradigm of convolutional neural
   network along with classical features fusion and selection
SO MICROSCOPY RESEARCH AND TECHNIQUE
LA English
DT Article
DE CNN features; database preparation; features selection; gastric
   infections; handcrafted features
ID HYBRID FEATURE-SELECTION; BLEEDING DETECTION; GENETIC ALGORITHM;
   SEGMENTATION; IMAGES; ENDOSCOPY; RECOGNITION; DIAGNOSIS; STRATEGY;
   DISEASES
AB Automated detection and classification of gastric infections (i.e., ulcer, polyp, esophagitis, and bleeding) through wireless capsule endoscopy (WCE) is still a key challenge. Doctors can identify these endoscopic diseases by using the computer-aided diagnostic (CAD) systems. In this article, a new fully automated system is proposed for the recognition of gastric infections through multi-type features extraction, fusion, and robust features selection. Five key steps are performed-database creation, handcrafted and convolutional neural network (CNN) deep features extraction, a fusion of extracted features, selection of best features using a genetic algorithm (GA), and recognition. In the features extraction step, discrete cosine transform, discrete wavelet transform strong color feature, and VGG16-based CNN features are extracted. Later, these features are fused by simple array concatenation and GA is performed through which best features are selected based on K-Nearest Neighbor fitness function. In the last, best selected features are provided to Ensemble classifier for recognition of gastric diseases. A database is prepared using four datasets-Kvasir, CVC-ClinicDB, Private, and ETIS-LaribPolypDB with four types of gastric infections such as ulcer, polyp, esophagitis, and bleeding. Using this database, proposed technique performs better as compared to existing methods and achieves an accuracy of 96.5%.
C1 [Majid, Abdul; Yasmin, Mussarat] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
   [Khan, Muhammad Attique; Yousafzai, Abdullah] HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Rawalpindi, Pakistan.
   [Rehman, Amjad] Prince Sultan Univ Riyadh, AIDA Lab CCIS, Riyadh, Saudi Arabia.
   [Tariq, Usman] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci, Al Kharj, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); NITEC University; Prince Sultan
   University; Prince Sattam Bin Abdulaziz University
RP Khan, MA (通讯作者)，HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Rawalpindi, Pakistan.
EM attique@ciitwah.edu.pk
RI Tariq, Usman/AAE-8037-2022; khan, sajid/HGE-2406-2022; Yasmin,
   Mussarat/HPC-9476-2023; Tariq, Usman/AAF-8954-2020; Khan, Dr. Muhammad
   Attique/AAX-2644-2021; Rehman, Amjad/GXV-0915-2022
OI Tariq, Usman/0000-0001-7672-1187; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Rehman, Amjad/0000-0002-3817-2655; Attique
   Khan, Muhammad/0000-0001-7058-0715
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   BLEDSOE WW, 1961, OPER RES, V9, pB145
   *CANC, 2019, STOM CANC STAT
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P2355, DOI 10.1109/LGRS.2017.2764915
   Cogan T, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103351
   Das AK, 2018, APPL SOFT COMPUT, V65, P400, DOI 10.1016/j.asoc.2018.01.040
   De Souza Luis Antonio, 2017, 2017 30 SIBGRAPI C G
   Deeba F, 2018, BIOMED SIGNAL PROCES, V40, P415, DOI 10.1016/j.bspc.2017.10.011
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ghareb AS, 2016, EXPERT SYST APPL, V49, P31, DOI 10.1016/j.eswa.2015.12.004
   Ghatwary N, 2019, IEEE ACCESS, V7, P84374, DOI 10.1109/ACCESS.2019.2925585
   Gunal S, 2012, TURK J ELECTR ENG CO, V20, P1296, DOI 10.3906/elk-1101-1064
   Holland J.H., 1992, ADAPTATION NATURAL A
   Hosseini S., 2018, ARXIV180107848
   Hu Y, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P386, DOI 10.1109/ICISCE.2016.91
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   KHAN MA, 2019, PATTERN RECOGNITION
   KHAN MA, 2019, MED TEACH 0713
   KHAN MA, 2019, 2019 INT C COMP INF
   Khan MA, 2021, NAT PROD RES, V35, P984, DOI 10.1080/14786419.2019.1608546
   Khan MA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12497
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Kim S, 2017, IEEE INFOCOM SER
   KISHORE M, 2015, INT J COMPUTER SCI I, V7, P2074
   Kwolek B, 2005, LECT NOTES COMPUT SC, V3696, P551, DOI 10.1007/11550822_86
   Lee JK, 2020, STRESS, V23, P153, DOI 10.1080/10253890.2019.1660871
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Liu LX, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-9
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Menon S, 2014, ENDOSC INT OPEN, V2, pE46, DOI 10.1055/s-0034-1365524
   Munzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Mussarat S., 2018, J AMB INTEL HUM COMP, DOI DOI 10.1007/S12652-018-1051-5
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pontabry J, 2017, MED IMAGE ANAL, V35, P313, DOI 10.1016/j.media.2016.07.005
   Rajaei A., 2011, INT J ENG SCI, V4, P131
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro MG, 2019, EXPERT SYST APPL, V120, P262, DOI 10.1016/j.eswa.2018.11.034
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Sharma M, 2019, J NEUROSURG-SPINE, V30, P623, DOI 10.3171/2018.10.SPINE18952
   Sharma M, 2019, J NEUROSURG, V131, P489, DOI [10.1007/s40032-017-0423-5, 10.3171/2018.4.JNS172909]
   Shi QQ, 2018, IEEE ACCESS, V6, P38656, DOI 10.1109/ACCESS.2018.2853620
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI [10.3322/caac.21220, 10.3322/caac.21208, 10.3322/caac.21395]
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Swain P, 2003, GUT, V52, P48
   Uuz H., 2011, KNOWL-BASED SYST, V24, P1024, DOI [DOI 10.1016/j.knosys.2011.04.014, 10.1016/j.knosys.2011.04.014, DOI 10.1016/J.KNOSYS.2011.04.014]
   Uysal AK, 2014, EXPERT SYST APPL, V41, P5938, DOI 10.1016/j.eswa.2014.03.041
   Vasilakakis M, 2019, EXPERT REV GASTROENT, V13, P129, DOI 10.1080/17474124.2019.1553616
NR 64
TC 88
Z9 88
U1 1
U2 53
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1059-910X
EI 1097-0029
J9 MICROSC RES TECHNIQ
JI Microsc. Res. Tech.
PD MAY
PY 2020
VL 83
IS 5
BP 562
EP 576
DI 10.1002/jemt.23447
EA JAN 2020
PG 15
WC Anatomy & Morphology; Biology; Microscopy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Anatomy & Morphology; Life Sciences & Biomedicine - Other Topics;
   Microscopy
GA LG2KJ
UT WOS:000509376700001
PM 31984630
DA 2023-08-21
ER

PT J
AU Song, EM
   Park, B
   Ha, CA
   Hwang, SW
   Park, SH
   Yang, DH
   Ye, BD
   Myung, SJ
   Yang, SK
   Kim, N
   Byeon, JS
AF Song, Eun Mi
   Park, Beomhee
   Ha, Chun-Ae
   Hwang, Sung Wook
   Park, Sang Hyoung
   Yang, Dong-Hoon
   Ye, Byong Duk
   Myung, Seung-Jae
   Yang, Suk-Kyun
   Kim, Namkug
   Byeon, Jeong-Sik
TI Endoscopic diagnosis and treatment planning for colorectal polyps using
   a deep-learning model
SO SCIENTIFIC REPORTS
LA English
DT Article
ID CLASSIFICATION; LESIONS; SYSTEM; CARCINOMA; HISTOLOGY; VALIDATION;
   MANAGEMENT; RESECTION; TUMORS
AB We aimed to develop a computer-aided diagnostic system (CAD) for predicting colorectal polyp histology using deep-learning technology and to validate its performance. Near-focus narrow-band imaging (NBI) pictures of colorectal polyps were retrieved from the database of our institution. Of these, 12480 image patches of 624 polyps were used as a training set to develop the CAD. The CAD performance was validated with two test datasets of 545 polyps. Polyps were classified into three histological groups: serrated polyp (SP), benign adenoma (BA)/mucosal or superficial submucosal cancer (MSMC), and deep submucosal cancer (DSMC). The overall kappa value measuring the agreement between the true polyp histology and the expected histology by the CAD was 0.614-0.642, which was higher than that of trainees (n=6, endoscopists with experience of 100 NBI colonoscopies in <6 months; 0.368-0.401) and almost comparable with that of the experts (n=3, endoscopists with experience of 2,500 NBI colonoscopies in >= 5 years) (0.649-0.735). The areas under the receiver operating curves for CAD were 0.93-0.95, 0.86-0.89, and 0.89-0.91 for SP, BA/MSMC, and DSMC, respectively. The overall diagnostic accuracy of the CAD was 81.3-82.4%, which was significantly higher than that of the trainees (63.8-71.8%, P<0.01) and comparable with that of experts (82.4-87.3%). The kappa value and diagnostic accuracies of the trainees improved with CAD assistance: that is, the kappa value increased from 0.368 to 0.655, and the overall diagnostic accuracy increased from 63.8-71.8% to 82.7-84.2%. CAD using a deep-learning model can accurately assess polyp histology and may facilitate the diagnosis of colorectal polyps by endoscopists.
C1 [Song, Eun Mi; Ha, Chun-Ae; Hwang, Sung Wook; Park, Sang Hyoung; Yang, Dong-Hoon; Ye, Byong Duk; Myung, Seung-Jae; Yang, Suk-Kyun; Byeon, Jeong-Sik] Univ Ulsan, Dept Gastroenterol, Asan Med Ctr, Coll Med, Seoul, South Korea.
   [Park, Beomhee] Univ Ulsan, Asan Med Inst Convergence Sci & Technol, Dept Convergence Med, Asan Med Ctr,Coll Med, Seoul, South Korea.
   [Kim, Namkug] Univ Ulsan, Res Inst Radiol, Dept Convergence Med & Radiol, Asan Med Ctr,Coll Med, Seoul, South Korea.
   [Kim, Namkug] Univ Ulsan, Inst Biomed Engn, Coll Med, Asan Med Ctr, Seoul, South Korea.
C3 University of Ulsan; Asan Medical Center; University of Ulsan; Asan
   Medical Center; University of Ulsan; Asan Medical Center; University of
   Ulsan
RP Byeon, JS (通讯作者)，Univ Ulsan, Dept Gastroenterol, Asan Med Ctr, Coll Med, Seoul, South Korea.; Kim, N (通讯作者)，Univ Ulsan, Res Inst Radiol, Dept Convergence Med & Radiol, Asan Med Ctr,Coll Med, Seoul, South Korea.; Kim, N (通讯作者)，Univ Ulsan, Inst Biomed Engn, Coll Med, Asan Med Ctr, Seoul, South Korea.
EM namkugkim@gmail.com; jsbyeon@amc.seoul.kr
RI Yang, Dong-Hoon/B-3437-2015; Park, Sang Hyoung/CAH-4735-2022; Ye, Byong
   Duk/AAF-4955-2020; Kim, Namkug/E-3843-2012
OI Yang, Dong-Hoon/0000-0001-7756-2704; Ye, Byong Duk/0000-0001-6647-6325;
   Kim, Namkug/0000-0002-3438-2217
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [NRF-2017R1A2B4005846]; Korea Health Technology R&D Project grant
   through the Korea Health Industry Development Institute (KHIDI) -
   Ministry of Health & Welfare, Republic of Korea [HI18C2383]; Korea
   Health Promotion Institute [HR18C0016020020] Funding Source: Korea
   Institute of Science & Technology Information (KISTI), National Science
   & Technology Information Service (NTIS)
FX This work was supported by a National Research Foundation of Korea (NRF)
   grant funded by the Korean government (MSIT) (grant number:
   NRF-2017R1A2B4005846); and the Korea Health Technology R&D Project grant
   through the Korea Health Industry Development Institute (KHIDI), funded
   by the Ministry of Health & Welfare, Republic of Korea (grant number:
   HI18C2383).
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   [Anonymous], 2016, P IEEE C COMP VIS PA
   Bartel MJ, 2016, DIGEST ENDOSC, V28, P330, DOI 10.1111/den.12598
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dai J, 2013, DIGEST ENDOSC, V25, P180, DOI 10.1111/j.1443-1661.2012.01367.x
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   East JE, 2015, GUT, V64, P991, DOI 10.1136/gutjnl-2014-309041
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Guo CG, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126237
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Huang G., P IEEE C COMP VIS PA, P3
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Khalid O, 2009, WORLD J GASTROENTERO, V15, P3767, DOI 10.3748/wjg.15.3767
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nakadoi K, 2012, J GASTROEN HEPATOL, V27, P1057, DOI 10.1111/j.1440-1746.2011.07041.x
   Pohl J, 2008, AM J GASTROENTEROL, V103, P562, DOI 10.1111/j.1572-0241.2007.01670.x
   Sano Y, 2016, DIGEST ENDOSC, V28, P526, DOI 10.1111/den.12644
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Watanabe T, 2012, INT J CLIN ONCOL, V17, P1, DOI 10.1007/s10147-011-0315-2
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhou B., P IEEE C COMP VIS PA, P2921
NR 28
TC 47
Z9 47
U1 6
U2 8
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JAN 8
PY 2020
VL 10
IS 1
AR 30
DI 10.1038/s41598-019-56697-0
PG 10
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA KI5WJ
UT WOS:000511420200012
PM 31913337
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Ashour, AS
   Dey, N
   Mohamed, WS
   Tromp, JG
   Sherratt, RS
   Shi, FQ
   Moraru, L
AF Ashour, Amira S.
   Dey, Nilanjan
   Mohamed, Waleed S.
   Tromp, Jolanda G.
   Sherratt, R. Simon
   Shi, Fuqian
   Moraru, Luminita
TI Colored Video Analysis in Wireless Capsule Endoscopy: A Survey of
   State-of-the-Art
SO CURRENT MEDICAL IMAGING
LA English
DT Review
DE Endoscopy capsule; video analysis; bleeding detection; reviewing time
   reduction; wireless video gastrointestinal (GI) endoscopy capsule;
   computer- aided diagnosis
ID INVARIANT TEXTURE CLASSIFICATION; HYBRID NEURAL-NETWORK; PUSH
   ENTEROSCOPY; TRANSIT-TIME; SMALL-BOWEL; GRAY-SCALE; IMAGES; ROTATION;
   SYSTEM; OPTIMIZATION
AB Wireless Capsule Endoscopy (WCE) is a highly promising technology for gastrointestinal (GI) tract abnormality diagnosis. However, low image resolution and low frame rates are challenging issues in WCE. In addition, the relevant frames containing the features of interest for accurate diagnosis only constitute 1% of the complete video information. For these reasons, analyzing the WCE videos is still a time consuming and laborious examination for the gastroenterologists, which reduces WCE system usability. This leads to the emergent need to speed-up and automates the WCE video process for GI tract examinations. Consequently, the present work introduced the concept of WCE technology, including the structure of WCE systems, with a focus on the medical endoscopy video capturing process using image sensors. It discussed also the significant characteristics of the different GI tract for effective feature extraction. Furthermore, video approaches for bleeding and lesion detection in the WCE video were reported with computer-aided diagnosis systems in different applications to support the gastroenterologist in the WCE video analysis. In image enhancement, WCE video review time reduction is also discussed, while reporting the challenges and future perspectives, including the new trend to employ the deep learning models for feature Learning, polyp recognition, and classification, as a new opportunity for researchers to develop future WCE video analysis techniques.
C1 [Ashour, Amira S.] Tanta Univ, Fac Engn, Dept Elect & Elect Commun Engn, Tanta 31527, Egypt.
   [Dey, Nilanjan] Techno India Coll Technol, Dept Informat Technol, Kolkata 740000, W Bengal, India.
   [Mohamed, Waleed S.] Tanta Univ, Fac Med, Dept Internal Med, Tanta 31527, Egypt.
   [Tromp, Jolanda G.] Duy Tan Univ, Ctr Visualizat & Simulat, Comp Sci Dept, Da Nang, Vietnam.
   [Sherratt, R. Simon] Univ Reading, Dept Biomed Engn, Reading, Berks, England.
   [Shi, Fuqian] Rutgers State Univ, Rutgers Canc Inst New Jersey, New Brunswick, NJ 08903 USA.
   [Moraru, Luminita] Dunarea de Jos Univ Galati, Fac Sci & Environm, Galati, Romania.
C3 Egyptian Knowledge Bank (EKB); Tanta University; Egyptian Knowledge Bank
   (EKB); Tanta University; Duy Tan University; University of Reading;
   Rutgers State University New Brunswick; Rutgers State University Medical
   Center; Rutgers Cancer Institute of New Jersey; Dunarea De Jos
   University Galati
RP Ashour, AS (通讯作者)，Tanta Univ, Fac Engn, Dept Elect & Elect Commun Engn, Tanta 31527, Egypt.
EM amira.salah@f-eng.tanta.edu.eg
RI Moraru, Luminita/A-8532-2012; Ashour, Amira S./T-5454-2019
OI Moraru, Luminita/0000-0002-9121-5714; Ashour, Amira
   S./0000-0003-3217-6185
CR Ahmed SS, 2017, MED BIOL ENG COMPUTI
   AlShahrani A.M, 2018, COMPUTER VISION CONC, P1208, DOI DOI 10.4018/978-1-5225-5204-8.CH050
   [Anonymous], 2015, THESIS
   Appleyard M, 2000, GASTROENTEROLOGY, V119, P1431, DOI 10.1053/gast.2000.20844
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Berens J, 2000, IEE P-VIS IMAGE SIGN, V147, P349, DOI 10.1049/ip-vis:20000630
   Boulougoura M, 2004, 2 INT C BIOM ENG
   Bourbakis N, 2005, NEURAL NETWORK BASED, DOI [10.1109/BIBE.2005.6, DOI 10.1109/BIBE.2005.6]
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   Chu X, 2010, EPITOMIZED SUMMARIZA, DOI [10.1007/978-3-642-15745-5_64, DOI 10.1007/978-3-642-15745-5_64]
   Ciuti G, 2016, J MICRO-BIO ROBOT, V11, P1, DOI 10.1007/s12213-016-0087-x
   Connah D, 2006, P EUR C COL GRAPH IM, V1, P60
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Dalal N., 2005, 2005 IEEE COMP SOC C, V1, P886, DOI DOI 10.1109/CVPR.2005.177
   Dey N., 2016, CLASSIFICATION CLUST
   Dey N, 2019, OPTIK, V183, P483, DOI 10.1016/j.ijleo.2019.02.118
   Dey Nilanjan, 2017, IEEE Rev Biomed Eng, V10, P2, DOI 10.1109/RBME.2017.2697950
   Drozdzal M, 2013, COMPUT MED IMAG GRAP, V37, P72, DOI 10.1016/j.compmedimag.2012.09.002
   Eliakim R, 2003, EUR J GASTROEN HEPAT, V15, P363, DOI 10.1097/00042737-200304000-00005
   Figueiredo IN, 2010, AUTOMATIC DETECTION, P10
   Fisher L, 2010, GASTROINTEST ENDOSC, V72, P471, DOI 10.1016/j.gie.2010.04.032
   Gong YH, 1996, MULTIMED TOOLS APPL, V2, P133, DOI 10.1023/A:1018095010693
   Gopi Varun P., 2013, International Journal of Imaging & Robotics, V9, P48
   Hafner M, 2013, COMP MED SY, P185, DOI 10.1109/CBMS.2013.6627786
   Hai V, 2006, INT C PATT RECOG, P980
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jia X, 2016, DEEP CONVOLUTIONAL N, DOI [10.1109/EMBC.2016.7590783, DOI 10.1109/EMBC.2016.7590783]
   Jung YS, ACTIVE BLOOD DETECTI
   Karargyris A, 2010, ELASTIC VIDEO INTERP
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Koulaouzidis A, 2013, ANN GASTROENTEROL, V26, P365
   Kriti, 2016, INTEL SYST REF LIBR, V96, P159, DOI 10.1007/978-3-319-21212-8_7
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Kwack WG, 2016, CLIN ENDOSC, V49, P8, DOI 10.5946/ce.2016.49.1.8
   Lee J, 2007, AUTOMATIC CLASSIFICA, DOI [10.1145/1244002.1244230, DOI 10.1145/1244002.1244230]
   Lewis BS, 2002, GASTROINTEST ENDOSC, V56, P349, DOI 10.1067/mge.2002.126906
   Li B, 2009, 2009 IEEE RSJ INT C
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li BP, 2009, COMPUT BIOL MED, V39, P141, DOI 10.1016/j.compbiomed.2008.11.007
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Malagelada C, 2008, GASTROENTEROLOGY, V135, P1155, DOI 10.1053/j.gastro.2008.06.084
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mirjalili S, 2012, APPL MATH COMPUT, V218, P11125, DOI 10.1016/j.amc.2012.04.069
   Moglia Andrea, 2008, Recent Patents on Biomedical Engineering, V1, P24, DOI 10.2174/1874764710801010024
   Mylonaki M, 2003, GUT, V52, P1122, DOI 10.1136/gut.52.8.1122
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Okuhata H, 2013, APPL REAL TIME RETIN
   Ramaraj M, 2013, HOMOMORPHIC FILTERIN
   Razmjooy N, 2018, OPEN MED-WARSAW, V13, P9, DOI 10.1515/med-2018-0002
   Razmjooy N, 2013, MATH COMPUT MODEL, V57, P848, DOI 10.1016/j.mcm.2012.09.013
   Saba L, 2016, COMPUT METH PROG BIO, V130, P118, DOI 10.1016/j.cmpb.2016.03.016
   Segui S, 2016, IB C PATT REC SPRING, P326
   Sekuboyina AK, 2017, CONVOLUTIONAL NEURAL
   Spyridonos P, 2006, LECT NOTES COMPUT SC, V4191, P161
   Szczypinski PM, 2009, MED IMAGE ANAL, V13, P312, DOI 10.1016/j.media.2008.12.002
   Szczypinski PM, 2004, 12 UN EUR GASTR WEEK, V36, pA76
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Toth E, 2017, ANN TRANSL MED, V5, DOI 10.21037/atm.2017.03.79
   Triester SL, 2005, AM J GASTROENTEROL, V100, P2407, DOI 10.1111/j.1572-0241.2005.00274.x
   Vilarino F, 2006, INT C PATT RECOG, P719
   Vilarino F, 2006, LECT NOTES COMPUT SC, V4225, P178
   Vilarino F, 2010, IEEE T MED IMAGING, V29, P246, DOI 10.1109/TMI.2009.2020753
   Vu H, 2009, COMPUT BIOL MED, V39, P16, DOI 10.1016/j.compbiomed.2008.10.005
   Wang A, 2013, GASTROINTEST ENDOSC, V78, P805, DOI 10.1016/j.gie.2013.06.026
   Wang CL, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293303
   Wang P, 2001, CLASSIFICATION ENDOS, DOI [10.1109/IEMBS.2001.1019637, DOI 10.1109/IEMBS.2001.1019637]
   Xin WH, 2010, INT J MED ROBOT COMP, V6, P113, DOI 10.1002/rcs.298
   Yagi Y., 2007, Inflammopharmacology, V15, P78, DOI 10.1007/s10787-006-0010-5
   Yu LC, 2012, INT C PATT RECOG, P45
   Yuan Y, 2013, HIERARCHICAL KEY FRA
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhao Q, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P948, DOI 10.1109/WCICA.2011.5970656
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 79
TC 3
Z9 3
U1 4
U2 16
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1573-4056
EI 1875-6603
J9 CURR MED IMAGING
JI Curr. Med. Imaging
PY 2020
VL 16
IS 9
BP 1074
EP 1084
DI 10.2174/1573405616666200124140915
PG 11
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA PG6IR
UT WOS:000599837400002
PM 32107996
OA Green Accepted
DA 2023-08-21
ER

PT J
AU Deeba, F
   Bui, FM
   Wahid, KA
AF Deeba, Farah
   Bui, Francis M.
   Wahid, Khan A.
TI Computer-aided polyp detection based on image enhancement and
   saliency-based selection
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Histogram of gradients; Polyp detection; Capsule endoscopy
ID CAPSULE ENDOSCOPY; PREVENTION; DIAGNOSIS; FEATURES
AB This paper presents a computer-aided polyp detection algorithm applicable to both colonoscopy and wireless capsule endoscopy (WCE). The proposed system has three integral parts: image enhancement, saliency map formation and Histogram of gradients (HOG) feature extraction for final classification. We propose a novel and efficient image enhancement algorithm, which enhances the saliency of clinically important features in endoscopic images. A saliency detection method is applied to the enhanced images to highlight the initial polyp candidates. In the classification stage, polyp candidates are selected after performing an image enhancement step and a saliency detection step. Exhaustive experiments have been performed on three publicly available databases: CVC ColonDB, CVC ClinicDB, and ETIS Larib to evaluate the performance of the proposed polyp detection algorithm. Comparison with the state-of-the-art methods shows that the proposed method outperforms the existing ones in terms of recall (=86.33%) and F2 score (=75.51%) for CVC ColonDB and in terms of recall (=74.04%) for the ETIS Larib dataset. With a significantly reduced number of search windows resulting from the saliency-based selection, the proposed scheme ensures a cost-effective and efficient polyp detection algorithm. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Deeba, Farah; Bui, Francis M.; Wahid, Khan A.] Univ Saskatchewan, Elect & Comp Engn, Saskatoon, SK, Canada.
C3 University of Saskatchewan
RP Deeba, F (通讯作者)，Univ Saskatchewan, Elect & Comp Engn, Saskatoon, SK, Canada.
EM farah.deeba@usask.ca
RI Deeba, Farah/AAJ-1923-2020
OI Deeba, Farah/0000-0001-9217-5032; Bui, Francis/0000-0002-8799-5965
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX This work was supported by the Natural Sciences and Engineering Research
   Council of Canada (NSERC).
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Altobelli E, 2014, PREV MED, V62, P132, DOI 10.1016/j.ypmed.2014.02.010
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], ISSCS 2013 INT S SIG
   [Anonymous], 2007, P ICIP
   Aranda-Hernandez J, 2016, WORLD J GASTROENTERO, V22, P1767, DOI 10.3748/wjg.v22.i5.1767
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   BOND JH, 1993, ANN INTERN MED, V119, P836, DOI 10.7326/0003-4819-119-8-199310150-00010
   Braun GJ, 1999, J ELECTRON IMAGING, V8, P380, DOI 10.1117/1.482706
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deeba F, 2016, IEEE ENG MED BIO, P3871, DOI 10.1109/EMBC.2016.7591573
   Forsyth D, 2014, COMPUTER, V47, P6, DOI 10.1109/MC.2014.42
   Gado A, 2013, ALEX J MED, V49, P25, DOI 10.1016/j.ajme.2012.08.005
   Hwang S., 2011, LECT NOTES COMPUT SC, V6939, P320
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Imperiale TF, 2009, GASTROINTEST ENDOSC, V69, P1288, DOI 10.1016/j.gie.2007.11.043
   Iwahori Y., 2013, INT C MACH VIS APPL, P21
   Jang JY, 2012, CLIN ENDOSC, V45, P379, DOI 10.5946/ce.2012.45.4.379
   Karargyris A, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P143, DOI 10.1109/LISSA.2009.4906730
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Koulaouzidis A, 2013, WORLD J GASTROENTERO, V19, P3726, DOI 10.3748/wjg.v19.i24.3726
   Li BP, 2012, J MED SYST, V36, P2463, DOI 10.1007/s10916-011-9713-2
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li DL, 2009, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON RISK MANAGEMENT & GLOBAL E-BUSINESS, VOLS I AND II, P1022
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Park DY, 2008, ARCH PATHOL LAB MED, V132, P633, DOI 10.1043/1543-2165(2008)132[633:GPCAM]2.0.CO;2
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Rahtu Esa, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1137, DOI 10.1109/ICCVW.2009.5457577
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Shussman N, 2014, GASTROENTEROL REP, V2, P1, DOI 10.1093/gastro/got041
   Sieg A, 2009, AM J GASTROENTEROL, V104, P848, DOI 10.1038/ajg.2008.163
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2014, I S BIOMED IMAGING, P97, DOI 10.1109/ISBI.2014.6867818
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Wallace JL, 2016, DIGEST DIS SCI, V61, P1, DOI 10.1007/s10620-015-3963-7
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Zhao Q, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P948, DOI 10.1109/WCICA.2011.5970656
NR 47
TC 32
Z9 33
U1 2
U2 16
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD JAN
PY 2020
VL 55
AR 101530
DI 10.1016/j.bspc.2019.04.007
PG 8
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA JW2NA
UT WOS:000502893200013
DA 2023-08-21
ER

PT J
AU Jia, X
   Xing, XH
   Yuan, YX
   Xing, L
   Meng, MQH
AF Jia, Xiao
   Xing, Xiaohan
   Yuan, Yixuan
   Xing, Lei
   Meng, Max Q. -H.
TI Wireless Capsule Endoscopy: A New Tool for Cancer Screening in the Colon
   With Deep-Learning-Based Polyp Recognition
SO PROCEEDINGS OF THE IEEE
LA English
DT Article
DE Cancer screening; deep learning; polyp recognition; wireless capsule
   endoscopy (WCE)
ID GENERATIVE ADVERSARIAL NETWORKS; CONVOLUTIONAL NEURAL-NETWORK; CT IMAGE;
   CLASSIFICATION; SEGMENTATION; AUTOENCODERS; COLONOSCOPY; VALIDATION;
   DIAGNOSIS; PATHOLOGY
AB Accurate recognition of polyps is crucial for early colorectal cancer diagnosis and treatment. Wireless capsule endoscopy (WCE) is a noninvasive, wireless imaging tool that allows direct visualization of the entire colon without discomfort to patients and has the potential to revolutionize the screening workup for colorectal diseases. However, current manual review is laborious and time consuming, requiring the undivided concentration of the gastroenterologist. Computational methods that can assist automated polyp recognition will enhance the outcome both in terms of diagnostic accuracy and efficiency of WCE. This review introduces the computer-assisted algorithms as applied to colorectal polyp screening, focusing on the successes of deep-learning-based strategies in the WCE sequences. We survey key applications of WCE polyp recognition, covering deep-learning-based image-level classification, lesion region detection, and pixel-accurate segmentation. We conclude by discussing emerging research challenges, possible trends, and future directions.
C1 [Jia, Xiao; Xing, Xiaohan; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Yuan, Yixuan] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Xing, Lei] Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94305 USA.
   [Meng, Max Q. -H.] Chinese Univ Hong Kong, Shenzhen Res Inst, Shenzhen 518172, Guangdong, Peoples R China.
C3 Chinese University of Hong Kong; City University of Hong Kong; Stanford
   University; Chinese University of Hong Kong, Shenzhen; CUHK Shenzhen
   Research Institute
RP Meng, MQH (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM xjia@ee.cuhk.edu.hk; xhxing@ee.cuhk.edu.hk; yxyuan.ee@cityu.edu.hk;
   lei@stanford.edu; max.meng@ieee.org
RI meng, meng/GWZ-7461-2022
OI Xing, Lei/0000-0003-2536-5359; Meng, Max Q.-H./0000-0002-5255-5898;
   Yuan, Yixuan/0000-0002-0853-6948; Xing, Xiaohan/0000-0002-9992-3387
FU Hong Kong Research Grants Council (RGC) Collaborative Research Fund
   (CRF) Project [C4063-18GF]; Shenzhen Science and Technology Innovation
   Project [JCYJ20170413161503220]
FX The work of M. Q.-H. Meng was supported in part by the Hong Kong
   Research Grants Council (RGC) Collaborative Research Fund (CRF) Project
   under Grant C4063-18GF and in part by the Shenzhen Science and
   Technology Innovation Project under Grant JCYJ20170413161503220. (Xiao
   Jia, Xiaohan Xing, and Yixuan Yuan contributed equally to this work.)
CR American Cancer Society, 2017, COL CANC FACTS FIG 2
   [Anonymous], 2015, DEEP LEARNING NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], [No title captured]
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baehrens D, 2010, J MACH LEARN RES, V11, P1803
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Blanz W. E., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P272, DOI 10.1109/ICPR.1990.119369
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen H, 2018, NEUROIMAGE, V170, P446, DOI 10.1016/j.neuroimage.2017.04.041
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Constantinescu AF, 2016, ROM J MORPHOL EMBRYO, V57, P979
   David E, 2013, P INT S SIGN CIRC SY, P1
   Diamantis DE, 2019, BIOMED SIGNAL PROCES, V49, P192, DOI 10.1016/j.bspc.2018.12.005
   Diamantis D, 2018, IEEE IMAGE PROC, P3124, DOI 10.1109/ICIP.2018.8451673
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Eliakim R, 2006, ENDOSCOPY, V38, P963, DOI 10.1055/s-2006-944832
   FISHER M, 2013, COLOR MED IMAGE ANAL, P129
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Frid-Adar M, 2018, I S BIOMED IMAGING, P289, DOI 10.1109/ISBI.2018.8363576
   Georgakopoulos SV, 2016, IEEE CONF IMAGING SY, P510, DOI 10.1109/IST.2016.7738279
   Gibson E, 2018, IEEE T MED IMAGING, V37, P1822, DOI 10.1109/TMI.2018.2806309
   Girshick R., 2014, P IEEE C COMP VIS PA, P580, DOI DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gorzalczany MB, 2017, EXPERT SYST APPL, V71, P26, DOI 10.1016/j.eswa.2016.11.017
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hong SN, 2018, CLIN ENDOSC, V51, P334, DOI 10.5946/ce.2018.121
   Huang C, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1423, DOI 10.1145/3269206.3271793
   Huang G., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243
   Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Janowczyk A, 2017, COMPUT MED IMAG GRAP, V57, P50, DOI 10.1016/j.compmedimag.2016.05.003
   Jeatrakul P, 2010, LECT NOTES COMPUT SC, V6444, P152, DOI 10.1007/978-3-642-17534-3_19
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Jin YM, 2018, IEEE T MED IMAGING, V37, P1114, DOI 10.1109/TMI.2017.2787657
   Johnson J. W., 2018, ARXIV180500500
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kallenberg M, 2016, IEEE T MED IMAGING, V35, P1322, DOI 10.1109/TMI.2016.2532122
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kermany Daniel, 2018, Mendeley Data, V3
   Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044
   Kooi T, 2017, MED PHYS, V44, P1017, DOI 10.1002/mp.12110
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lan LB, 2019, IEEE ACCESS, V7, P30017, DOI 10.1109/ACCESS.2019.2901568
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee HG, 2013, COMPUT BIOL MED, V43, P670, DOI 10.1016/j.compbiomed.2013.02.009
   Lei HJ, 2018, PATTERN RECOGN, V79, P290, DOI 10.1016/j.patcog.2018.02.006
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   LI KM, 2018, ARXIV180708332
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu HY, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P102, DOI 10.1109/PACRIM.2011.6032875
   Liu JM, 2017, MED PHYS, V44, P4630, DOI 10.1002/mp.12399
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long MZ, 2018, IEEE T BIOMED CIRC S, V12, P993, DOI 10.1109/TBCAS.2018.2869530
   Maghsoudi O. H., 2016, PROC IEEE SIGNAL PRO, P1
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Min SB, 2019, AAAI CONF ARTIF INTE, P4578, DOI 10.1609/aaai.v33i01.33014578
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   MOLLINEDA R, 2007, P C ESP INF, P84
   Nie Dong, 2017, Med Image Comput Comput Assist Interv, V10435, P417, DOI 10.1007/978-3-319-66179-7_48
   Nie D, 2016, LECT NOTES COMPUT SC, V10008, P170, DOI 10.1007/978-3-319-46976-8_18
   OQUAB M, 2015, PROC CVPR IEEE, P685, DOI DOI 10.1109/CVPR.2015.7298668
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P112, DOI 10.1145/3083187.3083189
   Radford A., 2016, PROC 4 INT C LEARN R
   Raina R., 2007, P 24 INT C MACHINE L, P759, DOI DOI 10.1145/1273496.1273592
   RAMACHANDRAN SS, 2018, P SOC PHOTO-OPT INS
   Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romain O, 2013, IEEE 13 INT C BIOINF, P1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sa R, 2017, IEEE ENG MED BIO, P564, DOI 10.1109/EMBC.2017.8036887
   Sae Hwang, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P320, DOI 10.1007/978-3-642-24031-7_32
   Sarikaya D, 2017, IEEE T MED IMAGING, V36, P1542, DOI 10.1109/TMI.2017.2665671
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277
   Silva J, 2013, IEEE ENG MED BIO, P5711, DOI 10.1109/EMBC.2013.6610847
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Singeap AM, 2016, WORLD J GASTROENTERO, V22, P369, DOI 10.3748/wjg.v22.i1.369
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.2012.09.004, 10.1016/j.cmpb.7017.09.004]
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tao GH, 2018, ADV NEUR IN, V31
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Van Gossum A, 2009, NEW ENGL J MED, V361, P264, DOI 10.1056/NEJMoa0806347
   VASILAKAKIS MD, 2018, EVOLVING SYST, P1
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang YR, 2016, IEEE IMAGE PROC, P111, DOI 10.1109/ICIP.2016.7532329
   Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Xing XH, 2018, IEEE ENG MED BIO, P3594, DOI 10.1109/EMBC.2018.8513012
   XU L, 2018, P SOC PHOTO-OPT INS
   Yan Xu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P496, DOI 10.1007/978-3-319-46723-8_57
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   Yim S, 2014, IEEE T BIO-MED ENG, V61, P513, DOI 10.1109/TBME.2013.2283369
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
   Yuan L, 2014, RSC ADV, V4, P30259, DOI 10.1039/c4ra05012f
   Yuan YX, 2019, MED PHYS, V46, P756, DOI 10.1002/mp.13367
   Yuan YX, 2018, LECT NOTES COMPUT SC, V11071, P620, DOI 10.1007/978-3-030-00934-2_69
   Yuan YX, 2018, IEEE T CYBERNETICS, V48, P2074, DOI 10.1109/TCYB.2017.2726818
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2017, IEEE T AUTOM SCI ENG, V14, P149, DOI 10.1109/TASE.2016.2610579
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Yuan YX, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P225, DOI 10.1109/ICMA.2013.6617922
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JK, 2016, INT SYM COMPUT INTEL, P363, DOI [10.1109/ISCID.2016.89, 10.1109/ISCID.2016.1090]
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang ZZ, 2018, PROC CVPR IEEE, P9242, DOI 10.1109/CVPR.2018.00963
   Zhang ZZ, 2017, PROC CVPR IEEE, P3549, DOI 10.1109/CVPR.2017.378
   Zhao Q, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P948, DOI 10.1109/WCICA.2011.5970656
   ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319
   Zhou B., 2018, ARXIV PREPRINT ARXIV
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
NR 147
TC 32
Z9 32
U1 4
U2 53
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9219
EI 1558-2256
J9 P IEEE
JI Proc. IEEE
PD JAN
PY 2020
VL 108
IS 1
BP 178
EP 197
DI 10.1109/JPROC.2019.2950506
PG 20
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA KA4TS
UT WOS:000505790500010
DA 2023-08-21
ER

PT J
AU Khan, MA
   Kadry, S
   Alhaisoni, M
   Nam, Y
   Zhang, YD
   Rajinikanth, V
   Sarfraz, MS
AF Khan, Muhammad Attique
   Kadry, Seifedine
   Alhaisoni, Majed
   Nam, Yunyoung
   Zhang, Yudong
   Rajinikanth, Venkatesan
   Sarfraz, Muhammad Shahzad
TI Computer-Aided Gastrointestinal Diseases Analysis From Wireless Capsule
   Endoscopy: A Framework of Best Features Selection
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Stomach; Cancer; Image color analysis; Hemorrhaging;
   Support vector machines; Gastrointestinal tract; Stomach diseases; WCE;
   saliency estimation; deep learning; features selection; features
   classification
ID NEURAL-NETWORK; CLASSIFICATION; RECOGNITION; FUSION; IMAGES;
   SEGMENTATION; ALGORITHM
AB The continuous improvements in the area of medical imaging, makes the patient monitoring a crucial concern. The internet of things (IoT) embedded in a medical technologies to collect data from human body through sensors, wireless connectivity etc. The junction of medicine and IT like medical informatics will transform healthcare, curbing cost, make more efficient, and saving lives. Various computerized techniques are implemented in the area of Artificial Intelligence (AI) for the application of medical imaging to diagnose the infected regions in the images and videos such as WCE and pathology. The famous stomach infections are ulcer, polyp, and bleeding. Stomach cancer is the most common infection and a leading cause of human deaths worldwide. In the USA, since 2019, a total of 27,510 new cases are reported including 17,230 men and 10,230 women. While the number of deaths is 11,140 consists of 6,800 men and 4,340 women. The manual diagnosis of these stomach infections is a difficult and agitated process therefore it is required to design a fully automated system using AI. In this article, we presented a fully automated system for stomach infection recognition based on deep learning features fusion and selection. In this design, ulcer images are assigned manually and support to a saliency-based method for ulcer detection. Later, pre-trained deep learning model named VGG16 is employing and re-trained using transfer learning. Features of re-trained model are extracted from two consecutive fully connected layers and fused by array-based approach. Besides, the best individuals are selected through the metaheuristic approach name PSO along mean value-based fitness function. The selected individuals are finally recognized through Cubic SVM. The experiments are conducted on Private collected dataset and achieved an accuracy of 98.4%, which is best as compared to existing state-of-the-art techniques.
C1 [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.
   [Kadry, Seifedine] Beirut Arab Univ, Fac Sci, Dept Math & Comp Sci, Beirut 11072809, Lebanon.
   [Alhaisoni, Majed] Univ Hail, Coll Comp Sci & Engn, Hail 55476, Saudi Arabia.
   [Nam, Yunyoung] Soonchunhyang Univ, Dept Comp Sci & Engn, Asan 31538, South Korea.
   [Zhang, Yudong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
   [Rajinikanth, Venkatesan] St Josephs Coll Engn, Dept Elect & Instrumentat Engn, Chennai 600119, Tamil Nadu, India.
   [Sarfraz, Muhammad Shahzad] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Chiniot Faisalabad Campus, Islamabad 44000, Pakistan.
C3 NITEC University; Beirut Arab University; University Ha'il;
   Soonchunhyang University; University of Leicester; St. Joseph's College
   of Engineering, Chennai
RP Khan, MA (通讯作者)，HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.; Nam, Y (通讯作者)，Soonchunhyang Univ, Dept Comp Sci & Engn, Asan 31538, South Korea.
EM attique@ciitwah.edu.pk; ynam@sch.ac.kr
RI Zhang, Yida/T-2546-2018; ALHAISONI, MAJED/ABF-7642-2021; VENKATESAN,
   RAJINIKANTH/F-6734-2011; Khan, Dr. Muhammad Attique/AAX-2644-2021; khan,
   sajid/HGE-2406-2022; Kadry, Seifedine/C-7437-2011; Zhang,
   Yudong/I-7633-2013; Rajinikanth, V/X-9395-2018
OI Zhang, Yida/0000-0002-1505-6678; VENKATESAN,
   RAJINIKANTH/0000-0003-3897-4460; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Kadry, Seifedine/0000-0002-1939-4842;
   Zhang, Yudong/0000-0002-4870-1493; Rajinikanth, V/0000-0003-3897-4460;
   Nam, Yunyoung/0000-0002-3318-9394; Attique Khan,
   Muhammad/0000-0001-7058-0715
FU Korea Institute for Advancement of Technology (KIAT) - Korea Government
   (MOTIE) [P0012724]; Soonchunhyang University Research Fund
FX This research was supported by Korea Institute for Advancement of
   Technology (KIAT) grant funded by the Korea Government (MOTIE)
   (P0012724, The Competency Development Program for Industry Specialist)
   and the Soonchunhyang University Research Fund.
CR Agrawal T., 2017, CEUR WORKSHOP PROC
   Anwar MZ, 2019, IEEE T VEH TECHNOL, V68, P2526, DOI 10.1109/TVT.2019.2893615
   Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Athi, 2019, TEXT FEAT EXTR GLDM
   Barbosa DJC, 2009, IEEE ENG MED BIO, P6683, DOI 10.1109/IEMBS.2009.5334013
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Charleer Sven, 2018, IEEE Transactions on Learning Technologies, V11, P389, DOI 10.1109/TLT.2017.2720670
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P2355, DOI 10.1109/LGRS.2017.2764915
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Deeba F, 2018, BIOMED SIGNAL PROCES, V40, P415, DOI 10.1016/j.bspc.2017.10.011
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Ghatwary N, 2019, IEEE ACCESS, V7, P84374, DOI 10.1109/ACCESS.2019.2925585
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu Y, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P386, DOI 10.1109/ICISCE.2016.91
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MA, 2020, NEURAL COMPUT APPL, V32, P15929, DOI 10.1007/s00521-019-04514-0
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P909, DOI 10.1002/jemt.23238
   Khan MA, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105986
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, MULTIMED TOOLS APPL, V78, P27743, DOI 10.1007/s11042-019-07875-9
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Khan SA, 2019, MICROSC RES TECHNIQ, V82, P1256, DOI 10.1002/jemt.23275
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kundu AK, 2017, TENCON IEEE REGION, P1300, DOI 10.1109/TENCON.2017.8228058
   Kwolek B, 2005, LECT NOTES COMPUT SC, V3696, P551, DOI 10.1007/11550822_86
   Lee JH, 2019, SURG ENDOSC, V33, P3790, DOI 10.1007/s00464-019-06677-2
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Mergener Klaus, 2008, Gastroenterol Hepatol (N Y), V4, P107
   Munzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Najarian K., 2018, ARXIV PREPRINT ARXIV
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sharif M, 2021, J EXP THEOR ARTIF IN, V33, P577, DOI 10.1080/0952813X.2019.1572657
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Shi QQ, 2018, IEEE ACCESS, V6, P38656, DOI 10.1109/ACCESS.2018.2853620
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI [10.3322/caac.21220, 10.3322/caac.21208, 10.3322/caac.21395]
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   Suman S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095731
   Suman S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101097
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Xu GP, 2019, SWARM EVOL COMPUT, V45, P33, DOI 10.1016/j.swevo.2018.12.009
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Yuan YX, 2016, IEEE J BIOMED HEALTH, V20, P624, DOI 10.1109/JBHI.2015.2399502
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zhao H., 2017, P IEEE C COMP VIS PA, P1
NR 55
TC 76
Z9 76
U1 2
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 132850
EP 132859
DI 10.1109/ACCESS.2020.3010448
PG 10
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MS6FU
UT WOS:000554370100001
OA gold
DA 2023-08-21
ER

PT J
AU Khan, MA
   Sarfraz, MS
   Alhaisoni, M
   Albesher, AA
   Wang, SH
   Ashraf, I
AF Khan, Muhammad Attique
   Sarfraz, Muhammad Shahzad
   Alhaisoni, Majed
   Albesher, Abdulaziz A.
   Wang, Shuihua
   Ashraf, Imran
TI StomachNet: Optimal Deep Learning Features Fusion for Stomach
   Abnormalities Classification
SO IEEE ACCESS
LA English
DT Article
DE Licenses; Stomach infections; contrast stretching; deep learning;
   optimization; fusion
ID WIRELESS CAPSULE ENDOSCOPY; GASTROINTESTINAL-DISEASES; ENHANCEMENT;
   CHALLENGES; IMAGES
AB A fully automated design is proposed in this work employing optimal deep learning features for classifying gastrointestinal infections. Here, three prominent infections- ulcer, bleeding, polyp and a healthy class are considered as class labels. In the initial stage, the contrast is improved by fusing bi-directional histogram equalization with top-hat filtering output. The resultant fusion images are then passed to ResNet101 pre-trained model and trained once again using deep transfer learning. However, there are challenges involved in extracting deep learning features including impertinent information and redundancy. To mitigate this problem, we took advantage of two metaheuristic algorithms- Enhanced Crow Search and Differential Evolution. These algorithms are implemented in parallel to obtain optimal feature vectors. Following this, a maximum correlation-based fusion approach is applied to fuse optimal vectors from the previous step to obtain an enhanced vector. This final vector is given as input to Extreme Learning Machine (ELM) classifier for final classification. The proposed method is evaluated on a combined database. It accomplished an accuracy of 99.46%, which shows significant improvement over preceding techniques and other neural network architectures.
C1 [Khan, Muhammad Attique; Ashraf, Imran] HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.
   [Sarfraz, Muhammad Shahzad] Natl Univ Comp & Emerging Sci Chiniot Faisalabad, Dept Comp Sci, Chiniot 35400, Pakistan.
   [Alhaisoni, Majed] Univ Hail, Coll Comp Sci & Engn, Hail 50141, Saudi Arabia.
   [Albesher, Abdulaziz A.] Saudi Elect Univ, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
   [Wang, Shuihua] Univ Leicester, Dept Math, Leicester LE1 7RH, Leics, England.
C3 NITEC University; University Ha'il; Saudi Electronic University;
   University of Leicester
RP Ashraf, I (通讯作者)，HITEC Univ, Dept Comp Sci, Taxila 47080, Pakistan.; Albesher, AA (通讯作者)，Saudi Elect Univ, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
EM a.albesher@seu.edu.sa; imran.ashraf@hitecuni.edu.pk
RI khan, sajid/HGE-2406-2022; ashraf, imran/HJA-5212-2022; ALHAISONI,
   MAJED/ABF-7642-2021; Wang, Shuihua/G-7326-2016; Khan, Dr. Muhammad
   Attique/AAX-2644-2021
OI ashraf, imran/0000-0003-4480-2489; Wang, Shuihua/0000-0003-4713-2791;
   Khan, Dr. Muhammad Attique/0000-0002-6347-4890; Attique Khan,
   Muhammad/0000-0001-7058-0715; albesher, abdulaziz/0000-0002-4879-9128
CR Alaskar H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061265
   [Anonymous], CA CANCER J CLIN, DOI [10.3322/CAAC.21254, DOI 10.3322/caac.21254]
   [Anonymous], 2018, J AMBIENT INTELL HUM, DOI 10.1007/s12652-018-1051-5
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen F, 2020, PATTERN RECOGN LETT, V136, P309, DOI 10.1016/j.patrec.2020.04.033
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fireman Z, 2003, GUT, V52, P390, DOI 10.1136/gut.52.3.390
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Iandola Forrest N., 2016, ARXIV
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2020, MULTIMED TOOLS APPL, DOI [10.1007/s11042-020-08806-9, 10.1007/978-3-030-23045-6_1, 10.1680/jmacr.19.00226]
   Khan MA, 2021, MICROSC RES TECHNIQ, V84, P202, DOI 10.1002/jemt.23578
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Khan MA, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1466-3
   Khan MA, 2019, MULTIMED TOOLS APPL, V78, P27743, DOI 10.1007/s11042-019-07875-9
   Khan SA, 2020, J MED IMAG HEALTH IN, V10, P2523, DOI 10.1166/jmihi.2020.3222
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kundu AK, 2020, IEEE ACCESS, V8, P58509, DOI 10.1109/ACCESS.2020.2982870
   Kuo CFJ, 2019, INT J IMAG SYST TECH, V29, P132, DOI 10.1002/ima.22307
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Little S. G., 2006, TECH REP
   Lu XX, 2020, NEW ENGL J MED, V382, P1663, DOI 10.1056/NEJMc2005073
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Mehmood I, 2019, MULTIMED TOOLS APPL, V78, P12723, DOI 10.1007/s11042-018-6027-0
   Muhammad K, 2020, FUTURE GENER COMP SY, V113, P266, DOI 10.1016/j.future.2020.06.048
   Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800
   Naheed N, 2020, CMES-COMP MODEL ENG, V125, P1, DOI 10.32604/cmes.2020.011380
   Ouadfel S, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113572
   Price K. V., 2006, DIFFERENTIAL EVOLUTI
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rehman A., MICROSC RES TECHNIQ
   Sharif M, 2021, J EXP THEOR ARTIF IN, V33, P577, DOI 10.1080/0952813X.2019.1572657
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Szegedy C., 2015, PROC IEEE C COMPUT V, DOI DOI 10.1109/CVPR.2015.7298594
   Torrey L., 2010, HDB RES MACHINE LEAR, P242, DOI 10.4018/978-1-60566-766-9.ch011
   Yeh J-Y, 2014, J SOFTWARE ENG APPL, V7, P422, DOI DOI 10.4236/JSEA.2014.75039
NR 43
TC 62
Z9 62
U1 4
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 197969
EP 197981
DI 10.1109/ACCESS.2020.3034217
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA OS7GJ
UT WOS:000590327700001
OA gold
DA 2023-08-21
ER

PT J
AU Liu, WN
   Zhang, YY
   Bian, XQ
   Wang, LJ
   Yang, Q
   Zhang, XD
   Huang, J
AF Liu, Wen-Na
   Zhang, Yang-Yang
   Bian, Xu-Qiang
   Wang, Li-Juan
   Yang, Qiang
   Zhang, Xi-Dou
   Huang, Jin
TI Study on detection rate of polyps and adenomas in
   artificial-intelligence-aided colonoscopy
SO SAUDI JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Adenoma; artificial intelligence; colonoscopy; detection rate; polyp
ID COLORECTAL-CANCER; CLASSIFICATION; PREVENTION; DIAGNOSIS; LESIONS; RISK
AB Background/Aim: To study the impact of computer-aided detection (CADe) system on the detection rate of polyps and adenomas in colonoscopy.
   Materials and Methods: A total of 1026 patients were prospectively randomly scheduled for colonoscopy with (the CADe group, CADe) or without (the control group, CON) the aid of the CADe system, together with visual notification and voice alarm, so as to compare the detection rate of polyp.
   Results: Compared with group CON, the detection rate of adenomas increased in group CADe, the average number of adenomas increased, the number of small adenomas increased, the number of proliferative polyps increased, and the differences were statistically significant (P < 0.001), but the comparison for the number of larger adenomas showed no significant difference between the groups (P > 0.05).
   Conclusions: The CADe system is feasible for increasing the detection of polyps and adenomas in colonoscopy.
C1 [Liu, Wen-Na; Zhang, Yang-Yang; Bian, Xu-Qiang; Wang, Li-Juan; Yang, Qiang; Zhang, Xi-Dou; Huang, Jin] 988 Hosp Joint Logist Support Force PLA, Dept Digest Endoscopy, Zhengzhou 450000, Peoples R China.
RP Huang, J (通讯作者)，988 Hosp Joint Logist Support Force PLA, Dept Digest Endoscopy, Zhengzhou 450000, Peoples R China.
EM jinhuangdoc@126.com
RI zhang, yangyang/GZG-7467-2022
CR Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chen SC, 2007, AM J GASTROENTEROL, V102, P856, DOI 10.1111/j.1572-0241.2006.01054.x
   Chin M, 2016, WORLD J GASTROENTERO, V22, P9642, DOI 10.3748/wjg.v22.i43.9642
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Halpern Z, 2015, ENDOSCOPY, V47, P238, DOI 10.1055/s-0034-1391437
   Horton N, 2016, AM J GASTROENTEROL, V111, P1330, DOI 10.1038/ajg.2016.273
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Marcondes FO, 2018, DIGEST DIS SCI, V63, P856, DOI 10.1007/s10620-018-4947-1
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 24
TC 85
Z9 86
U1 1
U2 9
PU WOLTERS KLUWER MEDKNOW PUBLICATIONS
PI MUMBAI
PA WOLTERS KLUWER INDIA PVT LTD , A-202, 2ND FLR, QUBE, C T S  NO 1498A-2
   VILLAGE MAROL, ANDHERI EAST, MUMBAI, Maharashtra, INDIA
SN 1319-3767
EI 1998-4049
J9 SAUDI J GASTROENTERO
JI Saudi J. Gastroenterol.
PD JAN-FEB
PY 2020
VL 26
IS 1
BP 13
EP 19
AR PMID 31898644
DI 10.4103/sjg.SJG_377_19
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA LC9NG
UT WOS:000525660100003
PM 31898644
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Meng, J
   Xue, LY
   Chang, Y
   Zhang, JG
   Chang, SL
   Liu, K
   Liu, S
   Wang, BM
   Yang, K
AF Meng, Jie
   Xue, Linyan
   Chang, Ying
   Zhang, Jianguang
   Chang, Shilong
   Liu, Kun
   Liu, Shuang
   Wang, Bangmao
   Yang, Kun
TI Automatic detection and segmentation of adenomatous colorectal polyps
   during colonoscopy using Mask R-CNN
SO OPEN LIFE SCIENCES
LA English
DT Article
DE CRC; adenomatous polyps; CAD; CNN; colonoscopy
ID REAL-TIME; CANCER; POLYPECTOMY; PREVENTION; GUIDELINES
AB Colorectal cancer (CRC) is one of the main alimentary tract system malignancies affecting people worldwide. Adenomatous polyps are precursors of CRC, and therefore, preventing the development of these lesions may also prevent subsequent malignancy. However, the adenoma detection rate (ADR), a measure of the ability of a colonoscopist to identify and remove precancerous colorectal polyps, varies significantly among endoscopists. Here, we attempt to use a convolutional neural network (CNN) to generate a unique computer-aided diagnosis (CAD) system by exploring in detail the multiple-scale performance of deep neural networks. We applied this system to 3,375 hand-labeled images from the screening colonoscopies of 1,197 patients; of whom, 3,045 were assigned to the training dataset and 330 to the testing dataset. The images were diagnosed simply as either an adenomatous or non-adenomatous polyp. When applied to the testing dataset, our CNN-CAD system achieved a mean average precision of 89.5%. We conclude that the proposed framework could increase the ADR and decrease the incidence of interval CRCs, although further validation through large multicenter trials is required.
C1 [Meng, Jie; Wang, Bangmao] Tianjin Med Univ, Dept Gastroenterol & Hepatol, Gen Hosp, Tianjin 300052, Peoples R China.
   [Xue, Linyan; Chang, Shilong; Liu, Kun; Liu, Shuang; Yang, Kun] Hebei Univ, Coll Qual & Tech Supervis, Baoding 071002, Peoples R China.
   [Meng, Jie; Chang, Ying; Zhang, Jianguang] Hebei Univ, Affiliated Hosp, Dept Gastroenterol, Baoding 071000, Peoples R China.
C3 Tianjin Medical University; Hebei University; Hebei University
RP Wang, BM (通讯作者)，Tianjin Med Univ, Dept Gastroenterol & Hepatol, Gen Hosp, Tianjin 300052, Peoples R China.; Yang, K (通讯作者)，Hebei Univ, Coll Qual & Tech Supervis, Baoding 071002, Peoples R China.
EM mwang02@tmu.edu.cn; hbuyangkun@163.com
FU Foundation of Hebei University [DXK201914]; Natural Science Foundation
   of Hebei Province [H2019201378]; President fund of Hebei University
   [XZJJ201914]
FX This work was funded by the Foundation of Hebei University (DXK201914),
   the Natural Science Foundation of Hebei Province (H2019201378) and the
   President fund of Hebei University (XZJJ201914).
CR Anderson JC, 2015, CLIN TRANSL GASTROEN, V6, DOI 10.1038/ctg.2015.5
   [Anonymous], 2019, IEEE ACCESS
   [Anonymous], 1997, ADV NEURAL INFORM PR
   [Anonymous], 2016, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2016.90, 10.1109/CVPR.2016.90]
   [Anonymous], 2015, PROC CVPR IEEE
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Brenner H, 2011, ANN INTERN MED, V154, P22, DOI 10.7326/0003-4819-154-1-201101040-00004
   Byrne MF, 2017, GASTROINTEST ENDOSC, V85, pAB364, DOI 10.1016/j.gie.2017.03.843
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang X, 2019, COMPUT MED IMAG GRAP, V74, P25, DOI 10.1016/j.compmedimag.2019.02.003
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Levine JS, 2006, NEW ENGL J MED, V355, P2551, DOI 10.1056/NEJMcp063038
   Li TB, 2016, GASTROINTEST ENDOSC, V83, pAB482, DOI 10.1016/j.gie.2016.03.671
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Pignone M, 2002, ANN INTERN MED, V137, P96, DOI 10.7326/0003-4819-137-2-200207160-00007
   Potter JD, 1999, JNCI-J NATL CANCER I, V91, P916, DOI 10.1093/jnci/91.11.916
   Rex DK, 2009, AM J GASTROENTEROL, V104, P739, DOI 10.1038/ajg.2009.104
   Simonyan K., 2013, ARXIV13126034
   Sun WQ, 2017, COMPUT MED IMAG GRAP, V57, P4, DOI 10.1016/j.compmedimag.2016.07.004
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 34
TC 7
Z9 7
U1 2
U2 8
PU DE GRUYTER POLAND SP Z O O
PI WARSAW
PA BOGUMILA ZUGA 32A STR, 01-811 WARSAW, MAZOVIA, POLAND
SN 2391-5412
J9 OPEN LIFE SCI
JI Open Life Sci.
PY 2020
VL 15
IS 1
BP 588
EP 596
DI 10.1515/biol-2020-0055
PG 9
WC Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics
GA NH4XQ
UT WOS:000564675100001
PM 33817247
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Nadimi, ES
   Buijs, MM
   Herp, J
   Kroijer, R
   Kobaek-Larsen, M
   Nielsen, E
   Pedersen, CD
   Blanes-Vidal, V
   Baatrup, G
AF Nadimi, Esmaeil S.
   Buijs, Maria M.
   Herp, Jurgen
   Kroijer, Rasmus
   Kobaek-Larsen, Morten
   Nielsen, Emilie
   Pedersen, Claus D.
   Blanes-Vidal, Victoria
   Baatrup, Gunnar
TI Application of deep learning for autonomous detection and localization
   of colorectal polyps in wireless colon capsule endoscopy
SO COMPUTERS & ELECTRICAL ENGINEERING
LA English
DT Article
DE Colorectal polyps; Colon capsule endoscopy (CCE); Deep learning; Machine
   learning; Convolutional neural networks
AB Recent advances in deep learning have prompted a surge of interest in analysis of medical images. In this study, we developed a convolutional neural network (CNN) for autonomous detection of colorectal polyps, in images captured during wireless colon capsule endoscopy, with risk of malignant evolution to colorectal cancer. Our CNN is an improved version of ZF-Net which uses a combination of transfer learning, pre-processing and data augmentation. We further deployed our CNN as the basis for a Faster R-CNN to localize regions of images containing colorectal polyps. We created an image database of 11,300 capsule endoscopy images from a screening population, including colorectal polyps (any size or morphology, N=4800) and normal mucosa (N=6500). Our CNN scored an accuracy of 98.0%, a sensitivity of 98.1% and a specificity of 96.3%. Our network outperforms all state-of-the-art results in autonomous detection of colorectal polyps and shows high interpretability in terms of sensitive regions. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Nadimi, Esmaeil S.; Herp, Jurgen; Blanes-Vidal, Victoria] Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Grp Appl AI & Data Sci, Odense, Denmark.
   [Buijs, Maria M.; Kroijer, Rasmus; Kobaek-Larsen, Morten; Baatrup, Gunnar] Odense Univ Hosp, Dept Surg, Odense, Denmark.
   [Buijs, Maria M.; Kroijer, Rasmus; Kobaek-Larsen, Morten; Baatrup, Gunnar] Univ Southern Denmark, Dept Clin Res, Odense, Denmark.
   [Nielsen, Emilie; Pedersen, Claus D.] Odense Univ Hosp, Ctr Innovat Med Technol, Odense, Denmark.
C3 University of Southern Denmark; University of Southern Denmark; Odense
   University Hospital; University of Southern Denmark; University of
   Southern Denmark; Odense University Hospital
RP Nadimi, ES (通讯作者)，Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Grp Appl AI & Data Sci, Odense, Denmark.
EM esi@mmmi.sdu.dk
RI Blanes-Vidal, Victoria/B-5196-2019; Nadimi, Esmaeil S/B-5289-2019
OI Blanes-Vidal, Victoria/0000-0002-9269-4526; Nadimi, Esmaeil
   S/0000-0003-2613-2696; Kroijer, Rasmus/0000-0003-4358-7916;
   Kobaek-Larsen, Morten/0000-0002-5097-9283; baatrup,
   gunnar/0000-0003-0300-5766
FU University of Southern Denmark; Odense University Hospital; Danish
   Cancer Society; Region of Southern Denmark, through the Project EFFICACY
FX This research was financially supported in part by a research grant from
   the University of Southern Denmark, Odense University Hospital, Danish
   Cancer Society and Region of Southern Denmark, through the Project
   EFFICACY. The Quadro P6000 GPU card used for this research was
   generously donated by NVIDIA Corporation.
CR Blanes-Vidal V, 2018, INT J COLORECTAL DIS
   Bujanda L, 2010, WORLD J GASTROENTERO, V16, P3103, DOI 10.3748/wjg.v16.i25.3103
   He K, 2018, ARXIV151203385V1
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Jia J, 2014, US Patent, Patent No. [14/471:143, 201414471143]
   Kobaek-Larsen M, 2018, COLORECTAL DIS, V20, P479, DOI 10.1111/codi.13965
   Kodogiannis VS, 2007, INT J INFORM TECHNOL, V13, P46
   Krizhevsky A., NIPS 2012
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Mohammed A. K., 2019, P BRIT MACH VIS C BM, P1
   Murino A, 2016, CURR OPIN GASTROEN, V32, P38, DOI 10.1097/MOG.0000000000000230
   Nadimi ES, 2017, 27 IEEE INT WORKSH M, DOI [10.1109/MLSP.2017.8168115, DOI 10.1109/MLSP.2017.8168115]
   Pogorelov Konstantin, 2018, 2018 IEEE 31 INT S C
   Puig I, 2018, GUT LIVER, V12, P385, DOI 10.5009/gnl17137
   Shaoqing R, 2015, ADV NEURAL INF PROCE, V28
   Simonyan K, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34553-x
   Surya-Prasath V.B, 2018, ARXIV160901915
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Urban G, 2018, GASTROENTEROLOGY
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zeiler M, ICCV 2012
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 25
TC 29
Z9 29
U1 6
U2 22
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0045-7906
EI 1879-0755
J9 COMPUT ELECTR ENG
JI Comput. Electr. Eng.
PD JAN
PY 2020
VL 81
AR 106531
DI 10.1016/j.compeleceng.2019.106531
PG 9
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KT0BH
UT WOS:000518675000030
DA 2023-08-21
ER

PT J
AU Nguyen, NQ
   Vo, DM
   Lee, SW
AF Ngoc-Quang Nguyen
   Duc My Vo
   Lee, Sang-Woong
TI Contour-Aware Polyp Segmentation in Colonoscopy Images Using Detailed
   Upsamling Encoder-Decoder Networks
SO IEEE ACCESS
LA English
DT Article
DE Cancer; Image segmentation; Colonoscopy; Feature extraction; Training;
   Decoding; Colon; Polyp segmentation; hierarchical collaborative
   representation-based classification; local ternary patterns; deep
   convolutional neural network; colorectal segmentation
AB Colorectal cancer has become one of the most common cause of cancer mortality worldwide, with a five-year survival rate of over 50%. Additionally, the potential of some common polyp types to progress to colorectal cancer is considered high. Colonoscopy is the most common method for finding and removing polyps. However, during colonoscopy, a significant number of polyps is missed as a result of human error mistakes. Thus, this study was primarily motivated by the need to obtain an early and accurate diagnosis of polyps detected in colonoscopy images. In this paper, we propose a new polyp segmentation method based on an architecture of multi-model deep encoder-decoder networks called MED-Net. Not only does this architecture obtain multi-level contextual information by extracting discriminative features at different effective fields-of-view and multiple image scales, it also can substantially do upsample more correctly to produce better prediction. It is also able to capture more accurate polyp boundaries by using multi-scale effective decoders. Moreover, we also present a complementary strategy for improving the method's segmentation performance based on a combination of a boundary-aware data augmentation method and an effective weighted loss function. The purpose of this strategy is to allow our deep learning network to sequentially focus on poorly defined polyp boundaries, which are caused by the non-specular transition zone between the polyp and non-polyp regions. To provide a general view of the proposed method, our network was trained and evaluated on four well-known dataset CVC-ColonDB, CVC-ClinicDB, ASU-Mayo Clinic Colonoscopy Video Database, and ETIS-LaribPolypDB. Our results show that our MED-Net significantly outperforms state-of-the-art methods.
C1 [Ngoc-Quang Nguyen; Duc My Vo; Lee, Sang-Woong] Gachon Univ, Pattern Recognit & Machine Learning Lab, Seongnam 13120, South Korea.
C3 Gachon University
RP Lee, SW (通讯作者)，Gachon Univ, Pattern Recognit & Machine Learning Lab, Seongnam 13120, South Korea.
EM slee@gachon.ac.kr
RI Lee, Sang-Woong/ABF-6191-2020
OI Lee, Sang-Woong/0000-0001-8117-6566; Nguyen, Quang/0000-0002-7448-535X
FU Gyeonggi-do Regional Research Center (GRRC) Program of Gyeonggi Province
   through the Analysis of Behavior Based on Senior Life Log
   [GRRC-2017-B01]
FX This work was supported by the Gyeonggi-do Regional Research Center
   (GRRC) Program of Gyeonggi Province through the Analysis of Behavior
   Based on Senior Life Log under Grant GRRC-2017-B01.
CR Abadi M., 2015, P 12 USENIX C OPERAT, DOI [DOI 10.5555/3026877.3026899, DOI 10.1038/NN.3331]
   Akbari M., 2018, ARXIV180200368
   [Anonymous], 2011, COL CANC FACTS FIG 2
   Arshad M, 2020, BRAZ J PROBAB STAT, V34, P167, DOI 10.1214/18-BJPS407
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bengio Y., 2016, ADAPTIVE COMPUTATION
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bradski G., 2008, LEARNING OPENCV COMP
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Breier M, 2011, PROC SPIE, V7963, DOI 10.1117/12.877986
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen YT, 2019, NEURAL NETWORKS, V110, P170, DOI 10.1016/j.neunet.2018.11.009
   Cho K., 2014, PROC C EMPIRICAL MET, P1724, DOI DOI 10.3115/V1/D14-1179
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Duc Bui T., 2017, ARXIV170903199
   Vo DM, 2019, INFORM SCIENCES, V482, P123, DOI 10.1016/j.ins.2018.12.089
   Vo DM, 2018, MULTIMED TOOLS APPL, V77, P18689, DOI 10.1007/s11042-018-5653-x
   Vo DM, 2018, INFORM SCIENCES, V432, P332, DOI 10.1016/j.ins.2017.12.014
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Haj-Manouchehri A, 2020, IET COMPUT VIS, V14, P241, DOI 10.1049/iet-cvi.2019.0300
   Han C, 2020, SMART INNOV SYST TEC, V151, P291, DOI 10.1007/978-981-13-8950-4_27
   Hassan C, 2020, GUT, V69, P799, DOI 10.1136/gutjnl-2019-319914
   Holland O, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500442
   Holschneider M., 1989, WAVELETS, P289, DOI DOI 10.1007/978-3-642-75988-8_28
   Huang FM, 2020, LANDSLIDES, V17, P217, DOI 10.1007/s10346-019-01274-9
   Izmailov P, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P876
   Jia X, 2020, IEEE T AUTOM SCI ENG, V17, P1570, DOI 10.1109/TASE.2020.2964827
   Jia YQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1631, DOI 10.1109/ROBIO.2015.7419005
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kucharski D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061546
   Lee K, 2020, J COMPUT PHYS, V404, DOI 10.1016/j.jcp.2019.108973
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Liang-Chieh Chen, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11211), P833, DOI 10.1007/978-3-030-01234-2_49
   Liu P, 2020, IEEE ACCESS, V8, P34029, DOI 10.1109/ACCESS.2020.2973707
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmood F, 2019, PROC SPIE, V10950, DOI 10.1117/12.2513117
   Nguyen NQ, 2019, IEEE ACCESS, V7, P33795, DOI 10.1109/ACCESS.2019.2904094
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Ouali Y., 2020, ARXIV200309005
   Papandreou G, 2015, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2015.7298636
   Park HC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051650
   Perl Y. S., 2020, DATA AUGMENTATION BA
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Siegel R, 2014, CA-CANCER J CLIN, V64, P104, DOI [10.3322/caac.21220, 10.3322/caac.21208, 10.3322/caac.21395]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tao Y, 2017, CHIN CONTR CONF, P4288, DOI 10.23919/ChiCC.2017.8028032
   Tian Z., 2019, ARXIV190302120
   Varkarakis V, 2020, NEURAL NETWORKS, V121, P101, DOI 10.1016/j.neunet.2019.07.020
   Wang LS, 2018, GUT, V67, pA84, DOI 10.1136/gutjnl-2018-IDDFabstracts.181
   Wojna Z, 2019, INT J COMPUT VISION, V127, P1694, DOI 10.1007/s11263-019-01170-8
   Wu Z, 2005, INT J PROD RES, V43, P3027, DOI 10.1080/00207540500057639
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang Y, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101664
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou Q, 2019, WORLD WIDE WEB, V22, P555, DOI 10.1007/s11280-018-0556-3
NR 67
TC 16
Z9 16
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 99495
EP 99508
DI 10.1109/ACCESS.2020.2995630
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LZ3KT
UT WOS:000541127800047
OA gold
DA 2023-08-21
ER

PT J
AU Patino-Barrientos, S
   Sierra-Sosa, D
   Garcia-Zapirain, B
   Castillo-Olea, C
   Elmaghraby, A
AF Patino-Barrientos, Sebastian
   Sierra-Sosa, Daniel
   Garcia-Zapirain, Begonya
   Castillo-Olea, Cristian
   Elmaghraby, Adel
TI Kudo's Classification for Colon Polyps Assessment Using a Deep Learning
   Approach
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE colon cancer; deep learning; image processing; medical dataset; VGG
ID COLONOSCOPY; DIAGNOSIS
AB Colorectal cancer (CRC) is the second leading cause of cancer death in the world. This disease could begin as a non-cancerous polyp in the colon, when not treated in a timely manner, these polyps could induce cancer, and in turn, death. We propose a deep learning model for classifying colon polyps based on the Kudo's classification schema, using basic colonoscopy equipment. We train a deep convolutional model with a private dataset from the University of Deusto with and without using a VGG model as a feature extractor, and compared the results. We obtained 83% of accuracy and 83% of F1-score after fine tuning our model with the VGG filter. These results show that deep learning algorithms are useful to develop computer-aided tools for early CRC detection, and suggest combining it with a polyp segmentation model for its use by specialists.
C1 [Patino-Barrientos, Sebastian] Univ EAFIT, Apolo Sci Comp Ctr, Medellin 50035, Colombia.
   [Sierra-Sosa, Daniel; Elmaghraby, Adel] Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA.
   [Garcia-Zapirain, Begonya; Castillo-Olea, Cristian] Univ Deusto, eVida Res Grp, Bilbao, Spain.
C3 Universidad EAFIT; University of Louisville; University of Deusto
RP Sierra-Sosa, D (通讯作者)，Univ Louisville, Dept Comp Sci & Engn, Louisville, KY 40292 USA.
EM spatino6@eafit.edu.co; desier01@louisville.edu; mbgarciazapi@deusto.es;
   cristian.castillo@deusto.es; adel@louisville.edu
RI Elmaghraby, Adel S/B-3353-2014; Zapirain, Begoña Garcia/L-5619-2014;
   Sierra-Sosa, Daniel/AAP-4610-2020; Sierra-Sosa, Daniel/AAP-4604-2020
OI Elmaghraby, Adel S/0000-0001-5274-8596; Zapirain, Begoña
   Garcia/0000-0002-9356-1186; Sierra-Sosa, Daniel/0000-0003-1326-0867;
   Sierra-Sosa, Daniel/0000-0003-1326-0867; Castillo olea,
   Cristian/0000-0002-8717-7524
FU Basque Government "Aids for health research projects"; Basque Government
   Department of Education (eVIDA Certified Group) [IT905-16]
FX This research was supported by the Basque Government "Aids for health
   research projects" and the publication fees supported by the Basque
   Government Department of Education (eVIDA Certified Group IT905-16).
CR Antipov G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1263, DOI 10.1145/2733373.2806332
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Holzinger A, 2018, LECT NOTES COMPUT SC, V11015, P1, DOI 10.1007/978-3-319-99740-7_1
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Li TB, 2016, GASTROINTEST ENDOSC, V83, pAB482, DOI 10.1016/j.gie.2016.03.671
   Lieberman DA, 2000, NEW ENGL J MED, V343, P162, DOI 10.1056/NEJM200007203430301
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Navarro M, 2017, WORLD J GASTROENTERO, V23, P3632, DOI 10.3748/wjg.v23.i20.3632
   Neilson LJ, 2015, FRONTLINE GASTROENTE, V6, P117, DOI 10.1136/flgastro-2015-100565
   Sanchez-Gonzalez A, 2018, COMPUT BIOL MED, V100, P152, DOI 10.1016/j.compbiomed.2018.07.002
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Tanaka S, 2006, GASTROINTEST ENDOSC, V64, P604, DOI 10.1016/j.gie.2006.06.007
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 19
TC 18
Z9 18
U1 9
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD JAN
PY 2020
VL 10
IS 2
AR 501
DI 10.3390/app10020501
PG 7
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA KY4LI
UT WOS:000522540400077
OA gold
DA 2023-08-21
ER

PT J
AU Qadir, HA
   Balasingham, I
   Solhusvik, J
   Bergsland, J
   Aabakken, L
   Shin, Y
AF Qadir, Hemin Ali
   Balasingham, Ilangko
   Solhusvik, Johannes
   Bergsland, Jacob
   Aabakken, Lars
   Shin, Younghak
TI Improving Automatic Polyp Detection Using CNN by Exploiting Temporal
   Dependency in Colonoscopy Video
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Detectors; Feature extraction; Sensitivity; Proposals; Colonoscopy;
   Convolutional neural networks; Cancer; Colonoscopy; polyp detection;
   computer aided diagnosis; convolutional neural networks; false positive
   learning; transfer learning; temporal information
ID VALIDATION
AB Automatic polyp detection has been shown to be difficult due to various polyp-like structures in the colon and high interclass variations in polyp size, color, shape, and texture. An efficient method should not only have a high correct detection rate (high sensitivity) but also a low false detection rate (high precision and specificity). The state-of-the-art detection methods include convolutional neural networks (CNN). However, CNNs have shown to be vulnerable to small perturbations and noise; they sometimes miss the same polyp appearing in neighboring frames and produce a high number of false positives. We aim to tackle this problem and improve the overall performance of the CNN-based object detectors for polyp detection in colonoscopy videos. Our method consists of two stages: a region of interest (RoI) proposal by CNN-based object detector networks and a false positive (FP) reduction unit. The FP reduction unit exploits the temporal dependencies among image frames in video by integrating the bidirectional temporal information obtained by RoIs in a set of consecutive frames. This information is used to make the final decision. The experimental results show that the bidirectional temporal information has been helpful in estimating polyp positions and accurately predict the FPs. This provides an overall performance improvement in terms of sensitivity, precision, and specificity compared to conventional false positive learning method, and thus achieves the state-of-the-art results on the CVC-ClinicVideoDB video data set.
C1 [Qadir, Hemin Ali] Oslo Univ Hosp, OmniVis Technol, Intervent Ctr, N-0337 Oslo, Norway.
   [Qadir, Hemin Ali; Solhusvik, Johannes] Univ Oslo, Dept Informat, N-0315 Oslo, Norway.
   [Balasingham, Ilangko; Bergsland, Jacob] Oslo Univ Hosp, Intervent Ctr, N-0337 Oslo, Norway.
   [Balasingham, Ilangko; Shin, Younghak] Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.
   [Solhusvik, Johannes] OmniVis Technol, N-0337 Oslo, Norway.
   [Aabakken, Lars] Univ Oslo, Fac Med, Dept Transplantat, N-0315 Oslo, Norway.
   [Aabakken, Lars] Oslo Univ Hosp, N-0337 Oslo, Norway.
C3 University of Oslo; University of Oslo; University of Oslo; Norwegian
   University of Science & Technology (NTNU); University of Oslo;
   University of Oslo
RP Shin, Y (通讯作者)，Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.
EM hemina.qadir@gmail.com; ilangko.balasingham@medisin.uio.no;
   johannes.solhusvik@ovt.com; jacobbergsland622@gmail.com;
   larsaa@medisin.uio.no; shinyh0919@gmail.com
RI Bergsland, Jacob/H-3966-2016; Balasingham, Ilangko/AGU-7268-2022
OI Bergsland, Jacob/0000-0002-3101-4064
FU Research Council of Norway through the industrial Ph.D. project
   [271542/O30]; Research Council of Norway through MELODY project
   [225885/O70]
FX This work was supported by Research Council of Norway through the
   industrial Ph.D. project under the contract number 271542/O30 and
   through the MELODY project under the contract number 225885/O70.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Angermann Q, 2016, PROCEDIA COMPUT SCI, V90, P182, DOI 10.1016/j.procs.2016.07.017
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Davis P. J., 1975, INTERPOLATION APPROX
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Howard A.G., 2017, ARXIV
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Jurman G., 2009, P ADV RANK NIPS 09 W, P22
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Narodytska N, 2017, IEEE COMPUT SOC CONF, P1310, DOI 10.1109/CVPRW.2017.172
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P1186, DOI 10.1016/S0002-9270(03)00183-7
   REDMON J, 2016, PROC CVPR IEEE, P779, DOI DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tajbakhsh N., 2018, US Patent App, Patent No. [15/562 088, 15562088]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 43
TC 43
Z9 44
U1 1
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD JAN
PY 2020
VL 24
IS 1
BP 180
EP 193
DI 10.1109/JBHI.2019.2907434
PG 14
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA KB6ZZ
UT WOS:000506642000019
PM 30946683
DA 2023-08-21
ER

PT J
AU Sharma, P
   Bora, K
   Kasugai, K
   Balabantaray, BK
AF Sharma, Pallabi
   Bora, Kangkana
   Kasugai, Kunio
   Balabantaray, Bunil Kumar
TI Two Stage Classification with CNN for Colorectal Cancer Detection
SO ONCOLOGIE
LA English
DT Article
DE Colon cancer; deep learning; polyps detection; CNN; colonoscopy
ID HIGHLIGHT REMOVAL; ARCHITECTURES
AB In this paper, we address a current problem in medical image processing, the detection of colorectal cancer from colonoscopy videos. According to worldwide cancer statistics, colorectal cancer is one of the most common cancers. The process of screening and the removal of pre-cancerous cells from the large intestine is a crucial task to date. The traditional manual process is dependent on the expertise of the medical practitioner. In this paper, a two-stage classification is proposed to detect colorectal cancer. In the first stage, frames of colonoscopy video are extracted and are rated as significant if it contains a polyp, and these results are then aggregated in a second stage to come to an overall decision concerning the final classification of that frame to be neoplastic and non-neoplastic. In doing so, a comparative study is being made by considering the applicability of deep learning to perform this two-stage classification. The CNN models namely VGG16, VGG19, Inception V3, Xception, GoogLeNet, ResNet50, ResNet100, DenseNet, NASNetMobile, MobilenetV2, InceptionResNetV2 and fine-tuned version of each model is evaluated. It is observed that the VGG19 model is the best deep learning method for colonoscopy image diagnosis.
C1 [Sharma, Pallabi; Balabantaray, Bunil Kumar] Natl Inst Technol Meghalaya, Dept Comp Sci & Engn, Shillong 793003, Meghalaya, India.
   [Bora, Kangkana] Cotton Univ, Comp Sci & Informat Technol, Gauhati 781001, India.
   [Kasugai, Kunio] Aichi Med Univ, Dept Gastroenterol, Nagakute, Aichi 4801195, Japan.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Meghalaya; Aichi Medical University
RP Sharma, P (通讯作者)，Natl Inst Technol Meghalaya, Dept Comp Sci & Engn, Shillong 793003, Meghalaya, India.
EM pallabishrma@nitm.ac.in
RI Balabantaray, Bunil Kumar/M-9711-2013
OI Balabantaray, Bunil Kumar/0000-0002-2769-7122; SHARMA,
   PALLABI/0000-0003-3447-9251
CR Akbari M, 2018, IEEE ENG MED BIO, P65, DOI 10.1109/EMBC.2018.8512226
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eaden JA, 2000, GASTROINTEST ENDOSC, V51, P123, DOI 10.1016/S0016-5107(00)70405-6
   Gao YF, 2017, PROCEDIA COMPUT SCI, V107, P762, DOI 10.1016/j.procs.2017.03.161
   Geng DQ, 2019, IEEE ACCESS, V7, P44574, DOI 10.1109/ACCESS.2019.2909060
   Ghesu FC, 2019, IEEE T PATTERN ANAL, V41, P176, DOI 10.1109/TPAMI.2017.2782687
   Graham S, 2019, MED IMAGE ANAL, V52, P199, DOI 10.1016/j.media.2018.12.001
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   He TC, 2019, JCO CLIN CANCER INFO, V3, P1, DOI 10.1200/CCI.18.00121
   Howard A.G., 2017, ARXIV
   Huang G., 2017, P IEEE C COMPUTER VI, P4700, DOI DOI 10.1109/CVPR.2017.243
   Jiang J, 2019, IEEE T MED IMAGING, V38, P134, DOI 10.1109/TMI.2018.2857800
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Ksiazek W, 2019, COGN SYST RES, V54, P116, DOI 10.1016/j.cogsys.2018.12.001
   Li C, 2019, MED IMAGE ANAL, V53, P165, DOI 10.1016/j.media.2019.01.013
   Morgand A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P274
   Nasr-Esfahani E, 2019, COMPUT MED IMAG GRAP, V78, DOI 10.1016/j.compmedimag.2019.101658
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Patel K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236452
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Qi XF, 2019, MED IMAGE ANAL, V52, P185, DOI 10.1016/j.media.2018.12.006
   Queiroz F, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P282, DOI 10.1109/SIBGRAPI.2014.18
   Saikia AR, 2019, TISSUE CELL, V57, P8, DOI 10.1016/j.tice.2019.02.001
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Sonnenberg A, 2000, ANN INTERN MED, V133, P573, DOI 10.7326/0003-4819-133-8-200010170-00007
   Sun WQ, 2017, COMPUT MED IMAG GRAP, V57, P4, DOI 10.1016/j.compmedimag.2016.07.004
   Sundaram PS, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1153-9
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan K, 2017, PROC SPIE, V10420, DOI 10.1117/12.2285403
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   World Health Organization, 2018, CANCER
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P1304, DOI 10.1109/TPAMI.2014.2360402
   Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7
   Yu DH, 2014, SIGNAL PROCESS, V103, P367, DOI 10.1016/j.sigpro.2013.11.021
   Zhang S, 2019, COMPUT MED IMAG GRAP, V77, DOI 10.1016/j.compmedimag.2019.101645
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 43
TC 6
Z9 7
U1 3
U2 13
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 1292-3818
EI 1765-2839
J9 ONCOLOGIE
JI Oncologie
PY 2020
VL 22
IS 3
BP 129
EP 145
DI 10.32604/oncologie.2020.013870
PG 17
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA PI7AR
UT WOS:000601239800002
OA hybrid
DA 2023-08-21
ER

PT J
AU Yoshii, S
   Mabe, K
   Watano, K
   Ohno, M
   Matsumoto, M
   Ono, S
   Kudo, T
   Nojima, M
   Kato, M
   Sakamoto, N
AF Yoshii, Shinji
   Mabe, Katsuhiro
   Watano, Keiko
   Ohno, Masayoshi
   Matsumoto, Mio
   Ono, Shoko
   Kudo, Takahiko
   Nojima, Masanori
   Kato, Mototsugu
   Sakamoto, Naoya
TI Validity of endoscopic features for the diagnosis of Helicobacter pylori
   infection status based on the Kyoto classification of gastritis
SO DIGESTIVE ENDOSCOPY
LA English
DT Article
DE classification; endoscopy; gastritis; Helicobacter pylori; infection
ID CANCER; ERADICATION; PREVALENCE; MUCOSA
AB Objectives Evaluation of Helicobacter pylori infection status (non-infection, past infection, current infection) has become important. This study aimed to determine the usefulness of the Kyoto classification of gastritis for diagnosing H. pylori infection status by endoscopy. Methods In this prospective study, 498 subjects were recruited. Seven well-experienced endoscopists blinded to the history of eradication therapy performed the examinations. Endoscopic findings were assessed according to the Kyoto classification of gastritis: diffuse redness, regular arrangement of collecting venules (RAC), fundic gland polyp (FGP), atrophy, xanthoma, hyperplastic polyp, map-like redness, intestinal metaplasia, nodularity, mucosal swelling, white and flat elevated lesion, sticky mucus, depressive erosion, raised erosion, red streak, and enlarged folds. We established prediction models according to a machine learning procedure and compared them with general assessment by endoscopists using the Kyoto classification of gastritis. Results Significantly higher diagnostic odds were obtained for RAC (32.2), FGP (7.7), and red streak (4.7) in subjects with non-infection, map-like redness (12.9) in subjects with past infection, and diffuse redness (26.8), mucosal swelling (13.3), sticky mucus (10.2) and enlarged fold (8.6) in subjects with current infection. The overall diagnostic accuracy rate was 82.9% with the Kyoto classification of gastritis. The diagnostic accuracy of the prediction model was 88.6% for the model without H. pylori eradication history and 93.4% for the model with eradication history. Conclusions The Kyoto classification of gastritis is useful for diagnosing H. pylori infection status based on endoscopic findings. Our prediction model is helpful for novice endoscopists. (UMIN000016674).
C1 [Yoshii, Shinji] Sapporo Med Ctr NTT EC, Dept Gastroenterol, Sapporo, Hokkaido, Japan.
   [Watano, Keiko] Sapporo Med Ctr NTT EC, Med Check Up Ctr, Sapporo, Hokkaido, Japan.
   [Mabe, Katsuhiro; Kato, Mototsugu] Hakodate Natl Hosp, Dept Gastroenterol, Sapporo, Hokkaido, Japan.
   [Ohno, Masayoshi; Ono, Shoko] Hokkaido Univ Hosp, Div Endoscopy, Sapporo, Hokkaido, Japan.
   [Matsumoto, Mio] Hokkaido Med Ctr, Dept Gastroenterol, Sapporo, Hokkaido, Japan.
   [Kudo, Takahiko] Hlth Sci Univ, Dept Gastroenterol, Hokkaido Hosp, Sapporo, Hokkaido, Japan.
   [Sakamoto, Naoya] Hokkaido Univ, Dept Gastroenterol, Grad Sch Med, Sapporo, Hokkaido, Japan.
   [Nojima, Masanori] Univ Tokyo, Inst Med Sci Hosp, Ctr Translat Res, Tokyo, Japan.
C3 Hokkaido University; Hokkaido University; University of Tokyo
RP Yoshii, S (通讯作者)，NTT EC, Sapporo Med Ctr, Dept Gastroenterol, Chuo Ku, S1 W15, Sapporo, Hokkaido 0600061, Japan.
EM shinji-yoshii@umin.ac.jp
RI Sakamoto, Naoya/G-2734-2012; Ono, Shoko/G-5226-2012
OI Sakamoto, Naoya/0000-0003-0061-059X; Ono, Shoko/0000-0002-4485-6367
CR Fukase K, 2008, LANCET, V372, P392, DOI 10.1016/S0140-6736(08)61159-9
   Glas AS, 2003, J CLIN EPIDEMIOL, V56, P1129, DOI 10.1016/S0895-4356(03)00177-X
   Haruma K., 2017, KYOTO CLASSIFICATION
   Kamada T, 2005, ALIMENT PHARM THER, V21, P1121, DOI 10.1111/j.1365-2036.2005.02459.x
   Kanda Y, 2013, BONE MARROW TRANSPL, V48, P452, DOI 10.1038/bmt.2012.244
   Kato M, 2013, DIGEST ENDOSC, V25, P264, DOI 10.1111/j.1443-1661.2012.01385.x
   Kato T, 2013, DIGEST ENDOSC, V25, P508, DOI 10.1111/den.12031
   Kikuchi S, 2000, JPN J MED PHARM SCI, V43, P581
   Kitamura Y, 2015, J GASTROEN HEPATOL, V30, P1473, DOI 10.1111/jgh.12987
   Mabe K, 2009, WORLD J GASTROENTERO, V15, P4290, DOI 10.3748/wjg.15.4290
   Matsuo T, 2011, HELICOBACTER, V16, P415, DOI 10.1111/j.1523-5378.2011.00889.x
   Miyamoto M, 2003, DIGEST DIS SCI, V48, P968, DOI 10.1023/A:1023016000096
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Nagata N, 2011, GASTROENTEROL RES, V4, P203, DOI 10.4021/gr357w
   Neumann H, 2019, DIGEST ENDOSC, V31, P389, DOI 10.1111/den.13391
   Nishibayashi H, 2003, J GASTROEN HEPATOL, V18, P1384, DOI 10.1046/j.1440-1746.2003.03192.x
   Nomura S, 2013, DIGEST ENDOSC, V25, P136, DOI 10.1111/j.1443-1661.2012.01357.x
   Ono S, 2012, DIGESTION, V86, P59, DOI 10.1159/000339176
   Research Center for Cancer Prevention and Screening, 2014, NAT CANC CTR JAP GUI
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Ueda J, 2014, HELICOBACTER, V19, P105, DOI 10.1111/hel.12110
   Uemura N, 2001, NEW ENGL J MED, V345, P784, DOI 10.1056/NEJMoa001999
   Watanabe K, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-128
   Watanabe K, 2013, WORLD J GASTROENTERO, V19, P4374, DOI 10.3748/wjg.v19.i27.4374
   Yagi K, 2002, J GASTROEN HEPATOL, V17, P39, DOI 10.1046/j.1440-1746.2002.02665.x
NR 26
TC 49
Z9 54
U1 2
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JAN
PY 2020
VL 32
IS 1
BP 74
EP 83
DI 10.1111/den.13486
PG 10
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA KA4LY
UT WOS:000505769500024
PM 31309632
DA 2023-08-21
ER

PT J
AU Zachariah, R
   Samarasena, J
   Luba, D
   Duh, E
   Dao, T
   Requa, J
   Ninh, A
   Karnes, W
AF Zachariah, Robin
   Samarasena, Jason
   Luba, Daniel
   Duh, Erica
   Dao, Tyler
   Requa, James
   Ninh, Andrew
   Karnes, William
TI Prediction of Polyp Pathology Using Convolutional Neural Networks
   Achieves "Resect and Discard" Thresholds
SO AMERICAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
ID SMALL COLORECTAL POLYPS; OPTICAL BIOPSY; DIAGNOSIS; ENDOSCOPY; CANCER;
   SYSTEM; PREVENTION; HISTOLOGY; ACCURACY; SOCIETY
AB OBJECTIVES: Reliable in situ diagnosis of diminutive (<= 5 mm) colorectal polyps could allow for "resect and discard" and "diagnose and leave" strategies, resulting in $1 billion cost savings per year in the United States alone. Current methodologies have failed to consistently meet the Preservation and Incorporation of Valuable endoscopic Innovations (PIVIs) initiative thresholds. Convolutional neural networks (CNNs) have the potential to predict polyp pathology and achieve PIVI thresholds in real time. METHODS: We developed a CNN-based optical pathology (OP) model using Tensorflow and pretrained on ImageNet, capable of operating at 77 frames per second. A total of 6,223 images of unique colorectal polyps of known pathology, location, size, and light source (white light or narrow band imaging [NBI]) underwent 5-fold cross-training (80%) and validation (20%). Separate fresh validation was performed on 634 polyp images. Surveillance intervals were calculated, comparing OP with true pathology. RESULTS: In the original validation set, the negative predictive value for adenomas was 97% among diminutive rectum/rectosigmoid polyps. Results were independent of use of NBI or white light. Surveillance interval concordance comparing OP and true pathology was 93%. In the fresh validation set, the negative predictive value was 97% among diminutive polyps in the rectum and rectosigmoid and surveillance concordance was 94%. DISCUSSION: This study demonstrates the feasibility of in situ diagnosis of colorectal polyps using CNN. Our model exceeds PIVI thresholds for both "resect and discard" and "diagnose and leave" strategies independent of NBI use. Point-of-care adenoma detection rate and surveillance recommendations are potential added benefits.
C1 [Zachariah, Robin; Samarasena, Jason; Duh, Erica; Karnes, William] Univ Calif Irvine, Med Ctr, Dept Gastroenterol, Orange, CA 92668 USA.
   [Zachariah, Robin; Samarasena, Jason; Duh, Erica; Karnes, William] Univ Calif Irvine, Med Ctr, Dept Internal Med, Orange, CA 92668 USA.
   [Samarasena, Jason; Dao, Tyler; Requa, James; Karnes, William] Docbot, Irvine, CA USA.
   [Luba, Daniel; Ninh, Andrew] Monterey Bay GI Consultants Med Grp, Monterey, CA USA.
C3 University of California System; University of California Irvine;
   University of California System; University of California Irvine
RP Zachariah, R (通讯作者)，Univ Calif Irvine, Med Ctr, Dept Gastroenterol, Orange, CA 92668 USA.; Zachariah, R (通讯作者)，Univ Calif Irvine, Med Ctr, Dept Internal Med, Orange, CA 92668 USA.
EM rzachar1@uci.edu
OI Karnes, William/0000-0002-6225-9080
FU National Center for Research Resources; National Center for Advancing
   Translational Sciences, National Institutes of Health [UL1 TR001414]
FX The project described was supported by the National Center for Research
   Resources and the National Center for Advancing Translational Sciences,
   National Institutes of Health, through Grant UL1 TR001414. The content
   is solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institutes of Health.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Flores SL, 2014, GASTROINTEST ENDOSC, V79, pAB170
   Hamoudah T, 2018, GASTROINTEST ENDOSC, V87, P1518, DOI 10.1016/j.gie.2017.12.028
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Iwatate Mineo, 2012, Diagn Ther Endosc, V2012, P173269, DOI 10.1155/2012/173269
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Kumar S, 2013, GASTROINTEST ENDOSC, V78, P902, DOI 10.1016/j.gie.2013.06.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lee J, 2016, CLIN ENDOSC, V49, P355, DOI 10.5946/ce.2016.063
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Ponugoti P, 2019, ENDOSCOPY, V51, P221, DOI 10.1055/a-0831-2348
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rex DK, 1999, GASTROINTEST ENDOSC, V50, P468, DOI 10.1016/S0016-5107(99)70067-2
   Rex DK, 2018, NEJM J WATCH
   Rex Douglas K, 2014, Gastroenterol Hepatol (N Y), V10, P671
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Surveillance Epidemiology and End Results (SEER) Program, 2016, SEER STAT DAT MORT A
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P22, DOI 10.1055/s-0029-1215268
   Turkiewicz J, 2018, GASTROINTEST ENDOSC, V87, pAB465
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wong NACS, 2009, HISTOPATHOLOGY, V55, P63, DOI 10.1111/j.1365-2559.2009.03329.x
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 29
TC 58
Z9 59
U1 0
U2 12
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0002-9270
EI 1572-0241
J9 AM J GASTROENTEROL
JI Am. J. Gastroenterol.
PD JAN
PY 2020
VL 115
IS 1
BP 138
EP 144
DI 10.14309/ajg.0000000000000429
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA LP3TS
UT WOS:000534242100019
PM 31651444
OA Green Accepted
DA 2023-08-21
ER

PT J
AU Cao, WG
   Pomeroy, MJ
   Gao, YF
   Barish, MA
   Abbasi, AF
   Pickhardt, PJ
   Liang, ZR
AF Cao, Weiguo
   Pomeroy, Marc J.
   Gao, Yongfeng
   Barish, Matthew A.
   Abbasi, Almas F.
   Pickhardt, Perry J.
   Liang, Zhengrong
TI Multi-scale characterizations of colon polyps via computed tomographic
   colonography
SO VISUAL COMPUTING FOR INDUSTRY BIOMEDICINE AND ART
LA English
DT Review
DE Colon cancer; Computed tomographic colonography; Polyp characterization;
   Texture feature
ID AMERICAN-CANCER-SOCIETY; TEXTURE FEATURES; IMAGES; CLASSIFICATION;
   SURVEILLANCE; LESIONS
AB Texture features have played an essential role in the field of medical imaging for computer-aided diagnosis. The gray-level co-occurrence matrix (GLCM)-based texture descriptor has emerged to become one of the most successful feature sets for these applications. This study aims to increase the potential of these features by introducing multi-scale analysis into the construction of GLCM texture descriptor. In this study, we first introduce a new parameter - stride, to explore the definition of GLCM. Then we propose three multi-scaling GLCM models according to its three parameters, (1) learning model by multiple displacements, (2) learning model by multiple strides (LMS), and (3) learning model by multiple angles. These models increase the texture information by introducing more texture patterns and mitigate direction sparsity and dense sampling problems presented in the traditional Haralick model. To further analyze the three parameters, we test the three models by performing classification on a dataset of 63 large polyp masses obtained from computed tomography colonoscopy consisting of 32 adenocarcinomas and 31 benign adenomas. Finally, the proposed methods are compared to several typical GLCM-texture descriptors and one deep learning model. LMS obtains the highest performance and enhances the prediction power to 0.9450 with standard deviation 0.0285 by area under the curve of receiver operating characteristics score which is a significant improvement.
C1 [Cao, Weiguo; Pomeroy, Marc J.; Gao, Yongfeng; Barish, Matthew A.; Abbasi, Almas F.; Liang, Zhengrong] SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.
   [Pomeroy, Marc J.; Liang, Zhengrong] SUNY Stony Brook, Dept Biomed Engn, Stony Brook, NY 11794 USA.
   [Pickhardt, Perry J.] Univ Wisconsin, Sch Med, Dept Radiol, Madison, WI 53792 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; State University of New York (SUNY) System; State
   University of New York (SUNY) Stony Brook; University of Wisconsin
   System; University of Wisconsin Madison
RP Liang, ZR (通讯作者)，SUNY Stony Brook, Dept Radiol, Stony Brook, NY 11794 USA.; Liang, ZR (通讯作者)，SUNY Stony Brook, Dept Biomed Engn, Stony Brook, NY 11794 USA.
EM jerome.liang@sunysb.edu
FU NIH/NCI [CA206171]
FX This work was supported by the NIH/NCI, No. CA206171.
CR Ahmed A, 2013, J MAGN RESON IMAGING, V38, P89, DOI 10.1002/jmri.23971
   American Cancer Society, 2018, CANC FACTS FIGURES 2
   [Anonymous], MACH LEARN
   Auffarth B, 2010, LECT NOTES ARTIF INT, V6171, P248, DOI 10.1007/978-3-642-14400-4_20
   Bins J, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P159, DOI 10.1109/ICCV.2001.937619
   BOUCHERON S., 2005, ESAIM-PROBAB STAT, V9, P323, DOI DOI 10.1051/PS:2005018
   Byers T, 1997, CA-CANCER J CLIN, V47, P154, DOI 10.3322/canjclin.47.3.154
   Cao WG, 2019, PROC SPIE, V10950, DOI 10.1117/12.2513056
   Castellano G, 2004, CLIN RADIOL, V59, P1061, DOI 10.1016/j.crad.2004.07.008
   Center MM, 2009, CA-CANCER J CLIN, V59, P366, DOI 10.3322/caac.20038
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Fiori M, 2010, IEEE ENG MED BIO, P3170, DOI 10.1109/IEMBS.2010.5627185
   Guo KH, 2010, LECT NOTES ARTIF INT, V6319, P373, DOI 10.1007/978-3-642-16530-6_44
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Hong XP, 2014, IEEE T IMAGE PROCESS, V23, P2557, DOI 10.1109/TIP.2014.2316640
   Hu YF, 2016, IEEE T MED IMAGING, V35, P1522, DOI 10.1109/TMI.2016.2518958
   Lam SWC, 1996, IEEE INT C SYST MAN
   Lee J, 2016, AM J NEURORADIOL, V37, P37, DOI 10.3174/ajnr.A4534
   Levin B, 2008, CA-CANCER J CLIN, V58, P130, DOI 10.3322/CA.2007.0018
   Li X, 2005, MED PHYS, V32, P2337, DOI 10.1118/1.1944912
   Liang Zhengrong, 2010, Expert Opin Med Diagn, V4, P159
   Lin WC, 2004, SIGGRAPH 04 ACM SIGG, DOI [10.1145/1186415.1186435, DOI 10.1145/1186415.1186435]
   Ma M, 2014, 2014 IEEE NUCLEAR SCIENCE SYMPOSIUM AND MEDICAL IMAGING CONFERENCE (NSS/MIC)
   Pickhardt PJ, 2013, ABDOM IMAGING, V38, P82, DOI 10.1007/s00261-012-9897-z
   Prasanna P, 2016, SCI REP-UK, V6, DOI 10.1038/srep37241
   Rangayyan RM, 2010, J DIGIT IMAGING, V23, P547, DOI 10.1007/s10278-009-9238-0
   Raschka S, 2017, PYTHON MACHINE LEARN
   Rathore S, 2014, COMPUT BIOL MED, V47, P76, DOI 10.1016/j.compbiomed.2013.12.010
   Rathore S, 2013, IEEE ACM T COMPUT BI, V10, P545, DOI 10.1109/TCBB.2013.84
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Song BW, 2014, INT J COMPUT ASS RAD, V9, P1021, DOI 10.1007/s11548-014-0991-2
   Song BW, 2014, INT J COMPUT ASS RAD, V9, P79, DOI 10.1007/s11548-013-0913-8
   Wainberg M, 2018, NAT BIOTECHNOL, V36, P829, DOI 10.1038/nbt.4233
   Xu XP, 2019, J MAGN RESON IMAGING, V49, P1489, DOI 10.1002/jmri.26327
   Zachevsky I, 2016, IEEE T IMAGE PROCESS, V25, P2130, DOI 10.1109/TIP.2016.2539689
   Zhang ZH, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.03.35
NR 38
TC 5
Z9 5
U1 1
U2 5
PU SPRINGER SINGAPORE PTE LTD
PI SINGAPORE
PA 152 Beach Road, #21-01 Gateway East, SINGAPORE, SINGAPORE
EI 2524-4442
J9 VIS COMPUT IND BIOME
JI Vis. Comput. Ind. Biomed. Art
PD DEC 27
PY 2019
VL 2
IS 1
AR 25
DI 10.1186/s42492-019-0032-7
PG 12
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic; Imaging Science & Photographic Technology
WE Emerging Sources Citation Index (ESCI)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA WD9RJ
UT WOS:000705269200001
PM 32240410
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Bisschops, R
   East, JE
   Hassan, C
   Hazewinkel, Y
   Kaminski, MF
   Neumann, H
   Pellise, M
   Antonelli, G
   Balen, MB
   Coron, E
   Cortas, G
   Iacucci, M
   Yuichi, M
   Longcroft-Wheaton, G
   Pilonis, N
   Puig, I
   van Hooft, JE
   Dekker, E
AF Bisschops, Raf
   East, James E.
   Hassan, Cesare
   Hazewinkel, Yark
   Kaminski, Michal F.
   Neumann, Helmut
   Pellise, Maria
   Antonelli, Giulio
   Bustamante Balen, Marco
   Coron, Emmanuel
   Cortas, Georges
   Iacucci, Marietta
   Yuichi, Mori
   Longcroft-Wheaton, Gaius
   Pilonis, Nastazja
   Puig, Ignasi
   van Hooft, Jeanin E.
   Dekker, Evelien
TI Advanced imaging for detection and differentiation of colorectal
   neoplasia: European Society of Gastrointestinal Endoscopy (ESGE)
   Guideline - Update 2019
SO ENDOSCOPY
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; WHITE-LIGHT ENDOSCOPY;
   INFLAMMATORY-BOWEL-DISEASE; SERRATED POLYPOSIS SYNDROME; HIGH-DEFINITION
   COLONOSCOPY; DIMINUTIVE COLONIC POLYPS; HIGH-RESOLUTION ENDOSCOPY; TIME
   OPTICAL DIAGNOSIS; HIGH-GRADE DYSPLASIA; OCCULT BLOOD-TEST
AB Main Recommendations 1 ESGE suggests that high definition endoscopy, and dye or virtual chromoendoscopy, as well as add-on devices, can be used in average risk patients to increase the endoscopist's adenoma detection rate. However, their routine use must be balanced against costs and practical considerations. Weak recommendation, high quality evidence. 2 ESGE recommends the routine use of high definition systems in individuals with Lynch syndrome. Strong recommendation, high quality evidence. 3 ESGE recommends the routine use, with targeted biopsies, of dye-based pancolonic chromoendoscopy or virtual chromoendoscopy for neoplasia surveillance in patients with long-standing colitis. Strong recommendation, moderate quality evidence. 4 ESGE suggests that virtual chromoendoscopy and dye-based chromoendoscopy can be used, under strictly controlled conditions, for real-time optical diagnosis of diminutive (<= 5 mm) colorectal polyps and can replace histopathological diagnosis. The optical diagnosis has to be reported using validated scales, must be adequately photodocumented, and can be performed only by experienced endoscopists who are adequately trained, as defined in the ESGE curriculum, and audited. Weak recommendation, high quality evidence. 5 ESGE recommends the use of high definition white-light endoscopy in combination with (virtual) chromoendoscopy to predict the presence and depth of any submucosal invasion in nonpedunculated colorectal polyps prior to any treatment. Strong recommendation, moderate quality evidence. 6 ESGE recommends the use of virtual or dye-based chromoendoscopy in addition to white-light endoscopy for the detection of residual neoplasia at a piecemeal polypectomy scar site. Strong recommendation, moderate quality evidence. 7 ESGE suggests the possible incorporation of computer-aided diagnosis (detection and characterization of lesions) to colonoscopy, if acceptable and reproducible accuracy for colorectal neoplasia is demonstrated in high quality multicenter in vivo clinical studies. Possible significant risks with implementation, specifically endoscopist deskilling and over-reliance on artificial intelligence, unrepresentative training datasets, and hacking, need to be considered. Weak recommendation, low quality evidence.
C1 [Bisschops, Raf] Katholieke Univ Leuven, Dept Gastroenterol & Hepatol, Univ Hosp Leuven, TARGID, Leuven, Belgium.
   [East, James E.] Univ Oxford, John Radcliffe Hosp, Nuffield Dept Med, Expt Med Div,Translat Gastroenterol Unit, Oxford, England.
   [East, James E.] Oxford Natl Inst Hlth Res, Biomed Res Ctr, Oxford, England.
   [Hassan, Cesare] Nuovo Regina Margherita Hosp, Digest Endoscopy Unit, Rome, Italy.
   [Hazewinkel, Yark; van Hooft, Jeanin E.; Dekker, Evelien] Univ Amsterdam, Acad Med Ctr, Dept Gastroenterol & Hepatol, Amsterdam, Netherlands.
   [Kaminski, Michal F.; Pilonis, Nastazja] Maria Sklodowska Curie Mem Canc Ctr, Dept Gastroenterol Oncol, Warsaw, Poland.
   [Kaminski, Michal F.; Pilonis, Nastazja] Inst Oncol, Warsaw, Poland.
   [Kaminski, Michal F.; Pilonis, Nastazja] Med Ctr Postgrad Educ, Dept Gastroenterol Hepatol & Oncol, Warsaw, Poland.
   [Kaminski, Michal F.] Univ Oslo, Inst Hlth & Soc, Oslo, Norway.
   [Neumann, Helmut] Univ Med Ctr Mainz, Dept Med 1, Mainz, Germany.
   [Pellise, Maria] Hosp Clin Barcelona, Dept Gastroenterol, Inst Clin Malalties Digest Metab 1, Barcelona, Spain.
   [Pellise, Maria] Univ Barcelona, CIBERehd, IDIBAPS, Barcelona, Spain.
   [Antonelli, Giulio] Sapienza Univ Rome, St Andrea Univ Hosp, Endoscopy Unit, Rome, Italy.
   [Bustamante Balen, Marco] La Fe Polytech Univ Hosp, Digest Dis Dept, Gastrointestinal Endoscopy Unit, Valencia, Spain.
   [Bustamante Balen, Marco] La Fe Hlth Res Inst, Gastrointestinal Endoscopy Res Grp, Valencia, Spain.
   [Coron, Emmanuel] Univ Nantes, CHU Nantes, IMAD, Nantes, France.
   [Cortas, Georges] Univ Balamand, St George Hosp Univ Med Ctr, Div Gastroenterol, Fac Med, Beirut, Lebanon.
   [Iacucci, Marietta] Univ Birmingham, Inst Immunol & Immunotherapy, Inst Translat Med, Birmingham, W Midlands, England.
   [Iacucci, Marietta] Univ Hosp Birmingham NHS Fdn Trust, Birmingham, W Midlands, England.
   [Yuichi, Mori] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Longcroft-Wheaton, Gaius] Portsmouth Hosp NHS Trust, Portsmouth, Hants, England.
   [Puig, Ignasi] Althaia Xarxa Assistencial Univ Manresa, Digest Dis Dept, Manresa, Spain.
   [Puig, Ignasi] Univ Vic, Univ Cent Catalunya, UVic UCC, Fac Ciencies Salut,Dept Med, Manresa, Spain.
C3 KU Leuven; University Hospital Leuven; University of Oxford; University
   of Oxford; Poliambulatorio Nuovo Regina Margherita; University of
   Amsterdam; Academic Medical Center Amsterdam; Maria Sklodowska-Curie
   National Research Institute of Oncology; Maria Sklodowska-Curie National
   Research Institute of Oncology; Centre of Postgraduate Medical Education
   - Poland; University of Oslo; Johannes Gutenberg University of Mainz;
   University of Barcelona; Hospital Clinic de Barcelona; CIBER - Centro de
   Investigacion Biomedica en Red; CIBEREHD; University of Barcelona;
   Hospital Clinic de Barcelona; IDIBAPS; Sapienza University Rome; Azienda
   Ospedaliera Sant'Andrea; Nantes Universite; CHU de Nantes; University
   Balamand; University of Birmingham; University of Birmingham; Showa
   University; Portsmouth Hospitals NHS Trust; Universitat de Vic -
   Universitat Central de Catalunya (UVic-UCC)
RP Bisschops, R (通讯作者)，Univ Hosp Leuven, Targid, Gastroenterol & Hepatol, 49 Herestr, B-3000 Leuven, Belgium.
EM raf.bisschops@uzleuven.be
RI Hazewinkel, Yark/AAD-6593-2019; Coron, Emmanuel/HZH-6760-2023; Kaminski,
   Michal F./AFN-3411-2022; Mori, Yuichi/AAU-5406-2020; Puig,
   Ignasi/N-1208-2014; Dekker, Evelien/HOH-9015-2023; hassan,
   cesare/H-2844-2012; Pellise, Maria/ABC-3246-2021; van hooft,
   Jeanin/AAT-3600-2020; Bustamante-Balen, Marco/E-2123-2013
OI Puig, Ignasi/0000-0002-9059-8602; hassan, cesare/0000-0001-7167-1459;
   van hooft, Jeanin/0000-0002-4424-0079; Dekker,
   Evelien/0000-0002-4363-0745; Bisschops, Raf/0000-0002-9994-8226;
   Bustamante-Balen, Marco/0000-0003-2019-0158; Antonelli,
   Giulio/0000-0003-1797-3864; IACUCCI, MARIETTA/0000-0002-3142-9550;
   Pilonis, Nastazja Dagny/0000-0003-3806-8679; Kaminski,
   Michal/0000-0002-9714-6457
FU National Institute for Health Research (NIHR) Oxford Biomedical Research
   Centre; National Institute for Health Research (NIHR) Birmingham
   Biomedical Research Centre - Research Foundation Flanders (FWO); Japan
   Society for the Promotion of Science
FX J.E. East was funded by the National Institute for Health Research
   (NIHR) Oxford Biomedical Research Centre, and M. Iacucci receives
   funding support from the National Institute for Health Research (NIHR)
   Birmingham Biomedical Research Centre. R. Bisschops was funded by a
   grant of the Research Foundation Flanders (FWO). Y. Mori was funded by
   the Japan Society for the Promotion of Science. E. Coron, H. Neumann,
   and Y. Hazewinkel received no funding.
CR Abdeljawad K, 2015, GASTROINTEST ENDOSC, V81, P517, DOI 10.1016/j.gie.2014.04.064
   Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Aldridge AJ, 2001, EUR J SURG, V167, P777
   [Anonymous], 2018, UNITED EUR GASTROENT, V6, pA195
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Atkin WS, 2012, ENDOSCOPY, V44, pSE151, DOI 10.1055/s-0032-1309821
   Atkinson NSS, 2019, GASTROENTEROLOGY, V157, P462, DOI 10.1053/j.gastro.2019.04.014
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Backes Y, 2017, AM J GASTROENTEROL, V112, P54, DOI 10.1038/ajg.2016.403
   Backes Y, 2019, GUT, V68, P271, DOI 10.1136/gutjnl-2017-314723
   Bae JH, 2019, CLIN GASTROENTEROL H, V17, P2479, DOI 10.1016/j.cgh.2019.02.019
   Belderbos TDG, 2014, ENDOSCOPY, V46, P388, DOI 10.1055/s-0034-1364970
   Bessissow T, 2018, INFLAMM BOWEL DIS, V24, P2518, DOI 10.1093/ibd/izy188
   Bisschops R, 2018, GUT, V67, P1087, DOI 10.1136/gutjnl-2016-313213
   Bisschops R, 2018, ENDOSCOPY, V50, P211, DOI 10.1055/s-0043-121570
   Bisschops R, 2017, GASTROINTEST ENDOSC, V86, P1100, DOI 10.1016/j.gie.2017.09.024
   Bisschops R, 2017, ENDOSCOPY, V49, P342, DOI 10.1055/s-0042-121005
   Biswas S, 2013, GUT, V62, P475, DOI 10.1136/gutjnl-2012-303233
   Bogie RMM, 2018, ENDOSCOPY, V50, P263, DOI 10.1055/s-0043-121144
   Boparai KS, 2011, ENDOSCOPY, V43, P676, DOI 10.1055/s-0030-1256447
   Bretagne JF, 2010, DIS COLON RECTUM, V53, P339, DOI 10.1007/DCR.0b013e3181c37f9c
   Brown SR, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006439.pub4
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Buchner AM, 2010, GASTROENTEROLOGY, V138, P834, DOI 10.1053/j.gastro.2009.10.053
   Bugajski M, 2015, SCAND J GASTROENTERO, V50, P1261, DOI 10.3109/00365521.2015.1024280
   Burgess NG, 2017, GASTROENTEROLOGY, V153, P732, DOI 10.1053/j.gastro.2017.05.047
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cabitza F, 2017, JAMA-J AM MED ASSOC, V318, P517, DOI 10.1001/jama.2017.7797
   Cairns SR, 2010, GUT, V59, P666, DOI 10.1136/gut.2009.179804
   Carballal S, 2018, GUT, V67, P70, DOI 10.1136/gutjnl-2016-312332
   Cassinotti A, 2019, J CLIN GASTROENTEROL, V53, P269, DOI 10.1097/MCG.0000000000000974
   Cellier C, 2019, AM J GASTROENTEROL, V114, P1665, DOI 10.14309/ajg.0000000000000386
   Chan JL, 2012, WORLD J GASTROENTERO, V18, P5905, DOI 10.3748/wjg.v18.i41.5905
   Chandran S, 2015, INTERN MED J, V45, P1293, DOI 10.1111/imj.12917
   Chaput U, 2011, DIGEST LIVER DIS, V43, P609, DOI 10.1016/j.dld.2011.02.002
   Chen C, 2019, PREV MED, V123, P333, DOI 10.1016/j.ypmed.2019.03.048
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chiu HM, 2014, DIGEST ENDOSC, V26, P64, DOI 10.1111/den.12260
   Church JM, 2004, DIS COLON RECTUM, V47, P481, DOI 10.1007/s10350-003-0078-6
   Clark BT, 2014, AM J GASTROENTEROL, V109, P1714, DOI 10.1038/ajg.2014.232
   Coe SG, 2012, GASTROINTEST ENDOSC, V76, P118, DOI 10.1016/j.gie.2012.03.007
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Deenadayalu VP, 2004, AM J GASTROENTEROL, V99, P2138, DOI 10.1111/j.1572-0241.2004.40430.x
   Deepak P, 2016, GASTROINTEST ENDOSC, V83, P1005, DOI 10.1016/j.gie.2015.09.021
   Dekker E, 2007, ENDOSCOPY, V39, P216, DOI 10.1055/s-2007-966214
   Delamothe T, 2004, BMJ-BRIT MED J, V328, P1, DOI 10.1136/bmj.328.7430.1
   Denis B, 2011, ENDOSCOPY, V43, P81, DOI 10.1055/s-0030-1255952
   Desomer L, 2017, GASTROINTEST ENDOSC, V85, P518, DOI 10.1016/j.gie.2016.06.031
   Dinesen L, 2012, GASTROINTEST ENDOSC, V75, P604, DOI 10.1016/j.gie.2011.10.017
   dos Santos CEO, 2018, EUR J GASTROEN HEPAT, V30, P1514, DOI 10.1097/MEG.0000000000001278
   Dos Santos Carlos Eduardo Oliveira, 2012, Diagn Ther Endosc, V2012, P279521, DOI 10.1155/2012/279521
   Dumonceau JM, 2012, ENDOSCOPY, V44, P626, DOI 10.1055/s-0031-1291747
   East JE, 2008, ENDOSCOPY, V40, P811, DOI 10.1055/s-2008-1077586
   East JE, 2008, GUT, V57, P65, DOI 10.1136/gut.2007.128926
   East JE, 2006, GUT, V55, P1432, DOI 10.1136/gut.2005.087171
   East JE, 2018, LANCET GASTROENTEROL, V3, P10, DOI 10.1016/S2468-1253(17)30366-7
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Elsadani NN, 2011, GUT, V60, P282, DOI 10.1136/gut.2010.225466
   Facciorusso A, 2018, CLIN GASTROENTEROL H, V16, P1209, DOI 10.1016/j.cgh.2017.11.007
   Fatima H, 2008, CLIN GASTROENTEROL H, V6, P109, DOI 10.1016/j.cgh.2007.10.009
   Feuerstein JD, 2019, GASTROINTEST ENDOSC, V90, P186, DOI 10.1016/j.gie.2019.04.219
   Figueiredo PN, 2019, ENDOSC INT OPEN, V7, pE209, DOI 10.1055/a-0808-4456
   Gasia MF, 2016, CLIN GASTROENTEROL H, V14, P704, DOI 10.1016/j.cgh.2015.12.047
   Graser A, 2009, GUT, V58, P241, DOI 10.1136/gut.2008.156448
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Gunther U, 2011, INT J COLORECTAL DIS, V26, P667, DOI 10.1007/s00384-011-1130-y
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P494, DOI 10.1016/j.gie.2011.08.002
   Haanstra JF, 2019, GASTROINTEST ENDOSC, V90, P624, DOI 10.1016/j.gie.2019.04.227
   Har-Noy O, 2017, DIGEST DIS SCI, V62, P2982, DOI 10.1007/s10620-017-4772-y
   Hassan C, 2010, CLIN J GASTROENTEROL, V8, P865
   Hazewinkel Y, 2015, GASTROINTEST ENDOSC, V81, P531, DOI 10.1016/j.gie.2014.06.043
   Hazewinkel Y, 2013, GASTROINTEST ENDOSC, V77, P916, DOI 10.1016/j.gie.2012.12.018
   Henry ZH, 2010, GASTROINTEST ENDOSC, V72, P118, DOI 10.1016/j.gie.2010.01.048
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hewett DG, 2012, GASTROINTEST ENDOSC, V76, P374, DOI 10.1016/j.gie.2012.04.446
   High-Level Expert Group on Artificial Intelligence, ETH GUID TRUSTW AI
   Hlavaty T, 2011, EUR J GASTROEN HEPAT, V23, P680, DOI 10.1097/MEG.0b013e32834791b4
   Hoffman A, 2010, ENDOSCOPY, V42, P827, DOI 10.1055/s-0030-1255713
   Hoffman A, 2010, DIGEST LIVER DIS, V42, P45, DOI 10.1016/j.dld.2009.04.005
   Hong S N, 2012, GASTROINTEST ENDOSC, V75, P1011
   Huneburg R, 2009, ENDOSCOPY, V41, P316, DOI 10.1055/s-0028-1119628
   Hurlstone DP, 2005, AM J GASTROENTEROL, V100, P2167, DOI 10.1111/j.1572-0241.2005.41481.x
   Iacucci M, 2019, ENDOSCOPY, V51, P133, DOI 10.1055/a-0757-7759
   Iacucci M, 2018, ENDOSCOPY, V50, P779, DOI 10.1055/s-0044-100791
   Iacucci M, 2018, AM J GASTROENTEROL, V113, P225, DOI 10.1038/ajg.2017.417
   Iannone A, 2017, CLIN GASTROENTEROL H, V15, P1684, DOI 10.1016/j.cgh.2016.11.021
   Ichimasa K, 2018, ENDOSCOPY, V50, P230, DOI 10.1055/s-0043-122385
   Ignjatovic A, 2011, ENDOSCOPY, V43, P94, DOI 10.1055/s-0030-1256074
   Ignjatovic A, 2012, AM J GASTROENTEROL, V107, P885, DOI 10.1038/ajg.2012.67
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Ijspeert JE, 2015, GASTROINTEST ENDOSC, V81, pAB260, DOI 10.1016/j.gie.2015.03.1348
   Ikematsu H, 2017, GASTROINTEST ENDOSC, V86, P386, DOI 10.1016/j.gie.2017.01.017
   Ito N, 2019, ONCOLOGY-BASEL, V96, P44, DOI 10.1159/000491636
   Iwai T, 2019, J GASTROEN HEPATOL, V34, P397, DOI 10.1111/jgh.14409
   Iwatate M, 2018, DIGEST ENDOSC, V30, P642, DOI 10.1111/den.13065
   Jeong YH, 2016, J KOREAN MED SCI, V31, P1426, DOI 10.3346/jkms.2016.31.9.1426
   Jin XF, 2012, J GASTROEN HEPATOL, V27, P882, DOI 10.1111/j.1440-1746.2011.06987.x
   Kahi CJ, 2012, GASTROINTEST ENDOSC, V75, P515, DOI 10.1016/j.gie.2011.08.021
   Kaltenbach T, 2015, GUT, V64, P1569, DOI 10.1136/gutjnl-2014-307742
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kandel P, 2019, GUT, V68, P1633, DOI 10.1136/gutjnl-2018-316574
   Kawaguti FS, 2019, DIS COLON RECTUM, V62, P422, DOI 10.1097/DCR.0000000000001343
   Kawasaki K, 2019, DIGEST ENDOSC, V31, P36, DOI 10.1111/den.13382
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Khashab M, 2009, GASTROINTEST ENDOSC, V70, P344, DOI 10.1016/j.gie.2008.10.037
   Kidambi TD, 2019, CLIN GASTROENTEROL H, V17, P701, DOI 10.1016/j.cgh.2018.06.024
   Kiesslich R, 2003, GASTROENTEROLOGY, V124, P880, DOI 10.1053/gast.2003.50146
   Kiesslich R, 2007, GASTROENTEROLOGY, V132, P874, DOI 10.1053/j.gastro.2007.01.048
   Kim YS, 2011, CLIN GASTROENTEROL H, V9, P744, DOI 10.1016/j.cgh.2011.05.021
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Klare P, 2016, ENDOSCOPY, V48, P909, DOI 10.1055/s-0042-110650
   Knabe M, 2014, AM J GASTROENTEROL, V109, P183, DOI 10.1038/ajg.2013.419
   Kobayashi S, 2019, UNITED EUR GASTROENT, V7, P914, DOI 10.1177/2050640619845987
   Kolligs FT, 2013, GUT, V62, P863, DOI 10.1136/gutjnl-2011-300111
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P49, DOI 10.1159/000481230
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Konijeti GG, 2014, GASTROINTEST ENDOSC, V79, P455, DOI 10.1016/j.gie.2013.10.026
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Kudo Shin-ei, 2008, Gastrointest Endosc Clin N Am, V18, P581, DOI 10.1016/j.giec.2008.05.013
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lecomte T, 2005, CLIN GASTROENTEROL H, V3, P897, DOI 10.1016/S1542-3565(05)00403-9
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P603, DOI 10.1016/j.gie.2011.04.049
   Lesne A, 2017, ENDOSCOPY, V49, P765, DOI 10.1055/s-0043-105073
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Longcroft-Wheaton G, 2012, ENDOSCOPY, V44, P905, DOI 10.1055/s-0032-1310004
   Longcroft-Wheaton GR, 2011, EUR J GASTROEN HEPAT, V23, P903, DOI 10.1097/MEG.0b013e328349e276
   Lopez-Vicente J, 2019, CLIN GASTROENTEROL H, V17, P2016, DOI 10.1016/j.cgh.2018.10.029
   Lui TKL, 2019, ENDOSC INT OPEN, V7, pE514, DOI 10.1055/a-0849-9548
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Marion JF, 2008, AM J GASTROENTEROL, V103, P2342, DOI 10.1111/j.1572-0241.2008.01934.x
   Marion JF, 2016, CLIN GASTROENTEROL H, V14, P713, DOI 10.1016/j.cgh.2015.11.011
   Matsuda T, 2008, AM J GASTROENTEROL, V103, P2700, DOI 10.1111/j.1572-0241.2008.02190.x
   Matsumoto T, 2010, COLORECTAL DIS, V12, pE291, DOI 10.1111/j.1463-1318.2009.02181.x
   Matsumoto T, 2003, AM J GASTROENTEROL, V98, P1827, DOI 10.1016/S0002-9270(03)00429-5
   Matsumoto T, 2007, GASTROINTEST ENDOSC, V66, P957, DOI 10.1016/j.gie.2007.04.014
   Min M, 2017, GASTROINTEST ENDOSC, V86, P724, DOI 10.1016/j.gie.2017.02.035
   Minoda Y, 2019, DIGEST ENDOSC, V31, P544, DOI 10.1111/den.13393
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Mooiweer E, 2015, AM J GASTROENTEROL, V110, P1014, DOI 10.1038/ajg.2015.63
   Moreira L, 2013, GUT, V62, P476, DOI 10.1136/gutjnl-2012-303496
   Mori Y, 2019, DIGEST ENDOSC, V31, P378, DOI 10.1111/den.13317
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Moss A, 2015, GUT, V64, P57, DOI 10.1136/gutjnl-2013-305516
   Moussata D, 2018, GUT, V67, P616, DOI 10.1136/gutjnl-2016-311892
   Nagorni A, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008361.pub2
   Nusko G, 1997, INT J COLORECTAL DIS, V12, P267, DOI 10.1007/s003840050103
   Oka S, 2014, DIGEST ENDOSC, V26, P78, DOI 10.1111/den.12275
   dos Santos CEO, 2015, ENDOSC INT OPEN, V3, pE240, DOI 10.1055/s-0034-1391667
   dos Santos CEO, 2010, EUR J GASTROEN HEPAT, V22, P1364, DOI 10.1097/MEG.0b013e32833a5d63
   Omata F, 2014, SCAND J GASTROENTERO, V49, P222, DOI 10.3109/00365521.2013.863964
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Paggi S, 2012, ENDOSCOPY, V44, P899, DOI 10.1055/s-0032-1309891
   Paggi S, 2018, ENDOSCOPY, V50, P396, DOI 10.1055/a-0580-7405
   Paggi S, 2015, ENDOSCOPY, V47, P808, DOI 10.1055/s-0034-1392042
   Pasha SF, 2012, AM J GASTROENTEROL, V107, P363, DOI 10.1038/ajg.2011.436
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Pellise M, 2011, GASTROINTEST ENDOSC, V74, P840, DOI 10.1016/j.gie.2011.05.013
   Pickhardt PJ, 2009, AM J ROENTGENOL, V193, P40, DOI 10.2214/AJR.08.1709
   Pickhardt PJ, 2003, NEW ENGL J MED, V349, P2191, DOI 10.1056/NEJMoa031618
   Picot J, 2017, HEALTH TECHNOL ASSES, V21, P1, DOI 10.3310/hta21790
   Pigo F, 2013, INT J COLORECTAL DIS, V28, P399, DOI 10.1007/s00384-012-1583-7
   Pioche M, 2018, GASTROINTEST ENDOSC, V88, P107, DOI 10.1016/j.gie.2018.01.025
   Pohl J, 2009, GUT, V58, P73, DOI 10.1136/gut.2008.153601
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Povyakalo AA, 2013, MED DECIS MAKING, V33, P98, DOI 10.1177/0272989X12465490
   Puig I, 2019, CURR OPIN GASTROEN, V35, P432, DOI 10.1097/MOG.0000000000000570
   Puig I, 2019, GASTROENTEROLOGY, V156, P75, DOI 10.1053/j.gastro.2018.10.004
   Rahmi G, 2015, AM J GASTROENTEROL, V110, P288, DOI 10.1038/ajg.2014.423
   Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259
   Ramsoekh D, 2010, GUT, V59, P785, DOI 10.1136/gut.2008.151589
   Rastogi A, 2014, GASTROINTEST ENDOSC, V79, P390, DOI 10.1016/j.gie.2013.07.032
   Rastogi A, 2011, GASTROINTEST ENDOSC, V74, P593, DOI 10.1016/j.gie.2011.04.050
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Regula J, 2006, NEW ENGL J MED, V355, P1863, DOI 10.1056/NEJMoa054967
   Repici A, 2016, GASTROINTEST ENDOSC, V84, P479
   Repici A, 2019, GASTROENTEROLOGY, V156, P2198, DOI 10.1053/j.gastro.2019.02.001
   Repici A, 2013, GASTROINTEST ENDOSC, V78, P106, DOI 10.1016/j.gie.2013.01.035
   Rex DK, 2003, AM J GASTROENTEROL, V98, P2000, DOI 10.1016/S0002-9270(03)00625-7
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rex DK, 2009, AM J GASTROENTEROL, V104, P149, DOI 10.1038/ajg.2008.35
   Richardson WS, 1995, ACP J CLUB, V123, pA12, DOI DOI 10.7326/ACPJC-1995-123-3-A12
   Pons FR, 2018, WORLD J GASTROENTERO, V24, P5179, DOI 10.3748/wjg.v24.i45.5179
   Rivero Sanchez L, 2018, UNITED EUR GASTROENT, V6, pA117
   Rivero-Sanchez L, 2019, ENDOSCOPY, V51, P637, DOI 10.1055/a-0925-4956
   Rivero-Sanchez L, 2017, ENDOSCOPY, V49, P44, DOI 10.1055/s-0042-115640
   Roelandt P, 2019, ENDOSCOPY, V51, P237, DOI 10.1055/a-0755-7471
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Ross C., 2018, IBMS WATSON SUPERCOM
   Rutter MD, 2004, GUT, V53, P256, DOI 10.1136/gut.2003.016386
   Sakamoto T, 2013, COLORECTAL DIS, V15, pE295, DOI 10.1111/codi.12210
   Sakamoto T, 2018, GASTROINTEST ENDOSC, V87, P1318, DOI 10.1016/j.gie.2017.12.021
   Sakamoto T, 2012, J GASTROEN HEPATOL, V27, P351, DOI 10.1111/j.1440-1746.2011.06854.x
   Sano Y, 2009, GASTROINTEST ENDOSC, V69, P278, DOI 10.1016/j.gie.2008.04.066
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Shahid MW, 2012, AM J GASTROENTEROL, V107, P231, DOI 10.1038/ajg.2011.376
   Shapiro R, 2012, INT J COLORECTAL DIS, V27, P1071, DOI 10.1007/s00384-012-1409-7
   Aladren BS, 2019, ENDOSC INT OPEN, V7, pE743, DOI 10.1055/a-0839-4514
   Singh R, 2013, DIGEST ENDOSC, V25, P16, DOI 10.1111/den.12075
   Sinh P, 2015, DIGEST ENDOSC, V27, P374, DOI 10.1111/den.12403
   Smith SCL, 2019, DIGEST ENDOSC, V31, P535, DOI 10.1111/den.13389
   Solon C, 2016, J MED ECON, V19, P1040, DOI 10.1080/13696998.2016.1192550
   Stock C, 2010, ENDOSCOPY, V42, P546, DOI 10.1055/s-0029-1244127
   Stoffel EM, 2008, CANCER PREV RES, V1, P470, DOI 10.1158/1940-6207.CAPR-08-0098
   Subramanian V, 2011, ENDOSCOPY, V43, P499, DOI 10.1055/s-0030-1256207
   Subramanian V, 2011, ALIMENT PHARM THER, V33, P304, DOI 10.1111/j.1365-2036.2010.04525.x
   Sugimoto S, 2017, GASTROINTEST ENDOSC, V85, P639, DOI 10.1016/j.gie.2016.11.013
   Sumimoto K, 2017, GASTROINTEST ENDOSC, V86, P700, DOI 10.1016/j.gie.2017.02.018
   Sumimoto K, 2017, GASTROINTEST ENDOSC, V85, P816, DOI 10.1016/j.gie.2016.07.035
   Suna N, 2015, ACTA GASTRO-ENT BELG, V78, P287
   Takeuchi Y, 2019, GASTROINTEST ENDOSC, V89, P460, DOI 10.1016/j.gie.2018.11.012
   Togashi K, 2009, GASTROINTEST ENDOSC, V69, P734, DOI 10.1016/j.gie.2008.10.063
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Tsai FC, 2011, DIGEST DIS SCI, V56, P2384, DOI 10.1007/s10620-011-1598-x
   Tsai TL, 2003, J AM MED INFORM ASSN, V10, P478, DOI 10.1197/jamia.M1279
   Turner KO, 2018, AM J GASTROENTEROL, V113, P303, DOI 10.1038/ajg.2017.439
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Van Assche G, 2013, J CROHNS COLITIS, V7, P1, DOI 10.1016/j.crohns.2012.09.005
   van den Broek FJC, 2008, GUT, V57, P1083, DOI 10.1136/gut.2007.144097
   van den Broek FJC, 2011, ENDOSCOPY, V43, P108, DOI 10.1055/s-0030-1255956
   van den Broek FJC, 2014, AM J GASTROENTEROL, V109, P715, DOI 10.1038/ajg.2011.93
   van den Broek FJC, 2009, CLIN GASTROENTEROL H, V7, P288, DOI 10.1016/j.cgh.2008.10.025
   van Leerdam ME, 2019, ENDOSCOPY, V51, P877, DOI 10.1055/a-0965-0605
   Vemulapalli KC, 2012, GASTROINTEST ENDOSC, V75, P1206, DOI 10.1016/j.gie.2012.01.033
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   Vleugels JLA, 2019, GASTROENTEROLOGY, V156, P623, DOI 10.1053/j.gastro.2018.10.050
   Vleugels JLA, 2018, J CROHNS COLITIS, V12, P1438, DOI 10.1093/ecco-jcc/jjy129
   Vleugels JLA, 2018, GASTROENTEROLOGY, V154, P1682, DOI 10.1053/j.gastro.2018.01.063
   Vleugels JLA, 2018, LANCET GASTROENTEROL, V3, P305, DOI 10.1016/S2468-1253(18)30055-4
   Vleugels JLA, 2017, ENDOSC INT OPEN, V5, pE1197, DOI 10.1055/s-0043-113565
   von Renteln D, 2018, CLIN GASTROENTEROL H, V16, P706, DOI 10.1016/j.cgh.2017.11.036
   Vu HT, 2015, DIGEST DIS SCI, V60, P502, DOI 10.1007/s10620-014-3376-z
   Wallace MB, 2014, GASTROINTEST ENDOSC, V80, P1072, DOI 10.1016/j.gie.2014.05.305
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Watanabe T, 2016, GASTROENTEROLOGY, V151, P1122, DOI 10.1053/j.gastro.2016.08.002
   WESTON AP, 1995, AM J GASTROENTEROL, V90, P24
   Yoo TW, 2007, HEPATO-GASTROENTEROL, V54, P418
   Zhao ZY, 2015, ENDOSC INT OPEN, V3, pE226, DOI 10.1055/s-0034-1391708
   Zimmermann-Fraedrich K, 2018, ENDOSCOPY, V50, P878, DOI 10.1055/a-0607-2636
NR 252
TC 132
Z9 135
U1 1
U2 11
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 0013-726X
EI 1438-8812
J9 ENDOSCOPY
JI Endoscopy
PD DEC
PY 2019
VL 51
IS 12
BP 1155
EP 1179
DI 10.1055/a-1031-7657
PG 25
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA JU6WR
UT WOS:000501815100042
PM 31711241
OA Green Submitted, Green Accepted, Bronze
DA 2023-08-21
ER

PT J
AU Ebigbo, A
   Palm, C
   Probst, A
   Mendel, R
   Manzeneder, J
   Prinz, F
   de Souza, LA
   Papa, JP
   Siersema, P
   Messmann, H
AF Ebigbo, Alanna
   Palm, Christoph
   Probst, Andreas
   Mendel, Robert
   Manzeneder, Johannes
   Prinz, Friederike
   de Souza, Luis A.
   Papa, Joao P.
   Siersema, Peter
   Messmann, Helmut
TI A technical review of artificial intelligence as applied to
   gastrointestinal endoscopy: clarifying the terminology
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Review
ID HELICOBACTER-PYLORI INFECTION; COMPUTER-AIDED DIAGNOSIS;
   BARRETTS-ESOPHAGUS; CLASSIFICATION; LESIONS; CANCER; SYSTEM
AB Background and aim The growing number of publications on the application of artificial intelligence (AI) in medicine underlines the enormous importance and potential of this emerging field of research. In gastrointestinal endoscopy, AI has been applied to all segments of the gastrointestinal tract most importantly in the detection and characterization of colorectal polyps. However, AI research has been published also in the stomach and esophagus for both neoplastic and non-neoplastic disorders. The various technical as well as medical aspects of AI, however, remain confusing especially for non-expert physicians. This physician-engineer co-authored review explains the basic technical aspects of AI and provides a comprehensive overview of recent publications on AI in gastrointestinal endoscopy. Finally, a basic insight is offered into understanding publications on AI in gastrointestinal endoscopy.
C1 [Ebigbo, Alanna; Probst, Andreas; Manzeneder, Johannes; Prinz, Friederike; Messmann, Helmut] Univ Klinikum Augsburg, Dept Gastroenterol, Augsburg, Germany.
   [Palm, Christoph; Mendel, Robert; de Souza, Luis A.] Ostbayer TH Regensburg OTH Regensburg, Regensburg Med Image Comp ReMIC, Regensburg, Germany.
   [Palm, Christoph; Mendel, Robert] OTH Regensburg, Regensburg Ctr Hlth Sci & Technol, Regensburg, Germany.
   [de Souza, Luis A.] Univ Fed Sao Carlos, Dept Comp, Sao Carlos, SP, Brazil.
   [Papa, Joao P.] Sao Paulo State Univ, Dept Comp, Sao Paulo, SP, Brazil.
   [Siersema, Peter] Radboud Univ Nijmegen, Dept Gastroenterol & Hepatol, Med Ctr, Nijmegen, Netherlands.
C3 Universidade Federal de Sao Carlos; Universidade Estadual Paulista;
   Radboud University Nijmegen
RP Ebigbo, A (通讯作者)，Univ Klinikum Augsburg, Stenglinstr 2, D-86156 Augsburg, Germany.
EM Alanna.ebigbo@gmx.de
RI Messmann, Helmut/AAB-6758-2020; Ebigbo, Alanna/ACP-0443-2022; Papa, Joao
   Paulo/ABC-6283-2020; Siersema, Peter/V-1636-2019; Messmann,
   Helmut/AAQ-3568-2021; Palm, Christoph/F-4943-2014
OI Papa, Joao Paulo/0000-0002-6494-7514; Palm,
   Christoph/0000-0001-9468-2871; Souza Jr., Luis
   Antonio/0000-0002-7060-6097
CR Baker JA, 2003, AM J ROENTGENOL, V181, P1083, DOI 10.2214/ajr.181.4.1811083
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   de Groof J, 2019, UNITED EUR GASTROENT, V7, P538, DOI 10.1177/2050640619837443
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ghatwary N, 2019, INT J COMPUT ASS RAD, V14, P611, DOI 10.1007/s11548-019-01914-4
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Iizuka T, 2008, J GASTROEN HEPATOL, V23, P1358, DOI 10.1111/j.1440-1746.2008.05528.x
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kanesaka T, 2018, GASTROINTEST ENDOSC, V87, P1339, DOI 10.1016/j.gie.2017.11.029
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Mendel R., 2017, BILDVERARBEITUNG MED, P80, DOI DOI 10.1007/978-3-662-54345-0_23
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Nakashima H, 2018, ANN GASTROENTEROL, V31, P462, DOI 10.20524/aog.2018.0269
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Scholvinck DW, 2017, ENDOSCOPY, V49, P113, DOI 10.1055/s-0042-118312
   Sharma P, 2016, GASTROENTEROLOGY, V150, P591, DOI 10.1053/j.gastro.2015.11.037
   Topol E, 2019, DEEP MED
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wong GLH, 2019, ALIMENT PHARM THER, V49, P912, DOI 10.1111/apt.15145
   Zhao YY, 2019, ENDOSCOPY, V51, P333, DOI 10.1055/a-0756-8754
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 29
TC 30
Z9 31
U1 1
U2 7
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD DEC
PY 2019
VL 7
IS 12
BP E1616
EP E1623
DI 10.1055/a-1010-5705
PG 8
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA JU6TW
UT WOS:000501807800006
PM 31788542
OA Green Published, Green Submitted, gold
DA 2023-08-21
ER

PT J
AU Furukawa, R
   Nagamatsu, G
   Oka, S
   Kotachi, T
   Okamoto, Y
   Tanaka, S
   Kawasaki, H
AF Furukawa, Ryo
   Nagamatsu, Genki
   Oka, Shiro
   Kotachi, Takahiro
   Okamoto, Yuki
   Tanaka, Shinji
   Kawasaki, Hiroshi
TI Simultaneous shape and camera-projector parameter estimation for 3D
   endoscopic system using CNN-based grid-oneshot scan
SO HEALTHCARE TECHNOLOGY LETTERS
LA English
DT Article
DE image matching; medical image processing; cameras; endoscopes; computer
   vision; feature extraction; stereo image processing; neural nets; image
   reconstruction; learning (artificial intelligence); extended bundle
   adjustment technique; camera-projector parameter estimation; 3D
   endoscopic system; CNN-based grid-oneshot scan; situ endoscopic
   diagnosis; polyp sizes; active stereo technique; special pattern;
   feature extraction; endoscope camera; pattern projection area;
   learning-based technique
AB For effective in situ endoscopic diagnosis and treatment, measurement of polyp sizes is important. For this purpose, 3D endoscopic systems have been researched. Among such systems, an active stereo technique, which projects a special pattern wherein each feature is coded, is a promising approach because of simplicity and high precision. However, previous works of this approach have problems. First, the quality of 3D reconstruction depended on the stabilities of feature extraction from the images captured by the endoscope camera. Second, due to the limited pattern projection area, the reconstructed region was relatively small. In this Letter, the authors propose a learning-based technique using convolutional neural networks to solve the first problem and an extended bundle adjustment technique, which integrates multiple shapes into a consistent single shape, to address the second. The effectiveness of the proposed techniques compared to previous techniques was evaluated experimentally.
C1 [Furukawa, Ryo] Hiroshima City Univ, Grad Sch Informat Sci, Hiroshima, Japan.
   [Nagamatsu, Genki; Kawasaki, Hiroshi] Kyushu Univ, Grad Sch, Fukuoka, Fukuoka, Japan.
   [Nagamatsu, Genki; Kawasaki, Hiroshi] Kyushu Univ, Fac Informat Sci & Elect Engn, Fukuoka, Fukuoka, Japan.
   [Oka, Shiro] Hiroshima Univ Hosp, Dept Gastroenterol & Metab, Hiroshima, Japan.
   [Kotachi, Takahiro; Okamoto, Yuki; Tanaka, Shinji] Hiroshima Univ Hosp, Dept Endoscopy, Hiroshima, Japan.
C3 Kyushu University; Kyushu University; Hiroshima University; Hiroshima
   University
RP Furukawa, R (通讯作者)，Hiroshima City Univ, Grad Sch Informat Sci, Hiroshima, Japan.
EM ryo-f@hiroshima-cu.ac.jp
RI Furukawa, Ryo/GWZ-2117-2022; Tanaka, Shinji/G-5266-2019; Oka,
   Shiro/AAZ-8368-2021
OI Furukawa, Ryo/0000-0002-2063-1008; 
FU JSPS/KAKENHI [16H02849, 16KK0151, 18H04119, 18K19824, MSRA CORE14];
   Grants-in-Aid for Scientific Research [16H02849] Funding Source: KAKEN
FX This work is supported by JSPS/KAKENHI 16H02849, 16KK0151, 18H04119,
   18K19824, and MSRA CORE14.
CR Carr JC, 1997, IEEE T MED IMAGING, V16, P96, DOI 10.1109/42.552059
   Furukawa R, 2016, IEEE ENG MED BIO, P2091, DOI 10.1109/EMBC.2016.7591140
   Furukawa R, 2016, LECT NOTES COMPUT SC, V9910, P399, DOI 10.1007/978-3-319-46466-4_24
   Geurten J, 2018, LECT NOTES COMPUT SC, V11073, P143, DOI 10.1007/978-3-030-00937-3_17
   Grasa OG, 2014, IEEE T MED IMAGING, V33, P135, DOI 10.1109/TMI.2013.2282997
   Inokuchi S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P806
   Lin JY, 2015, LECT NOTES COMPUT SC, V9349, P405, DOI 10.1007/978-3-319-24553-9_50
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Stoyanov D, 2010, LECT NOTES COMPUT SC, V6361, P275
   Visentini-Scarzanella M, 2012, IEEE IMAGE PROC, P25, DOI 10.1109/ICIP.2012.6466786
NR 11
TC 7
Z9 7
U1 0
U2 1
PU INST ENGINEERING TECHNOLOGY-IET
PI HERTFORD
PA MICHAEL FARADAY HOUSE SIX HILLS WAY STEVENAGE, HERTFORD SG1 2AY, ENGLAND
EI 2053-3713
J9 HEALTHC TECHNOL LETT
JI Healthc. Technol. Lett.
PD DEC
PY 2019
VL 6
IS 6
SI SI
BP 249
EP 254
DI 10.1049/htl.2019.0070
PG 6
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA KA3ZS
UT WOS:000505737400019
PM 32038866
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Guo, XD
   Zhang, N
   Guo, JF
   Zhang, HH
   Hao, YG
   Hang, JQ
AF Guo, Xudong
   Zhang, Na
   Guo, Jiefang
   Zhang, Huihe
   Hao, Youguo
   Hang, Jingqing
TI Automated polyp segmentation for colonoscopy images: A method based on
   convolutional neural networks and ensemble learning
SO MEDICAL PHYSICS
LA English
DT Article
DE colonoscopy image; deep learning; ensemble learning; polyp segmentation;
   transfer learning
AB Purpose: To automatically and efficiently segment the lesion area of the colonoscopy polyp image, a polyp segmentation method has been presented.
   Methods: An ensemble model of pretrained convolutional neural networks was proposed, using Unet-VGG, SegNet-VGG, and PSPNet. Firstly, the Unet-VGG is obtained by the first 10 layers of VGG16 as the contraction path of the left half of the Unet. Then, the SegNet-VGG is acquired by fine-tuned transfer learning VGG16, using the first 13 layers of VGG16 as the encoder of the SegNet and combined the original decoder of the SegNet. By adjusting the input size of the Unet-VGG, SegNet-VGG, and PSPNet, the preprocessed data can be correctly fed to the three network models. The three models are used as the basic trainer to train and segment the datasets. Based on the ensemble learning algorithm, the weight voting method is used to ensemble the segmentation results corresponding to single basic trainer.
   Results: Both IoU and DICE similarity score were used to evaluate the segmentation quality for cvc300 with 300 images, CVC-ClinicDB with 612 images, and ETIS-LaribPolypDB with 196 images. From the experimental results, the IoU and DICE obtained by the proposed method for the cvc300 datasets can reach up to 96.16% and 98.04%, respectively, the IoU and DICE for the CVCC-linicDB datasets can reach up to 96.66% and 98.30%, respectively, whereas the IoU and DICE for the ETIS-LaribPolypDB datasets can reach up to 96.95% and 98.45%, respectively. Evaluation of the IoU and DICE in our methods shows higher accuracy than previous methods.
   Conclusions: The experimental results show that the proposed method improved correspondingly in IoU and DICE compared to a single basic trainer. The range of improvement is 1.98%-6.38%. The proposed ensemble learning succeeds in automatic polyp segmentation, which potentially helps to establish more polyp datasets. (C) 2019 American Association of Physicists in Medicine
C1 [Guo, Xudong; Zhang, Na; Zhang, Huihe] Univ Shanghai Sci & Technol, Sch Med Instrument & Food Engn, Shanghai 200093, Peoples R China.
   [Guo, Jiefang] Changhai Hosp, Dept Gastroenterol, Shanghai 200433, Peoples R China.
   [Hao, Youguo; Hang, Jingqing] Shanghai Putuo Peoples Hosp, Dept Rehabil, Shanghai 200060, Peoples R China.
C3 University of Shanghai for Science & Technology; Naval Medical
   University
RP Guo, JF (通讯作者)，Changhai Hosp, Dept Gastroenterol, Shanghai 200433, Peoples R China.
EM zn_0506@163.com
RI Guo, Jiefang/AAD-9042-2021
FU Research Project on Community Medicine and Health Management of Shanghai
   Society of Integrated Traditional Chinese and Western Medicine
   [SH201741]; Key Funding Projects for Independent Innovation of Health
   System Research in Putuo District, Shanghai [ptkwws201708]
FX This study was supported by the Research Project on Community Medicine
   and Health Management of Shanghai Society of Integrated Traditional
   Chinese and Western Medicine (no: SH201741) and The Key Funding Projects
   for Independent Innovation of Health System Research in Putuo District,
   Shanghai (no: ptkwws201708).
CR Akbari M, 2018, POLYP SEGMENTATION C, DOI [10.1109/EMBC.2018.8512197, DOI 10.1109/EMBC.2018.8512197]
   Al-Kafri AS, 2019, IEEE ACCESS, V7, P43487, DOI 10.1109/ACCESS.2019.2908002
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bardhi O, 2017, IEEE INT SYMP SIGNAL, P445, DOI 10.1109/ISSPIT.2017.8388684
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, IEEE T MED IMAGING, V2017, P1
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dutta S, 2018, 2018 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET)
   Fehri H, 2019, IEEE T IMAGE PROCESS, V28, P3246, DOI 10.1109/TIP.2019.2895455
   Gao X, 2018, 2018 7TH INTERNATIONAL CONFERENCE ON SOCIAL SCIENCE, EDUCATION AND HUMANITIES RESEARCH (SSEHR 2018), P182, DOI 10.25236/ssehr.2018.036
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Jing Tang, 2018, 2018 33 YOUTH AC ANN, DOI [10.1109/YAC.2018.8406531, DOI 10.1109/YAC.2018.8406531]
   Kamal U, 2020, IEEE T INTELL TRANSP, V21, P1467, DOI 10.1109/TITS.2019.2911727
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Krishnan K, 2015, IEEE ENG MED BIO, P3093, DOI 10.1109/EMBC.2015.7319046
   Kumar N, 2017, IEEE T MED IMAGING, V36, P1550, DOI 10.1109/TMI.2017.2677499
   Kumar P, 2018, IEEE IMAGE PROC, P3503, DOI 10.1109/ICIP.2018.8451295
   Li QL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   LITTLESTONE N, 1994, INFORM COMPUT, V108, P212, DOI 10.1006/inco.1994.1009
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Maghsoudi OH, 2017, CONF REC ASILOMAR C, P209, DOI 10.1109/ACSSC.2017.8335168
   Miyamoto R, 2019, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2019.8702560
   Nguyen NQ, 2018, 2018 IEEE FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P208, DOI 10.1109/AIKE.2018.00048
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sasmal P, 2018, INT CONF CIRC SYST S, P201, DOI 10.1109/ICSIGSYS.2018.8372666
   Shan YF, 2018, 2018 INTERNATIONAL CONFERENCE ON CONTROL, ARTIFICIAL INTELLIGENCE, ROBOTICS & OPTIMIZATION (ICCAIRO), P147, DOI 10.1109/ICCAIRO.2018.00032
   Shin Y, 2018, IEEE ACCESS, V6, P56007, DOI 10.1109/ACCESS.2018.2872717
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Valliappan CA, 2019, ICASSP 2019 2019 IEE, DOI [10.1109/ICASSP.2019.8683153, DOI 10.1109/ICASSP.2019.8683153]
   Vazquez D., 2017, J HEALTHC ENG, P1
   Wang W, 2018, 2018 CHIN AUT C CAC, DOI [10.1109/CAC.2018, DOI 10.1109/CAC.2018]
   Weng Y, 2019, IEEE ACCESS, V7, P44247, DOI 10.1109/ACCESS.2019.2908991
   Wicke Kai, 2018, 2018 AIAA Aerospace Sciences Meeting, P1
   Xiao WT, 2018, IEEE INT C ELECTR TA
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI 10.1109/JSTARS.2018.2835377
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Yuan YX, 2018, IEEE J BIOMED HEALTH, V22, P1250, DOI 10.1109/JBHI.2017.2734329
   Zeng ZT, 2019, IEEE ACCESS, V7, P21420, DOI 10.1109/ACCESS.2019.2896920
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao X, 2018, 2018 AS PAC SIGN INF, DOI [10.23919/APSIPA.2018.8659654, DOI 10.23919/APSIPA.2018.8659654]
   Zhao Y, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P1, DOI 10.1109/AICAS.2019.8771573
   Zhou Z, 2012, ENSEMBLE METHODS FDN, DOI [10.1109/MCI.2012.2228600, DOI 10.1109/MCI.2012.2228600]
   Zhu B, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P55, DOI 10.1109/ICIVC.2018.8492747
NR 48
TC 25
Z9 26
U1 3
U2 33
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD DEC
PY 2019
VL 46
IS 12
BP 5666
EP 5676
DI 10.1002/mp.13865
PG 11
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA KP9VQ
UT WOS:000516580200031
PM 31610020
DA 2023-08-21
ER

PT J
AU Hsieh, YH
   Leung, FW
AF Hsieh, Yu-Hsi
   Leung, Felix W.
TI An overview of deep learning algorithms and water exchange in
   colonoscopy in improving adenoma detection
SO EXPERT REVIEW OF GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Review
DE Adenoma detection rate; water exchange; artificial intelligence; machine
   learning
ID BOWEL PREPARATION QUALITY; COMPUTER-AIDED DIAGNOSIS; GASTROINTESTINAL
   ENDOSCOPY; POLYP DETECTION; ARTIFICIAL-INTELLIGENCE; TIME; MULTICENTER;
   PREVALENCE; VALIDATION; HISTOLOGY
AB Introduction: Among the Gastrointestinal (GI) Endoscopy Editorial Board top 10 topics in advances in endoscopy in 2018, water exchange colonoscopy and artificial intelligence were both considered important advances. Artificial intelligence holds the potential to increase and water exchange significantly increases adenoma detection. Areas covered: The authors searched MEDLINE (1998-2019) using the following medical subject terms: water-aided, water-assisted and water exchange colonoscopy, adenoma, artificial intelligence, deep learning, computer-assisted detection, and neural networks. Additional related studies were manually searched from the reference lists of publications. Only fully published journal articles in English were reviewed. The latest date of the search was Aug10, 2019. Artificial intelligence, machine learning, and deep learning contribute to the promise of real-time computer-aided detection diagnosis. By emphasizing near-complete suction of infused water during insertion, water exchange provides salvage cleaning and decreases cleaning-related multi-tasking distractions during withdrawal, increasing adenoma detection. The review will address how artificial intelligence and water exchange can complement each other in improving adenoma detection during colonoscopy. Expert opinion: In 5 years, research on artificial intelligence will likely achieve real-time application and evaluation of factors contributing to quality colonoscopy. Better understanding and more widespread use of water exchange will be possible.
C1 [Hsieh, Yu-Hsi] Dalin Tzu Chi Hosp, Buddhist Tzu Chi Med Fdn, Chiayi, Taiwan.
   [Hsieh, Yu-Hsi] Tzu Chi Univ, Sch Med, Hualien, Taiwan.
   [Leung, Felix W.] Vet Affairs Greater Los Angeles Healthcare Syst, Sepulveda Ambulatory Care Ctr, North Hills, CA USA.
   [Leung, Felix W.] Univ Calif Los Angeles, David Geffen Sch Med, Los Angeles, CA 90095 USA.
C3 Buddhist Tzu Chi General Hospital; Dalin Tzu Chi Hospital; Tzu Chi
   University; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); VA Greater Los Angeles Healthcare System;
   University of California System; University of California Los Angeles;
   University of California Los Angeles Medical Center; David Geffen School
   of Medicine at UCLA
RP Hsieh, YH (通讯作者)，Dalin Tzu Chi Hosp, Buddhist Tzu Chi Med Fdn, Dept Med, Div Gastroenterol, 2 Minsheng Rd, Chiayi 62247, Taiwan.
EM hsieh.yuhsi@msa.hinet.net
FU 2016 Endoscopic Research Award titled, "A prospective RCT to Show
   Water-Exchange Cap Assisted Colonoscopy Significantly Increases ADR
   Compared with Water Exchange." (ASGE Sponsored Award, UCLA) [20174037];
   Veterans Affairs Merit Review [5101CX001418-02]
FX This paper was funded by the 2016 Endoscopic Research Award titled, "A
   prospective RCT to Show Water-Exchange Cap Assisted Colonoscopy
   Significantly Increases ADR Compared with Water Exchange." (ASGE
   Sponsored Award, UCLA #20174037). and the Veterans Affairs Merit Review
   (5101CX001418-02).
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Ahmad OF, 2019, LANCET GASTROENTEROL, V4, P71, DOI 10.1016/S2468-1253(18)30282-6
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Anderson JC, 2014, GASTROINTEST ENDOSC, V80, P463, DOI 10.1016/j.gie.2014.03.021
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Cadoni S, 2017, ENDOSCOPY, V49, P456, DOI 10.1055/s-0043-101229
   Calderwood AH, 2015, GASTROINTEST ENDOSC, V81, P691, DOI 10.1016/j.gie.2014.10.032
   Chokshi RV, 2012, GASTROINTEST ENDOSC, V75, P1197, DOI 10.1016/j.gie.2012.01.005
   Cohen J, 2019, GASTROINTEST ENDOSC, V90, P35, DOI 10.1016/j.gie.2019.03.020
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   de Lange T, 2018, WORLD J GASTROENTERO, V24, P5057, DOI 10.3748/wjg.v24.i45.5057
   East JE, 2007, AM J GASTROENTEROL, V102, P2529, DOI 10.1111/j.1572-0241.2007.01429.x
   Facciorusso A, 2019, CLIN GASTROENTEROL H, V17, P2439, DOI 10.1016/j.cgh.2018.11.058
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Filip D, 2012, WORLD J GASTROENTERO, V18, P4270, DOI 10.3748/wjg.v18.i32.4270
   Fritz CDL, 2018, DIGEST DIS SCI, V63, P3120, DOI 10.1007/s10620-018-5100-x
   Fuccio L, 2018, GASTROINTEST ENDOSC, V88, P589, DOI 10.1016/j.gie.2018.06.028
   Hsieh YH, 2019, UNITED EUR GASTROENT, V7, P230, DOI 10.1177/2050640618817105
   Hsieh YH, 2017, GASTROINTEST ENDOSC, V86, P192, DOI 10.1016/j.gie.2016.12.005
   Hwang S, 2008, IEEE ENG MED BIO, P3004, DOI 10.1109/IEMBS.2008.4649835
   Jia H, 2019, J CLIN GASTROENTEROL, V53, P523, DOI 10.1097/MCG.0000000000001080
   Jia H, 2017, AM J GASTROENTEROL, V112, P568, DOI 10.1038/ajg.2016.501
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lebwohl B, 2011, GASTROINTEST ENDOSC, V73, P1207, DOI 10.1016/j.gie.2011.01.051
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000007468
   Lee RH, 2011, GASTROINTEST ENDOSC, V74, P128, DOI 10.1016/j.gie.2011.03.003
   Leung JW, 2019, UNITED EUR GASTROENT, V7, P477, DOI 10.1177/2050640619832196
   Min JK, 2019, GUT LIVER, V13, P388, DOI 10.5009/gnl18384
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259
   Rembacken B, 2012, ENDOSCOPY, V44, P957, DOI 10.1055/s-0032-1325686
   Repici A, 2019, GASTROENTEROLOGY, V156, P2198, DOI 10.1053/j.gastro.2019.02.001
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Ruffle JK, 2019, AM J GASTROENTEROL, V114, P422, DOI 10.1038/s41395-018-0268-4
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Sawhney MS, 2008, GASTROENTEROLOGY, V135, P1892, DOI 10.1053/j.gastro.2008.08.024
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Soetikno RM, 2008, JAMA-J AM MED ASSOC, V299, P1027, DOI 10.1001/jama.299.9.1027
   Stanek SR, 2013, COMPUT METH PROG BIO, V112, P407, DOI 10.1016/j.cmpb.2013.07.028
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vinsard DG, 2019, GASTROINTEST ENDOSC, V90, P55, DOI 10.1016/j.gie.2019.03.019
   von Renteln D, 2017, GASTROINTEST ENDOSC, V85, P574, DOI 10.1016/j.gie.2016.08.021
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Yang MH, 2013, BMC GASTROENTEROL, V13, DOI 10.1186/1471-230X-13-124
   Zhao SB, 2019, GASTROENTEROLOGY, V156, P1661, DOI 10.1053/j.gastro.2019.01.260
NR 58
TC 9
Z9 9
U1 1
U2 14
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1747-4124
EI 1747-4132
J9 EXPERT REV GASTROENT
JI Expert Rev. Gastroenterol. Hepatol.
PD DEC 2
PY 2019
VL 13
IS 12
BP 1153
EP 1160
DI 10.1080/17474124.2019.1694903
EA DEC 2019
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA JS0JE
UT WOS:000499573900001
PM 31755802
DA 2023-08-21
ER

PT J
AU Itoh, H
   Roth, H
   Oda, M
   Misawa, M
   Mori, Y
   Kudo, SE
   Mori, K
AF Itoh, Hayato
   Roth, Holger
   Oda, Masahiro
   Misawa, Masashi
   Mori, Yuichi
   Kudo, Shin-Ei
   Mori, Kensaku
TI Stable polyp-scene classification via subsampling and residual learning
   from an imbalanced large dataset
SO HEALTHCARE TECHNOLOGY LETTERS
LA English
DT Article
DE feature extraction; image classification; learning (artificial
   intelligence); cancer; biological organs; computerised tomography;
   endoscopes; medical image processing; convolutional neural nets;
   polyp-detection dataset; stable polyp-scene classification method; false
   positive detection; high-performance CAD system; nonpolyp scenes;
   colonoscopic video dataset; unstable polyp detection; subsampling;
   residual learning; imbalanced large dataset; computer-assisted diagnosis
   system; three-dimensional convolutional neural network; 3D CNN
ID COLONOSCOPY
AB This Letter presents a stable polyp-scene classification method with low false positive (FP) detection. Precise automated polyp detection during colonoscopies is essential for preventing colon-cancer deaths. There is, therefore, a demand for a computer-assisted diagnosis (CAD) system for colonoscopies to assist colonoscopists. A high-performance CAD system with spatiotemporal feature extraction via a three-dimensional convolutional neural network (3D CNN) with a limited dataset achieved about 80% detection accuracy in actual colonoscopic videos. Consequently, further improvement of a 3D CNN with larger training data is feasible. However, the ratio between polyp and non-polyp scenes is quite imbalanced in a large colonoscopic video dataset. This imbalance leads to unstable polyp detection. To circumvent this, the authors propose an efficient and balanced learning technique for deep residual learning. The authors' method randomly selects a subset of non-polyp scenes whose number is the same number of still images of polyp scenes at the beginning of each epoch of learning. Furthermore, they introduce post-processing for stable polyp-scene classification. This post-processing reduces the FPs that occur in the practical application of polyp-scene classification. They evaluate several residual networks with a large polyp-detection dataset consisting of 1027 colonoscopic videos. In the scene-level evaluation, their proposed method achieves stable polyp-scene classification with 0.86 sensitivity and 0.97 specificity.
C1 [Itoh, Hayato; Roth, Holger; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Misawa, Masashi; Mori, Yuichi; Kudo, Shin-Ei] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Tsuzuki Ku, Yokohama, Kanagawa 2248503, Japan.
   [Mori, Kensaku] Nagoya Univ, Informat Technol Ctr, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Mori, Kensaku] Res Ctr Med Bigdata, Natl Inst Informat, Chiyoda Ku, Hitotsubashi 2-1-2, Tokyo 1018430, Japan.
C3 Nagoya University; Showa University; Nagoya University; Research
   Organization of Information & Systems (ROIS); National Institute of
   Informatics (NII) - Japan
RP Itoh, H (通讯作者)，Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM hitoh@mori.m.is.nagoya-u.ac.jp
RI Itoh, Hayato/AAM-4022-2021; Misawa, Masashi/H-9004-2019; Mori,
   Yuichi/AAU-5406-2020
OI Itoh, Hayato/0000-0002-1410-1078; Misawa, Masashi/0000-0002-8520-2036;
   Oda, Masahiro/0000-0001-7714-422X; Mori, Yuichi/0000-0003-2262-0334;
   Roth, Holger/0000-0002-3662-8743
FU AMED [19hs0110006h0003]; MEXT KAKENHI [26108006, 17H00867, 17K20099];
   JSPS Bilateral Joint Research Project
FX Parts of this research were supported by AMED (19hs0110006h0003), MEXT
   KAKENHI (26108006, 17H00867, 17K20099), and the JSPS Bilateral Joint
   Research Project. Conflict of interest: None declared.
CR [Anonymous], P INT WORKSH LEARN I
   [Anonymous], P VISIGRAPP PRAG CZE
   [Anonymous], SUBCH END VIS CHALL
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   King G., 2001, POLIT ANAL, V9, P137, DOI DOI 10.1093/OXFORDJOURNALS.PAN.A004868
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Miyato T., 2018, P ICLR, P1
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Neyshabur B., 2018, P INT C LEARN REPR I
   Vo N, 2017, IEEE INT CONF BIG DA, P797, DOI 10.1109/BigData.2017.8257995
   Ratner AJ, 2017, ADV NEUR IN, V30
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wittenburg P., 2006, P 5 INT C LANGUAGE R, P1556
   Zagoruyko S, 2016, BRIT MACH VIS C
NR 28
TC 4
Z9 4
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2053-3713
J9 HEALTHC TECHNOL LETT
JI Healthc. Technol. Lett.
PD DEC
PY 2019
VL 6
IS 6
SI SI
BP 237
EP 242
DI 10.1049/htl.2019.0079
PG 6
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA KA3ZS
UT WOS:000505737400017
PM 32038864
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Taunk, P
   Atkinson, CD
   Lichtenstein, D
   Rodriguez-Diaz, E
   Singh, SK
AF Taunk, Pushpak
   Atkinson, Christopher D.
   Lichtenstein, David
   Rodriguez-Diaz, Eladio
   Singh, Satish K.
TI Computer-assisted assessment of colonic polyp histopathology using
   probe-based confocal laser endomicroscopy
SO INTERNATIONAL JOURNAL OF COLORECTAL DISEASE
LA English
DT Article
DE Confocal laser endomicroscopy; Colorectal cancer; Polyp histology;
   Machine learning
ID SOCIETY-TASK-FORCE; COLORECTAL-CANCER; WHITE-LIGHT; COLONOSCOPY
   SURVEILLANCE; VIRTUAL CHROMOENDOSCOPY; BARRETTS-ESOPHAGUS; COMMUNITY
   PRACTICE; OPTICAL BIOPSY; HISTOLOGY; ACCURACY
AB Introduction Probe-based confocal laser endomicroscopy (pCLE) is a promising modality for classifying polyp histology in vivo, but decision making in real-time is hampered by high-magnification targeting and by the learning curve for image interpretation. The aim of this study is to test the feasibility of a system combining the use of a low-magnification, wider field-of-view pCLE probe and a computer-assisted diagnosis (CAD) algorithm that automatically classifies colonic polyps. Methods This feasibility study utilized images of polyps from 26 patients who underwent colonoscopy with pCLE. The pCLE images were reviewed offline by two expert and five junior endoscopists blinded to index histopathology. A subset of images was used to train classification software based on the consensus of two GI histopathologists. Images were processed to extract image features as inputs to a linear support vector machine classifier. We compared the CAD algorithm's prediction accuracy against the classification accuracy of the endoscopists. Results We utilized 96 neoplastic and 93 non-neoplastic confocal images from 27 neoplastic and 20 non-neoplastic polyps. The CAD algorithm had sensitivity of 95%, specificity of 94%, and accuracy of 94%. The expert endoscopists had sensitivities of 98% and 95%, specificities of 98% and 96%, and accuracies of 98% and 96%, while the junior endoscopists had, on average, a sensitivity of 60%, specificity of 85%, and accuracy of 73%. Conclusion The CAD algorithm showed comparable performance to offline review by expert endoscopists and improved performance when compared to junior endoscopists and may be useful for assisting clinical decision making in real time.
C1 [Taunk, Pushpak] Univ S Florida, Morsani Coll Med, Div Digest Dis & Nutr, Tampa, FL 33612 USA.
   [Atkinson, Christopher D.; Singh, Satish K.] VA Boston Healthcare Syst, Sect Gastroenterol, Dept Med, Boston, MA 02130 USA.
   [Lichtenstein, David] Boston Univ, Sch Med, Boston Med Ctr, Boston, MA 02118 USA.
   [Rodriguez-Diaz, Eladio] VA Boston Healthcare Syst, Res Serv, Boston, MA USA.
   [Singh, Satish K.] Boston Univ, Sch Med, Boston, MA 02118 USA.
   [Singh, Satish K.] Boston Univ, Coll Engn, Boston, MA 02215 USA.
C3 State University System of Florida; University of South Florida; US
   Department of Veterans Affairs; Veterans Health Administration (VHA);
   Harvard University; VA Boston Healthcare System; Boston Medical Center;
   Boston University; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); Harvard University; VA Boston Healthcare System;
   Boston University; Boston University
RP Singh, SK (通讯作者)，VA Boston Healthcare Syst, Sect Gastroenterol, Dept Med, Boston, MA 02130 USA.; Singh, SK (通讯作者)，Boston Univ, Sch Med, Boston, MA 02118 USA.; Singh, SK (通讯作者)，Boston Univ, Coll Engn, Boston, MA 02215 USA.
EM ptaunk@heahh.usf.edu; christopher.atkinson2@va.gov;
   David.Lichtenstein@bmc.org; Eladio.Rodriguez-Diaz@va.gov;
   Satish.Singh@va.gov
OI Singh, Satish/0000-0002-7664-3155
CR Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Andre B, 2011, MED IMAGE ANAL, V15, P460, DOI 10.1016/j.media.2011.02.003
   [Anonymous], 1998, NY WILEY
   Buchner AM, 2010, GASTROENTEROLOGY, V138, P834, DOI 10.1053/j.gastro.2009.10.053
   Buda A, 2014, J CROHNS COLITIS, V8, P304, DOI 10.1016/j.crohns.2013.09.005
   Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Canto MI, 2014, GASTROINTEST ENDOSC, V79, P211, DOI 10.1016/j.gie.2013.09.020
   Dhar A, 2006, GASTROINTEST ENDOSC, V63, P257, DOI 10.1016/j.gie.2005.07.026
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P1022, DOI 10.1016/j.gie.2012.01.020
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P494, DOI 10.1016/j.gie.2011.08.002
   Huang CS, 2004, AM J GASTROENTEROL, V99, P2242, DOI 10.1111/j.1572-0241.2004.40131.x
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jain AK, 1989, FUNDAMENTALS DIGITAL
   Kiesslich R, 2012, GUT, V61, P1146, DOI 10.1136/gutjnl-2011-300695
   Kim YS, 2011, CLIN GASTROENTEROL H, V9, P744, DOI 10.1016/j.cgh.2011.05.021
   Kuiper T, 2012, AM J GASTROENTEROL, V107, P543, DOI 10.1038/ajg.2012.14
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P603, DOI 10.1016/j.gie.2011.04.049
   Levin B, 2008, CA-CANCER J CLIN, V58, P130, DOI 10.3322/CA.2007.0018
   Lieberman D, 2008, GASTROENTEROLOGY, V135, P1100, DOI 10.1053/j.gastro.2008.06.083
   Liu JJ, 2011, J CLIN GASTROENTEROL, V45, P240, DOI 10.1097/MCG.0b013e3181fbdb8a
   Liu JJ, 2011, GASTROINTEST ENDOSC, V73, P1174, DOI 10.1016/j.gie.2011.01.018
   Meining A, 2011, GASTROINTEST ENDOSC, V74, P961, DOI 10.1016/j.gie.2011.05.009
   Moussata D, 2011, GUT, V60, P26, DOI 10.1136/gut.2010.213264
   Neumann H, 2012, INFLAMM BOWEL DIS, V18, P2261, DOI 10.1002/ibd.22907
   Parkin DM, 2001, EUR J CANCER, V37, pS4, DOI 10.1016/S0959-8049(01)00267-2
   Pohl J, 2008, AM J GASTROENTEROL, V103, P562, DOI 10.1111/j.1572-0241.2007.01670.x
   Rastogi A, 2014, GASTROINTEST ENDOSC, V79, P390, DOI 10.1016/j.gie.2013.07.032
   Rastogi A, 2009, AM J GASTROENTEROL, V104, P2422, DOI 10.1038/ajg.2009.403
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rodriguez-Diaz E, 2015, GASTROINTEST ENDOSC, V81, P539, DOI 10.1016/j.gie.2014.07.012
   Rodriguez-Diaz E, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3592488
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Shahid MW, 2012, ENDOSCOPY, V44, P343, DOI 10.1055/s-0031-1291589
   Shahid MW, 2012, AM J GASTROENTEROL, V107, P231, DOI 10.1038/ajg.2011.376
   Sharma P, 2011, GASTROINTEST ENDOSC, V74, P465, DOI 10.1016/j.gie.2011.04.004
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Singh R, 2013, J GASTROEN HEPATOL, V28, P472, DOI 10.1111/jgh.12098
   Stork D. G., 2001, PATTERN CLASSIFICATI, V2nd
   Ussui VM, 2012, GASTROENT RES PRACT, V2012, DOI 10.1155/2012/545679
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Wallace M, 2011, ENDOSCOPY, V43, P882, DOI 10.1055/s-0030-1256632
   Winawer SJ, 2006, GASTROENTEROLOGY, V130, P1872, DOI 10.1053/j.gastro.2006.03.012
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
NR 45
TC 9
Z9 11
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0179-1958
EI 1432-1262
J9 INT J COLORECTAL DIS
JI Int. J. Colorectal Dis.
PD DEC
PY 2019
VL 34
IS 12
BP 2043
EP 2051
DI 10.1007/s00384-019-03406-y
EA NOV 2019
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA JT7OL
UT WOS:000494764900001
PM 31696259
DA 2023-08-21
ER

PT J
AU Kim, DH
   Cho, H
   Cho, HC
AF Kim, Dong-hyun
   Cho, HyunChin
   Cho, Hyun-chong
TI Gastric Lesion Classification Using Deep Learning Based on Fast and
   Robust Fuzzy C-Means and Simple Linear Iterative Clustering Superpixel
   Algorithms
SO JOURNAL OF ELECTRICAL ENGINEERING & TECHNOLOGY
LA English
DT Article
DE Gastric disease; Computer aided diagnosis; CADx; Endoscopy; Deep
   learning; Inception module
ID COMPUTER-AIDED DIAGNOSIS; ENDOSCOPY
AB Gastric diseases are a common medical issue; they can be detected using endoscopy equipment. Computer-aided diagnosis (CADx) systems can help internists identify gastric diseases more accurately. In this paper, we present a CADx system that can detect and classify gastric diseases such as gastric polyps, gastric ulcers, gastritis, and cancer. The system uses a deep learning model as a GoogLeNet based on an Inception module. The fast and robust fuzzy C-means (FRFCM) and simple linear iterative clustering (SLIC) superpixel algorithms are applied for image segmentation during preprocessing. The FRFCM algorithm, which is based on morphological reconstruction and membership filtering, is much faster and more robust than fuzzy C-means. In addition, the SLIC superpixel algorithm adapts the k-means clustering method to efficiently generate superpixels. These two approaches produce a feasible method of classifying normal and abnormal gastric lesions. The areas under the receiver operating characteristic curves were 0.85 and 0.87 for normal and abnormal lesions, respectively. The proposed CADx system also performs reliably.
C1 [Cho, Hyun-chong] Kangwon Natl Univ, Dept Elect Engn, Chuncheon Si, South Korea.
   [Kim, Dong-hyun; Cho, Hyun-chong] Kangwon Natl Univ, Interdisciplinary Grad Program BIT Med Convergenc, Chuncheon Si, South Korea.
   [Cho, HyunChin] Gyeongsang Natl Univ, Dept Internal Med, Sch Med, Jinju Si, South Korea.
   [Cho, HyunChin] Gyeongsang Natl Univ, Inst Hlth Sci, Sch Med, Jinju Si, South Korea.
   [Cho, HyunChin] Gyeongsang Natl Univ Hosp, Jinju Si, South Korea.
C3 Kangwon National University; Kangwon National University; Gyeongsang
   National University; Gyeongsang National University; Gyeongsang National
   University; Gyeongsang National University Hospital
RP Cho, HC (通讯作者)，Kangwon Natl Univ, Dept Elect Engn, Chuncheon Si, South Korea.; Cho, HC (通讯作者)，Kangwon Natl Univ, Interdisciplinary Grad Program BIT Med Convergenc, Chuncheon Si, South Korea.
EM wlflqna@gmail.com; hccholuck@gmail.com; hyuncho@kangwon.ac.kr
RI Kim, Dong-Hyun/AAH-3043-2020
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2017R1E1A1A03070297]; MSIT (Ministry of Science and ICT), Korea, under
   the ITRC (Information Technology Research Center) support program
   [IITP-2019-2018-0-01433]; National Research Foundation of Korea
   [2017R1E1A1A03070297] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2017R1E1A1A03070297). This research was supported by the MSIT (Ministry
   of Science and ICT), Korea, under the ITRC (Information Technology
   Research Center) support program (IITP-2019-2018-0-01433) supervised by
   the IITP (Institute for Information & communications Technology
   Promotion).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bray F, 2019, CA CANC J CLIN, V2018
   Choi Il Ju, 2018, Korean J Gastroenterol, V72, P245, DOI 10.4166/kjg.2018.72.5.245
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   DONGHYUN KIM, 2018, 전기학회논문지, V67, P928
   Kim YI., 1992, KOR J GASTROENTEROL, V24, P216
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Lee TC, 2013, IEEE ENG MED BIO, P4430, DOI 10.1109/EMBC.2013.6610529
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Ministry of Health and Welfare Korea National Cancer Center, 2019, NAT CANC REG STAT 20
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
NR 14
TC 7
Z9 7
U1 1
U2 18
PU SPRINGER SINGAPORE PTE LTD
PI SINGAPORE
PA #04-01 CENCON I, 1 TANNERY RD, SINGAPORE 347719, SINGAPORE
SN 1975-0102
EI 2093-7423
J9 J ELECTR ENG TECHNOL
JI J. Electr. Eng. Technol.
PD NOV
PY 2019
VL 14
IS 6
BP 2549
EP 2556
DI 10.1007/s42835-019-00259-x
PG 8
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA JV1TL
UT WOS:000502151600032
DA 2023-08-21
ER

PT J
AU Shi, CF
   Xue, Y
   Jiang, C
   Tian, H
   Liu, B
AF Shi, Chenfei
   Xue, Yan
   Jiang, Chuan
   Tian, Hui
   Liu, Bei
TI Gastroscopic Panoramic View: Application to Automatic Polyps Detection
   under Gastroscopy
SO COMPUTATIONAL AND MATHEMATICAL METHODS IN MEDICINE
LA English
DT Article
ID CANCER
AB Endoscopic diagnosis is an important means for gastric polyp detection. In this paper, a panoramic image of gastroscopy is developed, which can display the inner surface of the stomach intuitively and comprehensively. Moreover, the proposed automatic detection solution can help doctors locate the polyps automatically and reduce missed diagnosis. The main contributions of this paper are firstly, a gastroscopic panorama reconstruction method is developed. The reconstruction does not require additional hardware devices and can solve the problem of texture dislocation and illumination imbalance properly; secondly, an end-to-end multiobject detection for gastroscopic panorama is trained based on a deep learning framework. Compared with traditional solutions, the automatic polyp detection system can locate all polyps in the inner wall of the stomach in real time and assist doctors to find the lesions. Thirdly, the system was evaluated in the Affiliated Hospital of Zhejiang University. The results show that the average error of the panorama is less than 2mm, the accuracy of the polyp detection is 95%, and the recall rate is 99%. In addition, the research roadmap of this paper has guiding significance for endoscopy-assisted detection of other human soft cavities.
C1 [Shi, Chenfei; Xue, Yan; Jiang, Chuan; Tian, Hui; Liu, Bei] ZheJiang Univ, Sch Med, Womens Hosp, Hangzhou 310000, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Shi, CF (通讯作者)，ZheJiang Univ, Sch Med, Womens Hosp, Hangzhou 310000, Zhejiang, Peoples R China.
EM 21315079@zju.edu.cn
FU Medical Scientific Research Foundation of Zhejiang Province, China
   [2018PY022]
FX The project was supported by the Medical Scientific Research Foundation
   of Zhejiang Province, China (2018PY022).
CR Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheung G., 2017, P 2017 IEEE INT C CO
   Cohen A. R., 2017, WORLD NEUROSURGERY, V103
   Denzer UW, 2015, J CLIN GASTROENTEROL, V49, P101, DOI 10.1097/MCG.0000000000000110
   Gao MK, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0315-2
   Guneri EA, 2018, CLIN EXP OTORHINOLAR, V11, P89, DOI 10.21053/ceo.2017.00927
   Hu WL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153202
   Leonard S, 2018, IEEE T MED IMAGING, V37, P2185, DOI 10.1109/TMI.2018.2833868
   Li DA, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.204
   Liu JQ, 2015, IEEE T BIO-MED ENG, V62, P2296, DOI 10.1109/TBME.2015.2424438
   Liu W, 2016, EUR C COMP VIS, V21, P37
   Lovat LB, 2006, GUT, V55, P1078, DOI 10.1136/gut.2005.081467
   Ma J, 2016, J CANCER RES THER, V12, P271, DOI 10.4103/0973-1482.200755
   Rashmi K, 2013, INT J MED RES HEALTH, V2, P418, DOI 10.5958/j.2319-5886.2.3.073
   van der Post RS, 2018, GASTROINTEST ENDOSC, V87, P397, DOI 10.1016/j.gie.2017.04.016
   Vemuri A. S., 2019, SURVEY COMPUTER VISI
   Wang B, 2014, J MED IMAG HEALTH IN, V4, P797, DOI 10.1166/jmihi.2014.1323
   Wang B, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/974038
   Wickremeratne T, 2019, ALIMENT PHARM THER, V49, P1464, DOI 10.1111/apt.15282
   Ye M., 2016, ROBUST IMAGE DESCRIP
   Zeng J. L., 2017, P INT C ADV ENG THEO
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 22
TC 2
Z9 3
U1 0
U2 12
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1748-670X
EI 1748-6718
J9 COMPUT MATH METHOD M
JI Comput. Math. Method Med.
PD OCT 30
PY 2019
VL 2019
AR 4393124
DI 10.1155/2019/4393124
PG 8
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA JO1OO
UT WOS:000497354500002
PM 31885680
OA gold, Green Submitted, Green Published
DA 2023-08-21
ER

PT J
AU Hwang, M
   Wang, D
   Jiang, WC
   Pan, X
   Fu, DL
   Hwang, KS
   Ding, KF
AF Hwang, Maxwell
   Wang, Da
   Jiang, Wei-Cheng
   Pan, Xiang
   Fu, Dongliang
   Hwang, Kao-Shing
   Ding, Kefeng
TI An Adaptive Regularization Approach to Colonoscopic Polyp Detection
   Using a Cascaded Structure of Encoder-Decoders
SO INTERNATIONAL JOURNAL OF FUZZY SYSTEMS
LA English
DT Article
DE Convolution neural networks; Encoder-decoder networks; Fuzzy logic
ID COLORECTAL-CANCER; MISS RATE; PARTICIPATION; PREVENTION; INCREASES;
   VISION
AB This research aims to segment colonoscopic images by automatically extracting polyp features by exploiting the strengths of convolution neural networks (CNN). The proposed model employs deep learning and adaptive regularization techniques. The model is structurally composed of two cascaded encoder-decoder networks, each of which is constructed by four CNN layers and two full connection layers. The front model is built on backpropagation learning for segmenting a colonoscopic polyp image. The output images from the precedent hetero-encoder are regarded as corrupted labeled images, especially during the time period close to the end of learning, and are selectively fed into the successive auto-encoder for denoising learning to enhance its discriminative power and relieve the problem of a lack of labeled data for medical image tasks. The performance of the proposed model can be further improved by a simple fuzzy logic approach setting the regularization parameter in the loss function. The proposed method utilizes features learned from some open medical datasets and our own collected dataset. The performance of the proposed architecture is compared with a state-of-the-art network. The evaluation shows the performances of the proposed method are consistent across all the datasets and often outperform the state-of-art model.
C1 [Hwang, Maxwell; Wang, Da; Pan, Xiang; Fu, Dongliang; Ding, Kefeng] Zhejiang Univ, Sch Med, Affiliated Hosp 2, Dept Colorectal Surg, Hangzhou, Zhejiang, Peoples R China.
   [Hwang, Maxwell; Wang, Da; Pan, Xiang; Fu, Dongliang; Ding, Kefeng] Zhejiang Univ, Affiliated Hosp 2, China Natl Minist Educ, Canc Inst,Key Lab Canc Prevent & Intervent, Hangzhou, Zhejiang, Peoples R China.
   [Hwang, Maxwell; Wang, Da; Pan, Xiang; Fu, Dongliang; Ding, Kefeng] Zhejiang Univ, Affiliated Hosp 2, Key Lab Mol Biol Med Sci, Sch Med, Hangzhou, Zhejiang, Peoples R China.
   [Jiang, Wei-Cheng] Tunghai Univ, Dept Elect Engn, Taichung, Taiwan.
   [Hwang, Kao-Shing] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Tunghai
   University; National Sun Yat Sen University
RP Ding, KF (通讯作者)，Zhejiang Univ, Sch Med, Affiliated Hosp 2, Dept Colorectal Surg, Hangzhou, Zhejiang, Peoples R China.; Ding, KF (通讯作者)，Zhejiang Univ, Affiliated Hosp 2, China Natl Minist Educ, Canc Inst,Key Lab Canc Prevent & Intervent, Hangzhou, Zhejiang, Peoples R China.; Ding, KF (通讯作者)，Zhejiang Univ, Affiliated Hosp 2, Key Lab Mol Biol Med Sci, Sch Med, Hangzhou, Zhejiang, Peoples R China.
EM himax26@126.com; wangda0618@zju.edu.cn; jiangwc@thu.edu.tw;
   panx@zju.edu.cn; 3120102932@zju.edu.cn; hwang@ccu.edu.tw;
   dingkefeng@zju.edu.cn
RI Hwang, Kao-Shing/AAD-2644-2020
OI Hwang, Kao-Shing/0000-0001-9234-4836
FU Key Technology Research and Development Program of Zhejiang Province
   [2017C03017]; National Natural Science Foundation of China [81672916,
   LQ17H160008]; National Key R&D Program of China [2017YFC0908200]
FX This work was supported in part by the Key Technology Research and
   Development Program of Zhejiang Province (2017C03017), the National
   Natural Science Foundation of China (81672916) and (LQ17H160008), and
   the National Key R&D Program of China (2017YFC0908200).
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Chatfield K., 2014, RETURN DEVIL DETAILS
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   El Khatib A, 2015, IEEE ENG MED BIO, P2669, DOI 10.1109/EMBC.2015.7318941
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin HF, 2019, INT J FUZZY SYST, V21, P1026, DOI 10.1007/s40815-018-00604-8
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Pan W, 2019, INT J FUZZY SYST, V21, P95, DOI 10.1007/s40815-018-0535-y
   Ranzato M., 2007, P IEEE C COMP VIS PA, P1, DOI [DOI 10.1109/CVPR.2007.383157, 10.1109/CVPR.2007.383157]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2015, I S BIOMED IMAGING, P101, DOI 10.1109/ISBI.2015.7163826
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Silva J, 2013, IEEE ENG MED BIO, P5711, DOI 10.1109/EMBC.2013.6610847
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 32
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1562-2479
EI 2199-3211
J9 INT J FUZZY SYST
JI Int. J. Fuzzy Syst.
PD OCT
PY 2019
VL 21
IS 7
BP 2091
EP 2101
DI 10.1007/s40815-019-00694-y
PG 11
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA JI6HB
UT WOS:000493567300009
DA 2023-08-21
ER

PT J
AU Wang, P
   Berzin, TM
   Brown, JRG
   Bharadwaj, S
   Becq, A
   Xiao, X
   Liu, PX
   Li, LP
   Song, Y
   Zhang, D
   Li, Y
   Xu, GR
   Tu, MT
   Liu, XG
AF Wang, Pu
   Berzin, Tyler M.
   Brown, Jeremy Romek Glissen
   Bharadwaj, Shishira
   Becq, Aymeric
   Xiao, Xun
   Liu, Peixi
   Li, Liangping
   Song, Yan
   Zhang, Di
   Li, Yi
   Xu, Guangre
   Tu, Mengtian
   Liu, Xiaogang
TI Real-time automatic detection system increases colonoscopic polyp and
   adenoma detection rates: a prospective randomised controlled study
SO GUT
LA English
DT Article
ID COLORECTAL-CANCER; MISS RATES; INATTENTIONAL BLINDNESS; SCREENING
   COLONOSCOPY; WIDE-ANGLE; TASK-FORCE; IMPACT; RISK; MULTICENTER;
   ENDOSCOPY
AB Objective The effect of colonoscopy on colorectal cancer mortality is limited by several factors, among them a certain miss rate, leading to limited adenoma detection rates (ADRs). We investigated the effect of an automatic polyp detection system based on deep learning on polyp detection rate and ADR.
   Design In an open, non-blinded trial, consecutive patients were prospectively randomised to undergo diagnostic colonoscopy with or without assistance of a real-time automatic polyp detection system providing a simultaneous visual notice and sound alarm on polyp detection. The primary outcome was ADR.
   Results Of 1058 patients included, 536 were randomised to standard colonoscopy, and 522 were randomised to colonoscopy with computer-aided diagnosis. The artificial intelligence (AI) system significantly increased ADR (29.1%vs20.3%, p<0.001) and the mean number of adenomas per patient (0.53vs0.31, p<0.001). This was due to a higher number of diminutive adenomas found (185vs102; p<0.001), while there was no statistical difference in larger adenomas (77vs58, p=0.075). In addition, the number of hyperplastic polyps was also significantly increased (114vs52, p<0.001).
   Conclusions In a low prevalent ADR population, an automatic polyp detection system during colonoscopy resulted in a significant increase in the number of diminutive adenomas detected, as well as an increase in the rate of hyperplastic polyps. The cost-benefit ratio of such effects has to be determined further.
C1 [Wang, Pu; Xiao, Xun; Liu, Peixi; Li, Liangping; Song, Yan; Zhang, Di; Li, Yi; Xu, Guangre; Tu, Mengtian; Liu, Xiaogang] Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Sichuan, Peoples R China.
   [Berzin, Tyler M.; Brown, Jeremy Romek Glissen; Bharadwaj, Shishira; Becq, Aymeric] Beth Israel Deaconess Med Ctr, Ctr Adv Endoscopy, Boston, MA 02215 USA.
   [Berzin, Tyler M.; Brown, Jeremy Romek Glissen; Bharadwaj, Shishira; Becq, Aymeric] Harvard Med Sch, Boston, MA 02115 USA.
C3 Sichuan Provincial People's Hospital; Harvard University; Beth Israel
   Deaconess Medical Center; Harvard University; Harvard Medical School
RP Liu, XG (通讯作者)，Sichuan Acad Med Sci & Sichuan Prov Peoples Hosp, Dept Gastroenterol, Chengdu, Sichuan, Peoples R China.
EM Gary.samsph@gmail.com
RI Tu, Mengtian/AAU-6816-2020
OI Wang, Pu/0000-0002-1234-309X; Berzin, Tyler/0000-0002-4364-6210; Glissen
   Brown, Jeremy/0000-0002-7204-7241
CR Adler A, 2012, CLIN GASTROENTEROL H, V10, P155, DOI 10.1016/j.cgh.2011.10.026
   Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   [Anonymous], [No title captured]
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Bai Y, 2018, ENDOSCOPY, V50, P128, DOI 10.1055/s-0043-119213
   Bailey CE, 2015, JAMA SURG, V150, P17, DOI 10.1001/jamasurg.2014.1756
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Burke Carol, 2017, Gastroenterol Hepatol (N Y), V13, P1
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cai B, 2015, ONCOL LETT, V9, P2073, DOI 10.3892/ol.2015.3005
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chin M, 2016, WORLD J GASTROENTERO, V22, P9642, DOI 10.3748/wjg.v22.i43.9642
   Cohen J, 2017, J CLIN GASTROENTEROL, V51, P818, DOI 10.1097/MCG.0000000000000695
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Doubeni CA, 2018, GUT, V67, P291, DOI 10.1136/gutjnl-2016-312712
   Doubeni CA, 2013, ANN INTERN MED, V158, P312, DOI 10.7326/0003-4819-158-5-201303050-00003
   Halpern Z, 2015, ENDOSCOPY, V47, P238, DOI 10.1055/s-0034-1391437
   Horton N, 2016, AM J GASTROENTEROL, V111, P1330, DOI 10.1038/ajg.2016.273
   Jia H, 2017, AM J GASTROENTEROL, V112, P568, DOI 10.1038/ajg.2016.501
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Leufkens AM, 2011, GASTROINTEST ENDOSC, V73, P480, DOI 10.1016/j.gie.2010.09.004
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Memmert D, 2010, J GEN PSYCHOL, V137, P129, DOI 10.1080/00221301003645061
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Rex DK, 2003, AM J GASTROENTEROL, V98, P2000, DOI 10.1016/S0002-9270(03)00625-7
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2006, AM J GASTROENTEROL, V101, P2866, DOI 10.1111/j.1572-0241.2006.00905.x
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rogart JN, 2008, AM J GASTROENTEROL, V103, P2841, DOI 10.1111/j.1572-0241.2008.02085.x
   Sanchez W, 2004, AM J GASTROENTEROL, V99, P1941, DOI 10.1111/j.1572-0241.2004.40569.x
   Siddiki HA, 2017, GASTROINTEST ENDOSC, V85, pAB84, DOI 10.1016/j.gie.2017.03.116
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wolfe JM, 2006, VIS COGN, V14, P749, DOI 10.1080/13506280500195292
   Xu Y, 2018, SCAND J GASTROENTERO, V53, P365, DOI 10.1080/00365521.2018.1433230
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhou Haiping, 2018, Zhonghua Wei Chang Wai Ke Za Zhi, V21, P678
NR 48
TC 379
Z9 404
U1 11
U2 71
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0017-5749
EI 1468-3288
J9 GUT
JI Gut
PD OCT
PY 2019
VL 68
IS 10
BP 1813
EP 1819
DI 10.1136/gutjnl-2018-317500
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Gastroenterology & Hepatology
GA JM8XL
UT WOS:000496491100011
PM 30814121
OA Green Published, hybrid
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Chao, WL
   Manickavasagan, H
   Krishna, SG
AF Chao, Wei-Lun
   Manickavasagan, Hanisha
   Krishna, Somashekar G.
TI Application of Artificial Intelligence in the Detection and
   Differentiation of Colon Polyps: A Technical Review for Physicians
SO DIAGNOSTICS
LA English
DT Review
DE colonoscopy; colon polyp; artificial intelligence; computer-aided
   diagnosis; machine learning
ID COMPUTER-AIDED DIAGNOSIS; COLORECTAL-CANCER; MISS RATE; TASK-FORCE;
   SYSTEM; CLASSIFICATION; PREVENTION; LESIONS; RISK; COLONOSCOPY
AB Research in computer-aided diagnosis (CAD) and the application of artificial intelligence (AI) in the endoscopic evaluation of the gastrointestinal tract is novel. Since colonoscopy and detection of polyps can decrease the risk of colon cancer, it is recommended by multiple national and international societies. However, the procedure of colonoscopy is performed by humans where there are significant interoperator and interpatient variations, and hence, the risk of missing detection of adenomatous polyps. Early studies involving CAD and AI for the detection and differentiation of polyps show great promise. In this appraisal, we review existing scientific aspects of AI in CAD of colon polyps and discuss the pitfalls and future directions for advancing the science. This review addresses the technical intricacies in a manner that physicians can comprehend to promote a better understanding of this novel application.
C1 [Chao, Wei-Lun] Cornell Univ, Dept Comp Sci, New York, NY 14853 USA.
   [Chao, Wei-Lun] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Manickavasagan, Hanisha; Krishna, Somashekar G.] Ohio State Univ, Wexner Med Ctr, Div Gastroenterol Hepatol & Nutr, Columbus, OH 43210 USA.
C3 Cornell University; University System of Ohio; Ohio State University;
   University System of Ohio; Ohio State University
RP Krishna, SG (通讯作者)，Ohio State Univ, Wexner Med Ctr, Div Gastroenterol Hepatol & Nutr, Columbus, OH 43210 USA.
EM Somashekar.krishna@osumc.edu
RI Krishna, Somashekar G/V-2593-2019; Krishna, Somashekar G/AAH-7145-2019
OI Krishna, Somashekar G/0000-0001-5748-7890; Krishna, Somashekar
   G/0000-0001-5748-7890
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   [Anonymous], 2012, LEARNING FROM DATA
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Bressler B, 2004, GASTROENTEROLOGY, V127, P452, DOI 10.1053/j.gastro.2004.05.032
   Burt RW, 2013, J NATL COMPR CANC NE, V11, P1538, DOI 10.6004/jnccn.2013.0180
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Division of Cancer Prevention and Control, COL CANC STAT
   Djinbachian Roupen, 2019, Curr Treat Options Gastroenterol, V17, P99, DOI 10.1007/s11938-019-00220-x
   Doubeni CA, 2013, ANN INTERN MED, V158, P312, DOI 10.7326/0003-4819-158-5-201303050-00003
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo SE, 2019, DIGEST ENDOSC, V31, P363, DOI 10.1111/den.13340
   LeCun Y., 1995, HDB BRAIN THEORY NEU, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Patel SG, 2014, CLIN GASTROENTEROL H, V12, P7, DOI 10.1016/j.cgh.2013.04.027
   Rex DK, 2017, GASTROINTEST ENDOSC, V86, P18, DOI 10.1016/j.gie.2017.04.003
   Rex DK, 2009, AM J GASTROENTEROL, V104, P739, DOI 10.1038/ajg.2009.104
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Than M, 2015, ANN GASTROENTEROL, V28, P94
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 46
TC 21
Z9 22
U1 0
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD SEP
PY 2019
VL 9
IS 3
AR 99
DI 10.3390/diagnostics9030099
PG 8
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA JA6WS
UT WOS:000487983100005
PM 31434208
OA Green Published, Green Submitted, gold
DA 2023-08-21
ER

PT J
AU Azer, SA
AF Azer, Samy A.
TI Challenges Facing the Detection of Colonic Polyps: What Can Deep
   Learning Do?
SO MEDICINA-LITHUANIA
LA English
DT Review
DE deep learning; convolutional neural network (CNN); colonic polyps;
   colorectal cancer; adenoma; colonoscopy; artificial intelligence;
   computer-aided diagnosis; surveillance
ID ADENOMA DETECTION RATE; COLONOSCOPY WITHDRAWAL TIME; COLORECTAL-CANCER;
   QUALITY INDICATORS; RISK; CLASSIFICATION; CARCINOMA; PROPOSAL; CATENIN;
   RATES
AB Colorectal cancer (CRC) is one of the most common causes of cancer mortality in the world. The incidence is related to increases with age and western dietary habits. Early detection through screening by colonoscopy has been proven to effectively reduce disease-related mortality. Currently, it is generally accepted that most colorectal cancers originate from adenomas. This is known as the adenoma-carcinoma sequence, and several studies have shown that early detection and removal of adenomas can effectively prevent the development of colorectal cancer. The other two pathways for CRC development are the Lynch syndrome pathway and the sessile serrated pathway. The adenoma detection rate is an established indicator of a colonoscopy's quality. A 1% increase in the adenoma detection rate has been associated with a 3% decrease in interval CRC incidence. However, several factors may affect the adenoma detection rate during a colonoscopy, and techniques to address these factors have been thoroughly discussed in the literature. Interestingly, despite the use of these techniques in colonoscopy training programs and the introduction of quality measures in colonoscopy, the adenoma detection rate varies widely. Considering these limitations, initiatives that use deep learning, particularly convolutional neural networks (CNNs), to detect cancerous lesions and colonic polyps have been introduced. The CNN architecture seems to offer several advantages in this field, including polyp classification, detection, and segmentation, polyp tracking, and an increase in the rate of accurate diagnosis. Given the challenges in the detection of colon cancer affecting the ascending (proximal) colon, which is more common in women aged over 65 years old and is responsible for the higher mortality of these patients, one of the questions that remains to be answered is whether CNNs can help to maximize the CRC detection rate in proximal versus distal colon in relation to a gender distribution. This review discusses the current challenges facing CRC screening and training programs, quality measures in colonoscopy, and the role of CNNs in increasing the detection rate of colonic polyps and early cancerous lesions.
C1 [Azer, Samy A.] King Saud Univ, Dept Med Educ, Coll Med, Riyadh 11461, Saudi Arabia.
C3 King Saud University
RP Azer, SA (通讯作者)，King Saud Univ, Dept Med Educ, Coll Med, Riyadh 11461, Saudi Arabia.
EM azer2000@optusnet.com.au
RI Azer, Samy A./C-8485-2009
OI Azer, Samy A./0000-0001-5638-3256
FU College of Medicine Research Center, Deanship of Scientific Research,
   King Saud University, Riyadh, Saudi Arabia
FX This work was funded by the College of Medicine Research Center,
   Deanship of Scientific Research, King Saud University, Riyadh, Saudi
   Arabia.
CR Abdelfatah MM, 2017, SCAND J GASTROENTERO, V52, P1148, DOI 10.1080/00365521.2017.1339827
   [Anonymous], 2014, COL CANC FACTS FIG 2
   Arnold M, 2017, GUT, V66, P683, DOI 10.1136/gutjnl-2015-310912
   Baxter NN, 2011, GASTROENTEROLOGY, V140, P65, DOI 10.1053/j.gastro.2010.09.006
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Benedict M, 2015, WORLD J GASTROENTERO, V21, P12735, DOI 10.3748/wjg.v21.i45.12735
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Blanes-Vidal V, 2019, ACTA ONCOL, V58, pS29, DOI 10.1080/0284186X.2019.1584404
   Bourroul GM, 2016, EINSTEIN-SAO PAULO, V14, P135, DOI 10.1590/S1679-45082016AO3678
   Brenner H, 2015, GASTROENTEROLOGY, V149, P356, DOI 10.1053/j.gastro.2015.04.012
   Brenner H, 2014, LANCET, V383, P1490, DOI 10.1016/S0140-6736(13)61649-9
   Brenner H, 2010, J NATL CANCER I, V102, P89, DOI 10.1093/jnci/djp436
   Canziani A., 2017, C ICLR
   Church J, 2014, SURG ONCOL CLIN N AM, V23, P1, DOI 10.1016/j.soc.2013.09.001
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dekker E, 2018, GASTROENTEROLOGY, V154, P1970, DOI 10.1053/j.gastro.2018.01.069
   Erichsen R, 2016, GASTROENTEROLOGY, V150, P895, DOI 10.1053/j.gastro.2015.11.046
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Haj-Hassan Hawraa, 2017, J Pathol Inform, V8, P1, DOI 10.4103/jpi.jpi_47_16
   HIXSON LJ, 1990, JNCI-J NATL CANCER I, V82, P1769, DOI 10.1093/jnci/82.22.1769
   Hoff G, 2017, ENDOSC INT OPEN, V5, pE489, DOI 10.1055/s-0043-106180
   Huang YL, 2012, DIGESTION, V86, P148, DOI 10.1159/000338680
   Hubel D, 2012, NEURON, V75, P182, DOI 10.1016/j.neuron.2012.07.002
   Jacob BJ, 2012, GASTROINTEST ENDOSC, V76, P355, DOI 10.1016/j.gie.2012.03.247
   Jemal A., 2020, CA-CANCER J CLIN, V70, p7, DOI DOI 10.3322/caac.21208
   Kainz P, 2017, PEERJ, V5, DOI 10.7717/peerj.3874
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kanczuga-Koda L, 2014, ONCOL LETT, V7, P1863, DOI 10.3892/ol.2014.1970
   Kim SE, 2015, WORLD J GASTROENTERO, V21, P5167, DOI 10.3748/wjg.v21.i17.5167
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee TJW, 2013, ENDOSCOPY, V45, P20, DOI 10.1055/s-0032-1325803
   Lund Martin, 2017, JBI Database System Rev Implement Rep, V15, P1991, DOI 10.11124/JBISRIR-2016-003241
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Men K, 2017, MED PHYS, V44, P6377, DOI 10.1002/mp.12602
   Oines M, 2017, BEST PRACT RES CL GA, V31, P419, DOI 10.1016/j.bpg.2017.06.004
   Pohl J, 2008, AM J GASTROENTEROL, V103, P562, DOI 10.1111/j.1572-0241.2007.01670.x
   Qadir HA, 2020, IEEE J BIOMED HEALTH, V24, P180, DOI 10.1109/JBHI.2019.2907434
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Rex DK, 2006, AM J GASTROENTEROL, V101, P2866, DOI 10.1111/j.1572-0241.2006.00905.x
   Rex DK, 2013, GASTROENTEROL CLIN N, V42, P429, DOI 10.1016/j.gtc.2013.05.009
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Sanduleanu S, 2015, GUT, V64, P1257, DOI 10.1136/gutjnl-2014-307992
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Singh R, 2016, WORLD J GASTROENTERO, V22, P7754, DOI 10.3748/wjg.v22.i34.7754
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vavricka SR, 2016, ENDOSCOPY, V48, P256, DOI 10.1055/s-0035-1569674
   White BD, 2012, GASTROENTEROLOGY, V142, P219, DOI 10.1053/j.gastro.2011.12.001
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhao TY, 2019, IEEE T PATTERN ANAL, V41, P1072, DOI 10.1109/TPAMI.2018.2828821
   Zhu FC, 2019, HERED CANCER CLIN PR, V17, DOI 10.1186/s13053-019-0108-6
NR 55
TC 23
Z9 25
U1 4
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 1010-660X
EI 1648-9144
J9 MEDICINA-LITHUANIA
JI Med. Lith.
PD AUG
PY 2019
VL 55
IS 8
AR 473
DI 10.3390/medicina55080473
PG 13
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA IZ0GQ
UT WOS:000486769900072
PM 31409050
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Cogan, T
   Cogan, M
   Tamil, L
AF Cogan, Timothy
   Cogan, Maribeth
   Tamil, Lakshman
TI MAPGI: Accurate identification of anatomical landmarks and diseased
   tissue in gastrointestinal tract using deep learning
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Endoscopy; Gastrointestinal tract; Image enhancement; Machine learning;
   Neural network; Deep learning
AB Automatic detection of anatomical landmarks and diseases in medical images is a challenging task which could greatly aid medical diagnosis and reduce the cost and time of investigational procedures. Also, two particular challenges of digital image processing in medical applications are the sparsity of annotated medical images and the lack of uniformity across images and image classes. This paper presents methodologies for maximizing classification accuracy on a small medical image dataset, the Kvasir dataset, by performing robust image preprocessing and applying state-of-the-art deep learning. Images are classified as being or involving an anatomical landmark (pylorus, z-line, cecum), a diseased state (esophagitis, ulcerative colitis, polyps), or a medical procedure (dyed lifted polyps, dyed resection margins). A framework for modular and automatic preprocessing of gastrointestinal tract images (MAPGI) is proposed, which applies edge removal, contrast enhancement, filtering, color mapping and scaling to each image in the dataset. Gamma correction values are automatically calculated for individual images such that the mean pixel value for each image is normalized to 90 +/- 1 in a 0-255 pixel value range. Three state-of-the-art neural networks architectures, Inception-ResNet-v2, Inception-v4, and NASNet, are trained on the Kvasir dataset, and their classification performance is juxtaposed on validation data. In each case, 85% of the images from the Kvasir dataset are used for training, while the other 15% are reserved for validation. The resulting accuracies achieved using Inception-v4, Inception-ResNet-v2, and NASNet were 0.9845, 0.9848, and 0.9735, respectively. In addition, Inception-v4 achieved an average of 0.938 precision, 0.939 recall, 0.991 specificity, 0.938 F1 score, and 0.929 Matthews correlation coefficient (MCC). Bootstrapping provided NASNet, the worst performing model, a lower bound of 0.9723 accuracy on the 95% confidence interval.
C1 [Cogan, Timothy; Cogan, Maribeth; Tamil, Lakshman] Univ Texas Dallas, Dept Elect & Comp Engn, Qual Life Technol Lab, Richardson, TX 75080 USA.
C3 University of Texas System; University of Texas Dallas
RP Cogan, T (通讯作者)，Univ Texas Dallas, Dept Elect & Comp Engn, Qual Life Technol Lab, Richardson, TX 75080 USA.
EM timothy.cogan@utdallas.edu; mxr127730@utdallas.edu; laxman@utdallas.edu
OI Cogan, Timothy/0000-0002-2998-3915
CR Abadi M., 2015, P 12 USENIX C OPERAT, DOI [DOI 10.5555/3026877.3026899, DOI 10.1038/NN.3331]
   Agrawal T., SCL UMD MED TASK MED
   Cogan T, 2019, COMPUT BIOL MED, V107, P18, DOI 10.1016/j.compbiomed.2019.01.024
   Domhan T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3460
   Furukawa H., 2017, ARXIV170807920
   Gribbon KT, 2004, INT SYM ELECT DES TE, P126
   HADDAD RA, 1991, IEEE T SIGNAL PROCES, V39, P723, DOI 10.1109/78.80892
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kim M., 2017, DOCTORAL CONSORTIUM, P32
   Lau S., 2017, WALKTHROUGH CONVOLUT
   Liu Y., HKBU MEDIAEVAL 2017
   Naqvi S.S.A., ENSEMBLE TEXTURE FEA
   Peery AF, 2012, GASTROENTEROLOGY, V143, P1179, DOI 10.1053/j.gastro.2012.08.002
   Petscharnig S., 2017, INCEPTION LIKE CNN A
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Szegedy C., ABS1602201607261 COR
   Torres L., 1999, IEEE INT C IM PROC, V3, P627
   Zoph B., ABS1707201707012 COR
   Zuiderveld K., 1994, GRAPHIC GEMS, P474
NR 20
TC 40
Z9 40
U1 3
U2 14
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD AUG
PY 2019
VL 111
AR 103351
DI 10.1016/j.compbiomed.2019.103351
PG 8
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA IX7HM
UT WOS:000485854400027
PM 31325742
DA 2023-08-21
ER

PT J
AU Kudo, SE
   Mori, Y
   Misawa, M
   Takeda, K
   Kudo, T
   Itoh, H
   Oda, M
   Mori, K
AF Kudo, Shin-ei
   Mori, Yuichi
   Misawa, Masashi
   Takeda, Kenichi
   Kudo, Toyoki
   Itoh, Hayato
   Oda, Masahiro
   Mori, Kensaku
TI Artificial intelligence and colonoscopy: Current status and future
   perspectives
SO DIGESTIVE ENDOSCOPY
LA English
DT Review
DE automated; characterization; colon; detection
ID COMPUTER-AIDED DIAGNOSIS; CONFOCAL LASER ENDOMICROSCOPY; COLORECTAL
   POLYP HISTOLOGY; QUANTITATIVE-ANALYSIS; OPTICAL BIOPSY; PIT-PATTERN;
   SYSTEM; CLASSIFICATION; LESIONS; ENDOSCOPY
AB Background and Aim Application of artificial intelligence in medicine is now attracting substantial attention. In the field of gastrointestinal endoscopy, computer-aided diagnosis (CAD) for colonoscopy is the most investigated area, although it is still in the preclinical phase. Because colonoscopy is carried out by humans, it is inherently an imperfect procedure. CAD assistance is expected to improve its quality regarding automated polyp detection and characterization (i.e. predicting the polyp's pathology). It could help prevent endoscopists from missing polyps as well as provide a precise optical diagnosis for those detected. Ultimately, these functions that CAD provides could produce a higher adenoma detection rate and reduce the cost of polypectomy for hyperplastic polyps. Methods and Results Currently, research on automated polyp detection has been limited to experimental assessments using an algorithm based on ex vivo videos or static images. Performance for clinical use was reported to have >90% sensitivity with acceptable specificity. In contrast, research on automated polyp characterization seems to surpass that for polyp detection. Prospective studies of in vivo use of artificial intelligence technologies have been reported by several groups, some of which showed a >90% negative predictive value for differentiating diminutive (<= 5 mm) rectosigmoid adenomas, which exceeded the threshold for optical biopsy. Conclusion We introduce the potential of using CAD for colonoscopy and describe the most recent conditions for regulatory approval for artificial intelligence-assisted medical devices.
C1 [Kudo, Shin-ei; Mori, Yuichi; Misawa, Masashi; Takeda, Kenichi; Kudo, Toyoki] Showa Univ, Digest Dis Ctr, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.
C3 Showa University; Nagoya University
RP Kudo, SE (通讯作者)，Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Tsuzuki Ku, 35-1 Chigasaki Tyuo, Yokohama, Kanagawa 2248503, Japan.
EM kudos@med.showa-u.ac.jp
RI Misawa, Masashi/H-9004-2019; Mori, Yuichi/AAU-5406-2020; Itoh,
   Hayato/AAM-4022-2021
OI Misawa, Masashi/0000-0002-8520-2036; Itoh, Hayato/0000-0002-1410-1078;
   Oda, Masahiro/0000-0001-7714-422X; Mori, Yuichi/0000-0003-2262-0334
CR Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   Arita K, 2011, ONCOL REP, V26, P43, DOI 10.3892/or.2011.1287
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chinzei K, 2018, ADV BIOMED ENG, V7, P118, DOI 10.14326/abe.7.118
   Committee AT, 2015, GASTROINTEST ENDOSC, V81
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dept of Health and Human Services FDA, 2018, RAD DEV RECL MED IM
   Du N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155371
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hafner M, 2009, LECT NOTES COMPUT SC, V5761, P247, DOI 10.1007/978-3-642-04268-3_31
   Hirakawa T, 2014, IEEE ENG MED BIO, P4739, DOI 10.1109/EMBC.2014.6944683
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Jerebko A, 2006, LECT NOTES COMPUT SC, V4191, P169
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kiesslich R, 2004, GASTROENTEROLOGY, V127, P706, DOI 10.1053/j.gastro.2004.06.050
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo S, 2001, ENDOSCOPY, V33, P367
   Kudo S, 2014, J GASTROEN HEPATOL, V29, P83, DOI 10.1111/jgh.12374
   Kudo Shin-ei, 2008, Gastrointest Endosc Clin N Am, V18, P581, DOI 10.1016/j.giec.2008.05.013
   Kuiper T, 2011, ENDOSCOPY, V43, P1076, DOI 10.1055/s-0030-1256767
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Maroulis DE, 2003, COMPUT METH PROG BIO, V70, P151, DOI 10.1016/S0169-2607(02)00007-X
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2013, ENDOSCOPY, V45, P98, DOI 10.1055/s-0032-1325932
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2018, DIGEST ENDOSC, V30, P52, DOI 10.1111/den.13005
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Okamoto T, 2015, IEEE ENG MED BIO, P2997, DOI 10.1109/EMBC.2015.7319022
   Park SH, 2018, RADIOLOGY, V288, P910, DOI 10.1148/radiol.2018181310
   Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Plagianakos VP, 2006, COMPUT METH PROG BIO, V81, P228, DOI 10.1016/j.cmpb.2005.11.005
   Prieto SP, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.2.024502
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Renkoski TE, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.1.016005
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Tafreshi MK, 2014, LECT NOTES COMPUT SC, V8673, P89, DOI 10.1007/978-3-319-10404-1_12
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Wang HF, 2015, PHYS MED BIOL, V60, P7207, DOI 10.1088/0031-9155/60/18/7207
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 67
TC 66
Z9 70
U1 2
U2 26
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0915-5635
EI 1443-1661
J9 DIGEST ENDOSC
JI Dig. Endosc.
PD JUL
PY 2019
VL 31
IS 4
BP 363
EP 371
DI 10.1111/den.13340
PG 9
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA IH2CK
UT WOS:000474302600006
PM 30624835
OA Bronze
DA 2023-08-21
ER

PT J
AU Li, JY
   Zhang, J
   Chang, DD
   Hu, YJ
AF Li Jiangyun
   Zhang Jie
   Chang Dedan
   Hu Yaojun
TI Computer-Assisted Detection of Colonic Polyps Using Improved Faster
   R-CNN
SO CHINESE JOURNAL OF ELECTRONICS
LA English
DT Article
DE Colonic polyps; Deep learning; Improved Faster R-CNN; Object detection
AB The deficiencies of existing polyp detection methods remain: i) They primarily depend on the manually extracted features and require considerable amounts of preprocessing. ii) Most traditional methods cannot specify the location of the polyps in colonoscopy images, especially for the polyps with variable size. In order to derive the improvement and lift the accuracy, we propose a novel and scalable detection algorithm based on deep neural networks-an improved Faster Region-based Convolutional neural networks (Faster R-CNN)-by increasing the fusion of feature maps at different levels. It can be employed to detect and locate polyps, and even achieve a multi-object task for polyps in the future. The experimental consequences demonstrate that the best version among improved algorithms achieves 97.13% accuracy on the CVC-ClinicDB database, overtaking the previous methods.
C1 [Li Jiangyun; Zhang Jie; Chang Dedan] Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing 100083, Peoples R China.
   [Li Jiangyun; Zhang Jie; Chang Dedan] Minist Educ, Key Lab Knowledge Automat Ind Proc, Beijing 100083, Peoples R China.
   [Hu Yaojun] Capital Med Univ, Fu Xing Hosp, Dept Gastroenterol, Beijing 100038, Peoples R China.
C3 University of Science & Technology Beijing; Capital Medical University
RP Li, JY (通讯作者)，Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing 100083, Peoples R China.; Li, JY (通讯作者)，Minist Educ, Key Lab Knowledge Automat Ind Proc, Beijing 100083, Peoples R China.
EM leejy@ustb.edu.cn; m15810821883@163.com; cdedan210@163.com;
   42118878@qq.com
FU Fundamental Research Funds for the China Central Universities of USTB;
   Open Project Program of the National Laboratory of Pattern Recognition
   [201800027]
FX This work is supported by the Fundamental Research Funds for the China
   Central Universities of USTB (No.FRF-BR-17-004A, No.FRF-GF-17-B49),and
   the Open Project Program of the National Laboratory of Pattern
   Recognition (No.201800027).
CR [Anonymous], 2007, IEEE INT C IMAGE PRO, DOI [10.1109/ICIP.2007.4379193, DOI 10.1109/ICIP.2007.4379193]
   Bale R, 2007, MINIM INVASIV THER, V16, P196, DOI 10.1080/13645700701520578
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   [毕威 Bi Wei], 2017, [电子学报, Acta Electronica Sinica], V45, P1902
   Girshick R., 2014, P IEEE C COMP VIS PA, P580, DOI DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Kodogiannis V., 2004, P INT C MED SIGN PRO, P262
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   [邱实 Qiu Shi], 2016, [电子学报, Acta Electronica Sinica], V44, P1413
   Qiu S, 2016, CHINESE J ELECTRON, V25, P711, DOI 10.1049/cje.2016.07.009
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Zhang RF, 2001, CHINESE J ORG CHEM, V21, P41
   Zheng MM, 2005, COMPUT BIOL MED, V35, P259, DOI 10.1016/j.compbiomed.2004.01.002
   [郑云飞 Zheng Yunfei], 2017, [电子学报, Acta Electronica Sinica], V45, P2593
NR 27
TC 7
Z9 9
U1 0
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1022-4653
EI 2075-5597
J9 CHINESE J ELECTRON
JI Chin. J. Electron.
PD JUL
PY 2019
VL 28
IS 4
BP 718
EP 724
DI 10.1049/cje.2019.03.005
PG 7
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA IM0OH
UT WOS:000477687600008
DA 2023-08-21
ER

PT J
AU Rau, A
   Edwards, PJE
   Ahmad, OF
   Riordan, P
   Janatka, M
   Lovat, LB
   Stoyanov, D
AF Rau, Anita
   Edwards, P. J. Eddie
   Ahmad, Omer F.
   Riordan, Paul
   Janatka, Mirek
   Lovat, Laurence B.
   Stoyanov, Danail
TI Implicit domain adaptation with conditional generative adversarial
   networks for depth prediction in endoscopy
SO INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY
LA English
DT Article; Proceedings Paper
CT 10th International Conference on Information Processing for
   Computer-Assisted Interventions (IPCAI)
CY JUN 18-19, 2019
CL FRANCE
DE Depth estimation; 3D reconstruction; Conditional GANs; Colonoscopy
ID 3D RECONSTRUCTION; POLYP DETECTION; COLONOSCOPY
AB PurposeColorectal cancer is the third most common cancer worldwide, and early therapeutic treatment of precancerous tissue during colonoscopy is crucial for better prognosis and can be curative. Navigation within the colon and comprehensive inspection of the endoluminal tissue are key to successful colonoscopy but can vary with the skill and experience of the endoscopist. Computer-assisted interventions in colonoscopy can provide better support tools for mapping the colon to ensure complete examination and for automatically detecting abnormal tissue regions.MethodsWe train the conditional generative adversarial network pix2pix, to transform monocular endoscopic images to depth, which can be a building block in a navigational pipeline or be used to measure the size of polyps during colonoscopy. To overcome the lack of labelled training data in endoscopy, we propose to use simulation environments and to additionally train the generator and discriminator of the model on unlabelled real video frames in order to adapt to real colonoscopy environments.ResultsWe report promising results on synthetic, phantom and real datasets and show that generative models outperform discriminative models when predicting depth from colonoscopy images, in terms of both accuracy and robustness towards changes in domains.ConclusionsTraining the discriminator and generator of the model on real images, we show that our model performs implicit domain adaptation, which is a key step towards bridging the gap between synthetic and real data. Importantly, we demonstrate the feasibility of training a single model to predict depth from both synthetic and real images without the need for explicit, unsupervised transformer networks mapping between the domains of synthetic and real data.
C1 [Rau, Anita; Edwards, P. J. Eddie; Ahmad, Omer F.; Janatka, Mirek; Lovat, Laurence B.; Stoyanov, Danail] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London, England.
   [Riordan, Paul] Digital Surg Ltd, London, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London
RP Rau, A (通讯作者)，UCL, Wellcome EPSRC Ctr Intervent & Surg Sci WEISS, London, England.
EM a.rau.16@ucl.ac.uk; eddie.edwards@ucl.ac.uk; o.ahmad@ucl.ac.uk;
   paul.riordan@touchsurgery.com; mirek.janatka@ucl.ac.uk;
   l.lovat@ucl.ac.uk; danail.stoyanov@ucl.ac.uk
RI Lovat, Laurence/C-1986-2009
OI Lovat, Laurence/0000-0003-4542-3915; Rau, Anita/0000-0002-4759-2846
FU Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS)
   at UCL [203145Z/16/Z]; EPSRC [EP/N027078/1, EP/P012841/1, EP/P027938/1,
   EP/R004080/1]; European Commission Project-H2020-ICT-24-2015 (Endoo EU
   Project-G.A.) [688592]; National Institute for Health Research
   University College London Hospitals Biomedical Research Centre; CRUK
   Experimental Cancer Medicine Centre at UCL; Engineering and Physical
   Sciences Research Council [EP/P012841/1, EP/P030084/1, EP/R004080/1]
   Funding Source: researchfish; EPSRC [EP/R004080/1, EP/P012841/1,
   EP/N027078/1, EP/P030084/1, EP/P027938/1] Funding Source: UKRI
FX This work was supported by the Wellcome/EPSRC Centre for Interventional
   and Surgical Sciences (WEISS) at UCL (203145Z/16/Z), EPSRC
   (EP/N027078/1, EP/P012841/1, EP/P027938/1, EP/R004080/1) and the
   European Commission Project-H2020-ICT-24-2015 (Endoo EU Project-G.A.
   No.: 688592). LBL is supported by the National Institute for Health
   Research University College London Hospitals Biomedical Research Centre
   and the CRUK Experimental Cancer Medicine Centre at UCL.
CR Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Armin MA, 2017, LECT NOTES COMPUT SC, V10550, P50, DOI 10.1007/978-3-319-67543-5_5
   Armin MA, 2018, LECT NOTES COMPUT SC, V11041, P108, DOI 10.1007/978-3-030-01201-4_13
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Chen RT, 2018, ARXIV
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   Hong DH, 2014, COMPUT MED IMAG GRAP, V38, P22, DOI 10.1016/j.compmedimag.2013.10.005
   Isola P., 2017, P COMP VIS PATT REC, P5967, DOI DOI 10.1109/CVPR.2017.632
   Itoh H, 2018, LECT NOTES COMPUT SC, V11071, P611, DOI 10.1007/978-3-030-00934-2_68
   Jun-Yan Zhu, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2242, DOI 10.1109/ICCV.2017.244
   Liu XT, 2018, LECT NOTES COMPUT SC, V11041, P128, DOI 10.1007/978-3-030-01201-4_15
   Mahmood F, 2018, MED IMAGE ANAL, V48, P230, DOI 10.1016/j.media.2018.06.005
   Mirza M., 2014, ARXIV14111784, DOI DOI 10.48550/ARXIV.1411.1784
   Odena A, 2017, PR MACH LEARN RES, V70
   Qingyu Zhao, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P439, DOI 10.1007/978-3-319-46720-7_51
   Radford A., 2016, PROC 4 INT C LEARN R
   Rex DK, 2017, BEST PRACT RES CL GA, V31, P425, DOI 10.1016/j.bpg.2017.05.010
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Visentini-Scarzanella M, 2017, INT J COMPUT ASS RAD, V12, P1089, DOI 10.1007/s11548-017-1609-2
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 23
TC 57
Z9 57
U1 2
U2 15
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1861-6410
EI 1861-6429
J9 INT J COMPUT ASS RAD
JI Int. J. Comput. Assist. Radiol. Surg.
PD JUL
PY 2019
VL 14
IS 7
SI SI
BP 1167
EP 1176
DI 10.1007/s11548-019-01962-w
PN 2
PG 10
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging;
   Surgery
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery
GA ID4GM
UT WOS:000471635000007
PM 30989505
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Vinsard, DG
   Mori, Y
   Misawa, M
   Kudo, S
   Rastogi, A
   Bagci, U
   Rex, DK
   Wallace, MB
AF Vinsard, Daniela Guerrero
   Mori, Yuichi
   Misawa, Masashi
   Kudo, Shin-ei
   Rastogi, Amit
   Bagci, Ulas
   Rex, Douglas K.
   Wallace, Michael B.
TI Quality assurance of computer-aided detection and diagnosis in
   colonoscopy
SO GASTROINTESTINAL ENDOSCOPY
LA English
DT Review
ID ADENOMA DETECTION RATE; COLORECTAL POLYP HISTOLOGY; DEEP-LEARNING
   ALGORITHM; ARTIFICIAL-INTELLIGENCE; GASTROINTESTINAL ENDOSCOPY; OPTICAL
   BIOPSY; SYSTEM; LESIONS; CLASSIFICATION; ENDOCYTOSCOPY
AB Recent breakthroughs in artificial intelligence (AI), specifically via its emerging sub-field "deep learning," have direct implications for computer-aided detection and diagnosis (CADe and/or CADx) for colonoscopy. AI is expected to have at least 2 major roles in colonoscopy practicedpolyp detection (CADe) and polyp characterization (CADx). CADe has the potential to decrease the polyp miss rate, contributing to improving adenoma detection, whereas CADx can improve the accuracy of colorectal polyp optical diagnosis, leading to reduction of unnecessary polypectomy of non-neoplastic lesions, potential implementation of a resect-and-discard paradigm, and proper application of advanced resection techniques. A growing number of medical-engineering researchers are developing both CADe and CADx systems, some of which allow real-time recognition of polyps or in vivo identification of adenomas, with over 90% accuracy. However, the quality of the developed AI systems as well as that of the study designs vary significantly, hence raising some concerns regarding the generalization of the proposed AI systems. Initial studies were conducted in an exploratory or retrospective fashion by using stored images and likely overestimating the results. These drawbacks potentially hinder smooth implementation of this novel technology into colonoscopy practice. The aim of this article is to review both contributions and limitations in recent machine-learning-based CADe and/or CADx colonoscopy studies and propose some principles that should underlie system development and clinical testing.
C1 [Vinsard, Daniela Guerrero] Showa Univ, Northern Yokohama Hosp, Int Ctr Endoscopy, Yokohama, Kanagawa, Japan.
   [Vinsard, Daniela Guerrero] Univ Connecticut, Div Internal Med, Hlth Ctr, Farmington, CT USA.
   [Mori, Yuichi; Misawa, Masashi; Kudo, Shin-ei] Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Yokohama, Kanagawa, Japan.
   [Rastogi, Amit] Univ Kansas, Med Ctr, Div Gastroenterol, Kansas City, KS 66103 USA.
   [Bagci, Ulas] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA.
   [Rex, Douglas K.] Indiana Univ Sch Med, Div Gastroenterol & Hepatol, Indianapolis, IN 46202 USA.
   [Wallace, Michael B.] Mayo Clin, Div Gastroenterol & Hepatol, Jacksonville, FL 32224 USA.
C3 Showa University; University of Connecticut; Showa University;
   University of Kansas; University of Kansas Medical Center; State
   University System of Florida; University of Central Florida; Indiana
   University System; Indiana University Bloomington; Mayo Clinic
RP Mori, Y (通讯作者)，Showa Univ, Northern Yokohama Hosp, Digest Dis Ctr, Tsuzuki Ku, 35-1 Chigasakichuo, Yokohama, Kanagawa 2248503, Japan.
RI Bagci, Ulas/A-4225-2012; Wallace, Michael/GZL-9731-2022; Mori,
   Yuichi/AAU-5406-2020; Misawa, Masashi/H-9004-2019
OI Bagci, Ulas/0000-0001-7379-6829; Wallace, Michael/0000-0002-6446-5785;
   Misawa, Masashi/0000-0002-8520-2036; Mori, Yuichi/0000-0003-2262-0334
FU NCI NIH HHS [R01 CA246704] Funding Source: Medline
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Aihara H, 2013, EUR J GASTROEN HEPAT, V25, P488, DOI 10.1097/MEG.0b013e32835c6d9a
   Aihara H, 2009, GASTROINTEST ENDOSC, V69, P726, DOI 10.1016/j.gie.2008.10.044
   Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Andre B, 2012, WORLD J GASTROENTERO, V18, P5560, DOI 10.3748/wjg.v18.i39.5560
   [Anonymous], 2016, DEEP LEARNING
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Brocklehurst P, 2017, LANCET, V389, P1719, DOI 10.1016/S0140-6736(17)30568-8
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Cabitza F, 2017, JAMA-J AM MED ASSOC, V318, P517, DOI 10.1001/jama.2017.7797
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chinzei K, 2018, ADV BIOMED ENG, V7, P118, DOI 10.14326/abe.7.118
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   East JE, 2018, LANCET GASTROENTEROL, V3, P10, DOI 10.1016/S2468-1253(17)30366-7
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Food and Drug Administration, 2018, RAD DEV RECL MED IM, P25598
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Hilsden RJ, 2016, AM J GASTROENTEROL, V111, P1743, DOI 10.1038/ajg.2016.449
   Hirata M, 2007, GASTROINTEST ENDOSC, V66, P945, DOI 10.1016/j.gie.2007.05.053
   Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5
   Hussein S, IEEE T MED IMAGING
   Ichimasa K, 2014, DIGEST ENDOSC, V26, P403, DOI 10.1111/den.12164
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101
   Justice AC, 1999, ANN INTERN MED, V130, P515, DOI 10.7326/0003-4819-130-6-199903160-00016
   Kahi CJ, 2014, GASTROINTEST ENDOSC, V79, P448, DOI 10.1016/j.gie.2013.10.013
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   KEITH RDF, 1995, BRIT J OBSTET GYNAEC, V102, P688, DOI 10.1111/j.1471-0528.1995.tb11425.x
   Khan S, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS), P633, DOI 10.1109/ICCOINS.2016.7783289
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   LaLonde R., 2018, 1 C MED IM DEEP LEAR
   Lami M, 2018, ENDOSCOPY, V50, P701, DOI 10.1055/s-0044-101026
   Leggett CL, 2016, GASTROINTEST ENDOSC, V84, P842, DOI 10.1016/j.gie.2016.07.045
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Maeda Y, 2019, GASTROINTEST ENDOSC, V89, P408, DOI 10.1016/j.gie.2018.09.024
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Yuichi, 2019, VideoGIE, V4, P7, DOI 10.1016/j.vgie.2018.10.006
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2018, DIGEST ENDOSC, V30, P52, DOI 10.1111/den.13005
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Mortazi Aliasghar, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P377, DOI 10.1007/978-3-319-66185-8_43
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Ozawa T, 2019, GASTROINTEST ENDOSC, V89, P416, DOI 10.1016/j.gie.2018.10.020
   Park SH, 2018, RADIOLOGY, V288, P910, DOI 10.1148/radiol.2018181310
   Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rex DK, 2006, GASTROINTEST ENDOSC, V63, pS16, DOI 10.1016/j.gie.2006.02.021
   Rex DK, 2002, AM J GASTROENTEROL, V97, P1296, DOI 10.1016/S0002-9270(02)04168-0
   Rex DK, 2015, AM J GASTROENTEROL, V110, P72, DOI 10.1038/ajg.2014.385
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Sanchez-Montes C, 2019, ENDOSCOPY, V51, P261, DOI 10.1055/a-0732-5250
   Stefanescu D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154863
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Torosdagli N, 2019, IEEE T MED IMAGING, V38, P919, DOI 10.1109/TMI.2018.2875814
   Tsai TL, 2003, J AM MED INFORM ASSN, V10, P478, DOI 10.1197/jamia.M1279
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Wang P, 2018, GASTROINTEST ENDOSC, V87, pAB490
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z
NR 83
TC 73
Z9 80
U1 3
U2 26
PU MOSBY-ELSEVIER
PI NEW YORK
PA 360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0016-5107
EI 1097-6779
J9 GASTROINTEST ENDOSC
JI Gastrointest. Endosc.
PD JUL
PY 2019
VL 90
IS 1
BP 55
EP 63
DI 10.1016/j.gie.2019.03.019
PG 9
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA ID9QI
UT WOS:000472021800006
PM 30926431
OA Green Submitted
DA 2023-08-21
ER

PT J
AU Sornapudi, S
   Meng, F
   Yi, S
AF Sornapudi, Sudhir
   Meng, Frank
   Yi, Steven
TI Region-Based Automated Localization of Colonoscopy and Wireless Capsule
   Endoscopy Polyps
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE colonoscopy; wireless capsule endoscopy; polyps; localization;
   segmentation; deep learning
ID COLORECTAL POLYPS; VALIDATION
AB The early detection of polyps could help prevent colorectal cancer. The automated detection of polyps on the colon walls could reduce the number of false negatives that occur due to manual examination errors or polyps being hidden behind folds, and could also help doctors locate polyps from screening tests such as colonoscopy and wireless capsule endoscopy. Losing polyps may result in lesions evolving badly. In this paper, we propose a modified region-based convolutional neural network (R-CNN) by generating masks around polyps detected from still frames. The locations of the polyps in the image are marked, which assists the doctors examining the polyps. The features from the polyp images are extracted using pre-trained Resnet-50 and Resnet-101 models through feature extraction and fine-tuning techniques. Various publicly available polyp datasets are analyzed with various pertained weights. It is interesting to notice that fine-tuning with balloon data (polyp-like natural images) improved the polyp detection rate. The optimum CNN models on colonoscopy datasets including CVC-ColonDB, CVC-PolypHD, and ETIS-Larib produced values (F1 score, F2 score) of (90.73, 91.27), (80.65, 79.11), and (76.43, 78.70) respectively. The best model on the wireless capsule endoscopy dataset gave a performance of (96.67, 96.10). The experimental results indicate the better localization of polyps compared to recent traditional and deep learning methods.
C1 [Sornapudi, Sudhir] Missouri Univ Sci & Technol, Rolla, MO 65401 USA.
   [Meng, Frank; Yi, Steven] Xyken LLC, Mclean, VA 22102 USA.
C3 University of Missouri System; Missouri University of Science &
   Technology
RP Yi, S (通讯作者)，Xyken LLC, Mclean, VA 22102 USA.
EM ssbw5@mst.edu; fmeng@xyken.com; syi@xyken.com
RI Sornapudi, Sudhir/Z-2626-2019
OI Sornapudi, Sudhir/0000-0001-5305-7797
FU NIH [5R43AG058269]
FX This research work was supported by NIH Grant 5R43AG058269.
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   [Anonymous], END VIS CHALL SUBCH
   [Anonymous], CANC FACTS FIG 2019
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Cheng DC, 2011, BIOMED ENG-APP BAS C, V23, P357, DOI 10.4015/S1016237211002761
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Figueiredo I., 2013, P 4 ECCOMAS THEM C C, DOI [10.1201/b15810-42, DOI 10.1201/B15810-42]
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang C, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1423, DOI 10.1145/3269206.3271793
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kohli MD, 2017, J DIGIT IMAGING, V30, P392, DOI 10.1007/s10278-017-9976-3
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Lin T.-Y., 2017, PROC IEEE C COMPUT V, P2117, DOI DOI 10.1109/CVPR.2017.106
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mo X, 2018, INT C PATT RECOG, P3929, DOI 10.1109/ICPR.2018.8545174
   Mori Y, 2018, NAT BIOMED ENG, V2, P713, DOI 10.1038/s41551-018-0308-9
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P471, DOI 10.1016/S0002-9270(02)05928-2
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Sargent D, 2016, PROC SPIE, V9784, DOI 10.1117/12.2217123
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sornapudi Sudhir, 2018, J Pathol Inform, V9, P5, DOI 10.4103/jpi.jpi_74_17
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang P, 2018, NAT BIOMED ENG, V2, P741, DOI 10.1038/s41551-018-0301-3
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
NR 44
TC 49
Z9 49
U1 2
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD JUN 2
PY 2019
VL 9
IS 12
AR 2404
DI 10.3390/app9122404
PG 15
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA IG4DR
UT WOS:000473754800013
OA gold
DA 2023-08-21
ER

PT J
AU Blanes-Vidal, V
   Baatrup, G
   Nadimi, ES
AF Blanes-Vidal, Victoria
   Baatrup, Gunnar
   Nadimi, Esmaeil S.
TI Addressing priority challenges in the detection and assessment of
   colorectal polyps from capsule endoscopy and colonoscopy in colorectal
   cancer screening using machine learning
SO ACTA ONCOLOGICA
LA English
DT Article
ID COLON CAPSULE; SIZE; MULTICENTER; SOCIETY
AB Background: Colorectal capsule endoscopy (CCE) is a potentially valuable patient-friendly technique for colorectal cancer screening in large populations. Before it can be widely applied, significant research priorities need to be addressed. We present two innovative data science algorithms which can considerably improve acquisition and analysis of relevant data on colorectal polyps obtained from capsule endoscopy. Material and methods: A fully paired study was performed (2015-2016), where 255 participants from the Danish national screening program had CCE, colonoscopy, and histopathology of all detected polyps. We developed: (1) a new algorithm to match CCE and colonoscopy polyps, based on objective measures of similarity between polyps, and (2) a deep convolutional neural network (CNN) for autonomous detection and localization of colorectal polyps in colon capsule endoscopy. Results and conclusion: Unlike previous matching methods, our matching algorithm is able to objectively quantify the similarity between CCE and colonoscopy polyps based on their size, morphology and location, and provides a one-to-one unequivocal match between CCE and colonoscopy polyps. Compared to previous methods, the autonomous detection algorithm showed unprecedented high accuracy (96.4%), sensitivity (97.1%) and specificity (93.3%), calculated in respect to the number of polyps detected by trained nurses and gastroenterologists after visualizing frame-by-frame the CCE videos.
C1 [Blanes-Vidal, Victoria; Nadimi, Esmaeil S.] Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Campusvej 55, DK-5230 Odense, Denmark.
   [Baatrup, Gunnar] Odense Univ Hosp, Dept Surg, Svendborg, Denmark.
   [Baatrup, Gunnar] Univ Southern Denmark, Dept Clin Res, Odense, Denmark.
C3 University of Southern Denmark; University of Southern Denmark; Odense
   University Hospital; University of Southern Denmark
RP Blanes-Vidal, V (通讯作者)，Univ Southern Denmark, Maersk Mc Kinney Moller Inst, Campusvej 55, DK-5230 Odense, Denmark.
EM vbv@mmmi.sdu.dk
RI Blanes-Vidal, Victoria/B-5196-2019; Nadimi, Esmaeil S/B-5289-2019
OI Blanes-Vidal, Victoria/0000-0002-9269-4526; Nadimi, Esmaeil
   S/0000-0003-2613-2696; baatrup, gunnar/0000-0003-0300-5766
FU Research Foundation of the Health Care Region of Southern Denmark;
   Kraeftens Bekaempelse, Odense Universitets hospital and Syddansk
   Universitet
FX The study was financially supported by the Research Foundation of the
   Health Care Region of Southern Denmark, Kraeftens Bekaempelse, Odense
   Universitets hospital and Syddansk Universitet.
CR Allen JE, 2017, BEST PRACT RES CL GA, V31, P435, DOI 10.1016/j.bpg.2017.07.001
   Eliakim R, 2006, ENDOSCOPY, V38, P963, DOI 10.1055/s-2006-944832
   Eliakim R, 2009, ENDOSCOPY, V41, P1026, DOI 10.1055/s-0029-1215360
   Gopalswamy N, 1997, GASTROINTEST ENDOSC, V46, P497, DOI 10.1016/S0016-5107(97)70003-8
   GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kobaek-Larsen M, 2018, COLORECTAL DIS, V20, P479, DOI 10.1111/codi.13965
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Morales TG, 1996, GASTROINTEST ENDOSC, V43, P25
   Moug SJ, 2010, COLORECTAL DIS, V12, P646, DOI 10.1111/j.1463-1318.2009.01870.x
   Pilz JB, 2010, BMC GASTROENTEROL, V10, DOI 10.1186/1471-230X-10-66
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2015, GASTROENTEROLOGY, V148, P948, DOI 10.1053/j.gastro.2015.01.025
   Schoen RE, 1997, GASTROINTEST ENDOSC, V46, P492, DOI 10.1016/S0016-5107(97)70002-6
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Spada C, 2012, ENDOSCOPY, V44, P527, DOI 10.1055/s-0031-1291717
   Spada C, 2015, GUT, V64, P272, DOI 10.1136/gutjnl-2013-306550
   Spada C, 2011, GASTROINTEST ENDOSC, V74, P581, DOI 10.1016/j.gie.2011.03.1125
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   van Heijningen EMB, 2013, GASTROENTEROLOGY, V144, P1410, DOI 10.1053/j.gastro.2013.03.002
NR 20
TC 44
Z9 47
U1 0
U2 6
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0284-186X
EI 1651-226X
J9 ACTA ONCOL
JI Acta Oncol.
PD APR 1
PY 2019
VL 58
SU 1
SI SI
BP S29
EP S36
DI 10.1080/0284186X.2019.1584404
PG 8
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA HS5SB
UT WOS:000463930200006
PM 30836800
OA Bronze
DA 2023-08-21
ER

PT J
AU Zhang, X
   Chen, F
   Yu, T
   An, JY
   Huang, ZX
   Liu, JQ
   Hu, WL
   Wang, LJ
   Duan, HL
   Si, JM
AF Zhang, Xu
   Chen, Fei
   Yu, Tao
   An, Jiye
   Huang, Zhengxing
   Liu, Jiquan
   Hu, Weiling
   Wang, Liangjing
   Duan, Huilong
   Si, Jianmin
TI Real-time gastric polyp detection using convolutional neural networks
SO PLOS ONE
LA English
DT Article
AB Computer-aided polyp detection in gastric gastroscopy has been the subject of research over the past few decades. However, despite significant advances, automatic polyp detection in real time is still an unsolved problem. In this paper, we report on a convolutional neural network (CNN) for polyp detection that is constructed based on Single Shot MultiBox Detector (SSD) architecture and which we call SSD for Gastric Polyps (SSD-GPNet). To take full advantages of feature maps information from the feature pyramid and to acquire higher accuracy, we re-use information that is abandoned by Max-Pooling layers. In other words, we reuse the lost data from the pooling layers and concatenate that data as extra feature maps to contribute to classification and detection. Meanwhile, in the feature pyramid, we concatenate feature maps of the lower layers and feature maps that are deconvolved from upper layers to make explicit relationships between layers and to effectively increase the number of channels. The results show that our enhanced SSD for gastric polyp detection can realize real-time polyp detection with 50 frames per second (FPS) and can improve the mean average precision (mAP) from 88.5% to 90.4%, with only a little loss in time-performance. And the further experiment shows that SSD-GPNet has excellent performance in improving polyp detection recalls over 10% (p = 0.00053), especially in small polyp detection. This can help endoscopic physicians more easily find missed polyps and decrease the gastric polyp miss rate. It may be applicable in daily clinical practice to reduce the burden on physicians.
C1 [Zhang, Xu; Yu, Tao; An, Jiye; Huang, Zhengxing; Liu, Jiquan; Duan, Huilong] Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Fei; Hu, Weiling; Wang, Liangjing; Si, Jianmin] Zhejiang Univ, Inst Gastroenterol, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Fei; Wang, Liangjing] Zhejiang Univ, Sch Med, Dept Gastroenterol, Affiliated Hosp 2, Hangzhou, Zhejiang, Peoples R China.
   [Hu, Weiling; Si, Jianmin] Zhejiang Univ, Sch Med, Sir Run Run Shaw Hosp, Dept Gastroenterol, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang
   University
RP An, JY; Huang, ZX; Liu, JQ (通讯作者)，Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Key Lab Biomed Engn, Minist Educ, Hangzhou, Zhejiang, Peoples R China.; Hu, WL (通讯作者)，Zhejiang Univ, Inst Gastroenterol, Hangzhou, Zhejiang, Peoples R China.; Hu, WL (通讯作者)，Zhejiang Univ, Sch Med, Sir Run Run Shaw Hosp, Dept Gastroenterol, Hangzhou, Zhejiang, Peoples R China.
EM an_jiye@zju.edu.cn; zhengxinghuang@zju.edu.cn; liujq@zju.edu.cn;
   huweiling@zju.edu.cn
OI liu, jiquan/0000-0001-5994-6472; Yu, Tao/0000-0001-9617-7465
FU National Natural Science Foundation of China [31771072]; National Key
   Research and Development Program of China [2017YFC0114106]; Zhejiang
   Science and Technology Project [LGF18H160012]
FX Jiquan Liu is supported by National Natural Science Foundation of China
   (grant numbers 31771072). The URL is https://hfbic021dcb05d8e549bdh0qkw69uxxc656nn5fiac.eds.tju.edu.cn/; Jiquan Liu
   is supported by National Key Research and Development Program of China
   (grant numbers 2017YFC0114106). The URL is
   https://hfbicf3d001a7e805482bh0qkw69uxxc656nn5fiac.eds.tju.edu.cn/kjjh/.Weiling Hu is supported by Zhejiang Science
   and Technology Project (grant numbers LGF18H160012). The URL is
   https://hfbic8e5506313a874ee6h0qkw69uxxc656nn5fiac.eds.tju.edu.cn/.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], 2007, IEEE INT C IMAGE PRO, DOI [10.1109/ICIP.2007.4379193, DOI 10.1109/ICIP.2007.4379193]
   Baopu Li, 2010, 2010 IEEE International Conference on Automation and Logistics (ICAL), P126, DOI 10.1109/ICAL.2010.5585395
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Carmack SW, 2009, NAT REV GASTRO HEPAT, V6, P331, DOI 10.1038/nrgastro.2009.70
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Desai Anant M, 2004, Gastric Cancer, V7, P196, DOI 10.1007/s10120-004-0289-0
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu CY, 2017, DSSD DECONVOLUTIONAL, DOI DOI 10.48550/ARXIV.1701.06659
   Fu JJC, 2014, COMPUT MED IMAG GRAP, V38, P267, DOI 10.1016/j.compmedimag.2013.12.009
   Girshick R., 2014, P IEEE C COMP VIS PA, P580, DOI DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, 2015 IEEE INT C COMP, P7
   Hafner M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P365, DOI 10.1007/978-3-662-46224-9_63
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Iakovidis DK, 2005, P IEEE INT S COMP BA
   Jeong J, 2017, ENHANCEMENT SSD CONC
   Jia Y., 2014, P ACM INT C MULT, DOI 10.1145/2647868.2654889
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Park SY, 2016, MEDICAL IMAGING 2016
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simmons DT, 2006, ALIMENT PHARM THERAP, V24, P965, DOI 10.1111/j.1365-2036.2006.03080.x
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sundaram P, 2008, MED IMAGE ANAL, V12, P99, DOI 10.1016/j.media.2007.08.001
   Taha B, 2017, IM PROC ICIP 2017 IE
   Tajbakhsh N, 2015, 2015 IEEE 12 INT S B
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zheng B, 2012, SURG ENDOSC, V26, P1352, DOI 10.1007/s00464-011-2038-x
NR 43
TC 62
Z9 64
U1 0
U2 23
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAR 25
PY 2019
VL 14
IS 3
AR e0214133
DI 10.1371/journal.pone.0214133
PG 16
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA HQ1KV
UT WOS:000462157600038
PM 30908513
OA Green Submitted, Green Published, gold
DA 2023-08-21
ER

PT J
AU Wimmer, G
   Gadermayr, M
   Wolkersdorfer, G
   Kwitt, R
   Tamaki, T
   Tischendorf, J
   Hafner, M
   Yoshida, S
   Tanaka, S
   Merhof, D
   Uhl, A
AF Wimmer, Georg
   Gadermayr, Michael
   Wolkersdoerfer, Gernot
   Kwitt, Roland
   Tamaki, Toru
   Tischendorf, Jens
   Haefner, Michael
   Yoshida, Shigeto
   Tanaka, Shinji
   Merhof, Dorit
   Uhl, Andreas
TI Quest for the best endoscopic imaging modality for computer-assisted
   colonic polyp staging
SO WORLD JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Endoscopy; Colonic polyps; Automated diagnosis system; Narrow-band
   imaging; Chromoendoscopy; Imaging modalities; Image enhancement
   technologies
ID COLORECTAL POLYPS; HIGH-DEFINITION; I-SCAN; CLASSIFICATION; HISTOLOGY;
   DIAGNOSIS; NBI
AB BACKGROUND
   It was shown in previous studies that high definition endoscopy, high magnification endoscopy and image enhancement technologies, such as chromoendoscopy and digital chromoendoscopy [narrow-band imaging (NBI), i-Scan] facilitate the detection and classification of colonic polyps during endoscopic sessions. However, there are no comprehensive studies so far that analyze which endoscopic imaging modalities facilitate the automated classification of colonic polyps. In this work, we investigate the impact of endoscopic imaging modalities on the results of computer-assisted diagnosis systems for colonic polyp staging.
   AIM
   To assess which endoscopic imaging modalities are best suited for the computer-assisted staging of colonic polyps.
   METHODS
   In our experiments, we apply twelve state-of-the-art feature extraction methods for the classification of colonic polyps to five endoscopic image databases of colonic lesions. For this purpose, we employ a specifically designed experimental setup to avoid biases in the outcomes caused by differing numbers of images per image database. The image databases were obtained using different imaging modalities. Two databases were obtained by high-definition endoscopy in combination with i-Scan technology (one with chromoendoscopy and one without chromoendoscopy). Three databases were obtained by high-magnification endoscopy (two databases using narrow band imaging and one using chromoendoscopy). The lesions are categorized into non-neoplastic and neoplastic according to the histological diagnosis.
   RESULTS
   Generally, it is feature-dependent which imaging modalities achieve high results and which do not. For the high-definition image databases, we achieved overall classification rates of up to 79.2% with chromoendoscopy and 88.9% without chromoendoscopy. In the case of the database obtained by high-magnification chromoendoscopy, the classification rates were up to 81.4%. For the combination of high-magnification endoscopy with NBI, results of up to 97.4% for one database and up to 84% for the other were achieved. Non-neoplastic lesions were classified more accurately in general than non-neoplastic lesions. It was shown that the image recording conditions highly affect the performance of automated diagnosis systems and partly contribute to a stronger effect on the staging results than the used imaging modality.
   CONCLUSION
   Chromoendoscopy has a negative impact on the results of the methods. NBI is better suited than chromoendoscopy. High-definition and high-magnification endoscopy are equally suited.
C1 [Wimmer, Georg; Kwitt, Roland; Uhl, Andreas] Univ Salzburg, Dept Comp Sci, Jakob Haringer Str 2, A-5020 Salzburg, Austria.
   [Gadermayr, Michael; Merhof, Dorit] Rhein Westfal TH Aachen, Interdisciplinary Imaging & Vis Inst Aachen, D-52074 Aachen, Germany.
   [Wolkersdoerfer, Gernot] Paracelsus Med Univ, Dept Internal Med 1, Salzburger Landesklin SALK, A-5020 Salzburg, Austria.
   [Tamaki, Toru] Hiroshima Univ, Grad Sch Engn, Dept Informat Engn, Hiroshima 7398527, Japan.
   [Tischendorf, Jens] Univ Hosp Aachen, Internal Med & Gastroenterol, D-52146 Wurselen, Germany.
   [Haefner, Michael] Krankenhaus St Elisabeth, Dept Gastroenterol & Hepatol, A-1080 Vienna, Austria.
   [Yoshida, Shigeto] Hiroshima Univ, Grad Sch Biomed & Hlth Sci, Dept Endoscopy & Med, Hiroshima 7348551, Japan.
   [Tanaka, Shinji] Hiroshima Univ Hosp, Dept Endoscopy, Hiroshima 7348551, Japan.
C3 Salzburg University; RWTH Aachen University; Paracelsus Private Medical
   University; Hiroshima University; RWTH Aachen University; RWTH Aachen
   University Hospital; Hiroshima University; Hiroshima University
RP Wimmer, G (通讯作者)，Univ Salzburg, Dept Comp Sci, Jakob Haringer Str 2, A-5020 Salzburg, Austria.
EM gwimmer@cosy.sbg.ac.at
RI Merhof, Dorit/AAV-7892-2021; Kwitt, Roland/AFS-8639-2022; Tanaka,
   Shinji/G-5266-2019; Tamaki, Toru/D-7091-2011; Kwitt,
   Roland/HII-6060-2022
OI Tamaki, Toru/0000-0001-9712-7777; , Michael/0000-0003-1450-9222
FU Austrian Science Fund (FWF), KLI project [429, TRP206]; Austrian Science
   Fund (FWF) [TRP206] Funding Source: Austrian Science Fund (FWF)
FX Supported by the Austrian Science Fund (FWF), KLI project 429, No.
   TRP206.
CR Berr F, 2014, EARLY NEOPLASIAS GAS, DOI [10.1007/978-1-4614-8292-5, DOI 10.1007/978-1-4614-8292-5]
   Bhat YM, 2014, GASTROINTEST ENDOSC, V80, P919, DOI 10.1016/j.gie.2014.06.019
   Bouwens MWE, 2013, WORLD J GASTROENTERO, V19, P4334, DOI 10.3748/wjg.v19.i27.4334
   Chang CC, 2009, INT J COLORECTAL DIS, V24, P1413, DOI 10.1007/s00384-009-0760-9
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gross S, 2012, PROC SPIE, V8315, DOI 10.1117/12.911177
   Hafner M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P365, DOI 10.1007/978-3-662-46224-9_63
   Hafner M, 2012, COMPUT METH PROG BIO, V107, P565, DOI 10.1016/j.cmpb.2011.12.012
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hafner M, 2014, LARGE DATA MED IMAGI, P205, DOI [10.1007/978-3-319-05530-5_20, DOI 10.1007/978-3-319-05530-5_20]
   Hafner M, 2014, SHAPE SIZE ADAPTED L, DOI [10.1109/ICIP.2014.7025466, DOI 10.1109/ICIP.2014.7025466]
   Hoffman A, 2010, DIGEST LIVER DIS, V42, P45, DOI 10.1016/j.dld.2009.04.005
   Kodashima S, 2010, WORLD J GASTROENTERO, V16, P1043, DOI 10.3748/wjg.v16.i9.1043
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Manfredi MA, 2015, GASTROINTEST ENDOSC, V81, P249, DOI 10.1016/j.gie.2014.06.020
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Rameshshanker R, 2016, Curr Treat Options Gastroenterol, V14, P140, DOI 10.1007/s11938-016-0075-1
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tischendorf JJW, 2007, ENDOSCOPY, V39, P1092, DOI 10.1055/s-2007-966781
   Wimmer G, 2016, INT CONF IMAG PROC
   Wimmer G, 2016, P 3 INT WORKSH COMP, P59, DOI [10.1007/978-3-319-54057-3_6, DOI 10.1007/978-3-319-54057-3_6]
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
NR 27
TC 2
Z9 2
U1 1
U2 2
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 1007-9327
EI 2219-2840
J9 WORLD J GASTROENTERO
JI World J. Gastroenterol.
PD MAR 14
PY 2019
VL 25
IS 10
BP 1197
EP 1209
DI 10.3748/wjg.v25.i10.1197
PG 13
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HO7ZO
UT WOS:000461169100003
PM 30886503
OA Green Submitted, Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Diamantis, DE
   Iakovidis, DK
   Koulaouzidis, A
AF Diamantis, Dimitrios E.
   Iakovidis, Dimitris K.
   Koulaouzidis, Anastasios
TI Look-behind fully convolutional neural network for computer-aided
   endoscopy
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Computer-aided diagnosis; Endoscopy; Convolutional neural networks;
   Abnormality detection
ID CAPSULE ENDOSCOPY; IMAGES
AB In this paper, we propose a novel Fully Convolutional Neural Network (FCN) architecture aiming to aid the detection of abnormalities, such as polyps, ulcers and blood, in gastrointestinal (GI) endoscopy images. The proposed architecture, named Look-Behind FCN (LB-FCN), is capable of extracting multi-scale image features by using blocks of parallel convolutional layers with different filter sizes. These blocks are connected by Look-Behind (LB) connections, so that the features they produce are combined with features extracted from behind layers, thus preserving the respective information. Furthermore, it has a smaller number of free parameters than conventional Convolutional Neural Network (CNN) architectures, which makes it suitable for training with smaller datasets. This is particularly useful in medical image analysis, since data availability is usually limited due to ethicolegal constraints. The performance of LB-FCN is evaluated on both flexible and wireless capsule endoscopy datasets, reaching 99.72% and 93.50%, in terms of Area Under receiving operating Characteristic (AUC) respectively. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Diamantis, Dimitrios E.; Iakovidis, Dimitris K.] Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
   [Koulaouzidis, Anastasios] Royal Infirm Edinburgh NHS Trust, Endoscopy Unit, Edinburgh, Midlothian, Scotland.
C3 Royal Infirmary of Edinburgh; University of Edinburgh
RP Iakovidis, DK (通讯作者)，Univ Thessaly, Dept Comp Sci & Biomed Informat, Lamia, Greece.
EM dimitris.iakovidis@ieee.org
RI Koulaouzidis, Anastasios/G-9060-2014
OI Koulaouzidis, Anastasios/0000-0002-2248-489X; Diamantis,
   Dimitrios/0000-0003-4384-8557; Iakovidis, Dimitris/0000-0002-5027-5323
CR Abadi Martin, 2016, arXiv
   [Anonymous], 2008, 2008 IEEE Hot Chips 20 Symposium (HCS), DOI 10.1109/HOTCHIPS.2008.7476516
   Chen HH, 2017, NEUROCOMPUTING, V229, P77, DOI 10.1016/j.neucom.2016.06.077
   Chollet F., 2015, KERAS PROBABILISTIC
   Cong Y, 2016, NEUROCOMPUTING, V196, P150, DOI 10.1016/j.neucom.2015.10.130
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Du K.L., 2006, NEURAL NETW SOFTCOMP, P1, DOI [10.1007/1-84628-303-5/COVER, DOI 10.1007/1-84628-303-5/COVER, DOI 10.1007/1-84628-303-5]
   EndoVisSub-Abnormal, 2015, ENDOVISSUB ABNORMAL
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gers FA, 2000, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2000.861302
   Gono K, 2004, J BIOMED OPT, V9, P568, DOI 10.1117/1.1695563
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   HE KM, 2015, PROC CVPR IEEE, P5353, DOI [DOI 10.1109/CVPR.2015.7299173, 10.1109/CVPR.2015.7299173]
   Hegenbart S, 2013, MED IMAGE ANAL, V17, P458, DOI 10.1016/j.media.2013.02.001
   Hinton G.E., 2012, COURSERA NEURAL NETW, P31
   Iakovidis D. K., 2018, IEEE T MED IMAGING
   Iakovidis DK, 2015, IEEE ENG MED BIO, P731, DOI 10.1109/EMBC.2015.7318466
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Jia Y., 2014, P ACM INT C MULT, DOI 10.1145/2647868.2654889
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kiesslich Ralf, 2005, Gastrointest Endosc Clin N Am, V15, P715, DOI 10.1016/j.giec.2005.08.010
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   MULLER AD, 1995, ANN INTERN MED, V123, P904, DOI 10.7326/0003-4819-123-12-199512150-00002
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Springenberg J. T., 2015, CORR, DOI DOI 10.48550/ARXIV.1412.6806
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Swain P, 2008, WORLD J GASTROENTERO, V14, P4142, DOI 10.3748/wjg.14.4142
   Szegedy C., 2017, INCEPTION V4 INCEPTI, P12
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   The Cleveland Clinic Foundation, 2017, DIG DIS GASTR DIS CL
   van der Sommen F, 2016, ENDOSCOPY, V48, P617, DOI 10.1055/s-0042-105284
   Vasilakakis M, 2017, LECT NOTES COMPUT SC, V10170, P96, DOI 10.1007/978-3-319-54057-3_9
   Wang S, 2016, IEEE T BIO-MED ENG, V63, P2347, DOI 10.1109/TBME.2016.2530141
   Wang S, 2015, IEEE IMAGE PROC, P3072, DOI 10.1109/ICIP.2015.7351368
   WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269
   Wimmer G., 2016, LNCS
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yao K, 2013, ZOOM GASTROSCOPY MAG
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 58
TC 32
Z9 32
U1 0
U2 13
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD MAR
PY 2019
VL 49
BP 192
EP 201
DI 10.1016/j.bspc.2018.12.005
PG 10
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA HL7SY
UT WOS:000458942500017
DA 2023-08-21
ER

PT J
AU Figueiredo, PN
   Figueiredo, IN
   Pinto, L
   Kumar, S
   Tsai, YHR
   Mamonov, AV
AF Figueiredo, Pedro N.
   Figueiredo, Isabel N.
   Pinto, Luis
   Kumar, Sunil
   Tsai, Yen-Hsi Richard
   Mamonov, Alexander V.
TI Polyp detection with computer-aided diagnosis in white light
   colonoscopy: comparison of three different methods
SO ENDOSCOPY INTERNATIONAL OPEN
LA English
DT Article
ID CLASSIFICATION; VALIDATION
AB Background and study aims Detection of polyps during colonoscopy is essential for screening colorectal cancer and computer-aided-diagnosis (CAD) could be helpful for this objective. The goal of this study was to assess the efficacy of CADin detection of polyps in video colonoscopy by using three methods we have proposed and applied for diagnosis of polyps in wireless capsule colonoscopy.
   Patients and methods Forty-two patients were included in the study, each one bearing one polyp.A dataset was generated with a total of 1680 polyp instances and 1360 frames of normal mucosa. We used three methods, that are all binary classifiers, labelling a frame as either containing a polyp or not. Two of the methods (Methods 1 and 2) are threshold-based and address the problem of polyp detection (i.e. separation between normal mucosa frames and polyp frames) and the problem of polyp localization (i.e. the ability to locate the polyp in a frame). The third method (Method 3) belongs to the class of machine learning methods and only addresses the polyp detection problem. The mathematical techniques underlying these three methods rely on appropriate fusion of information about the shape, color and texture content of the objects presented in the medical images.
   Results Regarding polyp localization, the best method is Method 1 with a sensitivity of 71.8%. Comparing the performance of the three methods in the detection of polyps, independently of the precision in the location of the lesions, Method 3 stands out, achieving a sensitivity of 99.7%, an accuracy of 91.1%, and a specificity of 84.9%.
   Conclusion CAD, using the three studied methods, showed good accuracy in the detection of polyps with white light colonoscopy.
C1 [Figueiredo, Pedro N.] Ctr Hosp & Univ Coimbra, Dept Gastroenterol, Coimbra, Portugal.
   [Figueiredo, Pedro N.] Univ Coimbra, Fac Med, Coimbra, Portugal.
   [Figueiredo, Pedro N.] Ctr Cirurg Coimbra, Coimbra, Portugal.
   [Figueiredo, Isabel N.; Pinto, Luis] Univ Coimbra, Dept Math, CMUC, Coimbra, Portugal.
   [Kumar, Sunil] Indian Inst Technol BHU Varanasi, Dept Math Sci, Varanasi, Uttar Pradesh, India.
   [Tsai, Yen-Hsi Richard] Univ Texas Austin, Dept Math, Austin, TX 78712 USA.
   [Tsai, Yen-Hsi Richard] Univ Texas Austin, Inst Computat Engn & Sci, Austin, TX 78712 USA.
   [Mamonov, Alexander V.] Univ Houston, Dept Math, Houston, TX 77204 USA.
C3 Universidade de Coimbra; Centro Hospitalar e Universitario de Coimbra
   (CHUC); Universidade de Coimbra; Universidade de Coimbra; Universidade
   de Coimbra; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology BHU Varanasi (IIT BHU Varanasi); University of
   Texas System; University of Texas Austin; University of Texas System;
   University of Texas Austin; University of Houston System; University of
   Houston
RP Figueiredo, PN (通讯作者)，Univ Coimbra, Fac Med, Gastroenterol, Polo 1 Rua Larga, P-3000504 Coimbra, Portugal.
EM pnf11@sapo.pt
RI Kumar, Sunil/Q-8557-2016; Mamonov, Alexander/IWM-4944-2023; Figueiredo,
   Isabel Narra/ABD-7828-2020; Mamonov, Alexander V/M-5315-2014; Kumar,
   Sunil/ABU-7487-2022
OI Kumar, Sunil/0000-0001-9991-1012; Mamonov,
   Alexander/0000-0002-1270-7535; Figueiredo, Isabel
   Narra/0000-0002-0215-8851; Mamonov, Alexander V/0000-0002-1270-7535;
   Pinto, Luis/0000-0003-1121-1738; Figueiredo, Pedro/0000-0001-9872-6341
FU FCT [POCI-01-0145-FEDER-028960]; Portuguese Government through FCT/MEC
   [CMUC-UID/MAT/00324/2013]; FCT scholarship [SFRH/BPD/112687/2015];
   European Regional Development Fund through the Partnership Agreement
   PT2020
FX This work was partially supported by the FCT research project
   POCI-01-0145-FEDER-028960. The authors Isabel N. Figueiredo and Luis
   Pinto also acknowledge some support from CMUC-UID/MAT/00324/2013, funded
   by the Portuguese Government through FCT/MEC and co-funded by the
   European Regional Development Fund through the Partnership Agreement
   PT2020. Luis Pinto was also supported by FCT scholarship
   SFRH/BPD/112687/2015.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brenner H, 2014, GASTROENTEROLOGY, V146, P709, DOI 10.1053/j.gastro.2013.09.001
   Calderwood AH, 2010, GASTROINTEST ENDOSC, V72, P686, DOI 10.1016/j.gie.2010.06.068
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Figueiredo I N, 2014, COMPUTATIONAL VISION, P235
   Figueiredo I N, 2010, 20101065 UCLA CAM, P10
   Figueiredo Pedro N, 2011, Diagn Ther Endosc, V2011, P182435, DOI 10.1155/2011/182435
   Globocan, 2012, EST CANC INC MORT PR
   Kaminski MF, 2017, ENDOSCOPY, V49, P378, DOI 10.1055/s-0043-103411
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rex DK, 2015, DIGEST DIS SCI, V60, P639, DOI 10.1007/s10620-014-3448-0
   Schanda J, 2007, COLORIMETRY: UNDERSTANDING THE CIE SYSTEM, P1, DOI 10.1002/9780470175637
   Shaukat A, 2009, CLIN GASTROENTEROL H, V7, P1335, DOI 10.1016/j.cgh.2009.07.027
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
NR 21
TC 20
Z9 22
U1 0
U2 0
PU GEORG THIEME VERLAG KG
PI STUTTGART
PA RUDIGERSTR 14, D-70469 STUTTGART, GERMANY
SN 2364-3722
EI 2196-9736
J9 ENDOSC INT OPEN
JI Endosc. Int. Open
PD FEB
PY 2019
VL 7
IS 2
BP E209
EP E215
DI 10.1055/a-0808-4456
PG 7
WC Gastroenterology & Hepatology; Surgery
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology; Surgery
GA HI0SP
UT WOS:000456153900010
PM 30705955
OA Green Submitted, gold, Green Published
DA 2023-08-21
ER

PT J
AU Ahmad, OF
   Soares, AS
   Mazomenos, E
   Brandao, P
   Vega, R
   Seward, E
   Stoyanov, D
   Chand, M
   Lovat, LB
AF Ahmad, Omer F.
   Soares, Antonio S.
   Mazomenos, Evangelos
   Brandao, Patrick
   Vega, Roser
   Seward, Edward
   Stoyanov, Danail
   Chand, Manish
   Lovat, Laurence B.
TI Artificial intelligence and computer-aided diagnosis in colonoscopy:
   current evidence and future directions
SO LANCET GASTROENTEROLOGY & HEPATOLOGY
LA English
DT Review
ID COLORECTAL POLYP HISTOLOGY; ADENOMA DETECTION; EUROPEAN-SOCIETY; OPTICAL
   BIOPSY; SCREENING COLONOSCOPY; QUALITY INDICATORS; COLON POLYPS; SYSTEM;
   LESIONS; CLASSIFICATION
AB Computer-aided diagnosis offers a promising solution to reduce variation in colonoscopy performance. Pooled miss rates for polyps are as high as 22%, and associated interval colorectal cancers after colonoscopy are of concern. Optical biopsy, whereby in-vivo classification of polyps based on enhanced imaging replaces histopathology, has not been incorporated into routine practice because it is limited by interobserver variability and generally only meets accepted standards in expert settings. Real-time decision-support software has been developed to detect and characterise polyps, and also to offer feedback on the technical quality of inspection. Some of the current algorithms, particularly with recent advances in artificial intelligence techniques, match human expert performance for optical biopsy. In this Review, we summarise the evidence for clinical applications of computer-aided diagnosis and artificial intelligence in colonoscopy.
C1 [Ahmad, Omer F.; Mazomenos, Evangelos; Brandao, Patrick; Stoyanov, Danail; Lovat, Laurence B.] UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, London W1W 7TS, England.
   [Soares, Antonio S.; Chand, Manish; Lovat, Laurence B.] UCL, Div Surg & Intervent Sci, London, England.
   [Ahmad, Omer F.; Vega, Roser; Seward, Edward; Chand, Manish; Lovat, Laurence B.] Univ Coll London Hosp, Gastrointestinal Serv, London, England.
C3 UK Research & Innovation (UKRI); Engineering & Physical Sciences
   Research Council (EPSRC); University of London; University College
   London; University of London; University College London; University
   College London Hospitals NHS Foundation Trust
RP Ahmad, OF (通讯作者)，UCL, Wellcome EPSRC Ctr Intervent & Surg Sci, London W1W 7TS, England.
EM o.ahmad@ucl.ac.uk
RI Lovat, Laurence/C-1986-2009; Stoyanov, Danail/V-1043-2019
OI Lovat, Laurence/0000-0003-4542-3915; Stoyanov,
   Danail/0000-0002-0980-3227; Sampaio Soares, Antonio/0000-0001-7773-2427;
   Mazomenos, Evangelos/0000-0003-0357-5996
FU Engineering and Physical Sciences Research Council [EP/R004080/1]
   Funding Source: researchfish; EPSRC [EP/P027938/1] Funding Source: UKRI
CR Alexandre LA, 2008, INT C BIOMEDICAL ENG
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Axon A, 2005, ENDOSCOPY, V37, P570, DOI 10.1055/s-2005-861352
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Byrne MF, 2017, GASTROENTEROLOGY, V153, P1460, DOI 10.1053/j.gastro.2017.10.026
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chen SC, 2007, AM J GASTROENTEROL, V102, P856, DOI 10.1111/j.1572-0241.2006.01054.x
   Coe SG, 2013, AM J GASTROENTEROL, V108, P219, DOI 10.1038/ajg.2012.417
   Corley DA, 2011, GASTROINTEST ENDOSC, V74, P656, DOI 10.1016/j.gie.2011.04.017
   Crockett SD, 2018, ENDOSCOPY, V50, P984, DOI 10.1055/a-0597-1740
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   East JE, 2018, LANCET GASTROENTEROL, V3, P10, DOI 10.1016/S2468-1253(17)30366-7
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Facciorusso A, 2018, CLIN GASTROENTEROL H, V16, P1209, DOI 10.1016/j.cgh.2017.11.007
   Ferlitsch M, 2017, ENDOSCOPY, V49, P270, DOI 10.1055/s-0043-102569
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Filip D, 2012, WORLD J GASTROENTERO, V18, P4270, DOI 10.3748/wjg.v18.i32.4270
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hazewinkel Y, 2013, GASTROINTEST ENDOSC, V77, P916, DOI 10.1016/j.gie.2012.12.018
   Hwang S, 2007, IEEE IMAGE PROC, P1029
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kudo SE, 2015, GASTROINTEST ENDOSC, V82, P912, DOI 10.1016/j.gie.2015.04.039
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   le Clercq CMC, 2014, GUT, V63, P957, DOI 10.1136/gutjnl-2013-304880
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   McGill SK, 2015, GUT, V64, P184, DOI 10.1136/gutjnl-2013-305743
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Morris EJA, 2015, GUT, V64, P1248, DOI 10.1136/gutjnl-2014-308362
   National Institute for Health and Care Excellence, 2017, VIRT CHROM ASS COL P
   Park S. Y., 2016, SPIE MED IMAGING
   Prior F, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.124
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rembacken B, 2012, ENDOSCOPY, V44, P957, DOI 10.1055/s-0032-1325686
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Samek W, 2017, IEEE T NEUR NET LEAR, V28, P2660, DOI 10.1109/TNNLS.2016.2599820
   Sawhney MS, 2008, GASTROENTEROLOGY, V135, P1892, DOI 10.1053/j.gastro.2008.08.024
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Stanek SR, 2013, COMPUT METH PROG BIO, V112, P407, DOI 10.1016/j.cmpb.2013.07.028
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Takeda K, 2017, ENDOSCOPY, V49, P798, DOI 10.1055/s-0043-105486
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   Torre LA, 2015, CA-CANCER J CLIN, V65, P87, DOI 10.3322/caac.21262
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Vlugt M, 2016, ENDOSC INT OPEN, V4, pE778, DOI 10.1055/s-0042-107667
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2010, IEEE T BIO-MED ENG, V57, P685, DOI 10.1109/TBME.2009.2034466
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 71
TC 98
Z9 105
U1 2
U2 36
PU ELSEVIER INC
PI SAN DIEGO
PA 525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA
EI 2468-1253
J9 LANCET GASTROENTEROL
JI Lancet Gastroenterol. Hepatol.
PD JAN
PY 2019
VL 4
IS 1
BP 71
EP 80
PG 10
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HG9MB
UT WOS:000455331500024
PM 30527583
OA Green Submitted, Green Accepted
DA 2023-08-21
ER

PT J
AU Allescher, HD
   Weingart, V
AF Allescher, Hans-Dieter
   Weingart, Vincens
TI Optimizing Screening Colonoscopy: Strategies and Alternatives
SO VISCERAL MEDICINE
LA English
DT Review
DE Adenoma detection rate; Polyp detection rate; Interval carcinoma;
   Colorectal cancer; Screening
ID ENDOCUFF-ASSISTED COLONOSCOPY; AIDED DIAGNOSTIC SYSTEM; ADENOMA
   DETECTION RATE; BALLOON COLONOSCOPE; POLYP DETECTION; COLORECTAL
   LESIONS; CECAL INTUBATION; MISS RATE; MULTICENTER; RISK
AB Screening colonoscopy is the most effective screening procedure for the prevention of colorectal cancer. The efficacy of colonoscopy is highly dependent on the overall quality of how this procedure is indicated, planned, prepared, and performed. The quality is directly linked to the number of polyps and/or adenomas detected or, in other words, to the number of polyps or adenomas missed during the procedure. The quality has a direct impact on the rate of interval carcinoma and on the range of how the incidence and occurrence of colorectal cancer is reduced. This review summarizes the current status on general measures and procedure improvements and standards as well as technical advances which have been suggested and established to improve the quality of polyp and adenoma detection rate. This includes selection and preparation of the patients, planning, methodological and technical performance of the procedure, and technical advances of the endoscope technology in order to improve screening results. It also covers new technologies with wide angle endoscopes (Ewave) and IT-based approaches using artificial intelligence to such as ai4GI for the polyp detection and image analysis. (C) 2019 S. Karger AG, Basel
C1 [Allescher, Hans-Dieter; Weingart, Vincens] Klinikum Garmisch Partenkirchen, Dept Gastroenterol, Garmisch Partenkirchen, Germany.
RP Allescher, HD (通讯作者)，Klinikum Garmisch Partenkirchen, Dept Gastroenterol, Ctr Internal Med, Auenstr 6, DE-82467 Garmisch Partenkirchen, Germany.
EM hans.allescher@klinikum-gap.de
CR Alagappan M, 2018, WORLD J GASTRO ENDOS, V10, P239, DOI 10.4253/wjge.v10.i10.239
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Bevan R, 2016, ENDOSC INT OPEN, V4, pE205, DOI 10.1055/s-0041-107900
   Brenner H, 2010, J NATL CANCER I, V102, P89, DOI 10.1093/jnci/djp436
   Bronzwaer MES, 2018, ENDOSCOPY, V50, P63, DOI 10.1055/s-0043-120666
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Denzer U, 2015, Z Gastroenterol, V53, pE1, DOI 10.1055/s-0041-109598
   Dik VK, 2015, ENDOSCOPY, V47, P1151, DOI 10.1055/s-0034-1392421
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Floer M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114267
   Gralnek IM, 2015, DIGEST ENDOSC, V27, P223, DOI 10.1111/den.12382
   Gralnek IM, 2014, ENDOSCOPY, V46, P883, DOI 10.1055/s-0034-1377968
   Halpern Z, 2015, ENDOSCOPY, V47, P238, DOI 10.1055/s-0034-1391437
   Hasan N, 2014, GASTROINTEST ENDOSC, V80, P1135, DOI 10.1016/j.gie.2014.04.024
   Heitzer E, 2019, NAT REV GENET, V20, P71, DOI 10.1038/s41576-018-0071-5
   Heitzer E, 2017, NPJ PRECIS ONCOL, V1, DOI 10.1038/s41698-017-0039-5
   Hsu CM, 2012, J GASTROEN HEPATOL, V27, P76, DOI 10.1111/j.1440-1746.2011.06795.x
   Jung P, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000011253
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Klare P, 2019, GASTROINTEST ENDOSC, V89, P576, DOI 10.1016/j.gie.2018.09.042
   Kondo S, 2007, AM J GASTROENTEROL, V102, P75, DOI 10.1111/j.1572-0241.2006.00897.x
   Kudo SE, 1996, GASTROINTEST ENDOSC, V44, P8, DOI 10.1016/S0016-5107(96)70222-5
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Lee SW, 2016, AM J GASTROENTEROL, V111, P63, DOI 10.1038/ajg.2015.354
   Lenze F, 2014, ENDOSCOPY, V46, P610, DOI 10.1055/s-0034-1365446
   Leung F, 2016, CLIN CHEM, V62, P1054, DOI 10.1373/clinchem.2016.260331
   Leung WK, 2014, AM J GASTROENTEROL, V109, P855, DOI 10.1038/ajg.2014.83
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Ng SC, 2012, AM J GASTROENTEROL, V107, P1165, DOI 10.1038/ajg.2012.135
   Omata F, 2014, SCAND J GASTROENTERO, V49, P222, DOI 10.3109/00365521.2013.863964
   Papanikolaou IS, 2017, ENDOSCOPY, V49, P468, DOI 10.1055/s-0042-124415
   Perakis S, 2017, BMC MED, V15, DOI 10.1186/s12916-017-0840-6
   Pohl J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126067
   Ristikankare M, 2016, SCAND J GASTROENTERO, V51, P368, DOI 10.3109/00365521.2015.1083611
   Sanaka MR, 2009, AM J GASTROENTEROL, V104, P1659, DOI 10.1038/ajg.2009.249
   Shaukat A, 2015, CANCER EPIDEM BIOMAR, V24, P913, DOI 10.1158/1055-9965.EPI-14-1321
   Sosna J, 2003, AM J ROENTGENOL, V181, P1593, DOI 10.2214/ajr.181.6.1811593
   Subramanian V, 2011, ENDOSCOPY, V43, P499, DOI 10.1055/s-0030-1256207
   Triantafyllou K, 2017, ENDOSCOPY, V49, P1051, DOI 10.1055/s-0043-114412
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Walter B, 2019, GASTROINTEST ENDOSC, V89, P506, DOI 10.1016/j.gie.2018.08.014
   Walter BM, 2016, JMIR MHEALTH UHEALTH, V4, P400, DOI 10.2196/mhealth.5289
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
NR 47
TC 6
Z9 6
U1 0
U2 7
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 2297-4725
EI 2297-475X
J9 VISC MED
JI Visc. Med.
PY 2019
VL 35
IS 4
BP 215
EP 225
DI 10.1159/000501835
PG 11
WC Gastroenterology & Hepatology; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology; Surgery
GA IP8BZ
UT WOS:000480273200004
PM 31602382
OA Bronze, Green Published
DA 2023-08-21
ER

PT J
AU Byrne, MF
   Chapados, N
   Soudan, F
   Oertel, C
   Perez, ML
   Kelly, R
   Iqbal, N
   Chandelier, F
   Rex, DK
AF Byrne, Michael F.
   Chapados, Nicolas
   Soudan, Florian
   Oertel, Clemens
   Linares Perez, Milagros
   Kelly, Raymond
   Iqbal, Nadeem
   Chandelier, Florent
   Rex, Douglas K.
TI Real-time differentiation of adenomatous and hyperplastic diminutive
   colorectal polyps during analysis of unaltered videos of standard
   colonoscopy using a deep learning model
SO GUT
LA English
DT Article
ID QUALITY INDICATORS; EUROPEAN-SOCIETY; SERRATED POLYPS; RISK; VALIDATION;
   CANCER; SYSTEM; PREVALENCE; DIAGNOSIS; HISTOLOGY
AB Background In general, academic but not community endoscopists have demonstrated adequate endoscopic differentiation accuracy to make the 'resect and discard' paradigm for diminutive colorectal polyps workable. Computer analysis of video could potentially eliminate the obstacle of interobserver variability in endoscopic polyp interpretation and enable widespread acceptance of 'resect and discard'.
   Study design and methods We developed an artificial intelligence (AI) model for real-time assessment of endoscopic video images of colorectal polyps. A deep convolutional neural network model was used. Only narrow band imaging video frames were used, split equally between relevant multiclasses. Unaltered videos from routine exams not specifically designed or adapted for AI classification were used to train and validate the model. The model was tested on a separate series of 125 videos of consecutively encountered diminutive polyps that were proven to be adenomas or hyperplastic polyps.
   Results T he AI model works with a confidence mechanism and did not generate sufficient confidence to predict the histology of 19 polyps in the test set, representing 15% of the polyps. For the remaining 106 diminutive polyps, the accuracy of the model was 94% (95% CI 86% to 97%), the sensitivity for identification of adenomas was 98% (95% CI 92% to 100%), specificity was 83% (95% CI 67% to 93%), negative predictive value 97% and positive predictive value 90%.
   Conclusions A n AI model trained on endoscopic video can differentiate diminutive adenomas from hyperplastic polyps with high accuracy. Additional study of this programme in a live patient clinical trial setting to address resect and discard is planned.
C1 [Byrne, Michael F.] Vancouver Gen Hosp, Div Gastroenterol, Vancouver, BC, Canada.
   [Chapados, Nicolas; Soudan, Florian; Oertel, Clemens; Chandelier, Florent] Imagia, Dept Technol, Montreal, PQ, Canada.
   [Chapados, Nicolas] Ecole Polytech Montreal, Dept Appl Math, Montreal, PQ, Canada.
   [Linares Perez, Milagros] Univ Buenos Aires, Dept Gastroenterol, Buenos Aires, DF, Argentina.
   [Kelly, Raymond] Beaumont Hosp, Dept Anaesthet, Dublin, Ireland.
   [Iqbal, Nadeem] St Lukes Hosp, Dept Gastroenterol, Kilkenny, Ireland.
   [Rex, Douglas K.] Indiana Univ, Div Gastroenterol & Hepatol, Med Ctr, Indianapolis, IN USA.
C3 University of British Columbia; Universite de Montreal; Polytechnique
   Montreal; University of Buenos Aires; Indiana University System; Indiana
   University-Purdue University Indianapolis
RP Byrne, MF (通讯作者)，Univ British Columbia, Div Gastroenterol, Vancouver Gen Hosp, Vancouver, BC V5Z 1M9, Canada.
EM mike@ai4gi.com
RI Iqbal, Nadeem/AAN-3196-2021
OI Iqbal, Nadeem/0000-0002-0602-8333
FU Satis Operations Inc; Imagia Cybernetics
FX This work was primarily supported by 'ai4gi', a joint venture between
   Satis Operations Inc and Imagia Cybernetics.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Barclay RL, 2006, NEW ENGL J MED, V355, P2533, DOI 10.1056/NEJMoa055498
   Chen SC, 2007, AM J GASTROENTEROL, V102, P856, DOI 10.1111/j.1572-0241.2006.01054.x
   Coe SG, 2013, AM J GASTROENTEROL, V108, P219, DOI 10.1038/ajg.2012.417
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Hayashi N, 2013, GASTROINTEST ENDOSC, V78, P625, DOI 10.1016/j.gie.2013.04.185
   Hetzel JT, 2010, AM J GASTROENTEROL, V105, P2656, DOI 10.1038/ajg.2010.315
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Ijspeert JE, 2015, GASTROINTEST ENDOSC, V81, pAB260, DOI 10.1016/j.gie.2015.03.1348
   Kahi CJ, 2012, GASTROINTEST ENDOSC, V75, P515, DOI 10.1016/j.gie.2011.08.021
   Kaminski MF, 2014, ENDOSCOPY, V46, P435, DOI 10.1055/s-0034-1365348
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kessler WR, 2011, ENDOSCOPY, V43, P683, DOI 10.1055/s-0030-1256381
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Pohl H, 2013, GASTROENTEROLOGY, V144, P74, DOI 10.1053/j.gastro.2012.09.043
   Ponugoti PL, 2017, DIGEST LIVER DIS, V49, P34, DOI 10.1016/j.dld.2016.06.025
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2017, GASTROINTEST ENDOSC, V85, P614, DOI 10.1016/j.gie.2016.10.011
   Rex DK, 2015, GASTROINTEST ENDOSC, V81, P31, DOI 10.1016/j.gie.2014.07.058
   Rex DK, 2012, AM J GASTROENTEROL, V107, P1315, DOI 10.1038/ajg.2012.161
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Tajbakhsh Nima, 2015, Inf Process Med Imaging, V24, P327, DOI 10.1007/978-3-319-19992-4_25
NR 34
TC 343
Z9 369
U1 9
U2 106
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 0017-5749
EI 1468-3288
J9 GUT
JI Gut
PD JAN
PY 2019
VL 68
IS 1
BP 94
EP 100
DI 10.1136/gutjnl-2017-314547
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HH4WU
UT WOS:000455727900015
PM 29066576
OA hybrid, Green Published
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Dadkhah, E
   Sikaroodi, M
   Korman, L
   Hardi, R
   Baybick, J
   Hanzel, D
   Kuehn, G
   Kuehn, T
   Gillevet, PM
AF Dadkhah, Ezzat
   Sikaroodi, Masoumeh
   Korman, Louis
   Hardi, Robert
   Baybick, Jeffrey
   Hanzel, David
   Kuehn, Gregory
   Kuehn, Thomas
   Gillevet, Patrick M.
TI Gut microbiome identifies risk for colorectal polyps
SO BMJ OPEN GASTROENTEROLOGY
LA English
DT Article
ID FECAL MICROBIOTA; CANCER; MICROARRAY; SEQUENCES; ADENOMA; SHIFTS
AB Objective To characterise the gut microbiome in subjects with and without polyps and evaluate the potential of the microbiome as a non-invasive biomarker to screen for risk of colorectal cancer (CRC).
   Design Presurgery rectal swab, home collected stool, and sigmoid biopsy samples were obtained from 231 subjects undergoing screening or surveillance colonoscopy. 16S rRNA analysis was performed on 552 samples (231 rectal swab, 183 stool, 138 biopsy) and operational taxonomic units (OTU) were identified using UPARSE. Non-parametric statistical methods were used to identify OTUs that were significantly different between subjects with and without polyps. These informative OTUs were then used to build classifiers to predict the presence of polyps using advanced machine learning models.
   Results We obtained clinical data on 218 subjects (87 females, 131 males) of which 193 were White, 21 African-American, and 4 Asian-American. Colonoscopy detected polyps in 56% of subjects. Modelling of the non-invasive home stool samples resulted in a classification accuracy >75% for Naive Bayes and Neural Network models using informative OTUs. A naive holdout analysis performed on home stool samples resulted in an average false negative rate of 11.5% for the Naive Bayes and Neural Network models, which was reduced to 5% when the two models were combined.
   Conclusion Gut microbiome analysis combined with advanced machine learning represents a promising approach to screen patients for the presence of polyps, with the potential to optimise the use of colonoscopy, reduce morbidity and mortality associated with CRC, and reduce associated healthcare costs.
C1 [Dadkhah, Ezzat; Sikaroodi, Masoumeh; Gillevet, Patrick M.] George Mason Univ, Microbiome Anal Ctr, Manassas, VA 20110 USA.
   [Korman, Louis; Baybick, Jeffrey] Capital Digest Care, Chevy Chase, MD USA.
   [Hardi, Robert] Capitol Res, Bethesda, MD USA.
   [Hanzel, David] Naked Biome, San Francisco, CA USA.
   [Kuehn, Gregory; Kuehn, Thomas] Metabiomics, Aurora, CO USA.
C3 George Mason University
RP Gillevet, PM (通讯作者)，George Mason Univ, Microbiome Anal Ctr, Manassas, VA 20110 USA.
EM pgilleve@gmu.edu
RI Group, Prescott Medical Communications/AAE-7494-2019
OI Gillevet, Patrick/0000-0001-7734-5566
FU Metabiomics
FX Research reported in this publication was supported in part by
   Metabiomics.
CR Acinas SG, 2004, J BACTERIOL, V186, P2629, DOI 10.1128/JB.186.9.2629-2635.2004
   Ahn J, 2013, JNCI-J NATL CANCER I, V105, P1907, DOI 10.1093/jnci/djt300
   American Cancer Society, COL CANC FACTS FIG 2
   [Anonymous], 2016, US PREVENTIVE SERVIC
   Bibbins-Domingo K, 2016, JAMA-J AM MED ASSOC, V315, P2564, DOI 10.1001/jama.2016.5989
   Brim H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081352
   Burns MB, 2015, GENOME MED, V7, DOI 10.1186/s13073-015-0177-8
   Castellarin M, 2012, GENOME RES, V22, P299, DOI 10.1101/gr.126516.111
   Chen WHC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039039
   Demsar J, 2013, J MACH LEARN RES, V14, P2349
   Ding CB, 2018, ONCOTARGETS THER, V11, P4797, DOI 10.2147/OTT.S170626
   Dufrene M, 1997, ECOL MONOGR, V67, P345, DOI 10.1890/0012-9615(1997)067[0345:SAAIST]2.0.CO;2
   Dupuy A, 2007, JNCI-J NATL CANCER I, V99, P147, DOI 10.1093/jnci/djk018
   Edgar RC, 2013, NAT METHODS, V10, P996, DOI [10.1038/NMETH.2604, 10.1038/nmeth.2604]
   Eklof V, 2017, INT J CANCER, V141, P2528, DOI 10.1002/ijc.31011
   Essink-Bot ML, 2016, GASTROENT RES PRACT, V2016, DOI 10.1155/2016/7292369
   Fearon ER, 2011, ANNU REV PATHOL-MECH, V6, P479, DOI 10.1146/annurev-pathol-011110-130235
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Gao R, 2017, EUR J CLIN MICROBIOL, V36, P757, DOI 10.1007/s10096-016-2881-8
   Geng JW, 2013, GUT PATHOG, V5, DOI 10.1186/1757-4749-5-2
   Goedert JJ, 2015, EBIOMEDICINE, V2, P597, DOI 10.1016/j.ebiom.2015.04.010
   Hale VL, 2017, CANCER EPIDEM BIOMAR, V26, P85, DOI 10.1158/1055-9965.EPI-16-0337
   Ju F, 2015, APPL MICROBIOL BIOT, V99, P4119, DOI 10.1007/s00253-015-6536-y
   Knights D, 2011, FEMS MICROBIOL REV, V35, P343, DOI 10.1111/j.1574-6976.2010.00251.x
   Kostic AD, 2012, GENOME RES, V22, P292, DOI 10.1101/gr.126573.111
   Lee GH, 2015, EJSO-EUR J SURG ONC, V41, P300, DOI 10.1016/j.ejso.2014.11.001
   Levin TR, 2018, GASTROENTEROLOGY, V155, P1383, DOI 10.1053/j.gastro.2018.07.017
   Marchesi JR, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020447
   McCoy AN, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053653
   McCune B., 2002, PCORD ANAL ECOLOGICA
   Mira-Pascual L, 2015, J GASTROENTEROL, V50, P167, DOI 10.1007/s00535-014-0963-x
   Nakatsu G, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9727
   Narayanan V, 2014, CANCER PREV RES, V7, P1108, DOI 10.1158/1940-6207.CAPR-14-0273
   Peters BA, 2016, MICROBIOME, V4, DOI 10.1186/s40168-016-0218-6
   Sanapareddy N, 2012, ISME J, V6, P1858, DOI 10.1038/ismej.2012.43
   Schloss PD, 2009, APPL ENVIRON MICROB, V75, P7537, DOI 10.1128/AEM.01541-09
   Schroy PC, 2015, HEALTH EXPECT, V18, P1327, DOI 10.1111/hex.12110
   Segata N, 2011, GENOME BIOL, V12, DOI 10.1186/gb-2011-12-6-r60
   Shen XJ, 2010, GUT MICROBES, V1, P138, DOI 10.4161/gmic.1.3.12360
   Simon R, 2003, J NATL CANCER I, V95, P14, DOI 10.1093/jnci/95.1.14
   Thomas AM, 2016, FRONT CELL INFECT MI, V6, DOI 10.3389/fcimb.2016.00179
   Vogelstein B, 2013, SCIENCE, V339, P1546, DOI 10.1126/science.1235122
   White JR, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000352
   Wisittipanit Nuttachat, 2015, Int J Bioinform Res Appl, V11, P111, DOI 10.1504/IJBRA.2015.068087
   Witten IH, 2011, MOR KAUF D, P3, DOI 10.1016/B978-0-12-374856-0.00001-8
   Wu N, 2013, MICROB ECOL, V66, P462, DOI 10.1007/s00248-013-0245-9
   Xu KH, 2017, MED SCI MONITOR, V23, DOI 10.12659/MSM.904220
   Yoon H, 2017, J CANCER PREV, V22, P108, DOI 10.15430/JCP.2017.22.2.108
   Zackular JP, 2014, CANCER PREV RES, V7, P1112, DOI 10.1158/1940-6207.CAPR-14-0129
   Zeller G, 2014, MOL SYST BIOL, V10, DOI 10.15252/msb.20145645
NR 50
TC 27
Z9 30
U1 0
U2 4
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 2054-4774
J9 BMJ OPEN GASTROENTER
JI BMJ Open Gastroenterol.
PD JAN
PY 2019
VL 6
IS 1
AR e000297
DI 10.1136/bmjgast-2019-000297
PG 10
WC Gastroenterology & Hepatology
WE Emerging Sources Citation Index (ESCI)
SC Gastroenterology & Hepatology
GA IC7DV
UT WOS:000471133700030
PM 31275588
OA Green Published, gold
DA 2023-08-21
ER

PT J
AU Du, WJ
   Rao, NN
   Liu, DY
   Jiang, HX
   Luo, CS
   Li, ZW
   Gan, T
   Zeng, B
AF Du, Wenju
   Rao, Nini
   Liu, Dingyun
   Jiang, Hongxiu
   Luo, Chengsi
   Li, Zhengwen
   Gan, Tao
   Zeng, Bing
TI Review on the Applications of Deep Learning in the Analysis of
   Gastrointestinal Endoscopy Images
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Cancer; Lesions; Image analysis; Endoscopes;
   Gastrointestinal tract; Gastrointestinal disease; gastrointestinal
   endoscopy image; deep learning; analysis; comparison
ID CONVOLUTIONAL NEURAL-NETWORK; HELICOBACTER-PYLORI INFECTION; CAPSULE
   ENDOSCOPY; FEATURE-EXTRACTION; COLORECTAL POLYPS; CANCER; DIAGNOSIS;
   CLASSIFICATION; SEGMENTATION; VALIDATION
AB Gastrointestinal (GI) disease is one of the most common diseases and primarily examined by GI endoscopy. Recently, deep learning (DL), in particular convolutional neural networks (CNNs) have made achievements in GI endoscopy image analysis. This review focuses on the applications of DL methods in the analysis of GI images. We summarized and compared the latest published literature related to the common clinical GI diseases and covers the key applications of DL in GI image detection, classification, segmentation, recognition, location, and other tasks. At the end, we give a discussion on the challenges and the research directions of GI image analysis based on DL in the future.
C1 [Du, Wenju; Rao, Nini; Liu, Dingyun; Luo, Chengsi; Li, Zhengwen] Univ Elect Sci & Technol China, Ctr Informat Biol, Chengdu 610054, Sichuan, Peoples R China.
   [Du, Wenju; Rao, Nini; Liu, Dingyun; Jiang, Hongxiu; Luo, Chengsi; Li, Zhengwen] Univ Elect Sci & Technol China, Ctr Informat Med, Chengdu 610054, Sichuan, Peoples R China.
   [Rao, Nini] UESTC, Inst Elect & Informat Engn, Dongguan 523107, Peoples R China.
   [Gan, Tao] Sichuan Univ, West China Hosp, Digest Endoscop Ctr, Chengdu 610017, Sichuan, Peoples R China.
   [Zeng, Bing] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 610054, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; University of Electronic
   Science & Technology of China; Sichuan University; University of
   Electronic Science & Technology of China
RP Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Ctr Informat Biol, Chengdu 610054, Sichuan, Peoples R China.; Rao, NN (通讯作者)，Univ Elect Sci & Technol China, Ctr Informat Med, Chengdu 610054, Sichuan, Peoples R China.; Rao, NN (通讯作者)，UESTC, Inst Elect & Informat Engn, Dongguan 523107, Peoples R China.; Zeng, B (通讯作者)，Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 610054, Sichuan, Peoples R China.
EM raonn@uestc.edu.cn; eezeng@uestc.edu.cn
RI Jiang, Hongxiu/IZQ-2381-2023
OI Rao, Nini/0000-0001-7979-2917
FU National Natural Science Foundation of China [61872405, 61720106004];
   Key Project of Natural Science Foundation of Guangdong Province
   [2016A030311040]; Sichuan Science and Technology Support Program
   [2015SZ0191]; Fundamental Research Funds for the Central Universities of
   China [ZYGX2016J189]; Scientific Platform Improvement Project of UESTC
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61872405 and Grant 61720106004, in part
   by the Key Project of Natural Science Foundation of Guangdong Province
   under Grant 2016A030311040, in part by the Sichuan Science and
   Technology Support Program under Grant 2015SZ0191, in part by the
   Fundamental Research Funds for the Central Universities of China under
   Grant ZYGX2016J189, and in part by the Scientific Platform Improvement
   Project of UESTC.
CR Andermatt S, 2016, LECT NOTES COMPUT SC, V10008, P142, DOI 10.1007/978-3-319-46976-8_15
   Aoki T, 2019, GASTROINTEST ENDOSC, V89, P357, DOI 10.1016/j.gie.2018.10.027
   Asperti A, 2017, ARXIV171203689, P1
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chandrakar M. K., 2018, J ADV RES DYN CONTRO, V10, P549
   Chen HH, 2017, NEUROCOMPUTING, V229, P77, DOI 10.1016/j.neucom.2016.06.077
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gao XT, 2015, IEEE T BIO-MED ENG, V62, P2693, DOI 10.1109/TBME.2015.2444389
   Ghosh T, 2018, IEEE IMAGE PROC, P3034, DOI 10.1109/ICIP.2018.8451300
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gondos A, 2008, EUR J CANCER, V44, P1463, DOI 10.1016/j.ejca.2008.03.010
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hajabdollahi M, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101565
   He JY, 2018, IEEE T IMAGE PROCESS, V27, P2379, DOI 10.1109/TIP.2018.2801119
   Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2
   Hong JS, 2017, IEEE ENG MED BIO, P2892, DOI 10.1109/EMBC.2017.8037461
   Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Iakovidis DK, 2018, IEEE T MED IMAGING, V37, P2196, DOI 10.1109/TMI.2018.2837002
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Itoh T, 2018, ENDOSC INT OPEN, V6, pE139, DOI 10.1055/s-0043-120830
   Jia X, 2017, IEEE ENG MED BIO, P3154, DOI 10.1109/EMBC.2017.8037526
   Jia X, 2017, I S BIOMED IMAGING, P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karnes WE, 2017, GASTROINTEST ENDOSC, V85, pAB376, DOI 10.1016/j.gie.2017.03.871
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumagai Y, 2019, ESOPHAGUS-TOKYO, V16, P180, DOI 10.1007/s10388-018-0651-7
   Lan LB, 2019, IEEE ACCESS, V7, P30017, DOI 10.1109/ACCESS.2019.2901568
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leenhardt R, 2019, GASTROINTEST ENDOSC, V89, P189, DOI 10.1016/j.gie.2018.06.036
   Li PP, 2017, IEEE INT CON MULTI, P1518, DOI 10.1109/ICME.2017.8019415
   Li YX, 2018, I S BIOMED IMAGING, P182, DOI 10.1109/ISBI.2018.8363550
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu B, 2018, P INT COMP SOFTW APP, P408, DOI 10.1109/COMPSAC.2018.10267
   Liu DY, 2015, J MED IMAG HEALTH IN, V5, P296, DOI 10.1166/jmihi.2015.1390
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Liu DY, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1063-x
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XQ, 2020, NEUROCOMPUTING, V392, P253, DOI 10.1016/j.neucom.2018.10.100
   Liu XQ, 2018, IEEE IMAGE PROC, P1388, DOI 10.1109/ICIP.2018.8451067
   Lo SCB, 1995, IEEE T MED IMAGING, V14, P711, DOI 10.1109/42.476112
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mannath J, 2016, NAT REV GASTRO HEPAT, V13, P720, DOI 10.1038/nrgastro.2016.148
   Nakagawa K, 2019, GASTROINTEST ENDOSC, V90, P407, DOI 10.1016/j.gie.2019.04.245
   Pogorelov K, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P363, DOI 10.1145/3204949.3208128
   Qu J, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8961781
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Rodriguez A, 2017, 2017 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS)
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Segui S, 2016, COMPUT BIOL MED, V79, P163, DOI 10.1016/j.compbiomed.2016.10.011
   Sekuboyina AK, 2017, I S BIOMED IMAGING, P1057, DOI 10.1109/ISBI.2017.7950698
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shichijo S, 2017, EBIOMEDICINE, V25, P106, DOI 10.1016/j.ebiom.2017.10.014
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Shin Y, 2017, IEEE ENG MED BIO, P3277, DOI 10.1109/EMBC.2017.8037556
   Siegel RL, 2020, CA-CANCER J CLIN, V70, P7, DOI [10.3322/caac.20107, 10.3322/caac.21601, 10.3322/caac.21590, 10.3322/caac.21708, 10.3322/caac.20115]
   Simonyan K., 2013, P ICLR
   Sun JY, 2018, COMP MED SY, P351, DOI 10.1109/CBMS.2018.00068
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Take I, 2015, TRANSL GASTROIN CANC, V4, P423, DOI 10.3978/j.issn.2224-4778.2015.09.04
   Tanabe S, 2016, CLIN ENDOSC, V49, P539, DOI 10.5946/ce.2016.004
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   van Riel S, 2018, IEEE IMAGE PROC, P1383, DOI 10.1109/ICIP.2018.8451771
   Washington K, 2010, ANN SURG ONCOL, V17, P3077, DOI 10.1245/s10434-010-1362-z
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Xiao WT, 2018, IEEE INT C ELECTR TA
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185508
   Zhao BY, 2017, SHOCK VIB, V2017, DOI 10.1155/2017/4350437
   Zhou J., 2020, THE OPEN, V1, P57, DOI DOI 10.1016/J.AIOPEN.2021.01.001
   Zhou T, 2017, COMPUT BIOL MED, V85, P1, DOI 10.1016/j.compbiomed.2017.03.031
   Zhu Y, 2019, GASTROINTEST ENDOSC, V89, P806, DOI 10.1016/j.gie.2018.11.011
NR 92
TC 39
Z9 41
U1 3
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 142053
EP 142069
DI 10.1109/ACCESS.2019.2944676
PG 17
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA JN8QJ
UT WOS:000497156000158
OA gold
DA 2023-08-21
ER

PT J
AU Kang, J
   Gwak, J
AF Kang, Jaeyong
   Gwak, Jeonghwan
TI Ensemble of Instance Segmentation Models for Polyp Segmentation in
   Colonoscopy Images
SO IEEE ACCESS
LA English
DT Article
DE Polyp segmentation; transfer learning; medical image analysis; deep
   learning; machine learning; artificial intelligence
ID CONVOLUTIONAL NEURAL-NETWORK; AUTOMATIC SEGMENTATION; DIAGNOSIS;
   VALIDATION
AB Colorectal cancer is the second most frequently diagnosed cancer in women and the third most frequently diagnosed cancer in men. At least 80%-95% of the colorectal cancers are evolved from intestinal polyps. Although colonoscopy is regarded as the most effective method for screening and diagnosis, the success of the procedure is highly dependent on the level of hand-eye coordination and the operator skills. Thus, we are primarily motivated by the need for obtaining an early and accurate diagnosis of polyps in the colonoscopy images. In this paper, we employed the powerful object detection neural network "Mask R-CNN'' to identify and segment polyps in the colonoscopy images. Also, we proposed an ensemble method to combine the two Mask R-CNN models with different backbone structures (ResNet50 and ResNet101) to enhance the performance. Mask R-CNNs in our model were first trained on COCO dataset, and then finely tuned using intestinal polyp dataset since a large number of annotated colonoscopy images are not easily accessible. In order to evaluate our proposed model, we used three open intestinal polyp datasets, CVC-ClinicDB, ETIS-Larib, and CVC-ColonDB. Our results show that our transfer learning-based ensemble model significantly outperforms state-of-the-art methods.
C1 [Kang, Jaeyong; Gwak, Jeonghwan] Seoul Natl Univ Hosp, Biomed Res Inst, Seoul 03080, South Korea.
   [Gwak, Jeonghwan] Seoul Natl Univ Hosp, Dept Radiol, Seoul 03080, South Korea.
   [Gwak, Jeonghwan] Seoul Natl Univ, Coll Med, Dept Radiol, Seoul 03080, South Korea.
C3 Seoul National University (SNU); Seoul National University Hospital;
   Seoul National University (SNU); Seoul National University Hospital;
   Seoul National University (SNU)
RP Gwak, J (通讯作者)，Seoul Natl Univ Hosp, Biomed Res Inst, Seoul 03080, South Korea.; Gwak, J (通讯作者)，Seoul Natl Univ Hosp, Dept Radiol, Seoul 03080, South Korea.; Gwak, J (通讯作者)，Seoul Natl Univ, Coll Med, Dept Radiol, Seoul 03080, South Korea.
EM james.han.gwak@gmail.com
OI Gwak, Jeonghwan/0000-0002-6237-0141
FU National Research Foundation of Korea (NRF), the Ministry of Education
   [NRF-2017R1D1A1B03036423]; NRF, the Ministry of Science, ICT and Future
   Planning (MSIT) [NRF-2016M3C7A1905477, NRF-2019M3C7A1020406];
   Engineering Research Center (ERC) Program of Extreme Exploitation of
   Dark Data through the Korean Government (MSIT) [NRF-2018R1A5A1060031]
FX This work was supported in part by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF), the Ministry of
   Education, under Grant NRF-2017R1D1A1B03036423, in part by the Brain
   Research Program through the NRF, the Ministry of Science, ICT and
   Future Planning (MSIT), under Grant NRF-2016M3C7A1905477 and Grant
   NRF-2019M3C7A1020406, and in part by the Engineering Research Center
   (ERC) Program of Extreme Exploitation of Dark Data through the Korean
   Government (MSIT) under Grant NRF-2018R1A5A1060031.
CR [Anonymous], 2007, IEEE INT C IMAGE PRO, DOI [10.1109/ICIP.2007.4379193, DOI 10.1109/ICIP.2007.4379193]
   [Anonymous], 2018, POLYP SEGMENTATION C
   Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   de Brebisson Alexandre, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P20, DOI 10.1109/CVPRW.2015.7301312
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu X., 2010, P INT C MULT, P451, DOI DOI 10.1145/1873951.1874016
   Hu XT, 2012, IEEE T MULTIMEDIA, V14, P314, DOI 10.1109/TMM.2011.2172201
   Jia YQ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1631, DOI 10.1109/ROBIO.2015.7419005
   Karargyris A, 2009, 2009 IEEE/NIH LIFE SCIENCE SYSTEMS AND APPLICATIONS WORKSHOP, P143, DOI 10.1109/LISSA.2009.4906730
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Nasr-Esfahani E, 2016, IEEE ENG MED BIO, P1373, DOI 10.1109/EMBC.2016.7590963
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Park S., 2015, POLYP DETECTION COLO
   Parkin M. C., 2008, GLOBOCAN 2008 V1 2 C
   Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Roth HR, 2015, PROC SPIE, V9413, DOI 10.1117/12.2081420
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Tulum G, 2017, INT J COMPUT ASS RAD, V12, P627, DOI 10.1007/s11548-017-1521-9
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Vazquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang Z, 2004, PROC SPIE, V5370, P972, DOI 10.1117/12.535664
   Wolterink JM, 2015, LECT NOTES COMPUT SC, V9349, P589, DOI 10.1007/978-3-319-24553-9_72
   Xiang Ji, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3633, DOI 10.1109/ICIP.2011.6116505
   Zhang JL, 2018, GEOPHYS RES LETT, V45, P8665, DOI 10.1029/2018GL077787
   Zhang L, 2017, COMM COM INF SC, V723, P707, DOI 10.1007/978-3-319-60964-5_62
   Zhang YT, 2015, PROC CVPR IEEE, P249, DOI 10.1109/CVPR.2015.7298621
NR 47
TC 65
Z9 66
U1 4
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 26440
EP 26447
DI 10.1109/ACCESS.2019.2900672
PG 8
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA HP3GC
UT WOS:000461563700001
OA gold
DA 2023-08-21
ER

PT J
AU Kim, JW
   Huh, G
   Rhee, CS
   Lee, CH
   Lee, J
   Chung, JH
   Cho, SW
AF Kim, Jeong-Whun
   Huh, Gene
   Rhee, Chae-Seo
   Lee, Chul Hee
   Lee, Jaebong
   Chung, Jin-Hang
   Cho, Sung-Woo
TI Unsupervised cluster analysis of chronic rhinosinusitis with nasal polyp
   using routinely available clinical markers and its implication in
   treatment outcomes
SO INTERNATIONAL FORUM OF ALLERGY & RHINOLOGY
LA English
DT Article
DE cluster analysis; sinusitis; nasal polyps; treatment outcome; clinical
   markers
ID ENDOSCOPIC SINUS SURGERY; PREDICTIVE SIGNIFICANCE; COMPUTED-TOMOGRAPHY;
   TISSUE EOSINOPHILIA; ASTHMA PHENOTYPES; SCORING SYSTEM; REVISION RATES;
   RECURRENCE; ENDOTYPES
AB Background Chronic rhinosinusitis with nasal polyps (CRSwNP) is a multidimensional disease. In this study, we performed an unsupervised cluster analysis of CRSwNP using routinely available clinical markers. Methods We conducted a retrospective review of patients treated with endoscopic sinus surgery due to medically intractable bilateral CRSwNP from 2009 to 2017. Unsupervised cluster analysis was performed using a patient's clinical features, including age, peripheral blood eosinophil, tissue eosinophilia, Lund-Mackay computed tomography (CT) scores, ratio of the CT scores for the ethmoid sinus and maxillary sinus (E/M ratio), and comorbid asthma. Tree analysis was performed to develop a clustering algorithm. Kaplan-Meier survival analysis was performed to determine the revision surgery-free probability corresponding to each cluster. Results Data were available on 375 patients. Patients were categorized into 6 clusters comprising 2 asthmatic clusters and 4 non-asthmatic clusters. The labels for the 2 asthmatic clusters were: asthmatic non-eosinophilic polyp (cluster A1) and asthmatic eosinophilic polyp (cluster A2). The labels for the 4 non-asthmatic clusters were: non-eosinophilic polyp with older age (cluster NA1); non-eosinophilic pol'yp with younger age (cluster NA2); eosinophilic polyp with lower E/M ratio (cluster NA3); and eosinophilic polyp with higher E/M ratio (cluster NA4). The 4-year revision-free rates were 100% (cluster NA1), 80.3% (NA2), 98.0% (NA3), 66.7% (NA4), 100% (A1), and 66.7% (A2). The clusters showed statistically significant differences in terms of 4-year revision-free rates (log-rank p < 0.05). Conclusion Cluster analysis identified 2 asthmatic clusters and 4 non-asthmatic clusters in CRSwNP. Each cluster corresponded to a different clinical outcome.
C1 [Kim, Jeong-Whun; Huh, Gene; Rhee, Chae-Seo; Lee, Chul Hee; Cho, Sung-Woo] Seoul Natl Univ, Coll Med, Bundang Hosp, Dept Otorhinolaryngol Head & Neck Surg, Seongnam, South Korea.
   [Lee, Jaebong] Seoul Natl Univ, Bundang Hosp, Med Res Collaborating Ctr, Seongnam, South Korea.
   [Chung, Jin-Hang] Seoul Natl Univ, Coll Med, Bundang Hosp, Dept Pathol, Seongnam, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU); Seoul
   National University (SNU)
RP Cho, SW (通讯作者)，Seoul Natl Univ, Bundang Hosp, Dept Otorhinolaryngol Head & Neck Surg, 82 Gumi Ro 173th St, Seongnam 13620, Gyeonggi Do, South Korea.
EM iamsungu@gmail.com
RI Lee, Chul Hee/J-5609-2012
CR Ahn JC, 2016, JAMA OTOLARYNGOL, V142, P162, DOI 10.1001/jamaoto.2015.3142
   Akdis CA, 2013, J ALLERGY CLIN IMMUN, V131, P1479, DOI 10.1016/j.jaci.2013.02.036
   [Anonymous], 2010, PASW STAT 18 STAT PR
   [Anonymous], VITAL HLTH STAT
   Bachert C, 2016, J ALLER CL IMM-PRACT, V4, P621, DOI 10.1016/j.jaip.2016.05.004
   Chapurin N, 2017, OTOLARYNG HEAD NECK, V156, P751, DOI 10.1177/0194599817691476
   Cho SW, 2017, ASIA PAC ALLERGY, V7, P121, DOI 10.5415/apallergy.2017.7.3.121
   DeConde AS, 2016, INT FORUM ALLERGY RH, V6, P478, DOI 10.1002/alr.21683
   Fokkens WJ, 2012, RHINOLOGY, V50, P1, DOI 10.4193/Rhin20.600
   Grgic MV, 2015, EUR ARCH OTO-RHINO-L, V272, P3735, DOI 10.1007/s00405-015-3519-7
   Jung H, 2011, KOREAN J LAB MED, V31, P219, DOI 10.3343/kjlm.2011.31.3.219
   Kim DW, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148442
   Kim SY, 2013, AM J RHINOL ALLERGY, V27, pE166, DOI 10.2500/ajra.2013.27.3959
   Lou HF, 2016, RHINOLOGY, V54, P150, DOI [10.4193/Rhino15.271, 10.4193/Rhin15.271]
   Lou HF, 2015, AM J RHINOL ALLERGY, V29, P350, DOI 10.2500/ajra.2015.29.4231
   Lund VJ, 1997, OTOLARYNG HEAD NECK, V117, pS35, DOI 10.1016/S0194-5998(97)70005-6
   Mendelsohn D, 2011, ANN OTO RHINOL LARYN, V120, P162, DOI 10.1177/000348941112000304
   Meng YF, 2016, INT FORUM ALLERGY RH, V6, P812, DOI 10.1002/alr.21749
   Moore WC, 2010, AM J RESP CRIT CARE, V181, P315, DOI 10.1164/rccm.200906-0896OC
   Psaltis AJ, 2014, LARYNGOSCOPE, V124, P2216, DOI 10.1002/lary.24654
   Rich JT, 2010, OTOLARYNG HEAD NECK, V143, P331, DOI 10.1016/j.otohns.2010.05.007
   Smith TL, 2010, OTOLARYNG HEAD NECK, V142, P55, DOI 10.1016/j.otohns.2009.10.009
   Soler ZM, 2010, OTOLARYNG HEAD NECK, V142, P64, DOI 10.1016/j.otohns.2009.10.005
   STAMMBERGER H, 1990, EUR ARCH OTO-RHINO-L, V247, P63
   Stein NR, 2018, LARYNGOSCOPE, V128, P31, DOI 10.1002/lary.26741
   Stewart MG, 2000, OTOLARYNG HEAD NECK, V123, P81, DOI 10.1067/mhn.2000.105922
   Tokunaga T, 2015, ALLERGY, V70, P995, DOI 10.1111/all.12644
   Tomassen P, 2016, J ALLERGY CLIN IMMUN, V137, P1449, DOI 10.1016/j.jaci.2015.12.1324
   Triglia JM, 1997, LARYNGOSCOPE, V107, P963, DOI 10.1097/00005537-199707000-00025
   Veloso-Teles R, 2017, AM J RHINOL ALLERGY, V31, P56, DOI 10.2500/ajra.2017.31.4402
   Wang XD, 2016, J ALLERGY CLIN IMMUN, V138, P1344, DOI 10.1016/j.jaci.2016.05.041
   Weatherall M, 2010, EUR RESPIR J, V36, P472, DOI 10.1183/09031936.00035210
   Wenzel SE, 2012, NAT MED, V18, P716, DOI 10.1038/nm.2678
   Wynn R, 2004, LARYNGOSCOPE, V114, P811, DOI 10.1097/00005537-200405000-00004
   Zinchuk AV, 2018, THORAX, V73, P472, DOI 10.1136/thoraxjnl-2017-210431
NR 35
TC 18
Z9 18
U1 1
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2042-6976
EI 2042-6984
J9 INT FORUM ALLERGY RH
JI Int. Forum Allergy Rhinol.
PD JAN
PY 2019
VL 9
IS 1
BP 79
EP 86
DI 10.1002/alr.22221
PG 8
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology
GA HG2AI
UT WOS:000454763600013
PM 30281956
OA Bronze
DA 2023-08-21
ER

PT J
AU Liu, M
   Jiang, J
   Wang, ZN
AF Liu, Ming
   Jiang, Jue
   Wang, Zenan
TI Colonic Polyp Detection in Endoscopic Videos With Single Shot Detection
   Based Deep Convolutional Neural Network
SO IEEE ACCESS
LA English
DT Article
DE Colonic polyp detection; convolutional neural network; single shot
   detector (SSD)
ID MISS RATE; COLONOSCOPY; VALIDATION
AB A major rise in the prevalence and influence of colorectal cancer (CRC) leads to substantially increasing healthcare costs and even death. It is widely accepted that early detection and removal of colonic polyps can prevent CRC. Detection of colonic polyps in colonoscopy videos is problematic because of complex environment of colon and various shapes of polyps. Currently, researchers indicate feasibility of Convolutional Neural Network (CNN)-based detection of polyps but better feature extractors are needed to improve detection performance. In this paper, we investigated the potential of the single shot detector (SSD) framework for detecting polyps in colonoscopy videos. SSD is a one-stage method, which uses a feed-forward CNN to produce a collection of fixed-size bounding boxes for each object from different feature maps. Three different feature extractors, including ResNet50, VGG16, and InceptionV3 were assessed. Multi-scale feature maps integrated into SSD were designed for ResNet50 and InceptionV3, respectively. We validated this method on the 2015 MICCAI polyp detection challenge datasets, compared it with teams attended the challenge, YOLOV3 and two-stage method, Faster-RCNN. Our results demonstrated that the proposed method surpassed all the teams in MICCAI challenge and YOLOV3 and was comparable with two-stage method. Especially in detection speed aspect, our proposed method outperformed all the methods, met real-time application requirement. Meanwhile, we also indicated that among all the feature extractors, InceptionV3 obtained the best result of precision and recall. In conclusion, SSD- based method achieved excellent detection performance in polyp detection and can potentially improve diagnostic accuracy and efficiency.
C1 [Liu, Ming] Hunan Key Lab Nonferrous Resources & Geol Hazard, Changsha 410083, Hunan, Peoples R China.
   [Jiang, Jue] Mem Sloan Kettering Canc Ctr, Dept Med Phys, New York, NY 10065 USA.
   [Wang, Zenan] Capital Med Univ, Clin Med Coll 3, Beijing Chaoyang Hosp, Dept Gastroenterol, Beijing 100020, Peoples R China.
C3 Memorial Sloan Kettering Cancer Center; Capital Medical University
RP Wang, ZN (通讯作者)，Capital Med Univ, Clin Med Coll 3, Beijing Chaoyang Hosp, Dept Gastroenterol, Beijing 100020, Peoples R China.
EM wangzenan@outlook.com
RI Jiang, Jue/AFN-5623-2022
OI Jiang, Jue/0000-0001-9642-3515
FU Digestive Medical Coordinated Development Center of Beijing Hospitals
   Authority
FX This work was supported by the Digestive Medical Coordinated Development
   Center of Beijing Hospitals Authority, No. XXT12.
CR Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hassan C, 2013, ENDOSCOPY, V45, P842, DOI 10.1055/s-0033-1344548
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Krishnan SM, 1998, P ANN INT IEEE EMBS, V20, P895, DOI 10.1109/IEMBS.1998.745583
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li P, 2005, PROC CVPR IEEE, P670
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ozawa T, 2018, GASTROINTEST ENDOSC, V87, pAB271
   REDMON J, 2016, PROC CVPR IEEE, P779, DOI DOI 10.1109/CVPR.2016.91
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767, DOI 10.1109/CVPR.2017.690]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   van Wijk C, 2010, IEEE T MED IMAGING, V29, P688, DOI 10.1109/TMI.2009.2031323
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang RK, 2018, PATTERN RECOGN, V83, P209, DOI 10.1016/j.patcog.2018.05.026
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
NR 37
TC 37
Z9 38
U1 0
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 75058
EP 75066
DI 10.1109/ACCESS.2019.2921027
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA IE8ZZ
UT WOS:000472664200001
PM 33604228
OA Green Accepted, gold
DA 2023-08-21
ER

PT J
AU Qadir, HA
   Solhusvik, J
   Bergsland, J
   Aabakken, L
   Balasingham, I
AF Qadir, Hemin Ali
   Solhusvik, Johannes
   Bergsland, Jacob
   Aabakken, Lars
   Balasingham, Ilangko
TI A Framework With a Fully Convolutional Neural Network for Semi-Automatic
   Colon Polyp Annotation
SO IEEE ACCESS
LA English
DT Article
DE Image segmentation; Decoding; Feature extraction; Manuals; Convolutional
   neural nets; Training; Colonic polyps; Colonoscopy; polyp segmentation;
   convolutional neural networks; semi-automatic; annotation;
   semi-supervised
ID VALIDATION; FEATURES
AB Deep learning has delivered promising results for automatic polyp detection and segmentation. However, deep learning is known for being data-hungry, and its performance is correlated with the amount of available training data. The lack of large labeled polyp training images is one of the major obstacles in performance improvement of automatic polyp detection and segmentation. Labeling is typically performed by an endoscopist, who performs pixel-level annotation of polyps. Manual polyp labeling of a video sequence is difficult and time-consuming. We propose a semi-automatic annotation framework powered by a convolutional neural network (CNN) to speed up polyp annotation in video-based datasets. Our CNN network requires only ground-truth (manually annotated masks) of a few frames in a video for training and annotating the rest of the frames in a semi-supervised manner. To generate masks similar to the ground-truth masks, we use some pre and post-processing steps such as different data augmentation strategies, morphological operations, Fourier descriptors, and a second stage fine-tuning. We use Fourier coefficients of the ground-truth masks to select similar generated output masks. The results show that it is possible to 1) produce 96 of Dice similarity score between the polyp masks provided by clinicians and the masks generated by our framework, and 2) save clinicians time as they need to manually annotate only a few frames instead of annotating the entire video, frame-by-frame.
C1 [Qadir, Hemin Ali; Bergsland, Jacob; Balasingham, Ilangko] Oslo Univ Hosp OUS, Intervent Ctr, N-0372 Oslo, Norway.
   [Qadir, Hemin Ali] OmniVis Technol Norway AS, N-0349 Oslo, Norway.
   [Qadir, Hemin Ali; Solhusvik, Johannes] Univ Oslo UiO, Dept Informat, N-0373 Oslo, Norway.
   [Aabakken, Lars] Univ Oslo UiO, Fac Med, Dept Transplantat, N-0372 Oslo, Norway.
   [Balasingham, Ilangko] Norwegian Univ Sci & Technol NTNU, Dept Elect Syst, N-7012 Trondheim, Norway.
C3 University of Oslo; University of Oslo; Norwegian University of Science
   & Technology (NTNU)
RP Qadir, HA (通讯作者)，Oslo Univ Hosp OUS, Intervent Ctr, N-0372 Oslo, Norway.; Qadir, HA (通讯作者)，OmniVis Technol Norway AS, N-0349 Oslo, Norway.; Qadir, HA (通讯作者)，Univ Oslo UiO, Dept Informat, N-0373 Oslo, Norway.
EM hqadir2011@my.fit.edu
RI Bergsland, Jacob/H-3966-2016; Balasingham, Ilangko/AGU-7268-2022
OI Balasingham, Ilangko/0000-0001-5259-3221; Bergsland,
   Jacob/0000-0002-3101-4064; Solhusvik, Johannes/0000-0002-4083-5964
FU Research Council of Norway [271542/O30]
FX This work was supported by the Research Council of Norway through the
   Industrial Ph.D. Project under Contract 271542/O30.
CR [Anonymous], 2018, IEEE T NEUR NET LEAR, DOI DOI 10.1109/TNNLS.2017.2727526
   [Anonymous], 2019, IEEE TRANS BIG DATA, DOI DOI 10.1109/TBDATA.2018.2797977
   [Anonymous], 2002, EUR J GASTROEN HEPAT
   [Anonymous], 2018, IEEE ACCESS, DOI DOI 10.1109/ACCESS.2018.2856402
   [Anonymous], 2017, GUT, DOI DOI 10.1136/GUTJNL-2015-310912
   [Anonymous], 2018, NEUROINFORMATICS, DOI DOI 10.1007/S12021-018-9377-X
   [Anonymous], 2012, ENDOSCOPY, DOI DOI 10.1055/S-0031-1291666
   [Anonymous], 2018, PATTERN RECOGN, DOI DOI 10.1016/J.PATCOG.2018.05.026
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.47
   [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.238
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46448-0_5
   [Anonymous], 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00770
   [Anonymous], 1982, COMPUT GRAPH IMAGE P
   [Anonymous], 2017, IEEE T MED IMAG, DOI DOI 10.1109/TMI.2017.2664042
   [Anonymous], 2012, INT J COMPUT VISION, DOI DOI 10.1007/S11263-011-0512-5
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.231
   [Anonymous], 2015, COMPUT MED IMAG GRAP, DOI DOI 10.1016/J.COMPMEDIMAG.2015.02.007
   [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.297
   [Anonymous], 2019, DIAGNOSTICS, DOI DOI 10.3390/DIAGNOSTICS9030099
   [Anonymous], 2015, IEEE T KNOWL DATA EN, DOI DOI 10.1109/TKDE.2013.182
   [Anonymous], 2010, PROC CVPR IEEE
   [Anonymous], 2016, IEEE T MED IMAGING, DOI DOI 10.1109/TMI.2015.2487997
   [Anonymous], 2017, IEEE J BIOMED HEALTH, DOI DOI 10.1109/JBHI.2016.2637004
   [Anonymous], 2014, INT J COMPUT ASS RAD, DOI DOI 10.1007/S11548-013-0926-3
   [Anonymous], 2019, COMP MED SY, DOI DOI 10.1109/CBMS.2019.00047
   [Anonymous], 2012, PATTERN RECOGN, DOI DOI 10.1016/J.PATCOG.2012.03.002
   [Anonymous], 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00255
   [Anonymous], 2019, INT J COMPUT ASS RAD, DOI DOI 10.1007/S11548-018-1864-X
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.87
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2005, P GRAPHICON
   [Anonymous], 2001, 8 IEEE INT C COMP
   [Anonymous], 2017, COMPUTER ASSISTED RO, DOI DOI 10.1007/978-3-319-67543-5_3
   Brandao P., 2017, P SPIE
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   Caelles S., 2017, P IEEE C COMP VIS PA, P221
   Castrejon L., 2017, P IEEE C COMP VIS PA, P5230
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Maninis K., 2017, ARXIV170906031
   Mohammed A., 2018, ARXIV180601907
   Perazzi F., 2017, P IEEE C COMP VIS PA, P2663
   Qadir H. A., IEEE J BIOMED HLTH I
   Qadir H. A., 2019, P 13 INT S MED INF C, P1
   Zhang L., 2017, P ANN C MED IM UND A, P707
   Zhu Y., 2018, P SIGIR
NR 45
TC 12
Z9 12
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 169537
EP 169547
DI 10.1109/ACCESS.2019.2954675
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA NB3ZQ
UT WOS:000560454900024
OA Green Submitted, gold, Green Published
DA 2023-08-21
ER

PT J
AU Sun, MJ
   Zhang, X
   Qu, G
   Zou, MS
   Du, H
   Ma, LY
   Qu, YW
AF Sun, Mingjian
   Zhang, Xiao
   Qu, Ge
   Zou, Mengshu
   Du, Hai
   Ma, Liyong
   Qu, Yawei
TI Automatic Polyp Detection in Colonoscopy Images: Convolutional Neural
   Network, Dataset and Transfer Learning
SO JOURNAL OF MEDICAL IMAGING AND HEALTH INFORMATICS
LA English
DT Article
DE Polyp Detection; Deep Learning; Convolutional Neural Network; Transfer
   Learning
AB Colonoscopy plays an essential role in colorectal cancer prevention and diagnosis. Due to the high miss-rate of colon polyps the application of automated polyp detection technology in clinical is necessary. However, despite researchers made significant progress, automatic polyp detection is still a challenge task. In recent years, deep learning shines in medical image processing and achieved satisfactory result in different kinds of medical images. In this paper, we propose an end-to-end convolutional neural network (CNN) framework to deal with this challenge problem. The whole framework consists of 16 convolutional layers and 6 pooling layers. In order to improve the performance of the proposed method we employ transfer learning algorithm to fine tune the pre-trained model. Several effective tricks in deep learning also adopt to train the network we proposed. Compared with other methods employing traditional algorithms or hand-crafted features, CNN has the ability to reach lower error rate and faster speed. More importantly, we establish a novel colonoscopy dataset to train our neural network. The dataset consists of more than 10 thousand high resolution images which are carefully selected from hospital. We evaluate our classification system using precision, recall and F1 score analysis. The final model obtained 95.2% precision, 97.9% recall and 96.5% F1 score. In addition, we draw receiver operation characteristic (ROC) curve and the area under ROC curve can reach 96.6%. For location task, we employed Intersection over Union (IoU) to evaluate the model and get 0.65 IoU score.
C1 [Sun, Mingjian; Zhang, Xiao; Qu, Ge; Zou, Mengshu; Du, Hai; Ma, Liyong] Harbin Inst Technol, Sch Informat & Elect Engn, Weihai 264209, Shandong, Peoples R China.
   [Qu, Yawei] Harbin Inst Technol, Dept Control Sci & Engn, Harbin 150001, Heilongjiang, Peoples R China.
   [Qu, Yawei] Gen Hosp Chinese Peoples Armed Police Forces, Dept Gastroenterol, Beijing 100000, Peoples R China.
   [Sun, Mingjian; Ma, Liyong] Harbin Inst Technol, Shenzhen Engn Lab Med Intelligent Wireless Ultras, Harbin 518000, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Harbin
   Institute of Technology
RP Ma, LY (通讯作者)，Harbin Inst Technol, Sch Informat & Elect Engn, Weihai 264209, Shandong, Peoples R China.; Qu, YW (通讯作者)，Harbin Inst Technol, Dept Control Sci & Engn, Harbin 150001, Heilongjiang, Peoples R China.; Qu, YW (通讯作者)，Gen Hosp Chinese Peoples Armed Police Forces, Dept Gastroenterol, Beijing 100000, Peoples R China.; Ma, LY (通讯作者)，Harbin Inst Technol, Shenzhen Engn Lab Med Intelligent Wireless Ultras, Harbin 518000, Heilongjiang, Peoples R China.
RI Ma, Liyong/AAE-1074-2020; Ma, Liyong/A-3468-2009
OI Ma, Liyong/0000-0002-9515-7988; Ma, Liyong/0000-0002-0718-379X
FU National Natural Science Foundation of China [11574064]; Natural Science
   Foundation of Shandong Province [ZR2017MF041, ZR2018MF026]; Science and
   Technology Development Plan Project of Shandong Province [2016GGX103032,
   2018GGX103047]; Wego Group [2017011]; Shenzhen Basic Research Program
   [JCYJ201604291153 09834]; Development Plan of Chinese Academy of
   Sciences [2017011]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No. 11574064), Natural Science Foundation of Shandong
   Province (Grant Nos. ZR2017MF041 and ZR2018MF026), the Science and
   Technology Development Plan Project of Shandong Province (Grant Nos.
   2016GGX103032 and 2018GGX103047), Development Plan of Chinese Academy of
   Sciences and Wego Group (Grant No. 2017011), and Shenzhen Basic Research
   Program under grant JCYJ201604291153 09834.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Haggar Fatima A, 2009, Clin Colon Rectal Surg, V22, P191, DOI 10.1055/s-0029-1242458
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Ioffe S., 2015, PROC INT C MACH LEAR, P448, DOI DOI 10.1007/S13398-014-0173-7.2
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin M., 2013, ARXIV E PRINTS
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., 2015, PROC IEEE C COMPUT V, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh N, 2014, I S BIOMED IMAGING, P97, DOI 10.1109/ISBI.2014.6867818
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
NR 23
TC 2
Z9 2
U1 2
U2 31
PU AMER SCIENTIFIC PUBLISHERS
PI VALENCIA
PA 26650 THE OLD RD, STE 208, VALENCIA, CA 91381-0751 USA
SN 2156-7018
EI 2156-7026
J9 J MED IMAG HEALTH IN
JI J. Med. Imaging Health Inform.
PD JAN
PY 2019
VL 9
IS 1
BP 126
EP 133
DI 10.1166/jmihi.2019.2550
PG 8
WC Mathematical & Computational Biology; Radiology, Nuclear Medicine &
   Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology; Radiology, Nuclear Medicine &
   Medical Imaging
GA HI3KH
UT WOS:000456348200020
DA 2023-08-21
ER

PT J
AU Hilsden, RJ
   Heitman, SJ
   Mizrahi, B
   Narod, SA
   Goshen, R
AF Hilsden, Robert J.
   Heitman, Steven J.
   Mizrahi, Barak
   Narod, Steven A.
   Goshen, Ran
TI Prediction of findings at screening colonoscopy using a machine learning
   algorithm based on complete blood counts (ColonFlag)
SO PLOS ONE
LA English
DT Article
ID SOCIETY TASK-FORCE; COLORECTAL-CANCER; RECOMMENDATIONS
AB Adenomatous polyps are a common precursor lesion for colorectal cancer. ColonFlag is a machine-learning-based algorithm that uses basic patient information and complete blood cell counts (CBC) to identify individuals at elevated risk of colorectal cancer for intensified screening. The purpose of this study was to determine whether ColonFlag is also able to predict the presence of high risk adenomatous polyps at colonoscopy. This study was conducted at a large colon cancer screening center in Calgary, Alberta. The study population included asymptomatic individuals between the ages of 50 and 75 who underwent a screening colonoscopy between January 2013 and June 2015. All subjects had at least one CBC result within the year prior to colonoscopy. Based on age, sex, red blood cell parameters, inflammatory cells and platelets, the ColonFlag algorithm generated a score from 0 to 100. We compared the ability of the ColonFlag test result to discriminate between individuals who were found to have a high risk polyp and those with a normal colonoscopy. Among the 17,676 individuals who underwent a screening colonoscopy there were 1,014 found to have a high risk precancerous lesion (5.7%) and 60 were found to have colorectal cancer (0.3%). At a specificity of 95%, the odds ratio for a positive ColonFlag was 2.0 for those with an advanced precancerous lesion compared with those with a normal colonoscopy. The odds ratio did not vary according to patient subgroup, colorectal cancer location or stage. ColonFlag is a passive test that can use routine blood test results to help identify individuals at elevated risk for high risk precancerous polyps as well as frank colorectal cancer. These individuals may be targeted in an effort to achieve greater compliance with conventional screening tests.
C1 [Hilsden, Robert J.; Heitman, Steven J.] Univ Calgary, Cumming Sch Med, Dept Med, Calgary, AB, Canada.
   [Hilsden, Robert J.; Heitman, Steven J.] Univ Calgary, Cumming Sch Med, Dept Community Hlth Sci, Calgary, AB, Canada.
   [Mizrahi, Barak] Medial Canc Res, Kfar Malal, Israel.
   [Narod, Steven A.] Womens Coll Hosp, Womens Coll Res Inst, Familial Breast Canc Res Unit, Toronto, ON, Canada.
   [Narod, Steven A.] Univ Toronto, Dalla Lana Sch Publ Hlth, Toronto, ON, Canada.
   [Goshen, Ran] Medial Early Sign, Kfar Malal, Israel.
C3 University of Calgary; University of Calgary; University of Toronto;
   Womens College Hospital; University of Toronto
RP Hilsden, RJ (通讯作者)，Univ Calgary, Cumming Sch Med, Dept Med, Calgary, AB, Canada.; Hilsden, RJ (通讯作者)，Univ Calgary, Cumming Sch Med, Dept Community Hlth Sci, Calgary, AB, Canada.
EM rhilsden@ucalgary.ca
RI Narod, Steven A/AAA-6112-2022
OI Hilsden, Robert/0000-0003-1545-1093
FU Medial Early Sign Inc., Kfar Malal, Israel
FX This research was funded by a contract to the University of Calgary from
   Medial Early Sign Inc., Kfar Malal, Israel. RG, EC, DW, BM and RY are
   employees of Medial EarlySign, Inc and were involved in the study
   concept, development of the research protocol, statistical analysis and
   writing of the manuscript.
CR Altobelli E, 2014, PREV MED, V62, P132, DOI 10.1016/j.ypmed.2014.02.010
   [Anonymous], 2010, AJCC CANC STAGING HD, V7
   Atkinson TM, 2015, J BEHAV MED, V38, P837, DOI 10.1007/s10865-015-9668-8
   Canadian Task Force Preventive Hlt, 2016, CAN MED ASSOC J, V188, P340, DOI 10.1503/cmaj.151125
   Driman DK, 2012, CAN J PATHOL, V4, P81
   Goshen R, 2017, BRIT J CANCER, V116, P944, DOI 10.1038/bjc.2017.53
   Hornbrook MC, 2017, DIGEST DIS SCI, V62, P2719, DOI 10.1007/s10620-017-4722-8
   Kinar Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171759
   Kinar Y, 2016, J AM MED INFORM ASSN, V23, P879, DOI 10.1093/jamia/ocv195
   Klabunde C, 2015, J MED SCREEN, V22, P119, DOI 10.1177/0969141315584694
   Ma GK, 2014, CLIN GASTROENTEROL H, V12, P1624, DOI 10.1016/j.cgh.2014.01.042
   Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174
   Rex DK, 2012, AM J GASTROENTEROL, V107, P1315, DOI 10.1038/ajg.2012.161
   Ritvo PG, 2015, CANCER EPIDEM BIOMAR, V24, P506, DOI 10.1158/1055-9965.EPI-14-0744
   Robertson DJ, 2017, GASTROINTEST ENDOSC, V85, P2, DOI 10.1016/j.gie.2016.09.025
   White A, 2017, MMWR-MORBID MORTAL W, V66, P1, DOI 10.15585/mmwr.mm6608a1
NR 16
TC 12
Z9 12
U1 0
U2 4
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD NOV 27
PY 2018
VL 13
IS 11
AR e0207848
DI 10.1371/journal.pone.0207848
PG 9
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA HB9UV
UT WOS:000451440000025
PM 30481208
OA Green Submitted, Green Published, gold
DA 2023-08-21
ER

PT J
AU Shin, Y
   Balasingham, I
AF Shin, Younghak
   Balasingham, Ilangko
TI Automatic polyp frame screening using patch based combined feature and
   dictionary learning
SO COMPUTERIZED MEDICAL IMAGING AND GRAPHICS
LA English
DT Article
DE Colonoscopy; Computer-aided detection; Shape and color feature;
   Dictionary learning; Polyp classification; Sparse coding
ID SPARSE; COLONOSCOPY; CLASSIFICATION; VALIDATION; DIAGNOSIS
AB Polyps in the colon can potentially become malignant cancer tissues where early detection and removal lead to high survival rate. Certain types of polyps can be difficult to detect even for highly trained physicians. Inspired by aforementioned problem our study aims to improve the human detection performance by developing an automatic polyp screening framework as a decision support tool. We use a small image patch based combined feature method. Features include shape and color information and are extracted using histogram of oriented gradient and hue histogram methods. Dictionary learning based training is used to learn features and final feature vector is formed using sparse coding. For classification, we use patch image classification based on linear support vector machine and whole image thresholding. The proposed framework is evaluated using three public polyp databases. Our experimental results show that the proposed scheme successfully classified polyps and normal images with over 95% of classification accuracy, sensitivity, specificity and precision. In addition, we compare performance of the proposed scheme with conventional feature based methods and the convolutional neural network (CNN) based deep learning approach which is the state of the art technique in many image classification applications. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Shin, Younghak] Norwegian Univ Sci & Technol NTNU, Dept Elect Syst, Trondheim, Norway.
   [Balasingham, Ilangko] Oslo Univ Hosp, Intervent Ctr, NO-0027 Oslo, Norway.
   [Balasingham, Ilangko] Univ Oslo, Inst Clin Med, Oslo, Norway.
   [Balasingham, Ilangko] Norwegian Univ Sci & Technol NTNU, Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU); University of Oslo;
   University of Oslo; Norwegian University of Science & Technology (NTNU)
RP Shin, Y (通讯作者)，Norwegian Univ Sci & Technol NTNU, Dept Elect Syst, Trondheim, Norway.
EM shinyh0919@gmail.com; ilangkob@medisin.uio.no
RI Balasingham, Ilangko/AGU-7268-2022
FU European Research Consortium for Informatics and Mathematics (ERCIM)
   'Alain Bensoussan' Fellowship Programme; Research Council of Norway
   through the MELODY project [225885/O70]
FX This work was supported by the European Research Consortium for
   Informatics and Mathematics (ERCIM) 'Alain Bensoussan' Fellowship
   Programme and Research Council of Norway through the MELODY project
   under the contract number 225885/O70.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], 7 INT C ADV ROB ICAR
   [Anonymous], 2007, P 24 INT C MACH LEAR
   [Anonymous], CA CANCER J CLIN, DOI [10.3322/CAAC.21254, DOI 10.3322/caac.21254]
   [Anonymous], P IEEE CHIN SUMM INT
   [Anonymous], 2006, FAST SOLUTION L1 NOR
   [Anonymous], INT S INT SIGN PROC
   [Anonymous], HOMOTOPY L
   [Anonymous], P IEEE INT C IM PROC
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Chen Yingju, 2012, Diagn Ther Endosc, V2012, P418037, DOI 10.1155/2012/418037
   Condessa F. J., 2011, DETECTION CLASSIFICA
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Ghosh T, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P354, DOI 10.1109/ICCITechn.2014.7073100
   Hajian-Tilaki K, 2013, CASP J INTERN MED, V4, P627
   Hashem HF, 2009, NAT RADIO SCI CO, P918
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lieberman D, 2005, GASTROINTEST ENDOSC, V61, P392, DOI 10.1016/S0016-5107(05)00133-1
   Liu MZ, 2011, LECT NOTES COMPUT SC, V6893, P41, DOI 10.1007/978-3-642-23626-6_6
   Mairal J., 2009, ICML, P1
   Mallat S, 1998, WAVELET TOUR SIGNAL
   Paclik P, 2000, PATTERN RECOGN LETT, V21, P1165, DOI 10.1016/S0167-8655(00)00078-7
   Park S., 2015, POLYP DETECTION COLO
   Park S. Y., 2016, SPIE MED IMAGING
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P1186, DOI 10.1016/S0002-9270(03)00183-7
   Shin Y, 2016, IEEE ENG MED BIO, P223, DOI 10.1109/EMBC.2016.7590680
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
NR 47
TC 21
Z9 21
U1 2
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-6111
EI 1879-0771
J9 COMPUT MED IMAG GRAP
JI Comput. Med. Imaging Graph.
PD NOV
PY 2018
VL 69
BP 33
EP 42
DI 10.1016/j.compmedimag.2018.08.001
PG 10
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Radiology, Nuclear Medicine & Medical Imaging
GA GX2VS
UT WOS:000447578800004
PM 30172091
DA 2023-08-21
ER

PT J
AU Wimmer, G
   Gadermayr, M
   Kwitt, R
   Hafner, M
   Tamaki, T
   Yoshida, S
   Tanaka, S
   Merhof, D
   Uhl, A
AF Wimmer, Georg
   Gadermayr, Michael
   Kwitt, Roland
   Haefner, Michael
   Tamaki, Toru
   Yoshida, Shigeto
   Tanaka, Shinji
   Merhof, Dorit
   Uhl, Andreas
TI Training of polyp staging systems using mixed imaging modalities
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp staging; Narrow-band imaging; Chromoscopy; Endoscopy; I-scan;
   Computer-assisted diagnosis
ID PIT-PATTERN; CLASSIFICATION; COLONOSCOPY; ENDOSCOPY; FEATURES
AB Background: In medical image data sets, the number of images is usually quite small. The small number of training samples does not allow to properly train classifiers which leads to massive overfitting to the training data. In this work, we investigate whether increasing the number of training samples by merging datasets from different imaging modalities can be effectively applied to improve predictive performance. Further, we investigate if the extracted features from the employed image representations differ between different imaging modalities and if domain adaption helps to overcome these differences.
   Method: We employ twelve feature extraction methods to differentiate between non-neoplastic and neoplastic lesions. Experiments are performed using four different classifier training strategies, each with a different combination of training data. The specifically designed setup for these experiments enables a fair comparison between the four training strategies.
   Results: Combining high definition with high magnification training data and chromoscopic with non-chromoscopic training data partly improved the results. The usage of domain adaptation has only a small effect on the results compared to just using non-adapted training data.
   Conclusion: Merging datasets from different imaging modalities turned out to be partially beneficial for the case of combining high definition endoscopic data with high magnification endoscopic data and for combining chromoscopic with non-chromoscopic data. NBI and chromoendoscopy on the other hand are mostly too different with respect to the extracted features to combine images of these two modalities for classifier training.
C1 [Wimmer, Georg; Kwitt, Roland; Uhl, Andreas] Univ Salzburg, Dept Comp Sci, Jakob Haringerstr 2, A-5020 Salzburg, Austria.
   [Gadermayr, Michael; Merhof, Dorit] Rhein Westfal TH Aachen, Templergraben 55, D-52056 Aachen, Germany.
   [Haefner, Michael] St Elizabeth Hosp, Landstrasser Hauptstr 4a, A-1030 Vienna, Austria.
   [Tamaki, Toru; Yoshida, Shigeto; Tanaka, Shinji] Hiroshima Univ, 1-4-1 Kagamiyama, Hiroshima 7398527, Japan.
C3 Salzburg University; RWTH Aachen University; Hiroshima University
RP Wimmer, G (通讯作者)，Univ Salzburg, Dept Comp Sci, Jakob Haringerstr 2, A-5020 Salzburg, Austria.
EM gwimmer@cosy.sbg.ac.at; uhl@cosy.sbg.ac.at
RI Kwitt, Roland/AFS-8639-2022; Kwitt, Roland/HII-6060-2022; Tamaki,
   Toru/D-7091-2011; Merhof, Dorit/AAV-7892-2021
OI Tamaki, Toru/0000-0001-9712-7777; , Michael/0000-0003-1450-9222
FU Austrian Science Fund, TRP Project [206]
FX This work was supported by the Austrian Science Fund, TRP Project 206.
CR Chatfield K., 2014, BRIT MACH VIS C BMVC
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gono K, 2003, OPT REV, V10, P211, DOI 10.1007/s10043-003-0211-8
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Gross S., 2012, P SOC PHOTO-OPT INS, V8315
   Hafner M, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P365, DOI 10.1007/978-3-662-46224-9_63
   Hafner M, 2012, COMPUT METH PROG BIO, V107, P565, DOI 10.1016/j.cmpb.2011.12.012
   Hafner M, 2012, MED IMAGE ANAL, V16, P75, DOI 10.1016/j.media.2011.05.006
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   Hafner Michael, 2014, Medical Computer Vision Large Data in Medical Imaging. Third International MICCAI Workshop, MCV 2013. Revised Selected Papers. LNCS: 8331, P205, DOI 10.1007/978-3-319-05530-5_20
   Hafner M., 2014, P IEEE INT C IM PROC
   Hafner M., 2014, P 22 INT C PATT REC, P2734
   Kato S, 2006, WORLD J GASTROENTERO, V12, P1416, DOI 10.3748/wjg.v12.i9.1416
   Kiesslich R., 2009, EUR GASTROENTEROL HE, V5, P22
   Kodashima S, 2010, WORLD J GASTROENTERO, V16, P1043, DOI 10.3748/wjg.v16.i9.1043
   KUDO S, 1994, J CLIN PATHOL, V47, P880, DOI 10.1136/jcp.47.10.880
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liedigruber M., 2012, IEEE REV BIOMEDICAL, V4, P73
   Ribeiro E., 2016, COMPUT MATH METHOD M, V2016, P16, DOI DOI 10.1155/2016/6584725.ARTICLE
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Wimmer G, 2016, P 3 INT WORKSH COMP, P59, DOI [10.1007/978-3-319-54057-3_6, DOI 10.1007/978-3-319-54057-3_6]
   Wimmer G, 2016, MED IMAGE ANAL, V31, P16, DOI 10.1016/j.media.2016.02.001
   Yan K., 2016, CORR
NR 24
TC 2
Z9 2
U1 0
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD NOV 1
PY 2018
VL 102
BP 251
EP 259
DI 10.1016/j.compbiomed.2018.05.003
PG 9
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA HA0IR
UT WOS:000449892200028
PM 29773226
DA 2023-08-21
ER

PT J
AU Zhang, RK
   Zheng, YL
   Poon, CCY
   Shen, DG
   Lau, JYW
AF Zhang, Ruikai
   Zheng, Yali
   Poon, Carmen C. Y.
   Shen, Dinggang
   Lau, James Y. W.
TI Polyp detection during colonoscopy using a regression-based
   convolutional neural network with a tracker
SO PATTERN RECOGNITION
LA English
DT Article
DE Smart cancer screening; Therapeutic endoscopy; Endoscopic Informatics;
   Body Sensor Network; Deep Learning; Health Informatics
ID MOLECULAR PATHOLOGICAL EPIDEMIOLOGY; MISS RATE; COLORECTAL-CANCER;
   CLASSIFICATION; PATHWAYS; CAPSULE
AB A computer-aided detection (CAD) tool for locating and detecting polyps can help reduce the chance of missing polyps during colonoscopy. Nevertheless, state-of-the-art algorithms were either computationally complex or suffered from low sensitivity and therefore unsuitable to be used in real clinical setting. In this paper, a novel regression-based Convolutional Neural Network (CNN) pipeline is presented for polyp detection during colonoscopy. The proposed pipeline was constructed in two parts: 1) to learn the spatial features of colorectal polyps, a fast object detection algorithm named ResYOLO was pre-trained with a large non-medical image database and further fine-tuned with colonoscopic images extracted from videos; and 2) temporal information was incorporated via a tracker named Efficient Convolution Operators (ECO) for refining the detection results given by ResYOLO. Evaluated on 17,574 frames extracted from 18 endoscopic videos of the AsuMayoDB, the proposed method was able to detect frames with polyps with a precision of 88.6%, recall of 71.6% and processing speed of 6.5 frames per second, i.e. the method can accurately locate polyps in more frames and at a faster speed compared to existing methods. In conclusion, the proposed method has great potential to be used to assist endoscopists in tracking polyps during colonoscopy. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Zhang, Ruikai; Zheng, Yali; Poon, Carmen C. Y.; Lau, James Y. W.] Chinese Univ Hong Kong, Dept Surg, Hong Kong, Hong Kong, Peoples R China.
   [Shen, Dinggang] Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA.
   [Shen, Dinggang] Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA.
   [Shen, Dinggang] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea.
C3 Chinese University of Hong Kong; University of North Carolina;
   University of North Carolina Chapel Hill; University of North Carolina;
   University of North Carolina Chapel Hill; Korea University
RP Poon, CCY (通讯作者)，Chinese Univ Hong Kong, Dept Surg, Hong Kong, Hong Kong, Peoples R China.; Shen, DG (通讯作者)，Univ N Carolina, Dept Radiol, Chapel Hill, NC 27599 USA.; Shen, DG (通讯作者)，Univ N Carolina, BRIC, Chapel Hill, NC 27599 USA.
EM rzhang@surgery.cuhk.edu.hk; ylzheng@surgery.cuhk.edu.hk;
   cpoon@surgery.cuhk.edu.hk; dgshen@med.unc.edu;
   laujyw@surgery.cuhk.edu.hk
RI Lau, James Y. W./O-2612-2016; Zhang, Ruikai/W-9848-2019; Shen,
   Dinggang/ABF-6812-2020; Poon, Carmen C. Y./B-4616-2011; Zhang,
   Ruikai/W-9847-2019
OI Lau, James Y. W./0000-0003-0122-4068; Zhang, Ruikai/0000-0001-8929-628X;
   Shen, Dinggang/0000-0002-7934-5698; Poon, Carmen C.
   Y./0000-0001-7717-4752; 
FU General Research Fund [GRF/14202417]; Innovation and Technology Fund
   [ITF/337/16FP]
FX This project is supported in part by General Research Fund
   (GRF/14202417) and Innovation and Technology Fund (ITF/337/16FP).
CR Afridi MJ, 2018, PATTERN RECOGN, V73, P65, DOI 10.1016/j.patcog.2017.07.019
   [Anonymous], 2016, NAT METHODS, DOI DOI 10.1038/nmeth.3707
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bishehsari F, 2014, WORLD J GASTROENTERO, V20, P6055, DOI 10.3748/wjg.v20.i20.6055
   Colussi D, 2013, INT J MOL SCI, V14, P16365, DOI 10.3390/ijms140816365
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210
   Hafner M, 2009, PATTERN RECOGN, V42, P1180, DOI 10.1016/j.patcog.2008.07.012
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Jiao ZC, 2018, PATTERN RECOGN, V75, P292, DOI 10.1016/j.patcog.2017.07.008
   Kaminski MF, 2012, ENDOSCOPY, V44, P695, DOI 10.1055/s-0032-1306895
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Leung BHK, 2017, IEEE T BIO-MED ENG, V64, P1106, DOI 10.1109/TBME.2016.2591060
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Ogino S, 2016, EPIDEMIOLOGY, V27, P602, DOI 10.1097/EDE.0000000000000471
   Ogino S, 2011, GUT, V60, P397, DOI 10.1136/gut.2010.217182
   Park S., 2015, POLYP DETECTION COLO
   Park S. Y., 2016, MED IMAGING 2016 COP
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Yuan ZJ, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254671
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
NR 38
TC 93
Z9 97
U1 1
U2 76
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD NOV
PY 2018
VL 83
BP 209
EP 219
DI 10.1016/j.patcog.2018.05.026
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GR0BL
UT WOS:000442172200016
PM 31105338
OA Green Accepted
DA 2023-08-21
ER

PT J
AU Urban, G
   Tripathi, P
   Alkayali, T
   Mittal, M
   Jalali, F
   Karnes, W
   Baldi, P
AF Urban, Gregor
   Tripathi, Priyam
   Alkayali, Talal
   Mittal, Mohit
   Jalali, Farid
   Karnes, William
   Baldi, Pierre
TI Deep Learning Localizes and Identifies Polyps in Real Time With 96%
   Accuracy in Screening Colonoscopy
SO GASTROENTEROLOGY
LA English
DT Article
DE Machine Learning; Convolutional Neural Networks; Colorectal Cancer
   Prevention; Adenoma Detection Rate Improving Technology
ID COLORECTAL-CANCER; ADENOMA DETECTION; NEURAL-NETWORKS; CLASSIFICATION;
   PREVENTION; GO
AB BACKGROUND & AIMS: The benefit of colonoscopy for colorectal cancer prevention depends on the adenoma detection rate (ADR). The ADR should reflect the adenoma prevalence rate, which is estimated to be higher than 50% in the screening-age population. However, the ADR by colonoscopists varies from 7% to 53%. It is estimated that every 1% increase in ADR lowers the risk of interval colorectal cancers by 3%-6%. New strategies are needed to increase the ADR during colonoscopy. We tested the ability of computer-assisted image analysis using convolutional neural networks (CNNs; a deep learning model for image analysis) to improve polyp detection, a surrogate of ADR. METHODS: We designed and trained deep CNNs to detect polyps using a diverse and representative set of 8,641 hand-labeled images from screening colonoscopies collected from more than 2000 patients. We tested the models on 20 colonoscopy videos with a total duration of 5 hours. Expert colonoscopists were asked to identify all polyps in 9 de-identified colonoscopy videos, which were selected from archived video studies, with or without benefit of the CNN overlay. Their findings were compared with those of the CNN using CNN-assisted expert review as the reference. RESULTS: When tested on manually labeled images, the CNN identified polyps with an area under the receiver operating characteristic curve of 0.991 and an accuracy of 96.4%. In the analysis of colonoscopy videos in which 28 polyps were removed, 4 expert reviewers identified 8 additional polyps without CNN assistance that had not been removed and identified an additional 17 polyps with CNN assistance (45 in total). All polyps removed and identified by expert review were detected by the CNN. The CNN had a false-positive rate of 7%. CONCLUSION: In a set of 8,641 colonoscopy images containing 4,088 unique polyps, the CNN identified polyps with a cross-validation accuracy of 96.4% and an area under the receiver operating characteristic curve of 0.991. The CNN system detected and localized polyps well within real-time constraints using an ordinary desktop machine with a contemporary graphics processing unit. This system could increase the ADR and decrease interval colorectal cancers but requires validation in large multicenter trials.
C1 [Urban, Gregor; Baldi, Pierre] Univ Calif Irvine, Dept Comp Sci, Irvine, CA USA.
   [Urban, Gregor; Baldi, Pierre] Univ Calif Irvine, Inst Genom & Bioinformat, Irvine, CA USA.
   [Baldi, Pierre] Univ Calif Irvine, Ctr Machine Learning & Intelligent Syst, Irvine, CA USA.
   [Tripathi, Priyam; Alkayali, Talal; Mittal, Mohit; Jalali, Farid; Karnes, William] Univ Calif Irvine, Dept Med, Irvine, CA 92717 USA.
   [Alkayali, Talal; Jalali, Farid; Karnes, William] Univ Calif Irvine, HH Chao Comprehens Digest Dis Ctr, Irvine, CA USA.
C3 University of California System; University of California Irvine;
   University of California System; University of California Irvine;
   University of California System; University of California Irvine;
   University of California System; University of California Irvine;
   University of California System; University of California Irvine
RP Baldi, P (通讯作者)，Univ Calif Irvine, 4038 Bren Hall, Irvine, CA 92697 USA.
EM pfbaldi@uci.edu
OI Alkayali, Talal/0000-0003-1802-8215; Karnes, William/0000-0002-6225-9080
FU NIH [GM123558]; NSF [IIS-1550705]
FX Supported in part by grants NIH GM123558 and NSF IIS-1550705 to PB.
CR Abadi M., 2016, CORR ABS160304467
   American Cancer Society, 2016, CANC FACTS FIG
   Anderson JC, 2015, CLIN TRANSL GASTROEN, V6, DOI 10.1038/ctg.2015.5
   Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412
   BALDI P, 1993, NEURAL COMPUT, V5, P402, DOI 10.1162/neco.1993.5.3.402
   Baldi P, 2018, ANNU REV BIOMED DA S, V1, P181, DOI 10.1146/annurev-biodatasci-080917-013343
   Baldi P, 2014, ARTIF INTELL, V210, P78, DOI 10.1016/j.artint.2014.02.004
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bond A, 2015, WORLD J GASTRO ENDOS, V7, P969, DOI 10.4253/wjge.v7.i10.969
   Chang P, 2018, AM J NEURORADIOL, V39, P1201, DOI 10.3174/ajnr.A5667
   Chatfield K., 2014, ARXIV14053531
   Chollet F., 2015, KERAS PROBABILISTIC
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Di Lena P, 2012, BIOINFORMATICS, V28, P2449, DOI 10.1093/bioinformatics/bts475
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fooshee D, 2018, MOL SYST DES ENG, V3, P442, DOI 10.1039/c7me00107j
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hassan C, 2017, GUT, V66, P1949, DOI 10.1136/gutjnl-2016-311906
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton GE, ARXIV201212070580
   Ioffe S, ARXIV201515020316
   Kaminski MF, 2017, GASTROENTEROLOGY, V153, P98, DOI 10.1053/j.gastro.2017.04.006
   Kingma D., 2015, ARXIV
   Kuntz KM, 2011, MED DECIS MAKING, V31, P530, DOI 10.1177/0272989X11408730
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Park SY, 2016, SPIE MED IMAGING
   Patel SG, 2014, CLIN GASTROENTEROL H, V12, P7, DOI 10.1016/j.cgh.2013.04.027
   Pohl H, 2010, CLIN GASTROENTEROL H, V8, P858, DOI 10.1016/j.cgh.2010.06.028
   REDMON J, 2016, PROC CVPR IEEE, P779, DOI DOI 10.1109/CVPR.2016.91
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shimmin C, 2017, PHYS REV D, V96, DOI 10.1103/PhysRevD.96.074034
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Soetikno R, 2006, GASTROENTEROLOGY, V130, P566, DOI 10.1053/j.gastro.2005.12.006
   Strum WB, 2016, NEW ENGL J MED, V374, P1065, DOI [10.1056/NEJMra1513581, 10.1056/NEJMc1604867]
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Than M, 2015, ANN GASTROENTEROL, V28, P94
   Waldmann E, 2015, SURG ENDOSC, V29, P466, DOI 10.1007/s00464-014-3688-2
   Wang J, 2017, IEEE T MED IMAGING, V36, P1172, DOI 10.1109/TMI.2017.2655486
   Wang J, 2017, COMPUT BIOL MED, V84, P137, DOI 10.1016/j.compbiomed.2017.03.024
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Wu L, 2008, NEURAL NETWORKS, V21, P1392, DOI 10.1016/j.neunet.2008.02.002
   Wu Y, ARXIV201616090814
NR 49
TC 357
Z9 373
U1 9
U2 74
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD OCT
PY 2018
VL 155
IS 4
BP 1069
EP +
DI 10.1053/j.gastro.2018.06.037
PG 18
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA GV7RI
UT WOS:000446327500033
PM 29928897
OA Green Accepted, Bronze
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Wang, P
   Xiao, X
   Brown, JRG
   Berzin, TM
   Tu, MT
   Xiong, F
   Hu, X
   Liu, PX
   Song, Y
   Zhang, D
   Yang, X
   Li, LP
   He, J
   Yi, X
   Liu, JJ
   Liu, XG
AF Wang, Pu
   Xiao, Xiao
   Brown, Jeremy R. Glissen
   Berzin, Tyler M.
   Tu, Mengtian
   Xiong, Fei
   Hu, Xiao
   Liu, Peixi
   Song, Yan
   Zhang, Di
   Yang, Xue
   Li, Liangping
   He, Jiong
   Yi, Xin
   Liu, Jingjia
   Liu, Xiaogang
TI Development and validation of a deep-learning algorithm for the
   detection of polyps during colonoscopy
SO NATURE BIOMEDICAL ENGINEERING
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; COLORECTAL-CANCER; MISS RATE; CLASSIFICATION;
   PARTICIPATION; POLYPECTOMY; MULTICENTER; GUIDELINES; INCREASES;
   HISTOLOGY
AB The detection and removal of precancerous polyps via colonoscopy is the gold standard for the prevention of colon cancer. However, the detection rate of adenomatous polyps can vary significantly among endoscopists. Here, we show that a machine-learning algorithm can detect polyps in clinical colonoscopies, in real time and with high sensitivity and specificity. We developed the deep-learning algorithm by using data from 1,290 patients, and validated it on newly collected 27,113 colonoscopy images from 1,138 patients with at least one detected polyp (per-image-sensitivity, 94.38%; per-image-specificity, 95.92%; area under the receiver operating characteristic curve, 0.984), on a public database of 612 polyp-containing images (per-image-sensitivity, 88.24%), on 138 colonoscopy videos with histologically confirmed polyps (per-image-sensitivity of 91.64%; per-polyp-sensitivity, 100%), and on 54 unaltered full-range colonoscopy videos without polyps (per-image-specificity, 95.40%). By using a multi-threaded processing system, the algorithm can process at least 25 frames per second with a latency of 76.80 +/- 5.60 ms in real-time video analysis. The software may aid endoscopists while performing colonoscopies, and help assess differences in polyp and adenoma detection performance among endoscopists.
C1 [Wang, Pu; Tu, Mengtian; Xiong, Fei; Hu, Xiao; Liu, Peixi; Song, Yan; Zhang, Di; Yang, Xue; Li, Liangping; Liu, Xiaogang] Sichuan Acad Med Sci, Chengdu, Sichuan, Peoples R China.
   [Wang, Pu; Tu, Mengtian; Xiong, Fei; Hu, Xiao; Liu, Peixi; Song, Yan; Zhang, Di; Yang, Xue; Li, Liangping; Liu, Xiaogang] Sichuan Prov Peoples Hosp, Chengdu, Sichuan, Peoples R China.
   [Xiao, Xiao; He, Jiong; Yi, Xin; Liu, Jingjia] Shanghai Wision Al Co Ltd, Shanghai, Peoples R China.
   [Brown, Jeremy R. Glissen; Berzin, Tyler M.] Beth Israel Deaconess Med Ctr, Boston, MA 02215 USA.
   [Brown, Jeremy R. Glissen; Berzin, Tyler M.] Harvard Med Sch, Ctr Adv Endoscopy, Boston, MA USA.
C3 Sichuan Provincial People's Hospital; Sichuan Provincial People's
   Hospital; Harvard University; Beth Israel Deaconess Medical Center;
   Harvard University; Harvard Medical School
RP Liu, XG (通讯作者)，Sichuan Acad Med Sci, Chengdu, Sichuan, Peoples R China.; Liu, XG (通讯作者)，Sichuan Prov Peoples Hosp, Chengdu, Sichuan, Peoples R China.
EM gary.samsph@gmail.com
RI Wang, Xuedan/ABG-5633-2021; Tu, Mengtian/AAU-6816-2020
OI Wang, Pu/0000-0002-1234-309X; Glissen Brown, Jeremy/0000-0002-7204-7241;
   Berzin, Tyler/0000-0002-4364-6210
CR Ahn SB, 2012, GUT LIVER, V6, P64, DOI 10.5009/gnl.2012.6.1.64
   Arezzo, 2018, J MED ROBOT RES, V3, DOI DOI 10.1142/S2424905X18400020
   Aslanian HR, 2013, AM J GASTROENTEROL, V108, P166, DOI 10.1038/ajg.2012.237
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bandos AI, 2009, BIOMETRICS, V65, P247, DOI 10.1111/j.1541-0420.2008.01049.x
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Brenner H, 2011, ANN INTERN MED, V154, P22, DOI 10.7326/0003-4819-154-1-201101040-00004
   Buchner AM, 2011, GASTROINTEST ENDOSC, V73, P1223, DOI 10.1016/j.gie.2011.01.060
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen JH, 2017, NEW ENGL J MED, V376, P2507, DOI 10.1056/NEJMp1702071
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   Chinese Society of Gastroenterology, 2011, CHIN J GASTROENTEROL, V20, P979, DOI [10.3969/j.issn.1006-5709.2011.11.001, DOI 10.3969/J.ISSN.1006-5709.2011.11.001]
   Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMc1405329, 10.1056/NEJMoa1309086]
   Dean J., 2012, P ADV NEUR INF PROC, P1223, DOI DOI 10.5555/2999134.2999271
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Edwards BK, 2010, CANCER-AM CANCER SOC, V116, P544, DOI 10.1002/cncr.24760
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gkolfakis P, 2017, WORLD J GASTROENTERO, V23, P3784, DOI 10.3748/wjg.v23.i21.3784
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Heresbach D, 2008, ENDOSCOPY, V40, P284, DOI 10.1055/s-2007-995618
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuo S. M., 2013, REAL TIME DIGITAL SI
   Lee CK, 2011, GASTROINTEST ENDOSC, V74, P1094, DOI 10.1016/j.gie.2011.06.033
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lieberman DA, 2012, GASTROENTEROLOGY, V143, P844, DOI 10.1053/j.gastro.2012.06.001
   Mahmud N, 2015, GASTROENTEROL REP, V3, P179, DOI 10.1093/gastro/gov027
   Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information
   Misawa M, 2018, GASTROENTEROLOGY, V154, P2027, DOI 10.1053/j.gastro.2018.04.003
   Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Rex DK, 1997, GASTROENTEROLOGY, V112, P24, DOI 10.1016/S0016-5085(97)70214-2
   Seeff LC, 2004, GASTROENTEROLOGY, V127, P1670, DOI 10.1053/j.gastro.2004.09.051
   Siegel R, 2013, CA-CANCER J CLIN, V63, P11, DOI 10.3322/caac.21166
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Winawer SJ, 1997, GASTROENTEROLOGY, V112, P594, DOI 10.1053/gast.1997.v112.agast970594
   Yao K, 2013, ANN GASTROENTEROL, V26, P11
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 41
TC 249
Z9 263
U1 6
U2 101
PU NATURE PORTFOLIO
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2157-846X
J9 NAT BIOMED ENG
JI Nat. Biomed. Eng
PD OCT
PY 2018
VL 2
IS 10
BP 741
EP 748
DI 10.1038/s41551-018-0301-3
PG 8
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA GW4SN
UT WOS:000446910800008
PM 31015647
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Mori, Y
   Kudo, SE
   Misawa, M
   Saito, Y
   Ikematsu, H
   Hotta, K
   Ohtsuka, K
   Urushibara, F
   Kataoka, S
   Ogawa, Y
   Maeda, Y
   Takeda, K
   Nakamura, H
   Ichimasa, K
   Kudo, T
   Hayashi, T
   Wakamura, K
   Ishida, F
   Inoue, H
   Itoh, H
   Oda, M
   Mori, K
AF Mori, Yuichi
   Kudo, Shin-ei
   Misawa, Masashi
   Saito, Yutaka
   Ikematsu, Hiroaki
   Hotta, Kinichi
   Ohtsuka, Kazuo
   Urushibara, Fumihiko
   Kataoka, Shinichi
   Ogawa, Yushi
   Maeda, Yasuharu
   Takeda, Kenichi
   Nakamura, Hiroki
   Ichimasa, Katsuro
   Kudo, Toyoki
   Hayashi, Takemasa
   Wakamura, Kunihiko
   Ishida, Fumio
   Inoue, Haruhiro
   Itoh, Hayato
   Oda, Masahiro
   Mori, Kensaku
TI Real-Time Use of Artificial Intelligence in Identification of Diminutive
   Polyps During Colonoscopy A Prospective Study
SO ANNALS OF INTERNAL MEDICINE
LA English
DT Article
ID COMPUTER-AIDED DIAGNOSIS; SMALL COLORECTAL LESIONS; OPTICAL DIAGNOSIS;
   COLON POLYPS; ENDOSCOPY; SYSTEM; HISTOLOGY; CLASSIFICATION;
   ENDOCYTOSCOPY; RECOGNITION
AB Background: Computer-aided diagnosis (CAD) for colonoscopy may help endoscopists distinguish neoplastic polyps (adenomas) requiring resection from nonneoplastic polyps not requiring resection, potentially reducing cost.
   Objective: To evaluate the performance of real-time CAD with endocytoscopes (x520 ultramagnifying colonoscopes providing microvascular and cellular visualization of colorectal polyps after application of the narrow-band imaging [NBI] and methylene blue staining modes, respectively).
   Design: Single-group, open-label, prospective study. (UMIN [University hospital Medical Information Network] Clinical Trial Registry: UMIN000027360).
   Setting: University hospital.
   Participants: 791 consecutive patients undergoing colonoscopy and 23 endoscopists.
   Intervention: Real-time use of CAD during colonoscopy.
   Measurements: CAD-predicted pathology (neoplastic or nonneoplastic) of detected diminutive polyps (5 mm) on the basis of real-time outputs compared with pathologic diagnosis of the resected specimen (gold standard). The primary end point was whether CAD with the stained mode produced a negative predictive value (NPV) of 90% or greater for identifying diminutive rectosigmoid adenomas, the threshold required to "diagnose-and-leave" nonneoplastic polyps. Best- and worst-case scenarios assumed that polyps lacking either CAD diagnosis or pathology were true- or false-positive or true- or false-negative, respectively.
   Results: Overall, 466 diminutive (including 250 rectosigmoid) polyps from 325 patients were assessed by CAD, with a pathologic prediction rate of 98.1% (457 of 466). The NPVs of CAD for diminutive rectosigmoid adenomas were 96.4% (95% CI, 91.8% to 98.8%) (best-case scenario) and 93.7% (CI, 88.3% to 97.1%) (worst-case scenario) with stained mode and 96.5% (CI, 92.1% to 98.9%) (best-case scenario) and 95.2% (CI, 90.3% to 98.0%) (worst-case scenario) with NBI.
   Limitation: Two thirds of the colonoscopies were conducted by experts who had each experienced more than 200 endocytoscopies; 186 polyps not assessed by CAD were excluded.
   Conclusion: Real-time CAD can achieve the performance level required for a diagnose-and-leave strategy for diminutive, nonneoplastic rectosigmoid polyps.
C1 [Mori, Yuichi; Kudo, Shin-ei; Misawa, Masashi; Urushibara, Fumihiko; Kataoka, Shinichi; Ogawa, Yushi; Maeda, Yasuharu; Takeda, Kenichi; Nakamura, Hiroki; Ichimasa, Katsuro; Kudo, Toyoki; Hayashi, Takemasa; Wakamura, Kunihiko; Ishida, Fumio] Showa Univ, Northern Yokohama Hosp, Yokohama, Kanagawa, Japan.
   [Saito, Yutaka] Natl Canc Ctr, Endoscopy Div, Chuo Ku, 5-1-1 Tsukiji, Tokyo 1040045, Japan.
   [Ikematsu, Hiroaki] Natl Canc Ctr Hosp East, Dept Gastroenterol & Endoscopy, 6-5-1 Kashiwanoha, Kashiwa, Chiba 2278577, Japan.
   [Hotta, Kinichi] Shizuoka Canc Ctr, Div Endoscopy, 1007 Shimonagakubo, Nagaizumi Tyo, Shizuoka 4118777, Japan.
   [Ohtsuka, Kazuo] Tokyo Med & Dent Univ, Dept Endoscopy, Bunkyo Ku, 1-5-45 Yushima, Tokyo 1138510, Japan.
   [Itoh, Hayato; Oda, Masahiro; Mori, Kensaku] Nagoya Univ, Grad Sch Informat, Chikusa Ku, Furo Cho, Nagoya, Aichi 4640814, Japan.
   [Mori, Yuichi; Kudo, Shin-ei; Misawa, Masashi; Urushibara, Fumihiko; Kataoka, Shinichi; Ogawa, Yushi; Maeda, Yasuharu; Takeda, Kenichi; Nakamura, Hiroki; Ichimasa, Katsuro; Kudo, Toyoki; Hayashi, Takemasa; Wakamura, Kunihiko; Ishida, Fumio] Showa Univ, Northern Yokohama Hosp, Ctr Digest Dis, Tsuzuki Ku, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
   [Inoue, Haruhiro] Showa Univ, Koto Toyosu Hosp, Ctr Digest Dis, Koto Ku, 5-1-38 Toyosu, Tokyo 1358577, Japan.
C3 Showa University; National Cancer Center - Japan; National Cancer Center
   - Japan; Shizuoka Cancer Center; Tokyo Medical & Dental University
   (TMDU); Nagoya University; Showa University; Showa University
RP Mori, Y (通讯作者)，Showa Univ, Northern Yokohama Hosp, Ctr Digest Dis, Tsuzuki Ku, 35-1 Chigasaki Chuo, Yokohama, Kanagawa 2248503, Japan.
EM ibusiginjp@gmail.com
RI Misawa, Masashi/H-9004-2019; Itoh, Hayato/AAM-4022-2021; Mori,
   Yuichi/AAU-5406-2020; Ichimasa, Katsuro/AAP-6941-2021
OI Misawa, Masashi/0000-0002-8520-2036; Itoh, Hayato/0000-0002-1410-1078;
   Oda, Masahiro/0000-0001-7714-422X; Mori, Yuichi/0000-0003-2262-0334
FU Japan Society for the Promotion of Science [17H05305]; Grants-in-Aid for
   Scientific Research [17H05305] Funding Source: KAKEN
FX By Grants-in-Aid for Scientific Research (grant 17H05305) from the Japan
   Society for the Promotion of Science.
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Chen PJ, 2018, GASTROENTEROLOGY, V154, P568, DOI 10.1053/j.gastro.2017.10.010
   East JE, 2016, ENDOSCOPY, V48, P1029, DOI 10.1055/s-0042-118087
   Fred TB, 2010, WHO CLASSIFICATION T
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Hetzel JT, 2010, AM J GASTROENTEROL, V105, P2656, DOI 10.1038/ajg.2010.315
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Iwatate M, 2015, ENDOSC INT OPEN, V3, pE140, DOI 10.1055/s-0034-1391362
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2015, ENDOSCOPY, V47, P56, DOI 10.1055/s-0034-1378112
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Lahiff C, 2017, FRONTLINE GASTROENTE, V8, P98, DOI 10.1136/flgastro-2016-100777
   Lai EJ, 2009, GASTROINTEST ENDOSC, V69, P620, DOI 10.1016/j.gie.2008.05.057
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2017, ENDOSCOPY, V49, P813, DOI 10.1055/s-0043-109430
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   National Institute for Health and Care Excellence, 2017, VIRT CHROM ASS COL P
   Nishihara R, 2013, NEW ENGL J MED, V369, P1095, DOI 10.1056/NEJMoa1301969
   Rath T, 2016, ENDOSCOPY, V48, P557, DOI 10.1055/s-0042-102251
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Singh R, 2017, WORLD J GASTRO ENDOS, V9, P273, DOI 10.4253/wjge.v9.i6.273
   Tamai N, 2017, ENDOSC INT OPEN, V5, pE690, DOI 10.1055/s-0043-105490
   Tanaka S, 2015, J GASTROENTEROL, V50, P252, DOI 10.1007/s00535-014-1021-4
NR 26
TC 269
Z9 276
U1 8
U2 65
PU AMER COLL PHYSICIANS
PI PHILADELPHIA
PA INDEPENDENCE MALL WEST 6TH AND RACE ST, PHILADELPHIA, PA 19106-1572 USA
SN 0003-4819
EI 1539-3704
J9 ANN INTERN MED
JI Ann. Intern. Med.
PD SEP 18
PY 2018
VL 169
IS 6
BP 357
EP +
DI 10.7326/M18-0249
PG 19
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA GT7CZ
UT WOS:000444679800012
PM 30105375
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Sanchez-Gonzalez, A
   Garcia-Zapirain, B
   Sierra-Sosa, D
   Elmaghraby, A
AF Sanchez-Gonzalez, Alain
   Garcia-Zapirain, Begonya
   Sierra-Sosa, Daniel
   Elmaghraby, Adel
TI Automatized colon polyp segmentation via contour region analysis
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Polyp detection; Colonoscopy images; Image processing; Feature
   classification; Feature selection
ID SYSTEM
AB The increasing use of colorectal cancer screening programs has contributed to the growing number of colonoscopies performed by health centers. Hence, in recent years there has been a tendency to develop medical diagnosis support tools in order to assist specialists. This research has designed an automatized polyp detection system that allows a reduction in the rate of missed polyps that can lead to interval cancer; one of the main risks existing in colonoscopy. A characterization has therefore been made of the shape, color and curvature of edges and their regions, enabling the segmentation of polyps present in colonoscopy images. A 90.53% polyp detection rate has been achieved using the designed system, and 76.29% and 71.57% segmentation quality for the Annotated Area Covered and Dice Coefficient indicators respectively. This system aims to offer assistance with medical diagnosis that has a positive impact on patient health.
C1 [Sanchez-Gonzalez, Alain; Garcia-Zapirain, Begonya] Univ Deusto, eVida Res Grp, Av Univ 24, Bilbao 48007, Spain.
   [Sierra-Sosa, Daniel; Elmaghraby, Adel] Univ Louisville, Dept Comp Engn & Comp Sci CECS, Louisville, KY 40292 USA.
C3 University of Deusto; University of Louisville
RP Sierra-Sosa, D (通讯作者)，Univ Louisville, Dept Comp Engn & Comp Sci CECS, Louisville, KY 40292 USA.
EM d.sierrasosa@louisville.edu
RI Zapirain, Begoña Garcia/L-5619-2014; Sierra-Sosa, Daniel/AAP-4604-2020;
   Sierra-Sosa, Daniel/AAP-4610-2020; Elmaghraby, Adel S/B-3353-2014
OI Zapirain, Begoña Garcia/0000-0002-9356-1186; Sierra-Sosa,
   Daniel/0000-0003-1326-0867; Sierra-Sosa, Daniel/0000-0003-1326-0867;
   Elmaghraby, Adel S/0000-0001-5274-8596
FU Basque Government "Aids for health research projects"; Basque Government
   Department of Education (eVIDA Certified Group) [IT579-13]
FX This research was supported by the Basque Government "Aids for health
   research projects" and the publication fees supported by the Basque
   Government Department of Education (eVIDA Certified Group IT579-13).
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Arnold M., 2010, J IMAGE VIDEO PROCES, V2010, P9
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J., 2012, COMPUTATIONAL CLIN A, P76
   Bernal J., 2011, DEPTH VALLEYS ACCUMU, P71
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Bernal J, 2011, LECT NOTES COMPUT SC, V6669, P134
   Bernal Jorge, 2011, INTELLIGENT SYSTEMS, V1
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Condessa F, 2012, LECT NOTES COMPUT SC, V7325, P188, DOI 10.1007/978-3-642-31298-4_23
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Hall M., 2000, 17 INT C MACH LEARN, P359
   Hao Chun Wang, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P564, DOI 10.1109/ISPACS.2012.6473553
   Herrera F., 2016, MULTILABEL CLASSIFIC
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iwahori Y., 2013, PROC INT C MACH VIS, P21
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Komeda Y, 2017, ONCOLOGY-BASEL, V93, P30, DOI 10.1159/000481227
   Li BP, 2012, J MED SYST, V36, P2463, DOI 10.1007/s10916-011-9713-2
   Manivannan S, 2013, I S BIOMED IMAGING, P644
   Park S., 2015, POLYP DETECTION COLO
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Pearl J., 2003, ARTIFICIAL INTELLIGE, V2
   Rafael C. G, 2009, DIGITAL IMAGE PROCES
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Tajbakhsh N., 2015, AUTOMATED POLYP DETE
   Tajbakhsh N, 2014, I S BIOMED IMAGING, P97, DOI 10.1109/ISBI.2014.6867818
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Tjoa M., 2003, BIOMEDICAL ENG ONLIN, V2, P1
   Tulum G, 2017, INT J COMPUT ASS RAD, V12, P627, DOI 10.1007/s11548-017-1521-9
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Wang Z, 2004, PROC SPIE, V5370, P972, DOI 10.1117/12.535664
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
NR 41
TC 28
Z9 30
U1 2
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD SEP 1
PY 2018
VL 100
BP 152
EP 164
DI 10.1016/j.compbiomed.2018.07.002
PG 13
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA GR5TH
UT WOS:000442704300018
PM 30015012
DA 2023-08-21
ER

PT J
AU Zhao, RX
   Zhang, RC
   Tang, TY
   Feng, X
   Li, JL
   Liu, Y
   Zhu, RX
   Wang, GZ
   Li, KN
   Zhou, WY
   Yang, YF
   Wang, YZ
   Ba, YJ
   Zhang, JJ
   Li, Y
   Zhou, FF
AF Zhao, Ruixue
   Zhang, Ruochi
   Tang, Tongyu
   Feng, Xin
   Li, Jialiang
   Liu, Yue
   Zhu, Renxiang
   Wang, Guangze
   Li, Kangning
   Zhou, Wenyang
   Yang, Yunfei
   Wang, Yuzhao
   Ba, Yuanjie
   Zhang, Jiaojiao
   Li, Yang
   Zhou, Fengfeng
TI TriZ-a rotation-tolerant image feature and its application in
   endoscope-based disease diagnosis
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Endoscopy; Feature extraction; Feature selection; TriZ;
   Rotation-tolerant; Disease diagnosis
ID DIABETIC MACULAR EDEMA; ULCER DETECTION; NEURAL-NETWORK; CANCER;
   CLASSIFICATION; DEGENERATION; INFORMATION; PREDICTION; LESIONS; SCALE
AB Endoscopy is becoming one of the widely-used technologies to screen the gastric diseases, and it heavily relies on the experiences of the clinical endoscopists. The location, shape, and size are the typical patterns for the endoscopists to make the diagnosis decisions. The contrasting texture patterns also suggest the potential lesions. This study designed a novel rotation-tolerant image feature, TriZ, and demonstrated the effectiveness on both the rotation invariance and the lesion detection of three gastric lesion types, i.e., gastric polyp, gastric ulcer, and gastritis. TriZ achieved 87.0% in the four-class classification problem of the three gastric lesion types and the healthy controls, averaged over the twenty random runs of 10-fold cross-validations. Due to that biomedical imaging technologies may capture the lesion sites from different angles, the symmetric image feature extraction algorithm TriZ may facilitate the biomedical image based disease diagnosis modeling. Compared with the 378,434 features of the HOG algorithm, TriZ achieved a better accuracy using only 126 image features.
C1 [Zhao, Ruixue; Zhang, Ruochi; Feng, Xin; Zhu, Renxiang; Wang, Guangze; Li, Kangning; Zhou, Wenyang; Ba, Yuanjie; Li, Yang; Zhou, Fengfeng] Jilin Univ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.
   [Li, Jialiang; Yang, Yunfei; Wang, Yuzhao; Zhang, Jiaojiao] Jilin Univ, Coll Software, Changchun 130012, Jilin, Peoples R China.
   [Tang, Tongyu] Jilin Univ, Hosp 1, Changchun 130012, Jilin, Peoples R China.
   [Liu, Yue] Jilin Univ, Coll Commun Engn, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University
RP Zhou, FF (通讯作者)，Jilin Univ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.
EM ffzhou@jlu.edu.cn
RI wang, yi/HOF-6668-2023; Zhou, Fengfeng/A-8932-2008
OI Zhou, Fengfeng/0000-0002-8108-6007; Li, Jialiang/0000-0002-9032-5962
FU Strategic Priority Research Program of the Chinese Academy of Sciences
   [XDB13040400]; Jilin University
FX This work was supported by the Strategic Priority Research Program of
   the Chinese Academy of Sciences (XDB13040400) and the startup grant from
   the Jilin University. The two anonymous reviewers were appreciated for
   their constructive comments on improving this manuscript.
CR Abdelhack M, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0443-17.2018
   Ali H, 2017, COMPUT BIOL MED, V88, P84, DOI 10.1016/j.compbiomed.2017.07.002
   Banzato T, 2018, VET J, V235, P90, DOI 10.1016/j.tvjl.2018.04.001
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bian LH, 2016, BIOMED OPT EXPRESS, V7, P4543, DOI 10.1364/BOE.7.004543
   Burger W, 2016, SCALE INVARIANT FEAT, P609
   Burke KA, 2015, J BIOMED OPT, V20, DOI 10.1117/1.JBO.20.5.051024
   Charisis VS, 2013, COMP MED SY, P203, DOI 10.1109/CBMS.2013.6627789
   Chen WQ, 2016, CA-CANCER J CLIN, V66, P115, DOI 10.3322/caac.21338
   Cheng R, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.017001
   Chung L, 2013, BRIT J CANCER, V108, P351, DOI 10.1038/bjc.2012.552
   Ciaccio EJ, 2015, COMPUT BIOL MED, V65, P364, DOI 10.1016/j.compbiomed.2015.04.019
   DEYHLE P, 1980, ENDOSCOPY, P35
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Gado A, 2013, ALEX J MED, V49, P25, DOI 10.1016/j.ajme.2012.08.005
   Ge RQ, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-0990-0
   Gutte P. H., 2014, INT J COMPUT APPL, V99, P28
   Hyduke Daniel R, 2013, Int J Bioinform Res Appl, V9, P365, DOI 10.1504/IJBRA.2013.054701
   Karri SPK, 2017, BIOMED OPT EXPRESS, V8, P579, DOI 10.1364/BOE.8.000579
   Lee H, 2015, EXPERT SYST APPL, V42, P5356, DOI 10.1016/j.eswa.2015.02.005
   Li BP, 2009, IMAGE VISION COMPUT, V27, P1336, DOI 10.1016/j.imavis.2008.12.003
   Li JQ, 2017, IEEE ACM T COMPUT BI, V14, P1165, DOI 10.1109/TCBB.2017.2649529
   Liu DY, 2016, MED IMAGE ANAL, V32, P281, DOI 10.1016/j.media.2016.04.007
   Liu JM, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13184-8
   Maruo K, 2015, J BIOMED OPT, V20, DOI 10.1117/1.JBO.20.4.047003
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Metsis V, 2009, INT FED INFO PROC, P233
   Milosavljevic T, 2011, DIGEST DIS, V29, P491, DOI 10.1159/000331517
   Mookiah MRK, 2015, COMPUT BIOL MED, V63, P208, DOI 10.1016/j.compbiomed.2015.05.019
   Moon HS, 2015, CLIN ENDOSC, V48, P291, DOI 10.5946/ce.2015.48.4.291
   Murillo AC, 2007, IEEE INT CONF ROBOT, P3901, DOI 10.1109/ROBOT.2007.364077
   Murra-Saca J. A., 2017, EL SALVADOR ATLAS GA
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Nguyen D. T., 2016, SENSORS, V16
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paul R, 2016, TOMOGRAPHY, V2, P388, DOI 10.18383/j.tom.2016.00211
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saaiq M, 2014, WORLD J CLIN CASES, V2, P507, DOI 10.12998/wjcc.v2.i10.507
   Simonyan K, 2015, Arxiv, DOI [arXiv:1409.1556, DOI 10.48550/ARXIV.1409.1556]
   Srinivasan PP, 2014, BIOMED OPT EXPRESS, V5, P3568, DOI 10.1364/BOE.5.003568
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tang W, 2016, ONCOTARGET, V7, P85613, DOI 10.18632/oncotarget.12828
   Wang F, 2018, NEURAL NETWORKS, V97, P162, DOI 10.1016/j.neunet.2017.09.007
   Wang GQ, 2010, FEBS LETT, V584, P194, DOI 10.1016/j.febslet.2009.11.067
   Wang L, 2017, J THEOR BIOL, V418, P105, DOI 10.1016/j.jtbi.2017.01.003
   Wang Y, 2016, BIOMED OPT EXPRESS, V7, P4928, DOI 10.1364/BOE.7.004928
   Wang ZW, 2018, IEEE T MED IMAGING, V37, P1127, DOI 10.1109/TMI.2017.2789181
   Wei LY, 2017, IEEE T NANOBIOSCI, V16, P240, DOI 10.1109/TNB.2017.2661756
   Wei LY, 2017, J PROTEOME RES, V16, P2044, DOI 10.1021/acs.jproteome.7b00019
   Winawer S, 2003, GASTROENTEROLOGY, V124, P544, DOI 10.1053/gast.2003.50044
   Wiseman SM, 2013, J CLIN ENDOCR METAB, V98, P4072, DOI 10.1210/jc.2013-1991
   Xiao CY, 2013, IEEE T IMAGE PROCESS, V22, P174, DOI 10.1109/TIP.2012.2216277
   XIE J, 2012, HLTH INFORM SCI, P173
   Xie JY, 2013, HEALTH INF SCI SYST, V1, DOI 10.1186/2047-2501-1-10
   Xie JY, 2011, EXPERT SYST APPL, V38, P5809, DOI 10.1016/j.eswa.2010.10.050
   Ye YT, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13259-6
   Yu LC, 2012, INT C PATT RECOG, P45
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang RK, 2017, IEEE J BIOMED HEALTH, V21, P41, DOI 10.1109/JBHI.2016.2635662
   Zhou Fengfeng, 2009, Genomics Proteomics & Bioinformatics, V7, P194, DOI 10.1016/S1672-0229(08)60049-2
   Zou Q, 2016, NEUROCOMPUTING, V173, P346, DOI 10.1016/j.neucom.2014.12.123
NR 63
TC 12
Z9 12
U1 2
U2 28
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD AUG 1
PY 2018
VL 99
BP 182
EP 190
DI 10.1016/j.compbiomed.2018.06.006
PG 9
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA GR8MT
UT WOS:000442978700017
PM 29936284
DA 2023-08-21
ER

PT J
AU Billah, M
   Waheed, S
AF Billah, Mustain
   Waheed, Sajjad
TI Gastrointestinal polyp detection in endoscopic images using an improved
   feature extraction method
SO BIOMEDICAL ENGINEERING LETTERS
LA English
DT Article
DE Endoscopic image; Video endoscopy; Convolutional neural network (CNN);
   Color wavelet features; Support vector machine (SVM); Improved method
ID SYSTEM
AB Gastrointestinal polyps are treated as the precursors of cancer development. So, possibility of cancers can be reduced at a great extent by early detection and removal of polyps. The most used diagnostic modality for gastrointestinal polyps is video endoscopy. But, as an operator dependant procedure, several human factors can lead to miss detection of polyps. In this peper, an improved computer aided polyp detection method has been proposed. Proposed improved method can reduce polyp miss detection rate and assists doctors in finding the most important regions to pay attention. Color wavelet features and convolutional neural network features are extracted from endoscopic images, which are used for training a support vector machine. Then a target endoscopic image will be given to the classifier as input in order to find whether it contains any polyp or not. If polyp is found, it will be marked automatically. Experiment shows that, color wavelet features and convolutional neural network features together construct a highly representative of endoscopic polyp images. Evaluations on standard public databases show that, proposed system outperforms state-of-the-art methods, gaining accuracy of 98.34%, sensitivity of 98.67% and specificity of 98.23%. In this paper, the strength of color wavelet features and power of convolutional neural network features are combined. Fusion of these two methodology and use of support vector machine results in an improved method for gastrointestinal polyp detection. An analysis of ROC reveals that, proposed method can be used for polyp detection purposes with greater accuracy than state-of-the-art methods.
C1 [Billah, Mustain; Waheed, Sajjad] Mawlana Bhashani Sci & Technol Univ, Dept Informat & Commun Technol ICT, Tangail, Bangladesh.
C3 Mawlana Bhashani Science & Technology University
RP Billah, M (通讯作者)，Mawlana Bhashani Sci & Technol Univ, Dept Informat & Commun Technol ICT, Tangail, Bangladesh.
EM mustainbillahx@gmail.com
OI Billah, Mustain/0000-0003-3649-5909
CR Alexandre LA, 2008, INT C BIOM ENG INF 2, V2
   [Anonymous], 2014, ICML
   BAXT WG, 1995, LANCET, V346, P1135, DOI 10.1016/S0140-6736(95)91804-3
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   Goszczynski J, 2003, PATTERN RECOGN, V36, P2883
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Jia X, 2016, 2016 IEEE 38 ANN INT
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Kodogiannis VS, 2007, INT J INFORM TECHNOL, V13, P46
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2009, 2009 IEEE INT C ROB
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Park SY, 2016, SPIE MED IMAGING
   Ribeiro E, 2016, 2016 IEEE 29 INT S C
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, P368
   Tajbakhsh N, 2015, 2015 IEEE 12 INT S B
   Tajbakhsh N, 2014, INT C MED IM COMP CO
   West D, 2000, ARTIF INTELL MED, V20, P183, DOI 10.1016/S0933-3657(00)00063-4
   Zhu R, 2015, 2015 8 INT C IM SIGN
   Zou Y, 2015, 2015 IEEE INT C DIG
NR 24
TC 18
Z9 19
U1 2
U2 10
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2093-9868
EI 2093-985X
J9 BIOMED ENG LETT
JI Biomed. Eng. Lett.
PD FEB
PY 2018
VL 8
IS 1
SI SI
BP 69
EP 75
DI 10.1007/s13534-017-0048-x
PG 7
WC Engineering, Biomedical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA GP2ML
UT WOS:000440667700006
PM 30603191
OA Green Published
DA 2023-08-21
ER

PT J
AU Chen, PJ
   Lin, MC
   Lai, MJ
   Lin, JC
   Lu, HHS
   Tseng, VS
AF Chen, Peng-Jen
   Lin, Meng-Chiung
   Lai, Mei-Ju
   Lin, Jung-Chun
   Lu, Henry Horng-Shing
   Tseng, Vincent S.
TI Accurate Classification of Diminutive Colorectal Polyps Using
   Computer-Aided Analysis
SO GASTROENTEROLOGY
LA English
DT Article
DE Colon Cancer Detection; Machine Learning; Cost-effectiveness; Magnifying
ID CONVENTIONAL COLONOSCOPY; OPTICAL MAGNIFICATION; DIAGNOSIS; HISTOLOGY;
   CANCER; SYSTEM; CHROMOENDOSCOPY; POLYPECTOMY; PREVENTION; STRATEGY
AB BACKGROUND & AIMS: Narrow-band imaging is an image-enhanced form of endoscopy used to observed microstructures and capillaries of the mucosal epithelium which allows for real-time prediction of histologic features of colorectal polyps. However, narrow-band imaging expertise is required to differentiate hyperplastic from neoplastic polyps with high levels of accuracy. We developed and tested a system of computer-aided diagnosis with a deep neural network (DNN-CAD) to analyze narrow-band images of diminutive colorectal polyps. METHODS: We collected 1476 images of neoplastic polyps and 681 images of hyperplastic polyps, obtained from the picture archiving and communications system database in a tertiary hospital in Taiwan. Histologic findings from the polyps were also collected and used as the reference standard. The images and data were used to train the DNN. A test set of images (96 hyperplastic and 188 neoplastic polyps, smaller than 5 mm), obtained from patients who underwent colonoscopies from March 2017 through August 2017, was then used to test the diagnostic ability of the DNN-CAD vs endoscopists (2 expert and 4 novice), who were asked to classify the images of the test set as neoplastic or hyperplastic. Their classifications were compared with findings from histologic analysis. The primary outcome measures were diagnostic accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and diagnostic time. The accuracy, sensitivity, specificity, PPV, NPV, and diagnostic time were compared among DNN-CAD, the novice endoscopists, and the expert endoscopists. The study was designed to detect a difference of 10% in accuracy by a 2-sided McNemar test. RESULTS: In the test set, the DNN-CAD identified neoplastic or hyperplastic polyps with 96.3% sensitivity, 78.1% specificity, a PPV of 89.6%, and a NPV of 91.5%. Fewer than half of the novice endoscopists classified polyps with a NPV of 90% (their NPVs ranged from 73.9% to 84.0%). DNN-CAD classified polyps as neoplastic or hyperplastic in 0.45 +/- 0.07 seconds-shorter than the time required by experts (1.54 +/- 1.30 seconds) and nonexperts (1.77 +/- 1.37 seconds) (both P < .001). DNN-CAD classified polyps with perfect intra-observer agreement (kappa score of 1). There was a low level of intra-observer and inter-observer agreement in classification among endoscopists. CONCLUSIONS: We developed a system called DNN-CAD to identify neoplastic or hyperplastic colorectal polyps less than 5 mm. The system classified polyps with a PPV of 89.6%, and a NPV of 91.5%, and in a shorter time than endoscopists. This deep-learning model has potential for not only endoscopic image recognition but for other forms of medical image analysis, including sonography, computed tomography, and magnetic resonance images.
C1 [Chen, Peng-Jen; Lin, Jung-Chun] Triserv Gen Hosp, Natl Def Med Ctr, Div Gastroenterol, 325,Sec 2,Chenggong Rd, Taipei 114, Taiwan.
   [Lin, Meng-Chiung] Natl Chiao Tung Univ, Dept Biol Sci & Technol, Hsinchu, Taiwan.
   [Lin, Meng-Chiung] Taichung Armed Forces Gen Hosp, Div Gastroenterol, Taichung, Taiwan.
   [Lai, Mei-Ju] Triserv Gen Hosp, Natl Def Med Ctr, Dept Pathol, Taipei, Taiwan.
   [Lu, Henry Horng-Shing] Natl Chiao Tung Univ, Big Data Res Ctr, Hsinchu, Taiwan.
   [Lu, Henry Horng-Shing] Natl Chiao Tung Univ, Inst Stat, Hsinchu, Taiwan.
   [Tseng, Vincent S.] Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
C3 National Defense Medical Center; Tri-Service General Hospital; National
   Yang Ming Chiao Tung University; National Defense Medical Center;
   Tri-Service General Hospital; National Yang Ming Chiao Tung University;
   National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University
RP Chen, PJ (通讯作者)，Triserv Gen Hosp, Natl Def Med Ctr, Div Gastroenterol, 325,Sec 2,Chenggong Rd, Taipei 114, Taiwan.; Tseng, VS (通讯作者)，Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM endoscopy@mail.ndmctsgh.edu.tw; vtseng@cs.nctu.edu.tw
OI Chen, Peng Jen/0000-0001-5400-905X
FU Ministry of Science and Technology, Taiwan [106-2218-E-009-031]
FX This research was partially supported by the Ministry of Science and
   Technology, Taiwan, under grant no. 106-2218-E-009-031.
CR Abadi M., 2016, TENSORFLOW LARGE SCA, P265
   Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   Chiu HM, 2007, GUT, V56, P373, DOI 10.1136/gut.2006.099614
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Iwatate M, 2015, ENDOSC INT OPEN, V3, pE140, DOI 10.1055/s-0034-1391362
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Kuiper T, 2012, CLIN GASTROENTEROL H, V10, P1016, DOI 10.1016/j.cgh.2012.05.004
   Ladabaum U, 2013, GASTROENTEROLOGY, V144, P81, DOI 10.1053/j.gastro.2012.09.054
   Liou JM, 2007, DIS COLON RECTUM, V50, P630, DOI 10.1007/s10350-006-0857-y
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Patel SG, 2016, GASTROENTEROLOGY, V150, P406, DOI 10.1053/j.gastro.2015.10.042
   Ranzato M., DEVISE DEEP VISUAL S
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Rex DK, 2011, GASTROINTEST ENDOSC, V73, P419, DOI 10.1016/j.gie.2011.01.023
   Rex DK, 2009, GASTROENTEROLOGY, V136, P1174, DOI 10.1053/j.gastro.2008.12.009
   Rogart JN, 2008, GASTROINTEST ENDOSC, V68, P1136, DOI 10.1016/j.gie.2008.04.035
   Rosenberg C., IMPROVING PHOTO SEAR
   Satodate H, 2003, GASTROINTEST ENDOSC, V58, P288, DOI 10.1067/mge.2003.361
   Sikka S, 2008, ENDOSCOPY, V40, P818, DOI 10.1055/s-2008-1077437
   Su MY, 2006, AM J GASTROENTEROL, V101, P2711, DOI 10.1111/j.1572-0241.2006.00932.x
   Szegedy C, 2015, 2015 IEEE C COMP VIS, P1
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tanaka S, 2011, DIGEST ENDOSC, V23, P131, DOI 10.1111/j.1443-1661.2011.01106.x
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   VOGELSTEIN B, 1988, NEW ENGL J MED, V319, P525, DOI 10.1056/NEJM198809013190901
   Walsh JME, 2003, JAMA-J AM MED ASSOC, V289, P1288, DOI 10.1001/jama.289.10.1288
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 28
TC 233
Z9 258
U1 4
U2 91
PU W B SAUNDERS CO-ELSEVIER INC
PI PHILADELPHIA
PA 1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA
SN 0016-5085
EI 1528-0012
J9 GASTROENTEROLOGY
JI Gastroenterology
PD FEB
PY 2018
VL 154
IS 3
BP 568
EP 575
DI 10.1053/j.gastro.2017.10.010
PG 8
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA FV7CW
UT WOS:000424741500029
PM 29042219
HC Y
HP N
DA 2023-08-21
ER

PT J
AU Renner, J
   Phlipsen, H
   Haller, B
   Navarro-Avila, F
   Saint-Hill-Febles, Y
   Mateus, D
   Ponchon, T
   Poszler, A
   Abdelhafez, M
   Schmid, RM
   von Delius, S
   Klare, P
AF Renner, Janis
   Phlipsen, Henrik
   Haller, Bernhard
   Navarro-Avila, Fernando
   Saint-Hill-Febles, Yadira
   Mateus, Diana
   Ponchon, Thierry
   Poszler, Alexander
   Abdelhafez, Mohamed
   Schmid, Roland M.
   von Delius, Stefan
   Klare, Peter
TI Optical classification of neoplastic colorectal polyps - a
   computer-assisted approach (the COACH study)
SO SCANDINAVIAN JOURNAL OF GASTROENTEROLOGY
LA English
DT Article
DE Adenoma; automatic; classification; optical; colonoscopy; colorectal;
   carcinoma; computer
ID DIAGNOSIS; SYSTEM; HISTOLOGY; LESIONS
AB Background and aims: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.Methods: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n=275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.Results: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p=.307 and p=1.000, respectively).Conclusions: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.
C1 [Renner, Janis; Phlipsen, Henrik; Poszler, Alexander; Abdelhafez, Mohamed; Schmid, Roland M.; Klare, Peter] Tech Univ Munich, Klinikum Rechts Isar, Med Klin 2, Munich, Germany.
   [Haller, Bernhard] Tech Univ Munich, Klinikum Rechts Isar, Inst Med Informat Stat & Epidemiol, Munich, Germany.
   [Navarro-Avila, Fernando; Saint-Hill-Febles, Yadira; Mateus, Diana] Tech Univ Munich, CAMP, Garching, Germany.
   [Ponchon, Thierry] Hop Edouard Herriot, Dept Endoscopy & Gastroenterol, Pavillon L, Lyon, France.
   [von Delius, Stefan] RoMed Klinikum Rosenheim, Med Klin 2, Rosenheim, Germany.
C3 Technical University of Munich; University of Hamburg; University
   Medical Center Hamburg-Eppendorf; University of Munich; Technical
   University of Munich; Technical University of Munich; CHU Lyon;
   University of Hamburg; University Medical Center Hamburg-Eppendorf
RP Klare, P (通讯作者)，Klinikum Rechts Der Isar, Klin & Poliklin Innere Med 2, Ismaninger Str 22, D-81675 Munich, Germany.
EM peter.klare@tum.de
RI Haller, Bernhard/I-1943-2019
OI Haller, Bernhard/0000-0002-9723-393X; Mateus, Diana/0000-0002-2252-8717
CR Abu Dayyeh BK, 2015, GASTROINTEST ENDOSC, V81, P502, DOI 10.1016/j.gie.2014.12.022
   [Anonymous], 2014, P 31 INT C INT C MAC
   Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547
   Hassan C, 2010, CLIN GASTROENTEROL H, V8, P865, DOI 10.1016/j.cgh.2010.05.018
   Klare P, 2016, ENDOSCOPY, V48, P909, DOI 10.1055/s-0042-110650
   Klare P, 2015, BMC MED EDUC, V15, DOI 10.1186/s12909-015-0312-7
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lieberman D, 2015, CLIN GASTROENTEROL H, V13, P1860, DOI 10.1016/j.cgh.2015.07.011
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Navarro F, 2017, SPIE MED IMAGING
   Pox C, 2013, Z GASTROENTEROL, V51, P753, DOI 10.1055/s-0033-1350264
   Rees CJ, 2017, GUT, V66, P887, DOI 10.1136/gutjnl-2015-310584
   Sakata S, 2016, DIGEST ENDOSC, V28, P281, DOI 10.1111/den.12625
   Schachschal G, 2014, GUT, V63, P458, DOI 10.1136/gutjnl-2013-304562
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   von Renteln D, 2017, CLIN TRANSL GASTROEN, V8, DOI 10.1038/ctg.2017.6
NR 18
TC 25
Z9 26
U1 0
U2 5
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0036-5521
EI 1502-7708
J9 SCAND J GASTROENTERO
JI Scand. J. Gastroenterol.
PY 2018
VL 53
IS 9
BP 1100
EP 1106
DI 10.1080/00365521.2018.1501092
PG 7
WC Gastroenterology & Hepatology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Gastroenterology & Hepatology
GA HA9OO
UT WOS:000450634000012
PM 30270677
DA 2023-08-21
ER

PT J
AU Shin, Y
   Qadir, HA
   Aabakken, L
   Bergsland, J
   Balasingham, I
AF Shin, Younghak
   Qadir, Hemin Ali
   Aabakken, Lars
   Bergsland, Jacob
   Balasingham, Ilangko
TI Automatic Colon Polyp Detection Using Region Based Deep CNN and Post
   Learning Approaches
SO IEEE ACCESS
LA English
DT Article
DE Colonoscopy; convolutional neural network; image augmentation; polyp
   detection; region proposal network; transfer learning
ID CONVOLUTIONAL NEURAL-NETWORKS; VALIDATION
AB Automatic image detection of colonic polyps is still an unsolved problem due to the large variation of polyps in terms of shape, texture, size, and color, and the existence of various polyp-like mimics during colonoscopy. In this paper, we apply a recent region-based convolutional neural network (CNN) approach for the automatic detection of polyps in the images and videos obtained from colonoscopy examinations. We use a deep-CNN model (Inception Resnet) as a transfer learning scheme in the detection system. To overcome the polyp detection obstacles and the small number of polyp images, we examine image augmentation strategies for training deep networks. We further propose two efficient post-learning methods, such as automatic false positive learning and offline learning, both of which can be incorporated with the region-based detection system for reliable polyp detection. Using the large size of colonoscopy databases, experimental results demonstrate that the suggested detection systems show better performance than other systems in the literature. Furthermore, we show improved detection performance using the proposed post-learning schemes for colonoscopy videos.
C1 [Shin, Younghak; Balasingham, Ilangko] Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.
   [Shin, Younghak; Qadir, Hemin Ali; Aabakken, Lars; Bergsland, Jacob; Balasingham, Ilangko] Oslo Univ Hosp, Intervent Ctr, N-0027 Oslo, Norway.
   [Qadir, Hemin Ali] Univ Oslo, Dept Informat, N-0315 Oslo, Norway.
   [Aabakken, Lars] Univ Oslo, Dept Transplantat, Fac Med, N-0315 Oslo, Norway.
C3 Norwegian University of Science & Technology (NTNU); University of Oslo;
   University of Oslo; University of Oslo
RP Shin, Y (通讯作者)，Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.; Shin, Y (通讯作者)，Oslo Univ Hosp, Intervent Ctr, N-0027 Oslo, Norway.
EM shinyh0919@gmail.com
RI Bergsland, Jacob/H-3966-2016; Balasingham, Ilangko/AGU-7268-2022
FU European Research Consortium for Informatics and Mathematics Alain
   Bensoussan Fellowship Programme; Research Council of Norway through
   MELODY Project [225885/O70]; Research Council of Norway through
   Industrial Ph.D. Project [271542/O30]
FX This work was supported in part by the European Research Consortium for
   Informatics and Mathematics Alain Bensoussan Fellowship Programme, in
   part by the Research Council of Norway through the MELODY Project under
   Contract 225885/O70, and in part by the Research Council of Norway
   through the Industrial Ph.D. Project under Contract 271542/O30.
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Chen X., 2017, ARXIV170202138
   Girshick R., 2014, P IEEE C COMP VIS PA, P580, DOI DOI 10.1109/CVPR.2014.81
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang J, 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.351
   Hundertmark S., 2015, 2015 42nd IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2015.7180004
   Jiang H., 2016, FACE DETECTION FASTE
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Park S., 2015, TECH REP
   Park SY, 2015, PROC SPIE, V9785, DOI 10.1117/12.2217148
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P1186, DOI 10.1016/S0002-9270(03)00183-7
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2013, LECT NOTES COMPUT SC, V8198, P53, DOI 10.1007/978-3-642-41083-3_7
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhao XD, 2016, ACSR ADV COMPUT, V56, P1
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 41
TC 108
Z9 111
U1 3
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2018
VL 6
BP 40950
EP 40962
DI 10.1109/ACCESS.2018.2856402
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA GQ6WJ
UT WOS:000441868800053
OA Green Submitted, gold
DA 2023-08-21
ER

PT J
AU Shin, Y
   Qadir, HA
   Balasingham, I
AF Shin, Younghak
   Qadir, Hemin Ali
   Balasingham, Ilangko
TI Abnormal Colon Polyp Image Synthesis Using Conditional Adversarial
   Networks for Improved Detection Performance
SO IEEE ACCESS
LA English
DT Article
DE Colonoscopy; convolutional neural network; dilated convolution;
   generative adversarial networks; polyp detection
ID VALIDATION
AB One of the major obstacles in automatic polyp detection during colonoscopy is the lack of labeled polyp training images. In this paper, we propose a framework of conditional adversarial networks to increase the number of training samples by generating synthetic polyp images. Using a normal binary form of polyp mask which represents only the polyp position as an input conditioned image, realistic polyp image generation is a difficult task in a generative adversarial networks approach. We propose an edge filtering-based combined input conditioned image to train our proposed networks. This enables realistic polyp image generations while maintaining the original structures of the colonoscopy image frames. More importantly, our proposed framework generates synthetic polyp images from normal colonoscopy images which have the advantage of being relatively easy to obtain. The network architecture is based on the use of multiple dilated convolutions in each encoding part of our generator network to consider large receptive fields and avoid much contractions of a feature map size. An image resizing with convolution for upsampling in the decoding layers is considered to prevent artifacts on generated images. We show that the generated polyp images are not only qualitatively realistic, but also help to improve polyp detection performance.
C1 [Shin, Younghak; Balasingham, Ilangko] Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.
   [Shin, Younghak; Qadir, Hemin Ali; Balasingham, Ilangko] Oslo Univ Hosp, Intervent Ctr, N-0315 Oslo, Norway.
   [Qadir, Hemin Ali] Univ Oslo, Dept Informat, N-0315 Oslo, Norway.
C3 Norwegian University of Science & Technology (NTNU); University of Oslo;
   University of Oslo
RP Shin, Y (通讯作者)，Norwegian Univ Sci & Technol, Dept Elect Syst, N-7491 Trondheim, Norway.; Shin, Y (通讯作者)，Oslo Univ Hosp, Intervent Ctr, N-0315 Oslo, Norway.
EM shinyh0919@gmail.com
RI Balasingham, Ilangko/AGU-7268-2022
FU Research Council of Norway through the MELODY Project [225885/O70];
   Research Council of Norway [271542/O30]
FX This work was supported in part by the Research Council of Norway
   through the MELODY Project under Contract 225885/O70 and in part by the
   Research Council of Norway through the Industrial Ph.D. Project under
   Contract 271542/O30.
CR Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   [Anonymous], 2017, PROC IEEE C COMPUT V
   [Anonymous], 2017, DEEPLAB SEMANTIC IMA
   [Anonymous], 2016, INT C LEARN REPR ICL
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], UNSUPERVISED REVERSE
   [Anonymous], 2015, 3 INT C LEARNING REP
   [Anonymous], 2017, P C COMP VIS PATT RE
   [Anonymous], 2016, 4 INT C LEARN REPR I
   [Anonymous], 2015, TECH REP
   [Anonymous], 2017, PROC INT C NEURAL IN
   [Anonymous], 2016, P INT C MACH LEARN I
   [Anonymous], 2016, P INT C LEARN REPR I
   [Anonymous], IMAGE AUGMENTATION M
   [Anonymous], 2016, P 4 INT C LEARN REPR
   [Anonymous], 2017, P INT C COMP VIS ICC
   [Anonymous], 2015, ADV NEUR IN
   [Anonymous], P ISMIR SUZH CHIN
   [Anonymous], 2018, ADV NEUR IN
   [Anonymous], 2016, DISTILL
   [Anonymous], P SPIE
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Park S., 2015, POLYP DETECTION COLO
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi Q, 2018, IEEE ACCESS, V6, P25486, DOI 10.1109/ACCESS.2017.2773142
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.20073, 10.3322/caac.21551, 10.3322/caac.21654, 10.3322/caac.21254, 10.3322/caac.21387, 10.3322/caac.21669]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
NR 39
TC 41
Z9 42
U1 4
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2018
VL 6
BP 56007
EP 56017
DI 10.1109/ACCESS.2018.2872717
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA GY1OJ
UT WOS:000448300700001
OA gold, Green Submitted, Green Published
DA 2023-08-21
ER

PT J
AU Xie, XL
   Xing, J
   Kong, N
   Li, C
   Li, JL
   Zhang, ST
AF Xie, Xiaolei
   Xing, Jie
   Kong, Nan
   Li, Chong
   Li, Jinlin
   Zhang, Shutian
TI Improving Colorectal Polyp Classification Based on Physical Examination
   Data-An Ensemble Learning Approach
SO IEEE ROBOTICS AND AUTOMATION LETTERS
LA English
DT Article
DE Colorectal polyp; ensemble learning; health care management; incidence
   prediction; physical examination; random forests; risk assessment;
   screening colonoscopy
ID LIFE-STYLE FACTORS; RISK; CANCER; IMPACT; COLONOSCOPY
AB Colorectal canceris a common type of cancer. Due to the alarming incidence and mortality rate, it has received increasing attention on early detection and treatment. Colorectal polyps form and grow at initial stages of most colorectal cancer cases. Due to rather stringent medical resource availability and low screening compliance rate, it is more desirable in China than industrialized countries to characterize the relations between colorectalpolyp occurrence and various potential determinants, including basic health information, comorbidities, and lifestyle conditions. Subsequently, one can better predict polyp incidence for each individual. In this letter, we report a data-driven modeling study to improve binary classification of colorectal polyp occurrence. We apply several machine-learning methods, particularly random forests, for physical examination and screening colonoscopy results of a Chinese cohort, to build the classifiers. Our results suggest improved prediction performance with the random forests model. Our study also provides evidence to support the general speculation that emotional status may be an influential risk factor to early colorectal cancer growth in China.
C1 [Xie, Xiaolei] Tsinghua Univ, Dept Ind Engn, Beijing 100084, Peoples R China.
   [Xing, Jie; Zhang, Shutian] Capital Med Univ, Beijing Friendship Hosp, Dept Gastroenterol, Beijing 100050, Peoples R China.
   [Kong, Nan] Purdue Univ, Weldon Sch Biomed Engn, W Lafayette, IN 47907 USA.
   [Li, Chong; Li, Jinlin] Beijing Inst Technol, Sch Management & Econ, Beijing 100081, Peoples R China.
C3 Tsinghua University; Capital Medical University; Purdue University
   System; Purdue University; Purdue University West Lafayette Campus;
   Beijing Institute of Technology
RP Li, JL (通讯作者)，Beijing Inst Technol, Sch Management & Econ, Beijing 100081, Peoples R China.
EM xxie@tsinghua.edu.cn; xingjie0315@126.com; nkong@purdue.edu;
   lichongbit@163.com; jinlinli@bit.edu.cn
FU National Natural Science Foundation of China [71432002, 71672006,
   71501109]; NIH/NCI National [106511]; Center for Data-Centric Management
   in the Department of Industrial Engineering, Tsinghua University; U.S.
   National Cancer Institute [106511]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 71432002, 71672006, and 71501109, in
   part by the NIH/NCI National under Grant 106511, in part by the Center
   for Data-Centric Management in the Department of Industrial Engineering,
   Tsinghua University, and in part by the U.S. National Cancer Institute
   under Grant 106511.
CR [Anonymous], CANC EPIDEMIOL
   [Anonymous], 2016, J PRACTICAL ONCOL
   [Anonymous], COLORECTAL POLYP
   [Anonymous], INT J COLORECTAL DIS
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brenner H, 2011, ANN INTERN MED, V154, P22, DOI 10.7326/0003-4819-154-1-201101040-00004
   Chen W, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00068
   Colditz GA, 2000, CANCER CAUSE CONTROL, V11, P477, DOI 10.1023/A:1008984432272
   Cottet V, 2012, GUT, V61, P1180, DOI 10.1136/gutjnl-2011-300295
   Freedman AN, 2009, J CLIN ONCOL, V27, P686, DOI 10.1200/JCO.2008.17.4797
   Freedman D. A., 2009, TECHNOMETRICS
   Fu ZM, 2012, AM J EPIDEMIOL, V176, P766, DOI 10.1093/aje/kws157
   Gromping U, 2009, AM STAT, V63, P308, DOI 10.1198/tast.2009.08199
   Hassan C, 2010, DIS COLON RECTUM, V53, P1328, DOI 10.1007/DCR.0b013e3181e10daa
   Huxley RR, 2009, INT J CANCER, V125, P171, DOI 10.1002/ijc.24343
   Imperiale TF, 2003, ANN INTERN MED, V139, P959, DOI 10.7326/0003-4819-139-12-200312160-00005
   ISBISTER WH, 1986, AUST NZ J SURG, V56, P717, DOI 10.1111/j.1445-2197.1986.tb02379.x
   LOTFI AM, 1986, MAYO CLIN PROC, V61, P337, DOI 10.1016/S0025-6196(12)61950-8
   Martinez ME, 2009, GASTROENTEROLOGY, V136, P832, DOI 10.1053/j.gastro.2008.12.007
   Miles J., 2005, ENCY STAT BEHAV SCI
   MURAKAMI R, 1990, INT J CANCER, V46, P159, DOI 10.1002/ijc.2910460203
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Schoen RE, 2003, AM J GASTROENTEROL, V98, P1237, DOI 10.1016/S0002-9270(03)00271-5
   Shin A, 2008, CANCER EPIDEM BIOMAR, V17, P320, DOI 10.1158/1055-9965.EPI-07-0615
   Shrubsole MJ, 2008, AM J EPIDEMIOL, V167, P1050, DOI 10.1093/aje/kwm400
   Sterne JAC, 2009, BMJ-BRIT MED J, V339, DOI 10.1136/bmj.b2393
   Torre LA, 2015, CA-CANCER J CLIN, V65, P87, DOI 10.3322/caac.21262
   Usher-Smith JA, 2016, CANCER PREV RES, V9, P13, DOI 10.1158/1940-6207.CAPR-15-0274
   Wei EK, 2009, AM J EPIDEMIOL, V170, P863, DOI 10.1093/aje/kwp210
   Weitz J, 2005, LANCET, V365, P153, DOI 10.1016/S0140-6736(05)17706-X
   Williams TGS, 2016, BMC GASTROENTEROL, V16, DOI 10.1186/s12876-016-0475-7
NR 32
TC 5
Z9 5
U1 0
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2377-3766
J9 IEEE ROBOT AUTOM LET
JI IEEE Robot. Autom. Lett.
PD JAN
PY 2018
VL 3
IS 1
BP 434
EP 441
DI 10.1109/LRA.2017.2746918
PG 8
WC Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Robotics
GA FM1DN
UT WOS:000414713800001
DA 2023-08-21
ER

PT J
AU Rahmatallah, Y
   Khaidakov, M
   Lai, KK
   Goyne, HE
   Lamps, LW
   Hagedorn, CH
   Glazko, G
AF Rahmatallah, Yasir
   Khaidakov, Magomed
   Lai, Keith K.
   Goyne, Hannah E.
   Lamps, Laura W.
   Hagedorn, Curt H.
   Glazko, Galina
TI Platform-independent gene expression signature differentiates sessile
   serrated adenomas/polyps and hyperplastic polyps of the colon
SO BMC MEDICAL GENOMICS
LA English
DT Article
DE Sessile serrated adenoma/polys; Hyperplastic polyps; Molecular
   signature; RNA-seq; Microarrays; Formalin-fixed paraffin-embedded;
   Shrunken centroid classifier; Summary metric; Feature selection;
   Cantelli's inequality
ID EPITHELIAL-MESENCHYMAL TRANSITION; COLORECTAL-CANCER; POOR-PROGNOSIS;
   RNA-SEQ; DOWN-REGULATION; BREAST-CANCER; PEPTIDE YY; MICROARRAY;
   COLONOSCOPY; PREVALENCE
AB Background: Sessile serrated adenomas/polyps are distinguished from hyperplastic colonic polyps subjectively by their endoscopic appearance and histological morphology. However, hyperplastic and sessile serrated polyps can have overlapping morphological features resulting in sessile serrated polyps diagnosed as hyperplastic. While sessile serrated polyps can progress into colon cancer, hyperplastic polyps have virtually no risk for colon cancer. Objective measures, differentiating these types of polyps would improve cancer prevention and treatment outcome.
   Methods: RNA-seq training data set and Affimetrix, Illumina testing data sets were obtained from Gene Expression Omnibus (GEO). RNA-seq single-end reads were filtered with FastX toolkit. Read mapping to the human genome, gene abundance estimation, and differential expression analysis were performed with Tophat-Cufflinks pipeline. Background correction, normalization, and probe summarization steps for Affimetrix arrays were performed using the robust multi-array method (RMA). For Illumina arrays, log(2)-scale expression data was obtained from GEO. Pathway analysis was implemented using Bioconductor package GSAR. To build a platform-independent molecular classifier that accurately differentiates sessile serrated and hyperplastic polyps we developed a new feature selection step. We also developed a simple procedure to classify new samples as either sessile serrated or hyperplastic with a class probability assigned to the decision, estimated using Cantelli's inequality.
   Results: The classifier trained on RNA-seq data and tested on two independent microarray data sets resulted in zero and three errors. The classifier was further tested using quantitative real-time PCR expression levels of 45 blinded independent formalin-fixed paraffin-embedded specimens and was highly accurate. Pathway analyses have shown that sessile serrated polyps are distinguished from hyperplastic polyps and normal controls by: up-regulation of pathways implicated in proliferation, inflammation, cell-cell adhesion and down-regulation of serine threonine kinase signaling pathway; differential co-expression of pathways regulating cell division, protein trafficking and kinase activities.
   Conclusions: Most of the differentially expressed pathways are known as hallmarks of cancer and likely to explain why sessile serrated polyps are more prone to neoplastic transformation than hyperplastic. The new molecular classifier includes 13 genes and may facilitate objective differentiation between two polyps.
C1 [Rahmatallah, Yasir; Glazko, Galina] Univ Arkansas Med Sci, Dept Biomed Informat, Little Rock, AR 72205 USA.
   [Khaidakov, Magomed; Hagedorn, Curt H.] Cent Arkansas Vet Healthcare Syst, Little Rock, AR 72205 USA.
   [Khaidakov, Magomed; Hagedorn, Curt H.] Univ Arkansas Med Sci, Div Gastroenterol & Hepatol, Dept Med, Little Rock, AR 72205 USA.
   [Goyne, Hannah E.; Lamps, Laura W.] Univ Arkansas Med Sci, Dept Pathol, Little Rock, AR 72205 USA.
   [Lai, Keith K.] Cleveland Clin, Dept Anat Pathol, Cleveland, OH 44195 USA.
C3 University of Arkansas System; University of Arkansas Medical Sciences;
   US Department of Veterans Affairs; Veterans Health Administration (VHA);
   Central Arkansas Veterans Healthcare System; University of Arkansas
   System; University of Arkansas Medical Sciences; University of Arkansas
   System; University of Arkansas Medical Sciences; Cleveland Clinic
   Foundation
RP Glazko, G (通讯作者)，Univ Arkansas Med Sci, Dept Biomed Informat, Little Rock, AR 72205 USA.
EM gvglazko@uams.edu
RI Lai, Keith/AAX-3945-2021
OI Lai, Keith/0000-0002-5727-6900; Rahmatallah, Yasir/0000-0002-8176-6328;
   Khaidakov, Magomed/0000-0003-4834-1077
FU Arkansas Biosciences Institute [UL1TR000039]; NIH [CA148068, CA176130];
   NIH IDeA Networks of Biomedical Research Excellence (INBRE) grant
   [P20GM103429]; Center for Translational Pediatric Research (CTPR) NIH
   Center of Biomedical Research Excellence award [P20GM121293]; National
   Science Foundation [CRI CNS-0855248, EPS-0701890, MRI CNS-0619069,
   OISE-0729792]
FX Support has been provided in part by the Arkansas Biosciences Institute
   under grant UL1TR000039, NIH CA148068, NIH CA176130, the NIH IDeA
   Networks of Biomedical Research Excellence (INBRE) grant P20GM103429,
   and by Center for Translational Pediatric Research (CTPR) NIH Center of
   Biomedical Research Excellence award P20GM121293. This work employed the
   High Performance Computing (HPC) resources at the UALR Computational
   Research Center that is supported by the following grants: National
   Science Foundation grants CRI CNS-0855248, EPS-0701890, MRI CNS-0619069,
   and OISE-0729792. None of the funding bodies had a role in the design of
   the study and collection, analysis, and interpretation of data and in
   writing the manuscript.
CR Abdeljawad K, 2015, GASTROINTEST ENDOSC, V81, P517, DOI 10.1016/j.gie.2014.04.064
   Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501
   Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699
   [Anonymous], 1972, PROBABILITY STAT ENG
   [Anonymous], GASTROENTEROLOGY RES
   Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556
   Ball HJ, 2009, INT J BIOCHEM CELL B, V41, P467, DOI 10.1016/j.biocel.2008.01.005
   Baron KD, 2015, BBA-MOL CELL RES, V1853, P1683, DOI 10.1016/j.bbamcr.2015.04.003
   Bartley AN, 2010, MODERN PATHOL, V23, P169, DOI 10.1038/modpathol.2009.155
   Beggs AD, 2013, PLOS GENET, V9, DOI 10.1371/journal.pgen.1003488
   Bettington M, 2013, HISTOPATHOLOGY, V62, P367, DOI 10.1111/his.12055
   Byrne JA, 2014, TUMOR BIOL, V35, P7369, DOI 10.1007/s13277-014-2006-x
   Carrega P, 2016, IMMUNOL LETT, V179, P29, DOI 10.1016/j.imlet.2016.06.003
   Caruso M, 2009, VIRCHOWS ARCH, V454, P291, DOI 10.1007/s00428-009-0731-0
   Castaldi PJ, 2011, BRIEF BIOINFORM, V12, P189, DOI 10.1093/bib/bbq073
   Chang CQ, 2015, GENET MED, V17, P431, DOI 10.1038/gim.2014.133
   Chen J, 2015, CANCER RES, V75, P4198, DOI 10.1158/0008-5472.CAN-15-1062
   Chibon F, 2013, EUR J CANCER, V49, P2000, DOI 10.1016/j.ejca.2013.02.021
   Cleven AHG, 2014, CLIN CANCER RES, V20, P3261, DOI 10.1158/1078-0432.CCR-12-3734
   Dave SS, 2004, NEW ENGL J MED, V351, P2159, DOI 10.1056/NEJMoa041869
   De Sousa E Melo F, 2013, NAT MED, V19, P614, DOI 10.1038/nm.3174
   de Veer MJ, 2001, J LEUKOCYTE BIOL, V69, P912
   Delker DA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088367
   El-Salhy M, 2013, INT J MOL MED, V31, P275, DOI 10.3892/ijmm.2012.1222
   Erichsen R, 2016, GASTROENTEROLOGY, V150, P895, DOI 10.1053/j.gastro.2015.11.046
   Fallarino F, 2003, ADV EXP MED BIOL, V527, P183
   Fang YJ, 2009, INT J COLORECTAL DIS, V24, P875, DOI 10.1007/s00384-009-0725-z
   Fumagalli D, 2014, BMC GENOMICS, V15, DOI 10.1186/1471-2164-15-1008
   Galamb O, 2008, CANCER EPIDEM BIOMAR, V17, P2835, DOI 10.1158/1055-9965.EPI-08-0231
   Gibson JA, 2011, AM J SURG PATHOL, V35, P742, DOI 10.1097/PAS.0b013e31821537a2
   Glebov OK, 2003, CANCER EPIDEM BIOMAR, V12, P755
   Gonzalo DH, 2013, J PATHOL, V230, P420, DOI 10.1002/path.4200
   Gray RG, 2011, J CLIN ONCOL, V29, P4611, DOI 10.1200/JCO.2010.32.8732
   Hamada S, 2012, FRONT PHYSIOL, V3, DOI 10.3389/fphys.2012.00254
   Hanahan D, 2011, CELL, V144, P646, DOI 10.1016/j.cell.2011.02.013
   Hendrix A, 2010, JNCI-J NATL CANCER I, V102, P866, DOI 10.1093/jnci/djq153
   Hewish M, 2010, NAT REV CLIN ONCOL, V7, P197, DOI 10.1038/nrclinonc.2010.18
   Higuchi T, 2004, J CLIN PATHOL, V57, P682, DOI 10.1136/jcp.2003.015230
   Iansante V, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8882
   IJspeert Joep Evert Godfried, 2015, Gastrointest Endosc Clin N Am, V25, P169, DOI 10.1016/j.giec.2014.11.004
   Irizarry RA, 2003, BIOSTATISTICS, V4, P249, DOI 10.1093/biostatistics/4.2.249
   Ishigooka S, 2012, WORLD J GASTROENTERO, V18, P4308, DOI 10.3748/wjg.v18.i32.4308
   Kahi CJ, 2012, GASTROINTEST ENDOSC, V75, P515, DOI 10.1016/j.gie.2011.08.021
   Kahi CJ, 2011, CLIN GASTROENTEROL H, V9, P42, DOI 10.1016/j.cgh.2010.09.013
   Kanth P, 2016, CANCER PREV RES, V9, P456, DOI 10.1158/1940-6207.CAPR-15-0363
   Kim JU, 2016, J NANOMATER, V2016, DOI 10.1155/2016/7602395
   Lagal V, 2014, J CELL SCI, V127, P328, DOI 10.1242/jcs.130161
   Langmead B, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-3-r25
   Lascorz J, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018867
   Lash RH, 2010, J CLIN PATHOL, V63, P681, DOI 10.1136/jcp.2010.075507
   Levin B, 2008, CA-CANCER J CLIN, V58, P130, DOI 10.3322/CA.2007.0018
   Li HJ, 2011, DIABETES OBES METAB, V13, P5, DOI 10.1111/j.1463-1326.2011.01438.x
   Li J, 2013, MOL BIOL CELL, V24, P3569, DOI 10.1091/mbc.E13-05-0273
   Liberzon A, 2011, BIOINFORMATICS, V27, P1739, DOI 10.1093/bioinformatics/btr260
   Lieberman DA, 2000, NEW ENGL J MED, V343, P162, DOI 10.1056/NEJM200007203430301
   Limketkai BN, 2013, GASTROINTEST ENDOSC, V77, P360, DOI 10.1016/j.gie.2012.11.013
   Manning S, 2014, ANNU REV PHYSIOL, V76, P585, DOI 10.1146/annurev-physiol-021113-170404
   Marioni JC, 2008, GENOME RES, V18, P1509, DOI 10.1101/gr.079558.108
   McVey M, 2008, TRENDS GENET, V24, P529, DOI 10.1016/j.tig.2008.08.007
   Mestdagh P, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-6-r64
   Opitz CA, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019823
   Oshimori N, 2006, NAT CELL BIOL, V8, P1095, DOI 10.1038/ncb1474
   Owens SR, 2008, MODERN PATHOL, V21, P660, DOI 10.1038/modpathol.2008.55
   Pavelitz T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108483
   Payne SR, 2014, CLIN GASTROENTEROL H, V12, P1119, DOI 10.1016/j.cgh.2013.11.034
   Pope JL, 2014, MOL CANCER, V13, DOI 10.1186/1476-4598-13-167
   Prendergast GC, 2014, CANCER IMMUNOL IMMUN, V63, P721, DOI 10.1007/s00262-014-1549-4
   Prendergast GC, 2010, AM J PATHOL, V176, P2082, DOI 10.2353/ajpath.2010.091173
   Quintero E, 2012, NEW ENGL J MED, V366, P697, DOI [10.1056/NEJMoa1108895, 10.1056/NEJMx150040]
   Rahmatallah Y, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1482-6
   Rahmatallah Y, 2014, BIOINFORMATICS, V30, P360, DOI 10.1093/bioinformatics/btt687
   Rex DK, 2012, AM J GASTROENTEROL, V107, P1315, DOI 10.1038/ajg.2012.161
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Salazar R, 2011, J CLIN ONCOL, V29, P17, DOI 10.1200/JCO.2010.30.1077
   Samarajiwa SA, 2009, NUCLEIC ACIDS RES, V37, pD852, DOI 10.1093/nar/gkn732
   SAVAGE R, 1961, J RES NBS B MATH SCI, V65, P211, DOI 10.6028/jres.065B.020
   Scolnick DM, 2000, NATURE, V406, P430, DOI 10.1038/35019108
   Shan ZZ, 2015, AM J CANCER RES, V5, P344
   Shi W, 2010, PHARMACOGENOMICS J, V10, P310, DOI 10.1038/tpj.2010.35
   Shon WJ, 2015, SCI REP-UK, V5, DOI 10.1038/srep17305
   Simon R, 2005, J CLIN ONCOL, V23, P7332, DOI 10.1200/JCO.2005.02.8712
   Starodub AN, 2015, CLIN CANCER RES, V21, P3870, DOI 10.1158/1078-0432.CCR-14-3321
   Su ZQ, 2014, GENOME BIOL, V15, DOI 10.1186/s13059-014-0523-y
   Tarca AL, 2013, BIOINFORMATICS, V29, P2892, DOI 10.1093/bioinformatics/btt492
   Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299
   Tinmouth J, 2014, AM J GASTROENTEROL, V109, P1698, DOI 10.1038/ajg.2014.78
   Torlakovic E, 1996, GASTROENTEROLOGY, V110, P748, DOI 10.1053/gast.1996.v110.pm8608884
   Torlakovic E, 2003, AM J SURG PATHOL, V27, P65, DOI 10.1097/00000478-200301000-00008
   Torlakovic EE, 2008, AM J SURG PATHOL, V32, P21, DOI 10.1097/PAS.0b013e318157f002
   Trapnell C, 2013, NAT BIOTECHNOL, V31, P46, DOI 10.1038/nbt.2450
   Trapnell C, 2012, NAT PROTOC, V7, P562, DOI 10.1038/nprot.2012.016
   Uyttenhove C, 2003, NAT MED, V9, P1269, DOI 10.1038/nm934
   Wang C, 2014, NAT BIOTECHNOL, V32, P926, DOI 10.1038/nbt.3001
   Wang GH, 2014, MOL CANCER THER, V13, P1837, DOI 10.1158/1535-7163.MCT-14-0049
   Wang XW, 2012, NUCLEIC ACIDS RES, V40, pD1144, DOI 10.1093/nar/gkr1013
   Weiss A, 2013, WIRES DEV BIOL, V2, P47, DOI 10.1002/wdev.86
   Wu D, 2010, BIOINFORMATICS, V26, P2176, DOI 10.1093/bioinformatics/btq401
   Xiong SB, 2014, P NATL ACAD SCI USA, V111, P11145, DOI 10.1073/pnas.1404139111
   Yamanami H, 2007, CANCER SCI, V98, P299, DOI 10.1111/j.1349-7006.2007.00403.x
   Yu XC, 2005, NAT GENET, V37, P401, DOI 10.1038/ng1538
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhang JX, 2012, J TRANSL MED, V10, DOI 10.1186/1479-5876-10-242
   Zhao P, 2015, MOL MED REP, V12, P4364, DOI 10.3892/mmr.2015.3900
NR 103
TC 10
Z9 10
U1 0
U2 12
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 1755-8794
J9 BMC MED GENOMICS
JI BMC Med. Genomics
PD DEC 28
PY 2017
VL 10
AR 81
DI 10.1186/s12920-017-0317-7
PG 18
WC Genetics & Heredity
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Genetics & Heredity
GA FR6LJ
UT WOS:000419177200001
PM 29284484
OA gold, Green Published
DA 2023-08-21
ER

PT J
AU Pogorelov, K
   Riegler, M
   Eskeland, SL
   de Lange, T
   Johansen, D
   Griwodz, C
   Schmidt, PT
   Halvorsen, P
AF Pogorelov, Konstantin
   Riegler, Michael
   Eskeland, Sigrun Losada
   de lange, Thomas
   Johansen, Dag
   Griwodz, Carsten
   Schmidt, Peter Thelin
   Halvorsen, Pal
TI Efficient disease detection in gastrointestinal videos - global features
   versus neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical; Automatic disease detection; Algorithmic screening; Global and
   local image features; Deep learning neural networks; Information
   retrieval; Performance evaluation
ID TEXTURAL FEATURES; POLYP DETECTION; DEEP
AB Analysis of medical videos from the human gastrointestinal (GI) tract for detection and localization of abnormalities like lesions and diseases requires both high precision and recall. Additionally, it is important to support efficient, real-time processing for live feedback during (i) standard colonoscopies and (ii) scalability for massive population-based screening, which we conjecture can be done using a wireless video capsule endoscope (camera-pill). Existing related work in this field does neither provide the necessary combination of accuracy and performance for detecting multiple classes of abnormalities simultaneously nor for particular disease localization tasks. In this paper, a complete end-to-end multimedia system is presented where the aim is to tackle automatic analysis of GI tract videos. The system includes an entire pipeline ranging from data collection, processing and analysis, to visualization. The system combines deep learning neural networks, information retrieval, and analysis of global and local image features in order to implement multi-class classification, detection and localization. Furthermore, it is built in a modular way, so that it can be easily extended to deal with other types of abnormalities. Simultaneously, the system is developed for efficient processing in order to provide real-time feedback to the doctors and for scalability reasons when potentially applied for massive population-based algorithmic screenings in the future. Initial experiments show that our system has multi-class detection accuracy and polyp localization precision at least as good as state-of-the-art systems, and provides additional novelty in terms of real-time performance, low resource consumption and ability to extend with support for new classes of diseases.
C1 [Pogorelov, Konstantin; Riegler, Michael; Griwodz, Carsten; Halvorsen, Pal] Simula Res Lab, POB 134, N-1325 Lysaker, Norway.
   [Eskeland, Sigrun Losada; de lange, Thomas] Baerum Hosp, Lysaker, Norway.
   [Johansen, Dag] UiT Arctic Univ Norway, Lysaker, Norway.
   [Schmidt, Peter Thelin] Karolinska Inst, Solna, Sweden.
C3 UiT The Arctic University of Tromso; Karolinska Institutet
RP Pogorelov, K (通讯作者)，Simula Res Lab, POB 134, N-1325 Lysaker, Norway.
EM konstantin@simula.no; michael@simula.no; sigesk@vestreviken.no;
   t.d.lange@medisin.uio.no; dag.johansen@uit.no; griff@simula.no;
   peter.thelin-schmidt@karolinska.se; paalh@ifi.uio.no
RI Riegler, Michael A/E-5443-2015; de Lange, Thomas/Q-9063-2016
OI Riegler, Michael A/0000-0002-3153-2064; de Lange,
   Thomas/0000-0003-3989-7487; Halvorsen, Pal/0000-0003-2073-7029
FU FRINATEK project "EONS" [231687]
FX This work is founded by the FRINATEK project "EONS" #231687.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Albisser Z, 2015, P MMSYS, P73
   Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], 2007, IEEE INT C IMAGE PRO, DOI [10.1109/ICIP.2007.4379193, DOI 10.1109/ICIP.2007.4379193]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Chaabouni S, 2016, IEEE IMAGE PROC, P1604, DOI 10.1109/ICIP.2016.7532629
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Cheng DC, 2008, LECT NOTES ARTIF INT, V5108, P62, DOI 10.1007/978-3-540-70715-8_6
   Chin C, 2000, J RES SCI TEACH, V37, P109, DOI 10.1002/(SICI)1098-2736(200002)37:2<109::AID-TEA3>3.0.CO;2-7
   Darknet Redmon J, OPEN SOURCE NEURAL N
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2014, PR MACH LEARN RES, V32
   Fitzgibbon AW, 1996, BUYERS XGUIDE CONIC
   Hall M, 2009, SIGKDD EXPLOR NEWSL, V11, P10, DOI [DOI 10.1145/1656274.1656278, 10.1145/1656274.1656278]
   Holme O, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD009259.pub2
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kang J, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1469
   Khaleghi A, 2015, IEEE ENG MED BIO, P4081, DOI 10.1109/EMBC.2015.7319291
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Lux M, 2013, SYNT LECT INFORM CON, V5, P1, DOI DOI 10.2200/S00468ED1V01Y201301ICR025
   Mallery S, 2000, MED CLIN N AM, V84, P1059, DOI 10.1016/S0025-7125(05)70276-5
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   NGIAM J, 2011, P 28 INT C MACH LEAR, P265
   Nguyen Anh, 2014, CORR
   O'Connell JB, 2004, JNCI-J NATL CANCER I, V96, P1420, DOI 10.1093/jnci/djh275
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P170, DOI 10.1145/3083187.3083216
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pogorelov K, 2016, COMP MED SY, P185, DOI 10.1109/CBMS.2016.63
   REDMON J, 2016, PROC CVPR IEEE, P779, DOI DOI 10.1109/CVPR.2016.91
   Riegler M., 2016, P 2016 ACM MULTIMEDI, P968, DOI [10.1145/2964284.2976760, DOI 10.1145/2964284.2976760]
   Riegler M, 2016, P MMSYS, P29
   Riegler M., 2016, 2016 14 INT WORKSHOP, P1, DOI [10.1109/CBMI.2016.7500257, DOI 10.1109/CBMI.2016.7500257]
   Riegler M, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3079765
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Stewart R, 2015, END TO END PEOPLE DE
   Szegedy C., 2015, PROC IEEE C COMPUT V, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C., 2016, P IEEE C COMP VIS PA
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tanimoto TT, 1958, LEMENTARY MATH THEOR
   Tieleman T, 2012, NEURAL NETWORKS MACH, V4
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   von Karsa L, 2012, ENDOSCOPY, V44, pSE1, DOI 10.1055/s-0032-1309822
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Zagoris Konstantinos, 2010, Proceedings of the 14th Panhellenic Conference on Informatics (PCI 2010), P143, DOI 10.1109/PCI.2010.38
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
NR 51
TC 33
Z9 33
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22493
EP 22525
DI 10.1007/s11042-017-4989-y
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200032
OA Green Accepted, hybrid, Green Published
DA 2023-08-21
ER

PT J
AU Petrossians, P
   Daly, AF
   Natchev, E
   Maione, L
   Blijdorp, K
   Sahnoun-Fathallah, M
   Auriemma, R
   Diallo, AM
   Hulting, AL
   Ferone, D
   Hana, V
   Filipponi, S
   Sievers, C
   Nogueira, C
   Fajardo-Montanana, C
   Carvalho, D
   Hana, V
   Stalla, GK
   Jaffrain-Rea, ML
   Delemer, B
   Colao, A
   Brue, T
   Neggers, SJCMM
   Zacharieva, S
   Chanson, P
   Beckers, A
AF Petrossians, Patrick
   Daly, Adrian F.
   Natchev, Emil
   Maione, Luigi
   Blijdorp, Karin
   Sahnoun-Fathallah, Mona
   Auriemma, Renata
   Diallo, Alpha M.
   Hulting, Anna-Lena
   Ferone, Diego
   Hana, Vaclav, Jr.
   Filipponi, Silvia
   Sievers, Caroline
   Nogueira, Claudia
   Fajardo-Montanana, Carmen
   Carvalho, Davide
   Hana, Vaclav
   Stalla, Guenter K.
   Jaffrain-Rea, Marie-Lise
   Delemer, Brigitte
   Colao, Annamaria
   Brue, Thierry
   Neggers, Sebastian J. C. M. M.
   Zacharieva, Sabina
   Chanson, Philippe
   Beckers, Albert
TI Acromegaly at diagnosis in 3173 patients from the Liege Acromegaly
   Survey (LAS) Database
SO ENDOCRINE-RELATED CANCER
LA English
DT Article
DE acromegaly; comorbidity; database; data mining; diagnosis; growth
   hormone; IGF-1; pituitary adenoma; symptoms
ID GROWTH-HORMONE REPLACEMENT; NORMAL GH SECRETION; LONG-TERM TREATMENT;
   PITUITARY-ADENOMAS; FOLLOW-UP; CLINICAL CHARACTERISTICS; SOMATOSTATIN
   ANALOGS; POLYCYTHEMIA-VERA; IGF-I; MORTALITY
AB Acromegaly is a rare disorder caused by chronic growth hormone (GH) hypersecretion. While diagnostic and therapeutic methods have advanced, little information exists on trends in acromegaly characteristics over time. The Liege Acromegaly Survey (LAS) Database, a relational database, is designed to assess the profile of acromegaly patients at diagnosis and during long-term follow-up at multiple treatment centers. The following results were obtained at diagnosis. The study population consisted of 3173 acromegaly patients from ten countries; 54.5% were female. Males were significantly younger at diagnosis than females (43.5 vs 46.4 years; P < 0.001). The median delay from first symptoms to diagnosis was 2 years longer in females (P = 0.015). Ages at diagnosis and first symptoms increased significantly over time (P < 0.001). Tumors were larger in males than females (P < 0.001); tumor size and invasion were inversely related to patient age (P < 0.001). Random GH at diagnosis correlated with nadir GH levels during OGTT (P < 0.001). GH was inversely related to age in both sexes (P < 0.001). Diabetes mellitus was present in 27.5%, hypertension in 28.8%, sleep apnea syndrome in 25.5% and cardiac hypertrophy in 15.5%. Serious cardiovascular outcomes like stroke, heart failure and myocardial infarction were present in <5% at diagnosis. Erythrocyte levels were increased and correlated with IGF-1 values. Thyroid nodules were frequent (34.0%); 820 patients had colonoscopy at diagnosis and 13% had polyps. Osteoporosis was present at diagnosis in 12.3% and 0.6-4.4% had experienced a fracture. In conclusion, this study of >3100 patients is the largest international acromegaly database and shows clinically relevant trends in the characteristics of acromegaly at diagnosis.
C1 [Petrossians, Patrick; Daly, Adrian F.; Beckers, Albert] Univ Liege, CHU Liege, Dept Endocrinol, Liege, Belgium.
   [Natchev, Emil; Zacharieva, Sabina] Med Univ, Clin Ctr Endocrinol & Gerontol, Sofia, Bulgaria.
   [Maione, Luigi; Chanson, Philippe] Paris Sud Univ, APHP Endocrinol & Reprod Dis, Le Kremlin Bicetre, France.
   [Blijdorp, Karin; Neggers, Sebastian J. C. M. M.] Erasmus Univ, Med Ctr, Dept Med, Sect Endocrinol, Rotterdam, Netherlands.
   [Sahnoun-Fathallah, Mona; Brue, Thierry] Hop La Timone, Ctr Reference Malad Rares Origine Hypophysaire, Dept Endocrinol, Marseille, France.
   [Auriemma, Renata; Colao, Annamaria] Univ Federico II, Sez Endocrinol, Dipartimento Med Clin & Chirurg, Naples, Italy.
   [Diallo, Alpha M.; Delemer, Brigitte] CHU Reims, Dept Endocrinol, Reims, France.
   [Hulting, Anna-Lena] Karolinska Univ Hosp, Dept Mol Med & Surg, Stockholm, Sweden.
   [Ferone, Diego] Univ Genoa, Dept Internal Med, Genoa, Italy.
   [Hana, Vaclav, Jr.; Hana, Vaclav] Charles Univ Prague, Fac Med 1, Dept Internal Med 3, Prague, Czech Republic.
   [Filipponi, Silvia; Jaffrain-Rea, Marie-Lise] Univ Aquila, Dept Biotechnol & Appl Clin Sci, Laquila, Italy.
   [Filipponi, Silvia; Jaffrain-Rea, Marie-Lise] IRCCS, Neuromed, Pozzilli, Italy.
   [Sievers, Caroline; Stalla, Guenter K.] Max Planck Inst Psychiat, Dept Internal Med Endocrinol & Clin Chem, Munich, Germany.
   [Nogueira, Claudia] Ctr Hosp Tras Os Montes & Alto Douro, Diabet & Metab Unit, Dept Internal Med, Endocrinol, Oporto, Portugal.
   [Fajardo-Montanana, Carmen] Hosp Univ Ribera, Dept Endocrinol, Alzira, Spain.
   [Carvalho, Davide] Univ Porto, Fac Med, Inst Invest & Inovacao Saude, Dept Endocrinol Diabet & Metab,Ctr Hosp S Joao, Oporto, Portugal.
C3 University of Liege; Medical University Sofia; Assistance Publique
   Hopitaux Paris (APHP); Hopital Universitaire Bicetre - APHP;
   UDICE-French Research Universities; Universite Paris Saclay; Erasmus
   University Rotterdam; Erasmus MC; Erasmus University Rotterdam - Excl
   Erasmus MC; UDICE-French Research Universities; Aix-Marseille
   Universite; Assistance Publique-Hopitaux de Marseille; University of
   Naples Federico II; CHU de Reims; Universite de Reims Champagne-Ardenne;
   Karolinska Institutet; Karolinska University Hospital; University of
   Genoa; Charles University Prague; University of L'Aquila; IRCCS
   Neuromed; Max Planck Society; Sao Joao Hospital; Universidade do Porto;
   i3S - Instituto de Investigacao e Inovacao em Saude, Universidade do
   Porto
RP Beckers, A (通讯作者)，Univ Liege, CHU Liege, Dept Endocrinol, Liege, Belgium.
EM albert.beckers@chu.ulg.ac.be
RI Jaffrain-Rea, Marie-Lise/D-1129-2009; Carvalho, Davide/AAR-2081-2020;
   Natchev, Emil/HLX-0027-2023; Hana, Vaclav/N-6429-2017; Rea, Marie Lise
   Jaffrain/AAK-9443-2021; Zacharieva, Sabina/GQO-9261-2022; Maione,
   Luigi/N-5300-2019; Brue, Thierry/P-6571-2019; Brue,
   Thierry/AAI-2328-2019; Daly, Adrian F/E-2178-2011; Hána,
   Václav/N-3853-2017; Ferone, Diego/K-1238-2018; Chanson,
   Philippe/F-8511-2013
OI Jaffrain-Rea, Marie-Lise/0000-0002-5916-8997; Carvalho,
   Davide/0000-0002-3156-3741; Natchev, Emil/0000-0001-8689-3222; Hana,
   Vaclav/0000-0003-0001-9935; Rea, Marie Lise
   Jaffrain/0000-0002-5916-8997; Zacharieva, Sabina/0000-0001-6087-7136;
   Maione, Luigi/0000-0001-8526-8046; Brue, Thierry/0000-0001-8482-6691;
   Brue, Thierry/0000-0001-8482-6691; Daly, Adrian F/0000-0001-6130-2975;
   Hána, Václav/0000-0002-6690-1413; Ferone, Diego/0000-0002-1410-6143;
   Beckers, Albert/0000-0001-6351-1367; Fajardo-Montanana,
   Carmen/0000-0002-0784-0761; Chanson, Philippe/0000-0001-5096-5722
FU Ipsen
FX This study was supported by an unrestricted educational grant from
   Ipsen. The study funder had no role in the collection of data, had no
   access to the data and had no involvement in the writing of this
   manuscript.
CR Alexopoulou O, 2008, J CLIN ENDOCR METAB, V93, P1324, DOI 10.1210/jc.2007-2104
   Attal P, 2010, J CLIN ENDOCR METAB, V95, P483, DOI 10.1210/jc.2009-1912
   Bergamaschi S, 2006, J ENDOCRINOL INVEST, V29, P399, DOI 10.1007/BF03344122
   Bernabeu I, 2016, PITUITARY, V19, P127, DOI 10.1007/s11102-015-0691-0
   Bex M, 2007, EUR J ENDOCRINOL, V157, P399, DOI 10.1530/EJE-07-0358
   Burton T, 2016, PITUITARY, V19, P262, DOI 10.1007/s11102-015-0701-2
   Butz LB, 2016, PITUITARY, V19, P547, DOI 10.1007/s11102-016-0735-0
   Christ ER, 1997, J CLIN ENDOCR METAB, V82, P2985, DOI 10.1210/jc.82.9.2985
   Daly AF, 2006, J CLIN ENDOCR METAB, V91, P4769, DOI 10.1210/jc.2006-1668
   Daly AF, 2010, J CLIN ENDOCR METAB, V95, pE373, DOI 10.1210/jc.2009-2556
   De Parijat, 2014, BMJ Case Rep, V2014, DOI 10.1136/bcr-2013-202622
   Dekkers OM, 2008, J CLIN ENDOCR METAB, V93, P61, DOI 10.1210/jc.2007-1191
   Dimaraki EV, 2002, J CLIN ENDOCR METAB, V87, P3537, DOI 10.1210/jc.87.8.3537
   Esposito A, 2016, ENDOCRINE, V53, P192, DOI 10.1007/s12020-015-0781-9
   Fernandez A, 2010, CLIN ENDOCRINOL, V72, P377, DOI 10.1111/j.1365-2265.2009.03667.x
   Franck SE, 2017, EUR J ENDOCRINOL, V176, P421, DOI 10.1530/EJE-16-0956
   Freda PU, 2015, ENDOCR PRACT, V21, P264, DOI 10.4158/EP14330.OR
   Giustina A, 2010, J CLIN ENDOCR METAB, V95, P3141, DOI 10.1210/jc.2009-2670
   Grellier P, 1996, ANN INTERN MED, V124, P495, DOI 10.7326/0003-4819-124-5-199603010-00006
   Hannon AM, 2017, CURR DIABETES REP, V17, DOI 10.1007/s11892-017-0838-7
   Holdaway IM, 2008, EUR J ENDOCRINOL, V159, P89, DOI 10.1530/EJE-08-0267
   JENKINS D, 1995, CLIN ENDOCRINOL, V43, P517, DOI 10.1111/j.1365-2265.1995.tb02913.x
   Katznelson L, 2014, J CLIN ENDOCR METAB, V99, P3933, DOI 10.1210/jc.2014-2700
   Lavrentaki A, 2017, PITUITARY, V20, P4, DOI 10.1007/s11102-016-0754-x
   Lesen E, 2017, EUR J ENDOCRINOL, V176, P203, DOI 10.1530/EJE-16-0623
   Lutz JM, 2003, ANN ONCOL, V14, P313, DOI 10.1093/annonc/mdg059
   Maione L, 2017, EUR J ENDOCRINOL, V176, P645, DOI 10.1530/EJE-16-1064
   Melmed S, 2013, PITUITARY, V16, P294, DOI 10.1007/s11102-012-0420-x
   Melmed S, 2017, PITUITARY, 4TH EDITION, P423, DOI 10.1016/B978-0-12-804169-7.00015-5
   Melmed S, 2016, J CLIN ENDOCR METAB, V101, P769, DOI 10.1210/jc.2015-3653
   Mestron A, 2004, EUR J ENDOCRINOL, V151, P439, DOI 10.1530/eje.0.1510439
   Petrossians P, 2012, ANN ENDOCRINOL-PARIS, V73, P190, DOI 10.1016/j.ando.2012.05.001
   Pivonello R, 2017, PITUITARY, V20, P46, DOI 10.1007/s11102-017-0797-7
   Portocarrero-Ortiz LA, 2016, J CLIN ENDOCR METAB, V101, P3997, DOI 10.1210/jc.2016-1937
   Potorac I, 2016, ENDOCR-RELAT CANCER, V23, P871, DOI 10.1530/ERC-16-0356
   Potorac I, 2015, ENDOCR-RELAT CANCER, V22, P169, DOI 10.1530/ERC-14-0305
   Ramos-Levi AM, 2017, ENDOCRINE, V55, P346, DOI 10.1007/s12020-016-1191-3
   Reid TJ, 2010, CLIN ENDOCRINOL, V72, P203, DOI 10.1111/j.1365-2265.2009.03626.x
   Reincke M, 2006, EXP CLIN ENDOCR DIAB, V114, P498, DOI 10.1055/s-2006-948313
   Ritvonen E, 2016, ENDOCR-RELAT CANCER, V23, P469, DOI 10.1530/ERC-16-0106
   Sesmilo G, 2013, PITUITARY, V16, P115, DOI 10.1007/s11102-012-0384-x
   Sherlock M, 2009, CLIN ENDOCRINOL, V71, P74, DOI 10.1111/j.1365-2265.2008.03461.x
   Sherlock M, 2010, ENDOCR REV, V31, P301, DOI 10.1210/er.2009-0033
   Stewart PM, 2012, ANN ENDOCRINOL-PARIS, V73, P81, DOI 10.1016/j.ando.2012.03.026
   Stewart PM, 2004, EUR J ENDOCRINOL, V151, P431, DOI 10.1530/eje.0.1510431
   Studen KB, 2008, J CLIN ENDOCR METAB, V93, P491, DOI 10.1210/jc.2007-1451
   Surchi H, 2017, ENDOCR-RELAT CANCER, V24, pL33, DOI 10.1530/ERC-17-0034
   Teramoto S, 1997, ANN INTERN MED, V126, P87, DOI 10.7326/0003-4819-126-1-199701010-00017
   Theodoropoulou M, 2009, INT J CANCER, V125, P2122, DOI 10.1002/ijc.24602
   Trainer PJ, 2009, EUR J ENDOCRINOL, V161, pS19, DOI 10.1530/EJE-09-0322
   Tritos NA, 2014, J CLIN ENDOCR METAB, V99, P2018, DOI 10.1210/jc.2014-1013
   Valerio G, 1997, HORM RES, V47, P62, DOI 10.1159/000185433
   van der Lely AJ, 2012, J CLIN ENDOCR METAB, V97, P1589, DOI 10.1210/jc.2011-2508
   VANDERLELY AJ, 1992, CLIN ENDOCRINOL, V37, P181
   Zoppoli G, 2012, PITUITARY, V15, P209, DOI 10.1007/s11102-011-0311-6
NR 55
TC 136
Z9 145
U1 0
U2 13
PU BIOSCIENTIFICA LTD
PI BRISTOL
PA EURO HOUSE, 22 APEX COURT WOODLANDS, BRADLEY STOKE, BRISTOL BS32 4JT,
   ENGLAND
SN 1351-0088
EI 1479-6821
J9 ENDOCR-RELAT CANCER
JI Endocr.-Relat. Cancer
PD OCT
PY 2017
VL 24
IS 10
BP 505
EP 518
DI 10.1530/ERC-17-0253
PG 14
WC Oncology; Endocrinology & Metabolism
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology; Endocrinology & Metabolism
GA FH4PU
UT WOS:000411139600012
PM 28733467
OA Green Published, hybrid
DA 2023-08-21
ER

PT J
AU Bernal, J
   Tajkbaksh, N
   Sanchez, FJ
   Matuszewski, BJ
   Chen, H
   Yu, LQ
   Angermann, Q
   Romain, O
   Rustad, B
   Balasingham, I
   Pogorelov, K
   Choi, S
   Debard, Q
   Maier-Hein, L
   Speidel, S
   Stoyanov, D
   Brandao, P
   Cordova, H
   Sanchez-Montes, C
   Gurudu, SR
   Fernandez-Esparrach, G
   Dray, X
   Liang, JM
   Histace, A
AF Bernal, Jorge
   Tajkbaksh, Nima
   Sanchez, Francisco Javier
   Matuszewski, Bogdan J.
   Chen, Hao
   Yu, Lequan
   Angermann, Quentin
   Romain, Olivier
   Rustad, Bjorn
   Balasingham, Ilangko
   Pogorelov, Konstantin
   Choi, Sungbin
   Debard, Quentin
   Maier-Hein, Lena
   Speidel, Stefanie
   Stoyanov, Danail
   Brandao, Patrick
   Cordova, Henry
   Sanchez-Montes, Cristina
   Gurudu, Suryakanth R.
   Fernandez-Esparrach, Gloria
   Dray, Xavier
   Liang, Jianming
   Histace, Aymeric
TI Comparative Validation of Polyp Detection Methods in Video Colonoscopy:
   Results From the MICCAI 2015 Endoscopic Vision Challenge
SO IEEE TRANSACTIONS ON MEDICAL IMAGING
LA English
DT Article
DE Endoscopic vision; polyp detection; handcrafted features; machine
   learning; validation framework
ID CT COLONOGRAPHY; MISS RATE; DIAGNOSIS; ADENOMAS; ACCURACY; SYSTEM;
   IMPACT
AB Colonoscopy is the gold standard for colon cancer screening though some polyps are still missed, thus preventing early disease detection and treatment. Several computational systems have been proposed to assist polyp detection during colonoscopy but so far without consistent evaluation. The lack of publicly available annotated databases has made it difficult to compare methods and to assess if they achieve performance levels acceptable for clinical use. The Automatic Polyp Detection subchallenge, conducted as part of the Endoscopic Vision Challenge (https://hfbicc3c649c5357d4053h0qkw69uxxc656nn5fiac.eds.tju.edu.cn) at the international conference onMedical Image Computing and Computer Assisted Intervention (MICCAI) in 2015, was an effort to address this need. In this paper, we report the results of this comparative evaluation of polyp detection methods, as well as describe additional experiments to further explore differences between methods. We define performance metrics and provide evaluation databases that allow comparison of multiple methodologies. Results show that convolutional neural networks are the state of the art. Nevertheless, it is also demonstrated that combining different methodologies can lead to an improved overall performance.
C1 [Bernal, Jorge; Sanchez, Francisco Javier] Univ Autonoma Barcelona, Dept Comp Sci, Bellaterra 08193, Spain.
   [Bernal, Jorge; Sanchez, Francisco Javier] Univ Autonoma Barcelona, Comp Vis Ctr, Bellaterra 08193, Spain.
   [Tajkbaksh, Nima; Liang, Jianming] Arizona State Univ, Tempe, AZ 85281 USA.
   [Matuszewski, Bogdan J.] Univ Cent Lancashire, Sch Engn, Preston PR1 2HE, Lancs, England.
   [Chen, Hao; Yu, Lequan] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Angermann, Quentin; Romain, Olivier; Dray, Xavier; Histace, Aymeric] Univ Cergy Pontoise, ENSEA, ETIS, CNRS, F-95000 Cergy C, France.
   [Rustad, Bjorn; Balasingham, Ilangko] Oslo Univ Hosp, N-0379 Oslo, Norway.
   [Rustad, Bjorn] Univ Oslo, OmniVis, N-0313 Oslo, Norway.
   [Pogorelov, Konstantin] Simula Res Lab, Media Performance Grp, N-0313 Oslo, Norway.
   [Pogorelov, Konstantin] Univ Oslo, N-0313 Oslo, Norway.
   [Choi, Sungbin] Seoul Natl Univ, Seoul 08826, South Korea.
   [Debard, Quentin] Univ Nice Sophia Antipolis, F-06000 Nice, France.
   [Maier-Hein, Lena] German Canc Res Ctr, Jr Grp Comp Assisted Intervent, D-69120 Heidelberg, Germany.
   [Speidel, Stefanie] Karlsruhe Inst Technol, Inst Anthropomat, D-76021 Karlsruhe, Germany.
   [Stoyanov, Danail; Brandao, Patrick] UCL, Ctr Med Image Comp, London WC1E 6BT, England.
   [Stoyanov, Danail; Brandao, Patrick] UCL, Dept Comp Sci, London WC1E 6BT, England.
   [Cordova, Henry; Sanchez-Montes, Cristina; Fernandez-Esparrach, Gloria] Univ Barcelona, CIBEREHD, IDIBAPS, Endoscopy Unit,Gastroenterol Dept,Hosp Clin, Barcelona, Spain.
   [Gurudu, Suryakanth R.] Mayo Clin, Div Gastroenterol & Hepatol, Scottsdale, AZ 85259 USA.
   [Dray, Xavier] Lariboisiere Hosp, APHP, F-75000 Paris, France.
C3 Autonomous University of Barcelona; Autonomous University of Barcelona;
   Centre de Visio per Computador (CVC); Arizona State University; Arizona
   State University-Tempe; University of Central Lancashire; Chinese
   University of Hong Kong; Centre National de la Recherche Scientifique
   (CNRS); CY Cergy Paris Universite; University of Oslo; University of
   Oslo; University of Oslo; Seoul National University (SNU); UDICE-French
   Research Universities; Universite Cote d'Azur; Helmholtz Association;
   German Cancer Research Center (DKFZ); Helmholtz Association; Karlsruhe
   Institute of Technology; University of London; University College
   London; University of London; University College London; CIBER - Centro
   de Investigacion Biomedica en Red; CIBEREHD; University of Barcelona;
   Hospital Clinic de Barcelona; IDIBAPS; Mayo Clinic; Mayo Clinic Phoenix;
   Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire
   Ambroise-Pare - APHP; Hopital Universitaire Pitie-Salpetriere - APHP;
   UDICE-French Research Universities; Sorbonne Universite; Hopital
   Universitaire Saint-Antoine - APHP; Universite Paris Cite; Hopital
   Universitaire Lariboisiere-Fernand-Widal - APHP
RP Histace, A (通讯作者)，Univ Cergy Pontoise, ENSEA, ETIS, CNRS, F-95000 Cergy C, France.
RI Chen, Hao/V-4299-2019; Córdova, Henry/HJG-5764-2022; Yu,
   Lequan/U-5377-2019; Bernal, Jorge/H-4647-2015; Stoyanov,
   Danail/V-1043-2019; Balasingham, Ilangko/AGU-7268-2022; Speidel,
   Stefanie/K-1959-2017; romain, olivier/AAF-1985-2019; Sánchez, F.
   Javier/H-5591-2015; Cordova Guevara, Henry Nelson/D-7844-2019
OI Chen, Hao/0000-0002-8400-3780; Yu, Lequan/0000-0002-9315-6527; Bernal,
   Jorge/0000-0001-8493-9514; Stoyanov, Danail/0000-0002-0980-3227;
   Speidel, Stefanie/0000-0002-4590-1908; romain,
   olivier/0000-0002-2172-1865; Sánchez, F. Javier/0000-0002-9364-3122;
   Cordova Guevara, Henry Nelson/0000-0002-6636-6764;
   Fernandez-Esparrach/0000-0002-3378-3940; Liang,
   Jianming/0000-0002-3029-341X; Liang, Jianming/0000-0001-5486-1613
FU ASU-Mayo Clinic partnerships; Spanish Government [DPI2015-65286-R];
   FSEED; Secretaria d'Universitats i Recerca de la Generalitat de
   Catalunya [2014-SGR-1470, 2014-SGR-135]; par SATT IdFInnov (France)
   through the Project Smart Videocolonoscopy [186]; European Union through
   the ERC [ERC-2015-StG-37960]; EPSRC [EP/M020533/1, EP/P012841/1,
   EP/N022750/1] Funding Source: UKRI; Engineering and Physical Sciences
   Research Council [EP/P012841/1, EP/M020533/1, EP/N022750/1, 1091178]
   Funding Source: researchfish
FX This work was supported in part by ASU-Mayo Clinic partnerships, in part
   by the Spanish Government through the Funded Project iVENDIS under
   Project DPI2015-65286-R, in part by FSEED, in part by the Secretaria
   d'Universitats i Recerca de la Generalitat de Catalunya under Grant
   2014-SGR-1470 and Grant 2014-SGR-135, in part by par SATT IdFInnov
   (France) through the Project Smart Videocolonoscopy under Grant 186, and
   in part by the European Union through the ERC starting grant COMBIOSCOPY
   under the New Horizon Framework Programme under Grant
   ERC-2015-StG-37960. (Jorge Bernal and Nima Tajbaksh share first
   co-authorship. Aymeric Histace and Jianming Liang share last
   co-authorship) Asterisk indicates corresponding author.
CR Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   Angermann Q, 2016, PROCEDIA COMPUT SCI, V90, P182, DOI 10.1016/j.procs.2016.07.017
   [Anonymous], 2003, GASTROINTEST ENDOSC, V58, pS3
   [Anonymous], 0B SEOUL NAT U DEP T
   [Anonymous], COLORECTAL CANC
   [Anonymous], CONVOLUTIONAL NEURAL
   [Anonymous], 2016, DCAN DEEP CONTOUR AW
   [Anonymous], 2016, P SPIE
   [Anonymous], P SPIE
   [Anonymous], 2007, P ICIP
   Armin MA, 2015, LECT NOTES COMPUT SC, V9349, P396, DOI 10.1007/978-3-319-24553-9_49
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bruno MJ, 2003, GUT, V52, P7
   Burling D, 2010, CLIN RADIOL, V65, P474, DOI 10.1016/j.crad.2009.12.003
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Coriat R, 2008, GASTROEN CLIN BIOL, V32, P363, DOI 10.1016/j.gcb.2007.11.013
   Farnbacher MJ, 2014, SCAND J GASTROENTERO, V49, P339, DOI 10.3109/00365521.2013.865784
   Gschwantler M, 2002, EUR J GASTROEN HEPAT, V14, P183, DOI 10.1097/00042737-200202000-00013
   Gupta N, 2012, GASTROINTEST ENDOSC, V75, P494, DOI 10.1016/j.gie.2011.08.002
   Hassan C, 2013, ENDOSCOPY, V45, P842, DOI 10.1055/s-0033-1344548
   Heimann T, 2009, IEEE T MED IMAGING, V28, P1251, DOI 10.1109/TMI.2009.2013851
   Hoffman A, 2010, ENDOSCOPY, V42, P827, DOI 10.1055/s-0030-1255713
   Hongbin Zhu, 2010, Virtual Colonoscopy and Abdominal Imaging. Computational Challenges and Clinical Opportunities. Second International Workshop Held in Conjunction with MICCAI 2010. Revised Selected Papers, P9, DOI 10.1007/978-3-642-25719-3_2
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Inomata H, 2013, WORLD J GASTROENTERO, V19, P7146, DOI 10.3748/wjg.v19.i41.7146
   Iwahori Y., 2013, PROC INT C MACH VIS, P21
   Jemal A, 2008, CA-CANCER J CLIN, V58, P71, DOI 10.3322/CA.2007.0010
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnson CD, 2008, NEW ENGL J MED, V359, P1207, DOI 10.1056/NEJMoa0800996
   Kang J, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1469
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lebwohl B, 2011, GASTROINTEST ENDOSC, V73, P1207, DOI 10.1016/j.gie.2011.01.051
   Lee C., 2014, DEEPLY SUPERVISED NE
   Lee SH, 2008, GASTROINTEST ENDOSC, V67, P683, DOI 10.1016/j.gie.2007.10.018
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Maier-Hein L, 2014, IEEE T MED IMAGING, V33, P1913, DOI 10.1109/TMI.2014.2325607
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Riegler M, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P397, DOI 10.1145/2647868.2654894
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sevo I, 2016, COMPUT BIOL MED, V72, P138, DOI 10.1016/j.compbiomed.2016.03.017
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Tajbakhsh N, 2014, LECT NOTES COMPUT SC, V8674, P179, DOI 10.1007/978-3-319-10470-6_23
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN
NR 52
TC 213
Z9 224
U1 2
U2 32
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0062
EI 1558-254X
J9 IEEE T MED IMAGING
JI IEEE Trans. Med. Imaging
PD JUN
PY 2017
VL 36
IS 6
BP 1231
EP 1249
DI 10.1109/TMI.2017.2664042
PG 19
WC Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology; Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic
   Technology; Radiology, Nuclear Medicine & Medical Imaging
GA EW7UM
UT WOS:000402722500003
PM 28182555
OA Green Accepted, Green Submitted
DA 2023-08-21
ER

PT J
AU Yuan, YX
   Meng, MQH
AF Yuan, Yixuan
   Meng, Max Q. -H.
TI Deep learning for polyp recognition in wireless capsule endoscopy images
SO MEDICAL PHYSICS
LA English
DT Article
DE image manifold information; polyp recognition; stacked sparse
   autoencoder with image manifold (SSAEIM); wireless capsule endoscopy
   images
AB Purpose: Wireless capsule endoscopy (WCE) enables physicians to examine the digestive tract without any surgical operations, at the cost of a large volume of images to be analyzed. In the computer-aided diagnosis of WCE images, the main challenge arises from the difficulty of robust characterization of images. This study aims to provide discriminative description of WCE images and assist physicians to recognize polyp images automatically.
   Methods: We propose a novel deep feature learning method, named stacked sparse autoencoder with image manifold constraint (SSAEIM), to recognize polyps in the WCE images. Our SSAEIM differs from the traditional sparse autoencoder (SAE) by introducing an image manifold constraint, which is constructed by a nearest neighbor graph and represents intrinsic structures of images. The image manifold constraint enforces that images within the same category share similar learned features and images in different categories should be kept far away. Thus, the learned features preserve large intervariances and small intravariances among images.
   Results: The average overall recognition accuracy (ORA) of our method for WCE images is 98.00%. The accuracies for polyps, bubbles, turbid images, and clear images are 98.00%, 99.50%, 99.00%, and 95.50%, respectively. Moreover, the comparison results show that our SSAEIM outperforms existing polyp recognition methods with relative higher ORA.
   Conclusion: The comprehensive results have demonstrated that the proposed SSAEIM can provide descriptive characterization for WCE images and recognize polyps in a WCE video accurately. This method could be further utilized in the clinical trials to help physicians from the tedious image reading work. (C) 2017 American Association of Physicists in Medicine
C1 [Yuan, Yixuan; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Yuan, YX (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM yxyuan@ee.cuhk.edu.hk
RI meng, meng/GWZ-7461-2022; Meng, Q./GSI-6185-2022; Meng, Max
   Q.-H./C-8078-2009
OI Yuan, Yixuan/0000-0002-0853-6948
CR Anthimopoulos MM, 2014, IEEE J BIOMED HEALTH, V18, P1261, DOI 10.1109/JBHI.2014.2308928
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Barbosa DC, 2012, BIOMED ENG ONLINE, V11, DOI 10.1186/1475-925X-11-3
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   El Khatib A, 2015, IEEE ENG MED BIO, P2669, DOI 10.1109/EMBC.2015.7318941
   Gueye L, 2015, IEEE IMAGE PROC, P1061, DOI 10.1109/ICIP.2015.7350962
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hosseini-Asl E, 2016, IEEE T NEUR NET LEAR, V27, P2486, DOI 10.1109/TNNLS.2015.2479223
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Iwahori Y, 2015, PROCEDIA COMPUT SCI, V60, P730, DOI 10.1016/j.procs.2015.08.226
   Karargyris A, 2012, INT J ARTIF INTELL T, V21, DOI 10.1142/S0218213012400210
   Karargyris A, 2011, IEEE T BIO-MED ENG, V58, P2777, DOI 10.1109/TBME.2011.2155064
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee NM, 2010, EXPERT REV GASTROENT, V4, P503, DOI [10.1586/egh.10.44, 10.1586/EGH.10.44]
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Li C, 2014, NEUROCOMPUTING, V123, P398, DOI 10.1016/j.neucom.2013.08.002
   Ma L, 2015, IEEE T GEOSCI REMOTE, V53, P2832, DOI 10.1109/TGRS.2014.2365676
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sae Hwang, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P320, DOI 10.1007/978-3-642-24031-7_32
   Segui S, 2012, IEEE T INF TECHNOL B, V16, P1341, DOI 10.1109/TITB.2012.2221472
   Silva J, 2013, IEEE ENG MED BIO, P5711, DOI 10.1109/EMBC.2013.6610847
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wilson DR, 2003, NEURAL NETWORKS, V16, P1429, DOI 10.1016/S0893-6080(03)00138-2
   Wu SS, 2014, IEEE IMAGE PROC, P1897, DOI 10.1109/ICIP.2014.7025380
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Yu JS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1822, DOI 10.1109/ROBIO.2015.7419037
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
   Zhao Q, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P948, DOI 10.1109/WCICA.2011.5970656
   Zhu RS, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P372, DOI 10.1109/CISP.2015.7407907
   Zou YX, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1274, DOI 10.1109/ICDSP.2015.7252086
NR 41
TC 111
Z9 125
U1 1
U2 26
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD APR
PY 2017
VL 44
IS 4
BP 1379
EP 1389
DI 10.1002/mp.12147
PG 11
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA ET8SZ
UT WOS:000400572700017
PM 28160514
OA Bronze
DA 2023-08-21
ER

PT J
AU Adnane, C
   Adouly, T
   Khallouk, A
   Rouadi, S
   Abada, R
   Roubal, M
   Mahtar, M
AF Adnane, Choaib
   Adouly, Taoufik
   Khallouk, Amine
   Rouadi, Sami
   Abada, Redallah
   Roubal, Mohamed
   Mahtar, Mohamed
TI Using preoperative unsupervised cluster analysis of chronic
   rhinosinusitis to inform patient decision and endoscopic sinus surgery
   outcome
SO EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY
LA English
DT Article
DE Cluster analysis; Phenotype; Endotype; Quality of life; Chronic
   rhinosinusitis; SNOT-22
ID PHENOTYPES; IDENTIFICATION; VALIDITY
AB The purpose of this study is to use unsupervised cluster methodology to identify phenotype and mucosal eosinophilia endotype subgroups of patients with medical refractory chronic rhinosinusitis (CRS), and evaluate the difference in quality of life (QOL) outcomes after endoscopic sinus surgery (ESS) between these clusters for better surgical case selection. A prospective cohort study included 131 patients with medical refractory CRS who elected ESS. The Sino-Nasal Outcome Test (SNOT-22) was used to evaluate QOL before and 12 months after surgery. Unsupervised two-step clustering method was performed. One hundred and thirteen subjects were retained in this study: 46 patients with CRS without nasal polyps and 67 patients with nasal polyps. Nasal polyps, gender, mucosal eosinophilia profile, and prior sinus surgery were the most discriminating factors in the generated clusters. Three clusters were identified. A significant clinical improvement was observed in all clusters 12 months after surgery with a reduction of SNOT-22 scores. There was a significant difference in QOL outcomes between clusters; cluster 1 had the worst QOL improvement after FESS in comparison with the other clusters 2 and 3. All patients in cluster 1 presented CRSwNP with the highest mucosal eosinophilia endotype. Clustering method is able to classify CRS phenotypes and endotypes with different associated surgical outcomes.
C1 [Adnane, Choaib; Adouly, Taoufik; Khallouk, Amine; Rouadi, Sami; Abada, Redallah; Roubal, Mohamed; Mahtar, Mohamed] Ibn Rochd Univ Hosp, Dept ENT, Aout Hosp 20, Casablanca, Morocco.
C3 Hassan II University of Casablanca; Ibn Rochd University Hospital Center
   of Casablanca
RP Adnane, C (通讯作者)，Ibn Rochd Univ Hosp, Dept ENT, Aout Hosp 20, Casablanca, Morocco.
EM adnanechoaib@gmail.com
RI cherif, adnen/A-4366-2018
OI cherif, adnen/0000-0003-2116-5763
CR Adnane C, 2015, AM J OTOLARYNG, V36, P47, DOI 10.1016/j.amjoto.2014.09.003
   Agache I, 2012, ALLERGY, V67, P835, DOI 10.1111/j.1398-9995.2012.02832.x
   Akdis CA, 2012, NAT MED, V18, P736, DOI 10.1038/nm.2754
   Anand VK, 2004, ANN OTO RHINOL LARYN, V113, P3, DOI 10.1177/00034894041130S502
   Bhattacharyya N, 2007, LARYNGOSCOPE, V117, P1834, DOI 10.1097/MLG.0b013e3180caa19d
   Bousquet J, 2011, GENOME MED, V3, DOI 10.1186/gm259
   Dursun E, 2003, OTOLARYNG HEAD NECK, V129, P526, DOI 10.1016/S0194-5998(03)01576-6
   Eweiss A, 2009, EUR ARCH OTO-RHINO-L, V266, P377, DOI 10.1007/s00405-008-0762-1
   Fokkens WJ, 2012, RHINOLOGY, V50, P1, DOI 10.4193/Rhin20.600
   Hopkins C, 2015, RHINOLOGY, V53, P10, DOI [10.4193/Rhin13.217, 10.4193/Rhino13.217]
   Hopkins C, 2009, CLIN OTOLARYNGOL, V34, P447, DOI 10.1111/j.1749-4486.2009.01995.x
   Kennedy DW, 2012, RHINOLOGY DIS NOSE S, P306
   Kennedy JL, 2013, ANN ALLERG ASTHMA IM, V111, P246, DOI 10.1016/j.anai.2013.06.033
   Lane AP, 2012, RHINOLOGY DIS NOSE S, P171
   Lund V, 1995, ANN OTOL RHINOL S10, V104, P1
   Meltzer Eli O, 2004, J Allergy Clin Immunol, V114, P155, DOI 10.1016/j.jaci.2004.09.029
   Nakayama T, 2012, AM J RHINOL ALLERGY, V26, P172, DOI 10.2500/ajra.2012.26.3749
   Piccirillo JF, 2002, OTOLARYNG HEAD NECK, V126, P41, DOI 10.1067/mhn.2002.121022
   Smith KA, 2014, INT FORUM ALLERGY RH, V4, P823, DOI 10.1002/alr.21366
   Smith TL, 2005, LARYNGOSCOPE, V115, P2199, DOI 10.1097/01.mlg.0000182825.82910.80
   Soler ZM, 2016, J ALLERGY CLIN IMMUN, V137, P1054, DOI 10.1016/j.jaci.2015.11.019
   Soler ZM, 2015, INT FORUM ALLERGY RH, V5, P399, DOI 10.1002/alr.21496
   Soler ZM, 2013, LARYNGOSCOPE, V123, P2341, DOI 10.1002/lary.24027
   Soler ZM, 2010, OTOLARYNG HEAD NECK, V142, P64, DOI 10.1016/j.otohns.2009.10.005
   Soler ZM, 2009, OTOLARYNG HEAD NECK, V141, P454, DOI 10.1016/j.otohns.2009.06.085
NR 25
TC 17
Z9 18
U1 1
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0937-4477
EI 1434-4726
J9 EUR ARCH OTO-RHINO-L
JI Eur. Arch. Oto-Rhino-Laryn.
PD FEB
PY 2017
VL 274
IS 2
BP 879
EP 885
DI 10.1007/s00405-016-4315-8
PG 7
WC Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Otorhinolaryngology
GA EL1AB
UT WOS:000394351800038
PM 27665096
DA 2023-08-21
ER

PT J
AU Komeda, Y
   Handa, H
   Watanabe, T
   Nomura, T
   Kitahashi, M
   Sakurai, T
   Okamoto, A
   Minami, T
   Kono, M
   Arizumi, T
   Takenaka, M
   Hagiwara, S
   Matsui, S
   Nishida, N
   Kashida, H
   Kudo, M
AF Komeda, Yoriaki
   Handa, Hisashi
   Watanabe, Tomohiro
   Nomura, Takanobu
   Kitahashi, Misaki
   Sakurai, Toshiharu
   Okamoto, Ayana
   Minami, Tomohiro
   Kono, Masashi
   Arizumi, Tadaaki
   Takenaka, Mamoru
   Hagiwara, Satoru
   Matsui, Shigenaga
   Nishida, Naoshi
   Kashida, Hiroshi
   Kudo, Masatoshi
TI Computer-Aided Diagnosis Based on Convolutional Neural Network System
   for Colorectal Polyp Classification: Preliminary Experience
SO ONCOLOGY
LA English
DT Article; Proceedings Paper
CT 1st Kindai International Symposium on Gastrointestinal Cancer (KISGIC)
CY JUL 08, 2017
CL Osaka, JAPAN
DE Computer-aided diagnosis; Convolutional neural network; Artificial
   intelligence; Colon polyp classification; Deep learning
ID LESIONS; HISTOLOGY; CANCER; PREVENTION; PATTERNS
AB Background and Aim: Computer-aided diagnosis (CAD) is becoming a next-generation tool for the diagnosis of human disease. CAD for colon polyps has been suggested as a particularly useful tool for trainee colonoscopists, as the use of a CAD system avoids the complications associated with endoscopic resections. In addition to conventional CAD, a convolutional neural network (CNN) system utilizing artificial intelligence (AI) has been developing rapidly over the past 5 years. We attempted to generate a unique CNN-CAD system with an AI function that studied endoscopic images extracted from movies obtained with colonoscopes used in routine examinations. Here, we report our preliminary results of this novel CNN-CAD system for the diagnosis of colon polyps. Methods: A total of 1,200 images from cases of colonoscopy performed between January 2010 and December 2016 at Kindai University Hospital were used. These images were extracted from the video of actual endoscopic examinations. Additional video images from 10 cases of unlearned processes were retrospectively assessed in a pilot study. They were simply diagnosed as either an adenomatous or nonadenomatous polyp. Results: The number of images used by AI to learn to distinguish adenomatous from nonadenomatous was 1,200: 600. These images were extracted from the videos of actual endoscopic examinations. The size of each image was adjusted to 256 x 256 pixels. A 10-hold cross-validation was carried out. The accuracy of the 10-hold cross-validation is 0.751, where the accuracy is the ratio of the number of correct answers over the number of all the answers produced by the CNN. The decisions by the CNN were correct in 7 of 10 cases. Conclusion: A CNN-CAD system using routine colonoscopy might be useful for the rapid diagnosis of colorectal polyp classification. Further prospective studies in an in vivo setting are required to confirm the effectiveness of a CNN-CAD system in routine colonoscopy. (C) 2017 S. Karger AG, Basel
C1 [Komeda, Yoriaki; Watanabe, Tomohiro; Sakurai, Toshiharu; Okamoto, Ayana; Minami, Tomohiro; Kono, Masashi; Arizumi, Tadaaki; Takenaka, Mamoru; Hagiwara, Satoru; Matsui, Shigenaga; Nishida, Naoshi; Kashida, Hiroshi; Kudo, Masatoshi] Kindai Univ, Fac Med, Dept Gastroenterol & Hepatol, 377-2 Ohno Higashi, Osakasayama, Osaka 5898511, Japan.
   [Handa, Hisashi] Kindai Univ, Fac Sci & Engn, Osakasayama, Japan.
   [Nomura, Takanobu; Kitahashi, Misaki] Kindai Univ, Grad Sch Sci & Engn Res, Osakasayama, Japan.
RP Komeda, Y (通讯作者)，Kindai Univ, Fac Med, Dept Gastroenterol & Hepatol, 377-2 Ohno Higashi, Osakasayama, Osaka 5898511, Japan.
EM y-komme@mvb.biglobe.ne.jp
RI Watanabe, Tomohiro/ABA-4712-2021; Komeda, Yoriaki/AAF-6652-2020; Kudo,
   Masatoshi/AAA-9744-2019
OI Kudo, Masatoshi/0000-0002-4102-3474; Kashida,
   Hiroshi/0000-0002-9774-9485
CR Butterly LF, 2006, CLIN GASTROENTEROL H, V4, P343, DOI 10.1016/j.cgh.2005.12.021
   Fernandez-Esparrach G, 2016, ENDOSCOPY, V48, P837, DOI 10.1055/s-0042-108434
   Gross S, 2011, GASTROINTEST ENDOSC, V74, P1354, DOI 10.1016/j.gie.2011.08.001
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Loberg M, 2014, NEW ENGL J MED, V371, P799, DOI 10.1056/NEJMoa1315870
   Misawa M, 2016, GASTROENTEROLOGY, V150, P1531, DOI 10.1053/j.gastro.2016.04.004
   Mori Y, 2016, ENDOSCOPY, V48, P1110, DOI 10.1055/s-0042-113609
   Mori Y, 2015, GASTROINTEST ENDOSC, V81, P621, DOI 10.1016/j.gie.2014.09.008
   Philpotts LE, 2009, RADIOLOGY, V253, P17, DOI 10.1148/radiol.2531090689
   Pohl J, 2008, AM J GASTROENTEROL, V103, P562, DOI 10.1111/j.1572-0241.2007.01670.x
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Takemura Y, 2012, GASTROINTEST ENDOSC, V75, P179, DOI 10.1016/j.gie.2011.08.051
   Takemura Y, 2010, GASTROINTEST ENDOSC, V72, P1047, DOI 10.1016/j.gie.2010.07.037
   Tischendorf JJW, 2010, ENDOSCOPY, V42, P203, DOI 10.1055/s-0029-1243861
   WINAWER SJ, 1993, NEW ENGL J MED, V329, P1977, DOI 10.1056/NEJM199312303292701
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
NR 17
TC 122
Z9 126
U1 2
U2 21
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0030-2414
EI 1423-0232
J9 ONCOLOGY-BASEL
JI Oncology
PY 2017
VL 93
SU 1
BP 30
EP 34
DI 10.1159/000481227
PG 5
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Oncology
GA FQ8VC
UT WOS:000418640300006
PM 29258081
OA Bronze
DA 2023-08-21
ER

PT J
AU Vazquez, D
   Bernal, J
   Sanchez, FJ
   Fernandez-Esparrach, G
   Lopez, AM
   Romero, A
   Drozdzal, M
   Courville, A
AF Vazquez, David
   Bernal, Jorge
   Javier Sanchez, F.
   Fernandez-Esparrach, Gloria
   Lopez, Antonio M.
   Romero, Adriana
   Drozdzal, Michal
   Courville, Aaron
TI A Benchmark for Endoluminal Scene Segmentation of Colonoscopy Images
SO JOURNAL OF HEALTHCARE ENGINEERING
LA English
DT Article
ID NETWORKS; VALIDATION; DIAGNOSIS; POLYPS
AB Colorectal cancer (CRC) is the third cause of cancer death worldwide. Currently, the standard approach to reduce CRC-related mortality is to perform regular screening in search for polyps and colonoscopy is the screening tool of choice. The main limitations of this screening procedure are polyp miss rate and the inability to perform visual assessment of polyp malignancy. These drawbacks can be reduced by designing decision support systems (DSS) aiming to help clinicians in the different stages of the procedure by providing endoluminal scene segmentation. Thus, in this paper, we introduce an extended benchmark of colonoscopy image segmentation, with the hope of establishing a new strong benchmark for colonoscopy image analysis research. The proposed dataset consists of 4 relevant classes to inspect the endoluminal scene, targeting different clinical needs. Together with the dataset and taking advantage of advances in semantic segmentation literature, we provide new baselines by training standard fully convolutional networks (FCNs). We perform a comparative study to show that FCNs significantly outperform, without any further postprocessing, prior results in endoluminal scene segmentation, especially with respect to polyp segmentation and localization.
C1 [Vazquez, David; Bernal, Jorge; Javier Sanchez, F.; Lopez, Antonio M.] Univ Autonoma Barcelona, Comp Sci Dept, Comp Vis Ctr, Barcelona, Spain.
   [Vazquez, David; Lopez, Antonio M.; Romero, Adriana; Courville, Aaron] Univ Montreal, Montreal Inst Learning Algorithms, Montreal, PQ, Canada.
   [Fernandez-Esparrach, Gloria] Univ Barcelona, Hosp Clin, IDIBAPS, Endoscopy Unit,Gastroenterol Serv,CIBERHED, Barcelona, Spain.
   [Drozdzal, Michal] Ecole Polytech, Montreal, PQ, Canada.
   [Drozdzal, Michal] Imagia Inc, Montreal, PQ, Canada.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Universite de Montreal; University of Barcelona; Hospital Clinic
   de Barcelona; IDIBAPS; Universite de Montreal; Polytechnique Montreal
RP Vazquez, D (通讯作者)，Univ Autonoma Barcelona, Comp Sci Dept, Comp Vis Ctr, Barcelona, Spain.; Vazquez, D (通讯作者)，Univ Montreal, Montreal Inst Learning Algorithms, Montreal, PQ, Canada.
EM dvazquez@cvc.uab.es
RI Vázquez, David/P-3306-2019; López, Antonio M/L-5303-2014; Bernal,
   Jorge/H-4647-2015
OI Vázquez, David/0000-0002-2845-8158; López, Antonio
   M/0000-0002-6979-5783; Bernal, Jorge/0000-0001-8493-9514;
   Fernandez-Esparrach/0000-0002-3378-3940
FU Imagia Inc.; Spanish government [AC/DC TRA2014-57088-C2-1-R]; iVENDIS
   [DPI2015-65286-R]; SGR [2014-SGR-1506, 2014-SGR-1470, 2014-SGR-135];
   CERCA Programme/Generalitat de Catalunya; TECNIOspring-ACCI grant;
   NVIDIA Corporation; FSEED
FX The authors would like to thank the developers of Theano [37] and Keras
   [38]. The authors acknowledge the support of the following agencies for
   research funding and computing support: Imagia Inc.; Spanish government
   through funded Project AC/DC TRA2014-57088-C2-1-R and iVENDIS
   (DPI2015-65286-R); SGR Projects 2014-SGR-1506, 2014-SGR-1470, and
   2014-SGR-135; CERCA Programme/Generalitat de Catalunya; and
   TECNIOspring-FP7-ACCI grant, FSEED, and NVIDIA Corporation for the
   generous support in the form of different GPU hardware units.
CR Arganda-Carreras I, 2015, FRONT NEUROANAT, V9, DOI 10.3389/fnana.2015.00142
   Bernal Jorge, 2014, Clinical Image-Based Procedures. Translational Research in Medical Imaging. Third International Workshop, CLIP 2014 Held in Conjunction with MICCAI 2014. Revised Selected Papers: LNCS 8680, P41, DOI 10.1007/978-3-319-13909-8_6
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bernal J, 2014, LECT NOTES COMPUT SC, V8899, P1, DOI 10.1007/978-3-319-13410-9_1
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821
   Bruno M. J., 2003, Gut, V52, piv7, DOI 10.1136/gut.52.suppl_4.iv7
   Cha KH, 2016, MED PHYS, V43, P1882, DOI 10.1118/1.4944498
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Chollet F., 2015, KERAS PROBABILISTIC
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fergus R., 2014, PREDICTING DEPTH SUR
   Gross S., 2009, INT SOC OPTICS PHOTO
   Havaei M, 2015, BRAIN TUMOR SEGMENTA
   Huang G., 2017, 2017 P IEEE C COMP V, P4700, DOI [10.1109/CVPR.2017.243, DOI 10.1109/CVPR.2017.243]
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Menze Bjoern H, 2015, IEEE Trans Med Imaging, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nunez JM, 2014, LECT NOTES COMPUT SC, V8899, P22, DOI 10.1007/978-3-319-13410-9_3
   Park S. Y., 2016, SPIE MED IMAGING
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Ribeiro E, 2016, COMP MED SY, P253, DOI 10.1109/CBMS.2016.39
   Romero A., 2015, PROC INT C LEARN REP
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy HK, 2011, GASTROENTEROLOGY, V140, P1863, DOI 10.1053/j.gastro.2011.04.027
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Society A. C, 2016, COLORECTAL CANC
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Styner M., 2008, MIDAS J, P1, DOI DOI 10.54294/LMKQVM
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   *THEAN DEV TEAM, 2016, ABS160502688 ARXIV T
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
NR 38
TC 171
Z9 173
U1 4
U2 14
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2040-2295
EI 2040-2309
J9 J HEALTHC ENG
JI J. Healthc. Eng.
PY 2017
VL 2017
AR 4037190
DI 10.1155/2017/4037190
PG 9
WC Health Care Sciences & Services
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services
GA FD1GJ
UT WOS:000407285100001
PM 29065595
OA Green Submitted, gold, Green Published, Green Accepted
DA 2023-08-21
ER

PT J
AU Yu, LQ
   Chen, H
   Dou, Q
   Qin, J
   Heng, PA
AF Yu, Lequan
   Chen, Hao
   Dou, Qi
   Qin, Jing
   Heng, Pheng Ann
TI Integrating Online and Offline Three-Dimensional Deep Learning for
   Automated Polyp Detection in Colonoscopy Videos
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Automated polyp detection; colonoscopy video; computer-aided diagnosis;
   convolutional neural networks (CNNs); deep learning
ID CONVOLUTIONAL NEURAL-NETWORKS; IMAGES; SEGMENTATION; CANCER
AB Automated polyp detection in colonoscopy videos has been demonstrated to be a promising way for colorectal cancer prevention and diagnosis. Traditional manual screening is time consuming, operator dependent, and error prone; hence, automated detection approach is highly demanded in clinical practice. However, automated polyp detection is very challenging due to high intraclass variations in polyp size, color, shape, and texture, and low interclass variations between polyps and hard mimics. In this paper, we propose a novel offline and online three-dimensional (3-D) deep learning integration framework by leveraging the 3-D fully convolutional network (3D-FCN) to tackle this challenging problem. Compared with the previous methods employing hand-crafted features or 2-D convolutional neural network, the 3D-FCN is capable of learning more representative spatio-temporal features from colonoscopy videos, and hence has more powerful discrimination capability. More importantly, we propose a novel online learning scheme to deal with the problem of limited training data by harnessing the specific information of an input video in the learning process. We integrate offline and online learning to effectively reduce the number of false positives generated by the offline network and further improve the detection performance. Extensive experiments on the dataset of MICCAI 2015 Challenge on Polyp Detection demonstrated the better performance of our method when compared with other competitors.
C1 [Yu, Lequan; Chen, Hao; Dou, Qi; Heng, Pheng Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Qin, Jing] Hong Kong Polytech Univ, Sch Nursing, Ctr Smart Hlth, Hong Kong, Hong Kong, Peoples R China.
   [Heng, Pheng Ann] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Virtual Real & Human Interact Te, Shenzhen 518055, Peoples R China.
C3 Chinese University of Hong Kong; Hong Kong Polytechnic University;
   Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS
RP Yu, LQ (通讯作者)，Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
EM lqyu@cse.cuhk.edu.hk; hchen@cse.cuhk.edu.hk; qdou@cse.cuhk.edu.hk;
   harry.qin@polyu.edu.hk; pheng@cse.cuhk.edu.hk
RI Chen, Hao/V-4299-2019; Qin, Jing/J-9807-2016; Dou, Qi/I-8175-2019; Yu,
   Lequan/U-5377-2019
OI Chen, Hao/0000-0002-8400-3780; Qin, Jing/0000-0002-7059-0929; Dou,
   Qi/0000-0002-3416-9950; Yu, Lequan/0000-0002-9315-6527; Heng, Pheng
   Ann/0000-0003-3055-5034
FU Research Grants Council of the Hong Kong Special Administrative Region
   [CUHK 14202514, CUHK 14203115]; National Natural Science Foundation of
   China [61233012]; Shenzhen Science and Technology Program
   [JCYJ20160429190300857]
FX This work was supported in part by the grants from the Research Grants
   Council of the Hong Kong Special Administrative Region under Project
   CUHK 14202514 and Project CUHK 14203115, in part by the National Natural
   Science Foundation of China under Project 61233012, and in part by the
   Shenzhen Science and Technology Program (JCYJ20160429190300857). (Lequan
   Yu and Hao Chen contributed equally to this work.)
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], CA CANCER J CLIN, DOI [10.3322/CAAC.21254, DOI 10.3322/caac.21254]
   [Anonymous], 2016, ARXIV160305959
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2007, P ICIP
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821
   Chassang Antoine, 2014, 3 INT C LEARN REPRES
   Chen H, 2016, AAAI CONF ARTIF INTE, P1160
   Chen H, 2016, AAAI CONF ARTIF INTE, P1167
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen H, 2015, LECT NOTES COMPUT SC, V9349, P507, DOI 10.1007/978-3-319-24553-9_62
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Li RJ, 2014, LECT NOTES COMPUT SC, V8675, P305, DOI 10.1007/978-3-319-10443-0_39
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Nie D, 2016, I S BIOMED IMAGING, P1342, DOI 10.1109/ISBI.2016.7493515
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Rabeneck L, 2003, AM J GASTROENTEROL, V98, P471, DOI 10.1016/S0002-9270(02)05928-2
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2014, LECT NOTES COMPUT SC, V8673, P520, DOI 10.1007/978-3-319-10404-1_65
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Simonyan K., 2015, 3 INT C LEARN REPRES, P1
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tajbakhsh N, 2015, I S BIOMED IMAGING, P79, DOI 10.1109/ISBI.2015.7163821
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
NR 46
TC 136
Z9 145
U1 3
U2 46
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD JAN
PY 2017
VL 21
IS 1
BP 65
EP 75
DI 10.1109/JBHI.2016.2637004
PG 11
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA EM8CJ
UT WOS:000395538500008
PM 28114049
DA 2023-08-21
ER

PT J
AU Yuan, YX
   Li, BP
   Meng, MQH
AF Yuan, Yixuan
   Li, Baopu
   Meng, Max Q. -H.
TI WCE Abnormality Detection Based on Saliency and Adaptive
   Locality-Constrained Linear Coding
SO IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING
LA English
DT Article
DE Adaptive coding bases; patch saliency; saliency and adaptive
   locality-constrained linear coding (SALLC) algorithm; wireless capsule
   endoscopy (WCE) image classification
ID CAPSULE ENDOSCOPY; IMAGE CLASSIFICATION; FEATURES; RECOGNITION; BAG
AB Wireless capsule endoscopy (WCE) has become a widely used diagnostic technique for the digestive tract, at the price of a large volume of data that needs to be analyzed. To tackle this problem, a new computer-aided system using novel features is proposed in this paper to classify WCE images automatically. In the feature learning stage, to obtain the representative visual words, we first calculate the color scale invariant feature transform from the bleeding, polyp, ulcer, and normal WCE image samples separately and then apply K-means clustering on these features to obtain visual words. These four types of visual words are combined together to composite the representative visual words for classifying the WCE images. In the feature coding stage, we propose a novel saliency and adaptive locality-constrained linear coding (SALLC) algorithm to encode the images. The SALLC encodes patch features based on adaptive coding bases, which are calculated by the distance differences among the features and the visual words. Moreover, it imposes the patch saliency constraint on the feature coding process to emphasize the important information in the images. The experimental results exhibit a promising overall recognition accuracy of 88.61%, validating the effectiveness of the proposed method.
   Note to Practitioners-Because of approximately 50 000 wireless capsule endoscopy (WCE) images for one patient, a clinician usually has to spend about 2 h to view these images and make a diagnostic decision on possible gastrointestinal diseases. Therefore, it is crucial to design an automatic computer-aided system to assist clinicians to classify images with abnormal structures. However, most WCE abnormality detection methods consider only one specific abnormality and the existing multiabnormality classification results are far from satisfactory. Thus, we propose a novel automatic multiabnormality WCE image detection scheme, namely, saliency and adaptive locality-constrained linear coding algorithm, by considering the local coding bases adaptively and the saliency information about the images. Results from comprehensive comparison experiments suggest that the proposed computer-aided classification system achieves improved accuracy.
C1 [Yuan, Yixuan; Meng, Max Q. -H.] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
   [Li, Baopu] Shenzhen Univ, Dept Biomed Engn, Shenzhen 518060, Peoples R China.
C3 Chinese University of Hong Kong; Shenzhen University
RP Meng, MQH (通讯作者)，Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM yxyuan@ee.cuhk.edu.hk; bpli@szu.edu.cn; max@ee.cuhk.edu.hk
RI meng, meng/GWZ-7461-2022; Meng, Max Q.-H./C-8078-2009; Meng,
   Q./GSI-6185-2022
OI Yuan, Yixuan/0000-0002-0853-6948
FU RGC GRF [415613]; National Natural Science Foundation of China
   [61305099]; Natural Science Foundation of Guangdong Province
   [2015A030313547]; Scientific and Technical Innovation Council of
   Shenzhen Government [000047]
FX The work of M.Q.-H. Meng was supported in part by RGC GRF under Grant
   415613, in part by the National Natural Science Foundation of China
   under Grant 61305099, in part by the Natural Science Foundation of
   Guangdong Province under Grant 2015A030313547, and in part by the Seed
   Funding from Scientific and Technical Innovation Council of Shenzhen
   Government under Grant 000047.
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   [Anonymous], 2009, ADV NEURAL INFORM PR
   Anthimopoulos MM, 2014, IEEE J BIOMED HEALTH, V18, P1261, DOI 10.1109/JBHI.2014.2308928
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen SH, 2015, PATTERN RECOGN LETT, V51, P44, DOI 10.1016/j.patrec.2014.08.008
   Coimbra MT, 2006, IEEE T CIRC SYST VID, V16, P628, DOI 10.1109/TCSVT.2006.873158
   Csurka G, 2004, PROC WORKSHOP STAT L, V1, P1
   Eid A, 2013, COMP MED SY, P273, DOI 10.1109/CBMS.2013.6627801
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Huang YZ, 2011, PROC CVPR IEEE, P1753, DOI 10.1109/CVPR.2011.5995682
   Iakovidis DK, 2015, NAT REV GASTRO HEPAT, V12, P172, DOI 10.1038/nrgastro.2015.13
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kumar R, 2012, IEEE T BIO-MED ENG, V59, P355, DOI 10.1109/TBME.2011.2172438
   Lazebnik S., 2006, P IEEE INT C COMP VI, V2, P2169, DOI DOI 10.1109/CVPR.2006.68
   Lee NM, 2010, EXPERT REV GASTROENT, V4, P503, DOI [10.1586/egh.10.44, 10.1586/EGH.10.44]
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maaten, 2011, P INT C MACH LEARN, P217
   Manno M., 2012, ILEOSCOPY, P79
   Nawarathna R, 2014, NEUROCOMPUTING, V144, P70, DOI 10.1016/j.neucom.2014.02.064
   Quan Fang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P260, DOI 10.1109/ICME.2012.164
   Sae Hwang, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P320, DOI 10.1007/978-3-642-24031-7_32
   Siddiqui AJ, 2016, IEEE T INTELL TRANSP, V17, P3205, DOI 10.1109/TITS.2016.2545640
   Toennies JL, 2010, P I MECH ENG C-J MEC, V224, P1397, DOI 10.1243/09544062JMES1879
   Upchurch BR, 2008, REV GASTROENTEROL DI, V8, P169
   van Grinsven MJJP, 2013, I S BIOMED IMAGING, P1444
   Wang J, 2010, APPL MECH MATER, V36, P96, DOI [10.1109/ICICTA.2010.35, 10.4028/www.scientific.net/AMM.36.96]
   WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018
   Wu X, 2016, IEEE T MED IMAGING, V35, P1741, DOI 10.1109/TMI.2016.2527736
   Wu ZF, 2012, INT C PATT RECOG, P1505
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
   Yuan YS, 2014, IEEE INT CONF ROBOT, P3930, DOI 10.1109/ICRA.2014.6907429
   Yuan YX, 2016, IEEE T AUTOM SCI ENG, V13, P529, DOI 10.1109/TASE.2015.2395429
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Yuan YX, 2014, IEEE INT C INT ROBOT, P5010, DOI 10.1109/IROS.2014.6943274
   Zare MR, 2013, IET COMPUT VIS, V7, P105, DOI 10.1049/iet-cvi.2012.0291
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhou JD, 2011, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.2011.6116405
NR 44
TC 55
Z9 61
U1 0
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-5955
EI 1558-3783
J9 IEEE T AUTOM SCI ENG
JI IEEE Trans. Autom. Sci. Eng.
PD JAN
PY 2017
VL 14
IS 1
BP 149
EP 159
DI 10.1109/TASE.2016.2610579
PG 11
WC Automation & Control Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems
GA EG9MJ
UT WOS:000391382700014
DA 2023-08-21
ER

PT J
AU Zhang, RK
   Zheng, YL
   Mak, TWC
   Yu, RX
   Wong, SH
   Lau, JYW
   Poon, CCY
AF Zhang, Ruikai
   Zheng, Yali
   Mak, Tony Wing Chung
   Yu, Ruoxi
   Wong, Sunny H.
   Lau, James Y. W.
   Poon, Carmen C. Y.
TI Automatic Detection and Classification of Colorectal Polyps by
   Transferring Low-Level CNN Features From Nonmedical Domain
SO IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
LA English
DT Article
DE Colorectal cancer; deep learning; health informatics; polyp diagnosis
ID CONVOLUTIONAL NEURAL-NETWORKS; DIFFERENTIAL-DIAGNOSIS; MUCOSAL; LESIONS
AB Colorectal cancer (CRC) is a leading cause of cancer deaths worldwide. Although polypectomy at early stage reduces CRC incidence, 90% of the polyps are small and diminutive, where removal of them poses risks to patients that may outweigh the benefits. Correctly detecting and predicting polyp type during colonoscopy allows endoscopists to resect and discard the tissue without submitting it for histology, saving time, and costs. Nevertheless, human visual observation of early stage polyps varies. Therefore, this paper aims at developing a fully automatic algorithm to detect and classify hyperplastic and adenomatous colorectal polyps. Adenomatous polyps should be removed, whereas distal diminutive hyperplastic polyps are considered clinically insignificant and may be left in situ. A novel transfer learning application is proposed utilizing features learned from big nonmedical datasets with 1.4-2.5 million images using deep convolutional neural network. The endoscopic images we collected for experiment were taken under random lighting conditions, zooming and optical magnification, including 1104 endoscopic nonpolyp images taken under both white-light and narrowband imaging (NBI) endoscopy and 826 NBI endoscopic polyp images, of which 263 images were hyperplasia and 563 were adenoma as confirmed by histology. The proposed method identified polyp images from nonpolyp images in the beginning followed by predicting the polyp histology. When compared with visual inspection by endoscopists, the results of this study show that the proposed method has similar precision (87.3% versus 86.4%) but a higher recall rate (87.6% versus 77.0%) and a higher accuracy (85.9% versus 74.3%). In conclusion, automatic algorithms can assist endoscopists in identifying polyps that are adenomatous but have been incorrectly judged as hyperplasia and, therefore, enable timely resection of these polyps at an early stage before they develop into invasive cancer.
C1 [Zhang, Ruikai; Zheng, Yali; Mak, Tony Wing Chung; Yu, Ruoxi; Lau, James Y. W.; Poon, Carmen C. Y.] Chinese Univ Hong Kong, Dept Surg, Shatin, Hong Kong, Peoples R China.
   [Wong, Sunny H.] Chinese Univ Hong Kong, Li Ka Shing Inst Hlth Sci, Inst Digest Dis, Dept Med & Therapeut,State Key Lab Digest Dis, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong; Chinese University of Hong Kong
RP Zhang, RK (通讯作者)，Chinese Univ Hong Kong, Dept Surg, Shatin, Hong Kong, Peoples R China.
EM rzhang@surgery.cuhk.edu.hk; ylzheng@surgery.cuhk.edu.hk;
   tonymak@surgery.cuhk.edu.hk; yuruoxi@surgery.cuhk.edu.hk;
   wonghei@cuhk.edu.hk; laujyw@surgery.cuhk.edu.hk;
   cpoon@surgery.cuhk.edu.hk
RI Zhang, Ruikai/W-9847-2019; Mak, Tony W. C./M-1310-2018; Zhang,
   Ruikai/W-9848-2019; Lau, James Y. W./O-2612-2016; Wong, Sunny
   H/N-3754-2015; Poon, Carmen C. Y./B-4616-2011
OI Mak, Tony W. C./0000-0002-4516-3124; Zhang, Ruikai/0000-0001-8929-628X;
   Lau, James Y. W./0000-0003-0122-4068; Wong, Sunny H/0000-0002-3354-9310;
   Poon, Carmen C. Y./0000-0001-7717-4752; Zheng, Yali/0000-0002-6215-1694
FU Hong Kong Innovation and Technology Fund; Shaw Endoscopy Center; Chow
   Yuk Ho Technology Centre for Innovative Medicine
FX This work was supported by the Hong Kong Innovation and Technology Fund,
   Shaw Endoscopy Center and the Chow Yuk Ho Technology Centre for
   Innovative Medicine.
CR Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bar Y, 2015, PROC SPIE, V9414, DOI 10.1117/12.2083124
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Hewett DG, 2012, GASTROENTEROLOGY, V143, P599, DOI 10.1053/j.gastro.2012.05.006
   Ignjatovic A, 2009, LANCET ONCOL, V10, P1171, DOI 10.1016/S1470-2045(09)70329-8
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Machida H, 2004, ENDOSCOPY, V36, P1094, DOI 10.1055/s-2004-826040
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Oba S, 2010, SCAND J GASTROENTERO, V45, P1084, DOI 10.3109/00365521003734166
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parkin DM, 2005, CA-CANCER J CLIN, V55, P74, DOI 10.3322/canjclin.55.2.74
   Rastogi A, 2009, GASTROINTEST ENDOSC, V69, P716, DOI 10.1016/j.gie.2008.09.058
   Rex DK, 2009, LANCET ONCOL, V10, P1135, DOI 10.1016/S1470-2045(09)70342-0
   Roth HR, 2015, I S BIOMED IMAGING, P101, DOI 10.1109/ISBI.2015.7163826
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sano Y, 2009, GASTROINTEST ENDOSC, V69, P278, DOI 10.1016/j.gie.2008.04.066
   Shie C.-K., 2015, P 37 ANN INT C IEEE
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Stehle T, 2009, PROC SPIE, V7260, DOI 10.1117/12.808103
   Su MY, 2006, AM J GASTROENTEROL, V101, P2711, DOI 10.1111/j.1572-0241.2006.00932.x
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tanaka S, 2011, DIGEST ENDOSC, V23, P131, DOI 10.1111/j.1443-1661.2011.01106.x
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Yosinski J., 2014, P 27 INT C NEURAL IN, V4, P3320
   Zauber AG, 2012, NEW ENGL J MED, V366, P687, DOI 10.1056/NEJMoa1100370
   Zhou B., 2014, ADV NEURAL INFORM PR, P487
NR 31
TC 208
Z9 222
U1 3
U2 73
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2194
EI 2168-2208
J9 IEEE J BIOMED HEALTH
JI IEEE J. Biomed. Health Inform.
PD JAN
PY 2017
VL 21
IS 1
BP 41
EP 47
DI 10.1109/JBHI.2016.2635662
PG 7
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Mathematical & Computational Biology;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematical & Computational Biology; Medical
   Informatics
GA EM8CJ
UT WOS:000395538500005
PM 28114040
DA 2023-08-21
ER

PT J
AU Cho, YJ
   Bae, SH
   Yoon, KJ
AF Cho, Yeong-Jun
   Bae, Seung-Hwan
   Yoon, Kuk-Jin
TI Multi-Classifier-Based Automatic Polyp Detection in Endoscopic Images
SO JOURNAL OF MEDICAL AND BIOLOGICAL ENGINEERING
LA English
DT Article
DE Medical imaging; Medical engineering; Automatic polyp detection;
   Multi-classifier learning; Contour intensity difference measure
ID COLONOSCOPY; ENSEMBLE
AB Automatic polyp detection in endoscopy (or colonoscopy) images is challenging because the types of polyp and their appearances are diverse, and the colors and textures of polyps are quite similar to those of normal tissues in many cases. It is thus often very difficult to distinguish polyps from normal tissues using conventional methodology. To effectively resolve these challenges, we propose a framework based on multi-classifier learning and a contour intensity difference (CID) measure. To detect polyps of diverse appearances, we first classify polyps into K types according to their shape via unsupervised learning. We then train K classifiers to detect the K types of polyp. This multi-classifier learning improves the polyp detection rate. However, false positives also increase because colon structures look similar to polyps. To reduce false positives while preserving the high detection rate, we propose a CID measure. Experimental results using public and our own datasets show that the proposed methods are promising for detecting polyps with diverse appearances.
C1 [Cho, Yeong-Jun; Yoon, Kuk-Jin] Gwangju Inst Sci & Technol, 123 Cheom Dan Gwagi Ro, Gwangju 500712, South Korea.
   [Bae, Seung-Hwan] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Electronics &
   Telecommunications Research Institute - Korea (ETRI)
RP Yoon, KJ (通讯作者)，Gwangju Inst Sci & Technol, 123 Cheom Dan Gwagi Ro, Gwangju 500712, South Korea.
EM kjyoon@gist.ac.kr
RI CHO, Yeong-Jun/HSF-4060-2023; Yoon, Kuk-Jin/F-4329-2018
CR Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   Ameling S., 2009, BILDVERARBEITUNG MED, P346, DOI [DOI 10.1007/978-3-540-93860-6_70, DOI 10.1007/978-3-540-93860-670]
   [Anonymous], 2007, P ICIP
   Baxter NN, 2009, ANN INTERN MED, V150, P1, DOI 10.7326/0003-4819-150-1-200901060-00306
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bieniek A, 2000, PATTERN RECOGN, V33, P907, DOI 10.1016/S0031-3203(99)00154-5
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   COOPE ID, 1993, J OPTIMIZ THEORY APP, V76, P381, DOI 10.1007/BF00939613
   Dalal N., 2005, COMPUTER VISION PATT, V1, P693
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Dollar P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Everingham M, 2006, LECT NOTES ARTIF INT, V3944, P117
   Iakovidis DK, 2006, COMPUT BIOL MED, V36, P1084, DOI 10.1016/j.compbiomed.2005.09.008
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Li BP, 2012, J MED SYST, V36, P2463, DOI 10.1007/s10916-011-9713-2
   Li BP, 2012, EXPERT SYST APPL, V39, P10952, DOI 10.1016/j.eswa.2012.03.029
   Li P, 2005, PROC CVPR IEEE, P670
   Organization WH, 2014, WORLD CANC REPORT
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Tjoa MP, 2003, BIOMED ENG ONLINE, V2, DOI 10.1186/1475-925X-2-9
   van Rijn JC, 2006, AM J GASTROENTEROL, V101, P343, DOI 10.1111/j.1572-0241.2006.00390.x
   Viola P., 2005, C NEUR INF PROC SYST
NR 24
TC 4
Z9 4
U1 1
U2 3
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1609-0985
EI 2199-4757
J9 J MED BIOL ENG
JI J. Med. Biol. Eng.
PD DEC
PY 2016
VL 36
IS 6
SI SI
BP 871
EP 882
DI 10.1007/s40846-016-0190-4
PG 12
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA EH9IN
UT WOS:000392085100012
DA 2023-08-21
ER

PT J
AU Oliva, JT
   Lee, HD
   Spolaor, N
   Coy, CSR
   Wu, FC
AF Oliva, Jefferson Tales
   Lee, Huei Diana
   Spolaor, Newton
   Coy, Claudio Saddy Rodrigues
   Wu, Feng Chung
TI Prototype system for feature extraction, classification and study of
   medical images
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Image analysis; Texture; Machine learning; Prototyping; Artificial
   intelligence; Medical information systems
ID COMPUTER-AIDED DETECTION; TEXTURAL FEATURES; FALSE POSITIVES; POLYPS;
   REDUCTION; SCALE
AB Colonoscopy exam images are useful to identify diseases, such as the colorectal cancer, which is one of the most common cancers worldwide. Computational image analysis and machine learning techniques can assist experts to identify abnormalities in these images. In this work, we present and evaluate MIAS 3.0, which aims to help experts to study and analyze colon tissue images. To do so, the system initially extracts features from these images. Currently, Amadasum, Haralick and Laws texture descriptors are supported. Then, the described images are classified into normal or abnormal images. In this version, J48, nearest neighbor, backpropagation based on multilayer perceptron, naive Bayes, and support vector machine classification algorithms are implemented. MIAS was developed with open source technologies using a software engineering approach to improve flexibility and maintainability. In this work, MIAS was quantitatively assessed by its application in a set of 134 tissue image fragments. The classifiers built from this set were compared according to the cross-validation and contingency table strategies. Also, the system was qualitatively evaluated using 12 heuristics by twelve volunteers from Health and Exact Sciences. The issues found were categorized according to Rolf Molich's severity scale. As a result, the J48 classifier achieved the highest sensitivity (85.07%) and reasonable average error (18.68%). In the qualitative evaluation, 61.26% of the issues found were not considered serious. These assessments suggest that MIAS can be useful to assist domain experts with minimum knowledge in informatics to conduct more complete studies of medical images, by identifying patterns regarding different abnormalities. (C) 2016 Published by Elsevier Ltd.
C1 [Oliva, Jefferson Tales] Univ Sao Paulo, Bioinspired Comp Lab, Trabalhador Sao Carlense Ave, BR-13560970 Sao Paulo, Brazil.
   [Oliva, Jefferson Tales; Lee, Huei Diana; Spolaor, Newton; Wu, Feng Chung] Western Parana State Univ, Lab Bioinformat, Presidente Tancredo Neves Ave 6731, BR-85867900 Foz Do Iguacu, Parana, Brazil.
   [Coy, Claudio Saddy Rodrigues; Wu, Feng Chung] Univ Estadual Campinas, Serv Coloproctol, Tessalia Vieira de Camargo St 126, BR-13083887 Sao Paulo, Brazil.
C3 Universidade de Sao Paulo; Centro Universitario La Salle; Universidade
   Estadual de Campinas
RP Lee, HD (通讯作者)，Western Parana State Univ, Lab Bioinformat, Presidente Tancredo Neves Ave 6731, BR-85867900 Foz Do Iguacu, Parana, Brazil.
EM jeffersontalesoliva@gmail.com; huei.lee@unioeste.br;
   newtonspolaor@gmail.com; claudiocoy@gmail.com; wufengchung@gmail.com
RI Lee, Huei Diana/D-8219-2015; Coy, Claudio/AAD-7599-2019; Chung, Wu
   Feng/AAB-1319-2021
OI Lee, Huei Diana/0000-0002-2189-1047; OLIVA,
   JEFFERSON/0000-0003-1574-1293
FU Higher Education Personnel (CAPES); Graduate Program in Electrical
   Engineering and Computer Science (PGEEC); Western Parana State
   University (Unioeste
FX The authors would like to thank the Coordination for the Improvement of
   Higher Education Personnel (CAPES) and the Graduate Program in
   Electrical Engineering and Computer Science (PGEEC) at the Western
   Parana State University (Unioeste) for the financial support.
CR Aizerman M. A., 1964, AUTOMAT REM CONTR, V25, P821, DOI DOI 10.1234/12345678
   Alpaydin E, 2014, ADAPT COMPUT MACH LE, P115
   AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   [Anonymous], 2014, COL CANC FACTS FIG 2
   [Anonymous], P 9 INT WORKSH RES E
   Beura S, 2015, NEUROCOMPUTING, V154, P1, DOI 10.1016/j.neucom.2014.12.032
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dasgupta S, 2003, RANDOM STRUCT ALGOR, V22, P60, DOI 10.1002/rsa.10073
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Ferrero C. A., 2009, BRAZILIAN J COLOPROC, V29, P23
   Fredman D, 1988, STATISTICS
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Fu JJC, 2014, COMPUT MED IMAG GRAP, V38, P267, DOI 10.1016/j.compmedimag.2013.12.009
   Gokturk SB, 2001, IEEE T MED IMAGING, V20, P1251, DOI 10.1109/42.974920
   Hafner M, 2015, MED IMAGE ANAL, V26, P92, DOI 10.1016/j.media.2015.08.007
   Hall M., 2009, WEKA 3 DATA MINING S
   Han J, 2012, MOR KAUF D, P1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Haykin S., 2009, NEURAL NETWORKS LEAR
   Hyvarinen A, 2013, PHILOS T R SOC A, V371, DOI 10.1098/rsta.2011.0534
   Karahaliou AN, 2008, IEEE T INF TECHNOL B, V12, P731, DOI 10.1109/TITB.2008.920634
   Karkanis S., 1999, P WORKSH MACH LEARN, P63
   Kominami Y, 2016, GASTROINTEST ENDOSC, V83, P643, DOI 10.1016/j.gie.2015.08.004
   Laws K., 1980, THESIS U SO CALIFORN
   Laws KI, 1979, P IM UND WORKSH, P47, DOI DOI 10.111141600-0846.2009.00354.X
   Lee H. D., 2013, P BRAZ C COL
   Li WQ, 2015, MED IMAGE ANAL, V26, P57, DOI 10.1016/j.media.2015.08.002
   Lilholt PH, 2015, INT J MED INFORM, V84, P319, DOI 10.1016/j.ijmedinf.2015.01.012
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu Z, 2011, LECT NOTES COMPUT SC, V6893, P124, DOI 10.1007/978-3-642-23626-6_16
   Lowe D. G, 1999, PROC 7 IEEE INT C CO, P1150
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mack R. L., 1994, USABILITY INSPECTION
   Mahapatra D, 2013, J DIGIT IMAGING, V26, P920, DOI 10.1007/s10278-013-9576-9
   Molich R, 2008, USABLE WEB DESIGN
   Molina JFG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093600
   Nanni L, 2013, EXPERT SYST APPL, V40, P7457, DOI 10.1016/j.eswa.2013.07.047
   Nappi J, 2002, ACAD RADIOL, V9, P386, DOI 10.1016/S1076-6332(03)80184-8
   National Cancer Institute of Brazil, 2014, EST 2014 CANC INC BR
   NetBeans I., 2015, NETB IDE FEAT
   Nielsen J., 1995, NIELSEN NORMAN GROUP, V1
   Niu LL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076880
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva J. T., 2012, P BRAZ C HLTH INF, P1
   Oracle, 2015, JAV ADV IM
   Pedrini H., 2008, DIGITAL IMAGE ANAL P
   Pressman R., 2010, SOFTWARE ENG PROFESS
   Quilici F., 2000, COLONOSCOPY
   Quinlan J. R., 1993, PROGRAM MACHINE LEAR
   Rezende S. O, 2003, INTELLIGENT SYSTEMS
   Shan J, 2012, ULTRASOUND MED BIOL, V38, P262, DOI 10.1016/j.ultrasmedbio.2011.10.022
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Spolaor N., 2010, P BRAZ C HLTH INF, P1
   Suzuki K, 2006, MED PHYS, V33, P3814, DOI 10.1118/1.2349839
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Wang ZA, 2005, MED PHYS, V32, P3602, DOI 10.1118/1.2122447
   Witten I., 2011, MACHINE LEARNING PRA
   Wong W. K., 2013, INT J ENHANCED RES S, V2, P1
   Zhang X., 2006, P ANN INT C ENG MED, P867
NR 61
TC 13
Z9 15
U1 0
U2 80
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 30
PY 2016
VL 63
BP 267
EP 283
DI 10.1016/j.eswa.2016.07.008
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA DU5TH
UT WOS:000382273700022
DA 2023-08-21
ER

EF